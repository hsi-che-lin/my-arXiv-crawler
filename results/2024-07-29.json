[
    {
        "paper id": "2407.20228",
        "abstract url": "https://arxiv.org/abs/2407.20228",
        "title": "FlexAttention for Efficient High-Resolution Vision-Language Models",
        "rating": "2.5",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Current high-resolution vision-language models encode images as high-resolution image tokens and exhaustively take all these tokens to compute attention, which significantly increases the computational cost. To address this problem, we propose FlexAttention, a flexible attention mechanism for efficient high-resolution vision-language models. Specifically, a high-resolution image is encoded both as high-resolution tokens and low-resolution tokens, where only the low-resolution tokens and a few selected high-resolution tokens are utilized to calculate the attention map, which greatly shrinks the computational cost. The high-resolution tokens are selected via a high-resolution selection module which could retrieve tokens of relevant regions based on an input attention map. The selected high-resolution tokens are then concatenated to the low-resolution tokens and text tokens, and input to a hierarchical self-attention layer which produces an attention map that could be used for the next-step high-resolution token selection. The hierarchical self-attention process and high-resolution token selection process are performed iteratively for each attention layer. Experiments on multimodal benchmarks prove that our FlexAttention outperforms existing high-resolution VLMs (e.g., relatively ~9% in V* Bench, ~7% in TextVQA), while also significantly reducing the computational cost by nearly 40%.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2407.19795",
        "abstract url": "https://arxiv.org/abs/2407.19795",
        "title": "VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Domain generalizability is a crucial aspect of a deep learning model since it determines the capability of the model to perform well on data from unseen domains. However, research on the domain generalizability of deep learning models for vision-language tasks remains limited, primarily because of the lack of required datasets. To address these challenges, we propose VolDoGer: Vision-Language Dataset for Domain Generalization, a dedicated dataset designed for domain generalization that addresses three vision-language tasks: image captioning, visual question answering, and visual entailment. We constructed VolDoGer by extending LLM-based data annotation techniques to vision-language tasks, thereby alleviating the burden of recruiting human annotators. We evaluated the domain generalizability of various models, ranging from fine-tuned models to a recent multimodal large language model, through VolDoGer.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "31 pages, 5 figures, 20 tables"
    },
    {
        "paper id": "2407.20034",
        "abstract url": "https://arxiv.org/abs/2407.20034",
        "title": "MaskInversion: Localized Embeddings via Optimization of Explainability Maps",
        "rating": "2",
        "keywords": [
            [
                "Vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-language foundation models such as CLIP have achieved tremendous results in global vision-language alignment, but still show some limitations in creating representations for specific image regions. % To address this problem, we propose MaskInversion, a method that leverages the feature representations of pre-trained foundation models, such as CLIP, to generate a context-aware embedding for a query image region specified by a mask at test time. MaskInversion starts with initializing an embedding token and compares its explainability map, derived from the foundation model, to the query mask. The embedding token is then subsequently refined to approximate the query region by minimizing the discrepancy between its explainability map and the query mask. During this process, only the embedding vector is updated, while the underlying foundation model is kept frozen allowing to use MaskInversion with any pre-trained model. As deriving the explainability map involves computing its gradient, which can be expensive, we propose a gradient decomposition strategy that simplifies this computation. The learned region representation can be used for a broad range of tasks, including open-vocabulary class retrieval, referring expression comprehension, as well as for localized captioning and image generation. We evaluate the proposed method on all those tasks on several datasets such as PascalVOC, MSCOCO, RefCOCO, and OpenImagesV7 and show its capabilities compared to other SOTA approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://walidbousselham.com/MaskInversion"
    },
    {
        "paper id": "2407.20086",
        "abstract url": "https://arxiv.org/abs/2407.20086",
        "title": "Segmenting Fetal Head with Efficient Fine-tuning Strategies in Low-resource Settings: an empirical study with U-Net",
        "rating": "2",
        "keywords": [
            [
                "Efficient Fine-tuning"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Accurate measurement of fetal head circumference is crucial for estimating fetal growth during routine prenatal screening. Prior to measurement, it is necessary to accurately identify and segment the region of interest, specifically the fetal head, in ultrasound images. Recent advancements in deep learning techniques have shown significant progress in segmenting the fetal head using encoder-decoder models. Among these models, U-Net has become a standard approach for accurate segmentation. However, training an encoder-decoder model can be a time-consuming process that demands substantial computational resources. Moreover, fine-tuning these models is particularly challenging when there is a limited amount of data available. There are still no \"best-practice\" guidelines for optimal fine-tuning of U-net for fetal ultrasound image segmentation. This work summarizes existing fine-tuning strategies with various backbone architectures, model components, and fine-tuning strategies across ultrasound data from Netherlands, Spain, Malawi, Egypt and Algeria. Our study shows that (1) fine-tuning U-Net leads to better performance than training from scratch, (2) fine-tuning strategies in decoder are superior to other strategies, (3) network architecture with less number of parameters can achieve similar or better performance. We also demonstrate the effectiveness of fine-tuning strategies in low-resource settings and further expand our experiments into few-shot learning. Lastly, we publicly released our code and specific fine-tuned weights.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "5 figures, 2 tables"
    },
    {
        "paper id": "2407.20114",
        "abstract url": "https://arxiv.org/abs/2407.20114",
        "title": "FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In the field of Image-Text Retrieval (ITR), recent advancements have leveraged large-scale Vision-Language Pretraining (VLP) for Fine-Grained (FG) instance-level retrieval, achieving high accuracy at the cost of increased computational complexity. For Coarse-Grained (CG) category-level retrieval, prominent approaches employ Cross-Modal Hashing (CMH) to prioritise efficiency, albeit at the cost of retrieval performance. Due to differences in methodologies, FG and CG models are rarely compared directly within evaluations in the literature, resulting in a lack of empirical data quantifying the retrieval performance-efficiency tradeoffs between the two. This paper addresses this gap by introducing the \\texttt{FiCo-ITR} library, which standardises evaluation methodologies for both FG and CG models, facilitating direct comparisons. We conduct empirical evaluations of representative models from both subfields, analysing precision, recall, and computational complexity across varying data scales. Our findings offer new insights into the performance-efficiency trade-offs between recent representative FG and CG models, highlighting their respective strengths and limitations. These findings provide the foundation necessary to make more informed decisions regarding model selection for specific retrieval tasks and highlight avenues for future research into hybrid systems that leverage the strengths of both FG and CG approaches.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "19 pages, submitted to International Journal of Multimedia Information Retrieval"
    },
    {
        "paper id": "2407.20013",
        "abstract url": "https://arxiv.org/abs/2407.20013",
        "title": "Classification of freshwater snails of the genus Radomaniola with multimodal triplet networks",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In this paper, we present our first proposal of a machine learning system for the classification of freshwater snails of the genus Radomaniola. We elaborate on the specific challenges encountered during system design, and how we tackled them; namely a small, very imbalanced dataset with a high number of classes and high visual similarity between classes. We then show how we employed triplet networks and the multiple input modalities of images, measurements, and genetic information to overcome these challenges and reach a performance comparable to that of a trained domain expert.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Spotlight at ICML 2024 AI for Science workshop"
    },
    {
        "paper id": "2407.20143",
        "abstract url": "https://arxiv.org/abs/2407.20143",
        "title": "ByteCheckpoint: A Unified Checkpointing System for LLM Development",
        "rating": "1.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The development of real-world Large Language Models (LLMs) necessitates checkpointing of training states in persistent storage to mitigate potential software and hardware failures, as well as to facilitate checkpoint transferring within the training pipeline and across various tasks. Due to the immense size of LLMs, saving and loading checkpoints often incur intolerable minute-level stalls, significantly diminishing training efficiency. Besides, when transferring checkpoints across tasks, checkpoint resharding, defined as loading checkpoints into parallel configurations differing from those used for saving, is often required according to the characteristics and resource quota of specific tasks. Previous checkpointing systems [16,3,33,6] assume consistent parallel configurations, failing to address the complexities of checkpoint transformation during resharding. Furthermore, in the industry platform, developers create checkpoints from different training frameworks[23,36,21,11], each with its own unique storage and I/O logic. This diversity complicates the implementation of unified checkpoint management and optimization. To address these challenges, we introduce ByteCheckpoint, a PyTorch-native multi-framework LLM checkpointing system that supports automatic online checkpoint resharding. ByteCheckpoint employs a data/metadata disaggregated storage architecture, decoupling checkpoint storage from the adopted parallelism strategies and training frameworks. We design an efficient asynchronous tensor merging technique to settle the irregular tensor sharding problem and propose several I/O performance optimizations to significantly enhance the efficiency of checkpoint saving and loading. Experimental results demonstrate ByteCheckpoint's substantial advantages in reducing checkpoint saving (by up to 529.22X) and loading (by up to 3.51X) costs, compared to baseline methods.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20230",
        "abstract url": "https://arxiv.org/abs/2407.20230",
        "title": "SAPG: Split and Aggregate Policy Gradients",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Despite extreme sample inefficiency, on-policy reinforcement learning, aka policy gradients, has become a fundamental tool in decision-making problems. With the recent advances in GPU-driven simulation, the ability to collect large amounts of data for RL training has scaled exponentially. However, we show that current RL methods, e.g. PPO, fail to ingest the benefit of parallelized environments beyond a certain point and their performance saturates. To address this, we propose a new on-policy RL algorithm that can effectively leverage large-scale environments by splitting them into chunks and fusing them back together via importance sampling. Our algorithm, termed SAPG, shows significantly higher performance across a variety of challenging environments where vanilla PPO and other strong baselines fail to achieve high performance. Website at https://sapg-rl.github.io/",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.RO",
            "eess.SY"
        ],
        "comment": "In ICML 2024 (Oral). Website at https://sapg-rl.github.io/"
    },
    {
        "paper id": "2407.20341",
        "abstract url": "https://arxiv.org/abs/2407.20341",
        "title": "BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Effectively aligning with human judgment when evaluating machine-generated image captions represents a complex yet intriguing challenge. Existing evaluation metrics like CIDEr or CLIP-Score fall short in this regard as they do not take into account the corresponding image or lack the capability of encoding fine-grained details and penalizing hallucinations. To overcome these issues, in this paper, we propose BRIDGE, a new learnable and reference-free image captioning metric that employs a novel module to map visual features into dense vectors and integrates them into multi-modal pseudo-captions which are built during the evaluation process. This approach results in a multimodal metric that properly incorporates information from the input image without relying on reference captions, bridging the gap between human judgment and machine-generated image captions. Experiments spanning several datasets demonstrate that our proposal achieves state-of-the-art results compared to existing reference-free evaluation scores. Our source code and trained models are publicly available at: https://github.com/aimagelab/bridge-score.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.MM"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2407.20371",
        "abstract url": "https://arxiv.org/abs/2407.20371",
        "title": "Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Artificial intelligence (AI) hiring tools have revolutionized resume screening, and large language models (LLMs) have the potential to do the same. However, given the biases which are embedded within LLMs, it is unclear whether they can be used in this scenario without disadvantaging groups based on their protected attributes. In this work, we investigate the possibilities of using LLMs in a resume screening setting via a document retrieval framework that simulates job candidate selection. Using that framework, we then perform a resume audit study to determine whether a selection of Massive Text Embedding (MTE) models are biased in resume screening scenarios. We simulate this for nine occupations, using a collection of over 500 publicly available resumes and 500 job descriptions. We find that the MTEs are biased, significantly favoring White-associated names in 85.1\\% of cases and female-associated names in only 11.1\\% of cases, with a minority of cases showing no statistically significant differences. Further analyses show that Black males are disadvantaged in up to 100\\% of cases, replicating real-world patterns of bias in employment settings, and validate three hypotheses of intersectionality. We also find an impact of document length as well as the corpus frequency of names in the selection of resumes. These findings have implications for widely used AI tools that are automating employment, fairness, and tech policy.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "To be published in Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society; code available at https://github.com/kyrawilson/Resume-Screening-Bias"
    },
    {
        "paper id": "2407.20524",
        "abstract url": "https://arxiv.org/abs/2407.20524",
        "title": "Contrastive Feedback Mechanism for Simultaneous Speech Translation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Recent advances in simultaneous speech translation (SST) focus on the decision policies that enable the use of offline-trained ST models for simultaneous inference. These decision policies not only control the quality-latency trade-off in SST but also mitigate the impact of unstable predictions on translation quality by delaying translation for more context or discarding these predictions through stable hypothesis detection. However, these policies often overlook the potential benefits of utilizing unstable predictions. We introduce the contrastive feedback mechanism (CFM) for SST, a novel method that leverages these unstable predictions as feedback to improve translation quality. CFM guides the system to eliminate undesired model behaviors from these predictions through a contrastive objective. The experiments on 3 state-of-the-art decision policies across 8 languages in the MuST-C v1.0 dataset show that CFM effectively improves the performance of SST.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to Interspeech 2024 main conference"
    },
    {
        "paper id": "2407.20530",
        "abstract url": "https://arxiv.org/abs/2407.20530",
        "title": "SuperCodec: A Neural Speech Codec with Selective Back-Projection Network",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Neural speech coding is a rapidly developing topic, where state-of-the-art approaches now exhibit superior compression performance than conventional methods. Despite significant progress, existing methods still have limitations in preserving and reconstructing fine details for optimal reconstruction, especially at low bitrates. In this study, we introduce SuperCodec, a neural speech codec that achieves state-of-the-art performance at low bitrates. It employs a novel back projection method with selective feature fusion for augmented representation. Specifically, we propose to use Selective Up-sampling Back Projection (SUBP) and Selective Down-sampling Back Projection (SDBP) modules to replace the standard up- and down-sampling layers at the encoder and decoder, respectively. Experimental results show that our method outperforms the existing neural speech codecs operating at various bitrates. Specifically, our proposed method can achieve higher quality reconstructed speech at 1 kbps than Lyra V2 at 3.2 kbps and Encodec at 6 kbps.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by ICASSP 2024"
    },
    {
        "paper id": "2407.19719",
        "abstract url": "https://arxiv.org/abs/2407.19719",
        "title": "Revolutionizing Urban Safety Perception Assessments: Integrating Multimodal Large Language Models with Street View Images",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Measuring urban safety perception is an important and complex task that traditionally relies heavily on human resources. This process often involves extensive field surveys, manual data collection, and subjective assessments, which can be time-consuming, costly, and sometimes inconsistent. Street View Images (SVIs), along with deep learning methods, provide a way to realize large-scale urban safety detection. However, achieving this goal often requires extensive human annotation to train safety ranking models, and the architectural differences between cities hinder the transferability of these models. Thus, a fully automated method for conducting safety evaluations is essential. Recent advances in multimodal large language models (MLLMs) have demonstrated powerful reasoning and analytical capabilities. Cutting-edge models, e.g., GPT-4 have shown surprising performance in many tasks. We employed these models for urban safety ranking on a human-annotated anchor set and validated that the results from MLLMs align closely with human perceptions. Additionally, we proposed a method based on the pre-trained Contrastive Language-Image Pre-training (CLIP) feature and K-Nearest Neighbors (K-NN) retrieval to quickly assess the safety index of the entire city. Experimental results show that our method outperforms existing training needed deep learning approaches, achieving efficient and accurate urban safety evaluations. The proposed automation for urban safety perception assessment is a valuable tool for city planners, policymakers, and researchers aiming to improve urban environments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 9 figures"
    },
    {
        "paper id": "2407.19726",
        "abstract url": "https://arxiv.org/abs/2407.19726",
        "title": "Do Text-to-Vis Benchmarks Test Real Use of Visualisations?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models are able to generate code for visualisations in response to user requests. This is a useful application, and an appealing one for NLP research because plots of data provide grounding for language. However, there are relatively few benchmarks, and it is unknown whether those that exist are representative of what people do in practice. This paper aims to answer that question through an empirical study comparing benchmark datasets and code from public repositories. Our findings reveal a substantial gap in datasets, with evaluations not testing the same distribution of chart types, attributes, and the number of actions. The only representative dataset requires modification to become an end-to-end and practical benchmark. This shows that new, more benchmarks are needed to support the development of systems that truly address users' visualisation needs. These observations will guide future data creation, highlighting which features hold genuine significance for users.",
        "subjects": [
            "cs.CL",
            "cs.HC"
        ],
        "comment": "ARR AE score of 4"
    },
    {
        "paper id": "2407.19740",
        "abstract url": "https://arxiv.org/abs/2407.19740",
        "title": "KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations in Dialogical Argument Mining",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Dialogical Argument Mining(DialAM) is an important branch of Argument Mining(AM). DialAM-2024 is a shared task focusing on dialogical argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes. To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment the training data in both stages and introduce context in Stage 2. We successfully completed the task and achieved good results. Our team Pokemon ranked 1st in the ARI Focused score and 4th in the Global Focused score.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Published on the 11th Workshop on Argument Mining"
    },
    {
        "paper id": "2407.19746",
        "abstract url": "https://arxiv.org/abs/2407.19746",
        "title": "Octave-YOLO: Cross frequency detection network with octave convolution",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the rapid advancement of object detection algorithms, processing high-resolution images on embedded devices remains a significant challenge. Theoretically, the fully convolutional network architecture used in current real-time object detectors can handle all input resolutions. However, the substantial computational demands required to process high-resolution images render them impractical for real-time applications. To address this issue, real-time object detection models typically downsample the input image for inference, leading to a loss of detail and decreased accuracy. In response, we developed Octave-YOLO, designed to process high-resolution images in real-time within the constraints of embedded systems. We achieved this through the introduction of the cross frequency partial network (CFPNet), which divides the input feature map into low-resolution, low-frequency, and high-resolution, high-frequency sections. This configuration enables complex operations such as convolution bottlenecks and self-attention to be conducted exclusively on low-resolution feature maps while simultaneously preserving the details in high-resolution maps. Notably, this approach not only dramatically reduces the computational demands of convolution tasks but also allows for the integration of attention modules, which are typically challenging to implement in real-time applications, with minimal additional cost. Additionally, we have incorporated depthwise separable convolution into the core building blocks and downsampling layers to further decrease latency. Experimental results have shown that Octave-YOLO matches the performance of YOLOv8 while significantly reducing computational demands. For example, in 1080x1080 resolution, Octave-YOLO-N is 1.56 times faster than YOLOv8, achieving nearly the same accuracy on the COCO dataset with approximately 40 percent fewer parameters and FLOPs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19752",
        "abstract url": "https://arxiv.org/abs/2407.19752",
        "title": "Contextuality Helps Representation Learning for Generalized Category Discovery",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel approach to Generalized Category Discovery (GCD) by leveraging the concept of contextuality to enhance the identification and classification of categories in unlabeled datasets. Drawing inspiration from human cognition's ability to recognize objects within their context, we propose a dual-context based method. Our model integrates two levels of contextuality: instance-level, where nearest-neighbor contexts are utilized for contrastive learning, and cluster-level, employing prototypical contrastive learning based on category prototypes. The integration of the contextual information effectively improves the feature learning and thereby the classification accuracy of all categories, which better deals with the real-world datasets. Different from the traditional semi-supervised and novel category discovery techniques, our model focuses on a more realistic and challenging scenario where both known and novel categories are present in the unlabeled data. Extensive experimental results on several benchmark data sets demonstrate that the proposed model outperforms the state-of-the-art. Code is available at: https://github.com/Clarence-CV/Contexuality-GCD",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19753",
        "abstract url": "https://arxiv.org/abs/2407.19753",
        "title": "PredIN: Towards Open-Set Gesture Recognition via Prediction Inconsistency",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Gesture recognition based on surface electromyography (sEMG) has achieved significant progress in human-machine interaction (HMI). However, accurately recognizing predefined gestures within a closed set is still inadequate in practice; a robust open-set system needs to effectively reject unknown gestures while correctly classifying known ones. To handle this challenge, we first report prediction inconsistency discovered for unknown classes due to ensemble diversity, which can significantly facilitate the detection of unknown classes. Based on this insight, we propose an ensemble learning approach, PredIN, to explicitly magnify the prediction inconsistency by enhancing ensemble diversity. Specifically, PredIN maximizes the class feature distribution inconsistency among ensemble members to enhance diversity. Meanwhile, it optimizes inter-class separability within an individual ensemble member to maintain individual performance. Comprehensive experiments on various benchmark datasets demonstrate that the PredIN outperforms state-of-the-art methods by a clear margin.Our proposed method simultaneously achieves accurate closed-set classification for predefined gestures and effective rejection for unknown gestures, exhibiting its efficacy and superiority in open-set gesture recognition based on sEMG.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2407.19775",
        "abstract url": "https://arxiv.org/abs/2407.19775",
        "title": "Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid growth of large-scale AI models, particularly large language models has brought significant challenges in data privacy, computational resources, and accessibility. Traditional centralized architectures often struggle to meet required data security and scalability needs which hinders the democratization of AI systems. Nesa introduces a model-agnostic sharding framework designed for decentralized AI inference. Our framework uses blockchain-based sequential deep neural network sharding to distribute computational tasks across a diverse network of nodes based on a personalised heuristic and routing mechanism. This enables efficient distributed training and inference for recent large-scale models even on consumer-grade hardware. We use compression techniques like dynamic blockwise quantization and mixed matrix decomposition to reduce data transfer and memory needs. We also integrate robust security measures, including hardware-based trusted execution environments to ensure data integrity and confidentiality. Evaluating our system across various natural language processing and vision tasks shows that these compression strategies do not compromise model accuracy. Our results highlight the potential to democratize access to cutting-edge AI technologies by enabling secure and efficient inference on a decentralized network.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19779",
        "abstract url": "https://arxiv.org/abs/2407.19779",
        "title": "Synthesizing Scientific Summaries: An Extractive and Abstractive Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The availability of a vast array of research papers in any area of study, necessitates the need of automated summarisation systems that can present the key research conducted and their corresponding findings. Scientific paper summarisation is a challenging task for various reasons including token length limits in modern transformer models and corresponding memory and compute requirements for long text. A significant amount of work has been conducted in this area, with approaches that modify the attention mechanisms of existing transformer models and others that utilise discourse information to capture long range dependencies in research papers. In this paper, we propose a hybrid methodology for research paper summarisation which incorporates an extractive and abstractive approach. We use the extractive approach to capture the key findings of research, and pair it with the introduction of the paper which captures the motivation for research. We use two models based on unsupervised learning for the extraction stage and two transformer language models, resulting in four combinations for our hybrid approach. The performances of the models are evaluated on three metrics and we present our findings in this paper. We find that using certain combinations of hyper parameters, it is possible for automated summarisation systems to exceed the abstractiveness of summaries written by humans. Finally, we state our future scope of research in extending this methodology to summarisation of generalised long documents.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "the paper consists of 10 pages , 5 figures and 4 tables"
    },
    {
        "paper id": "2407.19787",
        "abstract url": "https://arxiv.org/abs/2407.19787",
        "title": "SciPostLayout: A Dataset for Layout Analysis and Layout Generation of Scientific Posters",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Scientific posters are used to present the contributions of scientific papers effectively in a graphical format. However, creating a well-designed poster that efficiently summarizes the core of a paper is both labor-intensive and time-consuming. A system that can automatically generate well-designed posters from scientific papers would reduce the workload of authors and help readers understand the outline of the paper visually. Despite the demand for poster generation systems, only a limited research has been conduced due to the lack of publicly available datasets. Thus, in this study, we built the SciPostLayout dataset, which consists of 7,855 scientific posters and manual layout annotations for layout analysis and generation. SciPostLayout also contains 100 scientific papers paired with the posters. All of the posters and papers in our dataset are under the CC-BY license and are publicly available. As benchmark tests for the collected dataset, we conducted experiments for layout analysis and generation utilizing existing computer vision models and found that both layout analysis and generation of posters using SciPostLayout are more challenging than with scientific papers. We also conducted experiments on generating layouts from scientific papers to demonstrate the potential of utilizing LLM as a scientific poster generation system. The dataset is publicly available at https://huggingface.co/datasets/omron-sinicx/scipostlayout_v2. The code is also publicly available at https://github.com/omron-sinicx/scipostlayout.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by BMVC2024"
    },
    {
        "paper id": "2407.19789",
        "abstract url": "https://arxiv.org/abs/2407.19789",
        "title": "Interpreting Low-level Vision Models with Causal Effect Maps",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural networks have significantly improved the performance of low-level vision tasks but also increased the difficulty of interpretability. A deep understanding of deep models is beneficial for both network design and practical reliability. To take up this challenge, we introduce causality theory to interpret low-level vision models and propose a model-/task-agnostic method called Causal Effect Map (CEM). With CEM, we can visualize and quantify the input-output relationships on either positive or negative effects. After analyzing various low-level vision tasks with CEM, we have reached several interesting insights, such as: (1) Using more information of input images (e.g., larger receptive field) does NOT always yield positive outcomes. (2) Attempting to incorporate mechanisms with a global receptive field (e.g., channel attention) into image denoising may prove futile. (3) Integrating multiple tasks to train a general model could encourage the network to prioritize local information over global context. Based on the causal effect theory, the proposed diagnostic tool can refresh our common knowledge and bring a deeper understanding of low-level vision models. Codes are available at https://github.com/J-FHu/CEM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19794",
        "abstract url": "https://arxiv.org/abs/2407.19794",
        "title": "Introducing a new hyper-parameter for RAG: Context Window Utilization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces a new hyper-parameter for Retrieval-Augmented Generation (RAG) systems called Context Window Utilization. RAG systems enhance generative models by incorporating relevant information retrieved from external knowledge bases, improving the factual accuracy and contextual relevance of generated responses. The size of the text chunks retrieved and processed is a critical factor influencing RAG performance. This study aims to identify the optimal chunk size that maximizes answer generation quality. Through systematic experimentation, we analyze the effects of varying chunk sizes on the efficiency and effectiveness of RAG frameworks. Our findings reveal that an optimal chunk size balances the trade-off between providing sufficient context and minimizing irrelevant information. These insights are crucial for enhancing the design and implementation of RAG systems, underscoring the importance of selecting an appropriate chunk size to achieve superior performance.",
        "subjects": [
            "cs.CL",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19798",
        "abstract url": "https://arxiv.org/abs/2407.19798",
        "title": "Teaching LLMs at Charles University: Assignments and Activities",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents teaching materials, particularly assignments and ideas for classroom activities, from a new course on large language models (LLMs) taught at Charles University. The assignments include experiments with LLM inference for weather report generation and machine translation. The classroom activities include class quizzes, focused research on downstream tasks and datasets, and an interactive \"best paper\" session aimed at reading and comprehension of research papers.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "6th TeachNLP workshop at ACL 2024"
    },
    {
        "paper id": "2407.19807",
        "abstract url": "https://arxiv.org/abs/2407.19807",
        "title": "Cool-Fusion: Fuse Large Language Models without Training",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We focus on the problem of fusing two or more heterogeneous large language models (LLMs) to facilitate their complementary strengths. One of the challenges on model fusion is high computational load, i.e. to fine-tune or to align vocabularies via combinatorial optimization. To this end, we propose \\emph{Cool-Fusion}, a simple yet effective approach that fuses the knowledge of heterogeneous source LLMs to leverage their complementary strengths. \\emph{Cool-Fusion} is the first method that does not require any type of training like the ensemble approaches. But unlike ensemble methods, it is applicable to any set of source LLMs that have different vocabularies. The basic idea is to have each source LLM individually generate tokens until the tokens can be decoded into a text segment that ends at word boundaries common to all source LLMs. Then, the source LLMs jointly rerank the generated text segment and select the best one, which is the fused text generation in one step. Extensive experiments are conducted across a variety of benchmark datasets. On \\emph{GSM8K}, \\emph{Cool-Fusion} increases accuracy from three strong source LLMs by a significant 8\\%-17.8\\%.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19812",
        "abstract url": "https://arxiv.org/abs/2407.19812",
        "title": "Image-text matching for large-scale book collections",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We address the problem of detecting and mapping all books in a collection of images to entries in a given book catalogue. Instead of performing independent retrieval for each book detected, we treat the image-text mapping problem as a many-to-many matching process, looking for the best overall match between the two sets. We combine a state-of-the-art segmentation method (SAM) to detect book spines and extract book information using a commercial OCR. We then propose a two-stage approach for text-image matching, where CLIP embeddings are used first for fast matching, followed by a second slower stage to refine the matching, employing either the Hungarian Algorithm or a BERT-based model trained to cope with noisy OCR input and partial text matches. To evaluate our approach, we publish a new dataset of annotated bookshelf images that covers the whole book collection of a public library in Spain. In addition, we provide two target lists of book metadata, a closed-set of 15k book titles that corresponds to the known library inventory, and an open-set of 2.3M book titles to simulate an open-world scenario. We report results on two settings, on one hand on a matching-only task, where the book segments and OCR is given and the objective is to perform many-to-many matching against the target lists, and a combined detection and matching task, where books must be first detected and recognised before they are matched to the target list entries. We show that both the Hungarian Matching and the proposed BERT-based model outperform a fuzzy string matching baseline, and we highlight inherent limitations of the matching algorithms as the target increases in size, and when either of the two sets (detected books or target book list) is incomplete. The dataset and code are available at https://github.com/llabres/library-dataset",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19820",
        "abstract url": "https://arxiv.org/abs/2407.19820",
        "title": "ActivityCLIP: Enhancing Group Activity Recognition by Mining Complementary Information from Text to Supplement Image Modality",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Previous methods usually only extract the image modality's information to recognize group activity. However, mining image information is approaching saturation, making it difficult to extract richer information. Therefore, extracting complementary information from other modalities to supplement image information has become increasingly important. In fact, action labels provide clear text information to express the action's semantics, which existing methods often overlook. Thus, we propose ActivityCLIP, a plug-and-play method for mining the text information contained in the action labels to supplement the image information for enhancing group activity recognition. ActivityCLIP consists of text and image branches, where the text branch is plugged into the image branch (The off-the-shelf image-based method). The text branch includes Image2Text and relation modeling modules. Specifically, we propose the knowledge transfer module, Image2Text, which adapts image information into text information extracted by CLIP via knowledge distillation. Further, to keep our method convenient, we add fewer trainable parameters based on the relation module of the image branch to model interaction relation in the text branch. To show our method's generality, we replicate three representative methods by ActivityCLIP, which adds only limited trainable parameters, achieving favorable performance improvements for each method. We also conduct extensive ablation studies and compare our method with state-of-the-art methods to demonstrate the effectiveness of ActivityCLIP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19825",
        "abstract url": "https://arxiv.org/abs/2407.19825",
        "title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Today's large language models (LLMs) can solve challenging question-answering tasks, and prompt engineering techniques, such as chain-of-thought (CoT), have gained attention for enhancing the explanation and correctness of outputs. Nevertheless, models require significant time to generate answers augmented with lengthy reasoning details. To address this issue, this paper analyzes the impact of output lengths on LLM inference pipelines and proposes novel metrics to evaluate them in terms of \\textit{correct conciseness}. It also examines the impact of controlling output length through a refined prompt engineering strategy, Constrained-CoT (CCoT), which encourages the model to limit output length. Experiments on pre-trained LLMs demonstrated the benefit of the proposed metrics and the effectiveness of CCoT across different models. For instance, constraining the reasoning of LLaMA2-70b to 100 words improves the accuracy from 36.01\\% (CoT) to 41.07\\% (CCoT) on the GSM8K dataset, while reducing the average output length by 28 words.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Preprint version, under review"
    },
    {
        "paper id": "2407.19832",
        "abstract url": "https://arxiv.org/abs/2407.19832",
        "title": "ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have attracted much attention due to their multifunctionality. However, traditional Transformer architectures incur significant overhead due to their secondary computational complexity. To address this issue, we introduce ML-Mamba, a multimodal language model that utilizes the latest and efficient Mamba-2 model for inference. Mamba-2 is known for its linear extension and fast processing of long sequences. We replace the Transformer based backbone with a pre-trained Mamba-2 model and explore methods for integrating 2D visual selective scanning mechanisms into multimodal learning. We also try various visual encoders and Mamba-2 model variants. Our extensive experiments conducted in various multimodal benchmark tests have demonstrated the competitive performance of ML-Mamba and highlighted the potential of state space models in multimodal tasks. The experimental results show that: (1) ML-Mamba achieves performance comparable to state-of-the-art methods such as TinyLaVA and MobileVLM v2 through its linear sequential modeling, while also having faster inference speed; (2) ML-Mamba performs well in visual hallucinations and spatial relationship judgment in closed set benchmark tests; (3) ML-Mamba achieves performance comparable to LLaVA while reducing the number of parameters by 40\\%.(4) Compared to the multimodal model using the original Mamba model, the Mamba-2 based large-scale multimodal language model has stronger inference performance and effectiveness.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19834",
        "abstract url": "https://arxiv.org/abs/2407.19834",
        "title": "Frequency & Channel Attention Network for Small Footprint Noisy Spoken Keyword Spotting",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we aim to improve the robustness of Keyword Spotting (KWS) systems in noisy environments while keeping a small memory footprint. We propose a new convolutional neural network (CNN) called FCA-Net, which combines mixer unit-based feature interaction with a two-dimensional convolution-based attention module. First, we introduce and compare lightweight attention methods to enhance noise robustness in CNN. Then, we propose an attention module that creates fine-grained attention weights to capture channel and frequency-specific information, boosting the model's ability to handle noisy conditions. By combining the mixer unit-based feature interaction with the attention module, we enhance performance. Additionally, we use a curriculum-based multi-condition training strategy. Our experiments show that our system outperforms current state-of-the-art solutions for small-footprint KWS in noisy environments, making it reliable for real-world use.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Submitted to the APSIPA ASC 2024"
    },
    {
        "paper id": "2407.19835",
        "abstract url": "https://arxiv.org/abs/2407.19835",
        "title": "ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Classical Arabic represents a significant era, encompassing the golden age of Arab culture, philosophy, and scientific literature. With a broad consensus on the importance of translating these literatures to enrich knowledge dissemination across communities, the advent of large language models (LLMs) and translation systems offers promising tools to facilitate this goal. However, we have identified a scarcity of translation datasets in Classical Arabic, which are often limited in scope and topics, hindering the development of high-quality translation systems. In response, we present the ATHAR dataset, comprising 66,000 high-quality Classical Arabic to English translation samples that cover a wide array of subjects including science, culture, and philosophy. Furthermore, we assess the performance of current state-of-the-art LLMs under various settings, concluding that there is a need for such datasets in current systems. Our findings highlight how models can benefit from fine-tuning or incorporating this dataset into their pretraining pipelines. The dataset is publicly available on the HuggingFace Data Hub at \\url{https://huggingface.co/datasets/mohamed-khalil/ATHAR}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19862",
        "abstract url": "https://arxiv.org/abs/2407.19862",
        "title": "Wavespace: A Highly Explorable Wavetable Generator",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Wavetable synthesis generates quasi-periodic waveforms of musical tones by interpolating a list of waveforms called wavetable. As generative models that utilize latent representations offer various methods in waveform generation for musical applications, studies in wavetable generation with invertible architecture have also arisen recently. While they are promising, it is still challenging to generate wavetables with detailed controls in disentangling factors within the latent representation. In response, we present Wavespace, a novel framework for wavetable generation that empowers users with enhanced parameter controls. Our model allows users to apply pre-defined conditions to the output wavetables. We employ a variational autoencoder and completely factorize its latent space to different waveform styles. We also condition the generator with auxiliary timbral and morphological descriptors. This way, users can create unique wavetables by independently manipulating each latent subspace and descriptor parameters. Our framework is efficient enough for practical use; we prototyped an oscillator plug-in as a proof of concept for real-time integration of Wavespace within digital audio workspaces (DAWs).",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19866",
        "abstract url": "https://arxiv.org/abs/2407.19866",
        "title": "Deep Image Priors for Magnetic Resonance Fingerprinting with pretrained Bloch-consistent denoising autoencoders",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "The estimation of multi-parametric quantitative maps from Magnetic Resonance Fingerprinting (MRF) compressed sampled acquisitions, albeit successful, remains a challenge due to the high underspampling rate and artifacts naturally occuring during image reconstruction. Whilst state-of-the-art DL methods can successfully address the task, to fully exploit their capabilities they often require training on a paired dataset, in an area where ground truth is seldom available. In this work, we propose a method that combines a deep image prior (DIP) module that, without ground truth and in conjunction with a Bloch consistency enforcing autoencoder, can tackle the problem, resulting in a method faster and of equivalent or better accuracy than DIP-MRF.",
        "subjects": [
            "eess.IV",
            "cs.LG"
        ],
        "comment": "4 pages, 3 figures 1 table, presented at ISBI 2024"
    },
    {
        "paper id": "2407.19875",
        "abstract url": "https://arxiv.org/abs/2407.19875",
        "title": "Exploring Robust Face-Voice Matching in Multilingual Environments",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents Team Xaiofei's innovative approach to exploring Face-Voice Association in Multilingual Environments (FAME) at ACM Multimedia 2024. We focus on the impact of different languages in face-voice matching by building upon Fusion and Orthogonal Projection (FOP), introducing four key components: a dual-branch structure, dynamic sample pair weighting, robust data augmentation, and score polarization strategy. Our dual-branch structure serves as an auxiliary mechanism to better integrate and provide more comprehensive information. We also introduce a dynamic weighting mechanism for various sample pairs to optimize learning. Data augmentation techniques are employed to enhance the model's generalization across diverse conditions. Additionally, score polarization strategy based on age and gender matching confidence clarifies and accentuates the final results. Our methods demonstrate significant effectiveness, achieving an equal error rate (EER) of 20.07 on the V2-EH dataset and 21.76 on the V1-EU dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19884",
        "abstract url": "https://arxiv.org/abs/2407.19884",
        "title": "Preliminary WMT24 Ranking of General MT Systems and LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This is the preliminary ranking of WMT24 General MT systems based on automatic metrics. The official ranking will be a human evaluation, which is superior to the automatic ranking and supersedes it. The purpose of this report is not to interpret any findings but only provide preliminary results to the participants of the General MT task that may be useful during the writing of the system submission.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19889",
        "abstract url": "https://arxiv.org/abs/2407.19889",
        "title": "Self-Supervised Learning for Text Recognition: A Critical Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text Recognition (TR) refers to the research area that focuses on retrieving textual information from images, a topic that has seen significant advancements in the last decade due to the use of Deep Neural Networks (DNN). However, these solutions often necessitate vast amounts of manually labeled or synthetic data. Addressing this challenge, Self-Supervised Learning (SSL) has gained attention by utilizing large datasets of unlabeled data to train DNN, thereby generating meaningful and robust representations. Although SSL was initially overlooked in TR because of its unique characteristics, recent years have witnessed a surge in the development of SSL methods specifically for this field. This rapid development, however, has led to many methods being explored independently, without taking previous efforts in methodology or comparison into account, thereby hindering progress in the field of research. This paper, therefore, seeks to consolidate the use of SSL in the field of TR, offering a critical and comprehensive overview of the current state of the art. We will review and analyze the existing methods, compare their results, and highlight inconsistencies in the current literature. This thorough analysis aims to provide general insights into the field, propose standardizations, identify new research directions, and foster its proper development.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This article is under revision"
    },
    {
        "paper id": "2407.19897",
        "abstract url": "https://arxiv.org/abs/2407.19897",
        "title": "BEExAI: Benchmark to Evaluate Explainable AI",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Recent research in explainability has given rise to numerous post-hoc attribution methods aimed at enhancing our comprehension of the outputs of black-box machine learning models. However, evaluating the quality of explanations lacks a cohesive approach and a consensus on the methodology for deriving quantitative metrics that gauge the efficacy of explainability post-hoc attribution methods. Furthermore, with the development of increasingly complex deep learning models for diverse data applications, the need for a reliable way of measuring the quality and correctness of explanations is becoming critical. We address this by proposing BEExAI, a benchmark tool that allows large-scale comparison of different post-hoc XAI methods, employing a set of selected evaluation metrics.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19914",
        "abstract url": "https://arxiv.org/abs/2407.19914",
        "title": "Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Sentiment analysis is a widely researched area within Natural Language Processing (NLP), attracting significant interest due to the advent of automated solutions. Despite this, the task remains challenging because of the inherent complexity of languages and the subjective nature of sentiments. It is even more challenging for less-studied and less-resourced languages such as Lithuanian. Our review of existing Lithuanian NLP research reveals that traditional machine learning methods and classification algorithms have limited effectiveness for the task. In this work, we address sentiment analysis of Lithuanian five-star-based online reviews from multiple domains that we collect and clean. We apply transformer models to this task for the first time, exploring the capabilities of pre-trained multilingual Large Language Models (LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the inherent difficulty of the task, the fine-tuned models perform quite well, especially when the sentiments themselves are less ambiguous: 80.74% and 89.61% testing recognition accuracy of the most popular one- and five-star reviews respectively. They significantly outperform current commercial state-of-the-art general-purpose LLM GPT-4. We openly share our fine-tuned LLMs online.",
        "subjects": [
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "Accepted at the 29th International Conference on Information Society and University Studies (IVUS 2024)"
    },
    {
        "paper id": "2407.19947",
        "abstract url": "https://arxiv.org/abs/2407.19947",
        "title": "Inference acceleration for large language models using \"stairs\" assisted greedy generation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) with billions of parameters are known for their impressive predicting capabilities but require lots of resources to run. With their massive rise in popularity, even a small reduction in required resources could have an impact on environment. On the other hand, smaller models require fewer resources but may sacrifice accuracy. In this work, we are proposing an implementation of ``stairs'' assisted greedy generation. It is a modified assisted generation methodology that makes use of a smaller model's fast generation, large model's batch prediction, and \"stairs\" validation in order to achieve a speed up in prediction generation. Results show between 9.58 and 17.24 percent inference time reduction compared to a stand-alone large LLM prediction in a text generation task without a loss in accuracy.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted at the 29th International Conference on Information Society and University Studies (IVUS 2024)"
    },
    {
        "paper id": "2407.19967",
        "abstract url": "https://arxiv.org/abs/2407.19967",
        "title": "A Temporal Psycholinguistics Approach to Identity Resolution of Social Media Users",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this thesis, we propose an approach to identity resolution across social media platforms using the topics, sentiments, and timings of the posts on the platforms. After collecting the public posts of around 5000 profiles from Disqus and Twitter, we analyze their posts to match their profiles across the two platforms. We pursue both temporal and non-temporal methods in our analysis. While neither approach proves definitively superior, the temporal approach generally performs better. We found that the temporal window size influences results more than the shifting amount. On the other hand, our sentiment analysis shows that the inclusion of sentiment makes little difference, probably due to flawed data extraction methods. We also experimented with a distance-based reward-and-punishment-focused scoring model, which achieved an accuracy of 24.198% and an average rank of 158.217 out of 2525 in our collected corpus. Future work includes refining sentiment analysis by evaluating sentiments per topic, extending temporal analysis with additional phases, and improving the scoring model through weight adjustments and modified rewards.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19985",
        "abstract url": "https://arxiv.org/abs/2407.19985",
        "title": "Mixture of Nested Experts: Adaptive Processing of Visual Tokens",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The visual medium (images and videos) naturally contains a large amount of information redundancy, thereby providing a great opportunity for leveraging efficiency in processing. While Vision Transformer (ViT) based models scale effectively to large data regimes, they fail to capitalize on this inherent redundancy, leading to higher computational costs. Mixture of Experts (MoE) networks demonstrate scalability while maintaining same inference-time costs, but they come with a larger parameter footprint. We present Mixture of Nested Experts (MoNE), which utilizes a nested structure for experts, wherein individual experts fall on an increasing compute-accuracy curve. Given a compute budget, MoNE learns to dynamically choose tokens in a priority order, and thus redundant tokens are processed through cheaper nested experts. Using this framework, we achieve equivalent performance as the baseline models, while reducing inference time compute by over two-fold. We validate our approach on standard image and video datasets - ImageNet-21K, Kinetics400, and Something-Something-v2. We further highlight MoNE$'$s adaptability by showcasing its ability to maintain strong performance across different inference-time compute budgets on videos, using only a single trained model.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19989",
        "abstract url": "https://arxiv.org/abs/2407.19989",
        "title": "Blind Acoustic Parameter Estimation Through Task-Agnostic Embeddings Using Latent Approximations",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "We present a method for blind acoustic parameter estimation from single-channel reverberant speech. The method is structured into three stages. In the first stage, a variational auto-encoder is trained to extract latent representations of acoustic impulse responses represented as mel-spectrograms. In the second stage, a separate speech encoder is trained to estimate low-dimensional representations from short segments of reverberant speech. Finally, the pre-trained speech encoder is combined with a small regression model and evaluated on two parameter regression tasks. Experimentally, the proposed method is shown to outperform a fully end-to-end trained baseline model.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Accepted for publication at IWAENC 2024"
    },
    {
        "paper id": "2407.19992",
        "abstract url": "https://arxiv.org/abs/2407.19992",
        "title": "More precise edge detections",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image Edge detection (ED) is a base task in computer vision. While the performance of the ED algorithm has been improved greatly by introducing CNN-based models, current models still suffer from unsatisfactory precision rates especially when only a low error toleration distance is allowed. Therefore, model architecture for more precise predictions still needs an investigation. On the other hand, the unavoidable noise training data provided by humans would lead to unsatisfactory model predictions even when inputs are edge maps themselves, which also needs improvement. In this paper, more precise ED models are presented with cascaded skipping density blocks (CSDB). Our models obtain state-of-the-art(SOTA) predictions in several datasets, especially in average precision rate (AP), which is confirmed by extensive experiments. Moreover, our models do not include down-sample operations, demonstrating those widely believed operations are not necessary. Also, a novel modification on data augmentation for training is employed, which allows noiseless data to be employed in model training and thus improves the performance of models predicting on edge maps themselves.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2407.19998",
        "abstract url": "https://arxiv.org/abs/2407.19998",
        "title": "Do LLMs Really Adapt to Domains? An Ontology Learning Perspective",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains. Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL). However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone. This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage. This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning? To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms. We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame. However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted at ISWC 2024"
    },
    {
        "paper id": "2407.20021",
        "abstract url": "https://arxiv.org/abs/2407.20021",
        "title": "MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with Encouraging Inter-Head Attention Similarity",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Data-free quantization (DFQ) is a technique that creates a lightweight network from its full-precision counterpart without the original training data, often through a synthetic dataset. Although several DFQ methods have been proposed for vision transformer (ViT) architectures, they fail to achieve efficacy in low-bit settings. Examining the existing methods, we identify that their synthetic data produce misaligned attention maps, while those of the real samples are highly aligned. From the observation of aligned attention, we find that aligning attention maps of synthetic data helps to improve the overall performance of quantized ViTs. Motivated by this finding, we devise MimiQ, a novel DFQ method designed for ViTs that focuses on inter-head attention similarity. First, we generate synthetic data by aligning head-wise attention responses in relation to spatial query patches. Then, we apply head-wise structural attention distillation to align the attention maps of the quantized network to those of the full-precision teacher. The experimental results show that the proposed method significantly outperforms baselines, setting a new state-of-the-art performance for data-free ViT quantization.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Author Preprint"
    },
    {
        "paper id": "2407.20076",
        "abstract url": "https://arxiv.org/abs/2407.20076",
        "title": "Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Language",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Offensive language detection is a crucial task in today's digital landscape, where online platforms grapple with maintaining a respectful and inclusive environment. However, building robust offensive language detection models requires large amounts of labeled data, which can be expensive and time-consuming to obtain. Semi-supervised learning offers a feasible solution by utilizing labeled and unlabeled data to create more accurate and robust models. In this paper, we explore a few different semi-supervised methods, as well as data augmentation techniques. Concretely, we implemented eight semi-supervised methods and ran experiments for them using only the available data in the RO-Offense dataset and applying five augmentation techniques before feeding the data to the models. Experimental results demonstrate that some of them benefit more from augmentations than others.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at KES 2024"
    },
    {
        "paper id": "2407.20080",
        "abstract url": "https://arxiv.org/abs/2407.20080",
        "title": "UniTTA: Unified Benchmark and Versatile Framework Towards Realistic Test-Time Adaptation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Test-Time Adaptation (TTA) aims to adapt pre-trained models to the target domain during testing. In reality, this adaptability can be influenced by multiple factors. Researchers have identified various challenging scenarios and developed diverse methods to address these challenges, such as dealing with continual domain shifts, mixed domains, and temporally correlated or imbalanced class distributions. Despite these efforts, a unified and comprehensive benchmark has yet to be established. To this end, we propose a Unified Test-Time Adaptation (UniTTA) benchmark, which is comprehensive and widely applicable. Each scenario within the benchmark is fully described by a Markov state transition matrix for sampling from the original dataset. The UniTTA benchmark considers both domain and class as two independent dimensions of data and addresses various combinations of imbalance/balance and i.i.d./non-i.i.d./continual conditions, covering a total of \\( (2 \\times 3)^2 = 36 \\) scenarios. It establishes a comprehensive evaluation benchmark for realistic TTA and provides a guideline for practitioners to select the most suitable TTA method. Alongside this benchmark, we propose a versatile UniTTA framework, which includes a Balanced Domain Normalization (BDN) layer and a COrrelated Feature Adaptation (COFA) method--designed to mitigate distribution gaps in domain and class, respectively. Extensive experiments demonstrate that our UniTTA framework excels within the UniTTA benchmark and achieves state-of-the-art performance on average. Our code is available at \\url{https://github.com/LeapLabTHU/UniTTA}.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20083",
        "abstract url": "https://arxiv.org/abs/2407.20083",
        "title": "An Energy-based Model for Word-level AutoCompletion in Computer-aided Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Word-level AutoCompletion(WLAC) is a rewarding yet challenging task in Computer-aided Translation. Existing work addresses this task through a classification model based on a neural network that maps the hidden vector of the input context into its corresponding label (i.e., the candidate target word is treated as a label). Since the context hidden vector itself does not take the label into account and it is projected to the label through a linear classifier, the model can not sufficiently leverage valuable information from the source sentence as verified in our experiments, which eventually hinders its overall performance. To alleviate this issue, this work proposes an energy-based model for WLAC, which enables the context hidden vector to capture crucial information from the source sentence. Unfortunately, training and inference suffer from efficiency and effectiveness challenges, thereby we employ three simple yet effective strategies to put our model into practice. Experiments on four standard benchmarks demonstrate that our reranking-based approach achieves substantial improvements (about 6.07%) over the previous state-of-the-art model. Further analyses show that each strategy of our approach contributes to the final performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to TACL 2024"
    },
    {
        "paper id": "2407.20099",
        "abstract url": "https://arxiv.org/abs/2407.20099",
        "title": "RSC-SNN: Exploring the Trade-off Between Adversarial Robustness and Accuracy in Spiking Neural Networks via Randomized Smoothing Coding",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Spiking Neural Networks (SNNs) have received widespread attention due to their unique neuronal dynamics and low-power nature. Previous research empirically shows that SNNs with Poisson coding are more robust than Artificial Neural Networks (ANNs) on small-scale datasets. However, it is still unclear in theory how the adversarial robustness of SNNs is derived, and whether SNNs can still maintain its adversarial robustness advantage on large-scale dataset tasks. This work theoretically demonstrates that SNN's inherent adversarial robustness stems from its Poisson coding. We reveal the conceptual equivalence of Poisson coding and randomized smoothing in defense strategies, and analyze in depth the trade-off between accuracy and adversarial robustness in SNNs via the proposed Randomized Smoothing Coding (RSC) method. Experiments demonstrate that the proposed RSC-SNNs show remarkable adversarial robustness, surpassing ANNs and achieving state-of-the-art robustness results on large-scale dataset ImageNet. Our open-source implementation code is available at this https URL: https://github.com/KemingWu/RSC-SNN.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ACM MM 2024"
    },
    {
        "paper id": "2407.20171",
        "abstract url": "https://arxiv.org/abs/2407.20171",
        "title": "Diffusion Feedback Helps CLIP See Better",
        "rating": "1",
        "keywords": [
            [
                "VLM"
            ],
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Contrastive Language-Image Pre-training (CLIP), which excels at abstracting open-world representations across domains and modalities, has become a foundation for a variety of vision and multimodal tasks. However, recent studies reveal that CLIP has severe visual shortcomings, such as which can hardly distinguish orientation, quantity, color, structure, etc. These visual shortcomings also limit the perception capabilities of multimodal large language models (MLLMs) built on CLIP. The main reason could be that the image-text pairs used to train CLIP are inherently biased, due to the lack of the distinctiveness of the text and the diversity of images. In this work, we present a simple post-training approach for CLIP models, which largely overcomes its visual shortcomings via a self-supervised diffusion process. We introduce DIVA, which uses the DIffusion model as a Visual Assistant for CLIP. Specifically, DIVA leverages generative feedback from text-to-image diffusion models to optimize CLIP representations, with only images (without corresponding text). We demonstrate that DIVA improves CLIP's performance on the challenging MMVP-VLM benchmark which assesses fine-grained visual abilities to a large extent (e.g., 3-7%), and enhances the performance of MLLMs and vision models on multimodal understanding and segmentation tasks. Extensive evaluation on 29 image classification and retrieval benchmarks confirms that our framework preserves CLIP's strong zero-shot capabilities. The code will be available at https://github.com/baaivision/DIVA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20174",
        "abstract url": "https://arxiv.org/abs/2407.20174",
        "title": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Emerging multimodal large language models (MLLMs) exhibit great potential for chart question answering (CQA). Recent efforts primarily focus on scaling up training datasets (i.e., charts, data tables, and question-answer (QA) pairs) through data collection and synthesis. However, our empirical study on existing MLLMs and CQA datasets reveals notable gaps. First, current data collection and synthesis focus on data volume and lack consideration of fine-grained visual encodings and QA tasks, resulting in unbalanced data distribution divergent from practical CQA scenarios. Second, existing work follows the training recipe of the base MLLMs initially designed for natural images, under-exploring the adaptation to unique chart characteristics, such as rich text elements. To fill the gap, we propose a visualization-referenced instruction tuning approach to guide the training dataset enhancement and model development. Specifically, we propose a novel data engine to effectively filter diverse and high-quality data from existing datasets and subsequently refine and augment the data using LLM-based generation techniques to better align with practical QA tasks and visual encodings. Then, to facilitate the adaptation to chart characteristics, we utilize the enriched data to train an MLLM by unfreezing the vision encoder and incorporating a mixture-of-resolution adaptation strategy for enhanced fine-grained recognition. Experimental results validate the effectiveness of our approach. Even with fewer training examples, our model consistently outperforms state-of-the-art CQA models on established benchmarks. We also contribute a dataset split as a benchmark for future research. Source codes and datasets of this paper are available at https://github.com/zengxingchen/ChartQA-MLLM.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2407.20177",
        "abstract url": "https://arxiv.org/abs/2407.20177",
        "title": "AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "To ensure performance on a diverse set of downstream tasks, LLMs are pretrained via data mixtures over different domains. In this work, we demonstrate that the optimal data composition for a fixed compute budget varies depending on the scale of the training data, suggesting that the common practice of empirically determining an optimal composition using small-scale experiments will not yield the optimal data mixtures when scaling up to the final model. To address this challenge, we propose *AutoScale*, an automated tool that finds a compute-optimal data composition for training at any desired target scale. AutoScale first determines the optimal composition at a small scale using a novel bilevel optimization framework, Direct Data Optimization (*DDO*), and then fits a predictor to estimate the optimal composition at larger scales. The predictor's design is inspired by our theoretical analysis of scaling laws related to data composition, which could be of independent interest. In empirical studies with pre-training 774M Decoder-only LMs (GPT-2 Large) on RedPajama dataset, AutoScale decreases validation perplexity at least 25% faster than any baseline with up to 38% speed up compared to without reweighting, achieving the best overall performance across downstream tasks. On pre-training Encoder-only LMs (BERT) with masked language modeling, DDO is shown to decrease loss on all domains while visibly improving average task performance on GLUE benchmark by 8.7% and on large-scale QA dataset (SQuAD) by 5.9% compared with without reweighting. AutoScale speeds up training by up to 28%. Our codes are open-sourced.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20189",
        "abstract url": "https://arxiv.org/abs/2407.20189",
        "title": "Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Conversational search supports multi-turn user-system interactions to solve complex information needs. Different from the traditional single-turn ad-hoc search, conversational search encounters a more challenging problem of context-dependent query understanding with the lengthy and long-tail conversational history context. While conversational query rewriting methods leverage explicit rewritten queries to train a rewriting model to transform the context-dependent query into a stand-stone search query, this is usually done without considering the quality of search results. Conversational dense retrieval methods use fine-tuning to improve a pre-trained ad-hoc query encoder, but they are limited by the conversational search data available for training. In this paper, we leverage both rewritten queries and relevance judgments in the conversational search data to train a better query representation model. The key idea is to align the query representation with those of rewritten queries and relevant documents. The proposed model -- Query Representation Alignment Conversational Dense Retriever, QRACDR, is tested on eight datasets, including various settings in conversational search and ad-hoc search. The results demonstrate the strong performance of QRACDR compared with state-of-the-art methods, and confirm the effectiveness of representation alignment.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": "Accepted by CIKM 2024"
    },
    {
        "paper id": "2407.20207",
        "abstract url": "https://arxiv.org/abs/2407.20207",
        "title": "QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In dense retrieval, embedding long texts into dense vectors can result in information loss, leading to inaccurate query-text matching. Additionally, low-quality texts with excessive noise or sparse key information are unlikely to align well with relevant queries. Recent studies mainly focus on improving the sentence embedding model or retrieval process. In this work, we introduce a novel text augmentation framework for dense retrieval. This framework transforms raw documents into information-dense text formats, which supplement the original texts to effectively address the aforementioned issues without modifying embedding or retrieval methodologies. Two text representations are generated via large language models (LLMs) zero-shot prompting: question-answer pairs and element-driven events. We term this approach QAEA-DR: unifying question-answer generation and event extraction in a text augmentation framework for dense retrieval. To further enhance the quality of generated texts, a scoring-based evaluation and regeneration mechanism is introduced in LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval, supported by both theoretical analysis and empirical experiments.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20413",
        "abstract url": "https://arxiv.org/abs/2407.20413",
        "title": "Through the Looking Glass, and what Horn Clause Programs Found There",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Dual Horn clauses mirror key properties of Horn clauses. This paper explores the ``other side of the looking glass'' to reveal some expected and unexpected symmetries and their practical uses. We revisit Dual Horn clauses as enablers of a form of constructive negation that supports goal-driven forward reasoning and is valid both intuitionistically and classically. In particular, we explore the ability to falsify a counterfactual hypothesis in the context of a background theory expressed as a Dual Horn clause program. With Dual Horn clause programs, by contrast to negation as failure, the variable bindings in their computed answers provide explanations for the reasons why a statement is successfully falsified. Moreover, in the propositional case, by contrast to negation as failure as implemented with stable models semantics in ASP systems, and similarly to Horn clause programs, Dual Horn clause programs have polynomial complexity. After specifying their execution model with a metainterpreter, we devise a compilation scheme from Dual Horn clause programs to Horn clause programs, ensuring their execution with no performance penalty and we design the embedded SymLP language to support combined Horn clause and Dual Horn clause programs. As a (motivating) application, we cast LLM reasoning chains into propositional Horn and Dual Horn clauses that work together to constructively prove and disprove goals and enhance Generative AI with explainability of reasoning chains.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20421",
        "abstract url": "https://arxiv.org/abs/2407.20421",
        "title": "Event-based Optical Flow on Neuromorphic Processor: ANN vs. SNN Comparison based on Activation Sparsification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Spiking neural networks (SNNs) for event-based optical flow are claimed to be computationally more efficient than their artificial neural networks (ANNs) counterparts, but a fair comparison is missing in the literature. In this work, we propose an event-based optical flow solution based on activation sparsification and a neuromorphic processor, SENECA. SENECA has an event-driven processing mechanism that can exploit the sparsity in ANN activations and SNN spikes to accelerate the inference of both types of neural networks. The ANN and the SNN for comparison have similar low activation/spike density (~5%) thanks to our novel sparsification-aware training. In the hardware-in-loop experiments designed to deduce the average time and energy consumption, the SNN consumes 44.9ms and 927.0 microjoules, which are 62.5% and 75.2% of the ANN's consumption, respectively. We find that SNN's higher efficiency attributes to its lower pixel-wise spike density (43.5% vs. 66.5%) that requires fewer memory access operations for neuron states.",
        "subjects": [
            "cs.NE",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "18 pages, 12 figures, 4 tables"
    },
    {
        "paper id": "2407.20427",
        "abstract url": "https://arxiv.org/abs/2407.20427",
        "title": "Mean Opinion Score as a New Metric for User-Evaluation of XAI Methods",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This paper investigates the use of Mean Opinion Score (MOS), a common image quality metric, as a user-centric evaluation metric for XAI post-hoc explainers. To measure the MOS, a user experiment is proposed, which has been conducted with explanation maps of intentionally distorted images. Three methods from the family of feature attribution methods - Gradient-weighted Class Activation Mapping (Grad-CAM), Multi-Layered Feature Explanation Method (MLFEM), and Feature Explanation Method (FEM) - are compared with this metric. Additionally, the correlation of this new user-centric metric with automatic metrics is studied via Spearman's rank correlation coefficient. MOS of MLFEM shows the highest correlation with automatic metrics of Insertion Area Under Curve (IAUC) and Deletion Area Under Curve (DAUC). However, the overall correlations are limited, which highlights the lack of consensus between automatic and user-centric metrics.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "Supported by organization Laboratoire Bordelais de Recherche en Informatique, 15 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2407.20438",
        "abstract url": "https://arxiv.org/abs/2407.20438",
        "title": "Generating Gender Alternatives in Machine Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Machine translation (MT) systems often translate terms with ambiguous gender (e.g., English term \"the nurse\") into the gendered form that is most prevalent in the systems' training data (e.g., \"enfermera\", the Spanish term for a female nurse). This often reflects and perpetuates harmful stereotypes present in society. With MT user interfaces in mind that allow for resolving gender ambiguity in a frictionless manner, we study the problem of generating all grammatically correct gendered translation alternatives. We open source train and test datasets for five language pairs and establish benchmarks for this task. Our key technical contribution is a novel semi-supervised solution for generating alternatives that integrates seamlessly with standard MT models and maintains high performance without requiring additional components or increasing inference overhead.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "GeBNLP 2024"
    },
    {
        "paper id": "2407.20454",
        "abstract url": "https://arxiv.org/abs/2407.20454",
        "title": "CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Instruction tuning in multimodal large language models (MLLMs) aims to smoothly integrate a backbone LLM with a pre-trained feature encoder for downstream tasks. The major challenge is how to efficiently find the synergy through cooperative learning where LLMs adapt their reasoning abilities in downstream tasks while feature encoders adjust their encoding to provide more relevant modal information. In this paper, we analyze the MLLM instruction tuning from both theoretical and empirical perspectives, where we find unbalanced learning between the two components, i.e., the feature encoder and the LLM, can cause diminishing learning gradients that slow the model convergence and often lead to sub-optimal results due to insufficient learning. Inspired by our findings, we propose a measurement to quantitatively evaluate the learning balance, based on which we further design a dynamic learning scheduler that better coordinates the learning. In addition, we introduce an auxiliary loss regularization method to promote updating of the generation distribution of MLLMs considering the learning state of each model component, which potentially prevents each component from gradient diminishing and enables a more accurate estimation of the learning balance coefficient. We conduct experiments with multiple LLM backbones and feature encoders, where our techniques are model-agnostic and can be generically integrated with various MLLM backbones. Experiment results on multiple downstream tasks and modalities in vision and audio, demonstrate the proposed method's better efficiency and effectiveness in MLLM instruction tuning.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2407.20485",
        "abstract url": "https://arxiv.org/abs/2407.20485",
        "title": "A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Recently, large language models (LLM) based on transformers are facing memory bottleneck issues due to KV cache, especially in long sequence handling. Previous researches proposed KV cache compression techniques that identify insignificant tokens based on Accumulative Attention Scores and removes their items from KV cache, noting that only few tokens play an important role in attention operations. However, we have observed that the existing Accumulative Attention Score is not suitable for the transformer decoder structure. In the decoder model, the number of times the Attention Score accumulates varies depending on the order of token appearance due to the effect of masking, causing an uneven comparison between tokens. To solve this, we propose Accumulative Attention Score with Forgetting Factor (A2SF) technique, which introduces a Forgetting Factor in the Attention Score accumulation process. A2SF applies a penalty to the past Attention Score generated from old tokens by repeatedly multiplying the Forgetting Factor to the Attention Score over time. Therefore, older tokens receive a larger penalty, providing fairness among different ages of tokens. Through the fair comparison among tokens, we can more effectively select important tokens. We have verified the accuracy improvement through A2SF in the OPT and LLaMA models and A2SF improves the accuracy of LLaMA 2 by up to 7.8% and 5.1% on 1-shot and 0-shot.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "11 pages(9 pages + reference 2 pages), 6 figures"
    },
    {
        "paper id": "2407.20502",
        "abstract url": "https://arxiv.org/abs/2407.20502",
        "title": "Restoring Real-World Degraded Events Improves Deblurring Quality",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Due to its high speed and low latency, DVS is frequently employed in motion deblurring. Ideally, high-quality events would adeptly capture intricate motion information. However, real-world events are generally degraded, thereby introducing significant artifacts into the deblurred results. In response to this challenge, we model the degradation of events and propose RDNet to improve the quality of image deblurring. Specifically, we first analyze the mechanisms underlying degradation and simulate paired events based on that. These paired events are then fed into the first stage of the RDNet for training the restoration model. The events restored in this stage serve as a guide for the second-stage deblurring process. To better assess the deblurring performance of different methods on real-world degraded events, we present a new real-world dataset named DavisMCR. This dataset incorporates events with diverse degradation levels, collected by manipulating environmental brightness and target object contrast. Our experiments are conducted on synthetic datasets (GOPRO), real-world datasets (REBlur), and the proposed dataset (DavisMCR). The results demonstrate that RDNet outperforms classical event denoising methods in event restoration. Furthermore, RDNet exhibits better performance in deblurring tasks compared to state-of-the-art methods. DavisMCR are available at https://github.com/Yeeesir/DVS_RDNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20505",
        "abstract url": "https://arxiv.org/abs/2407.20505",
        "title": "Interpreting and Mitigating Hallucination in MLLMs through Multi-agent Debate",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination. Previous methods focus on determining whether a generated output is hallucinated, without identifying which image region leads to the hallucination or interpreting why such hallucinations occur. In this paper, we argue that hallucination in MLLMs is partially due to a lack of slow-thinking and divergent-thinking in these models. To address this, we propose adopting a self-reflection scheme to promote slow-thinking. Furthermore, we consider eliminating hallucination as a complex reasoning task and propose a multi-agent debate approach to encourage divergent-thinking. Consequently, our approach can not only mitigate hallucinations but also interpret why they occur and detail the specifics of hallucination. In addition, we propose to distinguish creativity from hallucination in the context of MLLMs, and illustrate how to evaluate MLLMs' creativity capability. Extensive experiments on various benchmarks demonstrate that our approach exhibits generalized hallucinations-mitigating performance across several MLLMs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20518",
        "abstract url": "https://arxiv.org/abs/2407.20518",
        "title": "High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Spatial transcriptomics (ST) is a groundbreaking genomic technology that enables spatial localization analysis of gene expression within tissue sections. However, it is significantly limited by high costs and sparse spatial resolution. An alternative, more cost-effective strategy is to use deep learning methods to predict high-density gene expression profiles from histological images. However, existing methods struggle to capture rich image features effectively or rely on low-dimensional positional coordinates, making it difficult to accurately predict high-resolution gene expression profiles. To address these limitations, we developed HisToSGE, a method that employs a Pathology Image Large Model (PILM) to extract rich image features from histological images and utilizes a feature learning module to robustly generate high-resolution gene expression profiles. We evaluated HisToSGE on four ST datasets, comparing its performance with five state-of-the-art baseline methods. The results demonstrate that HisToSGE excels in generating high-resolution gene expression profiles and performing downstream tasks such as spatial domain identification. All code and public datasets used in this paper are available at https://github.com/wenwenmin/HisToSGE and https://zenodo.org/records/12792163.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.21075",
        "abstract url": "https://arxiv.org/abs/2407.21075",
        "title": "Apple Intelligence Foundation Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We present foundation language models developed to power Apple Intelligence features, including a ~3 billion parameter model designed to run efficiently on devices and a large server-based language model designed for Private Cloud Compute. These models are designed to perform a wide range of tasks efficiently, accurately, and responsibly. This report describes the model architecture, the data used to train the model, the training process, how the models are optimized for inference, and the evaluation results. We highlight our focus on Responsible AI and how the principles are applied throughout the model development.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.21077",
        "abstract url": "https://arxiv.org/abs/2407.21077",
        "title": "Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) rely on instruction samples for alignment, but creating these datasets poses challenges, particularly in expert-dependent tasks like coding, which can be cost-prohibitive. One approach to mitigate these challenges is synthesizing data using another LLM. In this paper, we introduce a scalable method for generating synthetic instructions to enhance the code generation capability of LLMs. The proposed algorithm, Genetic-Instruct, mimics evolutionary processes, utilizing self-instruction to create numerous synthetic samples from a limited number of seeds. Genetic-Instruct is designed for efficient scaling of the generation process. Fine-tuning multiple coding LLMs with the synthetic samples demonstrates a significant improvement in their code generation accuracy compared to the baselines.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19707",
        "abstract url": "https://arxiv.org/abs/2407.19707",
        "title": "Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This research introduces an extended application of neural networks for solving nonlinear partial differential equations (PDEs). A neural network, combined with a pseudo-arclength continuation, is proposed to construct bifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural network approach is also presented for solving eigenvalue problems to analyze solution linear stability, focusing on identifying the largest eigenvalue. The effectiveness of the proposed neural network is examined through experiments on the Bratu equation and the Burgers equation. Results from a finite difference method are also presented as comparison. Varying numbers of grid points are employed in each case to assess the behavior and accuracy of both the neural network and the finite difference method. The experimental results demonstrate that the proposed neural network produces better solutions, generates more accurate bifurcation diagrams, has reasonable computational times, and proves effective for linear stability analysis.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": "Accepted for publication in Applied Mathematics and Computation"
    },
    {
        "paper id": "2407.19715",
        "abstract url": "https://arxiv.org/abs/2407.19715",
        "title": "Generalization bounds for regression and classification on adaptive covering input domains",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Our main focus is on the generalization bound, which serves as an upper limit for the generalization error. Our analysis delves into regression and classification tasks separately to ensure a thorough examination. We assume the target function is real-valued and Lipschitz continuous for regression tasks. We use the 2-norm and a root-mean-square-error (RMSE) variant to measure the disparities between predictions and actual values. In the case of classification tasks, we treat the target function as a one-hot classifier, representing a piece-wise constant function, and employ 0/1 loss for error measurement. Our analysis underscores the differing sample complexity required to achieve a concentration inequality of generalization bounds, highlighting the variation in learning efficiency for regression and classification tasks. Furthermore, we demonstrate that the generalization bounds for regression and classification functions are inversely proportional to a polynomial of the number of parameters in a network, with the degree depending on the hypothesis class and the network architecture. These findings emphasize the advantages of over-parameterized networks and elucidate the conditions for benign overfitting in such systems.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19721",
        "abstract url": "https://arxiv.org/abs/2407.19721",
        "title": "Rina: Enhancing Ring-AllReduce with In-network Aggregation in Distributed Model Training",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Parameter Server (PS) and Ring-AllReduce (RAR) are two widely utilized synchronization architectures in multi-worker Deep Learning (DL), also referred to as Distributed Deep Learning (DDL). However, PS encounters challenges with the ``incast'' issue, while RAR struggles with problems caused by the long dependency chain. The emerging In-network Aggregation (INA) has been proposed to integrate with PS to mitigate its incast issue. However, such PS-based INA has poor incremental deployment abilities as it requires replacing all the switches to show significant performance improvement, which is not cost-effective. In this study, we present the incorporation of INA capabilities into RAR, called RAR with In-Network Aggregation (Rina), to tackle both the problems above. Rina features its agent-worker mechanism. When an INA-capable ToR switch is deployed, all workers in this rack run as one abstracted worker with the help of the agent, resulting in both excellent incremental deployment capabilities and better throughput. We conducted extensive testbed and simulation evaluations to substantiate the throughput advantages of Rina over existing DDL training synchronization structures. Compared with the state-of-the-art PS-based INA methods ATP, Rina can achieve more than 50\\% throughput with the same hardware cost.",
        "subjects": [
            "cs.NI",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "To appear in ICNP 2024. Preview version only"
    },
    {
        "paper id": "2407.19772",
        "abstract url": "https://arxiv.org/abs/2407.19772",
        "title": "Generating Unseen Code Tests In Infinitum",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are used for many tasks, including those related to coding. An important aspect of being able to utilize LLMs is the ability to assess their fitness for specific usages. The common practice is to evaluate LLMs against a set of benchmarks. While benchmarks provide a sound foundation for evaluation and comparison of alternatives, they suffer from the well-known weakness of leaking into the training data \\cite{Xu2024Benchmarking}. We present a method for creating benchmark variations that generalize across coding tasks and programming languages, and may also be applied to in-house code bases. Our approach enables ongoing generation of test-data thus mitigating the leaking into the training data issue. We implement one benchmark, called \\textit{auto-regression}, for the task of text-to-code generation in Python. Auto-regression is specifically created to aid in debugging and in tracking model generation changes as part of the LLM regression testing process.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19777",
        "abstract url": "https://arxiv.org/abs/2407.19777",
        "title": "Revisiting Agnostic PAC Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "PAC learning, dating back to Valiant'84 and Vapnik and Chervonenkis'64,'74, is a classic model for studying supervised learning. In the agnostic setting, we have access to a hypothesis set $\\mathcal{H}$ and a training set of labeled samples $(x_1,y_1),\\dots,(x_n,y_n) \\in \\mathcal{X} \\times \\{-1,1\\}$ drawn i.i.d. from an unknown distribution $\\mathcal{D}$. The goal is to produce a classifier $h : \\mathcal{X} \\to \\{-1,1\\}$ that is competitive with the hypothesis $h^\\star_{\\mathcal{D}} \\in \\mathcal{H}$ having the least probability of mispredicting the label $y$ of a new sample $(x,y)\\sim \\mathcal{D}$. Empirical Risk Minimization (ERM) is a natural learning algorithm, where one simply outputs the hypothesis from $\\mathcal{H}$ making the fewest mistakes on the training data. This simple algorithm is known to have an optimal error in terms of the VC-dimension of $\\mathcal{H}$ and the number of samples $n$. In this work, we revisit agnostic PAC learning and first show that ERM is in fact sub-optimal if we treat the performance of the best hypothesis, denoted $\u03c4:=\\Pr_{\\mathcal{D}}[h^\\star_{\\mathcal{D}}(x) \\neq y]$, as a parameter. Concretely we show that ERM, and any other proper learning algorithm, is sub-optimal by a $\\sqrt{\\ln(1/\u03c4)}$ factor. We then complement this lower bound with the first learning algorithm achieving an optimal error for nearly the full range of $\u03c4$. Our algorithm introduces several new ideas that we hope may find further applications in learning theory.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19790",
        "abstract url": "https://arxiv.org/abs/2407.19790",
        "title": "Hashing based Contrastive Learning for Virtual Screening",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Virtual screening (VS) is a critical step in computer-aided drug discovery, aiming to identify molecules that bind to a specific target receptor like protein. Traditional VS methods, such as docking, are often too time-consuming for screening large-scale molecular databases. Recent advances in deep learning have demonstrated that learning vector representations for both proteins and molecules using contrastive learning can outperform traditional docking methods. However, given that target databases often contain billions of molecules, real-valued vector representations adopted by existing methods can still incur significant memory and time costs in VS. To address this problem, in this paper we propose a hashing-based contrastive learning method, called DrugHash, for VS. DrugHash treats VS as a retrieval task that uses efficient binary hash codes for retrieval. In particular, DrugHash designs a simple yet effective hashing strategy to enable end-to-end learning of binary hash codes for both protein and molecule modalities, which can dramatically reduce the memory and time costs with higher accuracy compared with existing methods. Experimental results show that DrugHash can outperform existing methods to achieve state-of-the-art accuracy, with a memory saving of 32$\\times$ and a speed improvement of 3.5$\\times$.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19804",
        "abstract url": "https://arxiv.org/abs/2407.19804",
        "title": "Imputation for prediction: beware of diminishing returns",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Missing values are prevalent across various fields, posing challenges for training and deploying predictive models. In this context, imputation is a common practice, driven by the hope that accurate imputations will enhance predictions. However, recent theoretical and empirical studies indicate that simple constant imputation can be consistent and competitive. This empirical study aims at clarifying if and when investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 20 datasets, we show that imputation accuracy matters less i) when using expressive models, ii) when incorporating missingness indicators as complementary inputs, iii) matters much more for generated linear outcomes than for real-data outcomes. Interestingly, we also show that the use of the missingness indicator is beneficial to the prediction performance, even in MCAR scenarios. Overall, on real-data with powerful models, improving imputation only has a minor effect on prediction performance. Thus, investing in better imputations for improved predictions often offers limited benefits.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19829",
        "abstract url": "https://arxiv.org/abs/2407.19829",
        "title": "Generative Retrieval with Preference Optimization for E-commerce Search",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Generative retrieval introduces a groundbreaking paradigm to document retrieval by directly generating the identifier of a pertinent document in response to a specific query. This paradigm has demonstrated considerable benefits and potential, particularly in representation and generalization capabilities, within the context of large language models. However, it faces significant challenges in E-commerce search scenarios, including the complexity of generating detailed item titles from brief queries, the presence of noise in item titles with weak language order, issues with long-tail queries, and the interpretability of results. To address these challenges, we have developed an innovative framework for E-commerce search, called generative retrieval with preference optimization. This framework is designed to effectively learn and align an autoregressive model with target data, subsequently generating the final item through constraint-based beam search. By employing multi-span identifiers to represent raw item titles and transforming the task of generating titles from queries into the task of generating multi-span identifiers from queries, we aim to simplify the generation process. The framework further aligns with human preferences using click data and employs a constrained search method to identify key spans for retrieving the final item, thereby enhancing result interpretability. Our extensive experiments show that this framework achieves competitive performance on a real-world dataset, and online A/B tests demonstrate the superiority and effectiveness in improving conversion gains.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19853",
        "abstract url": "https://arxiv.org/abs/2407.19853",
        "title": "Online Multi-Source Domain Adaptation through Gaussian Mixtures and Dataset Dictionary Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses the challenge of online multi-source domain adaptation (MSDA) in transfer learning, a scenario where one needs to adapt multiple, heterogeneous source domains towards a target domain that comes in a stream. We introduce a novel approach for the online fit of a Gaussian Mixture Model (GMM), based on the Wasserstein geometry of Gaussian measures. We build upon this method and recent developments in dataset dictionary learning for proposing a novel strategy in online MSDA. Experiments on the challenging Tennessee Eastman Process benchmark demonstrate that our approach is able to adapt \\emph{on the fly} to the stream of target domain data. Furthermore, our online GMM serves as a memory, representing the whole stream of data.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "6 pages, 3 figures, accepted at the IEEE International Workshop on Machine Learning for Signal Processing 2024"
    },
    {
        "paper id": "2407.19858",
        "abstract url": "https://arxiv.org/abs/2407.19858",
        "title": "AI-Powered Energy algorithmic Trading: Integrating Hidden Markov Models with Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the field of quantitative finance, machine learning methods have become essential for alpha generation. This paper presents a pioneering method that uniquely combines Hidden Markov Models (HMM) and neural networks, creating a dual-model alpha generation system integrated with Black-Litterman portfolio optimization. The methodology, implemented on the QuantConnect platform, aims to predict future price movements and optimize trading strategies. Specifically, it filters for highly liquid, top-cap energy stocks to ensure stable and predictable performance while also accounting for broker payments. QuantConnect was selected because of its robust framework and to guarantee experimental reproducibility. The algorithm achieved a 31% return between June 1, 2023, and January 1, 2024, with a Sharpe ratio of 1.669, demonstrating its potential. The findings suggest significant improvements in trading strategy performance through the combined use of the HMM and neural networks. This study explores the architecture of the algorithm, data pre-processing techniques, model training procedures, and performance evaluation, highlighting its practical applicability and effectiveness in real-world trading environments. The full code and backtesting data are available under the MIT license.",
        "subjects": [
            "q-fin.PM",
            "cs.LG",
            "q-fin.GN",
            "stat.AP"
        ],
        "comment": "14 pages, 4 figures, 2 tables"
    },
    {
        "paper id": "2407.19865",
        "abstract url": "https://arxiv.org/abs/2407.19865",
        "title": "Imitation Learning for Intra-Day Power Grid Operation through Topology Actions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Power grid operation is becoming increasingly complex due to the increase in generation of renewable energy. The recent series of Learning To Run a Power Network (L2RPN) competitions have encouraged the use of artificial agents to assist human dispatchers in operating power grids. In this paper we study the performance of imitation learning for day-ahead power grid operation through topology actions. In particular, we consider two rule-based expert agents: a greedy agent and a N-1 agent. While the latter is more computationally expensive since it takes N-1 safety considerations into account, it exhibits a much higher operational performance. We train a fully-connected neural network (FCNN) on expert state-action pairs and evaluate it in two ways. First, we find that classification accuracy is limited despite extensive hyperparameter tuning, due to class imbalance and class overlap. Second, as a power system agent, the FCNN performs only slightly worse than expert agents. Furthermore, hybrid agents, which incorporate minimal additional simulations, match expert agents' performance with significantly lower computational cost. Consequently, imitation learning shows promise for developing fast, high-performing power grid agents, motivating its further exploration in future L2RPN studies.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "To be presented at the Machine Learning for Sustainable Power Systems 2024 workshop and to be published in the corresponding Springer Communications in Computer and Information Science proceedings"
    },
    {
        "paper id": "2407.19869",
        "abstract url": "https://arxiv.org/abs/2407.19869",
        "title": "Distances Between Partial Preference Orderings",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper proposes to establish the distance between partial preference orderings based on two very different approaches. The first approach corresponds to the brute force method based on combinatorics. It generates all possible complete preference orderings compatible with the partial preference orderings and calculates the Frobenius distance between all fully compatible preference orderings. Unfortunately, this first method is not very efficient in solving high-dimensional problems because of its big combinatorial complexity. That is why we propose to circumvent this problem by using a second approach based on belief functions, which can adequately model the missing information of partial preference orderings. This second approach to the calculation of distance does not suffer from combinatorial complexity limitation. We show through simple examples how these two theoretical methods work.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2407.19872",
        "abstract url": "https://arxiv.org/abs/2407.19872",
        "title": "OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city Analysis of Area Usage Patterns",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We publicly release OpenUAS, a dataset of area embeddings based on urban usage patterns, including embeddings for over 1.3 million 50-meter square meshes covering a total area of 3,300 square kilometers. This dataset is valuable for analyzing area functions in fields such as market analysis, urban planning, transportation infrastructure, and infection prediction. It captures the characteristics of each area in the city, such as office districts and residential areas, by employing an area embedding technique that utilizes location information typically obtained by GPS. Numerous area embedding techniques have been proposed, and while the public release of such embedding datasets is technically feasible, it has not been realized. One of the obstacles has been the integration of data from different cities and periods into a unified space without sharing raw location data. We address this issue by developing an anchoring method that establishes anchors within a shared embedding space. We publicly release this anchor dataset along with area embedding datasets from several periods in eight major Japanese cities. This dataset allows users to analyze urban usage patterns in Japanese cities and embed their urban dataset into the same embedding space using the anchoring method. Our key contributions include the development of the anchoring method, releasing area embedding datasets for Japanese cities, and providing tools for effective data utilization.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19892",
        "abstract url": "https://arxiv.org/abs/2407.19892",
        "title": "Making Multi-Axis Gaussian Graphical Models Scalable to Millions of Samples and Features",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Gaussian graphical models can be used to extract conditional dependencies between the features of the dataset. This is often done by making an independence assumption about the samples, but this assumption is rarely satisfied in reality. However, state-of-the-art approaches that avoid this assumption are not scalable, with $O(n^3)$ runtime and $O(n^2)$ space complexity. In this paper, we introduce a method that has $O(n^2)$ runtime and $O(n)$ space complexity, without assuming independence. We validate our model on both synthetic and real-world datasets, showing that our method's accuracy is comparable to that of prior work We demonstrate that our approach can be used on unprecedentedly large datasets, such as a real-world 1,000,000-cell scRNA-seq dataset; this was impossible with previous approaches. Our method maintains the flexibility of prior work, such as the ability to handle multi-modal tensor-variate datasets and the ability to work with data of arbitrary marginal distributions. An additional advantage of our method is that, unlike prior work, our hyperparameters are easily interpretable.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "q-bio.GN"
        ],
        "comment": "39 pages (48 with appendix+references), 8 figures, 7 tables"
    },
    {
        "paper id": "2407.19911",
        "abstract url": "https://arxiv.org/abs/2407.19911",
        "title": "Efficient Shield Synthesis via State-Space Transformation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We consider the problem of synthesizing safety strategies for control systems, also known as shields. Since the state space is infinite, shields are typically computed over a finite-state abstraction, with the most common abstraction being a rectangular grid. However, for many systems, such a grid does not align well with the safety property or the system dynamics. That is why a coarse grid is rarely sufficient, but a fine grid is typically computationally infeasible to obtain. In this paper, we show that appropriate state-space transformations can still allow to use a coarse grid at almost no computational overhead. We demonstrate in three case studies that our transformation-based synthesis outperforms a standard synthesis by several orders of magnitude. In the first two case studies, we use domain knowledge to select a suitable transformation. In the third case study, we instead report on results in engineering a transformation without domain knowledge.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19922",
        "abstract url": "https://arxiv.org/abs/2407.19922",
        "title": "Monetizing Currency Pair Sentiments through LLM Explainability",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models (LLMs) play a vital role in almost every domain in today's organizations. In the context of this work, we highlight the use of LLMs for sentiment analysis (SA) and explainability. Specifically, we contribute a novel technique to leverage LLMs as a post-hoc model-independent tool for the explainability of SA. We applied our technique in the financial domain for currency-pair price predictions using open news feed data merged with market prices. Our application shows that the developed technique is not only a viable alternative to using conventional eXplainable AI but can also be fed back to enrich the input to the machine learning (ML) model to better predict future currency-pair values. We envision our results could be generalized to employing explainability as a conventional enrichment for ML input for better ML predictions in general.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "7 pages, 3 figures, AIFin@ECAI 2024"
    },
    {
        "paper id": "2407.19943",
        "abstract url": "https://arxiv.org/abs/2407.19943",
        "title": "Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Counterfactual learning to rank (CLTR ) can be risky; various circumstances can cause it to produce sub-optimal models that hurt performance when deployed. Safe CLTR was introduced to mitigate these risks when using inverse propensity scoring to correct for position bias. However, the existing safety measure for CLTR is not applicable to state-of-the-art CLTR, it cannot handle trust bias, and its guarantees rely on specific assumptions about user behavior. Our contributions are two-fold. First, we generalize the existing safe CLTR approach to make it applicable to state-of-the-art doubly robust (DR) CLTR and trust bias. Second, we propose a novel approach, proximal ranking policy optimization (PRPO ), that provides safety in deployment without assumptions about user behavior. PRPO removes incentives for learning ranking behavior that is too dissimilar to a safe ranking model. Thereby, PRPO imposes a limit on how much learned models can degrade performance metrics, without relying on any specific user assumptions. Our experiments show that both our novel safe doubly robust method and PRPO provide higher performance than the existing safe inverse propensity scoring approach. However, when circumstances are unexpected, the safe doubly robust approach can become unsafe and bring detrimental performance. In contrast, PRPO always maintains safety, even in maximally adversarial situations. By avoiding assumptions, PRPO is the first method with unconditional safety in deployment that translates to robust safety for real-world applications.",
        "subjects": [
            "cs.LG",
            "cs.IR"
        ],
        "comment": "Full paper at CIKM 2024"
    },
    {
        "paper id": "2407.19950",
        "abstract url": "https://arxiv.org/abs/2407.19950",
        "title": "A multilevel backbone extraction framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "As networks grow in size and complexity, backbones become an essential network representation. Indeed, they provide a simplified yet informative overview of the underlying organization by retaining the most significant and structurally influential connections within a network. Network heterogeneity often results in complex and intricate structures, making it challenging to identify the backbone. In response, we introduce the Multilevel Backbone Extraction Framework, a novel approach that diverges from conventional backbone methodologies. This generic approach prioritizes the mesoscopic organization of networks. First, it splits the network into homogeneous-density components. Second, it extracts independent backbones for each component using any classical Backbone technique. Finally, the various backbones are combined. This strategy effectively addresses the heterogeneity observed in network groupings. Empirical investigations on real-world networks underscore the efficacy of the Multilevel Backbone approach in preserving essential network structures and properties. Experiments demonstrate its superiority over classical methods in handling network heterogeneity and enhancing network integrity. The framework is adaptable to various types of networks and backbone extraction techniques, making it a versatile tool for network analysis and backbone extraction across diverse network applications.",
        "subjects": [
            "cs.SI",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19965",
        "abstract url": "https://arxiv.org/abs/2407.19965",
        "title": "Simply Trainable Nearest Neighbour Machine Translation with GPU Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Nearest neighbor machine translation is a successful approach for fast domain adaption, which interpolates the pre-trained transformers with domain-specific token-level k-nearest-neighbor (kNN) retrieval without retraining. Despite kNN MT's success, searching large reference corpus and fixed interpolation between the kNN and pre-trained model led to computational complexity and translation quality challenges. Among other papers, Dai et al. proposed methods to obtain a small number of reference samples dynamically for which they introduced a distance-aware interpolation method using an equation that includes free parameters. This paper proposes a simply trainable nearest neighbor machine translation and carry out inference experiments on GPU. Similar to Dai et al., we first adaptively construct a small datastore for each input sentence. Second, we train a single-layer network for the interpolation coefficient between the knnMT and pre-trained result to automatically interpolate in different domains. Experimental results on different domains show that our proposed method either improves or sometimes maintain the translation quality of methods in Dai et al. while being automatic. In addition, our GPU inference results demonstrate that knnMT can be integrated into GPUs with a drop of only 5% in terms of speed.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2407.20047",
        "abstract url": "https://arxiv.org/abs/2407.20047",
        "title": "Denoising ESG: quantifying data uncertainty from missing data with Machine Learning and prediction intervals",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Environmental, Social, and Governance (ESG) datasets are frequently plagued by significant data gaps, leading to inconsistencies in ESG ratings due to varying imputation methods. This paper explores the application of established machine learning techniques for imputing missing data in a real-world ESG dataset, emphasizing the quantification of uncertainty through prediction intervals. By employing multiple imputation strategies, this study assesses the robustness of imputation methods and quantifies the uncertainty associated with missing data. The findings highlight the importance of probabilistic machine learning models in providing better understanding of ESG scores, thereby addressing the inherent risks of wrong ratings due to incomplete data. This approach improves imputation practices to enhance the reliability of ESG ratings.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20053",
        "abstract url": "https://arxiv.org/abs/2407.20053",
        "title": "Orca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Significant wave height (SWH) is a vital metric in marine science, and accurate SWH estimation is crucial for various applications, e.g., marine energy development, fishery, early warning systems for potential risks, etc. Traditional SWH estimation methods that are based on numerical models and physical theories are hindered by computational inefficiencies. Recently, machine learning has emerged as an appealing alternative to improve accuracy and reduce computational time. However, due to limited observational technology and high costs, the scarcity of real-world data restricts the potential of machine learning models. To overcome these limitations, we propose an ocean SWH estimation framework, namely Orca. Specifically, Orca enhances the limited spatio-temporal reasoning abilities of classic LLMs with a novel spatiotemporal aware encoding module. By segmenting the limited buoy observational data temporally, encoding the buoys' locations spatially, and designing prompt templates, Orca capitalizes on the robust generalization ability of LLMs to estimate significant wave height effectively with limited data. Experimental results on the Gulf of Mexico demonstrate that Orca achieves state-of-the-art performance in SWH estimation.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20057",
        "abstract url": "https://arxiv.org/abs/2407.20057",
        "title": "Reconstructing Global Daily CO2 Emissions via Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "High temporal resolution CO2 emission data are crucial for understanding the drivers of emission changes, however, current emission dataset is only available on a yearly basis. Here, we extended a global daily CO2 emissions dataset backwards in time to 1970 using machine learning algorithm, which was trained to predict historical daily emissions on national scales based on relationships between daily emission variations and predictors established for the period since 2019. Variation in daily CO2 emissions far exceeded the smoothed seasonal variations. For example, the range of daily CO2 emissions equivalent to 31% of the year average daily emissions in China and 46% of that in India in 2022, respectively. We identified the critical emission-climate temperature (Tc) is 16.5 degree celsius for global average (18.7 degree celsius for China, 14.9 degree celsius for U.S., and 18.4 degree celsius for Japan), in which negative correlation observed between daily CO2 emission and ambient temperature below Tc and a positive correlation above it, demonstrating increased emissions associated with higher ambient temperature. The long-term time series spanning over fifty years of global daily CO2 emissions reveals an increasing trend in emissions due to extreme temperature events, driven by the rising frequency of these occurrences. This work suggests that, due to climate change, greater efforts may be needed to reduce CO2 emissions.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20058",
        "abstract url": "https://arxiv.org/abs/2407.20058",
        "title": "Shapley Value Computation in Ontology-Mediated Query Answering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The Shapley value, originally introduced in cooperative game theory for wealth distribution, has found use in KR and databases for the purpose of assigning scores to formulas and database tuples based upon their contribution to obtaining a query result or inconsistency. In the present paper, we explore the use of Shapley values in ontology-mediated query answering (OMQA) and present a detailed complexity analysis of Shapley value computation (SVC) in the OMQA setting. In particular, we establish a PF/#P-hard dichotomy for SVC for ontology-mediated queries (T,q) composed of an ontology T formulated in the description logic ELHI_\\bot and a connected constant-free homomorphism-closed query q. We further show that the #P-hardness side of the dichotomy can be strengthened to cover possibly disconnected queries with constants. Our results exploit recently discovered connections between SVC and probabilistic query evaluation and allow us to generalize existing results on probabilistic OMQA.",
        "subjects": [
            "cs.AI",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20068",
        "abstract url": "https://arxiv.org/abs/2407.20068",
        "title": "Unleash the Power of Ellipsis: Accuracy-enhanced Sparse Vector Technique with Exponential Noise",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The Sparse Vector Technique (SVT) is one of the most fundamental tools in differential privacy (DP). It works as a backbone for adaptive data analysis by answering a sequence of queries on a given dataset, and gleaning useful information in a privacy-preserving manner. Unlike the typical private query releases that directly publicize the noisy query results, SVT is less informative -- it keeps the noisy query results to itself and only reveals a binary bit for each query, indicating whether the query result surpasses a predefined threshold. To provide a rigorous DP guarantee for SVT, prior works in the literature adopt a conservative privacy analysis by assuming the direct disclosure of noisy query results as in typical private query releases. This approach, however, hinders SVT from achieving higher query accuracy due to an overestimation of the privacy risks, which further leads to an excessive noise injection using the Laplacian or Gaussian noise for perturbation. Motivated by this, we provide a new privacy analysis for SVT by considering its less informative nature. Our analysis results not only broaden the range of applicable noise types for perturbation in SVT, but also identify the exponential noise as optimal among all evaluated noises (which, however, is usually deemed non-applicable in prior works). The main challenge in applying exponential noise to SVT is mitigating the sub-optimal performance due to the bias introduced by noise distributions. To address this, we develop a utility-oriented optimal threshold correction method and an appending strategy, which enhances the performance of SVT by increasing the precision and recall, respectively. The effectiveness of our proposed methods is substantiated both theoretically and empirically, demonstrating significant improvements up to $50\\%$ across evaluated metrics.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20070",
        "abstract url": "https://arxiv.org/abs/2407.20070",
        "title": "An Interpretable Rule Creation Method for Black-Box Models based on Surrogate Trees -- SRules",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As artificial intelligence (AI) systems become increasingly integrated into critical decision-making processes, the need for transparent and interpretable models has become paramount. In this article we present a new ruleset creation method based on surrogate decision trees (SRules), designed to improve the interpretability of black-box machine learning models. SRules balances the accuracy, coverage, and interpretability of machine learning models by recursively creating surrogate interpretable decision tree models that approximate the decision boundaries of a complex model. We propose a systematic framework for generating concise and meaningful rules from these surrogate models, allowing stakeholders to understand and trust the AI system's decision-making process. Our approach not only provides interpretable rules, but also quantifies the confidence and coverage of these rules. The proposed model allows to adjust its parameters to counteract the lack of interpretability by precision and coverage by allowing a near perfect fit and high interpretability of some parts of the model . The results show that SRules improves on other state-of-the-art techniques and introduces the possibility of creating highly interpretable specific rules for specific sub-parts of the model.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20105",
        "abstract url": "https://arxiv.org/abs/2407.20105",
        "title": "Strong Copyright Protection for Language Models via Adaptive Model Fusion",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The risk of language models unintentionally reproducing copyrighted material from their training data has led to the development of various protective measures. In this paper, we propose model fusion as an effective solution to safeguard against copyright infringement. In particular, we introduce Copyright-Protecting Fusion (CP-Fuse), an algorithm that adaptively combines language models to minimize the reproduction of protected materials. CP-Fuse is inspired by the recently proposed Near-Access Free (NAF) framework and additionally incorporates a desirable balancing property that we demonstrate prevents the reproduction of memorized training data. Our results show that CP-Fuse significantly reduces the memorization of copyrighted content while maintaining high-quality text and code generation. Furthermore, we demonstrate how CP-Fuse can be integrated with other techniques for enhanced protection.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20122",
        "abstract url": "https://arxiv.org/abs/2407.20122",
        "title": "Tightening the Evaluation of PAC Bounds Using Formal Verification Results",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Probably Approximately Correct (PAC) bounds are widely used to derive probabilistic guarantees for the generalisation of machine learning models. They highlight the components of the model which contribute to its generalisation capacity. However, current state-of-the-art results are loose in approximating the generalisation capacity of deployed machine learning models. Consequently, while PAC bounds are theoretically useful, their applicability for evaluating a model's generalisation property in a given operational design domain is limited. The underlying classical theory is supported by the idea that bounds can be tightened when the number of test points available to the user to evaluate the model increases. Yet, in the case of neural networks, the number of test points required to obtain bounds of interest is often impractical even for small problems. In this paper, we take the novel approach of using the formal verification of neural systems to inform the evaluation of PAC bounds. Rather than using pointwise information obtained from repeated tests, we use verification results on regions around test points. We show that conditioning existing bounds on verification results leads to a tightening proportional to the underlying probability mass of the verified region.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2407.20124",
        "abstract url": "https://arxiv.org/abs/2407.20124",
        "title": "AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rapid evolution of multimedia and computer vision technologies requires adaptive visual model deployment strategies to effectively handle diverse tasks and varying environments. This work introduces AxiomVision, a novel framework that can guarantee accuracy by leveraging edge computing to dynamically select the most efficient visual models for video analytics under diverse scenarios. Utilizing a tiered edge-cloud architecture, AxiomVision enables the deployment of a broad spectrum of visual models, from lightweight to complex DNNs, that can be tailored to specific scenarios while considering camera source impacts. In addition, AxiomVision provides three core innovations: (1) a dynamic visual model selection mechanism utilizing continual online learning, (2) an efficient online method that efficiently takes into account the influence of the camera's perspective, and (3) a topology-driven grouping approach that accelerates the model selection process. With rigorous theoretical guarantees, these advancements provide a scalable and effective solution for visual tasks inherent to multimedia systems, such as object detection, classification, and counting. Empirically, AxiomVision achieves a 25.7\\% improvement in accuracy.",
        "subjects": [
            "cs.MM",
            "cs.AI"
        ],
        "comment": "Accepted by ACM MM 2024"
    },
    {
        "paper id": "2407.20130",
        "abstract url": "https://arxiv.org/abs/2407.20130",
        "title": "To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Since the public release of Chat Generative Pre-Trained Transformer (ChatGPT), extensive discourse has emerged concerning the potential advantages and challenges of integrating Generative Artificial Intelligence (GenAI) into education. In the realm of information systems, research on technology adoption is crucial for understanding the diverse factors influencing the uptake of specific technologies. Theoretical frameworks, refined and validated over decades, serve as guiding tools to elucidate the individual and organizational dynamics, obstacles, and perceptions surrounding technology adoption. However, while several models have been proposed, they often prioritize elucidating the factors that facilitate acceptance over those that impede it, typically focusing on the student perspective and leaving a gap in empirical evidence regarding educators viewpoints. Given the pivotal role educators play in higher education, this study aims to develop a theoretical model to empirically predict the barriers preventing educators from adopting GenAI in their classrooms. Acknowledging the lack of theoretical models tailored to identifying such barriers, our approach is grounded in the Innovation Resistance Theory (IRT) framework and augmented with constructs from the Technology-Organization-Environment (TOE) framework. This model is transformed into a measurement instrument employing a quantitative approach, complemented by a qualitative approach to enrich the analysis and uncover concerns related to GenAI adoption in the higher education domain.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.ET",
            "cs.HC",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20158",
        "abstract url": "https://arxiv.org/abs/2407.20158",
        "title": "Machine Learning for predicting chaotic systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predicting chaotic dynamical systems is critical in many scientific fields such as weather prediction, but challenging due to the characterizing sensitive dependence on initial conditions. Traditional modeling approaches require extensive domain knowledge, often leading to a shift towards data-driven methods using machine learning. However, existing research provides inconclusive results on which machine learning methods are best suited for predicting chaotic systems. In this paper, we compare different lightweight and heavyweight machine learning architectures using extensive existing databases, as well as a newly introduced one that allows for uncertainty quantification in the benchmark results. We perform hyperparameter tuning based on computational cost and introduce a novel error metric, the cumulative maximum error, which combines several desirable properties of traditional metrics, tailored for chaotic systems. Our results show that well-tuned simple methods, as well as untuned baseline methods, often outperform state-of-the-art deep learning models, but their performance can vary significantly with different experimental setups. These findings underscore the importance of matching prediction methods to data characteristics and available computational resources.",
        "subjects": [
            "cs.LG",
            "nlin.CD"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20197",
        "abstract url": "https://arxiv.org/abs/2407.20197",
        "title": "Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deployment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we developed a learning method for constructing a neural network system capable of memorizing data and recalling it without parameter updates. The system we built using this method is called the Appendable Memory system. The Appendable Memory system enables an artificial intelligence (AI) to acquire new knowledge even after deployment. It consists of two AIs: the Memorizer and the Recaller. This system is a key-value store built using neural networks. The Memorizer receives data and stores it in the Appendable Memory vector, which is dynamically updated when the AI acquires new knowledge. Meanwhile, the Recaller retrieves information from the Appendable Memory vector. What we want to teach AI in this study are the operations of memorizing and recalling information. However, traditional machine learning methods make AI learn features inherent in the learning dataset. We demonstrate that the systems we intend to create cannot be realized by current machine learning methods, that is, by merely repeating the input and output learning sequences with AI. Instead, we propose a method to teach AI to learn operations, by completely removing the features contained in the learning dataset. Specifically, we probabilized all the data involved in learning. This measure prevented AI from learning the features of the data. The learning method proposed in the study differs from traditional machine learning methods and provides fundamental approaches for building an AI system that can store information in a finite memory and recall it at a later date.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20199",
        "abstract url": "https://arxiv.org/abs/2407.20199",
        "title": "Emergence in non-neural models: grokking modular arithmetic via average gradient outer product",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural networks trained to solve modular arithmetic tasks exhibit grokking, a phenomenon where the test accuracy starts improving long after the model achieves 100% training accuracy in the training process. It is often taken as an example of \"emergence\", where model ability manifests sharply through a phase transition. In this work, we show that the phenomenon of grokking is not specific to neural networks nor to gradient descent-based optimization. Specifically, we show that this phenomenon occurs when learning modular arithmetic with Recursive Feature Machines (RFM), an iterative algorithm that uses the Average Gradient Outer Product (AGOP) to enable task-specific feature learning with general machine learning models. When used in conjunction with kernel machines, iterating RFM results in a fast transition from random, near zero, test accuracy to perfect test accuracy. This transition cannot be predicted from the training loss, which is identically zero, nor from the test loss, which remains constant in initial iterations. Instead, as we show, the transition is completely determined by feature learning: RFM gradually learns block-circulant features to solve modular arithmetic. Paralleling the results for RFM, we show that neural networks that solve modular arithmetic also learn block-circulant features. Furthermore, we present theoretical evidence that RFM uses such block-circulant features to implement the Fourier Multiplication Algorithm, which prior work posited as the generalizing solution neural networks learn on these tasks. Our results demonstrate that emergence can result purely from learning task-relevant features and is not specific to neural architectures nor gradient descent-based optimization methods. Furthermore, our work provides more evidence for AGOP as a key mechanism for feature learning in neural networks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20208",
        "abstract url": "https://arxiv.org/abs/2407.20208",
        "title": "Supertrust: Evolution-based superalignment strategy for safe coexistence",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "It's widely expected that humanity will someday create AI systems vastly more intelligent than we are, leading to the unsolved alignment problem of \"how to control superintelligence.\" However, this definition is not only self-contradictory but likely unsolvable. Nevertheless, the default strategy for solving it involves nurturing (post-training) constraints and moral values, while unfortunately building foundational nature (pre-training) on documented intentions of permanent control. In this paper, the default approach is reasoned to predictably embed natural distrust and test results are presented that show unmistakable evidence of this dangerous misalignment. If superintelligence can't instinctively trust humanity, then we can't fully trust it to reliably follow safety controls it can likely bypass. Therefore, a ten-point rationale is presented that redefines the alignment problem as \"how to establish protective mutual trust between superintelligence and humanity\" and then outlines a new strategy to solve it by aligning through instinctive nature rather than nurture. The resulting strategic requirements are identified as building foundational nature by exemplifying familial parent-child trust, human intelligence as the evolutionary mother of superintelligence, moral judgment abilities, and temporary safety constraints. Adopting and implementing this proposed Supertrust alignment strategy will lead to protective coexistence and ensure the safest future for humanity.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20209",
        "abstract url": "https://arxiv.org/abs/2407.20209",
        "title": "Characterizing Dynamical Stability of Stochastic Gradient Descent in Overparameterized Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "For overparameterized optimization tasks, such as the ones found in modern machine learning, global minima are generally not unique. In order to understand generalization in these settings, it is vital to study to which minimum an optimization algorithm converges. The possibility of having minima that are unstable under the dynamics imposed by the optimization algorithm limits the potential minima that the algorithm can find. In this paper, we characterize the global minima that are dynamically stable/unstable for both deterministic and stochastic gradient descent (SGD). In particular, we introduce a characteristic Lyapunov exponent which depends on the local dynamics around a global minimum and rigorously prove that the sign of this Lyapunov exponent determines whether SGD can accumulate at the respective global minimum.",
        "subjects": [
            "cs.LG",
            "math.DS",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20219",
        "abstract url": "https://arxiv.org/abs/2407.20219",
        "title": "Global Structure-from-Motion Revisited",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Recovering 3D structure and camera motion from images has been a long-standing focus of computer vision research and is known as Structure-from-Motion (SfM). Solutions to this problem are categorized into incremental and global approaches. Until now, the most popular systems follow the incremental paradigm due to its superior accuracy and robustness, while global approaches are drastically more scalable and efficient. With this work, we revisit the problem of global SfM and propose GLOMAP as a new general-purpose system that outperforms the state of the art in global SfM. In terms of accuracy and robustness, we achieve results on-par or superior to COLMAP, the most widely used incremental SfM, while being orders of magnitude faster. We share our system as an open-source implementation at {https://github.com/colmap/glomap}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted at ECCV2024"
    },
    {
        "paper id": "2407.20223",
        "abstract url": "https://arxiv.org/abs/2407.20223",
        "title": "Correspondence-Free SE(3) Point Cloud Registration in RKHS via Unsupervised Equivariant Learning",
        "rating": "0.5",
        "keywords": [
            [
                "Point Cloud",
                "RGB-D"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This paper introduces a robust unsupervised SE(3) point cloud registration method that operates without requiring point correspondences. The method frames point clouds as functions in a reproducing kernel Hilbert space (RKHS), leveraging SE(3)-equivariant features for direct feature space registration. A novel RKHS distance metric is proposed, offering reliable performance amidst noise, outliers, and asymmetrical data. An unsupervised training approach is introduced to effectively handle limited ground truth data, facilitating adaptation to real datasets. The proposed method outperforms classical and supervised methods in terms of registration accuracy on both synthetic (ModelNet40) and real-world (ETH3D) noisy, outlier-rich datasets. To our best knowledge, this marks the first instance of successful real RGB-D odometry data registration using an equivariant method. The code is available at {https://sites.google.com/view/eccv24-equivalign}",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "10 pages, to be published in ECCV 2024"
    },
    {
        "paper id": "2407.20229",
        "abstract url": "https://arxiv.org/abs/2407.20229",
        "title": "Improving 2D Feature Representations by 3D-Aware Fine-Tuning",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Current visual foundation models are trained purely on unstructured 2D data, limiting their understanding of 3D structure of objects and scenes. In this work, we show that fine-tuning on 3D-aware data improves the quality of emerging semantic features. We design a method to lift semantic 2D features into an efficient 3D Gaussian representation, which allows us to re-render them for arbitrary views. Using the rendered 3D-aware features, we design a fine-tuning strategy to transfer such 3D awareness into a 2D foundation model. We demonstrate that models fine-tuned in that way produce features that readily improve downstream task performance in semantic segmentation and depth estimation through simple linear probing. Notably, though fined-tuned on a single indoor dataset, the improvement is transferable to a variety of indoor datasets and out-of-domain datasets. We hope our study encourages the community to consider injecting 3D awareness when training 2D foundation models. Project page: https://ywyue.github.io/FiT3D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024. Project page: https://ywyue.github.io/FiT3D"
    },
    {
        "paper id": "2407.20360",
        "abstract url": "https://arxiv.org/abs/2407.20360",
        "title": "Evaluating Large Language Models for automatic analysis of teacher simulations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Digital Simulations (DS) provide safe environments where users interact with an agent through conversational prompts, providing engaging learning experiences that can be used to train teacher candidates in realistic classroom scenarios. These simulations usually include open-ended questions, allowing teacher candidates to express their thoughts but complicating an automatic response analysis. To address this issue, we have evaluated Large Language Models (LLMs) to identify characteristics (user behaviors) in the responses of DS for teacher education. We evaluated the performance of DeBERTaV3 and Llama 3, combined with zero-shot, few-shot, and fine-tuning. Our experiments discovered a significant variation in the LLMs' performance depending on the characteristic to identify. Additionally, we noted that DeBERTaV3 significantly reduced its performance when it had to identify new characteristics. In contrast, Llama 3 performed better than DeBERTaV3 in detecting new characteristics and showing more stable performance. Therefore, in DS where teacher educators need to introduce new characteristics because they change depending on the simulation or the educational objectives, it is more recommended to use Llama 3. These results can guide other researchers in introducing LLMs to provide the highly demanded automatic evaluations in DS.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20367",
        "abstract url": "https://arxiv.org/abs/2407.20367",
        "title": "Mixed Newton Method for Optimization in Complex Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we modify and apply the recently introduced Mixed Newton Method, which is originally designed for minimizing real-valued functions of complex variables, to the minimization of real-valued functions of real variables by extending the functions to complex space. We show that arbitrary regularizations preserve the favorable local convergence properties of the method, and construct a special type of regularization used to prevent convergence to complex minima. We compare several variants of the method applied to training neural networks with real and complex parameters.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": "16 pages, 7 figures, 6 tables"
    },
    {
        "paper id": "2407.20377",
        "abstract url": "https://arxiv.org/abs/2407.20377",
        "title": "Leveraging Natural Language and Item Response Theory Models for ESG Scoring",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper explores an innovative approach to Environmental, Social, and Governance (ESG) scoring by integrating Natural Language Processing (NLP) techniques with Item Response Theory (IRT), specifically the Rasch model. The study utilizes a comprehensive dataset of news articles in Portuguese related to Petrobras, a major oil company in Brazil, collected from 2022 and 2023. The data is filtered and classified for ESG-related sentiments using advanced NLP methods. The Rasch model is then applied to evaluate the psychometric properties of these ESG measures, providing a nuanced assessment of ESG sentiment trends over time. The results demonstrate the efficacy of this methodology in offering a more precise and reliable measurement of ESG factors, highlighting significant periods and trends. This approach may enhance the robustness of ESG metrics and contribute to the broader field of sustainability and finance by offering a deeper understanding of the temporal dynamics in ESG reporting.",
        "subjects": [
            "cs.AI",
            "q-fin.GN",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20432",
        "abstract url": "https://arxiv.org/abs/2407.20432",
        "title": "Neural Surrogate HMC: Accelerated Hamiltonian Monte Carlo with a Neural Network Surrogate Likelihood",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian Inference with Markov Chain Monte Carlo requires efficient computation of the likelihood function. In some scientific applications, the likelihood must be computed by numerically solving a partial differential equation, which can be prohibitively expensive. We demonstrate that some such problems can be made tractable by amortizing the computation with a surrogate likelihood function implemented by a neural network. We show that this has two additional benefits: reducing noise in the likelihood evaluations and providing fast gradient calculations. In experiments, the approach is applied to a model of heliospheric transport of galactic cosmic rays, where it enables efficient sampling from the posterior of latent parameters in the Parker equation.",
        "subjects": [
            "cs.LG",
            "astro-ph.HE"
        ],
        "comment": "5 pages, 3 figures, accepted at SPAICE Conference 2024"
    },
    {
        "paper id": "2407.20442",
        "abstract url": "https://arxiv.org/abs/2407.20442",
        "title": "The GPT Dilemma: Foundation Models and the Shadow of Dual-Use",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper examines the dual-use challenges of foundation models and the consequent risks they pose for international security. As artificial intelligence (AI) models are increasingly tested and deployed across both civilian and military sectors, distinguishing between these uses becomes more complex, potentially leading to misunderstandings and unintended escalations among states. The broad capabilities of foundation models lower the cost of repurposing civilian models for military uses, making it difficult to discern another state's intentions behind developing and deploying these models. As military capabilities are increasingly augmented by AI, this discernment is crucial in evaluating the extent to which a state poses a military threat. Consequently, the ability to distinguish between military and civilian applications of these models is key to averting potential military escalations. The paper analyzes this issue through four critical factors in the development cycle of foundation models: model inputs, capabilities, system use cases, and system deployment. This framework helps elucidate the points at which ambiguity between civilian and military applications may arise, leading to potential misperceptions. Using the Intermediate-Range Nuclear Forces (INF) Treaty as a case study, this paper proposes several strategies to mitigate the associated risks. These include establishing red lines for military competition, enhancing information-sharing protocols, employing foundation models to promote international transparency, and imposing constraints on specific weapon platforms. By managing dual-use risks effectively, these strategies aim to minimize potential escalations and address the trade-offs accompanying increasingly general AI models.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20444",
        "abstract url": "https://arxiv.org/abs/2407.20444",
        "title": "Importance Corrected Neural JKO Sampling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In order to sample from an unnormalized probability density function, we propose to combine continuous normalizing flows (CNFs) with rejection-resampling steps based on importance weights. We relate the iterative training of CNFs with regularized velocity fields to a JKO scheme and prove convergence of the involved velocity fields to the velocity field of the Wasserstein gradient flow (WGF). The alternation of local flow steps and non-local rejection-resampling steps allows to overcome local minima or slow convergence of the WGF for multimodal distributions. Since the proposal of the rejection step is generated by the model itself, they do not suffer from common drawbacks of classical rejection schemes. The arising model can be trained iteratively, reduces the reverse Kulback-Leibler (KL) loss function in each step, allows to generate iid samples and moreover allows for evaluations of the generated underlying density. Numerical examples show that our method yields accurate results on various test distributions including high-dimensional multimodal targets and outperforms the state of the art in almost all cases significantly.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20447",
        "abstract url": "https://arxiv.org/abs/2407.20447",
        "title": "Domain Adaptable Prescriptive AI Agent for Enterprise",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Despite advancements in causal inference and prescriptive AI, its adoption in enterprise settings remains hindered primarily due to its technical complexity. Many users lack the necessary knowledge and appropriate tools to effectively leverage these technologies. This work at the MIT-IBM Watson AI Lab focuses on developing the proof-of-concept agent, PrecAIse, a domain-adaptable conversational agent equipped with a suite of causal and prescriptive tools to help enterprise users make better business decisions. The objective is to make advanced, novel causal inference and prescriptive tools widely accessible through natural language interactions. The presented Natural Language User Interface (NLUI) enables users with limited expertise in machine learning and data science to harness prescriptive analytics in their decision-making processes without requiring intensive computing resources. We present an agent capable of function calling, maintaining faithful, interactive, and dynamic conversations, and supporting new domains.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20466",
        "abstract url": "https://arxiv.org/abs/2407.20466",
        "title": "A Method for Fast Autonomy Transfer in Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces a novel reinforcement learning (RL) strategy designed to facilitate rapid autonomy transfer by utilizing pre-trained critic value functions from multiple environments. Unlike traditional methods that require extensive retraining or fine-tuning, our approach integrates existing knowledge, enabling an RL agent to adapt swiftly to new settings without requiring extensive computational resources. Our contributions include development of the Multi-Critic Actor-Critic (MCAC) algorithm, establishing its convergence, and empirical evidence demonstrating its efficacy. Our experimental results show that MCAC significantly outperforms the baseline actor-critic algorithm, achieving up to 22.76x faster autonomy transfer and higher reward accumulation. This advancement underscores the potential of leveraging accumulated knowledge for efficient adaptation in RL applications.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20475",
        "abstract url": "https://arxiv.org/abs/2407.20475",
        "title": "Distribution Learning for Molecular Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Using \"soft\" targets to improve model performance has been shown to be effective in classification settings, but the usage of soft targets for regression is a much less studied topic in machine learning. The existing literature on the usage of soft targets for regression fails to properly assess the method's limitations, and empirical evaluation is quite limited. In this work, we assess the strengths and drawbacks of existing methods when applied to molecular property regression tasks. Our assessment outlines key biases present in existing methods and proposes methods to address them, evaluated through careful ablation studies. We leverage these insights to propose Distributional Mixture of Experts (DMoE): A model-independent, and data-independent method for regression which trains a model to predict probability distributions of its targets. Our proposed loss function combines the cross entropy between predicted and target distributions and the L1 distance between their expected values to produce a loss function that is robust to the outlined biases. We evaluate the performance of DMoE on different molecular property prediction datasets -- Open Catalyst (OC20), MD17, and QM9 -- across different backbone model architectures -- SchNet, GemNet, and Graphormer. Our results demonstrate that the proposed method is a promising alternative to classical regression for molecular property prediction tasks, showing improvements over baselines on all datasets and architectures.",
        "subjects": [
            "cs.LG",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20496",
        "abstract url": "https://arxiv.org/abs/2407.20496",
        "title": "Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "N:M sparsity pruning is a powerful technique for compressing deep neural networks, utilizing NVIDIA's Sparse Tensor Core technology. This method benefits from hardware support for sparse indexing, enabling the adoption of fine-grained sparsity to maintain model accuracy while minimizing the overhead typically associated with irregular data access. Although restricted to a fixed level of sparsity due to its reliance on hardware, N:M sparsity can be combined with coarser sparsity techniques to achieve diverse compression ratios. Initially, column-wise vector sparsity is applied to a dense model, followed by row-wise N:M sparsity on the preserved column vectors. We call this multi-level approach as hierarchical N:M (HiNM) sparsity. Similar to earlier single-level sparsity techniques, HiNM sparsity necessitates an effective channel permutation strategy to maximize the accuracy of the compressed networks. However, it introduces further complexities by requiring the rearrangement of both input and output channels, addressing challenges such as permutation sequence, HiNM-sparsity-aware permutation, and maintaining consistency in channel ordering across layers. In this paper, we introduce a channel permutation method designed specifically for HiNM sparsity, named gyro-permutation. This method is crafted to exploit the unique characteristics of HiNM pruning, incorporating a strategic policy in each permutation phase, including channel sampling, clustering, and assignment, to circumvent local minima. Additionally, we have developed a GPU kernel that facilitates independent layer permutation during the execution of HiNM sparse networks. Our extensive experimental evaluations on various DNN models demonstrate that our gyro-permutation significantly enhances the accuracy of HiNM sparse networks, allowing them to reach performance levels comparable to those of unstructured sparse networks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2407.20506",
        "abstract url": "https://arxiv.org/abs/2407.20506",
        "title": "Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The effectiveness of model training heavily relies on the quality of available training resources. However, budget constraints often impose limitations on data collection efforts. To tackle this challenge, we introduce causal exploration in this paper, a strategy that leverages the underlying causal knowledge for both data collection and model training. We, in particular, focus on enhancing the sample efficiency and reliability of the world model learning within the domain of task-agnostic reinforcement learning. During the exploration phase, the agent actively selects actions expected to yield causal insights most beneficial for world model training. Concurrently, the causal knowledge is acquired and incrementally refined with the ongoing collection of data. We demonstrate that causal exploration aids in learning accurate world models using fewer data and provide theoretical guarantees for its convergence. Empirical experiments, on both synthetic data and real-world applications, further validate the benefits of causal exploration.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "This paper was accepted by IJCAI'24"
    },
    {
        "paper id": "2407.20514",
        "abstract url": "https://arxiv.org/abs/2407.20514",
        "title": "The Future of International Data Transfers: Managing Legal Risk with a User-Held Data Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The General Data Protection Regulation contains a blanket prohibition on the transfer of personal data outside of the European Economic Area unless strict requirements are met. The rationale for this provision is to protect personal data and data subject rights by restricting data transfers to countries that may not have the same level of protection as the EEA. However, the ubiquitous and permeable character of new technologies such as cloud computing, and the increased inter connectivity between societies, has made international data transfers the norm and not the exception. The Schrems II case and subsequent regulatory developments have further raised the bar for companies to comply with complex and, often, opaque rules. Many firms are, therefore, pursuing technology-based solutions in order to mitigate this new legal risk. These emerging technological alternatives reduce the need for open-ended cross-border transfers and the practical challenges and legal risk that such transfers create after Schrems. This article examines one such alternative, namely a user-held data model. This approach takes advantage of personal data clouds that allows data subjects to store their data locally and in a more decentralised manner, thus decreasing the need for cross-border transfers and offering end-users the possibility of greater control over their data.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.21078",
        "abstract url": "https://arxiv.org/abs/2407.21078",
        "title": "Convergence rates for the Adam optimizer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Stochastic gradient descent (SGD) optimization methods are nowadays the method of choice for the training of deep neural networks (DNNs) in artificial intelligence systems. In practically relevant training problems, usually not the plain vanilla standard SGD method is the employed optimization scheme but instead suitably accelerated and adaptive SGD optimization methods are applied. As of today, maybe the most popular variant of such accelerated and adaptive SGD optimization methods is the famous Adam optimizer proposed by Kingma & Ba in 2014. Despite the popularity of the Adam optimizer in implementations, it remained an open problem of research to provide a convergence analysis for the Adam optimizer even in the situation of simple quadratic stochastic optimization problems where the objective function (the function one intends to minimize) is strongly convex. In this work we solve this problem by establishing optimal convergence rates for the Adam optimizer for a large class of stochastic optimization problems, in particular, covering simple quadratic stochastic optimization problems. The key ingredient of our convergence analysis is a new vector field function which we propose to refer to as the Adam vector field. This Adam vector field accurately describes the macroscopic behaviour of the Adam optimization process but differs from the negative gradient of the objective function (the function we intend to minimize) of the considered stochastic optimization problem. In particular, our convergence analysis reveals that the Adam optimizer does typically not converge to critical points of the objective function (zeros of the gradient of the objective function) of the considered optimization problem but converges with rates to zeros of this Adam vector field.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19704",
        "abstract url": "https://arxiv.org/abs/2407.19704",
        "title": "UNQA: Unified No-Reference Quality Assessment for Audio, Image, Video, and Audio-Visual Content",
        "rating": "0",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "Quality Assessment"
            ],
            [
                "eess.IV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "As multimedia data flourishes on the Internet, quality assessment (QA) of multimedia data becomes paramount for digital media applications. Since multimedia data includes multiple modalities including audio, image, video, and audio-visual (A/V) content, researchers have developed a range of QA methods to evaluate the quality of different modality data. While they exclusively focus on addressing the single modality QA issues, a unified QA model that can handle diverse media across multiple modalities is still missing, whereas the latter can better resemble human perception behaviour and also have a wider range of applications. In this paper, we propose the Unified No-reference Quality Assessment model (UNQA) for audio, image, video, and A/V content, which tries to train a single QA model across different media modalities. To tackle the issue of inconsistent quality scales among different QA databases, we develop a multi-modality strategy to jointly train UNQA on multiple QA databases. Based on the input modality, UNQA selectively extracts the spatial features, motion features, and audio features, and calculates a final quality score via the four corresponding modality regression modules. Compared with existing QA methods, UNQA has two advantages: 1) the multi-modality training strategy makes the QA model learn more general and robust quality-aware feature representation as evidenced by the superior performance of UNQA compared to state-of-the-art QA methods. 2) UNQA reduces the number of models required to assess multimedia data across different modalities. and is friendly to deploy to practical applications.",
        "subjects": [
            "eess.IV",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19774",
        "abstract url": "https://arxiv.org/abs/2407.19774",
        "title": "Garment Animation NeRF with Color Editing",
        "rating": "0",
        "keywords": [
            [
                "NeRF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generating high-fidelity garment animations through traditional workflows, from modeling to rendering, is both tedious and expensive. These workflows often require repetitive steps in response to updates in character motion, rendering viewpoint changes, or appearance edits. Although recent neural rendering offers an efficient solution for computationally intensive processes, it struggles with rendering complex garment animations containing fine wrinkle details and realistic garment-and-body occlusions, while maintaining structural consistency across frames and dense view rendering. In this paper, we propose a novel approach to directly synthesize garment animations from body motion sequences without the need for an explicit garment proxy. Our approach infers garment dynamic features from body motion, providing a preliminary overview of garment structure. Simultaneously, we capture detailed features from synthesized reference images of the garment's front and back, generated by a pre-trained image model. These features are then used to construct a neural radiance field that renders the garment animation video. Additionally, our technique enables garment recoloring by decomposing its visual elements. We demonstrate the generalizability of our method across unseen body motions and camera views, ensuring detailed structural consistency. Furthermore, we showcase its applicability to color editing on both real and synthetic garment data. Compared to existing neural rendering techniques, our method exhibits qualitative and quantitative improvements in garment dynamics and wrinkle detail modeling. Code is available at \\url{https://github.com/wrk226/GarmentAnimationNeRF}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19808",
        "abstract url": "https://arxiv.org/abs/2407.19808",
        "title": "Segmentation en phrases : ouvrez les guillemets sans perdre le fil",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a graph cascade for sentence segmentation of XML documents. Our proposal offers sentences inside sentences for cases introduced by quotation marks and hyphens, and also pays particular attention to situations involving incises introduced by parentheses and lists introduced by colons. We present how the tool works and compare the results obtained with those available in 2019 on the same dataset, together with an evaluation of the system's performance on a test corpus",
        "subjects": [
            "cs.CL"
        ],
        "comment": "in French language"
    },
    {
        "paper id": "2407.19813",
        "abstract url": "https://arxiv.org/abs/2407.19813",
        "title": "Improving Retrieval Augmented Language Model with Self-Reasoning",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The Retrieval-Augmented Language Model (RALM) has shown remarkable performance on knowledge-intensive tasks by incorporating external knowledge during inference, which mitigates the factual hallucinations inherited in large language models (LLMs). Despite these advancements, challenges persist in the implementation of RALMs, particularly concerning their reliability and traceability. To be specific, the irrelevant document retrieval may result in unhelpful response generation or even deteriorate the performance of LLMs, while the lack of proper citations in generated outputs complicates efforts to verify the trustworthiness of the models. To this end, we propose a novel self-reasoning framework aimed at improving the reliability and traceability of RALMs, whose core idea is to leverage reasoning trajectories generated by the LLM itself. The framework involves constructing self-reason trajectories with three processes: a relevance-aware process, an evidence-aware selective process, and a trajectory analysis process. We have evaluated our framework across four public datasets (two short-form QA datasets, one long-form QA dataset, and one fact verification dataset) to demonstrate the superiority of our method, which can outperform existing state-of-art models and can achieve comparable performance with GPT-4, while only using 2,000 training samples.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19837",
        "abstract url": "https://arxiv.org/abs/2407.19837",
        "title": "VortSDF: 3D Modeling with Centroidal Voronoi Tesselation on Signed Distance Field",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "voxel",
                "radiance fields",
                "Signed Distance Field",
                "SDF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Volumetric shape representations have become ubiquitous in multi-view reconstruction tasks. They often build on regular voxel grids as discrete representations of 3D shape functions, such as SDF or radiance fields, either as the full shape model or as sampled instantiations of continuous representations, as with neural networks. Despite their proven efficiency, voxel representations come with the precision versus complexity trade-off. This inherent limitation can significantly impact performance when moving away from simple and uncluttered scenes. In this paper we investigate an alternative discretization strategy with the Centroidal Voronoi Tesselation (CVT). CVTs allow to better partition the observation space with respect to shape occupancy and to focus the discretization around shape surfaces. To leverage this discretization strategy for multi-view reconstruction, we introduce a volumetric optimization framework that combines explicit SDF fields with a shallow color network, in order to estimate 3D shape properties over tetrahedral grids. Experimental results with Chamfer statistics validate this approach with unprecedented reconstruction quality on various scenarios such as objects, open scenes or human.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19845",
        "abstract url": "https://arxiv.org/abs/2407.19845",
        "title": "BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "As an emerging approach to explore the vulnerability of deep neural networks (DNNs), backdoor learning has attracted increasing interest in recent years, and many seminal backdoor attack and defense algorithms are being developed successively or concurrently, in the status of a rapid arms race. However, mainly due to the diverse settings, and the difficulties of implementation and reproducibility of existing works, there is a lack of a unified and standardized benchmark of backdoor learning, causing unfair comparisons or unreliable conclusions (e.g., misleading, biased or even false conclusions). Consequently, it is difficult to evaluate the current progress and design the future development roadmap of this literature. To alleviate this dilemma, we build a comprehensive benchmark of backdoor learning called BackdoorBench. Our benchmark makes three valuable contributions to the research community. 1) We provide an integrated implementation of state-of-the-art (SOTA) backdoor learning algorithms (currently including 20 attack and 32 defense algorithms), based on an extensible modular-based codebase. 2) We conduct comprehensive evaluations with 5 poisoning ratios, based on 4 models and 4 datasets, leading to 11,492 pairs of attack-against-defense evaluations in total. 3) Based on above evaluations, we present abundant analysis from 10 perspectives via 18 useful analysis tools, and provide several inspiring insights about backdoor learning. We hope that our efforts could build a solid foundation of backdoor learning to facilitate researchers to investigate existing algorithms, develop more innovative algorithms, and explore the intrinsic mechanism of backdoor learning. Finally, we have created a user-friendly website at http://backdoorbench.com, which collects all important information of BackdoorBench, including codebase, docs, leaderboard, and model Zoo.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "Substantial extensions based on our previous conference version \"Backdoorbench: A comprehensive benchmark of backdoor learning\" published at NeurIPS D&B Track 2022. 20 backdoor attack algorithms, 32 backdoor defense algorithms, 11000+ pairs of attack-against-defense evaluations, 10 analyses, 18 analysis tools"
    },
    {
        "paper id": "2407.19918",
        "abstract url": "https://arxiv.org/abs/2407.19918",
        "title": "FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video diffusion models have made substantial progress in various video generation applications. However, training models for long video generation tasks require significant computational and data resources, posing a challenge to developing long video diffusion models. This paper investigates a straightforward and training-free approach to extend an existing short video diffusion model (e.g. pre-trained on 16-frame videos) for consistent long video generation (e.g. 128 frames). Our preliminary observation has found that directly applying the short video diffusion model to generate long videos can lead to severe video quality degradation. Further investigation reveals that this degradation is primarily due to the distortion of high-frequency components in long videos, characterized by a decrease in spatial high-frequency components and an increase in temporal high-frequency components. Motivated by this, we propose a novel solution named FreeLong to balance the frequency distribution of long video features during the denoising process. FreeLong blends the low-frequency components of global video features, which encapsulate the entire video sequence, with the high-frequency components of local video features that focus on shorter subsequences of frames. This approach maintains global consistency while incorporating diverse and high-quality spatiotemporal details from local videos, enhancing both the consistency and fidelity of long video generation. We evaluated FreeLong on multiple base video diffusion models and observed significant improvements. Additionally, our method supports coherent multi-prompt generation, ensuring both visual coherence and seamless transitions between scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://yulu.net.cn/freelong"
    },
    {
        "paper id": "2407.19996",
        "abstract url": "https://arxiv.org/abs/2407.19996",
        "title": "Reproducibility Study of \"ITI-GEN: Inclusive Text-to-Image Generation\"",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image generative models often present issues regarding fairness with respect to certain sensitive attributes, such as gender or skin tone. This study aims to reproduce the results presented in \"ITI-GEN: Inclusive Text-to-Image Generation\" by Zhang et al. (2023a), which introduces a model to improve inclusiveness in these kinds of models. We show that most of the claims made by the authors about ITI-GEN hold: it improves the diversity and quality of generated images, it is scalable to different domains, it has plug-and-play capabilities, and it is efficient from a computational point of view. However, ITI-GEN sometimes uses undesired attributes as proxy features and it is unable to disentangle some pairs of (correlated) attributes such as gender and baldness. In addition, when the number of considered attributes increases, the training time grows exponentially and ITI-GEN struggles to generate inclusive images for all elements in the joint distribution. To solve these issues, we propose using Hard Prompt Search with negative prompting, a method that does not require training and that handles negation better than vanilla Hard Prompt Search. Nonetheless, Hard Prompt Search (with or without negative prompting) cannot be used for continuous attributes that are hard to express in natural language, an area where ITI-GEN excels as it is guided by images during training. Finally, we propose combining ITI-GEN and Hard Prompt Search with negative prompting.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted to TMLR, see https://openreview.net/forum?id=d3Vj360Wi2"
    },
    {
        "paper id": "2407.20020",
        "abstract url": "https://arxiv.org/abs/2407.20020",
        "title": "ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Generative models, such as diffusion models (DMs), variational autoencoders (VAEs), and generative adversarial networks (GANs), produce images with a level of authenticity that makes them nearly indistinguishable from real photos and artwork. While this capability is beneficial for many industries, the difficulty of identifying synthetic images leaves online media platforms vulnerable to impersonation and misinformation attempts. To support the development of defensive methods, we introduce ImagiNet, a high-resolution and balanced dataset for synthetic image detection, designed to mitigate potential biases in existing resources. It contains 200K examples, spanning four content categories: photos, paintings, faces, and uncategorized. Synthetic images are produced with open-source and proprietary generators, whereas real counterparts of the same content type are collected from public datasets. The structure of ImagiNet allows for a two-track evaluation system: i) classification as real or synthetic and ii) identification of the generative model. To establish a baseline, we train a ResNet-50 model using a self-supervised contrastive objective (SelfCon) for each track. The model demonstrates state-of-the-art performance and high inference speed across established benchmarks, achieving an AUC of up to 0.99 and balanced accuracy ranging from 86% to 95%, even under social network conditions that involve compression and resizing. Our data and code are available at https://github.com/delyan-boychev/imaginet.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "24 pages, 9 figures, 9 tables"
    },
    {
        "paper id": "2407.20024",
        "abstract url": "https://arxiv.org/abs/2407.20024",
        "title": "Fairness Through Controlled (Un)Awareness in Node Embeddings",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.SI",
                "cs.CY"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Graph representation learning is central for the application of machine learning (ML) models to complex graphs, such as social networks. Ensuring `fair' representations is essential, due to the societal implications and the use of sensitive personal data. In this paper, we demonstrate how the parametrization of the \\emph{CrossWalk} algorithm influences the ability to infer a sensitive attributes from node embeddings. By fine-tuning hyperparameters, we show that it is possible to either significantly enhance or obscure the detectability of these attributes. This functionality offers a valuable tool for improving the fairness of ML systems utilizing graph embeddings, making them adaptable to different fairness paradigms.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "comment": "Poster at ICML 2024 Workshop on the Next Generation of AI Safety"
    },
    {
        "paper id": "2407.20062",
        "abstract url": "https://arxiv.org/abs/2407.20062",
        "title": "SalNAS: Efficient Saliency-prediction Neural Architecture Search with self-knowledge distillation",
        "rating": "0",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in deep convolutional neural networks have significantly improved the performance of saliency prediction. However, the manual configuration of the neural network architectures requires domain knowledge expertise and can still be time-consuming and error-prone. To solve this, we propose a new Neural Architecture Search (NAS) framework for saliency prediction with two contributions. Firstly, a supernet for saliency prediction is built with a weight-sharing network containing all candidate architectures, by integrating a dynamic convolution into the encoder-decoder in the supernet, termed SalNAS. Secondly, despite the fact that SalNAS is highly efficient (20.98 million parameters), it can suffer from the lack of generalization. To solve this, we propose a self-knowledge distillation approach, termed Self-KD, that trains the student SalNAS with the weighted average information between the ground truth and the prediction from the teacher model. The teacher model, while sharing the same architecture, contains the best-performing weights chosen by cross-validation. Self-KD can generalize well without the need to compute the gradient in the teacher model, enabling an efficient training system. By utilizing Self-KD, SalNAS outperforms other state-of-the-art saliency prediction models in most evaluation rubrics across seven benchmark datasets while being a lightweight model. The code will be available at https://github.com/chakkritte/SalNAS",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Published in Engineering Applications of Artificial Intelligence"
    },
    {
        "paper id": "2407.20072",
        "abstract url": "https://arxiv.org/abs/2407.20072",
        "title": "Generative Diffusion Model Bootstraps Zero-shot Classification of Fetal Ultrasound Images In Underrepresented African Populations",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Developing robust deep learning models for fetal ultrasound image analysis requires comprehensive, high-quality datasets to effectively learn informative data representations within the domain. However, the scarcity of labelled ultrasound images poses substantial challenges, especially in low-resource settings. To tackle this challenge, we leverage synthetic data to enhance the generalizability of deep learning models. This study proposes a diffusion-based method, Fetal Ultrasound LoRA (FU-LoRA), which involves fine-tuning latent diffusion models using the LoRA technique to generate synthetic fetal ultrasound images. These synthetic images are integrated into a hybrid dataset that combines real-world and synthetic images to improve the performance of zero-shot classifiers in low-resource settings. Our experimental results on fetal ultrasound images from African cohorts demonstrate that FU-LoRA outperforms the baseline method by a 13.73% increase in zero-shot classification accuracy. Furthermore, FU-LoRA achieves the highest accuracy of 82.40%, the highest F-score of 86.54%, and the highest AUC of 89.78%. It demonstrates that the FU-LoRA method is effective in the zero-shot classification of fetal ultrasound images in low-resource settings. Our code and data are publicly accessible on https://github.com/13204942/FU-LoRA.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Accepted at MICCAI 2024 workshop PIPPI"
    },
    {
        "paper id": "2407.20078",
        "abstract url": "https://arxiv.org/abs/2407.20078",
        "title": "Background Semantics Matter: Cross-Task Feature Exchange Network for Clustered Infrared Small Target Detection With Sky-Annotated Dataset",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Infrared small target detection poses unique challenges due to the scarcity of intrinsic target features and the abundance of similar background distractors. We argue that background semantics play a pivotal role in distinguishing visually similar objects for this task. To address this, we introduce a new task -- clustered infrared small target detection, and present DenseSIRST, a novel benchmark dataset that provides per-pixel semantic annotations for background regions, enabling the transition from sparse to dense target detection. Leveraging this dataset, we propose the Background-Aware Feature Exchange Network (BAFE-Net), which transforms the detection paradigm from a single task focused on the foreground to a multi-task architecture that jointly performs target detection and background semantic segmentation. BAFE-Net introduces a cross-task feature hard-exchange mechanism to embed target and background semantics between the two tasks. Furthermore, we propose the Background-Aware Gaussian Copy-Paste (BAG-CP) method, which selectively pastes small targets into sky regions during training, avoiding the creation of false alarm targets in complex non-sky backgrounds. Extensive experiments validate the effectiveness of BAG-CP and BAFE-Net in improving target detection accuracy while reducing false alarms. The DenseSIRST dataset, code, and trained models are available at https://github.com/GrokCV/BAFE-Net.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20090",
        "abstract url": "https://arxiv.org/abs/2407.20090",
        "title": "Infrared Small Target Detection based on Adjustable Sensitivity Strategy and Multi-Scale Fusion",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, deep learning-based single-frame infrared small target (SIRST) detection technology has made significant progress. However, existing infrared small target detection methods are often optimized for a fixed image resolution, a single wavelength, or a specific imaging system, limiting their breadth and flexibility in practical applications. Therefore, we propose a refined infrared small target detection scheme based on an adjustable sensitivity (AS) strategy and multi-scale fusion. Specifically, a multi-scale model fusion framework based on multi-scale direction-aware network (MSDA-Net) is constructed, which uses input images of multiple scales to train multiple models and fuses them. Multi-scale fusion helps characterize the shape, edge, and texture features of the target from different scales, making the model more accurate and reliable in locating the target. At the same time, we fully consider the characteristics of the infrared small target detection task and construct an edge enhancement difficulty mining (EEDM) loss. The EEDM loss helps alleviate the problem of category imbalance and guides the network to pay more attention to difficult target areas and edge features during training. In addition, we propose an adjustable sensitivity strategy for post-processing. This strategy significantly improves the detection rate of infrared small targets while ensuring segmentation accuracy. Extensive experimental results show that the proposed scheme achieves the best performance. Notably, this scheme won the first prize in the PRCV 2024 wide-area infrared small target detection competition.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20111",
        "abstract url": "https://arxiv.org/abs/2407.20111",
        "title": "Enhancing Anti-spoofing Countermeasures Robustness through Joint Optimization and Transfer Learning",
        "rating": "0",
        "keywords": [
            [
                "speech enhancement"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Current research in synthesized speech detection primarily focuses on the generalization of detection systems to unknown spoofing methods of noise-free speech. However, the performance of anti-spoofing countermeasures (CM) system is often don't work as well in more challenging scenarios, such as those involving noise and reverberation. To address the problem of enhancing the robustness of CM systems, we propose a transfer learning-based speech enhancement front-end joint optimization (TL-SEJ) method, investigating its effectiveness in improving robustness against noise and reverberation. We evaluated the proposed method's performance through a series of comparative and ablation experiments. The experimental results show that, across different signal-to-noise ratio test conditions, the proposed TL-SEJ method improves recognition accuracy by 2.7% to 15.8% compared to the baseline. Compared to conventional data augmentation methods, our system achieves an accuracy improvement ranging from 0.7% to 5.8% in various noisy conditions and from 1.7% to 2.8% under different RT60 reverberation scenarios. These experiments demonstrate that the proposed method effectively enhances system robustness in noisy and reverberant conditions.",
        "subjects": [
            "cs.SD",
            "eess.AS",
            "eess.SP"
        ],
        "comment": "29 pages, 4 figures, Journal Papers"
    },
    {
        "paper id": "2407.20179",
        "abstract url": "https://arxiv.org/abs/2407.20179",
        "title": "Theia: Distilling Diverse Vision Foundation Models for Robot Learning",
        "rating": "0",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Vision-based robot policy learning, which maps visual inputs to actions, necessitates a holistic understanding of diverse visual tasks beyond single-task needs like classification or segmentation. Inspired by this, we introduce Theia, a vision foundation model for robot learning that distills multiple off-the-shelf vision foundation models trained on varied vision tasks. Theia's rich visual representations encode diverse visual knowledge, enhancing downstream robot learning. Extensive experiments demonstrate that Theia outperforms its teacher models and prior robot learning models using less training data and smaller model sizes. Additionally, we quantify the quality of pre-trained visual representations and hypothesize that higher entropy in feature norm distributions leads to improved robot learning performance. Code and models are available at https://github.com/bdaiinstitute/theia.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20232",
        "abstract url": "https://arxiv.org/abs/2407.20232",
        "title": "Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Image Editing"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Text-based editing diffusion models exhibit limited performance when the user's input instruction is ambiguous. To solve this problem, we propose $\\textit{Specify ANd Edit}$ (SANE), a zero-shot inference pipeline for diffusion-based editing systems. We use a large language model (LLM) to decompose the input instruction into specific instructions, i.e. well-defined interventions to apply to the input image to satisfy the user's request. We benefit from the LLM-derived instructions along the original one, thanks to a novel denoising guidance strategy specifically designed for the task. Our experiments with three baselines and on two datasets demonstrate the benefits of SANE in all setups. Moreover, our pipeline improves the interpretability of editing models, and boosts the output diversity. We also demonstrate that our approach can be applied to any edit, whether ambiguous or not. Our code is public at https://github.com/fabvio/SANE.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20382",
        "abstract url": "https://arxiv.org/abs/2407.20382",
        "title": "What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Role-playing games (RPGs) provide players with a rich, interactive world to explore. Dialogue serves as the primary means of communication between developers and players, manifesting in various forms such as guides, NPC interactions, and storytelling. While most games rely on written scripts to define the main story and character personalities, player immersion can be significantly enhanced through casual interactions between characters. With the advent of large language models (LLMs), we introduce a dialogue filler framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic and contextually appropriate character interactions. We test this framework within the environments of Final Fantasy VII Remake and Pokemon, providing qualitative and quantitative evidence that demonstrates GPT-4's capability to act with defined personalities and generate dialogue. However, some flaws remain, such as GPT-4 being overly positive or more subtle personalities, such as maturity, tend to be of lower quality compared to more overt traits like timidity. This study aims to assist developers in crafting more nuanced filler dialogues, thereby enriching player immersion and enhancing the overall RPG experience.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "ACL Wordplay 2024"
    },
    {
        "paper id": "2407.20391",
        "abstract url": "https://arxiv.org/abs/2407.20391",
        "title": "Alignment Scores: Robust Metrics for Multiview Pose Accuracy Evaluation",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose three novel metrics for evaluating the accuracy of a set of estimated camera poses given the ground truth: Translation Alignment Score (TAS), Rotation Alignment Score (RAS), and Pose Alignment Score (PAS). The TAS evaluates the translation accuracy independently of the rotations, and the RAS evaluates the rotation accuracy independently of the translations. The PAS is the average of the two scores, evaluating the combined accuracy of both translations and rotations. The TAS is computed in four steps: (1) Find the upper quartile of the closest-pair-distances, $d$. (2) Align the estimated trajectory to the ground truth using a robust registration method. (3) Collect all distance errors and obtain the cumulative frequencies for multiple thresholds ranging from $0.01d$ to $d$ with a resolution $0.01d$. (4) Add up these cumulative frequencies and normalize them such that the theoretical maximum is 1. The TAS has practical advantages over the existing metrics in that (1) it is robust to outliers and collinear motion, and (2) there is no need to adjust parameters on different datasets. The RAS is computed in a similar manner to the TAS and is also shown to be more robust against outliers than the existing rotation metrics. We verify our claims through extensive simulations and provide in-depth discussion of the strengths and weaknesses of the proposed metrics.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20437",
        "abstract url": "https://arxiv.org/abs/2407.20437",
        "title": "BaseBoostDepth: Exploiting Larger Baselines For Self-supervised Monocular Depth Estimation",
        "rating": "0",
        "keywords": [
            [
                "point cloud",
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the domain of multi-baseline stereo, the conventional understanding is that, in general, increasing baseline separation substantially enhances the accuracy of depth estimation. However, prevailing self-supervised depth estimation architectures primarily use minimal frame separation and a constrained stereo baseline. Larger frame separations can be employed; however, we show this to result in diminished depth quality due to various factors, including significant changes in brightness, and increased areas of occlusion. In response to these challenges, our proposed method, BaseBoostDepth, incorporates a curriculum learning-inspired optimization strategy to effectively leverage larger frame separations. However, we show that our curriculum learning-inspired strategy alone does not suffice, as larger baselines still cause pose estimation drifts. Therefore, we introduce incremental pose estimation to enhance the accuracy of pose estimations, resulting in significant improvements across all depth metrics. Additionally, to improve the robustness of the model, we introduce error-induced reconstructions, which optimize reconstructions with added error to the pose estimations. Ultimately, our final depth network achieves state-of-the-art performance on KITTI and SYNS-patches datasets across image-based, edge-based, and point cloud-based metrics without increasing computational complexity at test time. The project website can be found at https://kieran514.github.io/BaseBoostDepth-Project.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20446",
        "abstract url": "https://arxiv.org/abs/2407.20446",
        "title": "MEVDT: Multi-Modal Event-Based Vehicle Detection and Tracking Dataset",
        "rating": "0",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this data article, we introduce the Multi-Modal Event-based Vehicle Detection and Tracking (MEVDT) dataset. This dataset provides a synchronized stream of event data and grayscale images of traffic scenes, captured using the Dynamic and Active-Pixel Vision Sensor (DAVIS) 240c hybrid event-based camera. MEVDT comprises 63 multi-modal sequences with approximately 13k images, 5M events, 10k object labels, and 85 unique object tracking trajectories. Additionally, MEVDT includes manually annotated ground truth labels $\\unicode{x2014}$ consisting of object classifications, pixel-precise bounding boxes, and unique object IDs $\\unicode{x2014}$ which are provided at a labeling frequency of 24 Hz. Designed to advance the research in the domain of event-based vision, MEVDT aims to address the critical need for high-quality, real-world annotated datasets that enable the development and evaluation of object detection and tracking algorithms in automotive environments.",
        "subjects": [
            "cs.CV",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20455",
        "abstract url": "https://arxiv.org/abs/2407.20455",
        "title": "Learning Feature-Preserving Portrait Editing from Generated Pairs",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Portrait editing is challenging for existing techniques due to difficulties in preserving subject features like identity. In this paper, we propose a training-based method leveraging auto-generated paired data to learn desired editing while ensuring the preservation of unchanged subject features. Specifically, we design a data generation process to create reasonably good training pairs for desired editing at low cost. Based on these pairs, we introduce a Multi-Conditioned Diffusion Model to effectively learn the editing direction and preserve subject features. During inference, our model produces accurate editing mask that can guide the inference process to further preserve detailed subject features. Experiments on costume editing and cartoon expression editing show that our method achieves state-of-the-art quality, quantitatively and qualitatively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20513",
        "abstract url": "https://arxiv.org/abs/2407.20513",
        "title": "Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a conversational pipeline for crafting domain knowledge for complex neuro-symbolic models through natural language prompts. It leverages large language models to generate declarative programs in the DomiKnowS framework. The programs in this framework express concepts and their relationships as a graph in addition to logical constraints between them. The graph, later, can be connected to trainable neural models according to those specifications. Our proposed pipeline utilizes techniques like dynamic in-context demonstration retrieval, model refinement based on feedback from a symbolic parser, visualization, and user interaction to generate the tasks' structure and formal knowledge representation. This approach empowers domain experts, even those not well-versed in ML/AI, to formally declare their knowledge to be incorporated in customized neural models in the DomiKnowS framework.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "Accepted in NeSy 2024 Conference"
    },
    {
        "paper id": "2407.20516",
        "abstract url": "https://arxiv.org/abs/2407.20516",
        "title": "Machine Unlearning in Generative AI: A Survey",
        "rating": "0",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Generative AI technologies have been deployed in many places, such as (multimodal) large language models and vision generative models. Their remarkable performance should be attributed to massive training data and emergent reasoning abilities. However, the models would memorize and generate sensitive, biased, or dangerous information originated from the training data especially those from web crawl. New machine unlearning (MU) techniques are being developed to reduce or eliminate undesirable knowledge and its effects from the models, because those that were designed for traditional classification tasks could not be applied for Generative AI. We offer a comprehensive survey on many things about MU in Generative AI, such as a new problem formulation, evaluation methods, and a structured discussion on the advantages and limitations of different kinds of MU techniques. It also presents several critical challenges and promising directions in MU research. A curated list of readings can be found: https://github.com/franciscoliu/GenAI-MU-Reading.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.21073",
        "abstract url": "https://arxiv.org/abs/2407.21073",
        "title": "Enhancing Adversarial Text Attacks on BERT Models with Projected Gradient Descent",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Adversarial attacks against deep learning models represent a major threat to the security and reliability of natural language processing (NLP) systems. In this paper, we propose a modification to the BERT-Attack framework, integrating Projected Gradient Descent (PGD) to enhance its effectiveness and robustness. The original BERT-Attack, designed for generating adversarial examples against BERT-based models, suffers from limitations such as a fixed perturbation budget and a lack of consideration for semantic similarity. The proposed approach in this work, PGD-BERT-Attack, addresses these limitations by leveraging PGD to iteratively generate adversarial examples while ensuring both imperceptibility and semantic similarity to the original input. Extensive experiments are conducted to evaluate the performance of PGD-BERT-Attack compared to the original BERT-Attack and other baseline methods. The results demonstrate that PGD-BERT-Attack achieves higher success rates in causing misclassification while maintaining low perceptual changes. Furthermore, PGD-BERT-Attack produces adversarial instances that exhibit greater semantic resemblance to the initial input, enhancing their applicability in real-world scenarios. Overall, the proposed modification offers a more effective and robust approach to adversarial attacks on BERT-based models, thus contributing to the advancement of defense against attacks on NLP systems.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CR"
        ],
        "comment": "This paper is the pre-reviewed version of our paper that has been accepted for oral presentation and publication in the 4th IEEE ASIANCON. The conference will be organized in Pune, INDIA from August 23 to 25, 2024. The paper consists of 8 pages and it contains 10 tables. It is NOT the final camera-ready version that will be in IEEE Xplore"
    },
    {
        "paper id": "2407.19736",
        "abstract url": "https://arxiv.org/abs/2407.19736",
        "title": "Sensor Selection via GFlowNets: A Deep Generative Modeling Framework to Navigate Combinatorial Complexity",
        "rating": "-0.5",
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The performance of sensor arrays in sensing and wireless communications improves with more elements, but this comes at the cost of increased energy consumption and hardware expense. This work addresses the challenge of selecting $k$ sensor elements from a set of $m$ to optimize a generic Quality-of-Service metric. Evaluating all $\\binom{m}{k}$ possible sensor subsets is impractical, leading to prior solutions using convex relaxations, greedy algorithms, and supervised learning approaches. The current paper proposes a new framework that employs deep generative modeling, treating sensor selection as a deterministic Markov Decision Process where sensor subsets of size $k$ arise as terminal states. Generative Flow Networks (GFlowNets) are employed to model an action distribution conditioned on the state. Sampling actions from the aforementioned distribution ensures that the probability of arriving at a terminal state is proportional to the performance of the corresponding subset. Applied to a standard sensor selection scenario, the developed approach outperforms popular methods which are based on convex optimization and greedy algorithms. Finally, a multiobjective formulation of the proposed approach is adopted and applied on the sparse antenna array design for Integrated Sensing and Communication (ISAC) systems. The multiobjective variation is shown to perform well in managing the trade-off between radar and communication performance.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19828",
        "abstract url": "https://arxiv.org/abs/2407.19828",
        "title": "Federated Learning based Latent Factorization of Tensors for Privacy-Preserving QoS Prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In applications related to big data and service computing, dynamic connections tend to be encountered, especially the dynamic data of user-perspective quality of service (QoS) in Web services. They are transformed into high-dimensional and incomplete (HDI) tensors which include abundant temporal pattern information. Latent factorization of tensors (LFT) is an extremely efficient and typical approach for extracting such patterns from an HDI tensor. However, current LFT models require the QoS data to be maintained in a central place (e.g., a central server), which is impossible for increasingly privacy-sensitive users. To address this problem, this article creatively designs a federated learning based on latent factorization of tensors (FL-LFT). It builds a data-density -oriented federated learning model to enable isolated users to collaboratively train a global LFT model while protecting user's privacy. Extensive experiments on a QoS dataset collected from the real world verify that FL-LFT shows a remarkable increase in prediction accuracy when compared to state-of-the-art federated learning (FL) approaches.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19838",
        "abstract url": "https://arxiv.org/abs/2407.19838",
        "title": "RNACG: A Universal RNA Sequence Conditional Generation model based on Flow-Matching",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "RNA plays a crucial role in diverse life processes. In contrast to the rapid advancement of protein design methods, the work related to RNA is more demanding. Most current RNA design approaches concentrate on specified target attributes and rely on extensive experimental searches. However, these methods remain costly and inefficient due to practical limitations. In this paper, we characterize all sequence design issues as conditional generation tasks and offer parameterized representations for multiple problems. For these problems, we have developed a universal RNA sequence generation model based on flow matching, namely RNACG. RNACG can accommodate various conditional inputs and is portable, enabling users to customize the encoding network for conditional inputs as per their requirements and integrate it into the generation network. We evaluated RNACG in RNA 3D structure inverse folding, 2D structure inverse folding, family-specific sequence generation, and 5'UTR translation efficiency prediction. RNACG attains superior or competitive performance on these tasks compared with other methods. RNACG exhibits extensive applicability in sequence generation and property prediction tasks, providing a novel approach to RNA sequence design and potential methods for simulation experiments with large-scale RNA sequence data.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19860",
        "abstract url": "https://arxiv.org/abs/2407.19860",
        "title": "Anomalous State Sequence Modeling to Enhance Safety in Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The deployment of artificial intelligence (AI) in decision-making applications requires ensuring an appropriate level of safety and reliability, particularly in changing environments that contain a large number of unknown observations. To address this challenge, we propose a novel safe reinforcement learning (RL) approach that utilizes an anomalous state sequence to enhance RL safety. Our proposed solution Safe Reinforcement Learning with Anomalous State Sequences (AnoSeqs) consists of two stages. First, we train an agent in a non-safety-critical offline 'source' environment to collect safe state sequences. Next, we use these safe sequences to build an anomaly detection model that can detect potentially unsafe state sequences in a 'target' safety-critical environment where failures can have high costs. The estimated risk from the anomaly detection model is utilized to train a risk-averse RL policy in the target environment; this involves adjusting the reward function to penalize the agent for visiting anomalous states deemed unsafe by our anomaly model. In experiments on multiple safety-critical benchmarking environments including self-driving cars, our solution approach successfully learns safer policies and proves that sequential anomaly detection can provide an effective supervisory signal for training safety-aware RL agents",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19941",
        "abstract url": "https://arxiv.org/abs/2407.19941",
        "title": "Boosting Graph Foundation Model from Structural Perspective",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph foundation models have recently attracted significant attention due to its strong generalizability. Although existing methods resort to language models to learn unified semantic representations across domains, they disregard the unique structural characteristics of graphs from different domains. To address the problem, in this paper, we boost graph foundation model from structural perspective and propose BooG. The model constructs virtual super nodes to unify structural characteristics of graph data from different domains. Specifically, the super nodes fuse the information of anchor nodes and class labels, where each anchor node captures the information of a node or a graph instance to be classified. Instead of using the raw graph structure, we connect super nodes to all nodes within their neighborhood by virtual edges. This new structure allows for effective information aggregation while unifying cross-domain structural characteristics. Additionally, we propose a novel pre-training objective based on contrastive learning, which learns more expressive representations for graph data and generalizes effectively to different domains and downstream tasks. Experimental results on various datasets and tasks demonstrate the superior performance of BooG. We provide our code and data here: https://anonymous.4open.science/r/BooG-EE42/.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19944",
        "abstract url": "https://arxiv.org/abs/2407.19944",
        "title": "Noise-Resilient Unsupervised Graph Representation Learning via Multi-Hop Feature Quality Estimation",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Unsupervised graph representation learning (UGRL) based on graph neural networks (GNNs), has received increasing attention owing to its efficacy in handling graph-structured data. However, existing UGRL methods ideally assume that the node features are noise-free, which makes them fail to distinguish between useful information and noise when applied to real data with noisy features, thus affecting the quality of learned representations. This urges us to take node noisy features into account in real-world UGRL. With empirical analysis, we reveal that feature propagation, the essential operation in GNNs, acts as a \"double-edged sword\" in handling noisy features - it can both denoise and diffuse noise, leading to varying feature quality across nodes, even within the same node at different hops. Building on this insight, we propose a novel UGRL method based on Multi-hop feature Quality Estimation (MQE for short). Unlike most UGRL models that directly utilize propagation-based GNNs to generate representations, our approach aims to learn representations through estimating the quality of propagated features at different hops. Specifically, we introduce a Gaussian model that utilizes a learnable \"meta-representation\" as a condition to estimate the expectation and variance of multi-hop propagated features via neural networks. In this way, the \"meta representation\" captures the semantic and structural information underlying multiple propagated features but is naturally less susceptible to interference by noise, thereby serving as high-quality node representations beneficial for downstream tasks. Extensive experiments on multiple real-world datasets demonstrate that MQE in learning reliable node representations in scenarios with diverse types of feature noise.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted by CIKM 2024. 11 pages, 8 figures"
    },
    {
        "paper id": "2407.19951",
        "abstract url": "https://arxiv.org/abs/2407.19951",
        "title": "Can I trust my anomaly detection system? A case study based on explainable AI",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Generative models based on variational autoencoders are a popular technique for detecting anomalies in images in a semi-supervised context. A common approach employs the anomaly score to detect the presence of anomalies, and it is known to reach high level of accuracy on benchmark datasets. However, since anomaly scores are computed from reconstruction disparities, they often obscure the detection of various spurious features, raising concerns regarding their actual efficacy. This case study explores the robustness of an anomaly detection system based on variational autoencoder generative models through the use of eXplainable AI methods. The goal is to get a different perspective on the real performances of anomaly detectors that use reconstruction differences. In our case study we discovered that, in many cases, samples are detected as anomalous for the wrong or misleading factors.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "World Conference on eXplainable Artificial Intelligence"
    },
    {
        "paper id": "2407.19984",
        "abstract url": "https://arxiv.org/abs/2407.19984",
        "title": "Confidence Estimation for Automatic Detection of Depression and Alzheimer's Disease Based on Clinical Interviews",
        "rating": "-0.5",
        "keywords": [
            [
                "Disease",
                "Clinical"
            ],
            [
                "cs.CL"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Speech-based automatic detection of Alzheimer's disease (AD) and depression has attracted increased attention. Confidence estimation is crucial for a trust-worthy automatic diagnostic system which informs the clinician about the confidence of model predictions and helps reduce the risk of misdiagnosis. This paper investigates confidence estimation for automatic detection of AD and depression based on clinical interviews. A novel Bayesian approach is proposed which uses a dynamic Dirichlet prior distribution to model the second-order probability of the predictive distribution. Experimental results on the publicly available ADReSS and DAIC-WOZ datasets demonstrate that the proposed method outperforms a range of baselines for both classification accuracy and confidence estimation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by Interspeech 2024"
    },
    {
        "paper id": "2407.19994",
        "abstract url": "https://arxiv.org/abs/2407.19994",
        "title": "A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This study aims to improve knowledge-based question-answering (QA) systems by overcoming the limitations of existing Retrieval-Augmented Generation (RAG) models and implementing an advanced RAG system based on Graph technology to develop high-quality generative AI services. While existing RAG models demonstrate high accuracy and fluency by utilizing retrieved information, they may suffer from accuracy degradation as they generate responses using pre-loaded knowledge without reprocessing. Additionally, they cannot incorporate real-time data after the RAG configuration stage, leading to issues with contextual understanding and biased information. To address these limitations, this study implemented an enhanced RAG system utilizing Graph technology. This system is designed to efficiently search and utilize information. Specifically, it employs LangGraph to evaluate the reliability of retrieved information and synthesizes diverse data to generate more accurate and enhanced responses. Furthermore, the study provides a detailed explanation of the system's operation, key implementation steps, and examples through implementation code and validation results, thereby enhancing the understanding of advanced RAG technology. This approach offers practical guidelines for implementing advanced RAG systems in corporate services, making it a valuable resource for practical application.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20028",
        "abstract url": "https://arxiv.org/abs/2407.20028",
        "title": "Aircraft Trajectory Segmentation-based Contrastive Coding: A Framework for Self-supervised Trajectory Representation",
        "rating": "-0.5",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Air traffic trajectory recognition has gained significant interest within the air traffic management community, particularly for fundamental tasks such as classification and clustering. This paper introduces Aircraft Trajectory Segmentation-based Contrastive Coding (ATSCC), a novel self-supervised time series representation learning framework designed to capture semantic information in air traffic trajectory data. The framework leverages the segmentable characteristic of trajectories and ensures consistency within the self-assigned segments. Intensive experiments were conducted on datasets from three different airports, totaling four datasets, comparing the learned representation's performance of downstream classification and clustering with other state-of-the-art representation learning techniques. The results show that ATSCC outperforms these methods by aligning with the labels defined by aeronautical procedures. ATSCC is adaptable to various airport configurations and scalable to incomplete trajectories. This research has expanded upon existing capabilities, achieving these improvements independently without predefined inputs such as airport configurations, maneuvering procedures, or labeled data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, 7 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2407.20100",
        "abstract url": "https://arxiv.org/abs/2407.20100",
        "title": "F-KANs: Federated Kolmogorov-Arnold Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present an innovative federated learning (FL) approach that utilizes Kolmogorov-Arnold Networks (KANs) for classification tasks. By utilizing the adaptive activation capabilities of KANs in a federated framework, we aim to improve classification capabilities while preserving privacy. The study evaluates the performance of federated KANs (F- KANs) compared to traditional Multi-Layer Perceptrons (MLPs) on classification task. The results show that the F-KANs model significantly outperforms the federated MLP model in terms of accuracy, precision, recall, F1 score and stability, and achieves better performance, paving the way for more efficient and privacy-preserving predictive analytics.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.NI"
        ],
        "comment": "This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Related Code: https://github.com/ezeydan/F-KANs.git"
    },
    {
        "paper id": "2407.20109",
        "abstract url": "https://arxiv.org/abs/2407.20109",
        "title": "Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "One important property of DIstribution Correction Estimation (DICE) methods is that the solution is the optimal stationary distribution ratio between the optimized and data collection policy. In this work, we show that DICE-based methods can be viewed as a transformation from the behavior distribution to the optimal policy distribution. Based on this, we propose a novel approach, Diffusion-DICE, that directly performs this transformation using diffusion models. We find that the optimal policy's score function can be decomposed into two terms: the behavior policy's score function and the gradient of a guidance term which depends on the optimal distribution ratio. The first term can be obtained from a diffusion model trained on the dataset and we propose an in-sample learning objective to learn the second term. Due to the multi-modality contained in the optimal policy distribution, the transformation in Diffusion-DICE may guide towards those local-optimal modes. We thus generate a few candidate actions and carefully select from them to approach global-optimum. Different from all other diffusion-based offline RL methods, the guide-then-select paradigm in Diffusion-DICE only uses in-sample actions for training and brings minimal error exploitation in the value function. We use a didatic toycase example to show how previous diffusion-based methods fail to generate optimal actions due to leveraging these errors and how Diffusion-DICE successfully avoids that. We then conduct extensive experiments on benchmark datasets to show the strong performance of Diffusion-DICE.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Preprint, under review"
    },
    {
        "paper id": "2407.20119",
        "abstract url": "https://arxiv.org/abs/2407.20119",
        "title": "Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a novel self-supervised deep clustering approach tailored for unstructured data without requiring prior knowledge of the number of clusters, termed Adaptive Self-supervised Robust Clustering (ASRC). In particular, ASRC adaptively learns the graph structure and edge weights to capture both local and global structural information. The obtained graph enables us to learn clustering-friendly feature representations by an enhanced graph auto-encoder with contrastive learning technique. It further leverages the clustering results adaptively obtained by robust continuous clustering (RCC) to generate prototypes for negative sampling, which can further contribute to promoting consistency among positive pairs and enlarging the gap between positive and negative samples. ASRC obtains the final clustering results by applying RCC to the learned feature representations with their consistent graph structure and edge weights. Extensive experiments conducted on seven benchmark datasets demonstrate the efficacy of ASRC, demonstrating its superior performance over other popular clustering models. Notably, ASRC even outperforms methods that rely on prior knowledge of the number of clusters, highlighting its effectiveness in addressing the challenges of clustering unstructured data.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20164",
        "abstract url": "https://arxiv.org/abs/2407.20164",
        "title": "Language-Conditioned Offline RL for Multi-Robot Navigation",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot",
                "Navigation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We present a method for developing navigation policies for multi-robot teams that interpret and follow natural language instructions. We condition these policies on embeddings from pretrained Large Language Models (LLMs), and train them via offline reinforcement learning with as little as 20 minutes of randomly-collected data. Experiments on a team of five real robots show that these policies generalize well to unseen commands, indicating an understanding of the LLM latent space. Our method requires no simulators or environment models, and produces low-latency control policies that can be deployed directly to real robots without finetuning. We provide videos of our experiments at https://sites.google.com/view/llm-marl.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20311",
        "abstract url": "https://arxiv.org/abs/2407.20311",
        "title": "Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process",
        "rating": "-0.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Recent advances in language models have demonstrated their capability to solve mathematical reasoning problems, achieving near-perfect accuracy on grade-school level math benchmarks like GSM8K. In this paper, we formally study how language models solve these problems. We design a series of controlled experiments to address several fundamental questions: (1) Can language models truly develop reasoning skills, or do they simply memorize templates? (2) What is the model's hidden (mental) reasoning process? (3) Do models solve math questions using skills similar to or different from humans? (4) Do models trained on GSM8K-like datasets develop reasoning skills beyond those necessary for solving GSM8K problems? (5) What mental process causes models to make reasoning mistakes? (6) How large or deep must a model be to effectively solve GSM8K-level math questions? Our study uncovers many hidden mechanisms by which language models solve mathematical questions, providing insights that extend beyond current understandings of LLMs.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "video appeared in ICML 2024 tutorial"
    },
    {
        "paper id": "2407.20337",
        "abstract url": "https://arxiv.org/abs/2407.20337",
        "title": "Contrasting Deepfakes Diffusion via Contrastive Learning and Global-Local Similarities",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "deepfake"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Discerning between authentic content and that generated by advanced AI methods has become increasingly challenging. While previous research primarily addresses the detection of fake faces, the identification of generated natural images has only recently surfaced. This prompted the recent exploration of solutions that employ foundation vision-and-language models, like CLIP. However, the CLIP embedding space is optimized for global image-to-text alignment and is not inherently designed for deepfake detection, neglecting the potential benefits of tailored training and local image features. In this study, we propose CoDE (Contrastive Deepfake Embeddings), a novel embedding space specifically designed for deepfake detection. CoDE is trained via contrastive learning by additionally enforcing global-local similarities. To sustain the training of our model, we generate a comprehensive dataset that focuses on images generated by diffusion models and encompasses a collection of 9.2 million images produced by using four different generators. Experimental results demonstrate that CoDE achieves state-of-the-art accuracy on the newly collected dataset, while also showing excellent generalization capabilities to unseen image generators. Our source code, trained models, and collected dataset are publicly available at: https://github.com/aimagelab/CoDE.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2407.20351",
        "abstract url": "https://arxiv.org/abs/2407.20351",
        "title": "LiteEFG: An Efficient Python Library for Solving Extensive-form Games",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "LiteEFG is an efficient library with easy-to-use Python bindings, which can solve multiplayer extensive-form games (EFGs). LiteEFG enables the user to express computation graphs in Python to define updates on the game tree structure. The graph is then executed by the C++ backend, leading to significant speedups compared to running the algorithm in Python. Moreover, in LiteEFG, the user needs to only specify the computation graph of the update rule in a decision node of the game, and LiteEFG will automatically distribute the update rule to each decision node and handle the structure of the imperfect-information game.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20499",
        "abstract url": "https://arxiv.org/abs/2407.20499",
        "title": "Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Link prediction, as a fundamental task for graph neural networks (GNNs), has boasted significant progress in varied domains. Its success is typically influenced by the expressive power of node representation, but recent developments reveal the inferior performance of low-degree nodes owing to their sparse neighbor connections, known as the degree-based long-tailed problem. Will the degree-based long-tailed distribution similarly constrain the efficacy of GNNs on link prediction? Unexpectedly, our study reveals that only a mild correlation exists between node degree and predictive accuracy, and more importantly, the number of common neighbors between node pairs exhibits a strong correlation with accuracy. Considering node pairs with less common neighbors, i.e., tail node pairs, make up a substantial fraction of the dataset but achieve worse performance, we propose that link prediction also faces the long-tailed problem. Therefore, link prediction of GNNs is greatly hindered by the tail node pairs. After knowing the weakness of link prediction, a natural question is how can we eliminate the negative effects of the skewed long-tailed distribution on common neighbors so as to improve the performance of link prediction? Towards this end, we introduce our long-tailed framework (LTLP), which is designed to enhance the performance of tail node pairs on link prediction by increasing common neighbors. Two key modules in LTLP respectively supplement high-quality edges for tail node pairs and enforce representational alignment between head and tail node pairs within the same category, thereby improving the performance of tail node pairs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20542",
        "abstract url": "https://arxiv.org/abs/2407.20542",
        "title": "HandDAGT: A Denoising Adaptive Graph Transformer for 3D Hand Pose Estimation",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "The extraction of keypoint positions from input hand frames, known as 3D hand pose estimation, is crucial for various human-computer interaction applications. However, current approaches often struggle with the dynamic nature of self-occlusion of hands and intra-occlusion with interacting objects. To address this challenge, this paper proposes the Denoising Adaptive Graph Transformer, HandDAGT, for hand pose estimation. The proposed HandDAGT leverages a transformer structure to thoroughly explore effective geometric features from input patches. Additionally, it incorporates a novel attention mechanism to adaptively weigh the contribution of kinematic correspondence and local geometric features for the estimation of specific keypoints. This attribute enables the model to adaptively employ kinematic and local information based on the occlusion situation, enhancing its robustness and accuracy. Furthermore, we introduce a novel denoising training strategy aimed at improving the model's robust performance in the face of occlusion challenges. Experimental results show that the proposed model significantly outperforms the existing methods on four challenging hand pose benchmark datasets. Codes and pre-trained models are publicly available at https://github.com/cwc1260/HandDAGT.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "comment": "Accepted as a conference paper to European Conference on Computer Vision (ECCV) 2024"
    },
    {
        "paper id": "2407.19705",
        "abstract url": "https://arxiv.org/abs/2407.19705",
        "title": "CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "Healthcare"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid progress in Large Language Models (LLMs) has prompted the creation of numerous benchmarks to evaluate their capabilities.This study focuses on the Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset diversity and distribution in supervised fine-tuning (SFT) may enhance LLM performance.Remarkably, We successfully trained a smaller base model to achieve scores comparable to larger models, indicating that a diverse and well-distributed dataset can optimize performance regardless of model size.This study suggests that even smaller models may reach high performance levels with carefully curated and varied datasets. By integrating a wide range of instructional content, our approach addresses potential issues such as data quality inconsistencies. Our results imply that a broader spectrum of training data may enhance a model's ability to generalize and perform effectively across different medical scenarios, highlighting the importance of dataset quality and diversity in fine-tuning processes. We open-source the model for future research at https://github.com/CAS-SIAT-XinHai/CollectiveSFT",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Technical Report"
    },
    {
        "paper id": "2407.19760",
        "abstract url": "https://arxiv.org/abs/2407.19760",
        "title": "Legal Minds, Algorithmic Decisions: How LLMs Apply Constitutional Principles in Complex Scenarios",
        "rating": "-1",
        "keywords": [
            [
                "bioethics"
            ],
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we conduct an empirical analysis of how large language models (LLMs), specifically GPT-4, interpret constitutional principles in complex decision-making scenarios. We examine rulings from the Italian Constitutional Court on bioethics issues that involve trade-offs between competing values and compare model-generated legal arguments on these issues to those presented by the State, the Court, and the applicants. Our results indicate that GPT-4 consistently aligns more closely with progressive interpretations of the Constitution, often overlooking competing values and mirroring the applicants' views rather than the more conservative perspectives of the State or the Court's moderate positions. Our experiments reveal a distinct tendency of GPT-4 to favor progressive legal interpretations, underscoring the influence of underlying data biases. We thus underscore the importance of testing alignment in real-world scenarios and considering the implications of deploying LLMs in decision-making processes.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": "Accepted at AIES24"
    },
    {
        "paper id": "2407.19773",
        "abstract url": "https://arxiv.org/abs/2407.19773",
        "title": "Unmasking unlearnable models: a classification challenge for biomedical images without visible cues",
        "rating": "-1",
        "keywords": [
            [
                "biomedical",
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Predicting traits from images lacking visual cues is challenging, as algorithms are designed to capture visually correlated ground truth. This problem is critical in biomedical sciences, and their solution can improve the efficacy of non-invasive methods. For example, a recent challenge of predicting MGMT methylation status from MRI images is critical for treatment decisions of glioma patients. Using less robust models poses a significant risk in these critical scenarios and underscores the urgency of addressing this issue. Despite numerous efforts, contemporary models exhibit suboptimal performance, and underlying reasons for this limitation remain elusive. In this study, we demystify the complexity of MGMT status prediction through a comprehensive exploration by performing benchmarks of existing models adjoining transfer learning. Their architectures were further dissected by observing gradient flow across layers. Additionally, a feature selection strategy was applied to improve model interpretability. Our finding highlighted that current models are unlearnable and may require new architectures to explore applications in the real world. We believe our study will draw immediate attention and catalyse advancements in predictive modelling with non-visible cues.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19793",
        "abstract url": "https://arxiv.org/abs/2407.19793",
        "title": "NP-Completeness of Neighborhood Balanced Colorings",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A Neighborhood Balanced Coloring (NBC) of a graph is a red-blue coloring where each vertex has the same number of red and blue neighbors. This work proves that determining if a graph admits an NBC is NP-complete. We present a genetic algorithm to solve this problem, which we implemented and compared against exact and randomized algorithms.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19809",
        "abstract url": "https://arxiv.org/abs/2407.19809",
        "title": "Twins-PainViT: Towards a Modality-Agnostic Vision Transformer Framework for Multimodal Automatic Pain Assessment using Facial Videos and fNIRS",
        "rating": "-1",
        "keywords": [
            [
                "healthcare",
                "Facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Automatic pain assessment plays a critical role for advancing healthcare and optimizing pain management strategies. This study has been submitted to the First Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN). The proposed multimodal framework utilizes facial videos and fNIRS and presents a modality-agnostic approach, alleviating the need for domain-specific models. Employing a dual ViT configuration and adopting waveform representations for the fNIRS, as well as for the extracted embeddings from the two modalities, demonstrate the efficacy of the proposed method, achieving an accuracy of 46.76% in the multilevel pain assessment task.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19816",
        "abstract url": "https://arxiv.org/abs/2407.19816",
        "title": "Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies",
        "rating": "-1",
        "keywords": [
            [
                "Named Entity Recognition"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The labor market is undergoing rapid changes, with increasing demands on job seekers and a surge in job openings. Identifying essential skills and competencies from job descriptions is challenging due to varying employer requirements and the omission of key skills. This study addresses these challenges by comparing traditional Named Entity Recognition (NER) methods based on encoders with Large Language Models (LLMs) for extracting skills from Russian job vacancies. Using a labeled dataset of 4,000 job vacancies for training and 1,472 for testing, the performance of both approaches is evaluated. Results indicate that traditional NER models, especially DeepPavlov RuBERT NER tuned, outperform LLMs across various metrics including accuracy, precision, recall, and inference time. The findings suggest that traditional NER models provide more effective and efficient solutions for skill extraction, enhancing job requirement clarity and aiding job seekers in aligning their qualifications with employer expectations. This research contributes to the field of natural language processing (NLP) and its application in the labor market, particularly in non-English contexts.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19821",
        "abstract url": "https://arxiv.org/abs/2407.19821",
        "title": "Distilling High Diagnostic Value Patches for Whole Slide Image Classification Using Attention Mechanism",
        "rating": "-1",
        "keywords": [
            [
                "Whole Slide",
                "cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Multiple Instance Learning (MIL) has garnered widespread attention in the field of Whole Slide Image (WSI) classification as it replaces pixel-level manual annotation with diagnostic reports as labels, significantly reducing labor costs. Recent research has shown that bag-level MIL methods often yield better results because they can consider all patches of the WSI as a whole. However, a drawback of such methods is the incorporation of more redundant patches, leading to interference. To extract patches with high diagnostic value while excluding interfering patches to address this issue, we developed an attention-based feature distillation multi-instance learning (AFD-MIL) approach. This approach proposed the exclusion of redundant patches as a preprocessing operation in weakly supervised learning, directly mitigating interference from extensive noise. It also pioneers the use of attention mechanisms to distill features with high diagnostic value, as opposed to the traditional practice of indiscriminately and forcibly integrating all patches. Additionally, we introduced global loss optimization to finely control the feature distillation module. AFD-MIL is orthogonal to many existing MIL methods, leading to consistent performance improvements. This approach has surpassed the current state-of-the-art method, achieving 91.47% ACC (accuracy) and 94.29% AUC (area under the curve) on the Camelyon16 (Camelyon Challenge 2016, breast cancer), while 93.33% ACC and 98.17% AUC on the TCGA-NSCLC (The Cancer Genome Atlas Program: non-small cell lung cancer). Different feature distillation methods were used for the two datasets, tailored to the specific diseases, thereby improving performance and interpretability.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "q-bio.TO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19823",
        "abstract url": "https://arxiv.org/abs/2407.19823",
        "title": "Analyzing and reducing the synthetic-to-real transfer gap in Music Information Retrieval: the task of automatic drum transcription",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Automatic drum transcription is a critical tool in Music Information Retrieval for extracting and analyzing the rhythm of a music track, but it is limited by the size of the datasets available for training. A popular method used to increase the amount of data is by generating them synthetically from music scores rendered with virtual instruments. This method can produce a virtually infinite quantity of tracks, but empirical evidence shows that models trained on previously created synthetic datasets do not transfer well to real tracks. In this work, besides increasing the amount of data, we identify and evaluate three more strategies that practitioners can use to improve the realism of the generated data and, thus, narrow the synthetic-to-real transfer gap. To explore their efficacy, we used them to build a new synthetic dataset and then we measured how the performance of a model scales and, specifically, at what value it will stagnate when increasing the number of training tracks for different datasets. By doing this, we were able to prove that the aforementioned strategies contribute to make our dataset the one with the most realistic data distribution and the lowest synthetic-to-real transfer gap among the synthetic datasets we evaluated. We conclude by highlighting the limits of training with infinite data in drum transcription and we show how they can be overcome.",
        "subjects": [
            "cs.SD",
            "cs.IR",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "21 pages, 4 figures"
    },
    {
        "paper id": "2407.19840",
        "abstract url": "https://arxiv.org/abs/2407.19840",
        "title": "A simple linear time algorithm for smallest enclosing circles on the (hemi)sphere",
        "rating": "-1",
        "keywords": [
            [
                "point cloud"
            ]
        ],
        "abstract": "Based on Welzl's algorithm for smallest circles and spheres we develop a simple linear time algorithm for finding the smallest circle enclosing a point cloud on a sphere. The algorithm yields correct results as long as the point cloud is contained in a hemisphere, but the hemisphere does not have to be known in advance and the algorithm automatically detects whether the hemisphere assumption is met. For the full-sphere case, that is, if the point cloud is not contained in a hemisphere, we provide hints on how to adapt existing linearithmic time algorithms for spherical Voronoi diagrams to find the smallest enclosing circle.",
        "subjects": [
            "cs.CG",
            "math.MG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19849",
        "abstract url": "https://arxiv.org/abs/2407.19849",
        "title": "Normality Addition via Normality Detection in Industrial Image Anomaly Detection Models",
        "rating": "-1",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The task of image anomaly detection (IAD) aims to identify deviations from normality in image data. These anomalies are patterns that deviate significantly from what the IAD model has learned from the data during training. However, in real-world scenarios, the criteria for what constitutes normality often change, necessitating the reclassification of previously anomalous instances as normal. To address this challenge, we propose a new scenario termed \"normality addition,\" involving the post-training adjustment of decision boundaries to incorporate new normalities. To address this challenge, we propose a method called Normality Addition via Normality Detection (NAND), leveraging a vision-language model. NAND performs normality detection which detect patterns related to the intended normality within images based on textual descriptions. We then modify the results of a pre-trained IAD model to implement this normality addition. Using the benchmark dataset in IAD, MVTec AD, we establish an evaluation protocol for the normality addition task and empirically demonstrate the effectiveness of the NAND method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19888",
        "abstract url": "https://arxiv.org/abs/2407.19888",
        "title": "Yucca: A Deep Learning Framework For Medical Image Analysis",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Medical image analysis using deep learning frameworks has advanced healthcare by automating complex tasks, but many existing frameworks lack flexibility, modularity, and user-friendliness. To address these challenges, we introduce Yucca, an open-source AI framework available at https://github.com/Sllambias/yucca, designed specifically for medical imaging applications and built on PyTorch and PyTorch Lightning. Yucca features a three-tiered architecture: Functional, Modules, and Pipeline, providing a comprehensive and customizable solution. Evaluated across diverse tasks such as cerebral microbleeds detection, white matter hyperintensity segmentation, and hippocampus segmentation, Yucca achieves state-of-the-art results, demonstrating its robustness and versatility. Yucca offers a powerful, flexible, and user-friendly platform for medical image analysis, inviting community contributions to advance its capabilities and impact.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19894",
        "abstract url": "https://arxiv.org/abs/2407.19894",
        "title": "End-to-end SYNTAX score prediction: benchmark and methods",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "X-ray",
                "disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The SYNTAX score has become a widely used measure of coronary disease severity , crucial in selecting the optimal mode of revascularization. This paper introduces a new medical regression and classification problem - automatically estimating SYNTAX score from coronary angiography. Our study presents a comprehensive dataset of 1,844 patients, featuring a balanced distribution of individuals with zero and non-zero scores. This dataset includes a first-of-its-kind, complete coronary angiography samples captured through a multi-view X-ray video, allowing one to observe coronary arteries from multiple perspectives. Furthermore, we present a novel, fully automatic end-to-end method for estimating the SYNTAX. For such a difficult task, we have achieved a solid coefficient of determination R2 of 0.51 in score predictions.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19900",
        "abstract url": "https://arxiv.org/abs/2407.19900",
        "title": "Practical and Reproducible Symbolic Music Generation by Large Language Models with Structural Embeddings",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Music generation introduces challenging complexities to large language models. Symbolic structures of music often include vertical harmonization as well as horizontal counterpoint, urging various adaptations and enhancements for large-scale Transformers. However, existing works share three major drawbacks: 1) their tokenization requires domain-specific annotations, such as bars and beats, that are typically missing in raw MIDI data; 2) the pure impact of enhancing token embedding methods is hardly examined without domain-specific annotations; and 3) existing works to overcome the aforementioned drawbacks, such as MuseNet, lack reproducibility. To tackle such limitations, we develop a MIDI-based music generation framework inspired by MuseNet, empirically studying two structural embeddings that do not rely on domain-specific annotations. We provide various metrics and insights that can guide suitable encoding to deploy. We also verify that multiple embedding configurations can selectively boost certain musical aspects. By providing open-source implementations via HuggingFace, our findings shed light on leveraging large language models toward practical and reproducible music generation.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "9 pages, 6 figures, 4 tables"
    },
    {
        "paper id": "2407.19902",
        "abstract url": "https://arxiv.org/abs/2407.19902",
        "title": "A Differential Dynamic Programming Framework for Inverse Reinforcement Learning",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "A differential dynamic programming (DDP)-based framework for inverse reinforcement learning (IRL) is introduced to recover the parameters in the cost function, system dynamics, and constraints from demonstrations. Different from existing work, where DDP was used for the inner forward problem with inequality constraints, our proposed framework uses it for efficient computation of the gradient required in the outer inverse problem with equality and inequality constraints. The equivalence between the proposed method and existing methods based on Pontryagin's Maximum Principle (PMP) is established. More importantly, using this DDP-based IRL with an open-loop loss function, a closed-loop IRL framework is presented. In this framework, a loss function is proposed to capture the closed-loop nature of demonstrations. It is shown to be better than the commonly used open-loop loss function. We show that the closed-loop IRL framework reduces to a constrained inverse optimal control problem under certain assumptions. Under these assumptions and a rank condition, it is proven that the learning parameters can be recovered from the demonstration data. The proposed framework is extensively evaluated through four numerical robot examples and one real-world quadrotor system. The experiments validate the theoretical results and illustrate the practical relevance of the approach.",
        "subjects": [
            "cs.RO",
            "eess.SY",
            "math.OC"
        ],
        "comment": "20 pages, 15 figures; submitted to IEEE for potential publication"
    },
    {
        "paper id": "2407.19905",
        "abstract url": "https://arxiv.org/abs/2407.19905",
        "title": "The Bidirected Cut Relaxation for Steiner Tree has Integrality Gap Smaller than 2",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The Steiner tree problem is one of the most prominent problems in network design. Given an edge-weighted undirected graph and a subset of the vertices, called terminals, the task is to compute a minimum-weight tree containing all terminals (and possibly further vertices). The best-known approximation algorithms for Steiner tree involve enumeration of a (polynomial but) very large number of candidate components and are therefore slow in practice. A promising ingredient for the design of fast and accurate approximation algorithms for Steiner tree is the bidirected cut relaxation (BCR): bidirect all edges, choose an arbitrary terminal as a root, and enforce that each cut containing some terminal but not the root has one unit of fractional edges leaving it. BCR is known to be integral in the spanning tree case [Edmonds'67], i.e., when all the vertices are terminals. For general instances, however, it was not even known whether the integrality gap of BCR is better than the integrality gap of the natural undirected relaxation, which is exactly 2. We resolve this question by proving an upper bound of 1.9988 on the integrality gap of BCR.",
        "subjects": [
            "cs.DS",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19934",
        "abstract url": "https://arxiv.org/abs/2407.19934",
        "title": "Graph Fourier Transform Enhancement through Envelope Extensions",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Many real-world networks are characterized by directionality; however, the absence of an appropriate Fourier basis hinders the effective implementation of graph signal processing techniques. Inspired by discrete signal processing, where embedding a line digraph into a cycle digraph facilitates the powerful Discrete Fourier Transform for signal analysis, addressing the structural complexities of general digraphs can help overcome the limitations of the Graph Fourier Transform (GFT) and unlock its potential. The Discrete Fourier Transform (DFT) serves as a Graph Fourier Transform for both cycle graphs and Cayley digraphs on the finite cyclic groups $\\mathbb{Z}_N$. We propose a systematic method to identify a class of such Cayley digraphs that can encompass a given directed graph. By embedding the directed graph into these Cayley digraphs and opting for envelope extensions that naturally support the Graph Fourier Transform, the GFT functionalities of these extensions can be harnessed for signal analysis. Among the potential envelopes, optimal performance is achieved by selecting one that meets key properties. This envelope's structure closely aligns with the characteristics of the original digraph. The Graph Fourier Transform of this envelope is reliable in terms of numerical stability, and its columns approximately form an eigenbasis for the adjacency matrix associated with the original digraph. It is shown that the envelope extensions possess a convolution product, with their GFT fulfilling the convolution theorem. Additionally, shift-invariant graph filters (systems) are described as the convolution operator, analogous to the classical case. This allows the utilization of systems for signal analysis.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "14 pages, 16 figures, 3 tables"
    },
    {
        "paper id": "2407.19953",
        "abstract url": "https://arxiv.org/abs/2407.19953",
        "title": "FedDEO: Description-Enhanced One-Shot Federated Learning with Diffusion Models",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Federated Learning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the attention towards One-Shot Federated Learning (OSFL) has been driven by its capacity to minimize communication. With the development of the diffusion model (DM), several methods employ the DM for OSFL, utilizing model parameters, image features, or textual prompts as mediums to transfer the local client knowledge to the server. However, these mediums often require public datasets or the uniform feature extractor, significantly limiting their practicality. In this paper, we propose FedDEO, a Description-Enhanced One-Shot Federated Learning Method with DMs, offering a novel exploration of utilizing the DM in OSFL. The core idea of our method involves training local descriptions on the clients, serving as the medium to transfer the knowledge of the distributed clients to the server. Firstly, we train local descriptions on the client data to capture the characteristics of client distributions, which are then uploaded to the server. On the server, the descriptions are used as conditions to guide the DM in generating synthetic datasets that comply with the distributions of various clients, enabling the training of the aggregated model. Theoretical analyses and sufficient quantitation and visualization experiments on three large-scale real-world datasets demonstrate that through the training of local descriptions, the server is capable of generating synthetic datasets with high quality and diversity. Consequently, with advantages in communication and privacy protection, the aggregated model outperforms compared FL or diffusion-based OSFL methods and, on some clients, outperforms the performance ceiling of centralized training.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by MM 24"
    },
    {
        "paper id": "2407.19970",
        "abstract url": "https://arxiv.org/abs/2407.19970",
        "title": "From Flat to Spatial: Comparison of 4 methods constructing 3D, 2 and 1/2D Models from 2D Plans with neural networks",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "voxel",
                "depth"
            ],
            [
                "diffusion",
                "GAN"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the field of architecture, the conversion of single images into 2 and 1/2D and 3D meshes is a promising technology that enhances design visualization and efficiency. This paper evaluates four innovative methods: \"One-2-3-45,\" \"CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model,\" \"Instant Mesh,\" and \"Image-to-Mesh.\" These methods are at the forefront of this technology, focusing on their applicability in architectural design and visualization. They streamline the creation of 3D architectural models, enabling rapid prototyping and detailed visualization from minimal initial inputs, such as photographs or simple sketches.One-2-3-45 leverages a diffusion-based approach to generate multi-view reconstructions, ensuring high geometric fidelity and texture quality. CRM utilizes a convolutional network to integrate geometric priors into its architecture, producing detailed and textured meshes quickly and efficiently. Instant Mesh combines the strengths of multi-view diffusion and sparse-view models to offer speed and scalability, suitable for diverse architectural projects. Image-to-Mesh leverages a generative adversarial network (GAN) to produce 3D meshes from single images, focusing on maintaining high texture fidelity and geometric accuracy by incorporating image and depth map data into its training process. It uses a hybrid approach that combines voxel-based representations with surface reconstruction techniques to ensure detailed and realistic 3D models.This comparative study highlights each method's contribution to reducing design cycle times, improving accuracy, and enabling flexible adaptations to various architectural styles and requirements. By providing architects with powerful tools for rapid visualization and iteration, these advancements in 3D mesh generation are set to revolutionize architectural practices.",
        "subjects": [
            "cs.GR",
            "cs.CV",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19975",
        "abstract url": "https://arxiv.org/abs/2407.19975",
        "title": "Integrated Scenario-based Analysis: A data-driven approach to support automated driving systems development and safety evaluation",
        "rating": "-1",
        "keywords": [
            [
                "automated driving",
                "vehicle"
            ]
        ],
        "abstract": "Several scenario-based frameworks exist to aid in vehicle system development and safety assurance. However, there is a need for approaches that combine different types of datasets that offer varying levels of case severity, data richness, and representativeness. This study presents an integrated scenario-based analysis approach that encompasses scenario definition, fusion, parametrization, and test case generation. For this process, ten years of fatal and non-fatal national crash data from the United States are combined with over 34 million miles of naturalistic driving data. An illustrative example scenario, \"turns at intersection\", is chosen to demonstrate this approach. First, scenario definitions are established from both record-based and continuous time series data. Second, a frequency analysis is performed to understand how often events from the same scenario occur at different severities across datasets. Third, an analysis is performed to show the key factors relevant to the scenario and the distribution of various parameters. Finally, a method to combine both types of data into representative test case scenarios is presented. These techniques improve scenario representativeness in two major ways: first, they populate an entire spectrum of cases ranging from routine events to fatal crashes; and second, they provide context-rich, multi-year data by combining large-scale national and naturalistic datasets.",
        "subjects": [
            "cs.RO",
            "stat.AP"
        ],
        "comment": "8 pages, 5 figures, 27th IEEE International Conference on Intelligent Transportation Systems"
    },
    {
        "paper id": "2407.19976",
        "abstract url": "https://arxiv.org/abs/2407.19976",
        "title": "MambaGesture: Enhancing Co-Speech Gesture Generation with Mamba and Disentangled Multi-Modality Fusion",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "Co-speech gesture generation is crucial for producing synchronized and realistic human gestures that accompany speech, enhancing the animation of lifelike avatars in virtual environments. While diffusion models have shown impressive capabilities, current approaches often overlook a wide range of modalities and their interactions, resulting in less dynamic and contextually varied gestures. To address these challenges, we present MambaGesture, a novel framework integrating a Mamba-based attention block, MambaAttn, with a multi-modality feature fusion module, SEAD. The MambaAttn block combines the sequential data processing strengths of the Mamba model with the contextual richness of attention mechanisms, enhancing the temporal coherence of generated gestures. SEAD adeptly fuses audio, text, style, and emotion modalities, employing disentanglement to deepen the fusion process and yield gestures with greater realism and diversity. Our approach, rigorously evaluated on the multi-modal BEAT dataset, demonstrates significant improvements in Fr\u00e9chet Gesture Distance (FGD), diversity scores, and beat alignment, achieving state-of-the-art performance in co-speech gesture generation.",
        "subjects": [
            "cs.HC",
            "cs.MM"
        ],
        "comment": "Accepted to ACM MM 2024"
    },
    {
        "paper id": "2407.19981",
        "abstract url": "https://arxiv.org/abs/2407.19981",
        "title": "Adversarial Robustness in RGB-Skeleton Action Recognition: Leveraging Attention Modality Reweighter",
        "rating": "-1",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) have been applied in many computer vision tasks and achieved state-of-the-art (SOTA) performance. However, misclassification will occur when DNNs predict adversarial examples which are created by adding human-imperceptible adversarial noise to natural examples. This limits the application of DNN in security-critical fields. In order to enhance the robustness of models, previous research has primarily focused on the unimodal domain, such as image recognition and video understanding. Although multi-modal learning has achieved advanced performance in various tasks, such as action recognition, research on the robustness of RGB-skeleton action recognition models is scarce. In this paper, we systematically investigate how to improve the robustness of RGB-skeleton action recognition models. We initially conducted empirical analysis on the robustness of different modalities and observed that the skeleton modality is more robust than the RGB modality. Motivated by this observation, we propose the \\formatword{A}ttention-based \\formatword{M}odality \\formatword{R}eweighter (\\formatword{AMR}), which utilizes an attention layer to re-weight the two modalities, enabling the model to learn more robust features. Our AMR is plug-and-play, allowing easy integration with multimodal models. To demonstrate the effectiveness of AMR, we conducted extensive experiments on various datasets. For example, compared to the SOTA methods, AMR exhibits a 43.77\\% improvement against PGD20 attacks on the NTU-RGB+D 60 dataset. Furthermore, it effectively balances the differences in robustness between different modalities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IJCB 2024"
    },
    {
        "paper id": "2407.19990",
        "abstract url": "https://arxiv.org/abs/2407.19990",
        "title": "Classification of Alzheimer's Dementia vs. Healthy subjects by studying structural disparities in fMRI Time-Series of DMN",
        "rating": "-1",
        "keywords": [
            [
                "fMRI",
                "Disease"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Time series from different regions of interest (ROI) of default mode network (DMN) from Functional Magnetic Resonance Imaging (fMRI) can reveal significant differences between healthy and unhealthy people. Here, we propose the utility of an existing metric quantifying the lack/presence of structure in a signal called, \"deviation from stochasticity\" (DS) measure to characterize resting-state fMRI time series. The hypothesis is that differences in the level of structure in the time series can lead to discrimination between the subject groups. In this work, an autoencoder-based model is utilized to learn efficient representations of data by training the network to reconstruct its input data. The proposed methodology is applied on fMRI time series of 50 healthy individuals and 50 subjects with Alzheimer's Disease (AD), obtained from publicly available ADNI database. DS measure for healthy fMRI as expected turns out to be different compared to that of AD. Peak classification accuracy of 95% was obtained using Gradient Boosting classifier, using the DS measure applied on 100 subjects.",
        "subjects": [
            "cs.LG",
            "eess.IV",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20004",
        "abstract url": "https://arxiv.org/abs/2407.20004",
        "title": "Navigation services amplify concentration of traffic and emissions in our cities",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "The proliferation of human-AI ecosystems involving human interaction with algorithms, such as assistants and recommenders, raises concerns about large-scale social behaviour. Despite evidence of such phenomena across several contexts, the collective impact of GPS navigation services remains unclear: while beneficial to the user, they can also cause chaos if too many vehicles are driven through the same few roads. Our study employs a simulation framework to assess navigation services' influence on road network usage and CO2 emissions. The results demonstrate a universal pattern of amplified conformity: increasing adoption rates of navigation services cause a reduction of route diversity of mobile travellers and increased concentration of traffic and emissions on fewer roads, thus exacerbating an unequal distribution of negative externalities on selected neighbourhoods. Although navigation services recommendations can help reduce CO2 emissions when their adoption rate is low, these benefits diminish or even disappear when the adoption rate is high and exceeds a certain city- and service-dependent threshold. We summarize these discoveries in a non-linear function that connects the marginal increase of conformity with the marginal reduction in CO2 emissions. Our simulation approach addresses the challenges posed by the complexity of transportation systems and the lack of data and algorithmic transparency.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20007",
        "abstract url": "https://arxiv.org/abs/2407.20007",
        "title": "Rosetta Statements: Lowering the Barrier for Semantic Parsing and Increasing the Cognitive Interoperability of Knowledge Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "Machines need data and metadata to be machine-actionable and FAIR (findable, accessible, interoperable, reusable) to manage increasing data volumes. Knowledge graphs and ontologies are key to this, but their use is hampered by high access barriers due to required prior knowledge in semantics and data modelling. The Rosetta Statement approach proposes modeling English natural language statements instead of a mind-independent reality. We propose a metamodel for creating semantic schema patterns for simple statement types. The approach supports versioning of statements and provides a detailed editing history. Each Rosetta Statement pattern has a dynamic label for displaying statements as natural language sentences. Implemented in the Open Research Knowledge Graph (ORKG) as a use case, this approach allows domain experts to define data schema patterns without needing semantic knowledge. Future plans include combining Rosetta Statements with semantic units to organize ORKG into meaningful subgraphs, improving usability. A search interface for querying statements without needing SPARQL or Cypher knowledge is also planned, along with tools for data entry and display using Large Language Models and NLP. The Rosetta Statement metamodel supports a two-step knowledge graph construction procedure. Domain experts can model semantic content without support from ontology engineers, lowering entry barriers and increasing cognitive interoperability. The second level involves developing semantic graph patterns for reasoning, requiring collaboration with ontology engineers.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20031",
        "abstract url": "https://arxiv.org/abs/2407.20031",
        "title": "Query maintenance under batch changes with small-depth circuits",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "Which dynamic queries can be maintained efficiently? For constant-size changes, it is known that constant-depth circuits or, equivalently, first-order updates suffice for maintaining many important queries, among them reachability, tree isomorphism, and the word problem for context-free languages. In other words, these queries are in the dynamic complexity class DynFO. We show that most of the existing results for constant-size changes can be recovered for batch changes of polylogarithmic size if one allows circuits of depth O(log log n) or, equivalently, first-order updates that are iterated O(log log n) times.",
        "subjects": [
            "cs.LO",
            "cs.CC"
        ],
        "comment": "Full version of an MFCS 2024 paper"
    },
    {
        "paper id": "2407.20046",
        "abstract url": "https://arxiv.org/abs/2407.20046",
        "title": "Exploring Large Language Models to generate Easy to Read content",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Ensuring text accessibility and understandability are essential goals, particularly for individuals with cognitive impairments and intellectual disabilities, who encounter challenges in accessing information across various mediums such as web pages, newspapers, administrative tasks, or health documents. Initiatives like Easy to Read and Plain Language guidelines aim to simplify complex texts; however, standardizing these guidelines remains challenging and often involves manual processes. This work presents an exploratory investigation into leveraging Artificial Intelligence (AI) and Natural Language Processing (NLP) approaches to systematically simplify Spanish texts into Easy to Read formats, with a focus on utilizing Large Language Models (LLMs) for simplifying texts, especially in generating Easy to Read content. The study contributes a parallel corpus of Spanish adapted for Easy To Read format, which serves as a valuable resource for training and testing text simplification systems. Additionally, several text simplification experiments using LLMs and the collected corpus are conducted, involving fine-tuning and testing a Llama2 model to generate Easy to Read content. A qualitative evaluation, guided by an expert in text adaptation for Easy to Read content, is carried out to assess the automatically simplified texts. This research contributes to advancing text accessibility for individuals with cognitive impairments, highlighting promising strategies for leveraging LLMs while responsibly managing energy usage.",
        "subjects": [
            "cs.CL",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20094",
        "abstract url": "https://arxiv.org/abs/2407.20094",
        "title": "Orbital Angular Momentum Active Anti-Jamming in Radio Wireless Communications",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Orbital angular momentum (OAM), providing the orthogonality among different OAM modes, has attracted much attention to significantly increase spectrum efficiencies (SEs) and enhance the anti-jamming results of wireless communications. However, the SE of wireless communications is severely degraded under co-frequency and co-mode hostile jamming. Focused on this issue, we propose a novel OAM active anti-jamming scheme to significantly enhance the anti-jamming results of wireless communications under broadband hostile jamming. Specifically, the OAM transmitter with energy detection senses jamming signals to identify which OAM modes are jammed and unjammed. Based on the recognition of OAM modes, useful signals are modulated by reflecting the received co-frequency and co-mode jamming signals with the assistance of a programmable gain amplifier (PGA) to the OAM receiver, thus utilizing both the OAM modes jammed by hostile attacks and the energy of jamming signals. Meanwhile, the unjammed OAM modes allocated with total transmit power are multiplexed for useful signal transmission. Numerical results demonstrate that our proposed OAM active anti-jamming scheme can achieve high OAM mode utilization and significantly increase the SEs.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures and accepted by Ucom 2024"
    },
    {
        "paper id": "2407.20108",
        "abstract url": "https://arxiv.org/abs/2407.20108",
        "title": "Classification, Regression and Segmentation directly from k-Space in Cardiac MRI",
        "rating": "-1",
        "keywords": [
            [
                "diagnosing",
                "MRI",
                "disease",
                "Clinical",
                "Cardiac"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosing cardiovascular diseases. Clinical diagnoses predominantly rely on magnitude-only Digital Imaging and Communications in Medicine (DICOM) images, omitting crucial phase information that might provide additional diagnostic benefits. In contrast, k-space is complex-valued and encompasses both magnitude and phase information, while humans cannot directly perceive. In this work, we propose KMAE, a Transformer-based model specifically designed to process k-space data directly, eliminating conventional intermediary conversion steps to the image domain. KMAE can handle critical cardiac disease classification, relevant phenotype regression, and cardiac morphology segmentation tasks. We utilize this model to investigate the potential of k-space-based diagnosis in cardiac MRI. Notably, this model achieves competitive classification and regression performance compared to image-domain methods e.g. Masked Autoencoders (MAEs) and delivers satisfactory segmentation performance with a myocardium dice score of 0.884. Last but not least, our model exhibits robust performance with consistent results even when the k-space is 8* undersampled. We encourage the MR community to explore the untapped potential of k-space and pursue end-to-end, automated diagnosis with reduced human intervention.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20176",
        "abstract url": "https://arxiv.org/abs/2407.20176",
        "title": "Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Emotion-driven melody harmonization aims to generate diverse harmonies for a single melody to convey desired emotions. Previous research found it hard to alter the perceived emotional valence of lead sheets only by harmonizing the same melody with different chords, which may be attributed to the constraints imposed by the melody itself and the limitation of existing music representation. In this paper, we propose a novel functional representation for symbolic music. This new method takes musical keys into account, recognizing their significant role in shaping music's emotional character through major-minor tonality. It also allows for melodic variation with respect to keys and addresses the problem of data scarcity for better emotion modeling. A Transformer is employed to harmonize key-adaptable melodies, allowing for keys determined in rule-based or model-based manner. Experimental results confirm the effectiveness of our new representation in generating key-aware harmonies, with objective and subjective evaluations affirming the potential of our approach to convey specific valence for versatile melody.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "This work is the initial version of the ISMIR 2024 paper EMO-Disentanger"
    },
    {
        "paper id": "2407.20183",
        "abstract url": "https://arxiv.org/abs/2407.20183",
        "title": "MindSearch: Mimicking Human Minds Elicits Deep AI Searcher",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Information seeking and integration is a complex cognitive task that consumes enormous time and effort. Inspired by the remarkable progress of Large Language Models, recent works attempt to solve this task by combining LLMs and search engines. However, these methods still obtain unsatisfying performance due to three challenges: (1) complex requests often cannot be accurately and completely retrieved by the search engine once (2) corresponding information to be integrated is spread over multiple web pages along with massive noise, and (3) a large number of web pages with long contents may quickly exceed the maximum context length of LLMs. Inspired by the cognitive process when humans solve these problems, we introduce MindSearch to mimic the human minds in web information seeking and integration, which can be instantiated by a simple yet effective LLM-based multi-agent framework. The WebPlanner models the human mind of multi-step information seeking as a dynamic graph construction process: it decomposes the user query into atomic sub-questions as nodes in the graph and progressively extends the graph based on the search result from WebSearcher. Tasked with each sub-question, WebSearcher performs hierarchical information retrieval with search engines and collects valuable information for WebPlanner. The multi-agent design of MindSearch enables the whole framework to seek and integrate information parallelly from larger-scale (e.g., more than 300) web pages in 3 minutes, which is worth 3 hours of human effort. MindSearch demonstrates significant improvement in the response quality in terms of depth and breadth, on both close-set and open-set QA problems. Besides, responses from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web and Perplexity.ai applications, which implies that MindSearch can already deliver a competitive solution to the proprietary AI search engine.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Technical Report. Project Page: https://mindsearch.netlify.app Code: https://github.com/InternLM/MindSearch"
    },
    {
        "paper id": "2407.20194",
        "abstract url": "https://arxiv.org/abs/2407.20194",
        "title": "Radiance Fields for Robotic Teleoperation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF",
                "Radiance Fields"
            ]
        ],
        "abstract": "Radiance field methods such as Neural Radiance Fields (NeRFs) or 3D Gaussian Splatting (3DGS), have revolutionized graphics and novel view synthesis. Their ability to synthesize new viewpoints with photo-realistic quality, as well as capture complex volumetric and specular scenes, makes them an ideal visualization for robotic teleoperation setups. Direct camera teleoperation provides high-fidelity operation at the cost of maneuverability, while reconstruction-based approaches offer controllable scenes with lower fidelity. With this in mind, we propose replacing the traditional reconstruction-visualization components of the robotic teleoperation pipeline with online Radiance Fields, offering highly maneuverable scenes with photorealistic quality. As such, there are three main contributions to state of the art: (1) online training of Radiance Fields using live data from multiple cameras, (2) support for a variety of radiance methods including NeRF and 3DGS, (3) visualization suite for these methods including a virtual reality scene. To enable seamless integration with existing setups, these components were tested with multiple robots in multiple configurations and were displayed using traditional tools as well as the VR headset. The results across methods and robots were compared quantitatively to a baseline of mesh reconstruction, and a user study was conducted to compare the different visualization methods. For videos and code, check out https://leggedrobotics.github.io/rffr.github.io/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 10 figures, Accepted to IROS 2024"
    },
    {
        "paper id": "2407.20198",
        "abstract url": "https://arxiv.org/abs/2407.20198",
        "title": "SpaER: Learning Spatio-temporal Equivariant Representations for Fetal Brain Motion Tracking",
        "rating": "-1",
        "keywords": [
            [
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this paper, we introduce SpaER, a pioneering method for fetal motion tracking that leverages equivariant filters and self-attention mechanisms to effectively learn spatio-temporal representations. Different from conventional approaches that statically estimate fetal brain motions from pairs of images, our method dynamically tracks the rigid movement patterns of the fetal head across temporal and spatial dimensions. Specifically, we first develop an equivariant neural network that efficiently learns rigid motion sequences through low-dimensional spatial representations of images. Subsequently, we learn spatio-temporal representations by incorporating time encoding and self-attention neural network layers. This approach allows for the capture of long-term dependencies of fetal brain motion and addresses alignment errors due to contrast changes and severe motion artifacts. Our model also provides a geometric deformation estimation that properly addresses image distortions among all time frames. To the best of our knowledge, our approach is the first to learn spatial-temporal representations via deep neural networks for fetal motion tracking without data augmentation. We validated our model using real fetal echo-planar images with simulated and real motions. Our method carries significant potential value in accurately measuring, tracking, and correcting fetal motion in fetal MRI sequences.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "11 pages, 3 figures, Medical Image Computing and Computer Assisted Interventions (MICCAI) Workshop on Perinatal Imaging, Placental and Preterm Image analysis (PIPPI) 2024"
    },
    {
        "paper id": "2407.20203",
        "abstract url": "https://arxiv.org/abs/2407.20203",
        "title": "Privileged Reinforcement and Communication Learning for Distributed, Bandwidth-limited Multi-robot Exploration",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Communication bandwidth is an important consideration in multi-robot exploration, where information exchange among robots is critical. While existing methods typically aim to reduce communication throughput, they either require significant computation or significantly compromise exploration efficiency. In this work, we propose a deep reinforcement learning framework based on communication and privileged reinforcement learning to achieve a significant reduction in bandwidth consumption, while minimally sacrificing exploration efficiency. Specifically, our approach allows robots to learn to embed the most salient information from their individual belief (partial map) over the environment into fixed-sized messages. Robots then reason about their own belief as well as received messages to distributedly explore the environment while avoiding redundant work. In doing so, we employ privileged learning and learned attention mechanisms to endow the critic (i.e., teacher) network with ground truth map knowledge to effectively guide the policy (i.e., student) network during training. Compared to relevant baselines, our model allows the team to reduce communication by up to two orders of magnitude, while only sacrificing a marginal 2.4\\% in total travel distance, paving the way for efficient, distributed multi-robot exploration in bandwidth-limited scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted by DARS2024"
    },
    {
        "paper id": "2407.20224",
        "abstract url": "https://arxiv.org/abs/2407.20224",
        "title": "Can Editing LLMs Inject Harm?",
        "rating": "-1",
        "keywords": [
            [
                "Knowledge editing"
            ],
            [
                "Attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge editing techniques have been increasingly adopted to efficiently correct the false or outdated knowledge in Large Language Models (LLMs), due to the high cost of retraining from scratch. Meanwhile, one critical but under-explored question is: can knowledge editing be used to inject harm into LLMs? In this paper, we propose to reformulate knowledge editing as a new type of safety threat for LLMs, namely Editing Attack, and conduct a systematic investigation with a newly constructed dataset EditAttack. Specifically, we focus on two typical safety risks of Editing Attack including Misinformation Injection and Bias Injection. For the risk of misinformation injection, we first categorize it into commonsense misinformation injection and long-tail misinformation injection. Then, we find that editing attacks can inject both types of misinformation into LLMs, and the effectiveness is particularly high for commonsense misinformation injection. For the risk of bias injection, we discover that not only can biased sentences be injected into LLMs with high effectiveness, but also one single biased sentence injection can cause a bias increase in general outputs of LLMs, which are even highly irrelevant to the injected sentence, indicating a catastrophic impact on the overall fairness of LLMs. Then, we further illustrate the high stealthiness of editing attacks, measured by their impact on the general knowledge and reasoning capacities of LLMs, and show the hardness of defending editing attacks with empirical evidence. Our discoveries demonstrate the emerging misuse risks of knowledge editing techniques on compromising the safety alignment of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "The first two authors contributed equally. 9 pages for main paper, 36 pages including appendix. The code, results, dataset for this paper and more resources are on the project website: https://llm-editing.github.io"
    },
    {
        "paper id": "2407.20226",
        "abstract url": "https://arxiv.org/abs/2407.20226",
        "title": "Models of random spanning trees",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "There are numerous randomized algorithms to generate spanning trees in a given ambient graph; several target the uniform distribution on trees (UST), while in practice the fastest and most frequently used draw random weights on the edges and then employ a greedy algorithm to choose the minimum-weight spanning tree (MST). Though MST is a workhorse in applications, the mathematical properties of random MST are far less explored than those of UST. In this paper we develop tools for the quantitative study of random MST. We consider the standard case that the weights are drawn i.i.d. from a single distribution on the real numbers, as well as successive generalizations that lead to \\emph{product measures}, where the weights are independently drawn from arbitrary distributions.",
        "subjects": [
            "cs.DM",
            "math.CO",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20336",
        "abstract url": "https://arxiv.org/abs/2407.20336",
        "title": "Sun Off, Lights On: Photorealistic Monocular Nighttime Simulation for Robust Semantic Perception",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Nighttime scenes are hard to semantically perceive with learned models and annotate for humans. Thus, realistic synthetic nighttime data become all the more important for learning robust semantic perception at night, thanks to their accurate and cheap semantic annotations. However, existing data-driven or hand-crafted techniques for generating nighttime images from daytime counterparts suffer from poor realism. The reason is the complex interaction of highly spatially varying nighttime illumination, which differs drastically from its daytime counterpart, with objects of spatially varying materials in the scene, happening in 3D and being very hard to capture with such 2D approaches. The above 3D interaction and illumination shift have proven equally hard to model in the literature, as opposed to other conditions such as fog or rain. Our method, named Sun Off, Lights On (SOLO), is the first to perform nighttime simulation on single images in a photorealistic fashion by operating in 3D. It first explicitly estimates the 3D geometry, the materials and the locations of light sources of the scene from the input daytime image and relights the scene by probabilistically instantiating light sources in a way that accounts for their semantics and then running standard ray tracing. Not only is the visual quality and photorealism of our nighttime images superior to competing approaches including diffusion models, but the former images are also proven more beneficial for semantic nighttime segmentation in day-to-night adaptation. Code and data will be made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted for review"
    },
    {
        "paper id": "2407.20361",
        "abstract url": "https://arxiv.org/abs/2407.20361",
        "title": "From ML to LLM: Evaluating the Robustness of Phishing Webpage Detection Models against Adversarial Attacks",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Phishing attacks attempt to deceive users into stealing sensitive information, posing a significant cybersecurity threat. Advances in machine learning (ML) and deep learning (DL) have led to the development of numerous phishing webpage detection solutions, but these models remain vulnerable to adversarial attacks. Evaluating their robustness against adversarial phishing webpages is essential. Existing tools contain datasets of pre-designed phishing webpages for a limited number of brands, and lack diversity in phishing features. To address these challenges, we develop PhishOracle, a tool that generates adversarial phishing webpages by embedding diverse phishing features into legitimate webpages. We evaluate the robustness of two existing models, Stack model and Phishpedia, in classifying PhishOracle-generated adversarial phishing webpages. Additionally, we study a commercial large language model, Gemini Pro Vision, in the context of adversarial attacks. We conduct a user study to determine whether PhishOracle-generated adversarial phishing webpages deceive users. Our findings reveal that many PhishOracle-generated phishing webpages evade current phishing webpage detection models and deceive users, but Gemini Pro Vision is robust to the attack. We also develop the PhishOracle web app, allowing users to input a legitimate URL, select relevant phishing features and generate a corresponding phishing webpage. All resources are publicly available on GitHub.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20372",
        "abstract url": "https://arxiv.org/abs/2407.20372",
        "title": "A Model Generalization Study in Localizing Indoor Cows with COw LOcalization (COLO) dataset",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Precision livestock farming (PLF) increasingly relies on advanced object localization techniques to monitor livestock health and optimize resource management. This study investigates the generalization capabilities of YOLOv8 and YOLOv9 models for cow detection in indoor free-stall barn settings, focusing on varying training data characteristics such as view angles and lighting, and model complexities. Leveraging the newly released public dataset, COws LOcalization (COLO) dataset, we explore three key hypotheses: (1) Model generalization is equally influenced by changes in lighting conditions and camera angles; (2) Higher model complexity guarantees better generalization performance; (3) Fine-tuning with custom initial weights trained on relevant tasks always brings advantages to detection tasks. Our findings reveal considerable challenges in detecting cows in images taken from side views and underscore the importance of including diverse camera angles in building a detection model. Furthermore, our results emphasize that higher model complexity does not necessarily lead to better performance. The optimal model configuration heavily depends on the specific task and dataset. Lastly, while fine-tuning with custom initial weights trained on relevant tasks offers advantages to detection tasks, simpler models do not benefit similarly from this approach. It is more efficient to train a simple model with pre-trained weights without relying on prior relevant information, which can require intensive labor efforts. Future work should focus on adaptive methods and advanced data augmentation to improve generalization and robustness. This study provides practical guidelines for PLF researchers on deploying computer vision models from existing studies, highlights generalization issues, and contributes the COLO dataset containing 1254 images and 11818 cow instances for further research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "17 pages, 7 figures"
    },
    {
        "paper id": "2407.20387",
        "abstract url": "https://arxiv.org/abs/2407.20387",
        "title": "Two-Phase Segmentation Approach for Accurate Left Ventricle Segmentation in Cardiac MRI using Machine Learning",
        "rating": "-1",
        "keywords": [
            [
                "surgical",
                "diagnosis",
                "MRI",
                "disease",
                "Cardiac"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Accurate segmentation of the Left Ventricle (LV) holds substantial importance due to its implications in disease detection, regional analysis, and the development of complex models for cardiac surgical planning. CMR is a golden standard for diagnosis of serveral cardiac diseases. LV in CMR comprises of three distinct sections: Basal, Mid-Ventricle, and Apical. This research focuses on the precise segmentation of the LV from Cardiac MRI (CMR) scans, joining with the capabilities of Machine Learning (ML). The central challenge in this research revolves around the absence of a set of parameters applicable to all three types of LV slices. Parameters optimized for basal slices often fall short when applied to mid-ventricular and apical slices, and vice versa. To handle this issue, a new method is proposed to enhance LV segmentation. The proposed method involves using distinct sets of parameters for each type of slice, resulting in a two-phase segmentation approach. The initial phase categorizes images into three groups based on the type of LV slice, while the second phase aims to segment CMR images using parameters derived from the preceding phase. A publicly available dataset (Automated Cardiac Diagnosis Challenge (ACDC)) is used. 10-Fold Cross Validation is used and it achieved a mean score of 0.9228. Comprehensive testing indicates that the best parameter set for a particular type of slice does not perform adequately for the other slice types. All results show that the proposed approach fills a critical void in parameter standardization through a two-phase segmentation model for the LV, aiming to not only improve the accuracy of cardiac image analysis but also contribute advancements to the field of LV segmentation.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20395",
        "abstract url": "https://arxiv.org/abs/2407.20395",
        "title": "Dense Self-Supervised Learning for Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "MRI",
                "cardiac"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning has revolutionized medical image segmentation, but it relies heavily on high-quality annotations. The time, cost and expertise required to label images at the pixel-level for each new task has slowed down widespread adoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL) approach for few-shot segmentation, that reduces the manual annotation burden by learning powerful pixel-level representations directly from unlabeled images. Pix2Rep is a novel pixel-level loss and pre-training paradigm for contrastive SSL on whole images. It is applied to generic encoder-decoder deep learning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance of the learned image-level representations under intensity and spatial image augmentations, Pix2Rep enforces equivariance of the pixel-level representations. We demonstrate the framework on a task of cardiac MRI segmentation. Results show improved performance compared to existing semi- and self-supervised approaches; and a 5-fold reduction in the annotation burden for equivalent performance versus a fully supervised U-Net baseline. This includes a 30% (resp. 31%) DICE improvement for one-shot segmentation under linear-probing (resp. fine-tuning). Finally, we also integrate the novel Pix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even better segmentation performance.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at MIDL 2024"
    },
    {
        "paper id": "2407.20399",
        "abstract url": "https://arxiv.org/abs/2407.20399",
        "title": "Analysis and Improvement of Rank-Ordered Mean Algorithm in Single-Photon LiDAR",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Depth estimation using a single-photon LiDAR is often solved by a matched filter. It is, however, error-prone in the presence of background noise. A commonly used technique to reject background noise is the rank-ordered mean (ROM) filter previously reported by Shin \\textit{et al.} (2015). ROM rejects noisy photon arrival timestamps by selecting only a small range of them around the median statistics within its local neighborhood. Despite the promising performance of ROM, its theoretical performance limit is unknown. In this paper, we theoretically characterize the ROM performance by showing that ROM fails when the reflectivity drops below a threshold predetermined by the depth and signal-to-background ratio, and its accuracy undergoes a phase transition at the cutoff. Based on our theory, we propose an improved signal extraction technique by selecting tight timestamp clusters. Experimental results show that the proposed algorithm improves depth estimation performance over ROM by 3 orders of magnitude at the same signal intensities, and achieves high image fidelity at noise levels as high as 17 times that of signal.",
        "subjects": [
            "eess.SP",
            "cs.CV",
            "eess.IV"
        ],
        "comment": "6 pages, 7 figures, submitted to the IEEE 26th International Workshop on Multimedia Signal Processing (MMSP)"
    },
    {
        "paper id": "2407.20410",
        "abstract url": "https://arxiv.org/abs/2407.20410",
        "title": "Regrading Policies for Flexible Information Flow Control in Session-Typed Concurrency",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Noninterference guarantees that an attacker cannot infer secrets by interacting with a program. Information flow control (IFC) type systems assert noninterference by tracking the level of information learned (pc) and disallowing communication to entities of lesser or unrelated level than the pc. Control flow constructs such as loops are at odds with this pattern because they necessitate downgrading the pc upon recursion to be practical. In a concurrent setting, however, downgrading is not generally safe. This paper utilizes session types to track the flow of information and contributes an IFC type system for message-passing concurrent processes that allows downgrading the pc upon recursion. To make downgrading safe, the paper introduces regrading policies. Regrading policies are expressed in terms of integrity labels, which are also key to safe composition of entities with different regrading policies. The paper develops the type system and proves progress-sensitive noninterference for well-typed processes, ruling out timing attacks that exploit the relative order of messages. The type system has been implemented in a type checker, which supports security-polymorphic processes using local security theories.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "comment": "Technical report of ECOOP24 paper"
    },
    {
        "paper id": "2407.20439",
        "abstract url": "https://arxiv.org/abs/2407.20439",
        "title": "Haptic feedback of front car motion can improve driving control",
        "rating": "-1",
        "keywords": [
            [
                "automated driving",
                "vehicle"
            ]
        ],
        "abstract": "This study investigates the role of haptic feedback in a car-following scenario, where information about the motion of the front vehicle is provided through a virtual elastic connection with it. Using a robotic interface in a simulated driving environment, we examined the impact of varying levels of such haptic feedback on the driver's ability to follow the road while avoiding obstacles. The results of an experiment with 15 subjects indicate that haptic feedback from the front car's motion can significantly improve driving control (i.e., reduce motion jerk and deviation from the road) and reduce mental load (evaluated via questionnaire). This suggests that haptic communication, as observed between physically interacting humans, can be leveraged to improve safety and efficiency in automated driving systems, warranting further testing in real driving scenarios.",
        "subjects": [
            "cs.RO",
            "cs.HC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20445",
        "abstract url": "https://arxiv.org/abs/2407.20445",
        "title": "Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation",
        "rating": "-1",
        "keywords": [
            [
                "Song",
                "Music"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Existing music captioning methods are limited to generating concise global descriptions of short music clips, which fail to capture fine-grained musical characteristics and time-aware musical changes. To address these limitations, we propose FUTGA, a model equipped with fined-grained music understanding capabilities through learning from generative augmentation with temporal compositions. We leverage existing music caption datasets and large language models (LLMs) to synthesize fine-grained music captions with structural descriptions and time boundaries for full-length songs. Augmented by the proposed synthetic dataset, FUTGA is enabled to identify the music's temporal changes at key transition points and their musical functions, as well as generate detailed descriptions for each music segment. We further introduce a full-length music caption dataset generated by FUTGA, as the augmentation of the MusicCaps and the Song Describer datasets. We evaluate the automatically generated captions on several downstream tasks, including music generation and retrieval. The experiments demonstrate the quality of the generated captions and the better performance in various downstream tasks achieved by the proposed music captioning approach. Our code and datasets can be found in \\href{https://huggingface.co/JoshuaW1997/FUTGA}{\\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2407.20459",
        "abstract url": "https://arxiv.org/abs/2407.20459",
        "title": "Excavating Vulnerabilities Lurking in Multi-Factor Authentication Protocols: A Systematic Security Analysis",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Nowadays, cyberattacks are growing exponentially, causing havoc to Internet users. In particular, authentication attacks constitute the major attack vector where intruders impersonate legitimate users to maliciously access systems or resources. Traditional single-factor authentication (SFA) protocols are often bypassed by side-channel and other attack techniques, hence they are no longer sufficient to the current authentication requirements. To alleviate this problem, multi-factor authentication (MFA) protocols have been widely adopted recently, which helps to raise the security bar against imposters. Although MFA is generally considered more robust and secure than SFA, it may not always guarantee enhanced security and efficiency. This is because, critical security vulnerabilities and performance problems may still arise due to design or implementation flaws of the protocols. Such vulnerabilities are often left unnoticed until they are exploited by attackers. Therefore, the main objective of this work is identifying such vulnerabilities in existing MFA protocols by systematically analysing their designs and constructions. To this end, we first form a set of security evaluation criteria, encompassing both existing and newly introduced ones, which we believe are very critical for the security of MFA protocols. Then, we thoroughly review several MFA protocols across different domains. Subsequently, we revisit and thoroughly analyze the design and construction of the protocols to identify potential vulnerabilities. Consequently, we manage to identify critical vulnerabilities in ten of the MFA protocols investigated. We thoroughly discuss the identified vulnerabilities in each protocol and devise relevant mitigation strategies. We also consolidate the performance information of those protocols to show the runtime and storage cost when employing varying number of authentication factors.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20461",
        "abstract url": "https://arxiv.org/abs/2407.20461",
        "title": "Weakly Supervised Intracranial Hemorrhage Segmentation with YOLO and an Uncertainty Rectified Segment Anything Model",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "survival",
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Intracranial hemorrhage (ICH) is a life-threatening condition that requires rapid and accurate diagnosis to improve treatment outcomes and patient survival rates. Recent advancements in supervised deep learning have greatly improved the analysis of medical images, but often rely on extensive datasets with high-quality annotations, which are costly, time-consuming, and require medical expertise to prepare. To mitigate the need for large amounts of expert-prepared segmentation data, we have developed a novel weakly supervised ICH segmentation method that utilizes the YOLO object detection model and an uncertainty-rectified Segment Anything Model (SAM). In addition, we have proposed a novel point prompt generator for this model to further improve segmentation results with YOLO-predicted bounding box prompts. Our approach achieved a high accuracy of 0.933 and an AUC of 0.796 in ICH detection, along with a mean Dice score of 0.629 for ICH segmentation, outperforming existing weakly supervised and popular supervised (UNet and Swin-UNETR) approaches. Overall, the proposed method provides a robust and accurate alternative to the more commonly used supervised techniques for ICH quantification without requiring refined segmentation ground truths during model training.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Manuscript was accepted at SWITCH2024. 10 pages, 2 figures"
    },
    {
        "paper id": "2407.20469",
        "abstract url": "https://arxiv.org/abs/2407.20469",
        "title": "Efficient, gigapixel-scale, aberration-free whole slide scanner using angular ptychographic imaging with closed-form solution",
        "rating": "-1",
        "keywords": [
            [
                "biopsy",
                "surgery",
                "diagnosis",
                "whole slide",
                "clinical",
                "pathological"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Whole slide imaging provides a wide field-of-view (FOV) across cross-sections of biopsy or surgery samples, significantly facilitating pathological analysis and clinical diagnosis. Such high-quality images that enable detailed visualization of cellular and tissue structures are essential for effective patient care and treatment planning. To obtain such high-quality images for pathology applications, there is a need for scanners with high spatial bandwidth products, free from aberrations, and without the requirement for z-scanning. Here we report a whole slide imaging system based on angular ptychographic imaging with a closed-form solution (WSI-APIC), which offers efficient, tens-of-gigapixels, large-FOV, aberration-free imaging. WSI-APIC utilizes oblique incoherent illumination for initial high-level segmentation, thereby bypassing unnecessary scanning of the background regions and enhancing image acquisition efficiency. A GPU-accelerated APIC algorithm analytically reconstructs phase images with effective digital aberration corrections and improved optical resolutions. Moreover, an auto-stitching technique based on scale-invariant feature transform ensures the seamless concatenation of whole slide phase images. In our experiment, WSI-APIC achieved an optical resolution of 772 nm using a 10x/0.25 NA objective lens and captures 80-gigapixel aberration-free phase images for a standard 76.2 mm x 25.4 mm microscopic slide.",
        "subjects": [
            "physics.optics",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20515",
        "abstract url": "https://arxiv.org/abs/2407.20515",
        "title": "Markers Identification for Relative Pose Estimation of an Uncooperative Target",
        "rating": "-1",
        "keywords": [
            [
                "Satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel method using chaser spacecraft image processing and Convolutional Neural Networks (CNNs) to detect structural markers on the European Space Agency's (ESA) Environmental Satellite (ENVISAT) for safe de-orbiting. Advanced image pre-processing techniques, including noise addition and blurring, are employed to improve marker detection accuracy and robustness. Initial results show promising potential for autonomous space debris removal, supporting proactive strategies for space sustainability. The effectiveness of our approach suggests that our estimation method could significantly enhance the safety and efficiency of debris removal operations by implementing more robust and autonomous systems in actual space missions.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "2024 AAS/AIAA Astrodynamics Specialist Conference"
    },
    {
        "paper id": "2407.20535",
        "abstract url": "https://arxiv.org/abs/2407.20535",
        "title": "DeepSpeech models show Human-like Performance and Processing of Cochlear Implant Inputs",
        "rating": "-1",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Cochlear implants(CIs) are arguably the most successful neural implant, having restored hearing to over one million people worldwide. While CI research has focused on modeling the cochlear activations in response to low-level acoustic features, we hypothesize that the success of these implants is due in large part to the role of the upstream network in extracting useful features from a degraded signal and learned statistics of language to resolve the signal. In this work, we use the deep neural network (DNN) DeepSpeech2, as a paradigm to investigate how natural input and cochlear implant-based inputs are processed over time. We generate naturalistic and cochlear implant-like inputs from spoken sentences and test the similarity of model performance to human performance on analogous phoneme recognition tests. Our model reproduces error patterns in reaction time and phoneme confusion patterns under noise conditions in normal hearing and CI participant studies. We then use interpretability techniques to determine where and when confusions arise when processing naturalistic and CI-like inputs. We find that dynamics over time in each layer are affected by context as well as input type. Dynamics of all phonemes diverge during confusion and comprehension within the same time window, which is temporally shifted backward in each layer of the network. There is a modulation of this signal during processing of CI which resembles changes in human EEG signals in the auditory stream. This reduction likely relates to the reduction of encoded phoneme identity. These findings suggest that we have a viable model in which to explore the loss of speech-related information in time and that we can use it to find population-level encoding signals to target when optimizing cochlear implant inputs to improve encoding of essential speech-related information and improve perception.",
        "subjects": [
            "cs.NE",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "NEURIPS preprint"
    },
    {
        "paper id": "2407.19765",
        "abstract url": "https://arxiv.org/abs/2407.19765",
        "title": "Map2Traj: Street Map Piloted Zero-shot Trajectory Generation with Diffusion Model",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Trajectory"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "User mobility modeling serves a crucial role in analysis and optimization of contemporary wireless networks. Typical stochastic mobility models, e.g., random waypoint model and Gauss Markov model, can hardly capture the distribution characteristics of users within real-world areas. State-of-the-art trace-based mobility models and existing learning-based trajectory generation methods, however, are frequently constrained by the inaccessibility of substantial real trajectories due to privacy concerns. In this paper, we harness the intrinsic correlation between street maps and trajectories and develop a novel zero-shot trajectory generation method, named Map2Traj, by exploiting the diffusion model. We incorporate street maps as a condition to consistently pilot the denoising process and train our model on diverse sets of real trajectories from various regions in Xi'an, China, and their corresponding street maps. With solely the street map of an unobserved area, Map2Traj generates synthetic trajectories that not only closely resemble the real-world mobility pattern but also offer comparable efficacy. Extensive experiments validate the efficacy of our proposed method on zero-shot trajectory generation tasks in terms of both trajectory and distribution similarities. In addition, a case study of employing Map2Traj in wireless network optimization is presented to validate its efficacy for downstream applications.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19778",
        "abstract url": "https://arxiv.org/abs/2407.19778",
        "title": "Multimodal Large Language Models for Bioimage Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "Bioimage"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Rapid advancements in imaging techniques and analytical methods over the past decade have revolutionized our ability to comprehensively probe the biological world at multiple scales, pinpointing the type, quantity, location, and even temporal dynamics of biomolecules. The surge in data complexity and volume presents significant challenges in translating this wealth of information into knowledge. The recently emerged Multimodal Large Language Models (MLLMs) exhibit strong emergent capacities, such as understanding, analyzing, reasoning, and generalization. With these capabilities, MLLMs hold promise to extract intricate information from biological images and data obtained through various modalities, thereby expediting our biological understanding and aiding in the development of novel computational frameworks. Previously, such capabilities were mostly attributed to humans for interpreting and summarizing meaningful conclusions from comprehensive observations and analysis of biological images. However, the current development of MLLMs shows increasing promise in serving as intelligent assistants or agents for augmenting human researchers in biology research",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19784",
        "abstract url": "https://arxiv.org/abs/2407.19784",
        "title": "Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Alongside the continuous process of improving AI performance through the development of more sophisticated models, researchers have also focused their attention to the emerging concept of data-centric AI, which emphasizes the important role of data in a systematic machine learning training process. Nonetheless, the development of models has also continued apace. One result of this progress is the development of the Transformer Architecture, which possesses a high level of capability in multiple domains such as Natural Language Processing (NLP), Computer Vision (CV) and Time Series Forecasting (TSF). Its performance is, however, heavily dependent on input data preprocessing and output data evaluation, justifying a data-centric approach to future research. We argue that data-centric AI is essential for training AI models, particularly for transformer-based TSF models efficiently. However, there is a gap regarding the integration of transformer-based TSF and data-centric AI. This survey aims to pin down this gap via the extensive literature review based on the proposed taxonomy. We review the previous research works from a data-centric AI perspective and we intend to lay the foundation work for the future development of transformer-based architecture and data-centric AI.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19852",
        "abstract url": "https://arxiv.org/abs/2407.19852",
        "title": "Quantum Long Short-Term Memory for Drug Discovery",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantum computing combined with machine learning (ML) is an extremely promising research area, with numerous studies demonstrating that quantum machine learning (QML) is expected to solve scientific problems more effectively than classical ML. In this work, we successfully apply QML to drug discovery, showing that QML can significantly improve model performance and achieve faster convergence compared to classical ML. Moreover, we demonstrate that the model accuracy of the QML improves as the number of qubits increases. We also introduce noise to the QML model and find that it has little effect on our experimental conclusions, illustrating the high robustness of the QML model. This work highlights the potential application of quantum computing to yield significant benefits for scientific advancement as the qubit quantity increase and quality improvement in the future.",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19906",
        "abstract url": "https://arxiv.org/abs/2407.19906",
        "title": "Reverse Map Projections as Equivariant Quantum Embeddings",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce the novel class $(E_\u03b1)_{\u03b1\\in [-\\infty,1)}$ of reverse map projection embeddings, each one defining a unique new method of encoding classical data into quantum states. Inspired by well-known map projections from the unit sphere onto its tangent planes, used in practice in cartography, these embeddings address the common drawback of the amplitude embedding method, wherein scalar multiples of data points are identified and information about the norm of data is lost. We show how reverse map projections can be utilised as equivariant embeddings for quantum machine learning. Using these methods, we can leverage symmetries in classical datasets to significantly strengthen performance on quantum machine learning tasks. Finally, we select four values of $\u03b1$ with which to perform a simple classification task, taking $E_\u03b1$ as the embedding and experimenting with both equivariant and non-equivariant setups. We compare their results alongside those of standard amplitude embedding.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.ET",
            "math-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19916",
        "abstract url": "https://arxiv.org/abs/2407.19916",
        "title": "Aero-Nef: Neural Fields for Rapid Aircraft Aerodynamics Simulations",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a methodology to learn surrogate models of steady state fluid dynamics simulations on meshed domains, based on Implicit Neural Representations (INRs). The proposed models can be applied directly to unstructured domains for different flow conditions, handle non-parametric 3D geometric variations, and generalize to unseen shapes at test time. The coordinate-based formulation naturally leads to robustness with respect to discretization, allowing an excellent trade-off between computational cost (memory footprint and training time) and accuracy. The method is demonstrated on two industrially relevant applications: a RANS dataset of the two-dimensional compressible flow over a transonic airfoil and a dataset of the surface pressure distribution over 3D wings, including shape, inflow condition, and control surface deflection variations. On the considered test cases, our approach achieves a more than three times lower test error and significantly improves generalization error on unseen geometries compared to state-of-the-art Graph Neural Network architectures. Remarkably, the method can perform inference five order of magnitude faster than the high fidelity solver on the RANS transonic airfoil dataset. Code is available at https://gitlab.isae-supaero.fr/gi.catalani/aero-nepf",
        "subjects": [
            "cs.CE",
            "cs.LG",
            "math.NA",
            "physics.flu-dyn"
        ],
        "comment": "32 pages"
    },
    {
        "paper id": "2407.19937",
        "abstract url": "https://arxiv.org/abs/2407.19937",
        "title": "AOTree: Aspect Order Tree-based Model for Explainable Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent recommender systems aim to provide not only accurate recommendations but also explanations that help users understand them better. However, most existing explainable recommendations only consider the importance of content in reviews, such as words or aspects, and ignore the ordering relationship among them. This oversight neglects crucial ordering dimensions in the human decision-making process, leading to suboptimal performance. Therefore, in this paper, we propose Aspect Order Tree-based (AOTree) explainable recommendation method, inspired by the Order Effects Theory from cognitive and decision psychology, in order to capture the dependency relationships among decisive factors. We first validate the theory in the recommendation scenario by analyzing the reviews of the users. Then, according to the theory, the proposed AOTree expands the construction of the decision tree to capture aspect orders in users' decision-making processes, and use attention mechanisms to make predictions based on the aspect orders. Extensive experiments demonstrate our method's effectiveness on rating predictions, and our approach aligns more consistently with the user' s decision-making process by displaying explanations in a particular order, thereby enhancing interpretability.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20000",
        "abstract url": "https://arxiv.org/abs/2407.20000",
        "title": "Collision Probability Distribution Estimation via Temporal Difference Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "robotics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce CollisionPro, a pioneering framework designed to estimate cumulative collision probability distributions using temporal difference learning, specifically tailored to applications in robotics, with a particular emphasis on autonomous driving. This approach addresses the demand for explainable artificial intelligence (XAI) and seeks to overcome limitations imposed by model-based approaches and conservative constraints. We formulate our framework within the context of reinforcement learning to pave the way for safety-aware agents. Nevertheless, we assert that our approach could prove beneficial in various contexts, including a safety alert system or analytical purposes. A comprehensive examination of our framework is conducted using a realistic autonomous driving simulator, illustrating its high sample efficiency and reliable prediction capabilities for previously unseen collision events. The source code is publicly available.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Code: https://github.com/UniBwTAS/CollisionPro"
    },
    {
        "paper id": "2407.20003",
        "abstract url": "https://arxiv.org/abs/2407.20003",
        "title": "On the Effects of Irrelevant Variables in Treatment Effect Estimation with Deep Disentanglement",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Estimating treatment effects from observational data is paramount in healthcare, education, and economics, but current deep disentanglement-based methods to address selection bias are insufficiently handling irrelevant variables. We demonstrate in experiments that this leads to prediction errors. We disentangle pre-treatment variables with a deep embedding method and explicitly identify and represent irrelevant variables, additionally to instrumental, confounding and adjustment latent factors. To this end, we introduce a reconstruction objective and create an embedding space for irrelevant variables using an attached autoencoder. Instead of relying on serendipitous suppression of irrelevant variables as in previous deep disentanglement approaches, we explicitly force irrelevant variables into this embedding space and employ orthogonalization to prevent irrelevant information from leaking into the latent space representations of the other factors. Our experiments with synthetic and real-world benchmark datasets show that we can better identify irrelevant variables and more precisely predict treatment effects than previous methods, while prediction quality degrades less when additional irrelevant variables are introduced.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Paper is accepted at ECAI-2024"
    },
    {
        "paper id": "2407.20061",
        "abstract url": "https://arxiv.org/abs/2407.20061",
        "title": "Autonomous Bootstrapping of Quantum Dot Devices",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Semiconductor quantum dots (QD) are a promising platform for multiple different qubit implementations, all of which are voltage-controlled by programmable gate electrodes. However, as the QD arrays grow in size and complexity, tuning procedures that can fully autonomously handle the increasing number of control parameters are becoming essential for enabling scalability. We propose a bootstrapping algorithm for initializing a depletion mode QD device in preparation for subsequent phases of tuning. During bootstrapping, the QD device functionality is validated, all gates are characterized, and the QD charge sensor is made operational. We demonstrate the bootstrapping protocol in conjunction with a coarse tuning module, showing that the combined algorithm can efficiently and reliably take a cooled-down QD device to a desired global state configuration in under 8 minutes with a success rate of 96 %. Importantly, by following heuristic approaches to QD device initialization and combining the efficient ray-based measurement with the rapid radio-frequency reflectometry measurements, the proposed algorithm establishes a reference in terms of performance, reliability, and efficiency against which alternative algorithms can be benchmarked.",
        "subjects": [
            "cond-mat.mes-hall",
            "cs.ET",
            "cs.LG",
            "quant-ph"
        ],
        "comment": "9 pages, 3 figures, 1 table"
    },
    {
        "paper id": "2407.20121",
        "abstract url": "https://arxiv.org/abs/2407.20121",
        "title": "EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial",
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Cross-domain recommendation has attracted substantial interest in industrial apps such as Meituan, which serves multiple business domains via knowledge transfer and meets the diverse interests of users. However, existing methods typically follow an implicit modeling paradigm that blends the knowledge from both the source and target domains, and design intricate network structures to share learned embeddings or patterns between domains to improve recommendation accuracy. Since the transfer of interest signals is unsupervised, these implicit paradigms often struggle with the negative transfer resulting from differences in service functions and presentation forms across different domains. In this paper, we propose a simple and effective EXplicit Interest Transfer framework named EXIT to address the stated challenge. Specifically, we propose a novel label combination approach that enables the model to directly learn beneficial source domain interests through supervised learning, while excluding inappropriate interest signals. Moreover, we introduce a scene selector network to model the interest transfer intensity under fine-grained scenes. Offline experiments conducted on the industrial production dataset and online A/B tests validate the superiority and effectiveness of our proposed framework. Without complex network structures or training processes, EXIT can be easily deployed in the industrial recommendation system. EXIT has been successfully deployed in the online homepage recommendation system of Meituan App, serving the main traffic.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "Accepted at CIKM 2024"
    },
    {
        "paper id": "2407.20152",
        "abstract url": "https://arxiv.org/abs/2407.20152",
        "title": "Hierarchically Disentangled Recurrent Network for Factorizing System Dynamics of Multi-scale Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a knowledge-guided machine learning (KGML) framework for modeling multi-scale processes, and study its performance in the context of streamflow forecasting in hydrology. Specifically, we propose a novel hierarchical recurrent neural architecture that factorizes the system dynamics at multiple temporal scales and captures their interactions. This framework consists of an inverse and a forward model. The inverse model is used to empirically resolve the system's temporal modes from data (physical model simulations, observed data, or a combination of them from the past), and these states are then used in the forward model to predict streamflow. In a hydrological system, these modes can represent different processes, evolving at different temporal scales (e.g., slow: groundwater recharge and baseflow vs. fast: surface runoff due to extreme rainfall). A key advantage of our framework is that once trained, it can incorporate new observations into the model's context (internal state) without expensive optimization approaches (e.g., EnKF) that are traditionally used in physical sciences for data assimilation. Experiments with several river catchments from the NWS NCRFC region show the efficacy of this ML-based data assimilation framework compared to standard baselines, especially for basins that have a long history of observations. Even for basins that have a shorter observation history, we present two orthogonal strategies of training our FHNN framework: (a) using simulation data from imperfect simulations and (b) using observation data from multiple basins to build a global model. We show that both of these strategies (that can be used individually or together) are highly effective in mitigating the lack of training data. The improvement in forecast accuracy is particularly noteworthy for basins where local models perform poorly because of data sparsity.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20192",
        "abstract url": "https://arxiv.org/abs/2407.20192",
        "title": "Time series forecasting with high stakes: A field study of the air cargo industry",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Time series forecasting in the air cargo industry presents unique challenges due to volatile market dynamics and the significant impact of accurate forecasts on generated revenue. This paper explores a comprehensive approach to demand forecasting at the origin-destination (O\\&D) level, focusing on the development and implementation of machine learning models in decision-making for the air cargo industry. We leverage a mixture of experts framework, combining statistical and advanced deep learning models to provide reliable forecasts for cargo demand over a six-month horizon. The results demonstrate that our approach outperforms industry benchmarks, offering actionable insights for cargo capacity allocation and strategic decision-making in the air cargo industry. While this work is applied in the airline industry, the methodology is broadly applicable to any field where forecast-based decision-making in a volatile environment is crucial.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": "The 10th Mining and Learning from Time Series Workshop: From Classical Methods to LLMs. SIGKDD, Barcelona, Spain, 6 page"
    },
    {
        "paper id": "2407.20315",
        "abstract url": "https://arxiv.org/abs/2407.20315",
        "title": "Universal New Physics Latent Space",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop a machine learning method for mapping data originating from both Standard Model processes and various theories beyond the Standard Model into a unified representation (latent) space while conserving information about the relationship between the underlying theories. We apply our method to three examples of new physics at the LHC of increasing complexity, showing that models can be clustered according to their LHC phenomenology: different models are mapped to distinct regions in latent space, while indistinguishable models are mapped to the same region. This opens interesting new avenues on several fronts, such as model discrimination, selection of representative benchmark scenarios, and identifying gaps in the coverage of model space.",
        "subjects": [
            "hep-ph",
            "cs.LG",
            "hep-ex",
            "physics.data-an"
        ],
        "comment": "25 pages, 17 figures"
    },
    {
        "paper id": "2407.20352",
        "abstract url": "https://arxiv.org/abs/2407.20352",
        "title": "Designing Time-Series Models With Hypernetworks & Adversarial Portfolios",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This article describes the methods that achieved 4th and 6th place in the forecasting and investment challenges, respectively, of the M6 competition, ultimately securing the 1st place in the overall duathlon ranking. In the forecasting challenge, we tested a novel meta-learning model that utilizes hypernetworks to design a parametric model tailored to a specific family of forecasting tasks. This approach allowed us to leverage similarities observed across individual forecasting tasks while also acknowledging potential heterogeneity in their data generating processes. The model's training can be directly performed with backpropagation, eliminating the need for reliance on higher-order derivatives and is equivalent to a simultaneous search over the space of parametric functions and their optimal parameter values. The proposed model's capabilities extend beyond M6, demonstrating superiority over state-of-the-art meta-learning methods in the sinusoidal regression task and outperforming conventional parametric models on time-series from the M4 competition. In the investment challenge, we adjusted portfolio weights to induce greater or smaller correlation between our submission and that of other participants, depending on the current ranking, aiming to maximize the probability of achieving a good rank.",
        "subjects": [
            "cs.LG",
            "q-fin.PM",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20383",
        "abstract url": "https://arxiv.org/abs/2407.20383",
        "title": "Appraisal-Guided Proximal Policy Optimization: Modeling Psychological Disorders in Dynamic Grid World",
        "rating": "-1.5",
        "keywords": [
            [
                "Psychological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The integration of artificial intelligence across multiple domains has emphasized the importance of replicating human-like cognitive processes in AI. By incorporating emotional intelligence into AI agents, their emotional stability can be evaluated to enhance their resilience and dependability in critical decision-making tasks. In this work, we develop a methodology for modeling psychological disorders using Reinforcement Learning (RL) agents. We utilized Appraisal theory to train RL agents in a dynamic grid world environment with an Appraisal-Guided Proximal Policy Optimization (AG-PPO) algorithm. Additionally, we investigated numerous reward-shaping strategies to simulate psychological disorders and regulate the behavior of the agents. A comparison of various configurations of the modified PPO algorithm identified variants that simulate Anxiety disorder and Obsessive-Compulsive Disorder (OCD)-like behavior in agents. Furthermore, we compared standard PPO with AG-PPO and its configurations, highlighting the performance improvement in terms of generalization capabilities. Finally, we conducted an analysis of the agents' behavioral patterns in complex test environments to evaluate the associated symptoms corresponding to the psychological disorders. Overall, our work showcases the benefits of the appraisal-guided PPO algorithm over the standard PPO algorithm and the potential to simulate psychological disorders in a controlled artificial environment and evaluate them on RL agents.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20471",
        "abstract url": "https://arxiv.org/abs/2407.20471",
        "title": "Relaxed Equivariant Graph Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "3D Euclidean symmetry equivariant neural networks have demonstrated notable success in modeling complex physical systems. We introduce a framework for relaxed $E(3)$ graph equivariant neural networks that can learn and represent symmetry breaking within continuous groups. Building on the existing e3nn framework, we propose the use of relaxed weights to allow for controlled symmetry breaking. We show empirically that these relaxed weights learn the correct amount of symmetry breaking.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Extended abstract presented at the Geometry-grounded Representation Learning and Generative Modeling Workshop (GRaM) at the 41st International Conference on Machine Learning, July 2024, Vienna, Austria"
    },
    {
        "paper id": "2407.20503",
        "abstract url": "https://arxiv.org/abs/2407.20503",
        "title": "A federated large language model for long-term time series forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Long-term time series forecasting in centralized environments poses unique challenges regarding data privacy, communication overhead, and scalability. To address these challenges, we propose FedTime, a federated large language model (LLM) tailored for long-range time series prediction. Specifically, we introduce a federated pre-trained LLM with fine-tuning and alignment strategies. Prior to the learning process, we employ K-means clustering to partition edge devices or clients into distinct clusters, thereby facilitating more focused model training. We also incorporate channel independence and patching to better preserve local semantic information, ensuring that important contextual details are retained while minimizing the risk of information loss. We demonstrate the effectiveness of our FedTime model through extensive experiments on various real-world forecasting benchmarks, showcasing substantial improvements over recent approaches. In addition, we demonstrate the efficiency of FedTime in streamlining resource usage, resulting in reduced communication overhead.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20508",
        "abstract url": "https://arxiv.org/abs/2407.20508",
        "title": "Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies",
        "rating": "-1.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "biological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, spiking neural networks (SNNs) have attracted substantial interest due to their potential to replicate the energy-efficient and event-driven processing of biological neurons. Despite this, the application of SNNs in graph representation learning, particularly for non-Euclidean data, remains underexplored, and the influence of spiking dynamics on graph learning is not yet fully understood. This work seeks to address these gaps by examining the unique properties and benefits of spiking dynamics in enhancing graph representation learning. We propose a spike-based graph neural network model that incorporates spiking dynamics, enhanced by a novel spatial-temporal feature normalization (STFN) technique, to improve training efficiency and model stability. Our detailed analysis explores the impact of rate coding and temporal coding on SNN performance, offering new insights into their advantages for deep graph networks and addressing challenges such as the oversmoothing problem. Experimental results demonstrate that our SNN models can achieve competitive performance with state-of-the-art graph neural networks (GNNs) while considerably reducing computational costs, highlighting the potential of SNNs for efficient neuromorphic computing applications in complex graph-based scenarios.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20519",
        "abstract url": "https://arxiv.org/abs/2407.20519",
        "title": "DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Affective brain-computer interfaces (aBCIs) are increasingly recognized for their potential in monitoring and interpreting emotional states through electroencephalography (EEG) signals. Current EEG-based emotion recognition methods perform well with short segments of EEG data. However, these methods encounter significant challenges in real-life scenarios where emotional states evolve over extended periods. To address this issue, we propose a Dual Attentive (DuA) transformer framework for long-term continuous EEG emotion analysis. Unlike segment-based approaches, the DuA transformer processes an entire EEG trial as a whole, identifying emotions at the trial level, referred to as trial-based emotion analysis. This framework is designed to adapt to varying signal lengths, providing a substantial advantage over traditional methods. The DuA transformer incorporates three key modules: the spatial-spectral network module, the temporal network module, and the transfer learning module. The spatial-spectral network module simultaneously captures spatial and spectral information from EEG signals, while the temporal network module detects temporal dependencies within long-term EEG data. The transfer learning module enhances the model's adaptability across different subjects and conditions. We extensively evaluate the DuA transformer using a self-constructed long-term EEG emotion database, along with two benchmark EEG emotion databases. On the basis of the trial-based leave-one-subject-out cross-subject cross-validation protocol, our experimental results demonstrate that the proposed DuA transformer significantly outperforms existing methods in long-term continuous EEG emotion analysis, with an average enhancement of 5.28%.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "11 pages, 3 figures"
    },
    {
        "paper id": "2407.19708",
        "abstract url": "https://arxiv.org/abs/2407.19708",
        "title": "ALEN: A Dual-Approach for Uniform and Non-Uniform Low-Light Image Enhancement",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Low-light image enhancement is an important task in computer vision, essential for improving the visibility and quality of images captured in non-optimal lighting conditions. Inadequate illumination can lead to significant information loss and poor image quality, impacting various applications such as surveillance. photography, or even autonomous driving. In this regard, automated methods have been developed to automatically adjust illumination in the image for a better visual perception. Current enhancement techniques often use specific datasets to enhance low-light images, but still present challenges when adapting to diverse real-world conditions, where illumination degradation may be localized to specific regions. To address this challenge, the Adaptive Light Enhancement Network (ALEN) is introduced, whose main approach is the use of a classification mechanism to determine whether local or global illumination enhancement is required. Subsequently, estimator networks adjust illumination based on this classification and simultaneously enhance color fidelity. ALEN integrates the Light Classification Network (LCNet) for illuminance categorization, complemented by the Single-Channel Network (SCNet), and Multi-Channel Network (MCNet) for precise estimation of illumination and color, respectively. Extensive experiments on publicly available datasets for low-light conditions were carried out to underscore ALEN's robust generalization capabilities, demonstrating superior performance in both quantitative metrics and qualitative assessments when compared to recent state-of-the-art methods. The ALEN not only enhances image quality in terms of visual perception but also represents an advancement in high-level vision tasks, such as semantic segmentation, as presented in this work. The code of this method is available at https://github.com/xingyumex/ALEN.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19714",
        "abstract url": "https://arxiv.org/abs/2407.19714",
        "title": "Rethinking RGB-D Fusion for Semantic Segmentation in Surgical Datasets",
        "rating": "-2",
        "keywords": [
            [
                "RGB-D",
                "depth"
            ],
            [
                "Surgical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Surgical scene understanding is a key technical component for enabling intelligent and context aware systems that can transform various aspects of surgical interventions. In this work, we focus on the semantic segmentation task, propose a simple yet effective multi-modal (RGB and depth) training framework called SurgDepth, and show state-of-the-art (SOTA) results on all publicly available datasets applicable for this task. Unlike previous approaches, which either fine-tune SOTA segmentation models trained on natural images, or encode RGB or RGB-D information using RGB only pre-trained backbones, SurgDepth, which is built on top of Vision Transformers (ViTs), is designed to encode both RGB and depth information through a simple fusion mechanism. We conduct extensive experiments on benchmark datasets including EndoVis2022, AutoLapro, LapI2I and EndoVis2017 to verify the efficacy of SurgDepth. Specifically, SurgDepth achieves a new SOTA IoU of 0.86 on EndoVis 2022 SAR-RARP50 challenge and outperforms the current best method by at least 4%, using a shallow and compute efficient decoder consisting of ConvNeXt blocks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19718",
        "abstract url": "https://arxiv.org/abs/2407.19718",
        "title": "Robust Beamforming Design for Integrated Satellite-Terrestrial Maritime Communications in the Presence of Wave Fluctuation",
        "rating": "-2",
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "In order to provide wireless services for wide sea area, this paper designs an integrated satellite-terrestrial maritime communication framework. Specifically, the terrestrial base station (TBS) serves near-shore users, while the low earth orbit (LEO) satellite communicates with off-shore users. We aim to improve the overall performance of integrated satellite-terrestrial maritime communication system. Thus, it makes sense to jointly optimize transmit beamforming at the TBS and LEO satellite. Due to sea wave fluctuation, the obtained channel state information (CSI) is often imperfect. In this context, a robust beamforming design algorithm is proposed with the goal of minimizing the total power consumption of integrated satellite-terrestrial maritime communication system while satisfying quality of service (QoS) requirements. Both theoretical analysis and simulation results confirm the effectiveness of proposed algorithm in maritime communications.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "12 pages, 10 figures"
    },
    {
        "paper id": "2407.19724",
        "abstract url": "https://arxiv.org/abs/2407.19724",
        "title": "Constructing artificial life and materials scientists with accelerated AI using Deep AndersoNN",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Deep AndersoNN accelerates AI by exploiting the continuum limit as the number of explicit layers in a neural network approaches infinity and can be taken as a single implicit layer, known as a deep equilibrium model. Solving for deep equilibrium model parameters reduces to a nonlinear fixed point iteration problem, enabling the use of vector-to-vector iterative solvers and windowing techniques, such as Anderson extrapolation, for accelerating convergence to the fixed point deep equilibrium. Here we show that Deep AndersoNN achieves up to an order of magnitude of speed-up in training and inference. The method is demonstrated on density functional theory results for industrial applications by constructing artificial life and materials `scientists' capable of classifying drugs as strongly or weakly polar, metal-organic frameworks by pore size, and crystalline materials as metals, semiconductors, and insulators, using graph images of node-neighbor representations transformed from atom-bond networks. Results exhibit accuracy up to 98\\% and showcase synergy between Deep AndersoNN and machine learning capabilities of modern computing architectures, such as GPUs, for accelerated computational life and materials science by quickly identifying structure-property relationships. This paves the way for saving up to 90\\% of compute required for AI, reducing its carbon footprint by up to 60 gigatons per year by 2030, and scaling above memory limits of explicit neural networks in life and materials science, and beyond.",
        "subjects": [
            "cs.LG",
            "physics.app-ph"
        ],
        "comment": "7 pages, 5 figures, 2 tables, Accepted by ICML ML4LMS https://openreview.net/forum?id=qhwyvhqAvI . International Conference on Machine Learning (ICML). Machine Learning for Life and Material Science (ML4LMS) Workshop, May 2024"
    },
    {
        "paper id": "2407.19727",
        "abstract url": "https://arxiv.org/abs/2407.19727",
        "title": "Adaptive Utilization of Cross-scenario Information for Multi-scenario Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recommender system of the e-commerce platform usually serves multiple business scenarios. Multi-scenario Recommendation (MSR) is an important topic that improves ranking performance by leveraging information from different scenarios. Recent methods for MSR mostly construct scenario shared or specific modules to model commonalities and differences among scenarios. However, when the amount of data among scenarios is skewed or data in some scenarios is extremely sparse, it is difficult to learn scenario-specific parameters well. Besides, simple sharing of information from other scenarios may result in a negative transfer. In this paper, we propose a unified model named Cross-Scenario Information Interaction (CSII) to serve all scenarios by a mixture of scenario-dominated experts. Specifically, we propose a novel method to select highly transferable features in data instances. Then, we propose an attention-based aggregator module, which can adaptively extract relative knowledge from cross-scenario. Experiments on the production dataset verify the superiority of our method. Online A/B test in Meituan Waimai APP also shows a significant performance gain, leading to an average improvement in GMV (Gross Merchandise Value) of 1.0% for overall scenarios.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19739",
        "abstract url": "https://arxiv.org/abs/2407.19739",
        "title": "Nomadic Non-Public Networks for 6G: Use Cases and Key Performance Indicators",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "The landscape of wireless communication systems is evolving rapidly, with a pivotal role envisioned for dynamic network structures and self-organizing networks in upcoming technologies like the 6G mobile communications standard. This evolution is fueled by the growing demand from diverse sectors, including industry, manufacturing, agriculture, and the public sector, each with increasingly specific requirements. The establishment of non-public networks in the current 5G standard has laid a foundation, enabling independent operation within certain frequencies and local limitations, notably for Internet of Things applications. This paper explores the progression from non-public networks to nomadic non-public networks and their significance in the context of the forthcoming 6G era. Building on existing work in dynamic network structures, non-public networks regulations, and alternative technological solutions, this paper introduces specific use cases enhanced by nomadic networks. In addition, relevant Key Performance Indicators are discussed on the basis of the presented use cases. These serve as a starting point for the definition of requirement clusters and thus for a evaluation metric of nomadic non-public networks. This work lays the groundwork for understanding the potential of nomadic non-public networks in the dynamic landscape of 6G wireless communication systems.",
        "subjects": [
            "cs.NI",
            "cs.ET"
        ],
        "comment": "8 pages, 1 figure"
    },
    {
        "paper id": "2407.19763",
        "abstract url": "https://arxiv.org/abs/2407.19763",
        "title": "TeleOR: Real-time Telemedicine System for Full-Scene Operating Room",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "surgical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The advent of telemedicine represents a transformative development in leveraging technology to extend the reach of specialized medical expertise to remote surgeries, a field where the immediacy of expert guidance is paramount. However, the intricate dynamics of Operating Room (OR) scene pose unique challenges for telemedicine, particularly in achieving high-fidelity, real-time scene reconstruction and transmission amidst obstructions and bandwidth limitations. This paper introduces TeleOR, a pioneering system designed to address these challenges through real-time OR scene reconstruction for Tele-intervention. TeleOR distinguishes itself with three innovative approaches: dynamic self-calibration, which leverages inherent scene features for calibration without the need for preset markers, allowing for obstacle avoidance and real-time camera adjustment; selective OR reconstruction, focusing on dynamically changing scene segments to reduce reconstruction complexity; and viewport-adaptive transmission, optimizing data transmission based on real-time client feedback to efficiently deliver high-quality 3D reconstructions within bandwidth constraints. Comprehensive experiments on the 4D-OR surgical scene dataset demostrate the superiority and applicability of TeleOR, illuminating the potential to revolutionize tele-interventions by overcoming the spatial and technical barriers inherent in remote surgical guidance.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19768",
        "abstract url": "https://arxiv.org/abs/2407.19768",
        "title": "Efficient Face Super-Resolution via Wavelet-based Feature Enhancement Network",
        "rating": "-2",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Face super-resolution aims to reconstruct a high-resolution face image from a low-resolution face image. Previous methods typically employ an encoder-decoder structure to extract facial structural features, where the direct downsampling inevitably introduces distortions, especially to high-frequency features such as edges. To address this issue, we propose a wavelet-based feature enhancement network, which mitigates feature distortion by losslessly decomposing the input feature into high and low-frequency components using the wavelet transform and processing them separately. To improve the efficiency of facial feature extraction, a full domain Transformer is further proposed to enhance local, regional, and global facial features. Such designs allow our method to perform better without stacking many modules as previous methods did. Experiments show that our method effectively balances performance, model size, and speed. Code link: https://github.com/PRIS-CV/WFEN.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19826",
        "abstract url": "https://arxiv.org/abs/2407.19826",
        "title": "Design and Control of a Novel Six-Degree-of-Freedom Hybrid Robotic Arm",
        "rating": "-2",
        "keywords": [
            [
                "agricultural"
            ]
        ],
        "abstract": "Robotic arms are key components in fruit-harvesting robots. In agricultural settings, conventional serial or parallel robotic arms often fall short in meeting the demands for a large workspace, rapid movement, enhanced capability of obstacle avoidance and affordability. This study proposes a novel hybrid six-degree-of-freedom (DoF) robotic arm that combines the advantages of parallel and serial mechanisms. Inspired by yoga, we designed two sliders capable of moving independently along a single rail, acting as two feet. These sliders are interconnected with linkages and a meshed-gear set, allowing the parallel mechanism to lower itself and perform a split to pass under obstacles. This unique feature allows the arm to avoid obstacles such as pipes, tables and beams typically found in greenhouses. Integrated with serially mounted joints, the patented hybrid arm is able to maintain the end's pose even when it moves with a mobile platform, facilitating fruit picking with the optimal pose in dynamic conditions. Moreover, the hybrid arm's workspace is substantially larger, being almost three times the volume of UR3 serial arms and fourteen times that of the ABB IRB parallel arms. Experiments show that the repeatability errors are 0.017 mm, 0.03 mm and 0.109 mm for the two sliders and the arm's end, respectively, providing sufficient precision for agricultural robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted by IROS 2024"
    },
    {
        "paper id": "2407.19841",
        "abstract url": "https://arxiv.org/abs/2407.19841",
        "title": "RRAM-Based Bio-Inspired Circuits for Mobile Epileptic Correlation Extraction and Seizure Prediction",
        "rating": "-2",
        "keywords": [
            [
                "Bio-Inspired",
                "EEG"
            ]
        ],
        "abstract": "Non-invasive mobile electroencephalography (EEG) acquisition systems have been utilized for long-term monitoring of seizures, yet they suffer from limited battery life. Resistive random access memory (RRAM) is widely used in computing-in-memory(CIM) systems, which offers an ideal platform for reducing the computational energy consumption of seizure prediction algorithms, potentially solving the endurance issues of mobile EEG systems. To address this challenge, inspired by neuronal mechanisms, we propose a RRAM-based bio-inspired circuit system for correlation feature extraction and seizure prediction. This system achieves a high average sensitivity of 91.2% and a low false positive rate per hour (FPR/h) of 0.11 on the CHB-MIT seizure dataset. The chip under simulation demonstrates an area of approximately 0.83 mm2 and a latency of 62.2 \u03bcs. Power consumption is recorded at 24.4 mW during the feature extraction phase and 19.01 mW in the seizure prediction phase, with a cumulative energy consumption of 1.515 \u03bcJ for a 3-second window data processing, predicting 29.2 minutes ahead. This method exhibits an 81.3% reduction in computational energy relative to the most efficient existing seizure prediction approaches, establishing a new benchmark for energy efficiency.",
        "subjects": [
            "eess.SP",
            "cs.AR"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2407.19842",
        "abstract url": "https://arxiv.org/abs/2407.19842",
        "title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "healthcare"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the application of LLMs across a wide range of contexts. However, neural networks in general, and LLMs in particular, are known to be vulnerable to adversarial attacks, where an imperceptible change to the input can mislead the output of the model. This is a serious concern that impedes the use of LLMs on high-stakes applications, such as healthcare, where a wrong prediction can imply serious consequences. Even though there are many efforts on making LLMs more robust to adversarial attacks, there are almost no works that study \\emph{how} and \\emph{where} these vulnerabilities that make LLMs prone to adversarial attacks happen. Motivated by these facts, we explore how to localize and understand vulnerabilities, and propose a method, based on Mechanistic Interpretability (MI) techniques, to guide this process. Specifically, this method enables us to detect vulnerabilities related to a concrete task by (i) obtaining the subset of the model that is responsible for that task, (ii) generating adversarial samples for that task, and (iii) using MI techniques together with the previous samples to discover and understand the possible vulnerabilities. We showcase our method on a pretrained GPT-2 Small model carrying out the task of predicting 3-letter acronyms to demonstrate its effectiveness on locating and understanding concrete vulnerabilities of the model.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19847",
        "abstract url": "https://arxiv.org/abs/2407.19847",
        "title": "Brain-inspired polymer dendrite networks for morphology-dependent computing hardware",
        "rating": "-2",
        "keywords": [
            [
                "bio-inspired"
            ]
        ],
        "abstract": "Variability has always been a challenge to mitigate in electronics. This especially holds true for organic semiconductors, where reproducibility and long-term stability concerns hinder industrialization. By relying on a bio-inspired computing paradigm, we show that AC-electropolymerization is a powerful platform for the development of morphology-dependent computing hardware. Our findings reveal that electropolymerized polymer dendrite networks exhibit a complex relationship between structure and operation that allows them to implement nearly linear to nonlinear functions depending on the complexity of their structure. Moreover, dendritic networks can integrate a limitless number of inputs from their environment, for which their unique morphologies induce specific patterns in the dynamic encoding of the network's output. We demonstrate that this property can be used to our advantage in the context of in materio computing to discriminate between different spatiotemporal inputs. These results show how, due to its inherent stochasticity, electropolymerization is a pivotal technique for the bottom-up implementation of computationally powerful objects. We anticipate this study will help shifting the negative perception of variability in the material science community and promote the electropolymerization framework as a foundation for the development of a new generation of hardware defined by its topological richness.",
        "subjects": [
            "cs.ET",
            "physics.app-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19859",
        "abstract url": "https://arxiv.org/abs/2407.19859",
        "title": "ProRuka: A highly efficient HMI algorithm for controlling a novel prosthetic hand with 6-DOF using sonomyography",
        "rating": "-2",
        "keywords": [
            [
                "6-DOF"
            ],
            [
                "support vector machine"
            ]
        ],
        "abstract": "Sonomyography (SMG) is a novel human-machine interface that controls upper-limb prostheses by monitoring forearm muscle activity using ultrasonic imaging. SMG has been investigated for controlling upper-limb prostheses during the last two decades. The results show that this method, in combination with artificial intelligence, can classify different hand gestures with an accuracy of more than 90%, making it a great alternative control system compared to electromyography (EMG). However, up to now there are few reports of a system integrating SMG together with a prosthesis for testing on amputee subjects to demonstrate its capability in relation to daily activities. In this study, we developed ProRuka, a novel low-cost 6-degree-of-freedom prosthetic hand integrated with the control provided by a SMG system with a wearable ultrasound imaging probe. The classification of hand gestures using different machine learning classification/regression algorithms including KNN, nearest neighbor regression, random forest, decision tree classifier, decision tree regression, support vector regression and support vector machine in combination with a transfer learning model (VGG16) was first evaluated off-line to determine its reliability and precision. Additionally, the developed controlling system were evaluated on two amputees, in real-time experiments using a variety of hand function test kits. The results from an off-line study including ten healthy participants indicated that nine different hand motions can be classified with a success rate of 100%. In addition, the hand function test in real time (using 4 different hand gestures) confirmed that the designed prosthesis with the SMG controlling system can assist amputees to perform a variety of hand movements needed in daily activities.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19877",
        "abstract url": "https://arxiv.org/abs/2407.19877",
        "title": "Language-driven Grasp Detection with Mask-guided Attention",
        "rating": "-2",
        "keywords": [
            [
                "robotics"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Grasp detection is an essential task in robotics with various industrial applications. However, traditional methods often struggle with occlusions and do not utilize language for grasping. Incorporating natural language into grasp detection remains a challenging task and largely unexplored. To address this gap, we propose a new method for language-driven grasp detection with mask-guided attention by utilizing the transformer attention mechanism with semantic segmentation features. Our approach integrates visual data, segmentation mask features, and natural language instructions, significantly improving grasp detection accuracy. Our work introduces a new framework for language-driven grasp detection, paving the way for language-driven robotic applications. Intensive experiments show that our method outperforms other recent baselines by a clear margin, with a 10.0% success score improvement. We further validate our method in real-world robotic experiments, confirming the effectiveness of our approach.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Accepted at IROS 2024"
    },
    {
        "paper id": "2407.19907",
        "abstract url": "https://arxiv.org/abs/2407.19907",
        "title": "Neural Control Barrier Functions for Safe Navigation",
        "rating": "-2",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "robot",
                "Navigation"
            ]
        ],
        "abstract": "Autonomous robot navigation can be particularly demanding, especially when the surrounding environment is not known and safety of the robot is crucial. This work relates to the synthesis of Control Barrier Functions (CBFs) through data for safe navigation in unknown environments. A novel methodology to jointly learn CBFs and corresponding safe controllers, in simulation, inspired by the State Dependent Riccati Equation (SDRE) is proposed. The CBF is used to obtain admissible commands from any nominal, possibly unsafe controller. An approach to apply the CBF inside a safety filter without the need for a consistent map or position estimate is developed. Subsequently, the resulting reactive safety filter is deployed on a multirotor platform integrating a LiDAR sensor both in simulation and real-world experiments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for presentation at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2024"
    },
    {
        "paper id": "2407.19938",
        "abstract url": "https://arxiv.org/abs/2407.19938",
        "title": "Robust Conformal Volume Estimation in 3D Medical Images",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "surgery"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Volumetry is one of the principal downstream applications of 3D medical image segmentation, for example, to detect abnormal tissue growth or for surgery planning. Conformal Prediction is a promising framework for uncertainty quantification, providing calibrated predictive intervals associated with automatic volume measurements. However, this methodology is based on the hypothesis that calibration and test samples are exchangeable, an assumption that is in practice often violated in medical image applications. A weighted formulation of Conformal Prediction can be framed to mitigate this issue, but its empirical investigation in the medical domain is still lacking. A potential reason is that it relies on the estimation of the density ratio between the calibration and test distributions, which is likely to be intractable in scenarios involving high-dimensional data. To circumvent this, we propose an efficient approach for density ratio estimation relying on the compressed latent representations generated by the segmentation model. Our experiments demonstrate the efficiency of our approach to reduce the coverage error in the presence of covariate shifts, in both synthetic and real-world settings. Our implementation is available at https://github.com/benolmbrt/wcp_miccai",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Early accepted at MICCAI 2024"
    },
    {
        "paper id": "2407.19979",
        "abstract url": "https://arxiv.org/abs/2407.19979",
        "title": "Private and Secure Fuzzy Name Matching",
        "rating": "-2",
        "keywords": [
            [
                "crime"
            ]
        ],
        "abstract": "Modern financial institutions rely on data for many operations, including a need to drive efficiency, enhance services and prevent financial crime. Data sharing across an organisation or between institutions can facilitate rapid, evidence-based decision making, including identifying money laundering and fraud. However, data privacy regulations impose restrictions on data sharing. Privacy-enhancing technologies are being increasingly employed to allow organisations to derive shared intelligence while ensuring regulatory compliance. This paper examines the case in which regulatory restrictions mean a party cannot share data on accounts of interest with another (internal or external) party to identify people that hold an account in each dataset. We observe that the names of account holders may be recorded differently in each data set. We introduce a novel privacy-preserving approach for fuzzy name matching across institutions, employing fully homomorphic encryption with locality-sensitive hashing. The efficiency of the approach is enhanced using a clustering mechanism. The practicality and effectiveness of the proposed approach are evaluated using different datasets. Experimental results demonstrate it takes around 100 and 1000 seconds to search 1000 names from 10k and 100k names, respectively. Moreover, the proposed approach exhibits significant improvement in reducing communication overhead by 30-300 times, using clustering.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2407.19987",
        "abstract url": "https://arxiv.org/abs/2407.19987",
        "title": "HOBOTAN: Efficient Higher Order Binary Optimization Solver with Tensor Networks and PyTorch",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "In this study, we introduce HOBOTAN, a new solver designed for Higher Order Binary Optimization (HOBO). HOBOTAN supports both CPU and GPU, with the GPU version developed based on PyTorch, offering a fast and scalable system. This solver utilizes tensor networks to solve combinatorial optimization problems, employing a HOBO tensor that maps the problem and performs tensor contractions as needed. Additionally, by combining techniques such as batch processing for tensor optimization and binary-based integer encoding, we significantly enhance the efficiency of combinatorial optimization. In the future, the utilization of increased GPU numbers is expected to harness greater computational power, enabling efficient collaboration between multiple GPUs for high scalability. Moreover, HOBOTAN is designed within the framework of quantum computing, thus providing insights for future quantum computer applications. This paper details the design, implementation, performance evaluation, and scalability of HOBOTAN, demonstrating its effectiveness.",
        "subjects": [
            "cs.MS",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20026",
        "abstract url": "https://arxiv.org/abs/2407.20026",
        "title": "JAX-SSO: Differentiable Finite Element Analysis Solver for Structural Optimization and Seamless Integration with Neural Networks",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Differentiable numerical simulations of physical systems have gained rising attention in the past few years with the development of automatic differentiation tools. This paper presents JAX-SSO, a differentiable finite element analysis solver built with JAX, Google's high-performance computing library, to assist efficient structural design in the built environment. With the adjoint method and automatic differentiation feature, JAX-SSO can efficiently evaluate gradients of physical quantities in an automatic way, enabling accurate sensitivity calculation in structural optimization problems. Written in Python and JAX, JAX-SSO is naturally within the machine learning ecosystem so it can be seamlessly integrated with neural networks to train machine learning models with inclusion of physics. Moreover, JAX-SSO supports GPU acceleration to further boost finite element analysis. Several examples are presented to showcase the capabilities and efficiency of JAX-SSO: i) shape optimization of grid-shells and continuous shells; ii) size (thickness) optimization of continuous shells; iii) simultaneous shape and topology optimization of continuous shells; and iv) training of physics-informed neural networks for structural optimization. We believe that JAX-SSO can facilitate research related to differentiable physics and machine learning to further address problems in structural and architectural design.",
        "subjects": [
            "cs.MS",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20041",
        "abstract url": "https://arxiv.org/abs/2407.20041",
        "title": "Counterfactual rewards promote collective transport using individually controlled swarm microrobots",
        "rating": "-2",
        "keywords": [
            [
                "thermal"
            ]
        ],
        "abstract": "Swarm robots offer fascinating opportunities to perform complex tasks beyond the capabilities of individual machines. Just as a swarm of ants collectively moves a large object, similar functions can emerge within a group of robots through individual strategies based on local sensing. However, realizing collective functions with individually controlled microrobots is particularly challenging due to their micrometer size, large number of degrees of freedom, strong thermal noise relative to the propulsion speed, complex physical coupling between neighboring microrobots, and surface collisions. Here, we implement Multi-Agent Reinforcement Learning (MARL) to generate a control strategy for up to 200 microrobots whose motions are individually controlled by laser spots. During the learning process, we employ so-called counterfactual rewards that automatically assign credit to the individual microrobots, which allows for fast and unbiased training. With the help of this efficient reward scheme, swarm microrobots learn to collectively transport a large cargo object to an arbitrary position and orientation, similar to ant swarms. We demonstrate that this flexible and versatile swarm robotic system is robust to variations in group size, the presence of malfunctioning units, and environmental noise. Such control strategies can potentially enable complex and automated assembly of mobile micromachines, programmable drug delivery capsules, and other advanced lab-on-a-chip applications.",
        "subjects": [
            "cs.RO",
            "cond-mat.soft"
        ],
        "comment": "40 pages, 15 figures"
    },
    {
        "paper id": "2407.20089",
        "abstract url": "https://arxiv.org/abs/2407.20089",
        "title": "Performance Study of Various Relay Nodes in 5G Wireless Network",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "This paper studies performance of various types of relay nodes in a 5G wireless network: conventional amplify-forward repeaters, (semi-)smart/smart amplify-forward repeaters with different levels of side information, and half-duplex/full-duplex decode-forward relay nodes with and without spatial reuse. End-to-end effective signal to interference and noise ratios (SINRs) and achievable rates are derived for these different types of relay nodes. Performance and complexity tradeoffs are discussed with a simulation over a Manhattan topology setting. Over-the-air (OTA) test results corroborates the findings in this paper.",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": "Presented in IEEE ICC 2024 Industry workshop"
    },
    {
        "paper id": "2407.20135",
        "abstract url": "https://arxiv.org/abs/2407.20135",
        "title": "Trade-offs in Reliability and Performance Using Selective Beamforming for Ultra-Massive MIMO",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "This paper addresses the optimisation challenges in Ultra-Massive MIMO communication systems, focusing on array selection and beamforming in dynamic and diverse operational contexts. We introduce a novel array selection criterion that incorporates antenna health information into the optimisation process, distinguishing our approach from traditional methods. Our methodology employs dual proximal-gradient ascent to effectively tackle the constrained non-convex and non-smooth nature of sparse array selection problems. A central feature of our strategy is the implementation of proportional fairness among communication users, aligning with system resource limitations while ensuring minimum rate requirements for all users. This approach not only enhances system efficiency and responsiveness but also ensures equitable resource distribution. Extensive simulations validate the effectiveness of the proposed solutions in optimising Ultra-Massive MIMO system performance, demonstrating their applicability in complex communication scenarios. Our findings reveal key trade-offs influenced by the sparsity promotion weight (\u03b3). As \u03b3 increases, spectral efficiency (SE) and communication rate (Ri) decrease, while beamforming matrix density (BMD) reduces and antenna reliability (RL) significantly improves. These results highlight the critical balance between performance and reliability, essential for the practical deployment of Ultra-Massive MIMO systems. This work advances the field by providing innovative solutions and new insights into array selection and beamforming optimization, setting a foundation for future research in Ultra-Massive MIMO communication systems.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20156",
        "abstract url": "https://arxiv.org/abs/2407.20156",
        "title": "Autonomous and Teleoperation Control of a Drawing Robot Avatar",
        "rating": "-2",
        "keywords": [
            [
                "Avatar"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "A drawing robot avatar is a robotic system that allows for telepresence-based drawing, enabling users to remotely control a robotic arm and create drawings in real-time from a remote location. The proposed control framework aims to improve bimanual robot telepresence quality by reducing the user workload and required prior knowledge through the automation of secondary or auxiliary tasks. The introduced novel method calculates the near-optimal Cartesian end-effector pose in terms of visual feedback quality for the attached eye-to-hand camera with motion constraints in consideration. The effectiveness is demonstrated by conducting user studies of drawing reference shapes using the implemented robot avatar compared to stationary and teleoperated camera pose conditions. Our results demonstrate that the proposed control framework offers improved visual feedback quality and drawing performance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to ICRA 2024"
    },
    {
        "paper id": "2407.20172",
        "abstract url": "https://arxiv.org/abs/2407.20172",
        "title": "LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "GAN"
            ],
            [
                "Diagnosis"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Histological artifacts pose challenges for both pathologists and Computer-Aided Diagnosis (CAD) systems, leading to errors in analysis. Current approaches for histological artifact restoration, based on Generative Adversarial Networks (GANs) and pixel-level Diffusion Models, suffer from performance limitations and computational inefficiencies. In this paper, we propose a novel framework, LatentArtiFusion, which leverages the latent diffusion model (LDM) to reconstruct histological artifacts with high performance and computational efficiency. Unlike traditional pixel-level diffusion frameworks, LatentArtiFusion executes the restoration process in a lower-dimensional latent space, significantly improving computational efficiency. Moreover, we introduce a novel regional artifact reconstruction algorithm in latent space to prevent mistransfer in non-artifact regions, distinguishing our approach from GAN-based methods. Through extensive experiments on real-world histology datasets, LatentArtiFusion demonstrates remarkable speed, outperforming state-of-the-art pixel-level diffusion frameworks by more than 30X. It also consistently surpasses GAN-based methods by at least 5% across multiple evaluation metrics. Furthermore, we evaluate the effectiveness of our proposed framework in downstream tissue classification tasks, showcasing its practical utility. Code is available at https://github.com/bugs-creator/LatentArtiFusion.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accept to DGM4MICCAI2024"
    },
    {
        "paper id": "2407.20212",
        "abstract url": "https://arxiv.org/abs/2407.20212",
        "title": "Distributed Quantum Approximate Optimization Algorithm on Integrated High-Performance Computing and Quantum Computing Systems for Large-Scale Optimization",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum approximated optimization algorithm (QAOA) has shown promise for solving combinatorial optimization problems by providing quantum speedup on near-term gate-based quantum computing systems. However, QAOA faces challenges in optimizing variational parameters for high-dimensional problems due to the large number of qubits required and the complexity of deep circuits, which limit its scalability for real-world applications. In this study, we propose a distributed QAOA (DQAOA), which leverages a high-performance computing-quantum computing (HPC-QC) integrated system. DQAOA leverages distributed computing strategies to decompose a large job into smaller tasks, which are then processed on the HPC-QC system. The global solution is iteratively updated by aggregating sub-solutions obtained from DQAOA, allowing convergence toward the optimal solution. We demonstrate that DQAOA can handle considerably large-scale optimization problems (e.g., 1,000-bit problem) achieving high accuracy (~99%) and short time-to-solution (~276 s). To apply this algorithm to material science, we further develop an active learning algorithm integrated with our DQAOA (AL-DQAOA), which involves machine learning, DQAOA, and active data production in an iterative loop. We successfully optimize photonic structures using AL-DQAOA, indicating that solving real-world optimization problems using gate-based quantum computing is feasible with our strategies. We expect the proposed DQAOA to be applicable to a wide range of optimization problems and AL-DQAOA to find broader applications in material design.",
        "subjects": [
            "cs.DC",
            "cs.CE",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20213",
        "abstract url": "https://arxiv.org/abs/2407.20213",
        "title": "Registering Neural 4D Gaussians for Endoscopic Surgery",
        "rating": "-2",
        "keywords": [
            [
                "Gaussian Splatting"
            ],
            [
                "surgical",
                "Surgery",
                "Endoscopic"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The recent advance in neural rendering has enabled the ability to reconstruct high-quality 4D scenes using neural networks. Although 4D neural reconstruction is popular, registration for such representations remains a challenging task, especially for dynamic scene registration in surgical planning and simulation. In this paper, we propose a novel strategy for dynamic surgical neural scene registration. We first utilize 4D Gaussian Splatting to represent the surgical scene and capture both static and dynamic scenes effectively. Then, a spatial aware feature aggregation method, Spatially Weight Cluttering (SWC) is proposed to accurately align the feature between surgical scenes, enabling precise and realistic surgical simulations. Lastly, we present a novel strategy of deformable scene registration to register two dynamic scenes. By incorporating both spatial and temporal information for correspondence matching, our approach achieves superior performance compared to existing registration methods for implicit neural representation. The proposed method has the potential to improve surgical planning and training, ultimately leading to better patient outcomes.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20214",
        "abstract url": "https://arxiv.org/abs/2407.20214",
        "title": "SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Surgical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Graph-based holistic scene representations facilitate surgical workflow understanding and have recently demonstrated significant success. However, this task is often hindered by the limited availability of densely annotated surgical scene data. In this work, we introduce an end-to-end framework for the generation and optimization of surgical scene graphs on a downstream task. Our approach leverages the flexibility of graph-based spectral clustering and the generalization capability of foundation models to generate unsupervised scene graphs with learnable properties. We reinforce the initial spatial graph with sparse temporal connections using local matches between consecutive frames to predict temporally consistent clusters across a temporal neighborhood. By jointly optimizing the spatiotemporal relations and node features of the dynamic scene graph with the downstream task of phase segmentation, we address the costly and annotation-burdensome task of semantic scene comprehension and scene graph generation in surgical videos using only weak surgical phase labels. Further, by incorporating effective intermediate scene representation disentanglement steps within the pipeline, our solution outperforms the SOTA on the CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow recognition",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "9 pages, 3 figures, 3 tables, MICCAI GRAIL Workshop paper"
    },
    {
        "paper id": "2407.20304",
        "abstract url": "https://arxiv.org/abs/2407.20304",
        "title": "X-ray nano-holotomography reconstruction with simultaneous probe retrieval",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "X-ray"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "In conventional tomographic reconstruction, the pre-processing step includes flat-field correction, where each sample projection on the detector is divided by a reference image taken without the sample. When using coherent X-rays as probe, this approach overlooks the phase component of the illumination field (probe), leading to artifacts in phase-retrieved projection images, which are then propagated to the reconstructed 3D sample representation. The problem intensifies in nano-holotomography with focusing optics, that due to various imperfections creates high-frequency components in the probe function. Here, we present a new iterative reconstruction scheme for holotomography, simultaneously retrieving the complex-valued probe function. Implemented on GPUs, this algorithm results in 3D reconstruction resolving twice thinner layers in a 3D ALD standard sample measured using nano-holotomography.",
        "subjects": [
            "eess.IV",
            "physics.optics"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20407",
        "abstract url": "https://arxiv.org/abs/2407.20407",
        "title": "Deep Learning for Super-resolution Ultrasound Imaging with Spatiotemporal Data",
        "rating": "-2",
        "keywords": [
            [
                "Super-resolution"
            ],
            [
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Super-resolution ultrasound imaging (SRUS) is an active area of research as it brings up to a ten-fold improvement in the resolution of microvascular structures. The limitations to the clinical adoption of SRUS include long acquisition times and long image processing times. Both these limitations can be alleviated with deep learning approaches to the processing of SRUS images. In this study we propose an optimized architecture based on modern improvements to convolutional neural networks from the ConvNeXt architecture and further customize the choice of features to improve performance on the specific tasks of both MB detection and localization within a single network. We employ a spatiotemporal input of up to five successive image frames to increase the number of MBs detected. The output structure produces three classifications: a MB detection Boolean for each pixel in the central image frame, as well as x and z offsets at 4-fold subpixel resolution for each MB detected. Ultrasound simulations generated images based on the L22-14v transducer (Verasonics) for training and testing of the proposed SRUS-ConvNeXt network. In vivo image data of a mouse brain was used as further validation of the architecture. The proposed network had the highest performance as measured by F1 score when configured for a 3-frame spatiotemporal input. The smallest localization error of \u03bb/22 was achieved when the network was configured for a single input frame. The flexibility of the proposed architecture allows extension to 10-fold upscaling for SRUS images with a much lower impact to number of parameters and subsequent increase in inference time than typical U-Net style approaches. This network is promising in the quest to develop a SRUS deep network architecture for real time image formation.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20443",
        "abstract url": "https://arxiv.org/abs/2407.20443",
        "title": "Resilient Entanglement Distribution in a Multihop Quantum Network",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The evolution of quantum networking requires architectures capable of dynamically reconfigurable entanglement distribution to meet diverse user needs and ensure tolerance against transmission disruptions. We introduce multihop quantum networks to improve network reach and resilience by enabling quantum communications across intermediate nodes, thus broadening network connectivity and increasing scalability. We present multihop two-qubit polarization-entanglement distribution within a quantum network at the Oak Ridge National Laboratory campus. Our system uses wavelength-selective switches for adaptive bandwidth management on a software-defined quantum network that integrates a quantum data plane with classical data and control planes, creating a flexible, reconfigurable mesh. Our network distributes entanglement across six nodes within three subnetworks, each located in a separate building, optimizing quantum state fidelity and transmission rate through adaptive resource management. Additionally, we demonstrate the network's resilience by implementing a link recovery approach that monitors and reroutes quantum resources to maintain service continuity despite link failures -- paving the way for scalable and reliable quantum networking infrastructures.",
        "subjects": [
            "quant-ph",
            "cs.NI",
            "physics.optics"
        ],
        "comment": "9 PAGES, 6 FIGURES"
    },
    {
        "paper id": "2407.20463",
        "abstract url": "https://arxiv.org/abs/2407.20463",
        "title": "5G NR Positioning with OpenAirInterface: Tools and Methodologies",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "The fifth-generation new radio (5G NR) technology is expected to provide precise and reliable positioning capabilities along with high data rates. The Third Generation Partnership Project (3GPP) has started introducing positioning techniques from Release-16 based on time, angle, and signal strength using reference signals. However, validating these techniques with experimental prototypes is crucial before successful real-world deployment. This work provides useful tools and implementation details that are required in performing 5G positioning experiments with OpenAirInterface (OAI). As an example use case, we present an round trip time (RTT) estimation test-bed based on OAI and discusses the real-word experiment and measurement process.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20465",
        "abstract url": "https://arxiv.org/abs/2407.20465",
        "title": "A flexible framework for accurate LiDAR odometry, map manipulation, and localization",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "SLAM"
            ]
        ],
        "abstract": "LiDAR-based SLAM is a core technology for autonomous vehicles and robots. Despite the intense research activity in this field, each proposed system uses a particular sensor post-processing pipeline and a single map representation format. The present work aims at introducing a revolutionary point of view for 3D LiDAR SLAM and localization: (1) using view-based maps as the fundamental representation of maps (\"simple-maps\"), which can then be used to generate arbitrary metric maps optimized for particular tasks; and (2) by introducing a new framework in which mapping pipelines can be defined without coding, defining the connections of a network of reusable blocks much like deep-learning networks are designed by connecting layers of standardized elements. Moreover, the idea of including the current linear and angular velocity vectors as variables to be optimized within the ICP loop is also introduced, leading to superior robustness against aggressive motion profiles without an IMU. The presented open-source ecosystem, released to ROS 2, includes tools and prebuilt pipelines covering all the way from data acquisition to map editing and visualization, real-time localization, loop-closure detection, or map georeferencing from consumer-grade GNSS receivers. Extensive experimental validation reveals that the proposal compares well to, or improves, former state-of-the-art (SOTA) LiDAR odometry systems, while also successfully mapping some hard sequences where others diverge. A proposed self-adaptive configuration has been used, without parameter changes, for all 3D LiDAR datasets with sensors between 16 and 128 rings, extensively tested on 83 sequences over more than 250~km of automotive, hand-held, airborne, and quadruped LiDAR datasets, both indoors and outdoors. The open-sourced implementation is available online at https://github.com/MOLAorg/mola",
        "subjects": [
            "cs.RO"
        ],
        "comment": "41 pages, 30 figures"
    },
    {
        "paper id": "2407.20522",
        "abstract url": "https://arxiv.org/abs/2407.20522",
        "title": "Evaluating Fairness in Black-box Algorithmic Markets: A Case Study of Ride Sharing in Chicago",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "This study examines fairness within the rideshare industry, focusing on both drivers' wages and riders' trip fares. Through quantitative analysis, we found that drivers' hourly wages are significantly influenced by factors such as race/ethnicity, health insurance status, tenure to the platform, and working hours. Despite platforms' policies not intentionally embedding biases, disparities persist based on these characteristics. For ride fares, we propose a method to audit the pricing policy of a proprietary algorithm by replicating it; we conduct a hypothesis test to determine if the predicted rideshare fare is greater than the taxi fare, taking into account the approximation error in the replicated model. Challenges in accessing data and transparency hinder our ability to isolate discrimination from other factors, underscoring the need for collaboration with rideshare platforms and drivers to enhance fairness in algorithmic wage determination and pricing.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted to the Humans, Algorithmic Decision-Making and Society: Modeling Interactions and Impact, co-located with the International Conference on Machine Learning, Vienna, Austria"
    },
    {
        "paper id": "2407.21080",
        "abstract url": "https://arxiv.org/abs/2407.21080",
        "title": "Artificial Intelligence Enhanced Digital Nucleic Acid Amplification Testing for Precision Medicine and Molecular Diagnostics",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "biology",
                "health",
                "diagnosing",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "The precise quantification of nucleic acids is pivotal in molecular biology, underscored by the rising prominence of nucleic acid amplification tests (NAAT) in diagnosing infectious diseases and conducting genomic studies. This review examines recent advancements in digital Polymerase Chain Reaction (dPCR) and digital Loop-mediated Isothermal Amplification (dLAMP), which surpass the limitations of traditional NAAT by offering absolute quantification and enhanced sensitivity. In this review, we summarize the compelling advancements of dNNAT in addressing pressing public health issues, especially during the COVID-19 pandemic. Further, we explore the transformative role of artificial intelligence (AI) in enhancing dNAAT image analysis, which not only improves efficiency and accuracy but also addresses traditional constraints related to cost, complexity, and data interpretation. In encompassing the state-of-the-art (SOTA) development and potential of both software and hardware, the all-encompassing Point-of-Care Testing (POCT) systems cast new light on benefits including higher throughput, label-free detection, and expanded multiplex analyses. While acknowledging the enhancement of AI-enhanced dNAAT technology, this review aims to both fill critical gaps in the existing technologies through comparative assessments and offer a balanced perspective on the current trajectory, including attendant challenges and future directions. Leveraging AI, next-generation dPCR and dLAMP technologies promises integration into clinical practice, improving personalized medicine, real-time epidemic surveillance, and global diagnostic accessibility.",
        "subjects": [
            "q-bio.QM",
            "eess.IV"
        ],
        "comment": "Review article. 46 Pages. 6 Figures. 4 Tables"
    },
    {
        "paper id": "2407.19728",
        "abstract url": "https://arxiv.org/abs/2407.19728",
        "title": "PersonalityScanner: Exploring the Validity of Personality Assessment Based on Multimodal Signals in Virtual Reality",
        "rating": "-2.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "facial"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Human cognition significantly influences expressed behavior and is intrinsically tied to authentic personality traits. Personality assessment plays a pivotal role in various fields, including psychology, education, social media, etc. However, traditional self-report questionnaires can only provide data based on what individuals are willing and able to disclose, thereby lacking objective. Moreover, automated measurements and peer assessments demand significant human effort and resources. In this paper, given the advantages of the Virtual Reality (VR) technique, we develop a VR simulator -- PersonalityScanner, to stimulate cognitive processes and simulate daily behaviors based on an immersive and interactive simulation environment, in which participants carry out a battery of engaging tasks that formulate a natural story of first-day at work. Through this simulator, we collect a synchronous multi-modal dataset with ten modalities, including first/third-person video, audio, text, eye tracking, facial microexpression, pose, depth data, log, and inertial measurement unit. By systematically examining the contributions of different modalities on revealing personality, we demonstrate the superior performance and effectiveness of PersonalityScanner.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": "Accepted to COGSCI 2024"
    },
    {
        "paper id": "2407.19886",
        "abstract url": "https://arxiv.org/abs/2407.19886",
        "title": "A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the rapid development of online multimedia services, especially in e-commerce platforms, there is a pressing need for personalised recommendation systems that can effectively encode the diverse multi-modal content associated with each item. However, we argue that existing multi-modal recommender systems typically use isolated processes for both feature extraction and modality modelling. Such isolated processes can harm the recommendation performance. Firstly, an isolated extraction process underestimates the importance of effective feature extraction in multi-modal recommendations, potentially incorporating non-relevant information, which is harmful to item representations. Second, an isolated modality modelling process produces disjointed embeddings for item modalities due to the individual processing of each modality, which leads to a suboptimal fusion of user/item representations for effective user preferences prediction. We hypothesise that the use of a unified model for addressing both aforementioned isolated processes will enable the consistent extraction and cohesive fusion of joint multi-modal features, thereby enhancing the effectiveness of multi-modal recommender systems. In this paper, we propose a novel model, called Unified Multi-modal Graph Transformer (UGT), which firstly leverages a multi-way transformer to extract aligned multi-modal features from raw data for top-k recommendation. Subsequently, we build a unified graph neural network in our UGT model to jointly fuse the user/item representations with their corresponding multi-modal features. Using the graph transformer architecture of our UGT model, we show that the UGT model can achieve significant effectiveness gains, especially when jointly optimised with the commonly-used multi-modal recommendation losses.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20060",
        "abstract url": "https://arxiv.org/abs/2407.20060",
        "title": "RelBench: A Benchmark for Deep Learning on Relational Databases",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We present RelBench, a public benchmark for solving predictive tasks over relational databases with graph neural networks. RelBench provides databases and tasks spanning diverse domains and scales, and is intended to be a foundational infrastructure for future research. We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables. End-to-end learned RDL models fully exploit the predictive signal encoded in primary-foreign key links, marking a significant shift away from the dominant paradigm of manual feature engineering combined with tabular models. To thoroughly evaluate RDL against this prior gold-standard, we conduct an in-depth user study where an experienced data scientist manually engineers features for each task. In this study, RDL learns better models whilst reducing human work needed by more than an order of magnitude. This demonstrates the power of deep learning for solving predictive tasks over relational databases, opening up many new research opportunities enabled by RelBench.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20067",
        "abstract url": "https://arxiv.org/abs/2407.20067",
        "title": "xAI-Drop: Don't Use What You Cannot Explain",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "bioinformatics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have emerged as the predominant paradigm for learning from graph-structured data, offering a wide range of applications from social network analysis to bioinformatics. Despite their versatility, GNNs face challenges such as oversmoothing, lack of generalization and poor interpretability, which hinder their wider adoption and reliability in critical applications. Dropping has emerged as an effective paradigm for reducing noise during training and improving robustness of GNNs. However, existing approaches often rely on random or heuristic-based selection criteria, lacking a principled method to identify and exclude nodes that contribute to noise and over-complexity in the model. In this work, we argue that explainability should be a key indicator of a model's robustness throughout its training phase. To this end, we introduce xAI-Drop, a novel topological-level dropping regularizer that leverages explainability to pinpoint noisy network elements to be excluded from the GNN propagation mechanism. An empirical evaluation on diverse real-world datasets demonstrates that our method outperforms current state-of-the-art dropping approaches in accuracy, effectively reduces over-smoothing, and improves explanation quality.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20126",
        "abstract url": "https://arxiv.org/abs/2407.20126",
        "title": "Extreme time extrapolation capabilities and thermodynamic consistency of physics-inspired Neural Networks for the 3D microstructure evolution of materials",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A Convolutional Recurrent Neural Network (CRNN) is trained to reproduce the evolution of the spinodal decomposition process in three dimensions as described by the Cahn-Hilliard equation. A specialized, physics-inspired architecture is proven to provide close accordance between the predicted evolutions and the ground truth ones obtained via conventional integration schemes. The method can closely reproduce the evolution of microstructures not represented in the training set at a fraction of the computational costs. Extremely long-time extrapolation capabilities are achieved, up to reaching the theoretically expected equilibrium state of the system, despite the training set containing only relatively-short, initial phases of the evolution. Quantitative accordance with the decay rate of the Free energy is also demonstrated up to late coarsening stages, providing an example of a data-driven, physically consistent and high-accuracy Machine Learning method for the long timescale simulation of materials.",
        "subjects": [
            "cond-mat.mes-hall",
            "cond-mat.mtrl-sci",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": "10 pages, 6 main text figures, 2 appendix figures"
    },
    {
        "paper id": "2407.20157",
        "abstract url": "https://arxiv.org/abs/2407.20157",
        "title": "rLLM: Relational Table Learning with LLMs",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "tabular"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce rLLM (relationLLM), a PyTorch library designed for Relational Table Learning (RTL) with Large Language Models (LLMs). The core idea is to decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural Networks into standardized modules, to enable the fast construction of novel RTL-type models in a simple \"combine, align, and co-train\" manner. To illustrate the usage of rLLM, we introduce a simple RTL method named \\textbf{BRIDGE}. Additionally, we present three novel relational tabular datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope rLLM can serve as a useful and easy-to-use development framework for RTL-related tasks. Our code is available at: https://github.com/rllm-project/rllm.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20462",
        "abstract url": "https://arxiv.org/abs/2407.20462",
        "title": "Graphite: A Graph-based Extreme Multi-Label Short Text Classifier for Keyphrase Recommendation",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Keyphrase Recommendation has been a pivotal problem in advertising and e-commerce where advertisers/sellers are recommended keyphrases (search queries) to bid on to increase their sales. It is a challenging task due to the plethora of items shown on online platforms and various possible queries that users search while showing varying interest in the displayed items. Moreover, query/keyphrase recommendations need to be made in real-time and in a resource-constrained environment. This problem can be framed as an Extreme Multi-label (XML) Short text classification by tagging the input text with keywords as labels. Traditional neural network models are either infeasible or have slower inference latency due to large label spaces. We present Graphite, a graph-based classifier model that provides real-time keyphrase recommendations that are on par with standard text classification models. Furthermore, it doesn't utilize GPU resources, which can be limited in production environments. Due to its lightweight nature and smaller footprint, it can train on very large datasets, where state-of-the-art XML models fail due to extreme resource requirements. Graphite is deterministic, transparent, and intrinsically more interpretable than neural network-based models. We present a comprehensive analysis of our model's performance across forty categories spanning eBay's English-speaking sites.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20529",
        "abstract url": "https://arxiv.org/abs/2407.20529",
        "title": "Can LLMs be Fooled? Investigating Vulnerabilities in LLMs",
        "rating": "-2.5",
        "keywords": [
            [
                "Model Editing"
            ],
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The advent of Large Language Models (LLMs) has garnered significant popularity and wielded immense power across various domains within Natural Language Processing (NLP). While their capabilities are undeniably impressive, it is crucial to identify and scrutinize their vulnerabilities especially when those vulnerabilities can have costly consequences. One such LLM, trained to provide a concise summarization from medical documents could unequivocally leak personal patient data when prompted surreptitiously. This is just one of many unfortunate examples that have been unveiled and further research is necessary to comprehend the underlying reasons behind such vulnerabilities. In this study, we delve into multiple sections of vulnerabilities which are model-based, training-time, inference-time vulnerabilities, and discuss mitigation strategies including \"Model Editing\" which aims at modifying LLMs behavior, and \"Chroma Teaming\" which incorporates synergy of multiple teaming strategies to enhance LLMs' resilience. This paper will synthesize the findings from each vulnerability section and propose new directions of research and development. By understanding the focal points of current vulnerabilities, we can better anticipate and mitigate future risks, paving the road for more robust and secure LLMs.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "14 pages, 1 figure. arXiv admin note: text overlap with arXiv:2403.12503"
    },
    {
        "paper id": "2407.19711",
        "abstract url": "https://arxiv.org/abs/2407.19711",
        "title": "TVDiag: A Task-oriented and View-invariant Failure Diagnosis Framework with Multimodal Data",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "Diagnosis"
            ]
        ],
        "abstract": "Microservice-based systems often suffer from reliability issues due to their intricate interactions and expanding scale. With the rapid growth of observability techniques, various methods have been proposed to achieve failure diagnosis, including root cause localization and failure type identification, by leveraging diverse monitoring data such as logs, metrics, or traces. However, traditional failure diagnosis methods that use single-modal data can hardly cover all failure scenarios due to the restricted information. Several failure diagnosis methods have been recently proposed to integrate multimodal data based on deep learning. These methods, however, tend to combine modalities indiscriminately and treat them equally in failure diagnosis, ignoring the relationship between specific modalities and different diagnostic tasks. This oversight hinders the effective utilization of the unique advantages offered by each modality. To address the limitation, we propose \\textit{TVDiag}, a multimodal failure diagnosis framework for locating culprit microservice instances and identifying their failure types (e.g., Net-packets Corruption) in microservice-based systems. \\textit{TVDiag} employs task-oriented learning to enhance the potential advantages of each modality and establishes cross-modal associations based on contrastive learning to extract view-invariant failure information. Furthermore, we develop a graph-level data augmentation strategy that randomly inactivates the observability of some normal microservice instances during training to mitigate the shortage of training data. Experimental results show that \\textit{TVDiag} outperforms state-of-the-art methods in multimodal failure diagnosis, achieving at least a 55.94\\% higher $HR@1$ accuracy and over a 4.08\\% increase in F1-score across two datasets.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "30 pages"
    },
    {
        "paper id": "2407.19811",
        "abstract url": "https://arxiv.org/abs/2407.19811",
        "title": "Synthetic Thermal and RGB Videos for Automatic Pain Assessment utilizing a Vision-MLP Architecture",
        "rating": "-3",
        "keywords": [
            [
                "BioVid",
                "facial"
            ],
            [
                "Thermal"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Pain assessment is essential in developing optimal pain management protocols to alleviate suffering and prevent functional decline in patients. Consequently, reliable and accurate automatic pain assessment systems are essential for continuous and effective patient monitoring. This study presents synthetic thermal videos generated by Generative Adversarial Networks integrated into the pain recognition pipeline and evaluates their efficacy. A framework consisting of a Vision-MLP and a Transformer-based module is utilized, employing RGB and synthetic thermal videos in unimodal and multimodal settings. Experiments conducted on facial videos from the BioVid database demonstrate the effectiveness of synthetic thermal videos and underline the potential advantages of it.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19819",
        "abstract url": "https://arxiv.org/abs/2407.19819",
        "title": "Detecting Unsafe Behavior in Neural Network Imitation Policies for Caregiving Robotics",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Robotics"
            ],
            [
                "anomaly detection"
            ]
        ],
        "abstract": "In this paper, the application of imitation learning in caregiving robotics is explored, aiming at addressing the increasing demand for automated assistance in caring for the elderly and disabled. Leveraging advancements in deep learning and control algorithms, the study focuses on training neural network policies using offline demonstrations. A key challenge addressed is the \"Policy Stopping\" problem, crucial for enhancing safety in imitation learning-based policies, particularly diffusion policies. Novel solutions proposed include ensemble predictors and adaptations of the normalizing flow-based algorithm for early anomaly detection. Comparative evaluations against anomaly detection methods like VAE and Tran-AD demonstrate superior performance on assistive robotics benchmarks. The paper concludes by discussing the further research in integrating safety models into policy training, crucial for the reliable deployment of neural network policies in caregiving robotics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19913",
        "abstract url": "https://arxiv.org/abs/2407.19913",
        "title": "Cell Culture Assistive Application for Precipitation Image Diagnosis",
        "rating": "-3",
        "keywords": [
            [
                "biological",
                "Diagnosis"
            ],
            [
                "chemical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In regenerative medicine research, we experimentally design the composition of chemical medium. We add different components to 384-well plates and culture the biological cells. We monitor the condition of the cells and take time-lapse bioimages for morphological assay. In particular, precipitation can appear as artefacts in the image and contaminate the noise in the imaging assay. Inspecting precipitates is a tedious task for the observer, and differences in experience can lead to variations in judgement from person to person. The machine learning approach will remove the burden of human inspection and provide consistent inspection. In addition, precipitation features are as small as 10-20 \u03bcm. A 1200 pixel square well image resized under a resolution of 2.82 \u03bcm/pixel will result in a reduction in precipitation features. Dividing the well images into 240-pixel squares and learning without resizing preserves the resolution of the original image. In this study, we developed an application to automatically detect precipitation on 384-well plates utilising optical microscope images. We apply MN-pair contrastive clustering to extract precipitation classes from approximately 20,000 patch images. To detect precipitation features, we compare deeper FCDDs detectors with optional backbones and build a machine learning pipeline to detect precipitation from the maximum score of quadruplet well images using isolation Forest algorithm, where the anomaly score is ranged from zero to one. Furthermore, using this application we can visualise precipitation situ heatmap on a 384-well plate.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 15 figures, 5 tables"
    },
    {
        "paper id": "2407.19926",
        "abstract url": "https://arxiv.org/abs/2407.19926",
        "title": "Lightweight Dataset for Decoy Development to Improve IoT Security",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "industrial",
                "IoT"
            ]
        ],
        "abstract": "In this paper, the authors introduce a lightweight dataset to interpret IoT (Internet of Things) activity in preparation to create decoys by replicating known data traffic patterns. The dataset comprises different scenarios in a real network setting. This paper also surveys information related to other IoT datasets along with the characteristics that make our data valuable. Many of the datasets available are synthesized (simulated) or often address industrial applications, while the IoT dataset we present is based on likely smart home scenarios. Further, there are only a limited number of IoT datasets that contain both normal operation and attack scenarios. A discussion of the network configuration and the steps taken to prepare this dataset are presented as we prepare to create replicative patterns for decoy purposes. The dataset, which we refer to as IoT Flex Data, consists of four categories, namely, IoT benign idle, IoT benign active, IoT setup, and malicious (attack) traffic associating the IoT devices with the scenarios under consideration.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "13 pages, 4 figures, 4 tables"
    },
    {
        "paper id": "2407.19977",
        "abstract url": "https://arxiv.org/abs/2407.19977",
        "title": "Physically-based Path Tracer using WebGPU and OpenPBR",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "This work presents a web-based, open-source path tracer for rendering physically-based 3D scenes using WebGPU and the OpenPBR surface shading model. While rasterization has been the dominant real-time rendering technique on the web since WebGL's introduction in 2011, it struggles with global illumination. This necessitates more complex techniques, often relying on pregenerated artifacts to attain the desired level of visual fidelity. Path tracing inherently addresses these limitations but at the cost of increased rendering time. Our work focuses on industrial applications where highly customizable products are common and real-time performance is not critical. We leverage WebGPU to implement path tracing on the web, integrating the OpenPBR standard for physically-based material representation. The result is a near real-time path tracer capable of rendering high-fidelity 3D scenes directly in web browsers, eliminating the need for pregenerated assets. Our implementation demonstrates the potential of WebGPU for advanced rendering techniques and opens new possibilities for web-based 3D visualization in industrial applications.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "pre-print version"
    },
    {
        "paper id": "2407.20054",
        "abstract url": "https://arxiv.org/abs/2407.20054",
        "title": "Visual Support for the Loop Grafting Workflow on Proteins",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "biochemistry"
            ]
        ],
        "abstract": "In understanding and redesigning the function of proteins in modern biochemistry, protein engineers are increasingly focusing on exploring regions in proteins called loops. Analyzing various characteristics of these regions helps the experts design the transfer of the desired function from one protein to another. This process is denoted as loop grafting. We designed a set of interactive visualizations that provide experts with visual support through all the loop grafting pipeline steps. The workflow is divided into several phases, reflecting the steps of the pipeline. Each phase is supported by a specific set of abstracted 2D visual representations of proteins and their loops that are interactively linked with the 3D View of proteins. By sequentially passing through the individual phases, the user shapes the list of loops that are potential candidates for loop grafting. Finally, the actual in-silico insertion of the loop candidates from one protein to the other is performed, and the results are visually presented to the user. In this way, the fully computational rational design of proteins and their loops results in newly designed protein structures that can be further assembled and tested through in-vitro experiments. We showcase the contribution of our visual support design on a real case scenario changing the enantiomer selectivity of the engineered enzyme. Moreover, we provide the readers with the experts' feedback.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20141",
        "abstract url": "https://arxiv.org/abs/2407.20141",
        "title": "DDAP: Dual-Domain Anti-Personalization against Text-to-Image Diffusion Models",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "attack"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion-based personalized visual content generation technologies have achieved significant breakthroughs, allowing for the creation of specific objects by just learning from a few reference photos. However, when misused to fabricate fake news or unsettling content targeting individuals, these technologies could cause considerable societal harm. To address this problem, current methods generate adversarial samples by adversarially maximizing the training loss, thereby disrupting the output of any personalized generation model trained with these samples. However, the existing methods fail to achieve effective defense and maintain stealthiness, as they overlook the intrinsic properties of diffusion models. In this paper, we introduce a novel Dual-Domain Anti-Personalization framework (DDAP). Specifically, we have developed Spatial Perturbation Learning (SPL) by exploiting the fixed and perturbation-sensitive nature of the image encoder in personalized generation. Subsequently, we have designed a Frequency Perturbation Learning (FPL) method that utilizes the characteristics of diffusion models in the frequency domain. The SPL disrupts the overall texture of the generated images, while the FPL focuses on image details. By alternating between these two methods, we construct the DDAP framework, effectively harnessing the strengths of both domains. To further enhance the visual quality of the adversarial samples, we design a localization module to accurately capture attentive areas while ensuring the effectiveness of the attack and avoiding unnecessary disturbances in the background. Extensive experiments on facial benchmarks have shown that the proposed DDAP enhances the disruption of personalized generation models while also maintaining high quality in adversarial samples, making it more effective in protecting privacy in practical applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IJCB 2024"
    },
    {
        "paper id": "2407.19893",
        "abstract url": "https://arxiv.org/abs/2407.19893",
        "title": "Leveraging Foundation Models for Zero-Shot IoT Sensing",
        "rating": "-3.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep learning models are increasingly deployed on edge Internet of Things (IoT) devices. However, these models typically operate under supervised conditions and fail to recognize unseen classes different from training. To address this, zero-shot learning (ZSL) aims to classify data of unseen classes with the help of semantic information. Foundation models (FMs) trained on web-scale data have shown impressive ZSL capability in natural language processing and visual understanding. However, leveraging FMs' generalized knowledge for zero-shot IoT sensing using signals such as mmWave, IMU, and Wi-Fi has not been fully investigated. In this work, we align the IoT data embeddings with the semantic embeddings generated by an FM's text encoder for zero-shot IoT sensing. To utilize the physics principles governing the generation of IoT sensor signals to derive more effective prompts for semantic embedding extraction, we propose to use cross-attention to combine a learnable soft prompt that is optimized automatically on training data and an auxiliary hard prompt that encodes domain knowledge of the IoT sensing task. To address the problem of IoT embeddings biasing to seen classes due to the lack of unseen class data during training, we propose using data augmentation to synthesize unseen class IoT data for fine-tuning the IoT feature extractor and embedding projector. We evaluate our approach on multiple IoT sensing tasks. Results show that our approach achieves superior open-set detection and generalized zero-shot learning performance compared with various baselines. Our code is available at https://github.com/schrodingho/FM\\_ZSL\\_IoT.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20147",
        "abstract url": "https://arxiv.org/abs/2407.20147",
        "title": "Quantum Machine Learning Architecture Search via Deep Reinforcement Learning",
        "rating": "-3.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "Architecture Search"
            ],
            [
                "Quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The rapid advancement of quantum computing (QC) and machine learning (ML) has given rise to the burgeoning field of quantum machine learning (QML), aiming to capitalize on the strengths of quantum computing to propel ML forward. Despite its promise, crafting effective QML models necessitates profound expertise to strike a delicate balance between model intricacy and feasibility on Noisy Intermediate-Scale Quantum (NISQ) devices. While complex models offer robust representation capabilities, their extensive circuit depth may impede seamless execution on extant noisy quantum platforms. In this paper, we address this quandary of QML model design by employing deep reinforcement learning to explore proficient QML model architectures tailored for designated supervised learning tasks. Specifically, our methodology involves training an RL agent to devise policies that facilitate the discovery of QML models without predetermined ansatz. Furthermore, we integrate an adaptive mechanism to dynamically adjust the learning objectives, fostering continuous improvement in the agent's learning process. Through extensive numerical simulations, we illustrate the efficacy of our approach within the realm of classification tasks. Our proposed method successfully identifies VQC architectures capable of achieving high classification accuracy while minimizing gate depth. This pioneering approach not only advances the study of AI-driven quantum circuit design but also holds significant promise for enhancing performance in the NISQ era.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.ET",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "Accepted by IEEE International Conference on Quantum Computing and Engineering - QCE 2024"
    },
    {
        "paper id": "2407.19776",
        "abstract url": "https://arxiv.org/abs/2407.19776",
        "title": "Advancement of metal oxide nanomaterials on agri-food fronts",
        "rating": "-4",
        "keywords": [
            [
                "health"
            ],
            [
                "agricultural"
            ]
        ],
        "abstract": "The application of metal oxide nanomaterials (MOx NMs) in the agrifood industry offers innovative solutions that can facilitate a paradigm shift in a sector that is currently facing challenges in meeting the growing requirements for food production, while safeguarding the environment from the impacts of current agriculture practices. This review comprehensively illustrates recent advancements and applications of MOx for sustainable practices in the food and agricultural industries and environmental preservation. Relevant published data point out that MOx NMs can be tailored for specific properties, enabling advanced design concepts with improved features for various applications in the agrifood industry. Applications include nano-agrochemical formulation, control of food quality through nanosensors, and smart food packaging. Furthermore, recent research suggests MOx's vital role in addressing environmental challenges by removing toxic elements from contaminated soil and water. This mitigates the environmental effects of widespread agrichemical use and creates a more favorable environment for plant growth. The review also discusses potential barriers, particularly regarding MOx toxicity and risk evaluation. Fundamental concerns about possible adverse effects on human health and the environment must be addressed to establish an appropriate regulatory framework for nano metal oxide-based food and agricultural products.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20495",
        "abstract url": "https://arxiv.org/abs/2407.20495",
        "title": "Enhancing Quantitative Image Synthesis through Pretraining and Resolution Scaling for Bone Mineral Density Estimation from a Plain X-ray Image",
        "rating": "-4",
        "keywords": [
            [
                "depth"
            ],
            [
                "medical",
                "X-ray"
            ],
            [
                "Mineral"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "While most vision tasks are essentially visual in nature (for recognition), some important tasks, especially in the medical field, also require quantitative analysis (for quantification) using quantitative images. Unlike in visual analysis, pixel values in quantitative images correspond to physical metrics measured by specific devices (e.g., a depth image). However, recent work has shown that it is sometimes possible to synthesize accurate quantitative values from visual ones (e.g., depth from visual cues or defocus). This research aims to improve quantitative image synthesis (QIS) by exploring pretraining and image resolution scaling. We propose a benchmark for evaluating pretraining performance using the task of QIS-based bone mineral density (BMD) estimation from plain X-ray images, where the synthesized quantitative image is used to derive BMD. Our results show that appropriate pretraining can improve QIS performance, significantly raising the correlation of BMD estimation from 0.820 to 0.898, while others do not help or even hinder it. Scaling-up the resolution can further boost the correlation up to 0.923, a significant enhancement over conventional methods. Future work will include exploring more pretraining strategies and validating them on other image synthesis tasks.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "SASHIMI, 2024 (MICCAI workshop). 13 pages, 3 figures"
    },
    {
        "paper id": "2407.19709",
        "abstract url": "https://arxiv.org/abs/2407.19709",
        "title": "The Family of LML Detectors and the Family of LAS Detectors for Massive MIMO Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "The family of local maximum likelihood (LML) detectors and the family of likelihood ascent search (LAS) detectors are successfully applied to symbol detection in massive multi-input multi-output (MIMO) communications and demonstrate performance approaching the NP-hard global maximum likelihood (GML) detector. The LML and LAS detectors in the two families are akin to each other and possess common properties significant in both theory and practical MIMO communications. This book chapter reviews the LML and LAS detectors in a unified framework. The focus is on their formulation, relationships, properties, and GML performance in bit error rate (BER) and spectral efficiency in large MIMO channels.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "26 pages, 4 figures"
    },
    {
        "paper id": "2407.19732",
        "abstract url": "https://arxiv.org/abs/2407.19732",
        "title": "Performance Optimization of High-Conflict Transactions within the Hyperledger Fabric Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "Hyperledger Fabric (HLF) is a secure and robust blockchain (BC) platform that supports high-throughput and low-latency transactions. However, it encounters challenges in managing conflicting transactions that negatively affect throughput and latency. This paper proposes a novel solution to address these challenges and improve performance, especially in applications incorporating extensive volumes of highly conflicting transactions. Our solution involves reallocating the Multi-Version Concurrency Control (MVCC) of the validation phase to a preceding stage in the transaction flow to enable early detection of conflicting transactions. Specifically, we propose and evaluate two innovative modifications, called Orderer Early MVCC (OEMVCC) and OEMVCC with Execution Avoidance (OEMVCC-EA). Our experimental evaluation results demonstrate significant throughput and latency improvements, providing a practical solution for high-conflict applications that demand high performance and scalability.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19758",
        "abstract url": "https://arxiv.org/abs/2407.19758",
        "title": "Quasi-optimum distance flag codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "A flag is a sequence of nested subspaces of a given ambient space F_q^n over a finite field F_q. In network coding, a flag code is a set of flags, all of them with the same sequence of dimensions, the type vector. In this paper, we investigate quasi-optimum distance flag codes, i.e., those attaining the second best possible distance value. We characterize them and present upper bounds for their cardinality. Moreover, we propose a systematic construction for every choice of the type vector by using partial spreads and sunflowers. For flag codes with lower minimum distance, we adapt the previous construction and provide some results towards their characterization, especially in the case of the third best possible distance value.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19781",
        "abstract url": "https://arxiv.org/abs/2407.19781",
        "title": "Recent Developments in Real Quantifier Elimination and Cylindrical Algebraic Decomposition",
        "rating": "-10",
        "keywords": [],
        "abstract": "This extended abstract accompanies an invited talk at CASC 2024, which surveys recent developments in Real Quantifier Elimination (QE) and Cylindrical Algebraic Decomposition (CAD). After introducing these concepts we will first consider adaptations of CAD inspired by computational logic, in particular the algorithms which underpin modern SAT solvers. CAD theory has found use in collaboration with these via the Satisfiability Modulo Theory (SMT) paradigm; while the ideas behind SAT/SMT have led to new algorithms for Real QE. Second we will consider the optimisation of CAD through the use of Machine Learning (ML). The choice of CAD variable ordering has become a key case study for the use of ML to tune algorithms in computer algebra. We will also consider how explainable AI techniques might give insight for improved computer algebra software without any reliance on ML in the final code.",
        "subjects": [
            "cs.SC"
        ],
        "comment": "Extended Abstract to accompany Invited Talk at CASC 2024"
    },
    {
        "paper id": "2407.19796",
        "abstract url": "https://arxiv.org/abs/2407.19796",
        "title": "Subsequence Pattern Matching with Segment Number Constraint",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper is concerned with subsequences that consist of limited numbers of segments. We call a subsequence \\emph{$f$-segmental} if it is composed of $f$ factors. More precisely, any string of the form $u_1 \\dots u_f$ is an $f$-segmental subsequence of a string $v_0u_1v_1 \\dots u_fv_f$. Since factors are $1$-segmental subsequences, this relativizes the notions of factors and subsequences. This paper studies some basic problems concerning $f$-segmental subsequences: namely, the longest common $f$-segmental subsequence problem and the $f$-segmental subsequence matching problem. The former asks the longest string that is an $f_i$-segmental subsequence of two input strings $T_i$ with $i=1,2$. The latter asks whether an input string $P$ is an $f$-segmental subsequence of the other input string $T$. We present polynomial-time algorithms for those problems and show that the one for the $f$-segmental subsequence matching problem is optimal modulo sub-polynomial factors under the strong exponential-time hypothesis.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19802",
        "abstract url": "https://arxiv.org/abs/2407.19802",
        "title": "A novel Taguchi-based approach for optimizing neural network architectures: application to elastic short fiber composites",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study presents an innovative application of the Taguchi design of experiment method to optimize the structure of an Artificial Neural Network (ANN) model for the prediction of elastic properties of short fiber reinforced composites. The main goal is to minimize the required computational effort for hyperparameter optimization while enhancing the prediction accuracy. Utilizing a robust design of experiment framework, the structure of an ANN model is optimized. This essentially is the identification of a combination of hyperparameters that yields an optimal predictive accuracy with the fewest algorithmic runs, thereby achieving a significant reduction of the required computational effort. Our findings demonstrate that the Taguchi method not only streamlines the hyperparameter tuning process but also could substantially improve the algorithm's performance. These results underscore the potential of the Taguchi method as a powerful tool for optimizing machine learning algorithms, particularly in scenarios where computational resources are limited. The implications of this study are far-reaching, offering insights for future research in the optimization of different algorithms for improved accuracies and computational efficiencies.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19843",
        "abstract url": "https://arxiv.org/abs/2407.19843",
        "title": "The Second Joint Workshop on Cross Reality",
        "rating": "-10",
        "keywords": [],
        "abstract": "The 2nd Joint Workshop on Cross Reality (JWCR'24), organized as part of ISMAR 2024, seeks to explore the burgeoning field of Cross Reality (CR), which encompasses the seamless integration and transition between various points on the reality-virtuality continuum (RVC) such as Virtual Reality (VR), Augmented Virtuality (AV), and Augmented Reality (AR). This hybrid workshop aims to build upon the foundation laid by the inaugural JWCR at ISMAR 2023, which successfully unified diverse CR research communities. The workshop will address key themes including CR visualization, interaction, user behavior, design, development, engineering, and collaboration. CR Visualization focuses on creating and displaying spatial data across the RVC, enabling users to navigate and interpret information fluidly. CR Interaction delves into natural user engagements using gestures, voice commands, and other advanced techniques to enhance immersion. The study of CR User Behavior and Experience investigates how users perceive and interact within these hybrid environments. Furthermore, CR Design and Development emphasizes creating effective CR applications using innovative processes and tools, while CR Collaboration examines methods for fostering teamwork in mixed reality settings.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2407.19863",
        "abstract url": "https://arxiv.org/abs/2407.19863",
        "title": "Before and After Blockchain: Development and Principle of Distributed Fault Tolerance Consensus",
        "rating": "-10",
        "keywords": [],
        "abstract": "The concept of distributed consensus gained widespread attention following the publication of ``Byzantine Generals Problem'' by Leslie Lamport in the 1980s. This research topic has been active and extensively studied over the last four decades, particularly since the advent of blockchain technology in 2009. Blockchain technology employs Proof-of-X (PoX) or Byzantine-fault-tolerant (BFT) systems, where all participants follow a protocol to achieve a common state (i.e., consistency) eventually. However, because PoX consensus such as Proof-of-Work is is resource-intensive with high power consumption, most permissioned blockchains employ BFT to achieve consistency. In this article, we provide an introduction to the fundamental principles and history of distributed consensus. We then explore the well-known fault-tolerant state machine replication (SMR) in partially synchronous networks, as well as consensus protocols in asynchronous models and recently proposed DAG-based consensus. Additionally, we examine the relationship between BFT consensus and blockchain technology and discuss the following questions: What is the history and evolution of BFT? Why are BFT protocols designed in the way they are and what core components do they use? What is the connection between BFT and blockchain technology, and what are the driving needs for future BFT research?",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19867",
        "abstract url": "https://arxiv.org/abs/2407.19867",
        "title": "Design and Testing for Steel Support Axial Force Servo System",
        "rating": "-10",
        "keywords": [],
        "abstract": "Foundation excavations are deepening, expanding, and approaching structures. Steel supports measure and manage axial force. The study regulates steel support structure power during deep excavation using a novel axial force management system for safety, efficiency, and structural integrity. Closed-loop control changes actuator output to maintain axial force based on force. In deep excavation, the servo system regulates unstable soil, side pressure, and structural demands. Modern engineering and tech are used. Temperature changes automatically adjust the jack to maintain axial force. Includes hydraulic jacks, triple-acting cylinders, temperature, and deformation sensors, and automatic control. Foundation pit excavation is dynamic, yet structure tension is constant. There is no scientific way to regulate axial force foundation pit excavation. The revolutionary Servo system adjusts temperature, compression, and axial force to deform pits. System control requires foundation pit direction detection and modification. This engineering method has performed effectively for deep foundation pit excavation at railway crossings and other infrastructure projects. The surrounding protective structure may reduce the steel support's axial stress, making deep foundation excavation safe and efficient. Keywords: Servo systems, Steel strut support design, Deformation control, Monitoring and control, Deep excavation projects.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages,7 figures, 1 table, 2 graph, conference paper"
    },
    {
        "paper id": "2407.19871",
        "abstract url": "https://arxiv.org/abs/2407.19871",
        "title": "Fast Private Location-based Information Retrieval Over the Torus",
        "rating": "-10",
        "keywords": [],
        "abstract": "Location-based services offer immense utility, but also pose significant privacy risks. In response, we propose LocPIR, a novel framework using homomorphic encryption (HE), specifically the TFHE scheme, to preserve user location privacy when retrieving data from public clouds. Our system employs TFHE's expertise in non-polynomial evaluations, crucial for comparison operations. LocPIR showcases minimal client-server interaction, reduced memory overhead, and efficient throughput. Performance tests confirm its computational speed, making it a viable solution for practical scenarios, demonstrated via application to a COVID-19 alert model. Thus, LocPIR effectively addresses privacy concerns in location-based services, enabling secure data sharing from the public cloud.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "comment": "Accepted at the IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS) 2024"
    },
    {
        "paper id": "2407.19895",
        "abstract url": "https://arxiv.org/abs/2407.19895",
        "title": "Culsans: An Efficient Snoop-based Coherency Unit for the CVA6 Open Source RISC-V application processor",
        "rating": "-10",
        "keywords": [],
        "abstract": "Symmetric Multi-Processing (SMP) based on cache coherency is crucial for high-end embedded systems like automotive applications. RISC-V is gaining traction, and open-source hardware (OSH) platforms offer solutions to issues such as IP costs and vendor dependency. Existing multi-core cache-coherent RISC-V platforms are complex and not efficient for small embedded core clusters. We propose an open-source SystemVerilog implementation of a lightweight snoop-based cache-coherent cluster of Linux-capable CVA6 cores. Our design uses the MOESI protocol via the Arm's AMBA ACE protocol. Evaluated with Splash-3 benchmarks, our solution shows up to 32.87% faster performance in a dual-core setup and an average improvement of 15.8% over OpenPiton. Synthesized using GF 22nm FDSOI technology, the Cache Coherency Unit occupies only 1.6% of the system area.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "4 pages, 4 figures, DSD2024 and SEAA2024 Works in Progress Session AUG 2024"
    },
    {
        "paper id": "2407.19901",
        "abstract url": "https://arxiv.org/abs/2407.19901",
        "title": "Environmentally Sustainable Software Design and Development: A Systematic Literature Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "The ICT sector, responsible for 2% of global carbon emissions and significant energy consumption, is under scrutiny calling for methodologies and tools to design and develop software in an environmentally sustainable-by-design manner. However, the software engineering solutions for designing and developing sustainable software are currently scattered over multiple different pieces of literature, which makes it difficult to consult the body of knowledge on the topic. In this article, we precisely conduct a systematic literature review on state-of-the-art proposals for designing and developing sustainable software. We identify and analyse 65 primary studies by classifying them through a taxonomy aimed at answering the 5W1H questions of environmentally sustainable software design and development. We first provide a reasoned overview and discussion of the existing guidelines, reference models, measurement solutions and techniques for measuring, reducing, or minimising the energy consumption and carbon footprint of software. Ultimately, we identify open challenges and research gaps, offering insights for future work in this field.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19904",
        "abstract url": "https://arxiv.org/abs/2407.19904",
        "title": "Modeling Local Search Metaheuristics Using Markov Decision Processes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Local search metaheuristics like tabu search or simulated annealing are popular heuristic optimization algorithms for finding near-optimal solutions for combinatorial optimization problems. However, it is still challenging for researchers and practitioners to analyze their behaviour and systematically choose one over a vast set of possible metaheuristics for the particular problem at hand. In this paper, we introduce a theoretical framework based on Markov Decision Processes (MDP) for analyzing local search metaheuristics. This framework not only helps in providing convergence results for individual algorithms, but also provides an explicit characterization of the exploration-exploitation tradeoff and a theory-grounded guidance for practitioners for choosing an appropriate metaheuristic for the problem at hand. We present this framework in detail and show how to apply it in the case of hill climbing and the simulated annealing algorithm.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19921",
        "abstract url": "https://arxiv.org/abs/2407.19921",
        "title": "colorspace: A Python Toolbox for Manipulating and Assessing Colors and Palettes",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Python colorspace package provides a toolbox for mapping between different color spaces which can then be used to generate a wide range of perceptually-based color palettes for qualitative or quantitative (sequential or diverging) information. These palettes (as well as any other sets of colors) can be visualized, assessed, and manipulated in various ways, e.g., by color swatches, emulating the effects of color vision deficiencies, or depicting the perceptual properties. Finally, the color palettes generated by the package can be easily integrated into standard visualization workflows in Python, e.g., using matplotlib, seaborn, or plotly.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19927",
        "abstract url": "https://arxiv.org/abs/2407.19927",
        "title": "Minimum Time Consensus of Multi-agent System under Fuel Constraints",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work addresses the problem of finding a consensus point in the state space ($\\mathbb{R}^2$) for a multi-agent system that is comprised of $N$ identical double integrator agents. It is assumed that each agent operates under constrained control input (i.e., $|u_i(t)| \\leq 1$ $\\forall i = 1, \\hdots N$). Further, a fixed fuel budget is also assumed i.e., the total amount of cumulative input that can be expended is limited by $\\int_0^{t_f}|u(t)|dt \\le \u03b2$. First, the attainable set $\\mathcal{A}(t,x_0,\u03b2)$ at time $t$, which is the set of all states that an agent can attain starting from initial conditions $x_0$ under the fuel budget constraints at time $t$ is computed for every agent. This attainable set is a convex set for all $t\\ge0$. Then the minimum time to consensus is the minimum time $\\bar{t}$ at which attainable sets of all agents intersect, and the consensus point is the point of intersection. A closed-form expression for the minimum time consensus point is provided for the case of three agents. Then, using Helly's theorem, the intersection will be non-empty at a time when all the $N \\choose 3$ triplets of agents have non-empty intersection. The computation of minimum time consensus for all $N \\choose 3$ triplets is performed independently and can be distributed among all the $N$ agents. Finally, the overall minimum time to consensus is given by the triplet that has the highest minimum time to consensus. Further, the intersection of all the attainable sets of this triplet gives the minimum time consensus point for all $N$ agents.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19928",
        "abstract url": "https://arxiv.org/abs/2407.19928",
        "title": "Enabling Message Passing Interface Containers on the LUMI Supercomputer",
        "rating": "-10",
        "keywords": [],
        "abstract": "Containers represent a convenient way of packing applications with dependencies for easy user-level installation and productivity. When running on supercomputers, it becomes crucial to optimize the containers to exploit the performance optimizations provided by the system vendors. In this paper, we discuss an approach we have developed for deploying containerized applications on the LUMI supercomputer, specifically for running applications based on Message Passing Interface (MPI) parallelization. We show how users can build and run containers and get the expected performance. The proposed MPI containers can be provided on LUMI so that users can use them as base images. Although we only refer to the LUMI supercomputer, similar concepts can be applied to the case of other supercomputers.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "13 pages, presented at the Nordic e-Infrastructure Collaboration Conference (NeIC) 2024, 27-19 May 2024, Tallinn, Estonia"
    },
    {
        "paper id": "2407.19942",
        "abstract url": "https://arxiv.org/abs/2407.19942",
        "title": "Predicting citation impact of research papers using GPT and other text embeddings",
        "rating": "-10",
        "keywords": [],
        "abstract": "The impact of research papers, typically measured in terms of citation counts, depends on several factors, including the reputation of the authors, journals, and institutions, in addition to the quality of the scientific work. In this paper, we present an approach that combines natural language processing and machine learning to predict the impact of papers in a specific journal. Our focus is on the text, which should correlate with impact and the topics covered in the research. We employed a dataset of over 40,000 articles from ACS Applied Materials and Interfaces spanning from 2012 to 2022. The data was processed using various text embedding techniques and classified with supervised machine learning algorithms. Papers were categorized into the top 20% most cited within the journal, using both yearly and cumulative citation counts as metrics. Our analysis reveals that the method employing generative pre-trained transformers (GPT) was the most efficient for embedding, while the random forest algorithm exhibited the best predictive power among the machine learning algorithms. An optimized accuracy of 80\\% in predicting whether a paper was among the top 20% most cited was achieved for the cumulative citation count when abstracts were processed. This accuracy is noteworthy, considering that author, institution, and early citation pattern information were not taken into account. The accuracy increased only slightly when the full texts of the papers were processed. Also significant is the finding that a simpler embedding technique, term frequency-inverse document frequency (TFIDF), yielded performance close to that of GPT. Since TFIDF captures the topics of the paper we infer that, apart from considering author and institution biases, citation counts for the considered journal may be predicted by identifying topics and \"reading\" the abstract of a paper.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19946",
        "abstract url": "https://arxiv.org/abs/2407.19946",
        "title": "Engineering an Efficient Approximate DNF-Counter",
        "rating": "-10",
        "keywords": [],
        "abstract": "Model counting is a fundamental problem in many practical applications, including query evaluation in probabilistic databases and failure-probability estimation of networks. In this work, we focus on a variant of this problem where the underlying formula is expressed in the Disjunctive Normal Form (DNF), also known as #DNF. This problem has been shown to be #P-complete, making it often intractable to solve exactly. Much research has therefore focused on obtaining approximate solutions, particularly in the form of $(\\varepsilon, \u03b4)$ approximations. The primary contribution of this paper is a new approach, called pepin, an approximate #DNF counter that significantly outperforms prior state-of-the-art approaches. Our work is based on the recent breakthrough in the context of the union of sets in the streaming model. We demonstrate the effectiveness of our approach through extensive experiments and show that it provides an affirmative answer to the challenge of efficiently computing #DNF.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "13 pages, 7 Figures"
    },
    {
        "paper id": "2407.19949",
        "abstract url": "https://arxiv.org/abs/2407.19949",
        "title": "R-Index: A Metric for Assessing Researcher Contributions to Peer Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "I propose the R-Index, defined as the difference between the sum of review responsibilities for a researcher's publications and the number of reviews they have completed, as a novel metric to effectively characterize a researcher's contribution to the peer review process. This index aims to balance the demands placed on the peer review system by a researcher's publication output with their engagement in reviewing others' work, providing a measure of whether they are giving back to the academic community commensurately with their own publication demands. The R-Index offers a straightforward and fair approach to encourage equitable participation in peer review, thereby supporting the sustainability and efficiency of the scholarly publishing process.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19954",
        "abstract url": "https://arxiv.org/abs/2407.19954",
        "title": "A Family of Switching Pursuit Strategies for a Multi-Pursuer Single-Evader Game",
        "rating": "-10",
        "keywords": [],
        "abstract": "A new family of pursuit strategies is introduced for a multi-pursuer single-evader game. By exploiting the optimal solution of the game involving two pursuers, conditions are derived under which the multi-pursuer game becomes equivalent to the two-pursuer one. This opens the possibility of designing a number of pursuit strategies in which the pursuers first try to enforce the satisfaction of the aforementioned condition and then switch to a two-pursuer game as soon as it is verified. The contribution is useful in two ways. First, new winning pursuit strategies can be devised starting from simple plans, such as pure pursuit. Moreover, the performance of existing pursuit strategies, like those based on Voronoi partitions, can be significantly improved by resorting to the corresponding switching version.",
        "subjects": [
            "eess.SY",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19956",
        "abstract url": "https://arxiv.org/abs/2407.19956",
        "title": "Requirements on bit resolution in optical Ising machine implementations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Optical Ising machines have emerged as a promising dynamical hardware solver for computational hard optimization problems. These Ising machines typically require an optical modulator to represent the analog spin variables of these problems. However, modern day optical modulators have a relatively low modulation resolution. We therefore investigate how the low bit-resolution of optical hardware influences the performance of this type of novel computing platform. Based on numerical simulations, we determine the minimum required bit-resolution of an optical Ising machine for different benchmark problems of different sizes. Our study shows that a limited bit-resolution of 8bit is sufficient for the optical modulator. Surprisingly, we also observe that the use of a 1bit-resolution modulator significantly improves the performance of the Ising machine across all considered benchmark problems.",
        "subjects": [
            "physics.app-ph",
            "cs.ET",
            "physics.optics"
        ],
        "comment": "8 pages and 5 main figures"
    },
    {
        "paper id": "2407.19960",
        "abstract url": "https://arxiv.org/abs/2407.19960",
        "title": "Integrated Communications and Security: RIS-Assisted Simultaneous Transmission and Generation of Secret Keys",
        "rating": "-10",
        "keywords": [],
        "abstract": "We develop a new integrated communications and security (ICAS) design paradigm by leveraging the concept of reconfigurable intelligent surfaces (RISs). In particular, we propose RIS-assisted simultaneous transmission and secret key generation by sharing the RIS for these two tasks. Specifically, the legitimate transceivers intend to jointly optimize the data transmission rate and the key generation rate by configuring the phase-shift of the RIS in the presence of a smart attacker. We first derive the key generation rate of the RIS-assisted physical layer key generation (PLKG). Then, to obtain the optimal RIS configuration, we formulate the problem as a secure transmission (ST) game and prove the existence of the Nash equilibrium (NE), and then derive the NE point of the static game. For the dynamic ST game, we model the problem as a finite Markov decision process and propose a model-free reinforcement learning approach to obtain the NE point. Particularly, considering that the legitimate transceivers cannot obtain the channel state information (CSI) of the attacker in real-world conditions, we develop a deep recurrent Q-network (DRQN) based dynamic ST strategy to learn the optimal RIS configuration. The details of the algorithm are provided, and then, the system complexity is analyzed. Our simulation results show that the proposed DRQN based dynamic ST strategy has a better performance than the benchmarks even with a partial observation information, and achieves \"one time pad\" communication by allocating a suitable weight factor for data transmission and PLKG.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.19961",
        "abstract url": "https://arxiv.org/abs/2407.19961",
        "title": "Prichain II: CloudGuardian Cloud Security Proposal with Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the advancement of cloud computing, data storage, and security have become crucial. The growing adoption of cloud services by companies, accompanied by increased threats from cybersecurity, highlights the importance of privacy and ownership of user data. Between 2022 and 2023, there has been an increase of around 48% in cloud security threats, emphasizing the urgent need for strong security solutions. To face these challenges, in this project, we propose integrating the Ethereum network's blockchain technology with a database located in the PostgreSQL cloud. The proposed solution aims to provide bidirectional data synchronization and strict control of access mechanisms. Blockchain technology ensures immutability and transparency of transactions, while PostgreSQL provides efficient and scalable storage. Through rigorous testing in an adaptive traffic control scenario, the results obtained indicate that this solution offers a significantly high level of security due to the decentralization of data, confirming that this solution is effective, and making it a powerful new option to improve security in cloud environments. In conclusion, the solution proposed in this project not only increases information security but also demonstrates the practical feasibility of integrating blockchain with cloud relational databases. This two-way alignment improves protection against cyberattacks and ensures that user data is protected from unauthorized access and malicious changes.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2407.19988",
        "abstract url": "https://arxiv.org/abs/2407.19988",
        "title": "HeadsetOff: Enabling Photorealistic Video Conferencing on Economical VR Headsets",
        "rating": "-10",
        "keywords": [],
        "abstract": "Virtual Reality (VR) headsets have become increasingly popular for remote collaboration, but video conferencing poses challenges when the user's face is covered by the headset. Existing solutions have limitations in terms of accessibility. In this paper, we propose HeadsetOff, a novel system that achieves photorealistic video conferencing on economical VR headsets by leveraging voice-driven face reconstruction. HeadsetOff consists of three main components: a multimodal attention-based predictor, a generator, and an adaptive controller. The predictor effectively predicts user future behavior based on different modalities. The generator employs voice input, head motion, and eye blink to animate the human face. The adaptive controller dynamically selects the appropriate generator model based on the trade-off between video quality and delay, aiming to maximize Quality of Experience while minimizing latency. Experimental results demonstrate the effectiveness of HeadsetOff in achieving high-quality, low-latency video conferencing on economical VR headsets.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "Accepted by ACM Multimedia 2024"
    },
    {
        "paper id": "2407.20002",
        "abstract url": "https://arxiv.org/abs/2407.20002",
        "title": "Formal Foundations for Translational Separation Logic Verifiers (extended version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "Program verification tools are often implemented as front-end translations of an input program into an intermediate verification language (IVL) such as Boogie, GIL, Viper, or Why3. The resulting IVL program is then verified using an existing back-end verifier. A soundness proof for such a translational verifier needs to relate the input program and verification logic to the semantics of the IVL, which in turn needs to be connected with the verification logic implemented in the back-end verifiers. Performing such proofs is challenging due to the large semantic gap between the input and output programs and logics, especially for complex verification logics such as separation logic. This paper presents a formal framework for reasoning about translational separation logic verifiers. At its center is a generic core IVL that captures the essence of different separation logics. We define its operational semantics and formally connect it to two different back-end verifiers, which use symbolic execution and verification condition generation, resp. Crucially, this semantics uses angelic non-determinism to enable the application of different proof search algorithms and heuristics in the back-end verifiers. An axiomatic semantics for the core IVL simplifies reasoning about the front-end translation by performing essential proof steps once and for all in the equivalence proof with the operational semantics rather than for each concrete front-end translation. We illustrate the usefulness of our formal framework by instantiating our core IVL with elements of Viper and connecting it to two Viper back-ends as well as a front-end for concurrent separation logic. All our technical results have been formalized in Isabelle/HOL, including the core IVL and its semantics, the semantics of two back-ends for a subset of Viper, and all proofs.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20018",
        "abstract url": "https://arxiv.org/abs/2407.20018",
        "title": "Efficient Training of Large Language Models on Distributed Infrastructures: A Survey",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large Language Models (LLMs) like GPT and LLaMA are revolutionizing the AI industry with their sophisticated capabilities. Training these models requires vast GPU clusters and significant computing time, posing major challenges in terms of scalability, efficiency, and reliability. This survey explores recent advancements in training systems for LLMs, including innovations in training infrastructure with AI accelerators, networking, storage, and scheduling. Additionally, the survey covers parallelism strategies, as well as optimizations for computation, communication, and memory in distributed LLM training. It also includes approaches of maintaining system reliability over extended training periods. By examining current innovations and future directions, this survey aims to provide valuable insights towards improving LLM training systems and tackling ongoing challenges. Furthermore, traditional digital circuit-based computing systems face significant constraints in meeting the computational demands of LLMs, highlighting the need for innovative solutions such as optical computing and optical networks.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20036",
        "abstract url": "https://arxiv.org/abs/2407.20036",
        "title": "Planning For Edge Failure in Fixed-Charge Flow Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Fixed-Charge Network Flow problem is a well-studied NP-hard problem that has the goal of finding a flow in a network where fixed edge costs are incurred, regardless of the amount of flow hosted by the edge. In this paper, we consider scenarios where a designated edge in the network has the potential to fail after edges have already been purchased. If the edge does fail, procurement of additional edges may be required to repair the flow and compensate for the failed edge so as to maintain the original flow amount. We formulate a multi-objective optimization problem that aims to minimize the costs of both the initial flow as well as the repaired flow. We introduce an algorithm that finds the Pareto front between these two objectives, thereby providing decision makers with a sequence of solutions that trade off initial flow cost with repaired flow cost. We demonstrate the algorithm's efficacy with an evaluation using real-world CO2 capture and storage infrastructure data.",
        "subjects": [
            "cs.DS",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20042",
        "abstract url": "https://arxiv.org/abs/2407.20042",
        "title": "When to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention",
        "rating": "-10",
        "keywords": [],
        "abstract": "Code generation aims to automatically generate code snippets that meet given natural language requirements and plays an important role in software development. Although Code LLMs have shown excellent performance in this domain, their long generation time poses a signification limitation in practice use. In this paper, we first conduct an in-depth preliminary study with different Code LLMs on code generation tasks and identify a significant efficiency issue, i.e., continual generation of excess tokens. It harms the developer productivity and leads to huge computational wastes. To address it, we introduce CodeFast, an inference acceleration approach for Code LLMs on code generation. The key idea of CodeFast is to terminate the inference process in time when unnecessary excess tokens are detected. First, we propose an automatic data construction framework to obtain training data. Then, we train a unified lightweight model GenGuard applicable to multiple programming languages to predict whether to terminate inference at the current step. Finally, we enhance Code LLM with GenGuard to accelerate its inference in code generation tasks. We conduct extensive experiments with CodeFast on five representative Code LLMs across four widely used code generation datasets. Experimental results show that (1) CodeFast can significantly improve the inference speed of various Code LLMs in code generation, ranging form 34% to 452%, without compromising the quality of generated code. (2) CodeFast is stable across different parameter settings and can generalize to untrained datasets. Our code and data are available at https://github.com/DeepSoftwareAnalytics/CodeFast",
        "subjects": [
            "cs.SE"
        ],
        "comment": "To appear at ISSTA 2024"
    },
    {
        "paper id": "2407.20045",
        "abstract url": "https://arxiv.org/abs/2407.20045",
        "title": "NegotiaToR: Towards A Simple Yet Effective On-demand Reconfigurable Datacenter Network",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent advances in fast optical switching technology show promise in meeting the high goodput and low latency requirements of datacenter networks (DCN). We present NegotiaToR, a simple network architecture for optical reconfigurable DCNs that utilizes on-demand scheduling to handle dynamic traffic. In NegotiaToR, racks exchange scheduling messages through an in-band control plane and distributedly calculate non-conflicting paths from binary traffic demand information. Optimized for incasts, it also provides opportunities to bypass scheduling delays. NegotiaToR is compatible with prevalent flat topologies, and is tailored towards a minimalist design for on-demand reconfigurable DCNs, enhancing practicality. Through large-scale simulations, we show that NegotiaToR achieves both small mice flow completion time (FCT) and high goodput on two representative flat topologies, especially under heavy loads. Particularly, the FCT of mice flows is one to two orders of magnitude better than the state-of-the-art traffic-oblivious reconfigurable DCN design.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "This paper is accepted by ACM SIGCOMM 2024"
    },
    {
        "paper id": "2407.20052",
        "abstract url": "https://arxiv.org/abs/2407.20052",
        "title": "Uncertainty Propagation and Filtering via the Koopman Operator in Astrodynamics",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Koopman Operator (KO) provides an analytical solution of dynamical systems in terms of orthogonal polynomials. This work exploits this representation to include the propagation of uncertainties, where the polynomials are modified to work with stochastic variables. Thus, a new uncertainty quantification technique is proposed, where the KO solution is expanded to include the prediction of central moments, up to an arbitrary order. The propagation of uncertainties is then expanded to develop a new filtering algorithm, where measurements are considered as additional observables in the KO mathematics. Numerical simulations in astrodynamics assess the accuracy and performance of the new methodologies.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "2022 AAS/AIAA Astrodynamics Specialist Conference"
    },
    {
        "paper id": "2407.20088",
        "abstract url": "https://arxiv.org/abs/2407.20088",
        "title": "As Transparent as Possible, System Implementation Governance Using Process Mining",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper advocates for guiding an effective system implementation approach at a business process level. It details a case study of a food product manufacturer that transitioned to a new local information system. 41 units' data (10160 cases) over the pre-maturity phase of the system were then structured into event logs and analyzed. This analysis identified deviant process paths, questioning whether the new system efficiently supports procurement operations immediately post-implementation. The findings reveal critical implementation risks with conformance-checking of the as-is process with the to-be process model; this includes incomplete cases, unauthorized activities, irregular payment practices, stemming from organizational bottlenecks, or violating internal control regulations. Challenges are attributed to technical shortcomings in system design and cultural misalignments, necessitating immediate interventions or longer-term cultural and training solutions. This study's contribution is its demonstration of a transparent, process-driven approach to system governance, highlighting the strategic benefits of this integration for organizational management.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20095",
        "abstract url": "https://arxiv.org/abs/2407.20095",
        "title": "Crafting Generative Art through Genetic Improvement: Managing Creative Outputs in Diverse Fitness Landscapes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Generative art is a rules-driven approach to creating artistic outputs in various mediums. For example, a fluid simulation can govern the flow of colored pixels across a digital display or a rectangle placement algorithm can yield a Mondrian-style painting. Previously, we investigated how genetic improvement, a sub-field of genetic programming, can automatically create and optimize generative art drawing programs. One challenge of applying genetic improvement to generative art is defining fitness functions and their interaction in a many-objective evolutionary algorithm such as Lexicase selection. Here, we assess the impact of each fitness function in terms of the their individual effects on generated images, characteristics of generated programs, and impact of bloat on this specific domain. Furthermore, we have added an additional fitness function that uses a classifier for mimicking a human's assessment as to whether an output is considered as \"art.\" This classifier is trained on a dataset of input images resembling the glitch art aesthetic that we aim to create. Our experimental results show that with few fitness functions, individual generative techniques sweep across populations. Moreover, we found that compositions tended to be driven by one technique with our current fitness functions. Lastly, we show that our classifier is best suited for filtering out noisy images, ideally leading towards more outputs relevant to user preference.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20103",
        "abstract url": "https://arxiv.org/abs/2407.20103",
        "title": "What Can Interactive Visualization do for Participatory Budgeting in Chicago?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Participatory budgeting (PB) is a democratic approach to allocating municipal spending that has been adopted in many places in recent years, including in Chicago. Current PB voting resembles a ballot where residents are asked which municipal projects, such as school improvements and road repairs, to fund with a limited budget. In this work, we ask how interactive visualization can benefit PB by conducting a design probe-based interview study (N=13) with policy workers and academics with expertise in PB, urban planning, and civic HCI. Our probe explores how graphical elicitation of voter preferences and a dashboard of voting statistics can be incorporated into a realistic PB tool. Through qualitative analysis, we find that visualization creates opportunities for city government to set expectations about budget constraints while also granting their constituents greater freedom to articulate a wider range of preferences. However, using visualization to provide transparency about PB requires efforts to mitigate potential access barriers and mistrust. We call for more visualization professionals to help build civic capacity by working in and studying political systems.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20123",
        "abstract url": "https://arxiv.org/abs/2407.20123",
        "title": "Context-Aware CSI Tracking and Path Loss Prediction Using Machine Learning and Dynamical Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present an advanced model for Channel State Information (CSI) tracking, leveraging a dynamical system approach to adapt CSI dynamically based on exogenous contextual information. This methodology allows for continuous updates to the Channel Knowledge Map (CKM), enhancing communication reliability and responsiveness in dynamic environments. To generate realistic and comprehensive datasets for training and evaluation, we developed a new MATLAB simulator that models radio wave propagation in urban environments. We address the challenge of real-time CKM adaptation using online learning of the Koopman operator, a technique that forecasts channel behaviour by exploiting dynamical system properties. Our approach supports real-time updates with high accuracy and efficiency, as demonstrated by experiments with varying window sizes for the Koopman Autoencoder model. A window size of 100 was found to offer the best balance between prediction accuracy (RMSE: 1.8323 +- 1.1071, MAE: 0.3780 +- 0.2221) and computational efficiency (training time: 231.1 +- 82.5 ms, prediction time: 109.0 +- 55.7 ms). Additionally, we introduce a moving window mechanism to address privacy and security concerns by updating the Koopman operator within the window and purging input data thereafter, minimising data retention and storage risks. This ensures the CKM remains accurate and relevant while maintaining stringent data privacy standards. Our findings suggest that this approach can significantly improve the resilience and security of communication systems, making them highly adaptable to environmental changes without compromising user privacy.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20128",
        "abstract url": "https://arxiv.org/abs/2407.20128",
        "title": "Finite-Sample Guarantees for Best-Response Learning Dynamics in Zero-Sum Matrix Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study best-response type learning dynamics for two player zero-sum matrix games. We consider two settings that are distinguished by the type of information that each player has about the game and their opponent's strategy. The first setting is the full information case, in which each player knows their own and the opponent's payoff matrices and observes the opponent's mixed strategy. The second setting is the minimal information case, where players do not observe the opponent's strategy and are not aware of either of the payoff matrices (instead they only observe their realized payoffs). For this setting, also known as the radically uncoupled case in the learning in games literature, we study a two-timescale learning dynamics that combine smoothed best-response type updates for strategy estimates with a TD-learning update to estimate a local payoff function. For these dynamics, without additional exploration, we provide polynomial-time finite-sample guarantees for convergence to an $\u03b5$-Nash equilibrium.",
        "subjects": [
            "math.OC",
            "cs.GT",
            "stat.ML"
        ],
        "comment": "35 pages; under review"
    },
    {
        "paper id": "2407.20139",
        "abstract url": "https://arxiv.org/abs/2407.20139",
        "title": "Emission Reduction in Urban Environments by Replacing Conventional City Buses with Electric Bus Technology: A Case Study of Pakistan",
        "rating": "-10",
        "keywords": [],
        "abstract": "The global transportation industry has become one of the main contributors to air pollution. Consequently, electric buses and green transportation are gaining popularity as crucial steps to reduce emission concerns. Many developed countries have already adopted the concept of Battery Electric Buses (BEBs), while the developing ones are just starting with it. However, BEB fleets have advantages, such as lower fuel, higher efficiency, lower maintenance, and energy security. Yet, several obstacles must be overcome to support the mass deployment of BEBs. These incorporate forthright expense charges, arranging loads, BEB reach, and newness to BEB innovation. Stakeholders like policymakers, private company owners, and government leaders have a lot to consider before introducing BEBs at any level in Pakistan. As a result, to operate an electric bus system profitably, it is crucial to develop a proper electric bus network and fleet, especially for bus operators who need to buy enough electric buses at the appropriate time. As a result, this paper aims to investigate if operating an electric bus could be an alternative to regular bus operations. The proposed methodology develops modeling software to cater to various scenarios to determine a proper-designed electric bus operating system in terms of the electric bus route, service frequency, and quantity. This research work simulates and financially analyses an operating Public Transport Infrastructure with a proposed Green Solution. The results show that regardless of the high upfront costs of BEB infrastructure, it becomes profitable in 6-7 years, resulting in a decreased Total Cost of Ownership (TCO) of approximately 30% of its counterpart. The study also provides a clear policy pathway to help stakeholders make informed decisions related to the electrification of public transport in Pakistan.",
        "subjects": [
            "econ.GN",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20165",
        "abstract url": "https://arxiv.org/abs/2407.20165",
        "title": "Meta-Learning for Adaptive Control with Automated Mirror Descent",
        "rating": "-10",
        "keywords": [],
        "abstract": "Adaptive control achieves concurrent parameter learning and stable control under uncertainties that are linearly parameterized with known nonlinear features. Nonetheless, it is often difficult to obtain such nonlinear features. To address this difficulty, recent progress has been made in integrating meta-learning with adaptive control to learn such nonlinear features from data. However, these meta-learning-based control methods rely on classical adaptation laws using gradient descent, which is confined to the Euclidean geometry. In this paper, we propose a novel method that combines meta-learning and adaptation laws based on mirror descent, a popular generalization of gradient descent, which takes advantage of the potentially non-Euclidean geometry of the parameter space. In our approach, meta-learning not only learns the nonlinear features but also searches for a suitable mirror-descent potential function that optimizes control performance. Through numerical simulations, we demonstrate the effectiveness of the proposed method in learning efficient representations and real-time tracking control performance under uncertain dynamics.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20170",
        "abstract url": "https://arxiv.org/abs/2407.20170",
        "title": "Propagation of Uncertainty with the Koopman Operator",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes a new method to propagate uncertainties undergoing nonlinear dynamics using the Koopman Operator (KO). Probability density functions are propagated directly using the Koopman approximation of the solution flow of the system, where the dynamics have been projected on a well-defined set of basis functions. The prediction technique is derived following both the analytical (Galerkin) and numerical (EDMD) derivation of the KO, and a least square reduction algorithm assures the recursivity of the proposed methodology.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "27th Conference of Information Fusion ID 14"
    },
    {
        "paper id": "2407.20187",
        "abstract url": "https://arxiv.org/abs/2407.20187",
        "title": "Eliminating Majority Illusion is Easy",
        "rating": "-10",
        "keywords": [],
        "abstract": "Majority Illusion is a phenomenon in social networks wherein the decision by the majority of the network is not the same as one's personal social circle's majority, leading to an incorrect perception of the majority in a large network. In this paper, we present polynomial-time algorithms which can eliminate majority illusion in a network by altering as few connections as possible. Additionally, we prove that the more general problem of ensuring all neighbourhoods in the network are at least a $p$-fraction of the majority is NP-hard for most values of $p$.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20204",
        "abstract url": "https://arxiv.org/abs/2407.20204",
        "title": "Constant-Cost Communication is not Reducible to k-Hamming Distance",
        "rating": "-10",
        "keywords": [],
        "abstract": "Every known communication problem whose randomized communication cost is constant (independent of the input size) can be reduced to $k$-Hamming Distance, that is, solved with a constant number of deterministic queries to some $k$-Hamming Distance oracle. We exhibit the first examples of constant-cost problems which cannot be reduced to $k$-Hamming Distance. To prove this separation, we relate it to a natural coding-theoretic question. For $f : \\{2, 4, 6\\} \\to \\mathbb{N}$, we say an encoding function $E : \\{0, 1\\}^n \\to \\{0, 1\\}^m$ is an $f$-code if it transforms Hamming distances according to $\\mathrm{dist}(E(x), E(y)) = f(\\mathrm{dist}(x, y))$ whenever $f$ is defined. We prove that, if there exist $f$-codes for infinitely many $n$, then $f$ must be affine: $f(4) = (f(2) + f(6))/2$.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20205",
        "abstract url": "https://arxiv.org/abs/2407.20205",
        "title": "Fast computation of permanents over $\\mathbb{F}_3$ via $\\mathbb{F}_2$ arithmetic",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a method of representing an element of $\\mathbb{F}_3^n$ as an element of $\\mathbb{F}_n^2 \\times \\mathbb{F}_n^2$ which in practice will be a pair of unsigned integers. We show how to do addition, subtraction and pointwise multiplication and division of such vectors quickly using primitive binary operations (and, or, xor). We use this machinery to develop a fast algorithm for computing the permanent of a matrix in $\\mathbb{F}_3^{n\\times n}$. We present Julia code for a natural implementation of the permanent and show that our improved implementation gives, roughly, a factor of 80 speedup for problems of practical size. Using this improved code, we perform Monte Carlo simulations that suggest that the distribution of $\\mbox{perm}(A)$ tends to the uniform distribution as $n \\to \\infty$.",
        "subjects": [
            "cs.DS",
            "math.CO"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2407.20362",
        "abstract url": "https://arxiv.org/abs/2407.20362",
        "title": "Generalized Ellipsoids",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce a family of symmetric convex bodies called generalized ellipsoids of degree $d$ (GE-$d$s), with ellipsoids corresponding to the case of $d=0$. Generalized ellipsoids (GEs) retain many geometric, algebraic, and algorithmic properties of ellipsoids. We show that the conditions that the parameters of a GE must satisfy can be checked in strongly polynomial time, and that one can search for GEs of a given degree by solving a semidefinite program whose size grows only linearly with dimension. We give an example of a GE which does not have a second-order cone representation, but show that every GE has a semidefinite representation whose size depends linearly on both its dimension and degree. In terms of expressiveness, we prove that for any integer $m\\geq 2$, every symmetric full-dimensional polytope with $2m$ facets and every intersection of $m$ co-centered ellipsoids can be represented exactly as a GE-$d$ with $d \\leq 2m-3$. Using this result, we show that every symmetric convex body can be approximated arbitrarily well by a GE-$d$ and we quantify the quality of the approximation as a function of the degree $d$. Finally, we present applications of GEs to several areas, such as time-varying portfolio optimization, stability analysis of switched linear systems, robust-to-dynamics optimization, and robust polynomial regression.",
        "subjects": [
            "math.OC",
            "eess.SY",
            "math.AG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20390",
        "abstract url": "https://arxiv.org/abs/2407.20390",
        "title": "Hug Reports: Supporting Expression of Appreciation between Users and Contributors of Open Source Software Packages",
        "rating": "-10",
        "keywords": [],
        "abstract": "Contributors to open source software packages often describe feeling discouraged by the lack of positive feedback from users. This paper describes a technology probe, Hug Reports, that provides users a communication affordance within their code editors, through which users can convey appreciation to contributors of packages they use. In our field study, 18 users interacted with the probe for 3 weeks, resulting in messages of appreciation to 550 contributors, 26 of whom participated in subsequent research. Our findings show how locating a communication affordance within the code editor, and allowing users to express appreciation in terms of the abstractions they are exposed to (packages, modules, functions), can support exchanges of appreciation that are meaningful to users and contributors. Findings also revealed the moments in which users expressed appreciation, the two meanings that appreciation took on -- as a measure of utility and as an act of expressive communication -- and how contributors' reactions to appreciation were influenced by their perceived level of contribution. Based on these findings, we discuss opportunities and challenges for designing appreciation systems for open source in particular, and peer production communities more generally.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20402",
        "abstract url": "https://arxiv.org/abs/2407.20402",
        "title": "Channel Estimation for Beyond Diagonal RIS via Tensor Decomposition",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper addresses the channel estimation problem for beyond diagonal reconfigurable intelligent surface (BD-RIS) from a tensor decomposition perspective. We first show that the received pilot signals can be arranged as a three-way tensor, allowing us to recast the cascaded channel estimation problem as a block Tucker decomposition problem that yields decoupled estimates for the involved channel matrices while offering a substantial performance gain over the conventional (matrix-based) least squares (LS) estimation method. More specifically, we develop two solutions to solve the problem. The first one is a closed-form solution that extracts the channel estimates via a block Tucker Kronecker factorization (BTKF), which boils down to solving a set of parallel rank-one matrix approximation problems. Exploiting such a low-rank property yields a noise rejection gain compared to the standard LS estimation scheme while allowing the two involved channels to be estimated separately. The second solution is based on a block Tucker alternating least squares (BTALS) algorithm that directly estimates the involved channel matrices using an iterative estimation procedure. We discuss the uniqueness and identifiability issues and their implications for training design. We also propose a tensor-based design of the BD-RIS training tensor for each algorithm that ensures unique decoupled channel estimates under trivial scaling ambiguities. Our numerical results shed light on the tradeoffs offered by BTKF and BTALS methods. Specifically, while the first enjoys fast and parallel extraction of the channel estimates in closed form, the second has a more flexible training design, allowing for a significantly reduced training overhead compared to the state-of-the-art LS method.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20419",
        "abstract url": "https://arxiv.org/abs/2407.20419",
        "title": "Randomized Rounding Approaches to Online Allocation, Sequencing, and Matching",
        "rating": "-10",
        "keywords": [],
        "abstract": "Randomized rounding is a technique that was originally used to approximate hard offline discrete optimization problems from a mathematical programming relaxation. Since then it has also been used to approximately solve sequential stochastic optimization problems, overcoming the curse of dimensionality. To elaborate, one first writes a tractable linear programming relaxation that prescribes probabilities with which actions should be taken. Rounding then designs a (randomized) online policy that approximately preserves all of these probabilities, with the challenge being that the online policy faces hard constraints, whereas the prescribed probabilities only have to satisfy these constraints in expectation. Moreover, unlike classical randomized rounding for offline problems, the online policy's actions unfold sequentially over time, interspersed by uncontrollable stochastic realizations that affect the feasibility of future actions. This tutorial provides an introduction for using randomized rounding to design online policies, through four self-contained examples representing fundamental problems in the area: online contention resolution, stochastic probing, stochastic knapsack, and stochastic matching.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "To appear as an INFORMS 2024 Tutorial"
    },
    {
        "paper id": "2407.20422",
        "abstract url": "https://arxiv.org/abs/2407.20422",
        "title": "Greedy Conjecture for the Shortest Common Superstring Problem and its Strengthenings",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the Shortest Common Superstring problem, one needs to find the shortest superstring for a set of strings. This problem is APX-hard, and many approximation algorithms were proposed, with the current best approximation factor of 2.466. Whereas these algorithms are technically involved, for more than thirty years the Greedy Conjecture remains unsolved, that states that the Greedy Algorithm ``take two strings with the maximum overlap; merge them; repeat'' is a 2-approximation. This conjecture is still open, and one way to approach it is to consider its stronger version, which may make the proof easier due to the stronger premise or provide insights from its refutation. In this paper, we propose two directions to strengthen the conjecture. First, we introduce the Locally Greedy Algorithm (LGA), that selects a pair of strings not with the largest overlap but with the \\emph{locally largest} overlap, that is, the largest among all pairs of strings with the same first or second string. Second, we change the quality metric: instead of length, we evaluate the solution by the number of occurrences of an arbitrary symbol. Despite the double strengthening, we prove that LGA is a \\emph{uniform} 4-approximation, that is, it always constructs a superstring with no more than four times as many occurrences of an arbitrary symbol as any other superstring. At the same time, we discover the limitations of the greedy heuristic: we show that LGA is at least 3-approximation, and the Greedy Algorithm is at least uniform 2.5-approximation. These result show that if the Greedy Conjecture is true, it is not because the Greedy Algorithm is locally greedy or is uniformly 2-approximation.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20431",
        "abstract url": "https://arxiv.org/abs/2407.20431",
        "title": "Limitations of Validity Intervals in Data Freshness Management",
        "rating": "-10",
        "keywords": [],
        "abstract": "In data-intensive real-time applications, such as smart transportation and manufacturing, ensuring data freshness is essential, as using obsolete data can lead to negative outcomes. Validity intervals serve as the standard means to specify freshness requirements in real-time databases. In this paper, we bring attention to significant drawbacks of validity intervals that have largely been unnoticed and introduce a new definition of data freshness, while discussing future research directions to address these limitations.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20441",
        "abstract url": "https://arxiv.org/abs/2407.20441",
        "title": "Finite-Time Analysis of Asynchronous Multi-Agent TD Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent research endeavours have theoretically shown the beneficial effect of cooperation in multi-agent reinforcement learning (MARL). In a setting involving $N$ agents, this beneficial effect usually comes in the form of an $N$-fold linear convergence speedup, i.e., a reduction - proportional to $N$ - in the number of iterations required to reach a certain convergence precision. In this paper, we show for the first time that this speedup property also holds for a MARL framework subject to asynchronous delays in the local agents' updates. In particular, we consider a policy evaluation problem in which multiple agents cooperate to evaluate a common policy by communicating with a central aggregator. In this setting, we study the finite-time convergence of \\texttt{AsyncMATD}, an asynchronous multi-agent temporal difference (TD) learning algorithm in which agents' local TD update directions are subject to asynchronous bounded delays. Our main contribution is providing a finite-time analysis of \\texttt{AsyncMATD}, for which we establish a linear convergence speedup while highlighting the effect of time-varying asynchronous delays on the resulting convergence rate.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20456",
        "abstract url": "https://arxiv.org/abs/2407.20456",
        "title": "Learning to Provably Satisfy High Relative Degree Constraints for Black-Box Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we develop a method for learning a control policy guaranteed to satisfy an affine state constraint of high relative degree in closed loop with a black-box system. Previous reinforcement learning (RL) approaches to satisfy safety constraints either require access to the system model, or assume control affine dynamics, or only discourage violations with reward shaping. Only recently have these issues been addressed with POLICEd RL, which guarantees constraint satisfaction for black-box systems. However, this previous work can only enforce constraints of relative degree 1. To address this gap, we build a novel RL algorithm explicitly designed to enforce an affine state constraint of high relative degree in closed loop with a black-box control system. Our key insight is to make the learned policy be affine around the unsafe set and to use this affine region to dissipate the inertia of the high relative degree constraint. We prove that such policies guarantee constraint satisfaction for deterministic systems while being agnostic to the choice of the RL training algorithm. Our results demonstrate the capacity of our approach to enforce hard constraints in the Gym inverted pendulum and on a space shuttle landing simulation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "CDC 2024"
    },
    {
        "paper id": "2407.20474",
        "abstract url": "https://arxiv.org/abs/2407.20474",
        "title": "Two parallel dynamic lexicographic algorithms for factorization sets in numerical semigroups",
        "rating": "-10",
        "keywords": [],
        "abstract": "To the existing dynamic algorithm FactorizationsUpToElement for factorization sets of elements in a numerical semigroup, we add lexicographic and parallel behavior. To the existing parallel lexicographic algorithm for the same, we add dynamic behavior. The (dimensionwise) dynamic algorithm is parallelized either elementwise or factorizationwise, while the parallel lexicographic algorithm is made dynamic with low-dimension tabulation. The tabulation for the parallel lexicographic algorithm can itself be performed using the dynamic algorithm. We provide reference CUDA implementations with measured runtimes.",
        "subjects": [
            "math.AC",
            "cs.DC",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20479",
        "abstract url": "https://arxiv.org/abs/2407.20479",
        "title": "RE#: High Performance Derivative-Based Regex Matching with Intersection, Complement and Lookarounds",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a tool and theory RE# for regular expression matching that is built on symbolic derivatives, does not use backtracking, and, in addition to the classical operators, also supports complement, intersection and lookarounds. We develop the theory formally and show that the main matching algorithm has input-linear complexity both in theory as well as experimentally. We apply thorough evaluation on popular benchmarks that show that RE# is over 71% faster than the next fastest regex engine in Rust on the baseline, and outperforms all state-of-the-art engines on extensions of the benchmarks often by several orders of magnitude.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20494",
        "abstract url": "https://arxiv.org/abs/2407.20494",
        "title": "MLOPS in a multicloud environment: Typical Network Topology",
        "rating": "-10",
        "keywords": [],
        "abstract": "As artificial intelligence, machine learning, and data science continue to drive the data-centric economy, the challenges of implementing machine learning on a single machine due to extensive data and computational needs have led to the adoption of cloud computing solutions. This research paper explores the design and implementation of a secure, cloud-native machine learning operations (MLOPS) pipeline that supports multi-cloud environments. The primary objective is to create a robust infrastructure that facilitates secure data collection, real-time model inference, and efficient management of the machine learning lifecycle. By leveraging cloud providers' capabilities, the solution aims to streamline the deployment and maintenance of machine learning models, ensuring high availability, scalability, and security. This paper details the network topology, problem description, business and technical requirements, trade-offs, and the provider selection process for achieving an optimal MLOPS environment.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "56 pages"
    },
    {
        "paper id": "2407.20521",
        "abstract url": "https://arxiv.org/abs/2407.20521",
        "title": "Integrability and Linearizability of a Family of Three-Dimensional Polynomial Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We investigate the local integrability and linearizability of a family of three-dimensional polynomial systems with the matrix of the linear approximation having the eigenvalues $1, \u03b6, \u03b6^2 $, where $\u03b6$ is a primitive cubic root of unity. We establish a criterion for the convergence of the Poincar\u00e9--Dulac normal form of the systems and examine the relationship between the normal form and integrability. Additionally, we introduce an efficient algorithm to determine the necessary conditions for the integrability of the systems. This algorithm is then applied to a quadratic subfamily of the systems to analyze its integrability and linearizability. Our findings offer insights into the integrability properties of three-dimensional polynomial systems.",
        "subjects": [
            "math.DS",
            "cs.SC"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20523",
        "abstract url": "https://arxiv.org/abs/2407.20523",
        "title": "Wireless Multi-User Interactive Virtual Reality in Metaverse with Edge-Device Collaborative Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "The immersive nature of the metaverse presents significant challenges for wireless multi-user interactive virtual reality (VR), such as ultra-low latency, high throughput and intensive computing, which place substantial demands on the wireless bandwidth and rendering resources of mobile edge computing (MEC). In this paper, we propose a wireless multi-user interactive VR with edge-device collaborative computing framework to overcome the motion-to-photon (MTP) threshold bottleneck. Specifically, we model the serial-parallel task execution in queues within a foreground and background separation architecture. The rendering indices of background tiles within the prediction window are determined, and both the foreground and selected background tiles are loaded into respective processing queues based on the rendering locations. To minimize the age of sensor information and the power consumption of mobile devices, we optimize rendering decisions and MEC resource allocation subject to the MTP constraint. To address this optimization problem, we design a safe reinforcement learning (RL) algorithm, active queue management-constrained updated projection (AQM-CUP). AQM-CUP constructs an environment suitable for queues, incorporating expired tiles actively discarded in processing buffers into its state and reward system. Experimental results demonstrate that the proposed framework significantly enhances user immersion while reducing device power consumption, and the superiority of the proposed AQM-CUP algorithm over conventional methods in terms of the training convergence and performance metrics.",
        "subjects": [
            "cs.IT",
            "cs.MM"
        ],
        "comment": "submitted to IEEE journal"
    },
    {
        "paper id": "2407.20532",
        "abstract url": "https://arxiv.org/abs/2407.20532",
        "title": "Scalable Synthesis of Formally Verified Neural Value Function for Hamilton-Jacobi Reachability Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Hamilton-Jacobi (HJ) reachability analysis provides a formal method for guaranteeing safety in constrained control problems. It synthesizes a value function to represent a long-term safe set called feasible region. Early synthesis methods based on state space discretization cannot scale to high-dimensional problems, while recent methods that use neural networks to approximate value functions result in unverifiable feasible regions. To achieve both scalability and verifiability, we propose a framework for synthesizing verified neural value functions for HJ reachability analysis. Our framework consists of three stages: pre-training, adversarial training, and verification-guided training. We design three techniques to address three challenges to improve scalability respectively: boundary-guided backtracking (BGB) to improve counterexample search efficiency, entering state regularization (ESR) to enlarge feasible region, and activation pattern alignment (APA) to accelerate neural network verification. We also provide a neural safety certificate synthesis and verification benchmark called Cersyve-9, which includes nine commonly used safe control tasks and supplements existing neural network verification benchmarks. Our framework successfully synthesizes verified neural value functions on all tasks, and our proposed three techniques exhibit superior scalability and efficiency compared with existing methods.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20536",
        "abstract url": "https://arxiv.org/abs/2407.20536",
        "title": "Single-BS Simultaneous Environment Sensing and UE Localization without LoS Path by Exploiting Near-Field Scatterers",
        "rating": "-10",
        "keywords": [],
        "abstract": "As the mobile communication network evolves over the past few decades, localizing user equipment (UE) has become an important network service. While localization in line-of-sight (LoS) scenarios has reached a level of maturity, it is known that in far-field scenarios without a LoS path nor any prior information about the scatterers, accurately localizing the UE is impossible. In this letter, we show that this becomes possible if there are scatterers in the near-field region of the base station (BS) antenna arrays. Specifically, by exploiting the additional distance sensing capability of extremely large-scale antenna arrays (XL-arrays) provided by near-field effects, we propose a novel method that simultaneously performs environment sensing and non-line-of-sight (NLoS) UE localization using one single BS. In the proposed method, the BS leverages the near-field characteristics of XL-arrays to directly estimate the locations of the near-field scatterers with array signal processing, which then serves as virtual anchors for UE localization. Then, the propagation delay for each path is estimated and the position of the UE is obtained based on the positions of scatterers and the path delays. Simulation results demonstrate that the proposed method achieves superior accuracy and robustness with similar complexity compared with benchmark methods.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Accepted by IEEE Communication Letters"
    },
    {
        "paper id": "2407.20537",
        "abstract url": "https://arxiv.org/abs/2407.20537",
        "title": "Switchboard: An Open-Source Framework for Modular Simulation of Large Hardware Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Scaling up hardware systems has become an important tactic for improving performance as Moore's law fades. Unfortunately, simulations of large hardware systems are often a design bottleneck due to slow throughput and long build times. In this article, we propose a solution targeting designs composed of modular blocks connected by latency-insensitive interfaces. Our approach is to construct the hardware simulation in a similar fashion as the design itself, using a prebuilt simulator for each block and connecting the simulators via fast shared-memory queues at runtime. This improves build time, because simulation scale-up simply involves running more instances of the prebuilt simulators. It also addresses simulation speed, because prebuilt simulators can run in parallel, without fine-grained synchronization or global barriers. We introduce a framework, Switchboard, that implements our approach, and discuss two applications, demonstrating its speed, scalability, and accuracy: (1) a web application where users can run fast simulations of chiplets on an interposer, and (2) a wafer-scale simulation of one million RISC-V cores distributed across thousands of cloud compute cores.",
        "subjects": [
            "cs.DC",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2407.20539",
        "abstract url": "https://arxiv.org/abs/2407.20539",
        "title": "Memristive Linear Algebra",
        "rating": "-10",
        "keywords": [],
        "abstract": "The advent of memristive devices offers a promising avenue for efficient and scalable analog computing, particularly for linear algebra operations essential in various scientific and engineering applications. This paper investigates the potential of memristive crossbars in implementing matrix inversion algorithms. We explore both static and dynamic approaches, emphasizing the advantages of analog and in-memory computing for matrix operations beyond multiplication. Our results demonstrate that memristive arrays can significantly reduce computational complexity and power consumption compared to traditional digital methods for certain matrix tasks. Furthermore, we address the challenges of device variability, precision, and scalability, providing insights into the practical implementation of these algorithms.",
        "subjects": [
            "cond-mat.mes-hall",
            "cs.DC",
            "math.CA",
            "math.DS",
            "nlin.AO"
        ],
        "comment": "11 pages, 2 columns + Appendices"
    }
]