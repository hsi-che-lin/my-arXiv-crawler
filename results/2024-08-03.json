[
    {
        "paper id": "2408.01682",
        "abstract url": "https://arxiv.org/abs/2408.01682",
        "title": "Multi-Frame Vision-Language Model for Long-form Reasoning in Driver Behavior Analysis",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Identifying risky driving behavior in real-world situations is essential for the safety of both drivers and pedestrians. However, integrating natural language models in this field remains relatively untapped. To address this, we created a novel multi-modal instruction tuning dataset and driver coaching inference system. Our primary use case is dashcam-based coaching for commercial drivers. The North American Dashcam Market is expected to register a CAGR of 15.4 percent from 2022 to 2027. Our dataset enables language models to learn visual instructions across various risky driving scenarios, emphasizing detailed reasoning crucial for effective driver coaching and managerial comprehension. Our model is trained on road-facing and driver-facing RGB camera footage, capturing the comprehensive scope of driving behavior in vehicles equipped with dashcams.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": "On-going work"
    },
    {
        "paper id": "2408.01708",
        "abstract url": "https://arxiv.org/abs/2408.01708",
        "title": "AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual Segmentation",
        "rating": "2",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, transformer-based models have demonstrated remarkable performance on audio-visual segmentation (AVS) tasks. However, their expensive computational cost makes real-time inference impractical. By characterizing attention maps of the network, we identify two key obstacles in AVS models: 1) attention dissipation, corresponding to the over-concentrated attention weights by Softmax within restricted frames, and 2) inefficient, burdensome transformer decoder, caused by narrow focus patterns in early stages. In this paper, we introduce AVESFormer, the first real-time Audio-Visual Efficient Segmentation transformer that achieves fast, efficient and light-weight simultaneously. Our model leverages an efficient prompt query generator to correct the behaviour of cross-attention. Additionally, we propose ELF decoder to bring greater efficiency by facilitating convolutions suitable for local features to reduce computational burdens. Extensive experiments demonstrate that our AVESFormer significantly enhances model performance, achieving 79.9% on S4, 57.9% on MS3 and 31.2% on AVSS, outperforming previous state-of-the-art and achieving an excellent trade-off between performance and speed. Code can be found at https://github.com/MarkXCloud/AVESFormer.git.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01835",
        "abstract url": "https://arxiv.org/abs/2408.01835",
        "title": "TS-SAM: Fine-Tuning Segment-Anything Model for Downstream Tasks",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Adapter based fine-tuning has been studied for improving the performance of SAM on downstream tasks. However, there is still a significant performance gap between fine-tuned SAMs and domain-specific models. To reduce the gap, we propose Two-Stream SAM (TS-SAM). On the one hand, inspired by the side network in Parameter-Efficient Fine-Tuning (PEFT), we designed a lightweight Convolutional Side Adapter (CSA), which integrates the powerful features from SAM into side network training for comprehensive feature fusion. On the other hand, in line with the characteristics of segmentation tasks, we designed Multi-scale Refinement Module (MRM) and Feature Fusion Decoder (FFD) to keep both the detailed and semantic features. Extensive experiments on ten public datasets from three tasks demonstrate that TS-SAM not only significantly outperforms the recently proposed SAM-Adapter and SSOM, but achieves competitive performance with the SOTA domain-specific models. Our code is available at: https://github.com/maoyangou147/TS-SAM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01669",
        "abstract url": "https://arxiv.org/abs/2408.01669",
        "title": "SynopGround: A Large-Scale Dataset for Multi-Paragraph Video Grounding from TV Dramas and Synopses",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video grounding is a fundamental problem in multimodal content understanding, aiming to localize specific natural language queries in an untrimmed video. However, current video grounding datasets merely focus on simple events and are either limited to shorter videos or brief sentences, which hinders the model from evolving toward stronger multimodal understanding capabilities. To address these limitations, we present a large-scale video grounding dataset named SynopGround, in which more than 2800 hours of videos are sourced from popular TV dramas and are paired with accurately localized human-written synopses. Each paragraph in the synopsis serves as a language query and is manually annotated with precise temporal boundaries in the long video. These paragraph queries are tightly correlated to each other and contain a wealth of abstract expressions summarizing video storylines and specific descriptions portraying event details, which enables the model to learn multimodal perception on more intricate concepts over longer context dependencies. Based on the dataset, we further introduce a more complex setting of video grounding dubbed Multi-Paragraph Video Grounding (MPVG), which takes as input multiple paragraphs and a long video for grounding each paragraph query to its temporal interval. In addition, we propose a novel Local-Global Multimodal Reasoner (LGMR) to explicitly model the local-global structures of long-term multimodal inputs for MPVG. Our method provides an effective baseline solution to the multi-paragraph video grounding problem. Extensive experiments verify the proposed model's effectiveness as well as its superiority in long-term multi-paragraph video grounding over prior state-of-the-arts. Dataset and code are publicly available. Project page: https://synopground.github.io/.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted to ACM MM 2024. Project page: https://synopground.github.io/"
    },
    {
        "paper id": "2408.01690",
        "abstract url": "https://arxiv.org/abs/2408.01690",
        "title": "IDNet: A Novel Dataset for Identity Document Analysis and Fraud Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Effective fraud detection and analysis of government-issued identity documents, such as passports, driver's licenses, and identity cards, are essential in thwarting identity theft and bolstering security on online platforms. The training of accurate fraud detection and analysis tools depends on the availability of extensive identity document datasets. However, current publicly available benchmark datasets for identity document analysis, including MIDV-500, MIDV-2020, and FMIDV, fall short in several respects: they offer a limited number of samples, cover insufficient varieties of fraud patterns, and seldom include alterations in critical personal identifying fields like portrait images, limiting their utility in training models capable of detecting realistic frauds while preserving privacy. In response to these shortcomings, our research introduces a new benchmark dataset, IDNet, designed to advance privacy-preserving fraud detection efforts. The IDNet dataset comprises 837,060 images of synthetically generated identity documents, totaling approximately 490 gigabytes, categorized into 20 types from $10$ U.S. states and 10 European countries. We evaluate the utility and present use cases of the dataset, illustrating how it can aid in training privacy-preserving fraud detection methods, facilitating the generation of camera and video capturing of identity documents, and testing schema unification and other identity document management functionalities.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "40 pages"
    },
    {
        "paper id": "2408.01692",
        "abstract url": "https://arxiv.org/abs/2408.01692",
        "title": "A Comparative Analysis of CNN-based Deep Learning Models for Landslide Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Landslides inflict substantial societal and economic damage, underscoring their global significance as recurrent and destructive natural disasters. Recent landslides in northern parts of India and Nepal have caused significant disruption, damaging infrastructure and posing threats to local communities. Convolutional Neural Networks (CNNs), a type of deep learning technique, have shown remarkable success in image processing. Because of their sophisticated architectures, advanced CNN-based models perform better in landslide detection than conventional algorithms. The purpose of this work is to investigate CNNs' potential in more detail, with an emphasis on comparison of CNN based models for better landslide detection. We compared four traditional semantic segmentation models (U-Net, LinkNet, PSPNet, and FPN) and utilized the ResNet50 backbone encoder to implement them. Moreover, we have experimented with the hyperparameters such as learning rates, batch sizes, and regularization techniques to fine-tune the models. We have computed the confusion matrix for each model and used performance metrics including precision, recall and f1-score to evaluate and compare the deep learning models. According to the experimental results, LinkNet gave the best results among the four models having an Accuracy of 97.49% and a F1-score of 85.7% (with 84.49% precision, 87.07% recall). We have also presented a comprehensive comparison of all pixel-wise confusion matrix results and the time taken to train each model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Paper Accepted for presentation at IEEE 2024 Asian Conference on Intelligent Technologies (ACOIT)"
    },
    {
        "paper id": "2408.01694",
        "abstract url": "https://arxiv.org/abs/2408.01694",
        "title": "Bayesian Active Learning for Semantic Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fully supervised training of semantic segmentation models is costly and challenging because each pixel within an image needs to be labeled. Therefore, the sparse pixel-level annotation methods have been introduced to train models with a subset of pixels within each image. We introduce a Bayesian active learning framework based on sparse pixel-level annotation that utilizes a pixel-level Bayesian uncertainty measure based on Balanced Entropy (BalEnt) [84]. BalEnt captures the information between the models' predicted marginalized probability distribution and the pixel labels. BalEnt has linear scalability with a closed analytical form and can be calculated independently per pixel without relational computations with other pixels. We train our proposed active learning framework for Cityscapes, Camvid, ADE20K and VOC2012 benchmark datasets and show that it reaches supervised levels of mIoU using only a fraction of labeled pixels while outperforming the previous state-of-the-art active learning models with a large margin.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01712",
        "abstract url": "https://arxiv.org/abs/2408.01712",
        "title": "A General Ambiguity Model for Binary Edge Images with Edge Tracing and its Implementation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present a general and intuitive ambiguity model for intersections, junctions and other structures in binary edge images. The model is combined with edge tracing, where edges are ordered sequences of connected pixels. The objective is to provide a versatile preprocessing method for tasks such as figure-ground segmentation, object recognition, topological analysis, etc. By using only a small set of straightforward principles, the results are intuitive to describe. This helps to implement subsequent processing steps, such as resolving ambiguous edge connections at junctions. By using an augmented edge map, neighboring edges can be directly accessed using quick local search operations. The edge tracing uses recursion, which leads to compact programming code. We explain our algorithm using pseudocode, compare it with related methods, and show how simple modular postprocessing steps can be used to optimize the results. The complete algorithm, including all data structures, requires less than 50 lines of pseudocode. We also provide a C++ implementation of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2408.01723",
        "abstract url": "https://arxiv.org/abs/2408.01723",
        "title": "A Novel Evaluation Framework for Image2Text Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Evaluating the quality of automatically generated image descriptions is challenging, requiring metrics that capture various aspects such as grammaticality, coverage, correctness, and truthfulness. While human evaluation offers valuable insights, its cost and time-consuming nature pose limitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr aim to bridge this gap but often show weak correlations with human judgment. We address this challenge by introducing a novel evaluation framework rooted in a modern large language model (LLM), such as GPT-4 or Gemini, capable of image generation. In our proposed framework, we begin by feeding an input image into a designated image captioning model, chosen for evaluation, to generate a textual description. Using this description, an LLM then creates a new image. By extracting features from both the original and LLM-created images, we measure their similarity using a designated similarity metric. A high similarity score suggests that the image captioning model has accurately generated textual descriptions, while a low similarity score indicates discrepancies, revealing potential shortcomings in the model's performance. Human-annotated reference captions are not required in our proposed evaluation framework, which serves as a valuable tool for evaluating the effectiveness of image captioning models. Its efficacy is confirmed through human evaluation.",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "comment": "The paper has been accepted for presentation at the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, specifically in the Large Language Model for Evaluation in IR (LLM4Eval) Workshop in 2024"
    },
    {
        "paper id": "2408.01736",
        "abstract url": "https://arxiv.org/abs/2408.01736",
        "title": "Can LLMs predict the convergence of Stochastic Gradient Descent?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Large-language models are notoriously famous for their impressive performance across a wide range of tasks. One surprising example of such impressive performance is a recently identified capacity of LLMs to understand the governing principles of dynamical systems satisfying the Markovian property. In this paper, we seek to explore this direction further by studying the dynamics of stochastic gradient descent in convex and non-convex optimization. By leveraging the theoretical link between the SGD and Markov chains, we show a remarkable zero-shot performance of LLMs in predicting the local minima to which SGD converges for previously unseen starting points. On a more general level, we inquire about the possibility of using LLMs to perform zero-shot randomized trials for larger deep learning models used in practice.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "9 pages. Accepted to 1st ICML Workshop on In-Context Learning at ICML 2024"
    },
    {
        "paper id": "2408.01744",
        "abstract url": "https://arxiv.org/abs/2408.01744",
        "title": "Summarization of Investment Reports Using Pre-trained Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we attempt to summarize monthly reports as investment reports. Fund managers have a wide range of tasks, one of which is the preparation of investment reports. In addition to preparing monthly reports on fund management, fund managers prepare management reports that summarize these monthly reports every six months or once a year. The preparation of fund reports is a labor-intensive and time-consuming task. Therefore, in this paper, we tackle investment summarization from monthly reports using transformer-based models. There are two main types of summarization methods: extractive summarization and abstractive summarization, and this study constructs both methods and examines which is more useful in summarizing investment reports.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01745",
        "abstract url": "https://arxiv.org/abs/2408.01745",
        "title": "Indexing and Visualization of Climate Change Narratives Using BERT and Causal Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this study, we propose a methodology to extract, index, and visualize ``climate change narratives'' (stories about the connection between causal and consequential events related to climate change). We use two natural language processing methods, BERT (Bidirectional Encoder Representations from Transformers) and causal extraction, to textually analyze newspaper articles on climate change to extract ``climate change narratives.'' The novelty of the methodology could extract and quantify the causal relationships assumed by the newspaper's writers. Looking at the extracted climate change narratives over time, we find that since 2018, an increasing number of narratives suggest the impact of the development of climate change policy discussion and the implementation of climate change-related policies on corporate behaviors, macroeconomics, and price dynamics. We also observed the recent emergence of narratives focusing on the linkages between climate change-related policies and monetary policy. Furthermore, there is a growing awareness of the negative impacts of natural disasters (e.g., abnormal weather and severe floods) related to climate change on economic activities, and this issue might be perceived as a new challenge for companies and governments. The methodology of this study is expected to be applied to a wide range of fields, as it can analyze causal relationships among various economic topics, including analysis of inflation expectation or monetary policy communication strategy.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01746",
        "abstract url": "https://arxiv.org/abs/2408.01746",
        "title": "Domain penalisation for improved Out-of-Distribution Generalisation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the field of object detection, domain generalisation (DG) aims to ensure robust performance across diverse and unseen target domains by learning the robust domain-invariant features corresponding to the objects of interest across multiple source domains. While there are many approaches established for performing DG for the task of classification, there has been a very little focus on object detection. In this paper, we propose a domain penalisation (DP) framework for the task of object detection, where the data is assumed to be sampled from multiple source domains and tested on completely unseen test domains. We assign penalisation weights to each domain, with the values updated based on the detection networks performance on the respective source domains. By prioritising the domains that needs more attention, our approach effectively balances the training process. We evaluate our solution on the GWHD 2021 dataset, a component of the WiLDS benchmark and we compare against ERM and GroupDRO as these are primarily loss function based. Our extensive experimental results reveals that the proposed approach improves the accuracy by 0.3 percent and 0.5 percent on validation and test out-of-distribution (OOD) sets, respectively for FasterRCNN. We also compare the performance of our approach on FCOS detector and show that our approach improves the baseline OOD performance over the existing approaches by 1.3 percent and 1.4 percent on validation and test sets, respectively. This study underscores the potential of performance based domain penalisation in enhancing the generalisation ability of object detection models across diverse environments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01767",
        "abstract url": "https://arxiv.org/abs/2408.01767",
        "title": "Comparison of Embedded Spaces for Deep Learning Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Embedded spaces are a key feature in deep learning. Good embedded spaces represent the data well to support classification and advanced techniques such as open-set recognition, few-short learning and explainability. This paper presents a compact overview of different techniques to design embedded spaces for classification. It compares different loss functions and constraints on the network parameters with respect to the achievable geometric structure of the embedded space. The techniques are demonstrated with two and three-dimensional embeddings for the MNIST, Fashion MNIST and CIFAR-10 datasets, allowing visual inspection of the embedded spaces.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "eess.IV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01800",
        "abstract url": "https://arxiv.org/abs/2408.01800",
        "title": "MiniCPM-V: A GPT-4V Level MLLM on Your Phone",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The recent surge of Multimodal Large Language Models (MLLMs) has fundamentally reshaped the landscape of AI research and industry, shedding light on a promising path toward the next AI milestone. However, significant challenges remain preventing MLLMs from being practical in real-world applications. The most notable challenge comes from the huge cost of running an MLLM with a massive number of parameters and extensive computation. As a result, most MLLMs need to be deployed on high-performing cloud servers, which greatly limits their application scopes such as mobile, offline, energy-sensitive, and privacy-protective scenarios. In this work, we present MiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By integrating the latest MLLM techniques in architecture, pretraining and alignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1) Strong performance, outperforming GPT-4V-1106, Gemini Pro and Claude 3 on OpenCompass, a comprehensive evaluation over 11 popular benchmarks, (2) strong OCR capability and 1.8M pixel high-resolution image perception at any aspect ratio, (3) trustworthy behavior with low hallucination rates, (4) multilingual support for 30+ languages, and (5) efficient deployment on mobile phones. More importantly, MiniCPM-V can be viewed as a representative example of a promising trend: The model sizes for achieving usable (e.g., GPT-4V) level performance are rapidly decreasing, along with the fast growth of end-side computation capacity. This jointly shows that GPT-4V level MLLMs deployed on end devices are becoming increasingly possible, unlocking a wider spectrum of real-world AI applications in the near future.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "preprint"
    },
    {
        "paper id": "2408.01803",
        "abstract url": "https://arxiv.org/abs/2408.01803",
        "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we present STBLLM, the first structural binarization framework for compressing Large Language Models (LLMs) to less than 1-bit precision. LLMs have achieved remarkable performance, but their heavy memory requirements have hindered widespread adoption, particularly on resource-constrained devices. Binarization, which quantifies weights to a mere 1-bit, achieves a milestone in increasing computational efficiency. However, we observe that some weights in binarized LLMs can be randomly flipped without significant performance degradation, indicating the potential for further compression. To exploit this, our STBLLM employs an N:M sparsity to perform structural binarization of the weights. First, we introduce a new Standardized Importance (SI) metric that considers weight magnitude and input feature norm to better evaluate weight significance. Then, we propose a layer-wise approach where different layers of the LLM can be sparsified with varying N:M ratios, balancing compression and accuracy. Finally, we use residual approximation with double binarization to preserve information for salient weights. In addition, we utilize a fine-grained grouping strategy for less important weights that applies different quantization schemes to sparse, intermediate, and dense regions. We conduct extensive experiments on various language models, including the LLaMA-1/2/3, OPT family, and Mistral, to evaluate the effectiveness of STBLLM. The results demonstrate that our approach performs better than other compressed binarization LLM methods while significantly reducing memory requirements.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01827",
        "abstract url": "https://arxiv.org/abs/2408.01827",
        "title": "ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Painting classification plays a vital role in organizing, finding, and suggesting artwork for digital and classic art galleries. Existing methods struggle with adapting knowledge from the real world to artistic images during training, leading to poor performance when dealing with different datasets. Our innovation lies in addressing these challenges through a two-step process. First, we generate more data using Style Transfer with Adaptive Instance Normalization (AdaIN), bridging the gap between diverse styles. Then, our classifier gains a boost with feature-map adaptive spatial attention modules, improving its understanding of artistic details. Moreover, we tackle the problem of imbalanced class representation by dynamically adjusting augmented samples. Through a dual-stage process involving careful hyperparameter search and model fine-tuning, we achieve an impressive 87.24\\% accuracy using the ResNet-50 backbone over 40 training epochs. Our study explores quantitative analyses that compare different pretrained backbones, investigates model optimization through ablation studies, and examines how varying augmentation levels affect model performance. Complementing this, our qualitative experiments offer valuable insights into the model's decision-making process using spatial attention and its ability to differentiate between easy and challenging samples based on confidence ranking.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01831",
        "abstract url": "https://arxiv.org/abs/2408.01831",
        "title": "A Deep CNN Model for Ringing Effect Attenuation of Vibroseis Data",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the field of exploration geophysics, seismic vibrator is one of the widely used seismic sources to acquire seismic data, which is usually named vibroseis. \"Ringing effect\" is a common problem in vibroseis data processing due to the limited frequency bandwidth of the vibrator, which degrades the performance of first-break picking. In this paper, we proposed a novel deringing model for vibroseis data using deep convolutional neural network (CNN). In this model we use end-to-end training strategy to obtain the deringed data directly, and skip connections to improve model training process and preserve the details of vibroseis data. For real vibroseis deringing task we synthesize training data and corresponding labels from real vibroseis data and utilize them to train the deep CNN model. Experiments are conducted both on synthetic data and real vibroseis data. The experiment results show that deep CNN model can attenuate the ringing effect effectively and expand the bandwidth of vibroseis data. The STA/LTA ratio method for first-break picking also shows improvement on deringed vibroseis data using deep CNN model.",
        "subjects": [
            "cs.CV",
            "physics.geo-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01866",
        "abstract url": "https://arxiv.org/abs/2408.01866",
        "title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in comprehending and analyzing lengthy sequential inputs, owing to their extensive context windows that allow processing millions of tokens in a single forward pass. However, this paper uncovers a surprising limitation: LLMs fall short when handling long input sequences. We investigate this issue using three datasets and two tasks (sentiment analysis and news categorization) across various LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct, and Mistral Instruct models. To address this limitation, we propose and evaluate ad-hoc solutions that substantially enhance LLMs' performance on long input sequences by up to 50%, while reducing API cost and latency by up to 93% and 50%, respectively.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "11 pages, 5 figures, 6 tables"
    },
    {
        "paper id": "2408.01872",
        "abstract url": "https://arxiv.org/abs/2408.01872",
        "title": "Safe Semi-Supervised Contrastive Learning Using In-Distribution Data as Positive Examples",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Semi-supervised learning methods have shown promising results in solving many practical problems when only a few labels are available. The existing methods assume that the class distributions of labeled and unlabeled data are equal; however, their performances are significantly degraded in class distribution mismatch scenarios where out-of-distribution (OOD) data exist in the unlabeled data. Previous safe semi-supervised learning studies have addressed this problem by making OOD data less likely to affect training based on labeled data. However, even if the studies effectively filter out the unnecessary OOD data, they can lose the basic information that all data share regardless of class. To this end, we propose to apply a self-supervised contrastive learning approach to fully exploit a large amount of unlabeled data. We also propose a contrastive loss function with coefficient schedule to aggregate as an anchor the labeled negative examples of the same class into positive examples. To evaluate the performance of the proposed method, we conduct experiments on image classification datasets - CIFAR-10, CIFAR-100, Tiny ImageNet, and CIFAR-100+Tiny ImageNet - under various mismatch ratios. The results show that self-supervised contrastive learning significantly improves classification accuracy. Moreover, aggregating the in-distribution examples produces better representation and consequently further improves classification accuracy.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01875",
        "abstract url": "https://arxiv.org/abs/2408.01875",
        "title": "Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in large language models (LLMs) have enabled autonomous agents with complex reasoning and task-fulfillment capabilities using a wide range of tools. However, effectively identifying the most relevant tools for a given task becomes a key bottleneck as the toolset size grows, hindering reliable tool utilization. To address this, we introduce Re-Invoke, an unsupervised tool retrieval method designed to scale effectively to large toolsets without training. Specifically, we first generate a diverse set of synthetic queries that comprehensively cover different aspects of the query space associated with each tool document during the tool indexing phase. Second, we leverage LLM's query understanding capabilities to extract key tool-related context and underlying intents from user queries during the inference phase. Finally, we employ a novel multi-view similarity ranking strategy based on intents to pinpoint the most relevant tools for each query. Our evaluation demonstrates that Re-Invoke significantly outperforms state-of-the-art alternatives in both single-tool and multi-tool scenarios, all within a fully unsupervised setting. Notably, on the ToolE datasets, we achieve a 20% relative improvement in nDCG@5 for single-tool retrieval and a 39% improvement for multi-tool retrieval.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01877",
        "abstract url": "https://arxiv.org/abs/2408.01877",
        "title": "Is Generative Communication between Embodied Agents Good for Zero-Shot ObjectNav?",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In Zero-Shot ObjectNav, an embodied ground agent is expected to navigate to a target object specified by a natural language label without any environment-specific fine-tuning. This is challenging, given the limited view of a ground agent and its independent exploratory behavior. To address these issues, we consider an assistive overhead agent with a bounded global view alongside the ground agent and present two coordinated navigation schemes for judicious exploration. We establish the influence of the Generative Communication (GC) between the embodied agents equipped with Vision-Language Models (VLMs) in improving zero-shot ObjectNav, achieving a 10% improvement in the ground agent's ability to find the target object in comparison with an unassisted setup in simulation. We further analyze the GC for unique traits quantifying the presence of hallucination and cooperation. In particular, we identify a unique trait of \"preemptive hallucination\" specific to our embodied setting, where the overhead agent assumes that the ground agent has executed an action in the dialogue when it is yet to move. Finally, we conduct real-world inferences with GC and showcase qualitative examples where countering pre-emptive hallucination via prompt finetuning improves real-world ObjectNav performance.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01892",
        "abstract url": "https://arxiv.org/abs/2408.01892",
        "title": "Re-ENACT: Reinforcement Learning for Emotional Speech Generation using Actor-Critic Strategy",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we propose the first method to modify the prosodic features of a given speech signal using actor-critic reinforcement learning strategy. Our approach uses a Bayesian framework to identify contiguous segments of importance that links segments of the given utterances to perception of emotions in humans. We train a neural network to produce the variational posterior of a collection of Bernoulli random variables; our model applies a Markov prior on it to ensure continuity. A sample from this distribution is used for downstream emotion prediction. Further, we train the neural network to predict a soft assignment over emotion categories as the target variable. In the next step, we modify the prosodic features (pitch, intensity, and rhythm) of the masked segment to increase the score of target emotion. We employ an actor-critic reinforcement learning to train the prosody modifier by discretizing the space of modifications. Further, it provides a simple solution to the problem of gradient computation through WSOLA operation for rhythm manipulation. Our experiments demonstrate that this framework changes the perceived emotion of a given speech utterance to the target. Further, we show that our unified technique is on par with state-of-the-art emotion conversion models from supervised and unsupervised domains that require pairwise training.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "7 pages, 10 figures"
    },
    {
        "paper id": "2408.01900",
        "abstract url": "https://arxiv.org/abs/2408.01900",
        "title": "Quantifying gendered citation imbalance in computer science conferences",
        "rating": "1",
        "keywords": [
            [
                "cs.SI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "The number of citations received by papers often exhibits imbalances in terms of author attributes such as country of affiliation and gender. While recent studies have quantified citation imbalance in terms of the authors' gender in journal papers, the computer science discipline, where researchers frequently present their work at conferences, may exhibit unique patterns in gendered citation imbalance. Additionally, understanding how network properties in citations influence citation imbalances remains challenging due to a lack of suitable reference models. In this paper, we develop a family of reference models for citation networks and investigate gender imbalance in citations between papers published in computer science conferences. By deploying these reference models, we found that homophily in citations is strongly associated with gendered citation imbalance in computer science, whereas heterogeneity in the number of citations received per paper has a relatively minor association with it. Furthermore, we found that the gendered citation imbalance is most pronounced in papers published in the highest-ranked conferences, is present across different subfields, and extends to citation-based rankings of papers. Our study provides a framework for investigating associations between network properties and citation imbalances, aiming to enhance our understanding of the structure and dynamics of citations between research publications.",
        "subjects": [
            "cs.SI",
            "cs.DL"
        ],
        "comment": "14 pages, 6 figures, and 7 tables. This work has been accepted as a full paper in the AAAI/ACM conference on Artificial Intelligence, Ethics and Society (AIES) 2024"
    },
    {
        "paper id": "2408.01920",
        "abstract url": "https://arxiv.org/abs/2408.01920",
        "title": "Self-Supervised Pretrained Models and Latent Feature Distribution Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In the face of complex natural images, existing deep clustering algorithms fall significantly short in terms of clustering accuracy when compared to supervised classification methods, making them less practical. This paper introduces an image clustering algorithm based on self-supervised pretrained models and latent feature distribution optimization, substantially enhancing clustering performance. It is found that: (1) For complex natural images, we effectively enhance the discriminative power of latent features by leveraging self-supervised pretrained models and their fine-tuning, resulting in improved clustering performance. (2) In the latent feature space, by searching for k-nearest neighbor images for each training sample and shortening the distance between the training sample and its nearest neighbor, the discriminative power of latent features can be further enhanced, and clustering performance can be improved. (3) In the latent feature space, reducing the distance between sample features and the nearest predefined cluster centroids can optimize the distribution of latent features, therefore further improving clustering performance. Through experiments on multiple datasets, our approach outperforms the latest clustering algorithms and achieves state-of-the-art clustering results. When the number of categories in the datasets is small, such as CIFAR-10 and STL-10, and there are significant differences between categories, our clustering algorithm has similar accuracy to supervised methods without using pretrained models, slightly lower than supervised methods using pre-trained models. The code linked algorithm is https://github.com/LihengHu/ICBPL.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01677",
        "abstract url": "https://arxiv.org/abs/2408.01677",
        "title": "HIVE: HIerarchical Volume Encoding for Neural Implicit Surface Reconstruction",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Neural implicit surface reconstruction has become a new trend in reconstructing a detailed 3D shape from images. In previous methods, however, the 3D scene is only encoded by the MLPs which do not have an explicit 3D structure. To better represent 3D shapes, we introduce a volume encoding to explicitly encode the spatial information. We further design hierarchical volumes to encode the scene structures in multiple scales. The high-resolution volumes capture the high-frequency geometry details since spatially varying features could be learned from different 3D points, while the low-resolution volumes enforce the spatial consistency to keep the shape smooth since adjacent locations possess the same low-resolution feature. In addition, we adopt a sparse structure to reduce the memory consumption at high-resolution volumes, and two regularization terms to enhance results smoothness. This hierarchical volume encoding could be appended to any implicit surface reconstruction method as a plug-and-play module, and can generate a smooth and clean reconstruction with more details. Superior performance is demonstrated in DTU, EPFL, and BlendedMVS datasets with significant improvement on the standard metrics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to ICLR 2023"
    },
    {
        "paper id": "2408.01730",
        "abstract url": "https://arxiv.org/abs/2408.01730",
        "title": "Real-time Hybrid System Identification with Online Deterministic Annealing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a real-time identification method for discrete-time state-dependent switching systems in both the input--output and state-space domains. In particular, we design a system of adaptive algorithms running in two timescales; a stochastic approximation algorithm implements an online deterministic annealing scheme at a slow timescale and estimates the mode-switching signal, and an recursive identification algorithm runs at a faster timescale and updates the parameters of the local models based on the estimate of the switching signal. We first focus on piece-wise affine systems and discuss identifiability conditions and convergence properties based on the theory of two-timescale stochastic approximation. In contrast to standard identification algorithms for switched systems, the proposed approach gradually estimates the number of modes and is appropriate for real-time system identification using sequential data acquisition. The progressive nature of the algorithm improves computational efficiency and provides real-time control over the performance-complexity trade-off. Finally, we address specific challenges that arise in the application of the proposed methodology in identification of more general switching systems. Simulation results validate the efficacy of the proposed methodology.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01787",
        "abstract url": "https://arxiv.org/abs/2408.01787",
        "title": "Towards an ontology of state actors in cyberspace",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "To improve cyber threat analysis practices in cybersecurity, I present a plan to build a formal ontological representation of state actors in cyberspace and of cyber operations. I argue that modelling these phenomena via ontologies allows for coherent integration of data coming from diverse sources, automated reasoning over such data, as well as intelligence extraction and reuse from and of them. Existing ontological tools in cybersecurity can be ameliorated by connecting them to neighboring domains such as law, regulations, governmental institutions, and documents. In this paper, I propose metrics to evaluate currently existing ontological tools to create formal representations in the cybersecurity domain, and I provide a plan to develop and extend them when they are lacking.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01795",
        "abstract url": "https://arxiv.org/abs/2408.01795",
        "title": "Review of Cloud Service Composition for Intelligent Manufacturing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Intelligent manufacturing is a new model that uses advanced technologies such as the Internet of Things, big data, and artificial intelligence to improve the efficiency and quality of manufacturing production. As an important support to promote the transformation and upgrading of the manufacturing industry, cloud service optimization has received the attention of researchers. In recent years, remarkable research results have been achieved in this field. For the sustainability of intelligent manufacturing platforms, in this paper we summarize the process of cloud service optimization for intelligent manufacturing. Further, to address the problems of dispersed optimization indicators and nonuniform/unstandardized definitions in the existing research, 11 optimization indicators that take into account three-party participant subjects are defined from the urgent requirements of the sustainable development of intelligent manufacturing platforms. Next, service optimization algorithms are classified into two categories, heuristic and reinforcement learning. After comparing the two categories, the current key techniques of service optimization are targeted. Finally, research hotspots and future research trends of service optimization are summarized.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01839",
        "abstract url": "https://arxiv.org/abs/2408.01839",
        "title": "Complexity of Minimizing Projected-Gradient-Dominated Functions with Stochastic First-order Oracles",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work investigates the performance limits of projected stochastic first-order methods for minimizing functions under the $(\u03b1,\u03c4,\\mathcal{X})$-projected-gradient-dominance property, that asserts the sub-optimality gap $F(\\mathbf{x})-\\min_{\\mathbf{x}'\\in \\mathcal{X}}F(\\mathbf{x}')$ is upper-bounded by $\u03c4\\cdot\\|\\mathcal{G}_{\u03b7,\\mathcal{X}}(\\mathbf{x})\\|^\u03b1$ for some $\u03b1\\in[1,2)$ and $\u03c4>0$ and $\\mathcal{G}_{\u03b7,\\mathcal{X}}(\\mathbf{x})$ is the projected-gradient mapping with $\u03b7>0$ as a parameter. For non-convex functions, we show that the complexity lower bound of querying a batch smooth first-order stochastic oracle to obtain an $\u03b5$-global-optimum point is $\u03a9(\u03b5^{-{2}/\u03b1})$. Furthermore, we show that a projected variance-reduced first-order algorithm can obtain the upper complexity bound of $\\mathcal{O}(\u03b5^{-{2}/\u03b1})$, matching the lower bound. For convex functions, we establish a complexity lower bound of $\u03a9(\\log(1/\u03b5)\\cdot\u03b5^{-{2}/\u03b1})$ for minimizing functions under a local version of gradient-dominance property, which also matches the upper complexity bound of accelerated stochastic subgradient methods.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01861",
        "abstract url": "https://arxiv.org/abs/2408.01861",
        "title": "Batch Active Learning in Gaussian Process Regression using Derivatives",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate the use of derivative information for Batch Active Learning in Gaussian Process regression models. The proposed approach employs the predictive covariance matrix for selection of data batches to exploit full correlation of samples. We theoretically analyse our proposed algorithm taking different optimality criteria into consideration and provide empirical comparisons highlighting the advantage of incorporating derivatives information. Our results show the effectiveness of our approach across diverse applications.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "29 pages, 10 figures"
    },
    {
        "paper id": "2408.01868",
        "abstract url": "https://arxiv.org/abs/2408.01868",
        "title": "Meta-Posterior Consistency for the Bayesian Inference of Metastable System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The vast majority of the literature on learning dynamical systems or stochastic processes from time series has focused on stable or ergodic systems, for both Bayesian and frequentist inference procedures. However, most real-world systems are only metastable, that is, the dynamics appear to be stable on some time scale, but are in fact unstable over longer time scales. Consistency of inference for metastable systems may not be possible, but one can ask about metaconsistency: Do inference procedures converge when observations are taken over a large but finite time interval, but diverge on longer time scales? In this paper we introduce, discuss, and quantify metaconsistency in a Bayesian framework. We discuss how metaconsistency can be exploited to efficiently infer a model for a sub-system of a larger system, where inference on the global behavior may require much more data. We also discuss the relation between meta-consistency and the spectral properties of the model dynamical system in the case of uniformly ergodic diffusions.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR",
            "math.ST"
        ],
        "comment": "32 pages, 3 figures"
    },
    {
        "paper id": "2408.01904",
        "abstract url": "https://arxiv.org/abs/2408.01904",
        "title": "The Artificial Intelligence Disclosure (AID) Framework: An Introduction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "As the use of Generative Artificial Intelligence tools have grown in higher education and research, there have been increasing calls for transparency and granularity around the use and attribution of the use of these tools. Thus far, this need has been met via the recommended inclusion of a note, with little to no guidance on what the note itself should include. This has been identified as a problem to the use of AI in academic and research contexts. This article introduces The Artificial Intelligence Disclosure (AID) Framework, a standard, comprehensive, and detailed framework meant to inform the development and writing of GenAI disclosure for education and research.",
        "subjects": [
            "cs.DL",
            "cs.AI"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2408.01916",
        "abstract url": "https://arxiv.org/abs/2408.01916",
        "title": "MAO: A Framework for Process Model Generation with Multi-Agent Orchestration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Process models are frequently used in software engineering to describe business requirements, guide software testing and control system improvement. However, traditional process modeling methods often require the participation of numerous experts, which is expensive and time-consuming. Therefore, the exploration of a more efficient and cost-effective automated modeling method has emerged as a focal point in current research. This article explores a framework for automatically generating process models with multi-agent orchestration (MAO), aiming to enhance the efficiency of process modeling and offer valuable insights for domain experts. Our framework MAO leverages large language models as the cornerstone for multi-agent, employing an innovative prompt strategy to ensure efficient collaboration among multi-agent. Specifically, 1) generation. The first phase of MAO is to generate a slightly rough process model from the text description; 2) refinement. The agents would continuously refine the initial process model through multiple rounds of dialogue; 3) reviewing. Large language models are prone to hallucination phenomena among multi-turn dialogues, so the agents need to review and repair semantic hallucinations in process models; 4) testing. The representation of process models is diverse. Consequently, the agents utilize external tools to test whether the generated process model contains format errors, namely format hallucinations, and then adjust the process model to conform to the output paradigm. The experiments demonstrate that the process models generated by our framework outperform existing methods and surpass manual modeling by 89%, 61%, 52%, and 75% on four different datasets, respectively.",
        "subjects": [
            "cs.AI",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01926",
        "abstract url": "https://arxiv.org/abs/2408.01926",
        "title": "Efficient Decision Trees for Tensor Regressions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We proposed the tensor-input tree (TT) method for scalar-on-tensor and tensor-on-tensor regression problems. We first address scalar-on-tensor problem by proposing scalar-output regression tree models whose input variable are tensors (i.e., multi-way arrays). We devised and implemented fast randomized and deterministic algorithms for efficient fitting of scalar-on-tensor trees, making TT competitive against tensor-input GP models. Based on scalar-on-tensor tree models, we extend our method to tensor-on-tensor problems using additive tree ensemble approaches. Theoretical justification and extensive experiments on real and synthetic datasets are provided to illustrate the performance of TT.",
        "subjects": [
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "comment": "36 pages, 9 Figures"
    },
    {
        "paper id": "2408.02692",
        "abstract url": "https://arxiv.org/abs/2408.02692",
        "title": "Attention is all you need for an improved CNN-based flash flood susceptibility modeling. The case of the ungauged Rheraya watershed, Morocco",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Effective flood hazard management requires evaluating and predicting flash flood susceptibility. Convolutional neural networks (CNNs) are commonly used for this task but face issues like gradient explosion and overfitting. This study explores the use of an attention mechanism, specifically the convolutional block attention module (CBAM), to enhance CNN models for flash flood susceptibility in the ungauged Rheraya watershed, a flood prone region. We used ResNet18, DenseNet121, and Xception as backbone architectures, integrating CBAM at different locations. Our dataset included 16 conditioning factors and 522 flash flood inventory points. Performance was evaluated using accuracy, precision, recall, F1-score, and the area under the curve (AUC) of the receiver operating characteristic (ROC). Results showed that CBAM significantly improved model performance, with DenseNet121 incorporating CBAM in each convolutional block achieving the best results (accuracy = 0.95, AUC = 0.98). Distance to river and drainage density were identified as key factors. These findings demonstrate the effectiveness of the attention mechanism in improving flash flood susceptibility modeling and offer valuable insights for disaster management.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.02694",
        "abstract url": "https://arxiv.org/abs/2408.02694",
        "title": "KAN based Autoencoders for Factor Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Inspired by recent advances in Kolmogorov-Arnold Networks (KANs), we introduce a novel approach to latent factor conditional asset pricing models. While previous machine learning applications in asset pricing have predominantly used Multilayer Perceptrons with ReLU activation functions to model latent factor exposures, our method introduces a KAN-based autoencoder which surpasses MLP models in both accuracy and interpretability. Our model offers enhanced flexibility in approximating exposures as nonlinear functions of asset characteristics, while simultaneously providing users with an intuitive framework for interpreting latent factors. Empirical backtesting demonstrates our model's superior ability to explain cross-sectional risk exposures. Moreover, long-short portfolios constructed using our model's predictions achieve higher Sharpe ratios, highlighting its practical value in investment management.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-fin.CP"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2408.01689",
        "abstract url": "https://arxiv.org/abs/2408.01689",
        "title": "Controllable Unlearning for Image-to-Image Generative Models via $\\varepsilon$-Constrained Optimization",
        "rating": "0",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "While generative models have made significant advancements in recent years, they also raise concerns such as privacy breaches and biases. Machine unlearning has emerged as a viable solution, aiming to remove specific training data, e.g., containing private information and bias, from models. In this paper, we study the machine unlearning problem in Image-to-Image (I2I) generative models. Previous studies mainly treat it as a single objective optimization problem, offering a solitary solution, thereby neglecting the varied user expectations towards the trade-off between complete unlearning and model utility. To address this issue, we propose a controllable unlearning framework that uses a control coefficient $\\varepsilon$ to control the trade-off. We reformulate the I2I generative model unlearning problem into a $\\varepsilon$-constrained optimization problem and solve it with a gradient-based method to find optimal solutions for unlearning boundaries. These boundaries define the valid range for the control coefficient. Within this range, every yielded solution is theoretically guaranteed with Pareto optimality. We also analyze the convergence rate of our framework under various control functions. Extensive experiments on two benchmark datasets across three mainstream I2I models demonstrate the effectiveness of our controllable unlearning framework.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "40 pages, 54 figures"
    },
    {
        "paper id": "2408.01700",
        "abstract url": "https://arxiv.org/abs/2408.01700",
        "title": "Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data",
        "rating": "0",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Aerospace manufacturing companies, such as Thales Alenia Space, design, develop, integrate, verify, and validate products characterized by high complexity and low volume. They carefully document all phases for each product but analyses across products are challenging due to the heterogeneity and unstructured nature of the data in documents. In this paper, we propose a hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with Large Language Models (LLMs) to extract and validate data contained in these documents. We consider a case study focused on test data related to electronic boards for satellites. To do so, we extend the Semantic Sensor Network ontology. We store the metadata of the reports in a KG, while the actual test results are stored in parquet accessible via a Virtual Knowledge Graph. The validation process is managed using an LLM-based approach. We also conduct a benchmarking study to evaluate the performance of state-of-the-art LLMs in executing this task. Finally, we analyze the costs and benefits of automating preexisting processes of manual data extraction and validation for subsequent cross-report analyses.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Paper Accepted at ISWC 2024 In-Use Track"
    },
    {
        "paper id": "2408.01701",
        "abstract url": "https://arxiv.org/abs/2408.01701",
        "title": "Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action Recognition via Learning Temporal-Frequency Dynamics",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In skeletal-based action recognition, Graph Convolutional Networks (GCNs) based methods face limitations due to their complexity and high energy consumption. Spiking Neural Networks (SNNs) have gained attention in recent years for their low energy consumption, but existing methods combining GCNs and SNNs fail to fully utilize the temporal characteristics of skeletal sequences, leading to increased storage and computational costs. To address this issue, we propose a Signal-SGN(Spiking Graph Convolutional Network), which leverages the temporal dimension of skeletal sequences as the spiking timestep and treats features as discrete stochastic signals. The core of the network consists of a 1D Spiking Graph Convolutional Network (1D-SGN) and a Frequency Spiking Convolutional Network (FSN). The SGN performs graph convolution on single frames and incorporates spiking network characteristics to capture inter-frame temporal relationships, while the FSN uses Fast Fourier Transform (FFT) and complex convolution to extract temporal-frequency features. We also introduce a multi-scale wavelet transform feature fusion module(MWTF) to capture spectral features of temporal signals, enhancing the model's classification capability. We propose a pluggable temporal-frequency spatial semantic feature extraction module(TFSM) to enhance the model's ability to distinguish features without increasing inference-phase consumption. Our numerous experiments on the NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets demonstrate that the proposed models not only surpass existing SNN-based methods in accuracy but also reduce computational and storage costs during training. Furthermore, they achieve competitive accuracy compared to corresponding GCN-based methods, which is quite remarkable.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01705",
        "abstract url": "https://arxiv.org/abs/2408.01705",
        "title": "Downstream Transfer Attack: Adversarial Attacks on Downstream Models with Pre-trained Vision Transformers",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "With the advancement of vision transformers (ViTs) and self-supervised learning (SSL) techniques, pre-trained large ViTs have become the new foundation models for computer vision applications. However, studies have shown that, like convolutional neural networks (CNNs), ViTs are also susceptible to adversarial attacks, where subtle perturbations in the input can fool the model into making false predictions. This paper studies the transferability of such an adversarial vulnerability from a pre-trained ViT model to downstream tasks. We focus on \\emph{sample-wise} transfer attacks and propose a novel attack method termed \\emph{Downstream Transfer Attack (DTA)}. For a given test image, DTA leverages a pre-trained ViT model to craft the adversarial example and then applies the adversarial example to attack a fine-tuned version of the model on a downstream dataset. During the attack, DTA identifies and exploits the most vulnerable layers of the pre-trained model guided by a cosine similarity loss to craft highly transferable attacks. Through extensive experiments with pre-trained ViTs by 3 distinct pre-training methods, 3 fine-tuning schemes, and across 10 diverse downstream datasets, we show that DTA achieves an average attack success rate (ASR) exceeding 90\\%, surpassing existing methods by a huge margin. When used with adversarial training, the adversarial examples generated by our DTA can significantly improve the model's robustness to different downstream transfer attacks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01728",
        "abstract url": "https://arxiv.org/abs/2408.01728",
        "title": "Survey on Emotion Recognition through Posture Detection and the possibility of its application in Virtual Reality",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "A survey is presented focused on using pose estimation techniques in Emotional recognition using various technologies normal cameras, and depth cameras for real-time, and the potential use of VR and inputs including images, videos, and 3-dimensional poses described in vector space. We discussed 19 research papers collected from selected journals and databases highlighting their methodology, classification algorithm, and the used datasets that relate to emotion recognition and pose estimation. A benchmark has been made according to their accuracy as it was the most common performance measurement metric used. We concluded that the multimodal Approaches overall made the best accuracy and then we mentioned futuristic concerns that can improve the development of this research topic.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01774",
        "abstract url": "https://arxiv.org/abs/2408.01774",
        "title": "STDA: Spatio-Temporal Dual-Encoder Network Incorporating Driver Attention to Predict Driver Behaviors Under Safety-Critical Scenarios",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate behavior prediction for vehicles is essential but challenging for autonomous driving. Most existing studies show satisfying performance under regular scenarios, but most neglected safety-critical scenarios. In this study, a spatio-temporal dual-encoder network named STDA for safety-critical scenarios was developed. Considering the exceptional capabilities of human drivers in terms of situational awareness and comprehending risks, driver attention was incorporated into STDA to facilitate swift identification of the critical regions, which is expected to improve both performance and interpretability. STDA contains four parts: the driver attention prediction module, which predicts driver attention; the fusion module designed to fuse the features between driver attention and raw images; the temporary encoder module used to enhance the capability to interpret dynamic scenes; and the behavior prediction module to predict the behavior. The experiment data are used to train and validate the model. The results show that STDA improves the G-mean from 0.659 to 0.719 when incorporating driver attention and adopting a temporal encoder module. In addition, extensive experimentation has been conducted to validate that the proposed module exhibits robust generalization capabilities and can be seamlessly integrated into other mainstream models.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01838",
        "abstract url": "https://arxiv.org/abs/2408.01838",
        "title": "Tracking Emotional Dynamics in Chat Conversations: A Hybrid Approach using DistilBERT and Emoji Sentiment Analysis",
        "rating": "0",
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Computer-mediated communication has become more important than face-to-face communication in many contexts. Tracking emotional dynamics in chat conversations can enhance communication, improve services, and support well-being in various contexts. This paper explores a hybrid approach to tracking emotional dynamics in chat conversations by combining DistilBERT-based text emotion detection and emoji sentiment analysis. A Twitter dataset was analyzed using various machine learning algorithms, including SVM, Random Forest, and AdaBoost. We contrasted their performance with DistilBERT. Results reveal DistilBERT's superior performance in emotion recognition. Our approach accounts for emotive expressions conveyed through emojis to better understand participants' emotions during chats. We demonstrate how this approach can effectively capture and analyze emotional shifts in real-time conversations. Our findings show that integrating text and emoji analysis is an effective way of tracking chat emotion, with possible applications in customer service, work chats, and social media interactions.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This work has been submitted to the Springer journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2408.01840",
        "abstract url": "https://arxiv.org/abs/2408.01840",
        "title": "E$^3$NeRF: Efficient Event-Enhanced Neural Radiance Fields from Blurry Images",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRF) achieve impressive rendering performance by learning volumetric 3D representation from several images of different views. However, it is difficult to reconstruct a sharp NeRF from blurry input as it often occurs in the wild. To solve this problem, we propose a novel Efficient Event-Enhanced NeRF (E$^3$NeRF) by utilizing the combination of RGB images and event streams. To effectively introduce event streams into the neural volumetric representation learning process, we propose an event-enhanced blur rendering loss and an event rendering loss, which guide the network via modeling the real blur process and event generation process, respectively. Specifically, we leverage spatial-temporal information from the event stream to evenly distribute learning attention over temporal blur while simultaneously focusing on blurry texture through the spatial attention. Moreover, a camera pose estimation framework for real-world data is built with the guidance of the events to generalize the method to practical applications. Compared to previous image-based or event-based NeRF, our framework makes more profound use of the internal relationship between events and images. Extensive experiments on both synthetic data and real-world data demonstrate that E$^3$NeRF can effectively learn a sharp NeRF from blurry images, especially in non-uniform motion and low-light scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01859",
        "abstract url": "https://arxiv.org/abs/2408.01859",
        "title": "Graph Unfolding and Sampling for Transitory Video Summarization via Gershgorin Disc Alignment",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "User-generated videos (UGVs) uploaded from mobile phones to social media sites like YouTube and TikTok are short and non-repetitive. We summarize a transitory UGV into several keyframes in linear time via fast graph sampling based on Gershgorin disc alignment (GDA). Specifically, we first model a sequence of $N$ frames in a UGV as an $M$-hop path graph $\\mathcal{G}^o$ for $M \\ll N$, where the similarity between two frames within $M$ time instants is encoded as a positive edge based on feature similarity. Towards efficient sampling, we then \"unfold\" $\\mathcal{G}^o$ to a $1$-hop path graph $\\mathcal{G}$, specified by a generalized graph Laplacian matrix $\\mathcal{L}$, via one of two graph unfolding procedures with provable performance bounds. We show that maximizing the smallest eigenvalue $\u03bb_{\\min}(\\mathbf{B})$ of a coefficient matrix $\\mathbf{B} = \\textit{diag}\\left(\\mathbf{h}\\right) + \u03bc\\mathcal{L}$, where $\\mathbf{h}$ is the binary keyframe selection vector, is equivalent to minimizing a worst-case signal reconstruction error. We maximize instead the Gershgorin circle theorem (GCT) lower bound $\u03bb^-_{\\min}(\\mathbf{B})$ by choosing $\\mathbf{h}$ via a new fast graph sampling algorithm that iteratively aligns left-ends of Gershgorin discs for all graph nodes (frames). Extensive experiments on multiple short video datasets show that our algorithm achieves comparable or better video summarization performance compared to state-of-the-art methods, at a substantially reduced complexity.",
        "subjects": [
            "cs.CV",
            "eess.IV",
            "eess.SP"
        ],
        "comment": "13 pages, 5 figures"
    },
    {
        "paper id": "2408.01878",
        "abstract url": "https://arxiv.org/abs/2408.01878",
        "title": "FBINeRF: Feature-Based Integrated Recurrent Network for Pinhole and Fisheye Neural Radiance Fields",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "voxel",
                "depth",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Previous studies aiming to optimize and bundle-adjust camera poses using Neural Radiance Fields (NeRFs), such as BARF and DBARF, have demonstrated impressive capabilities in 3D scene reconstruction. However, these approaches have been designed for pinhole-camera pose optimization and do not perform well under radial image distortions such as those in fisheye cameras. Furthermore, inaccurate depth initialization in DBARF results in erroneous geometric information affecting the overall convergence and quality of results. In this paper, we propose adaptive GRUs with a flexible bundle-adjustment method adapted to radial distortions and incorporate feature-based recurrent neural networks to generate continuous novel views from fisheye datasets. Other NeRF methods for fisheye images, such as SCNeRF and OMNI-NeRF, use projected ray distance loss for distorted pose refinement, causing severe artifacts, long rendering time, and are difficult to use in downstream tasks, where the dense voxel representation generated by a NeRF method needs to be converted into a mesh representation. We also address depth initialization issues by adding MiDaS-based depth priors for pinhole images. Through extensive experiments, we demonstrate the generalization capacity of FBINeRF and show high-fidelity results for both pinhole-camera and fisheye-camera NeRFs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2408.01890",
        "abstract url": "https://arxiv.org/abs/2408.01890",
        "title": "Cross-layer Attention Sharing for Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "As large language models (LLMs) evolve, the increase in model depth and parameter number leads to substantial redundancy. To enhance the efficiency of the attention mechanism, previous works primarily compress the KV cache or group attention heads, while largely overlooking redundancy between layers. Our comprehensive analyses across various LLMs show that highly similar attention patterns persist within most layers. It's intuitive to save the computation by sharing attention weights across layers. However, further analysis reveals two challenges: (1) Directly sharing the weight matrix without carefully rearranging the attention heads proves to be ineffective; (2) Shallow layers are vulnerable to small deviations in attention weights. Driven by these insights, we introduce LiSA, a lightweight substitute for self-attention in well-trained LLMs. LiSA employs tiny feed-forward networks to align attention heads between adjacent layers and low-rank matrices to approximate differences in layer-wise attention weights. Evaluations encompassing 13 typical benchmarks demonstrate that LiSA maintains high response quality in terms of accuracy and perplexity while reducing redundant attention calculations within 53-84% of the total layers. Our implementations of LiSA achieve a 6X compression of Q and K, with maximum throughput improvements of 19.5% for LLaMA3-8B and 32.3% for LLaMA2-7B.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Working in process"
    },
    {
        "paper id": "2408.01895",
        "abstract url": "https://arxiv.org/abs/2408.01895",
        "title": "Computational Trichromacy Reconstruction: Empowering the Color-Vision Deficient to Recognize Colors Using Augmented Reality",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose an assistive technology that helps individuals with Color Vision Deficiencies (CVD) to recognize/name colors. A dichromat's color perception is a reduced two-dimensional (2D) subset of a normal trichromat's three dimensional color (3D) perception, leading to confusion when visual stimuli that appear identical to the dichromat are referred to by different color names. Using our proposed system, CVD individuals can interactively induce distinct perceptual changes to originally confusing colors via a computational color space transformation. By combining their original 2D precepts for colors with the discriminative changes, a three dimensional color space is reconstructed, where the dichromat can learn to resolve color name confusions and accurately recognize colors. Our system is implemented as an Augmented Reality (AR) interface on smartphones, where users interactively control the rotation through swipe gestures and observe the induced color shifts in the camera view or in a displayed image. Through psychophysical experiments and a longitudinal user study, we demonstrate that such rotational color shifts have discriminative power (initially confusing colors become distinct under rotation) and exhibit structured perceptual shifts dichromats can learn with modest training. The AR App is also evaluated in two real-world scenarios (building with lego blocks and interpreting artistic works); users all report positive experience in using the App to recognize object colors that they otherwise could not.",
        "subjects": [
            "cs.HC",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01928",
        "abstract url": "https://arxiv.org/abs/2408.01928",
        "title": "A Semi-supervised Multi-channel Graph Convolutional Network for Query Classification in E-commerce",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Query intent classification is an essential module for customers to find desired products on the e-commerce application quickly. Most existing query intent classification methods rely on the users' click behavior as a supervised signal to construct training samples. However, these methods based entirely on posterior labels may lead to serious category imbalance problems because of the Matthew effect in click samples. Compared with popular categories, it is difficult for products under long-tail categories to obtain traffic and user clicks, which makes the models unable to detect users' intent for products under long-tail categories. This in turn aggravates the problem that long-tail categories cannot obtain traffic, forming a vicious circle. In addition, due to the randomness of the user's click, the posterior label is unstable for the query with similar semantics, which makes the model very sensitive to the input, leading to an unstable and incomplete recall of categories. In this paper, we propose a novel Semi-supervised Multi-channel Graph Convolutional Network (SMGCN) to address the above problems from the perspective of label association and semi-supervised learning. SMGCN extends category information and enhances the posterior label by utilizing the similarity score between the query and categories. Furthermore, it leverages the co-occurrence and semantic similarity graph of categories to strengthen the relations among labels and weaken the influence of posterior label instability. We conduct extensive offline and online A/B experiments, and the experimental results show that SMGCN significantly outperforms the strong baselines, which shows its effectiveness and practicality.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "Accepted by WWW2024"
    },
    {
        "paper id": "2408.01691",
        "abstract url": "https://arxiv.org/abs/2408.01691",
        "title": "TreeCSS: An Efficient Framework for Vertical Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Vertical federated learning (VFL) considers the case that the features of data samples are partitioned over different participants. VFL consists of two main steps, i.e., identify the common data samples for all participants (alignment) and train model using the aligned data samples (training). However, when there are many participants and data samples, both alignment and training become slow. As such, we propose TreeCSS as an efficient VFL framework that accelerates the two main steps. In particular, for sample alignment, we design an efficient multi-party private set intersection (MPSI) protocol called Tree-MPSI, which adopts a tree-based structure and a data-volume-aware scheduling strategy to parallelize alignment among the participants. As model training time scales with the number of data samples, we conduct coreset selection (CSS) to choose some representative data samples for training. Our CCS method adopts a clustering-based scheme for security and generality, which first clusters the features locally on each participant and then merges the local clustering results to select representative samples. In addition, we weight the samples according to their distances to the centroids to reflect their importance to model training. We evaluate the effectiveness and efficiency of our TreeCSS framework on various datasets and models. The results show that compared with vanilla VFL, TreeCSS accelerates training by up to 2.93x and achieves comparable model accuracy.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "16 pages, 7 figures"
    },
    {
        "paper id": "2408.01697",
        "abstract url": "https://arxiv.org/abs/2408.01697",
        "title": "Invariant Graph Learning Meets Information Bottleneck for Out-of-Distribution Generalization",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph out-of-distribution (OOD) generalization remains a major challenge in graph learning since graph neural networks (GNNs) often suffer from severe performance degradation under distribution shifts. Invariant learning, aiming to extract invariant features across varied distributions, has recently emerged as a promising approach for OOD generation. Despite the great success of invariant learning in OOD problems for Euclidean data (i.e., images), the exploration within graph data remains constrained by the complex nature of graphs. Existing studies, such as data augmentation or causal intervention, either suffer from disruptions to invariance during the graph manipulation process or face reliability issues due to a lack of supervised signals for causal parts. In this work, we propose a novel framework, called Invariant Graph Learning based on Information bottleneck theory (InfoIGL), to extract the invariant features of graphs and enhance models' generalization ability to unseen distributions. Specifically, InfoIGL introduces a redundancy filter to compress task-irrelevant information related to environmental factors. Cooperating with our designed multi-level contrastive learning, we maximize the mutual information among graphs of the same class in the downstream classification tasks, preserving invariant features for prediction to a great extent. An appealing feature of InfoIGL is its strong generalization ability without depending on supervised signal of invariance. Experiments on both synthetic and real-world datasets demonstrate that our method achieves state-of-the-art performance under OOD generalization for graph classification tasks. The source code is available at https://github.com/maowenyu-11/InfoIGL.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01713",
        "abstract url": "https://arxiv.org/abs/2408.01713",
        "title": "Intuitionistic Fuzzy Generalized Eigenvalue Proximal Support Vector Machine",
        "rating": "-0.5",
        "keywords": [
            [
                "Support Vector Machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generalized eigenvalue proximal support vector machine (GEPSVM) has attracted widespread attention due to its simple architecture, rapid execution, and commendable performance. GEPSVM gives equal significance to all samples, thereby diminishing its robustness and efficacy when confronted with real-world datasets containing noise and outliers. In order to reduce the impact of noises and outliers, we propose a novel intuitionistic fuzzy generalized eigenvalue proximal support vector machine (IF-GEPSVM). The proposed IF-GEPSVM assigns the intuitionistic fuzzy score to each training sample based on its location and surroundings in the high-dimensional feature space by using a kernel function. The solution of the IF-GEPSVM optimization problem is obtained by solving a generalized eigenvalue problem. Further, we propose an intuitionistic fuzzy improved GEPSVM (IF-IGEPSVM) by solving the standard eigenvalue decomposition resulting in simpler optimization problems with less computation cost which leads to an efficient intuitionistic fuzzy-based model. We conduct a comprehensive evaluation of the proposed IF-GEPSVM and IF-IGEPSVM models on UCI and KEEL datasets. Moreover, to evaluate the robustness of the proposed IF-GEPSVM and IF-IGEPSVM models, label noise is introduced into some UCI and KEEL datasets. The experimental findings showcase the superior generalization performance of the proposed models when compared to the existing baseline models, both with and without label noise. Our experimental results, supported by rigorous statistical analyses, confirm the superior generalization abilities of the proposed IF-GEPSVM and IF-IGEPSVM models over the baseline models. Furthermore, we implement the proposed IF-GEPSVM and IF-IGEPSVM models on the USPS recognition dataset, yielding promising results that underscore the models' effectiveness in practical and real-world applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01715",
        "abstract url": "https://arxiv.org/abs/2408.01715",
        "title": "Joint Universal Adversarial Perturbations with Interpretations",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) have significantly boosted the performance of many challenging tasks. Despite the great development, DNNs have also exposed their vulnerability. Recent studies have shown that adversaries can manipulate the predictions of DNNs by adding a universal adversarial perturbation (UAP) to benign samples. On the other hand, increasing efforts have been made to help users understand and explain the inner working of DNNs by highlighting the most informative parts (i.e., attribution maps) of samples with respect to their predictions. Moreover, we first empirically find that such attribution maps between benign and adversarial examples have a significant discrepancy, which has the potential to detect universal adversarial perturbations for defending against adversarial attacks. This finding motivates us to further investigate a new research problem: whether there exist universal adversarial perturbations that are able to jointly attack DNNs classifier and its interpretation with malicious desires. It is challenging to give an explicit answer since these two objectives are seemingly conflicting. In this paper, we propose a novel attacking framework to generate joint universal adversarial perturbations (JUAP), which can fool the DNNs model and misguide the inspection from interpreters simultaneously. Comprehensive experiments on various datasets demonstrate the effectiveness of the proposed method JUAP for joint attacks. To the best of our knowledge, this is the first effort to study UAP for jointly attacking both DNNs and interpretations.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01747",
        "abstract url": "https://arxiv.org/abs/2408.01747",
        "title": "Classical Machine Learning: Seventy Years of Algorithmic Learning Evolution",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) has transformed numerous fields, but understanding its foundational research is crucial for its continued progress. This paper presents an overview of the significant classical ML algorithms and examines the state-of-the-art publications spanning twelve decades through an extensive bibliometric analysis study. We analyzed a dataset of highly cited papers from prominent ML conferences and journals, employing citation and keyword analyses to uncover critical insights. The study further identifies the most influential papers and authors, reveals the evolving collaborative networks within the ML community, and pinpoints prevailing research themes and emerging focus areas. Additionally, we examine the geographic distribution of highly cited publications, highlighting the leading countries in ML research. This study provides a comprehensive overview of the evolution of traditional learning algorithms and their impacts. It discusses challenges and opportunities for future development, focusing on the Global South. The findings from this paper offer valuable insights for both ML experts and the broader research community, enhancing understanding of the field's trajectory and its significant influence on recent advances in learning algorithms.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01765",
        "abstract url": "https://arxiv.org/abs/2408.01765",
        "title": "Joint Model Pruning and Resource Allocation for Wireless Time-triggered Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Time-triggered federated learning, in contrast to conventional event-based federated learning, organizes users into tiers based on fixed time intervals. However, this network still faces challenges due to a growing number of devices and limited wireless bandwidth, increasing issues like stragglers and communication overhead. In this paper, we apply model pruning to wireless Time-triggered systems and jointly study the problem of optimizing the pruning ratio and bandwidth allocation to minimize training loss under communication latency constraints. To solve this joint optimization problem, we perform a convergence analysis on the gradient $l_2$-norm of the asynchronous multi-tier federated learning (FL) model with adaptive model pruning. The convergence upper bound is derived and a joint optimization problem of pruning ratio and wireless bandwidth is defined to minimize the model training loss under a given communication latency constraint. The closed-form solutions for wireless bandwidth and pruning ratio by using KKT conditions are then formulated. As indicated in the simulation experiments, our proposed TT-Prune demonstrates a 40% reduction in communication cost, compared with the asynchronous multi-tier FL without model pruning, while maintaining the model convergence at the same level.",
        "subjects": [
            "cs.LG",
            "cs.IT"
        ],
        "comment": "Accepted in IEEE Global Communications Conference 2024"
    },
    {
        "paper id": "2408.01857",
        "abstract url": "https://arxiv.org/abs/2408.01857",
        "title": "Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop an algorithm to approximate the time evolution of a probability measure without explicitly learning an operator that governs the evolution. A particular application of interest is discrete measures $\u03bc_t^N$ that arise from particle systems. In many such situations, the individual particles move chaotically on short time scales, making it difficult to learn the dynamics of a governing operator, but the bulk distribution $\u03bc_t^N$ approximates an absolutely continuous measure $\u03bc_t$ that evolves ``smoothly.'' If $\u03bc_t$ is known on some time interval, then linearized optimal transport theory provides an Euler-like scheme for approximating the evolution of $\u03bc_t$ using its ``tangent vector field'' (represented as a time-dependent vector field on $\\mathbb R^d$), which can be computed as a limit of optimal transport maps. We propose an analog of this Euler approximation to predict the evolution of the discrete measure $\u03bc_t^N$ (without knowing $\u03bc_t$). To approximate the analogous tangent vector field, we use a finite difference over a time step that sits between the two time scales of the system -- long enough for the large-$N$ evolution ($\u03bc_t$) to emerge but short enough to satisfactorily approximate the derivative object used in the Euler scheme. By allowing the limiting behavior to emerge, the optimal transport maps closely approximate the vector field describing the bulk distribution's smooth evolution instead of the individual particles' more chaotic movements. We demonstrate the efficacy of this approach with two illustrative examples, Gaussian diffusion and a cell chemotaxis model, and show that our method succeeds in predicting the bulk behavior over relatively large steps.",
        "subjects": [
            "math.NA",
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01880",
        "abstract url": "https://arxiv.org/abs/2408.01880",
        "title": "Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recent years, multi-hop reasoning has been widely studied for knowledge graph (KG) reasoning due to its efficacy and interpretability. However, previous multi-hop reasoning approaches are subject to two primary shortcomings. First, agents struggle to learn effective and robust policies at the early phase due to sparse rewards. Second, these approaches often falter on specific datasets like sparse knowledge graphs, where agents are required to traverse lengthy reasoning paths. To address these problems, we propose a multi-hop reasoning model with dual agents based on hierarchical reinforcement learning (HRL), which is named FULORA. FULORA tackles the above reasoning challenges by eFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks on the simplified knowledge graph to provide stage-wise hints for the low-level agent walking on the original knowledge graph. In this framework, the low-level agent optimizes a value function that balances two objectives: (1) maximizing return, and (2) integrating efficient guidance from the high-level agent. Experiments conducted on three real-word knowledge graph datasets demonstrate that FULORA outperforms RL-based baselines, especially in the case of long-distance reasoning.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.02693",
        "abstract url": "https://arxiv.org/abs/2408.02693",
        "title": "Diff-PIC: Revolutionizing Particle-In-Cell Simulation for Advancing Nuclear Fusion with Diffusion Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Sustainable energy is a crucial global challenge, and recent breakthroughs in nuclear fusion ignition underscore the potential of harnessing energy extracted from nuclear fusion in everyday life, thereby drawing significant attention to fusion ignition research, especially Laser-Plasma Interaction (LPI). Unfortunately, the complexity of LPI at ignition scale renders theory-based analysis nearly impossible -- instead, it has to rely heavily on Particle-in-Cell (PIC) simulations, which is extremely computationally intensive, making it a major bottleneck in advancing fusion ignition. In response, this work introduces Diff-PIC, a novel paradigm that leverages conditional diffusion models as a computationally efficient alternative to PIC simulations for generating high-fidelity scientific data. Specifically, we design a distillation paradigm to distill the physical patterns captured by PIC simulations into diffusion models, demonstrating both theoretical and practical feasibility. Moreover, to ensure practical effectiveness, we provide solutions for two critical challenges: (1) We develop a physically-informed conditional diffusion model that can learn and generate meaningful embeddings for mathematically continuous physical conditions. This model offers algorithmic generalization and adaptable transferability, effectively capturing the complex relationships between physical conditions and simulation outcomes; and (2) We employ the rectified flow technique to make our model a one-step conditional diffusion model, enhancing its efficiency further while maintaining high fidelity and physical validity. Diff-PIC establishes a new paradigm for using diffusion models to overcome the computational barriers in nuclear fusion research, setting a benchmark for future innovations and advancements in this field.",
        "subjects": [
            "physics.comp-ph",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01678",
        "abstract url": "https://arxiv.org/abs/2408.01678",
        "title": "iControl3D: An Interactive System for Controllable 3D Scene Generation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D content creation has long been a complex and time-consuming process, often requiring specialized skills and resources. While recent advancements have allowed for text-guided 3D object and scene generation, they still fall short of providing sufficient control over the generation process, leading to a gap between the user's creative vision and the generated results. In this paper, we present iControl3D, a novel interactive system that empowers users to generate and render customizable 3D scenes with precise control. To this end, a 3D creator interface has been developed to provide users with fine-grained control over the creation process. Technically, we leverage 3D meshes as an intermediary proxy to iteratively merge individual 2D diffusion-generated images into a cohesive and unified 3D scene representation. To ensure seamless integration of 3D meshes, we propose to perform boundary-aware depth alignment before fusing the newly generated mesh with the existing one in 3D space. Additionally, to effectively manage depth discrepancies between remote content and foreground, we propose to model remote content separately with an environment map instead of 3D meshes. Finally, our neural rendering interface enables users to build a radiance field of their scene online and navigate the entire scene. Extensive experiments have been conducted to demonstrate the effectiveness of our system. The code will be made available at https://github.com/xingyi-li/iControl3D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ACM MM 2024"
    },
    {
        "paper id": "2408.01688",
        "abstract url": "https://arxiv.org/abs/2408.01688",
        "title": "SiamMo: Siamese Motion-Centric 3D Object Tracking",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current 3D single object tracking methods primarily rely on the Siamese matching-based paradigm, which struggles with textureless and incomplete LiDAR point clouds. Conversely, the motion-centric paradigm avoids appearance matching, thus overcoming these issues. However, its complex multi-stage pipeline and the limited temporal modeling capability of a single-stream architecture constrain its potential. In this paper, we introduce SiamMo, a novel and simple Siamese motion-centric tracking approach. Unlike the traditional single-stream architecture, we employ Siamese feature extraction for motion-centric tracking. This decouples feature extraction from temporal fusion, significantly enhancing tracking performance. Additionally, we design a Spatio-Temporal Feature Aggregation module to integrate Siamese features at multiple scales, capturing motion information effectively. We also introduce a Box-aware Feature Encoding module to encode object size priors into motion estimation. SiamMo is a purely motion-centric tracker that eliminates the need for additional processes like segmentation and box refinement. Without whistles and bells, SiamMo not only surpasses state-of-the-art methods across multiple benchmarks but also demonstrates exceptional robustness in challenging scenarios. SiamMo sets a new record on the KITTI tracking benchmark with 90.1\\% precision while maintaining a high inference speed of 108 FPS. The code will be released at https://github.com/HDU-VRLab/SiamMo.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01696",
        "abstract url": "https://arxiv.org/abs/2408.01696",
        "title": "Generating High-quality Symbolic Music Using Fine-grained Discriminators",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Existing symbolic music generation methods usually utilize discriminator to improve the quality of generated music via global perception of music. However, considering the complexity of information in music, such as rhythm and melody, a single discriminator cannot fully reflect the differences in these two primary dimensions of music. In this work, we propose to decouple the melody and rhythm from music, and design corresponding fine-grained discriminators to tackle the aforementioned issues. Specifically, equipped with a pitch augmentation strategy, the melody discriminator discerns the melody variations presented by the generated samples. By contrast, the rhythm discriminator, enhanced with bar-level relative positional encoding, focuses on the velocity of generated notes. Such a design allows the generator to be more explicitly aware of which aspects should be adjusted in the generated music, making it easier to mimic human-composed music. Experimental results on the POP909 benchmark demonstrate the favorable performance of the proposed method compared to several state-of-the-art methods in terms of both objective and subjective metrics.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "Accepted by ICPR2024"
    },
    {
        "paper id": "2408.01721",
        "abstract url": "https://arxiv.org/abs/2408.01721",
        "title": "MoleNetwork: A tool for the generation of synthetic optical network topologies",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Model networks and their underlying topologies have been used as a reference for techno-economic studies for several decades. Existing reference topologies for optical networks may cover different network segments such as backbone, metro core, metro aggregation, access and/or data center. While telco operators work on the optimization of their own existing deployed optical networks, the availability of different topologies is useful for researchers and technology developers to test their solutions in a variety of scenarios and validate the performance in terms of energy efficiency or cost reduction. This paper presents an open-source tool, MoleNetwork, to generate graphs inspired by real network topologies of telecommunication operators that can be used as benchmarks for techno-economic studies.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01739",
        "abstract url": "https://arxiv.org/abs/2408.01739",
        "title": "LAM3D: Leveraging Attention for Monocular 3D Object Detection",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Since the introduction of the self-attention mechanism and the adoption of the Transformer architecture for Computer Vision tasks, the Vision Transformer-based architectures gained a lot of popularity in the field, being used for tasks such as image classification, object detection and image segmentation. However, efficiently leveraging the attention mechanism in vision transformers for the Monocular 3D Object Detection task remains an open question. In this paper, we present LAM3D, a framework that Leverages self-Attention mechanism for Monocular 3D object Detection. To do so, the proposed method is built upon a Pyramid Vision Transformer v2 (PVTv2) as feature extraction backbone and 2D/3D detection machinery. We evaluate the proposed method on the KITTI 3D Object Detection Benchmark, proving the applicability of the proposed solution in the autonomous driving domain and outperforming reference methods. Moreover, due to the usage of self-attention, LAM3D is able to systematically outperform the equivalent architecture that does not employ self-attention.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "6 pages. Accepted to MMSP 2024"
    },
    {
        "paper id": "2408.01748",
        "abstract url": "https://arxiv.org/abs/2408.01748",
        "title": "Discovery of Rare Causal Knowledge from Financial Statement Summaries",
        "rating": "-1",
        "keywords": [
            [
                "agricultural"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "What would happen if temperatures were subdued and result in a cool summer? One can easily imagine that air conditioner, ice cream or beer sales would be suppressed as a result of this. Less obvious is that agricultural shipments might be delayed, or that sound proofing material sales might decrease. The ability to extract such causal knowledge is important, but it is also important to distinguish between cause-effect pairs that are known and those that are likely to be unknown, or rare. Therefore, in this paper, we propose a method for extracting rare causal knowledge from Japanese financial statement summaries produced by companies. Our method consists of three steps. First, it extracts sentences that include causal knowledge from the summaries using a machine learning method based on an extended language ontology. Second, it obtains causal knowledge from the extracted sentences using syntactic patterns. Finally, it extracts the rarest causal knowledge from the knowledge it has obtained.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01752",
        "abstract url": "https://arxiv.org/abs/2408.01752",
        "title": "Advancing Green AI: Efficient and Accurate Lightweight CNNs for Rice Leaf Disease Identification",
        "rating": "-1",
        "keywords": [
            [
                "Disease"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Rice plays a vital role as a primary food source for over half of the world's population, and its production is critical for global food security. Nevertheless, rice cultivation is frequently affected by various diseases that can severely decrease yield and quality. Therefore, early and accurate detection of rice diseases is necessary to prevent their spread and minimize crop losses. In this research, we explore three mobile-compatible CNN architectures, namely ShuffleNet, MobileNetV2, and EfficientNet-B0, for rice leaf disease classification. These models are selected due to their compatibility with mobile devices, as they demand less computational power and memory compared to other CNN models. To enhance the performance of the three models, we added two fully connected layers separated by a dropout layer. We used early stop creation to prevent the model from being overfiting. The results of the study showed that the best performance was achieved by the EfficientNet-B0 model with an accuracy of 99.8%. Meanwhile, MobileNetV2 and ShuffleNet only achieved accuracies of 84.21% and 66.51%, respectively. This study shows that EfficientNet-B0 when combined with the proposed layer and early stop, can produce a high-accuracy model. Keywords: rice leaf detection; green AI; smart agriculture; EfficientNet;",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01766",
        "abstract url": "https://arxiv.org/abs/2408.01766",
        "title": "MultiFuser: Multimodal Fusion Transformer for Enhanced Driver Action Recognition",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Driver action recognition, aiming to accurately identify drivers' behaviours, is crucial for enhancing driver-vehicle interactions and ensuring driving safety. Unlike general action recognition, drivers' environments are often challenging, being gloomy and dark, and with the development of sensors, various cameras such as IR and depth cameras have emerged for analyzing drivers' behaviors. Therefore, in this paper, we propose a novel multimodal fusion transformer, named MultiFuser, which identifies cross-modal interrelations and interactions among multimodal car cabin videos and adaptively integrates different modalities for improved representations. Specifically, MultiFuser comprises layers of Bi-decomposed Modules to model spatiotemporal features, with a modality synthesizer for multimodal features integration. Each Bi-decomposed Module includes a Modal Expertise ViT block for extracting modality-specific features and a Patch-wise Adaptive Fusion block for efficient cross-modal fusion. Extensive experiments are conducted on Drive&Act dataset and the results demonstrate the efficacy of our proposed approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01775",
        "abstract url": "https://arxiv.org/abs/2408.01775",
        "title": "3DStoryline: Immersive Visual Storytelling",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Storyline visualization has emerged as an innovative method for illustrating the development and changes in stories across various domains. Traditional approaches typically represent stories with one line per character, progressing from left to right. While effective for simpler narratives, this method faces significant challenges when dealing with complex stories involving multiple characters, as well as temporal and spatial dynamics. In this study, we investigate the potential of immersive environments for enhancing storyline visualizations. We begin by summarizing the key design considerations for effective storyline visualization in virtual reality (VR). Guided by these principles, we develop 3DStoryline, a system that allows users to view and interact with 3D immersive storyline visualizations. To evaluate the effectiveness of 3DStoryline, we conduct a task-based user study, revealing that the system significantly enhances users' comprehension of complex narratives.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2408.01779",
        "abstract url": "https://arxiv.org/abs/2408.01779",
        "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the development of artificial intelligence (AI), large language models (LLM) are widely used in many fields. However, the reasoning ability of LLM is still very limited when it comes to mathematical reasoning. Mathematics plays an important role in all aspects of human society and is a technical guarantee in the fields of healthcare, transport and aerospace, for this reason, the development of AI big language models in the field of mathematics has great potential significance. To improve the mathematical reasoning ability of large language models, we proposed an agent framework for learning to solve mathematical problems based on inductive reasoning. By emulating the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks, this framework has great performance in the mathematical reasoning process. It improves global accuracy over the baseline method (chain-of-thought) by 20.96% and solves 17.54% of the mathematical problems that the baseline cannot solve. Benefiting from the efficient RETRIEVAL method, our model improves the ability of large language models to efficiently use external knowledge, i.e., the mathematical computation of the model can be based on written procedures. In education, our model can be used as a personalised learning aid, thus reducing the inequality of educational resources.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01784",
        "abstract url": "https://arxiv.org/abs/2408.01784",
        "title": "Graph Stochastic Neural Process for Inductive Few-shot Knowledge Graph Completion",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Knowledge graphs (KGs) store enormous facts as relationships between entities. Due to the long-tailed distribution of relations and the incompleteness of KGs, there is growing interest in few-shot knowledge graph completion (FKGC). Existing FKGC methods often assume the existence of all entities in KGs, which may not be practical since new relations and entities can emerge over time. Therefore, we focus on a more challenging task called inductive few-shot knowledge graph completion (I-FKGC), where both relations and entities during the test phase are unknown before. Inspired by the idea of inductive reasoning, we cast I-FKGC as an inductive reasoning problem. Specifically, we propose a novel Graph Stochastic Neural Process approach (GS-NP), which consists of two major modules. In the first module, to obtain a generalized hypothesis (e.g., shared subgraph), we present a neural process-based hypothesis extractor that models the joint distribution of hypothesis, from which we can sample a hypothesis for predictions. In the second module, based on the hypothesis, we propose a graph stochastic attention-based predictor to test if the triple in the query set aligns with the extracted hypothesis. Meanwhile, the predictor can generate an explanatory subgraph identified by the hypothesis. Finally, the training of these two modules is seamlessly combined into a unified objective function, of which the effectiveness is verified by theoretical analyses as well as empirical studies. Extensive experiments on three public datasets demonstrate that our method outperforms existing methods and derives new state-of-the-art performance.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01797",
        "abstract url": "https://arxiv.org/abs/2408.01797",
        "title": "NuLite -- Lightweight and Fast Model for Nuclei Instance Segmentation and Classification",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In pathology, accurate and efficient analysis of Hematoxylin and Eosin (H\\&E) slides is crucial for timely and effective cancer diagnosis. Although many deep learning solutions for nuclei instance segmentation and classification exist in the literature, they often entail high computational costs and resource requirements, thus limiting their practical usage in medical applications. To address this issue, we introduce a novel convolutional neural network, NuLite, a U-Net-like architecture designed explicitly on Fast-ViT, a state-of-the-art (SOTA) lightweight CNN. We obtained three versions of our model, NuLite-S, NuLite-M, and NuLite-H, trained on the PanNuke dataset. The experimental results prove that our models equal CellViT (SOTA) in terms of panoptic quality and detection. However, our lightest model, NuLite-S, is 40 times smaller in terms of parameters and about 8 times smaller in terms of GFlops, while our heaviest model is 17 times smaller in terms of parameters and about 7 times smaller in terms of GFlops. Moreover, our model is up to about 8 times faster than CellViT. Lastly, to prove the effectiveness of our solution, we provide a robust comparison of external datasets, namely CoNseP, MoNuSeg, and GlySAC. Our model is publicly available at https://github.com/CosmoIknosLab/NuLite",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01798",
        "abstract url": "https://arxiv.org/abs/2408.01798",
        "title": "Differentially Private Gomory-Hu Trees",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Given an undirected, weighted $n$-vertex graph $G = (V, E, w)$, a Gomory-Hu tree $T$ is a weighted tree on $V$ such that for any pair of distinct vertices $s, t \\in V$, the Min-$s$-$t$-Cut on $T$ is also a Min-$s$-$t$-Cut on $G$. Computing a Gomory-Hu tree is a well-studied problem in graph algorithms and has received considerable attention. In particular, a long line of work recently culminated in constructing a Gomory-Hu tree in almost linear time [Abboud, Li, Panigrahi and Saranurak, FOCS 2023]. We design a differentially private (DP) algorithm that computes an approximate Gomory-Hu tree. Our algorithm is $\\varepsilon$-DP, runs in polynomial time, and can be used to compute $s$-$t$ cuts that are $\\tilde{O}(n/\\varepsilon)$-additive approximations of the Min-$s$-$t$-Cuts in $G$ for all distinct $s, t \\in V$ with high probability. Our error bound is essentially optimal, as [Dalirrooyfard, Mitrovi\u0107 and Nevmyvaka, NeurIPS 2023] showed that privately outputting a single Min-$s$-$t$-Cut requires $\u03a9(n)$ additive error even with $(1, 0.1)$-DP and allowing for a multiplicative error term. Prior to our work, the best additive error bounds for approximate all-pairs Min-$s$-$t$-Cuts were $O(n^{3/2}/\\varepsilon)$ for $\\varepsilon$-DP [Gupta, Roth and Ullman, TCC 2012] and $O(\\sqrt{mn} \\cdot \\text{polylog}(n/\u03b4) / \\varepsilon)$ for $(\\varepsilon, \u03b4)$-DP [Liu, Upadhyay and Zou, SODA 2024], both of which are implied by differential private algorithms that preserve all cuts in the graph. An important technical ingredient of our main result is an $\\varepsilon$-DP algorithm for computing minimum Isolating Cuts with $\\tilde{O}(n / \\varepsilon)$ additive error, which may be of independent interest.",
        "subjects": [
            "cs.DS",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01801",
        "abstract url": "https://arxiv.org/abs/2408.01801",
        "title": "Introducing Bidirectional Programming in Constructive Solid Geometry-Based CAD",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "3D Computer-Aided Design (CAD) users need to overcome several obstacles to benefit from the flexibility of programmatic interface tools. Besides the barriers of any programming language, users face challenges inherent to 3D spatial interaction. Scripting simple operations, such as moving an element in 3D space, can be significantly more challenging than performing the same task using direct manipulation. We introduce the concept of bidirectional programming for Constructive Solid Geometry (CSG) CAD tools, informed by interviews we performed with programmatic interface users. We describe how users can navigate and edit the 3D model using direct manipulation in the view or code editing while the system ensures consistency between both spaces. We also detail a proof-of-concept implementation using a modified version of OpenSCAD.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01843",
        "abstract url": "https://arxiv.org/abs/2408.01843",
        "title": "Supervised Image Translation from Visible to Infrared Domain for Object Detection",
        "rating": "-1",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study aims to learn a translation from visible to infrared imagery, bridging the domain gap between the two modalities so as to improve accuracy on downstream tasks including object detection. Previous approaches attempt to perform bi-domain feature fusion through iterative optimization or end-to-end deep convolutional networks. However, we pose the problem as similar to that of image translation, adopting a two-stage training strategy with a Generative Adversarial Network and an object detection model. The translation model learns a conversion that preserves the structural detail of visible images while preserving the texture and other characteristics of infrared images. Images so generated are used to train standard object detection frameworks including Yolov5, Mask and Faster RCNN. We also investigate the usefulness of integrating a super-resolution step into our pipeline to further improve model accuracy, and achieve an improvement of as high as 5.3% mAP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01850",
        "abstract url": "https://arxiv.org/abs/2408.01850",
        "title": "MotionTrace: IMU-based Field of View Prediction for Smartphone AR Interactions",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "For handheld smartphone AR interactions, bandwidth is a critical constraint. Streaming techniques have been developed to provide a seamless and high-quality user experience despite these challenges. To optimize streaming performance in smartphone-based AR, accurate prediction of the user's field of view is essential. This prediction allows the system to prioritize loading digital content that the user is likely to engage with, enhancing the overall interactivity and immersion of the AR experience. In this paper, we present MotionTrace, a method for predicting the user's field of view using a smartphone's inertial sensor. This method continuously estimates the user's hand position in 3D-space to localize the phone position. We evaluated MotionTrace over future hand positions at 50, 100, 200, 400, and 800ms time horizons using the large motion capture (AMASS) and smartphone-based full-body pose estimation (Pose-on-the-Go) datasets. We found that our method can estimate the future phone position of the user with an average MSE between 0.11 - 143.62 mm across different time horizons.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted to IEEE International Conference on Wearable and Implantable Body Sensor Networks (BSN 2024)"
    },
    {
        "paper id": "2408.01852",
        "abstract url": "https://arxiv.org/abs/2408.01852",
        "title": "S\u00f3lo Esc\u00fachame: Spanish Emotional Accompaniment Chatbot",
        "rating": "-1",
        "keywords": [
            [
                "Health",
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "According to the World Health Organization (WHO), suicide was the fourth leading cause of death in the world for individuals aged 15 to 29 in 2019. Given the rapid increase in mental health issues, providing psychological support is both crucial and urgent. In this paper: (1) we propose S\u00f3lo Esc\u00fachame, the first open-source Spanish emotional assistance chatbot, based on LLaMA-2-7b-Chat. (2) We introduced the HEAR (Hispanic Emotional Accompaniment Responses) dataset, compiled from multiple English sources translated into Spanish, as well as generic data generated using ChatGPT-3.5-Turbo. Finally, (3) we propose an evaluation metric based on two semi-automatic assessment methods. Our system outperforms a range of state-of-the-art models in providing psychological assistance in Spanish. Our models and datasets are publicly available to facilitate reproducibility.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at the 23rd Mexican International Conference on Artificial Intelligence (MICAI) 2024"
    },
    {
        "paper id": "2408.01867",
        "abstract url": "https://arxiv.org/abs/2408.01867",
        "title": "TrustNavGPT: Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation",
        "rating": "-1",
        "keywords": [
            [
                "Robot",
                "Navigation"
            ]
        ],
        "abstract": "While LLMs are proficient at processing text in human conversations, they often encounter difficulties with the nuances of verbal instructions and, thus, remain prone to hallucinate trust in human command. In this work, we present TrustNavGPT, an LLM based audio guided navigation agent that uses affective cues in spoken communication elements such as tone and inflection that convey meaning beyond words, allowing it to assess the trustworthiness of human commands and make effective, safe decisions. Our approach provides a lightweight yet effective approach that extends existing LLMs to model audio vocal features embedded in the voice command and model uncertainty for safe robotic navigation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01869",
        "abstract url": "https://arxiv.org/abs/2408.01869",
        "title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In the era of Large Language Models (LLMs), given their remarkable text understanding and generation abilities, there is an unprecedented opportunity to develop new, LLM-based methods for trustworthy medical knowledge synthesis, extraction and summarization. This paper focuses on the problem of Pharmacovigilance (PhV), where the significance and challenges lie in identifying Adverse Drug Events (ADEs) from diverse text sources, such as medical literature, clinical notes, and drug labels. Unfortunately, this task is hindered by factors including variations in the terminologies of drugs and outcomes, and ADE descriptions often being buried in large amounts of narrative text. We present MALADE, the first effective collaborative multi-agent system powered by LLM with Retrieval Augmented Generation for ADE extraction from drug label data. This technique involves augmenting a query to an LLM with relevant information extracted from text resources, and instructing the LLM to compose a response consistent with the augmented data. MALADE is a general LLM-agnostic architecture, and its unique capabilities are: (1) leveraging a variety of external sources, such as medical literature, drug labels, and FDA tools (e.g., OpenFDA drug information API), (2) extracting drug-outcome association in a structured format along with the strength of the association, and (3) providing explanations for established associations. Instantiated with GPT-4 Turbo or GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our implementation leverages the Langroid multi-agent LLM framework and can be found at https://github.com/jihyechoi77/malade.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG",
            "cs.MA",
            "q-bio.QM"
        ],
        "comment": "Paper published at Machine Learning for Healthcare 2024 (MLHC'24)"
    },
    {
        "paper id": "2408.01897",
        "abstract url": "https://arxiv.org/abs/2408.01897",
        "title": "CAF-YOLO: A Robust Framework for Multi-Scale Lesion Detection in Biomedical Imagery",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical",
                "medical",
                "Lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Object detection is of paramount importance in biomedical image analysis, particularly for lesion identification. While current methodologies are proficient in identifying and pinpointing lesions, they often lack the precision needed to detect minute biomedical entities (e.g., abnormal cells, lung nodules smaller than 3 mm), which are critical in blood and lung pathology. To address this challenge, we propose CAF-YOLO, based on the YOLOv8 architecture, a nimble yet robust method for medical object detection that leverages the strengths of convolutional neural networks (CNNs) and transformers. To overcome the limitation of convolutional kernels, which have a constrained capacity to interact with distant information, we introduce an attention and convolution fusion module (ACFM). This module enhances the modeling of both global and local features, enabling the capture of long-term feature dependencies and spatial autocorrelation. Additionally, to improve the restricted single-scale feature aggregation inherent in feed-forward networks (FFN) within transformer architectures, we design a multi-scale neural network (MSNN). This network improves multi-scale information aggregation by extracting features across diverse scales. Experimental evaluations on widely used datasets, such as BCCD and LUNA16, validate the rationale and efficacy of CAF-YOLO. This methodology excels in detecting and precisely locating diverse and intricate micro-lesions within biomedical imagery. Our codes are available at https://github.com/xiaochen925/CAF-YOLO.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01902",
        "abstract url": "https://arxiv.org/abs/2408.01902",
        "title": "A Comprehensive Survey on GNN Characterization",
        "rating": "-1",
        "keywords": [
            [
                "GNN",
                "graph"
            ]
        ],
        "abstract": "Characterizing graph neural networks (GNNs) is essential for identifying performance bottlenecks and facilitating their deployment. Despite substantial work in this area, a comprehensive survey on GNN characterization is lacking. This work presents a comprehensive survey, proposing a triple-level classification method to categorize, summarize, and compare existing efforts. In addition, we identify promising future directions for GNN characterization. Our survey aims to help scholars systematically understand GNN performance bottlenecks and patterns from a computer architecture perspective, contributing to more efficient GNN execution.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01929",
        "abstract url": "https://arxiv.org/abs/2408.01929",
        "title": "Advancing H&E-to-IHC Stain Translation in Breast Cancer: A Multi-Magnification and Attention-Based Approach",
        "rating": "-1",
        "keywords": [
            [
                "biomarkers",
                "healthcare",
                "Cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Breast cancer presents a significant healthcare challenge globally, demanding precise diagnostics and effective treatment strategies, where histopathological examination of Hematoxylin and Eosin (H&E) stained tissue sections plays a central role. Despite its importance, evaluating specific biomarkers like Human Epidermal Growth Factor Receptor 2 (HER2) for personalized treatment remains constrained by the resource-intensive nature of Immunohistochemistry (IHC). Recent strides in deep learning, particularly in image-to-image translation, offer promise in synthesizing IHC-HER2 slides from H\\&E stained slides. However, existing methodologies encounter challenges, including managing multiple magnifications in pathology images and insufficient focus on crucial information during translation. To address these issues, we propose a novel model integrating attention mechanisms and multi-magnification information processing. Our model employs a multi-magnification processing strategy to extract and utilize information from various magnifications within pathology images, facilitating robust image translation. Additionally, an attention module within the generative network prioritizes critical information for image distribution translation while minimizing less pertinent details. Rigorous testing on a publicly available breast cancer dataset demonstrates superior performance compared to existing methods, establishing our model as a state-of-the-art solution in advancing pathology image translation from H&E to IHC staining.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted by IEEE CIS-RAM 2024 Invited Session Oral"
    },
    {
        "paper id": "2408.01725",
        "abstract url": "https://arxiv.org/abs/2408.01725",
        "title": "The Drama Machine: Simulating Character Development with LLM Agents",
        "rating": "-1.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper explores use of multiple large language model (LLM) agents to simulate complex, dynamic characters in dramatic scenarios. We introduce a `drama machine' framework that coordinates interactions between LLM agents playing different `Ego' and `Superego' psychological roles. In roleplay simulations, this design allows intersubjective dialogue and intra-subjective internal monologue to develop in parallel. We apply this framework to two dramatic scenarios - an interview and a detective story - and compare character development with and without the Superego's influence. Though exploratory, results suggest this multi-agent approach can produce more nuanced, adaptive narratives that evolve over a sequence of dialogical turns. We discuss different modalities of LLM-based roleplay and character development, along with what this might mean for conceptualization of AI subjectivity. The paper concludes by considering how this approach opens possibilities for thinking of the roles of internal conflict and social performativity in AI-based simulation.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "28 pages, 2 figures"
    },
    {
        "paper id": "2408.01829",
        "abstract url": "https://arxiv.org/abs/2408.01829",
        "title": "Neural Network Emulator for Atmospheric Chemical ODE",
        "rating": "-1.5",
        "keywords": [
            [
                "chemistry",
                "Chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modeling atmospheric chemistry is complex and computationally intense. Given the recent success of Deep neural networks in digital signal processing, we propose a Neural Network Emulator for fast chemical concentration modeling. We consider atmospheric chemistry as a time-dependent Ordinary Differential Equation. To extract the hidden correlations between initial states and future time evolution, we propose ChemNNE, an Attention based Neural Network Emulator (NNE) that can model the atmospheric chemistry as a neural ODE process. To efficiently simulate the chemical changes, we propose the sinusoidal time embedding to estimate the oscillating tendency over time. More importantly, we use the Fourier neural operator to model the ODE process for efficient computation. We also propose three physical-informed losses to supervise the training optimization. To evaluate our model, we propose a large-scale chemical dataset that can be used for neural network training and evaluation. The extensive experiments show that our approach achieves state-of-the-art performance in modeling accuracy and computational speed.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph",
            "physics.chem-ph"
        ],
        "comment": "25 pages, 8 figures"
    },
    {
        "paper id": "2408.01851",
        "abstract url": "https://arxiv.org/abs/2408.01851",
        "title": "Cost-constrained multi-label group feature selection using shadow features",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider the problem of feature selection in multi-label classification, considering the costs assigned to groups of features. In this task, the goal is to select a subset of features that will be useful for predicting the label vector, but at the same time, the cost associated with the selected features will not exceed the assumed budget. Solving the problem is of great importance in medicine, where we may be interested in predicting various diseases based on groups of features. The groups may be associated with parameters obtained from a certain diagnostic test, such as a blood test. Because diagnostic test costs can be very high, considering cost information when selecting relevant features becomes crucial to reducing the cost of making predictions. We focus on the feature selection method based on information theory. The proposed method consists of two steps. First, we select features sequentially while maximizing conditional mutual information until the budget is exhausted. In the second step, we select additional cost-free features, i.e., those coming from groups that have already been used in previous steps. Limiting the number of added features is possible using the stop rule based on the concept of so-called shadow features, which are randomized counterparts of the original ones. In contrast to existing approaches based on penalized criteria, in our method, we avoid the need for computationally demanding optimization of the penalty parameter. Experiments conducted on the MIMIC medical database show the effectiveness of the method, especially when the assumed budget is limited.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01668",
        "abstract url": "https://arxiv.org/abs/2408.01668",
        "title": "Multiple Contexts and Frequencies Aggregation Network forDeepfake Detection",
        "rating": "-2",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "facial",
                "organ"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deepfake detection faces increasing challenges since the fast growth of generative models in developing massive and diverse Deepfake technologies. Recent advances rely on introducing heuristic features from spatial or frequency domains rather than modeling general forgery features within backbones. To address this issue, we turn to the backbone design with two intuitive priors from spatial and frequency detectors, \\textit{i.e.,} learning robust spatial attributes and frequency distributions that are discriminative for real and fake samples. To this end, we propose an efficient network for face forgery detection named MkfaNet, which consists of two core modules. For spatial contexts, we design a Multi-Kernel Aggregator that adaptively selects organ features extracted by multiple convolutions for modeling subtle facial differences between real and fake faces. For the frequency components, we propose a Multi-Frequency Aggregator to process different bands of frequency components by adaptively reweighing high-frequency and low-frequency features. Comprehensive experiments on seven popular deepfake detection benchmarks demonstrate that our proposed MkfaNet variants achieve superior performances in both within-domain and across-domain evaluations with impressive efficiency of parameter usage.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01679",
        "abstract url": "https://arxiv.org/abs/2408.01679",
        "title": "MMPKUBase: A Comprehensive and High-quality Chinese Multi-modal Knowledge Graph",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multi-modal knowledge graphs have emerged as a powerful approach for information representation, combining data from different modalities such as text, images, and videos. While several such graphs have been constructed and have played important roles in applications like visual question answering and recommendation systems, challenges persist in their development. These include the scarcity of high-quality Chinese knowledge graphs and limited domain coverage in existing multi-modal knowledge graphs. This paper introduces MMPKUBase, a robust and extensive Chinese multi-modal knowledge graph that covers diverse domains, including birds, mammals, ferns, and more, comprising over 50,000 entities and over 1 million filtered images. To ensure data quality, we employ Prototypical Contrastive Learning and the Isolation Forest algorithm to refine the image data. Additionally, we have developed a user-friendly platform to facilitate image attribute exploration.",
        "subjects": [
            "cs.CL",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01732",
        "abstract url": "https://arxiv.org/abs/2408.01732",
        "title": "Landmark-guided Diffusion Model for High-fidelity and Temporally Coherent Talking Head Generation",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "GAN"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Audio-driven talking head generation is a significant and challenging task applicable to various fields such as virtual avatars, film production, and online conferences. However, the existing GAN-based models emphasize generating well-synchronized lip shapes but overlook the visual quality of generated frames, while diffusion-based models prioritize generating high-quality frames but neglect lip shape matching, resulting in jittery mouth movements. To address the aforementioned problems, we introduce a two-stage diffusion-based model. The first stage involves generating synchronized facial landmarks based on the given speech. In the second stage, these generated landmarks serve as a condition in the denoising process, aiming to optimize mouth jitter issues and generate high-fidelity, well-synchronized, and temporally coherent talking head videos. Extensive experiments demonstrate that our model yields the best performance.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01796",
        "abstract url": "https://arxiv.org/abs/2408.01796",
        "title": "Understanding the Challenges of OpenSCAD Users for 3D Printing",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Direct manipulation has been established as the main interaction paradigm for Computer-Aided Design (CAD) for decades. It provides fast, incremental, and reversible actions that allow for an iterative process on a visual representation of the result. Despite its numerous advantages, some users prefer a programming-based approach where they describe the 3D model they design with a specific programming language, such as OpenSCAD. It allows users to create complex structured geometries and facilitates abstraction. Unfortunately, most current knowledge about CAD practices only focuses on direct manipulation programs. In this study, we interviewed 20 programming-based CAD users to understand their motivations and challenges. Our findings reveal that this programming-oriented population presents difficulties in the design process in tasks such as 3D spatial understanding, validation and code debugging, creation of organic shapes, and code-view navigation.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01807",
        "abstract url": "https://arxiv.org/abs/2408.01807",
        "title": "Novel rotor fault diagnostic method based on rlmd and ht techniques",
        "rating": "-2",
        "keywords": [
            [
                "diagnosing"
            ]
        ],
        "abstract": "Frequency domain analysis using the Fast Fourier transform (FFT) has been a popular method for diagnosing broken rotor bar (BRB) faults in squirrel-cage induction motors (IM). However, FFT analysis is limited by sampling frequency and time acquisition constraints, making it less effective under time-varying conditions. To overcome these difficulties, a novel BRB fault detection method for non-stationary conditions is proposed. The proposed strategy is based on the recently developed robust local mean decomposition (RLMD) and Hilbert transform (HT) methods. Using these techniques, the BRB characteristic frequency and amplitude component are obtained from only one phase stator current allowing automation of the features detection process. in fact, HT is used to extract the stator current envelope (SCE). Then, the SCE is processed by RLMD for determining the sub signals production functions (PFs). Finally, HT is applied to the most sensible PF to compute its instantaneous frequency and amplitude. The tracking of the BRB fault characteristic can inform us about the condition of the induction motor. The effectiveness of the proposed diagnostic strategy is validated through simulation conducted in the Matlab environment. The simulation results show the capability of this method to track accurately the frequency and amplitude of the 2sf component where f and s represent the fundamental stator current frequency and motor slip respectively",
        "subjects": [
            "eess.SP"
        ],
        "comment": "10th International Conference on Computer Science and Information Technology (CSTY 2024), July 20 ~ 21, 2024, Toronto, Canada"
    },
    {
        "paper id": "2408.01808",
        "abstract url": "https://arxiv.org/abs/2408.01808",
        "title": "ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features",
        "rating": "-2",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "text-to-speech"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Extensive research has revealed that adversarial examples (AE) pose a significant threat to voice-controllable smart devices. Recent studies have proposed black-box adversarial attacks that require only the final transcription from an automatic speech recognition (ASR) system. However, these attacks typically involve many queries to the ASR, resulting in substantial costs. Moreover, AE-based adversarial audio samples are susceptible to ASR updates. In this paper, we identify the root cause of these limitations, namely the inability to construct AE attack samples directly around the decision boundary of deep learning (DL) models. Building on this observation, we propose ALIF, the first black-box adversarial linguistic feature-based attack pipeline. We leverage the reciprocal process of text-to-speech (TTS) and ASR models to generate perturbations in the linguistic embedding space where the decision boundary resides. Based on the ALIF pipeline, we present the ALIF-OTL and ALIF-OTA schemes for launching attacks in both the digital domain and the physical playback environment on four commercial ASRs and voice assistants. Extensive evaluations demonstrate that ALIF-OTL and -OTA significantly improve query efficiency by 97.7% and 73.3%, respectively, while achieving competitive performance compared to existing methods. Notably, ALIF-OTL can generate an attack sample with only one query. Furthermore, our test-of-time experiment validates the robustness of our approach against ASR updates.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Published in the 2024 IEEE Symposium on Security and Privacy (SP)"
    },
    {
        "paper id": "2408.01812",
        "abstract url": "https://arxiv.org/abs/2408.01812",
        "title": "SkyDiffusion: Street-to-Satellite Image Synthesis with Diffusion Models and BEV Paradigm",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Satellite",
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Street-to-satellite image synthesis focuses on generating realistic satellite images from corresponding ground street-view images while maintaining a consistent content layout, similar to looking down from the sky. The significant differences in perspectives create a substantial domain gap between the views, making this cross-view generation task particularly challenging. In this paper, we introduce SkyDiffusion, a novel cross-view generation method for synthesizing satellite images from street-view images, leveraging diffusion models and Bird's Eye View (BEV) paradigm. First, we design a Curved-BEV method to transform street-view images to the satellite view, reformulating the challenging cross-domain image synthesis task into a conditional generation problem. Curved-BEV also includes a \"Multi-to-One\" mapping strategy for combining multiple street-view images within the same satellite coverage area, effectively solving the occlusion issues in dense urban scenes. Next, we design a BEV-controlled diffusion model to generate satellite images consistent with the street-view content, which also incorporates a light manipulation module to optimize the lighting condition of the synthesized image using a reference satellite. Experimental results demonstrate that SkyDiffusion outperforms state-of-the-art methods on both suburban (CVUSA & CVACT) and urban (VIGOR-Chicago) cross-view datasets, with an average SSIM increase of 14.5% and a FID reduction of 29.6%, achieving realistic and content-consistent satellite image generation. The code and models of this work will be released at https://opendatalab.github.io/skydiffusion/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 8 figures"
    },
    {
        "paper id": "2408.01855",
        "abstract url": "https://arxiv.org/abs/2408.01855",
        "title": "MoodPupilar: Predicting Mood Through Smartphone Detected Pupillary Responses in Naturalistic Settings",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "MoodPupilar introduces a novel method for mood evaluation using pupillary response captured by a smartphone's front-facing camera during daily use. Over a four-week period, data was gathered from 25 participants to develop models capable of predicting daily mood averages. Utilizing the GLOBEM behavior modeling platform, we benchmarked the utility of pupillary response as a predictor for mood. Our proposed model demonstrated a Matthew's Correlation Coefficient (MCC) score of 0.15 for Valence and 0.12 for Arousal, which is on par with or exceeds those achieved by existing behavioral modeling algorithms supported by GLOBEM. This capability to accurately predict mood trends underscores the effectiveness of pupillary response data in providing crucial insights for timely mental health interventions and resource allocation. The outcomes are encouraging, demonstrating the potential of real-time and predictive mood analysis to support mental health interventions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted to IEEE International Conference on Wearable and Implantable Body Sensor Networks (BSN 2024)"
    },
    {
        "paper id": "2408.01885",
        "abstract url": "https://arxiv.org/abs/2408.01885",
        "title": "Channel-Aware Distributed Transmission Control and Video Streaming in UAV Networks",
        "rating": "-2",
        "keywords": [
            [
                "UAV"
            ]
        ],
        "abstract": "In this paper, we study the problem of distributed transmission control and video streaming optimization for unmanned aerial vehicles (UAVs) operating in unlicensed spectrum bands. We develop a rigorous cross-layer analysis framework that jointly considers three inter-dependent factors: (i) in-band interference introduced by ground/aerial nodes at the physical (PHY) layer, (ii) limited-size queues with delay-constrained packet arrival at the medium access control (MAC) layer, and (iii) video encoding rate at the application layer. First, we formulate an optimization problem to maximize the throughput by optimizing the fading threshold. To this end, we jointly analyze the queue-related packet loss probabilities (i.e., buffer overflow and time threshold event) as well as the outage probability due to the low signal-to-interference-plus-noise ratio (SINR). We introduce the Distributed Transmission Control (DTC) algorithm that maximizes the throughput by adjusting transmission policies to balance the trade-offs between packet drop from queues vs. transmission errors due to low SINRs. Second, we incorporate the video distortion model to develop distributed peak signal-to-noise ratio (PSNR) optimization for video streaming. The formulated optimization incorporates two cross-layer parameters, specifically the fading threshold and video encoding rate. To tackle this problem, we develop the Joint Distributed Video Transmission and Encoder Control (JDVT-EC) algorithm that enhances the PSNR for all nodes by fine-tuning transmission policies and video encoding rates to balance the trade-offs between packet loss and lossy video compression distortions. Through extensive numerical analysis, we thoroughly examine the proposed algorithms and demonstrate that they are able to find the optimal transmission policies and video encoding rates under various scenarios.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Submitted to IEEE Transactions on Communications"
    },
    {
        "paper id": "2408.01908",
        "abstract url": "https://arxiv.org/abs/2408.01908",
        "title": "Public Transit of the Future: Enhancing Well-Being through Designing Human-centered Public Transportation Spaces",
        "rating": "-2",
        "keywords": [
            [
                "biophilic",
                "psychological"
            ]
        ],
        "abstract": "Studies show that psychological effects are among one of the top concerns for public transportation users. While many Americans spend a significant portion of their time in public transportation spaces, the impact of the design and maintenance of these spaces on user well-being has not been fully studied. In this study, we conducted a survey to better understand the effect of implementing different designs on people's well-being and perceptual metrics (N=304). Participants were presented with six images depicting different cabin configurations, including (1) the current version of the cabin space, (2) a low-maintenance version, (3) an aesthetically enhanced version, (4) a bike rack-enabled version, (5) a version with an added workspace, and (6) an improved version with biophilic design. After viewing each image, participants' well-being metrics (e.g., stress, and emotion) and their public transportation perception metrics (e.g., perceptions of safety, and reasonable cost) were evaluated. Our results from linear mixed-effect modeling indicated that adding functional amenities and biophilic design elements led to an overall enhancement in well-being and perceptual metrics. Conversely, low maintenance worsened all measured well-being. This research lays the ground for developing human-centered public transportation spaces that can lead to an increase in public transportation adoption.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01672",
        "abstract url": "https://arxiv.org/abs/2408.01672",
        "title": "radarODE: An ODE-Embedded Deep Learning Model for Contactless ECG Reconstruction from Millimeter-Wave Radar",
        "rating": "-2.5",
        "keywords": [
            [
                "Radar"
            ],
            [
                "cardiac"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Radar-based contactless cardiac monitoring has become a popular research direction recently, but the fine-grained electrocardiogram (ECG) signal is still hard to reconstruct from millimeter-wave radar signal. The key obstacle is to decouple the cardiac activities in the electrical domain (i.e., ECG) from that in the mechanical domain (i.e., heartbeat), and most existing research only uses pure data-driven methods to map such domain transformation as a black box. Therefore, this work first proposes a signal model for domain transformation, and then a novel deep learning framework called radarODE is designed to fuse the temporal and morphological features extracted from radar signals and generate ECG. In addition, ordinary differential equations are embedded in radarODE as a decoder to provide morphological prior, helping the convergence of the model training and improving the robustness under body movements. After being validated on the dataset, the proposed radarODE achieves better performance compared with the benchmark in terms of missed detection rate, root mean square error, Pearson correlation coefficient with the improvement of 9%, 16% and 19%, respectively. The validation results imply that radarODE is capable of recovering ECG signals from radar signals with high fidelity and can be potentially implemented in real-life scenarios.",
        "subjects": [
            "eess.SP",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.02691",
        "abstract url": "https://arxiv.org/abs/2408.02691",
        "title": "Symmetric Graph Contrastive Learning against Noisy Views for Recommendation",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph Contrastive Learning (GCL) leverages data augmentation techniques to produce contrasting views, enhancing the accuracy of recommendation systems through learning the consistency between contrastive views. However, existing augmentation methods, such as directly perturbing interaction graph (e.g., node/edge dropout), may interfere with the original connections and generate poor contrasting views, resulting in sub-optimal performance. In this paper, we define the views that share only a small amount of information with the original graph due to poor data augmentation as noisy views (i.e., the last 20% of the views with a cosine similarity value less than 0.1 to the original view). We demonstrate through detailed experiments that noisy views will significantly degrade recommendation performance. Further, we propose a model-agnostic Symmetric Graph Contrastive Learning (SGCL) method with theoretical guarantees to address this issue. Specifically, we introduce symmetry theory into graph contrastive learning, based on which we propose a symmetric form and contrast loss resistant to noisy interference. We provide theoretical proof that our proposed SGCL method has a high tolerance to noisy views. Further demonstration is given by conducting extensive experiments on three real-world datasets. The experimental results demonstrate that our approach substantially increases recommendation accuracy, with relative improvements reaching as high as 12.25% over nine other competing models. These results highlight the efficacy of our method.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "24 pages, submitted to TOIS"
    },
    {
        "paper id": "2408.01680",
        "abstract url": "https://arxiv.org/abs/2408.01680",
        "title": "Service Placement and Trajectory Design for Heterogeneous Tasks in Multi-UAV Cooperative Computing Networks",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this paper, we consider deploying multiple Unmanned Aerial Vehicles (UAVs) to enhance the computation service of Mobile Edge Computing (MEC) through collaborative computation among UAVs. In particular, the tasks of different types and service requirements in MEC network are offloaded from one UAV to another. To pursue the goal of low-carbon edge computing, we study the problem of minimizing system energy consumption by jointly optimizing computation resource allocation, task scheduling, service placement, and UAV trajectories. Considering the inherent unpredictability associated with task generation and the dynamic nature of wireless fading channels, addressing this problem presents a significant challenge. To overcome this issue, we reformulate the complicated non-convex problem as a Markov decision process and propose a soft actor-critic-based trajectory optimization and resource allocation algorithm to implement a flexible learning strategy. Numerical results illustrate that within a multi-UAV-enabled MEC network, the proposed algorithm effectively reduces the system energy consumption in heterogeneous tasks and services scenarios compared to other baseline solutions.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "11 pages, 10 figures"
    },
    {
        "paper id": "2408.01716",
        "abstract url": "https://arxiv.org/abs/2408.01716",
        "title": "Visual-Inertial SLAM for Agricultural Robotics: Benchmarking the Benefits and Computational Costs of Loop Closing",
        "rating": "-3",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "Robotics",
                "navigation"
            ],
            [
                "Agricultural"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Simultaneous Localization and Mapping (SLAM) is essential for mobile robotics, enabling autonomous navigation in dynamic, unstructured outdoor environments without relying on external positioning systems. In agricultural applications, where environmental conditions can be particularly challenging due to variable lighting or weather conditions, Visual-Inertial SLAM has emerged as a potential solution. This paper benchmarks several open-source Visual-Inertial SLAM systems, including ORB-SLAM3, VINS-Fusion, OpenVINS, Kimera, and SVO Pro, to evaluate their performance in agricultural settings. We focus on the impact of loop closing on localization accuracy and computational demands, providing a comprehensive analysis of these systems' effectiveness in real-world environments and especially their application to embedded systems in agricultural robotics. Our contributions further include an assessment of varying frame rates on localization accuracy and computational load. The findings highlight the importance of loop closing in improving localization accuracy while managing computational resources efficiently, offering valuable insights for optimizing Visual-Inertial SLAM systems for practical outdoor applications in mobile robotics.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "18 pages, 8 figures, 5 tables"
    },
    {
        "paper id": "2408.01729",
        "abstract url": "https://arxiv.org/abs/2408.01729",
        "title": "A Survey on Robotic Prosthetics: Neuroprosthetics, Soft Actuators, and Control Strategies",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "Chemistry"
            ]
        ],
        "abstract": "The field of robotics is a quickly evolving feat of technology that accepts contributions from various genres of science. Neuroscience, Physiology, Chemistry, Material science, Computer science, and the wide umbrella of mechatronics have all simultaneously contributed to many innovations in the prosthetic applications of robotics. This review begins with a discussion of the scope of the term robotic prosthetics and discusses the evolving domain of Neuroprosthetics. The discussion is then constrained to focus on various actuation and control strategies for robotic prosthetic limbs. This review discusses various soft robotic actuators such as EAP, SMA, FFA, etc., and the merits of such actuators over conventional hard robotic actuators. Options in control strategies for robotic prosthetics, that are in various states of research and development, are reviewed. This paper concludes the discussion with an analysis regarding the prospective direction in which this field of robotic prosthetics is evolving in terms of actuation, control, and other features relevant to artificial limbs. This paper intends to review some of the emerging research and development trends in the field of robotic prosthetics and summarize many tangents that are represented under this broad domain in an approachable manner.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01737",
        "abstract url": "https://arxiv.org/abs/2408.01737",
        "title": "Real-time Localization and Mapping in Architectural Plans with Deviations",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "robot"
            ],
            [
                "Graphs"
            ]
        ],
        "abstract": "Having prior knowledge of an environment boosts the localization and mapping accuracy of robots. Several approaches in the literature have utilized architectural plans in this regard. However, almost all of them overlook the deviations between actual as-built environments and as-planned architectural designs, introducing bias in the estimations. To address this issue, we present a novel localization and mapping method denoted as deviations-informed Situational Graphs or diS-Graphs that integrates prior knowledge from architectural plans even in the presence of deviations. It is based on Situational Graphs (S-Graphs) that merge geometric models of the environment with 3D scene graphs into a multi-layered jointly optimizable factor graph. Our diS-Graph extracts information from architectural plans by first modeling them as a hierarchical factor graph, which we will call an Architectural Graph (A-Graph). While the robot explores the real environment, it estimates an S-Graph from its onboard sensors. We then use a novel matching algorithm to register the A-Graph and S-Graph in the same reference, and merge both of them with an explicit model of deviations. Finally, an alternating graph optimization strategy allows simultaneous global localization and mapping, as well as deviation estimation between both the A-Graph and the S-Graph. We perform several experiments in simulated and real datasets in the presence of deviations. On average, our diS-Graphs outperforms the baselines by a margin of approximately 43% in simulated environments and by 7% in real environments, while being able to estimate deviations up to 35 cm and 15 degrees.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01841",
        "abstract url": "https://arxiv.org/abs/2408.01841",
        "title": "BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles",
        "rating": "-3",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "BEV"
            ]
        ],
        "abstract": "This article introduces BEVPlace++, a novel, fast, and robust LiDAR global localization method for unmanned ground vehicles. It uses lightweight convolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like representations of LiDAR data to achieve accurate global localization through place recognition followed by 3-DoF pose estimation. Our detailed analyses reveal an interesting fact that CNNs are inherently effective at extracting distinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV images with large translations can be effectively matched using CNN-extracted features. Building on this insight, we design a rotation equivariant module (REM) to obtain distinctive features while enhancing robustness to rotational changes. A Rotation Equivariant and Invariant Network (REIN) is then developed by cascading REM and a descriptor generator, NetVLAD, to sequentially generate rotation equivariant local features and rotation invariant global descriptors. The global descriptors are used first to achieve robust place recognition, and the local features are used for accurate pose estimation. Experimental results on multiple public datasets demonstrate that BEVPlace++, even when trained on a small dataset (3000 frames of KITTI) only with place labels, generalizes well to unseen environments, performs consistently across different days and years, and adapts to various types of LiDAR scanners. BEVPlace++ achieves state-of-the-art performance in subtasks of global localization including place recognition, loop closure detection, and global localization. Additionally, BEVPlace++ is lightweight, runs in real-time, and does not require accurate pose supervision, making it highly convenient for deployment. The source codes are publicly available at \\href{https://github.com/zjuluolun/BEVPlace}{https://github.com/zjuluolun/BEVPlace}.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2408.01883",
        "abstract url": "https://arxiv.org/abs/2408.01883",
        "title": "Impact of Major Health Events on Pharmaceutical Stocks: A Comprehensive Analysis Using Macroeconomic and Market Indicators",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Health"
            ]
        ],
        "abstract": "This study investigates the impact of significant health events on pharmaceutical stock performance, employing a comprehensive analysis incorporating macroeconomic and market indicators. Using Ordinary Least Squares (OLS) regression, we evaluate the effects of thirteen major health events since 2000, including the Anthrax attacks, SARS outbreak, H1N1 pandemic, and COVID-19 pandemic, on the pharmaceutical sector. The analysis covers different phases of each event beginning, peak, and ending to capture their temporal influence on stock prices. Our findings reveal distinct patterns in stock performance, driven by market reactions to the initial news, peak impact, and eventual resolution of these crises. We also examine scenarios with and without key macroeconomic (MA) and market (MI) indicators to isolate their contributions. This detailed examination provides valuable insights for investors, policymakers, and stakeholders in understanding the interplay between major health events and health market dynamics, guiding better decision-making during future health related disruptions.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "17 pages, 5 figures, under review"
    },
    {
        "paper id": "2408.01676",
        "abstract url": "https://arxiv.org/abs/2408.01676",
        "title": "Prototyping of a multirotor UAV for precision landing under rotor failures",
        "rating": "-4",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "navigation"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "This work presents a prototype of a multirotor aerial vehicle capable of precision landing, even under the effects of rotor failures. The manuscript presents the fault-tolerant techniques and mechanical designs to achieve a fault-tolerant multirotor, and a vision-based navigation system required to achieve a precision landing. Preliminary experimental results will be shown, to validate on one hand the fault-tolerant control vehicle and, on the other hand, the autonomous landing algorithm. Also, a prototype of the fault-tolerant UAV is presented, capable of precise autonomous landing, which will be used in future experiments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01826",
        "abstract url": "https://arxiv.org/abs/2408.01826",
        "title": "GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent Diffusion Transformer",
        "rating": "-6",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "Graph"
            ],
            [
                "Facial"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D speech-driven facial animation generation has received much attention in both industrial applications and academic research. Since the non-verbal facial cues that exist across the face in reality are non-deterministic, the generated results should be diverse. However, most recent methods are deterministic models that cannot learn a many-to-many mapping between audio and facial motion to generate diverse facial animations. To address this problem, we propose GLDiTalker, which introduces a motion prior along with some stochasticity to reduce the uncertainty of cross-modal mapping while increasing non-determinacy of the non-verbal facial cues that reside throughout the face. Particularly, GLDiTalker uses VQ-VAE to map facial motion mesh sequences into latent space in the first stage, and then iteratively adds and removes noise to the latent facial motion features in the second stage. In order to integrate different levels of spatial information, the Spatial Pyramidal SpiralConv Encoder is also designed to extract multi-scale features. Extensive qualitative and quantitative experiments demonstrate that our method achieves the state-of-the-art performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2408.01667",
        "abstract url": "https://arxiv.org/abs/2408.01667",
        "title": "Automated Phishing Detection Using URLs and Webpages",
        "rating": "-10",
        "keywords": [],
        "abstract": "Phishing detection is a critical cybersecurity task that involves the identification and neutralization of fraudulent attempts to obtain sensitive information, thereby safeguarding individuals and organizations from data breaches and financial loss. In this project, we address the constraints of traditional reference-based phishing detection by developing an LLM agent framework. This agent harnesses Large Language Models to actively fetch and utilize online information, thus providing a dynamic reference system for more accurate phishing detection. This innovation circumvents the need for a static knowledge base, offering a significant enhancement in adaptability and efficiency for automated security measures. The project report includes an initial study and problem analysis of existing solutions, which motivated us to develop a new framework. We demonstrate the framework with LLMs simulated as agents and detail the techniques required for construction, followed by a complete implementation with a proof-of-concept as well as experiments to evaluate our solution's performance against other similar solutions. The results show that our approach has achieved with accuracy of 0.945, significantly outperforms the existing solution(DynaPhish) by 0.445. Furthermore, we discuss the limitations of our approach and suggest improvements that could make it more effective. Overall, the proposed framework has the potential to enhance the effectiveness of current reference-based phishing detection approaches and could be adapted for real-world applications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01684",
        "abstract url": "https://arxiv.org/abs/2408.01684",
        "title": "Near-Field Beamforming for Stacked Intelligent Metasurfaces-assisted MIMO Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Stacked intelligent metasurfaces (SIMs) have recently gained significant interest since they enable precoding in the wave domain that comes with increased processing capability and reduced energy consumption. The study of SIMs and high frequency propagation make the study of the performance in the near field of crucial importance. Hence, in this work, we focus on SIM-assisted multiuser multiple-input multiple-output (MIMO) systems operating in the near field region. To this end, we formulate the weighted sum rate maximisation problem in terms of the transmit power and the phase shifts of the SIM. By applying a block coordinate descent (BCD)-relied algorithm, numerical results show the enhanced performance of the SIM in the near field with respect to the far field.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "5 pages, accepted in IEEE WCL"
    },
    {
        "paper id": "2408.01687",
        "abstract url": "https://arxiv.org/abs/2408.01687",
        "title": "Voices from the Frontier: A Comprehensive Analysis of the OpenAI Developer Forum",
        "rating": "-10",
        "keywords": [],
        "abstract": "OpenAI's advanced large language models (LLMs) have revolutionized natural language processing and enabled developers to create innovative applications. As adoption grows, understanding the experiences and challenges of developers working with these technologies is crucial. This paper presents a comprehensive analysis of the OpenAI Developer Forum, focusing on (1) popularity trends and user engagement patterns, and (2) a taxonomy of challenges and concerns faced by developers. We first employ a quantitative analysis of the metadata from 29,576 forum topics, investigating temporal trends in topic creation, the popularity of topics across different categories, and user contributions at various trust levels. We then qualitatively analyze content from 9,301 recently active topics on developer concerns. From a sample of 886 topics, we construct a taxonomy of concerns in the OpenAI Developer Forum. Our findings uncover critical concerns raised by developers in creating AI-powered applications and offer targeted recommendations to address them. This work not only advances AI-assisted software engineering but also empowers developer communities to shape the responsible evolution and integration of AI technology in society.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01702",
        "abstract url": "https://arxiv.org/abs/2408.01702",
        "title": "Beamforming for PIN Diode-Based IRS-Assisted Systems Under a Phase Shift-Dependent Power Consumption Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "Intelligent reflecting surfaces (IRSs) have been regarded as a promising enabler for future wireless communication systems. In the literature, IRSs have been considered power-free or assumed to have constant power consumption. However, recent experimental results have shown that for positive-intrinsic-negative (PIN) diode-based IRSs, the power consumption dynamically changes with the phase shift configuration. This phase shift-dependent power consumption (PS-DPC) introduces a challenging power allocation problem between base station (BS) and IRS. To tackle this issue, in this paper, we investigate a rate maximization problem for IRS-assisted systems under a practical PS-DPC model. For the single-user case, we propose a generalized Benders decomposition-based beamforming method to maximize the achievable rate while satisfying a total system power consumption constraint. Moreover, we propose a low-complexity beamforming design, where the powers allocated to BS and IRS are optimized offline based on statistical channel state information. Furthermore, for the multi-user case, we solve an equivalent weighted mean square error minimization problem with two different joint power allocation and phase shift optimization methods. Simulation results indicate that compared to baseline schemes, our proposed methods can flexibly optimize the power allocation between BS and IRS, thus achieving better performance. The optimized power allocation strategy strongly depends on the system power budget. When the system power budget is high, the PS-DPC is not the dominant factor in the system power consumption, allowing the IRS to turn on as many PIN diodes as needed to achieve high beamforming quality. When the system power budget is limited, however, more power tends to be allocated to the BS to enhance the transmit power, resulting in a lower beamforming quality at the IRS due to the reduced PS-DPC budget.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01703",
        "abstract url": "https://arxiv.org/abs/2408.01703",
        "title": "WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language models (LLMs) support data analysis through conversational user interfaces, as exemplified in OpenAI's ChatGPT (formally known as Advanced Data Analysis or Code Interpreter). Essentially, LLMs produce code for accomplishing diverse analysis tasks. However, presenting raw code can obscure the logic and hinder user verification. To empower users with enhanced comprehension and augmented control over analysis conducted by LLMs, we propose a novel approach to transform LLM-generated code into an interactive visual representation. In the approach, users are provided with a clear, step-by-step visualization of the LLM-generated code in real time, allowing them to understand, verify, and modify individual data operations in the analysis. Our design decisions are informed by a formative study (N=8) probing into user practice and challenges. We further developed a prototype named WaitGPT and conducted a user study (N=12) to evaluate its usability and effectiveness. The findings from the user study reveal that WaitGPT facilitates monitoring and steering of data analysis performed by LLMs, enabling participants to enhance error detection and increase their overall confidence in the results.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Accepted in the 37th Annual ACM Symposium on User Interface Software and Technology (UIST'24)"
    },
    {
        "paper id": "2408.01731",
        "abstract url": "https://arxiv.org/abs/2408.01731",
        "title": "Composite Learning Adaptive Control without Excitation Condition",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper focuses on excitation collection and composite learning adaptive control design for uncertain nonlinear systems. By adopting the spectral decomposition technique, a linear regression equation is constructed to collect previously appeared excitation information, establishing a relationship between unknown parameters and the system's historical data. A composite learning term, developed using the linear regression equation, is incorporating into the Lyapunov-based parameter update law. In comparison to the existing results, all spectrums of previously appeared excitation information are collected, with the matrices in linear regression equation guaranteed to be bounded. This paper introduces concepts of excited and unexcited subspaces for analyzing the parameter estimation errors, and a novel Lyapunov function is developed for stability analysis. It is demonstrated that, without imposing any excitation condition, the state and excited parameter estimation error component converge to zero, while the unexcited component remains unchanged.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "15 pages, 13 figures"
    },
    {
        "paper id": "2408.01733",
        "abstract url": "https://arxiv.org/abs/2408.01733",
        "title": "CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent years have seen the development of LLM-based code generation. Compared to generating code in a software project, incremental code edits are empirically observed to be more frequent. The emerging code editing approaches usually formulate the problem as generating an edit based on known relevant prior edits and context. However, practical code edits can be more complicated. First, an editing session can include multiple (ir)relevant edits to the code under edit. Second, the inference of the subsequent edits is non-trivial as the scope of its ripple effect can be the whole project. In this work, we propose CoEdPilot, an LLM-driven solution to recommend code edits by discriminating the relevant edits, exploring their interactive natures, and estimating its ripple effect in the project. Specifically, CoEdPilot orchestrates multiple neural transformers to identify what and how to edit in the project regarding both edit location and edit content. When a user accomplishes an edit with an optional editing description, a Subsequent Edit Analysis first reports the most relevant files in the project with what types of edits (e.g., keep, insert, and replace) can happen for each line of their code. Next, an Edit-content Generator generates concrete edit options for the lines of code, regarding its relevant prior changes reported by an Edit-dependency Analyzer. Lastly, both the Subsequent Edit Analysis and the Edit-content Generator capture relevant prior edits as feedback to readjust their recommendations. We train our models by collecting over 180K commits from 471 open-source projects in 5 programming languages. Our extensive experiments show that CoEdPilot can well predict the edits (i.e., predicting edit location with an accuracy of 70.8%-85.3%, and the edit content with an exact match rate of 41.8% and BLEU4 score of 60.7)...",
        "subjects": [
            "cs.SE"
        ],
        "comment": "13 pages, 7 figures"
    },
    {
        "paper id": "2408.01738",
        "abstract url": "https://arxiv.org/abs/2408.01738",
        "title": "Adaptive Safety with Control BarrierFunctions and Triggered Batch Least-Squares Identifier",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a triggered Batch Least-Squares Identifier (BaLSI) based adaptive safety control scheme is proposed for uncertain systems with potentially conflicting control objectives and safety constraints. A relaxation term is added to the Quadratic Programs (QP) combining the transformed Control Lyapunov Functions (CLFs) and Control Barrier Functions (CBFs), to mediate the potential conflict. The existing Lyapunov-based adaptive schemes designed to guarantee specific properties of the Lyapunov functions, may grow unboundedly under the effects of the relaxation term. The adaptive law is designed by processing system inputs and outputs, to avoid unbounded estimates and overparameterization problems in the existing results. A safetytriggered condition is presented, based on which the forward invariant property of the safe set is shown and Zeno behavior can be excluded. Simulation results are presented to demonstrate the effectiveness of the proposed adaptive control scheme.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "11 pages, 10 fidures"
    },
    {
        "paper id": "2408.01751",
        "abstract url": "https://arxiv.org/abs/2408.01751",
        "title": "On the Rationale and Use of Assertion Messages in Test Code: Insights from Software Practitioners",
        "rating": "-10",
        "keywords": [],
        "abstract": "Unit testing is an important practice that helps ensure the quality of a software system by validating its behavior through a series of test cases. Core to these test cases are assertion statements, which enable software practitioners to validate the correctness of the system's behavior. To aid with understanding and troubleshooting test case failures, practitioners can include a message (i.e., assertion message) within the assertion statement. While prior studies have examined the frequency and structure of assertion messages by mining software repositories, they do not determine their types or purposes or how practitioners perceive the need for or the usage of various types of assertion messages. In this paper, we survey 138 professional software practitioners to gather insights into their experience and views regarding assertion messages. Our findings reveal that a majority of survey respondents find assertion messages valuable for troubleshooting failures, improving test understandability, and serving as documentation. However, not all respondents consistently include messages in their assertion methods. We also identified common considerations for constructing effective assertion messages, challenges in crafting them, maintenance techniques, and their integration into debugging processes. Our results contribute to the understanding of current practices and provide guidelines for authoring high-quality assertion messages, serving as a foundation for best practices and coding standards. Furthermore, the insights can guide the improvement of automated unit testing tools by incorporating checks for the presence and quality of assertion messages and providing real-time feedback to practitioners.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted: International Conference on Software Maintenance and Evolution (ICSME 2024); Research Track"
    },
    {
        "paper id": "2408.01753",
        "abstract url": "https://arxiv.org/abs/2408.01753",
        "title": "Opinion Dynamics with Set-Based Confidence: Convergence Criteria and Periodic Solutions",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces a new multidimensional extension of the Hegselmann-Krause (HK) opinion dynamics model, where opinion proximity is not determined by a norm or metric. Instead, each agent trusts opinions within the Minkowski sum $\u03be+\\mathcal{O}$, where $\u03be$ is the agent's current opinion and $\\mathcal{O}$ is the confidence set defining acceptable deviations. During each iteration, agents update their opinions by simultaneously averaging the trusted opinions. Unlike traditional HK systems, where $\\mathcal{O}$ is a ball in some norm, our model allows the confidence set to be non-convex and even unbounded. We demonstrate that the new model, referred to as SCOD (Set-based Confidence Opinion Dynamics), can exhibit properties absent in the conventional HK model. Some solutions may converge to non-equilibrium points in the state space, while others oscillate periodically. These ``pathologies'' disappear if the set $\\mathcal{O}$ is symmetric and contains zero in its interior: similar to the usual HK model, SCOD then converges in a finite number of iterations to one of the equilibrium points. The latter property is also preserved if one agent is \"stubborn\" and resists changing their opinion, yet still influences the others; however, two stubborn agents can lead to oscillations.",
        "subjects": [
            "cs.MA",
            "eess.SY",
            "math.DS",
            "math.OC",
            "nlin.AO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01760",
        "abstract url": "https://arxiv.org/abs/2408.01760",
        "title": "Large Language Models for Equivalent Mutant Detection: How Far Are We?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mutation testing is vital for ensuring software quality. However, the presence of equivalent mutants is known to introduce redundant cost and bias issues, hindering the effectiveness of mutation testing in practical use. Although numerous equivalent mutant detection (EMD) techniques have been proposed, they exhibit limitations due to the scarcity of training data and challenges in generalizing to unseen mutants. Recently, large language models (LLMs) have been extensively adopted in various code-related tasks and have shown superior performance by more accurately capturing program semantics. Yet the performance of LLMs in equivalent mutant detection remains largely unclear. In this paper, we conduct an empirical study on 3,302 method-level Java mutant pairs to comprehensively investigate the effectiveness and efficiency of LLMs for equivalent mutant detection. Specifically, we assess the performance of LLMs compared to existing EMD techniques, examine the various strategies of LLMs, evaluate the orthogonality between EMD techniques, and measure the time overhead of training and inference. Our findings demonstrate that LLM-based techniques significantly outperform existing techniques (i.e., the average improvement of 35.69% in terms of F1-score), with the fine-tuned code embedding strategy being the most effective. Moreover, LLM-based techniques offer an excellent balance between cost (relatively low training and inference time) and effectiveness. Based on our findings, we further discuss the impact of model size and embedding quality, and provide several promising directions for future research. This work is the first to examine LLMs in equivalent mutant detection, affirming their effectiveness and efficiency.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This paper has been accepted by ISSTA'2024"
    },
    {
        "paper id": "2408.01768",
        "abstract url": "https://arxiv.org/abs/2408.01768",
        "title": "Building Living Software Systems with Generative & Agentic AI",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper is an opinion paper that looks at the future of computing in the age of Generative \\& Agentic AI. Current software systems are static and inflexible, leading to significant challenges in translating human goals into computational actions. \"Living software systems\" powered by generative AI offer a solution to this fundamental problem in computing. Traditional software development involves multiple layers of imperfect translation, from business requirements to code, resulting in rigid systems that struggle to adapt to changing user needs and contexts. Generative AI, particularly large language models, can serve as a universal translator between human intent and computer operations. This approach enables the creation of more flexible, context-aware systems that can dynamically evolve to meet user goals. Two pathways for implementing living software systems are explored: using generative AI to accelerate traditional software development, and leveraging agentic AI to create truly adaptive systems. New skills like Prompt Engineering are necessary. By reimagining software as a living, adaptable entity, we can create computing interfaces that are more intuitive, powerful, and responsive to human needs.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01789",
        "abstract url": "https://arxiv.org/abs/2408.01789",
        "title": "Adaptic: A Shape Changing Prop with Haptic Retargeting",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present Adaptic, a novel \"hybrid\" active/passive haptic device that can change shape to act as a proxy for a range of virtual objects in VR. We use Adaptic with haptic retargeting to redirect the user's hand to provide haptic feedback for several virtual objects in arm's reach using only a single prop. To evaluate the effectiveness of Adaptic with haptic retargeting, we conducted a within-subjects experiment employing a docking task to compare Adaptic to non-matching proxy objects (i.e., Styrofoam balls) and matching shape props. In our study, Adaptic sat on a desk in front of the user and changed shapes between grasps, to provide matching tactile feedback for various virtual objects placed in different virtual locations. Results indicate that the illusion was convincing: users felt they were manipulating several virtual objects in different virtual locations with a single Adaptic device. Docking performance (completion time and accuracy) with Adaptic was comparable to props without haptic retargeting.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "10 Pages"
    },
    {
        "paper id": "2408.01791",
        "abstract url": "https://arxiv.org/abs/2408.01791",
        "title": "Implementing NAT Hole Punching with QUIC",
        "rating": "-10",
        "keywords": [],
        "abstract": "The widespread adoption of Network Address Translation (NAT) technology has led to a significant number of network end nodes being located in private networks behind NAT devices, impeding direct communication between these nodes. To solve this problem, a technique known as \"hole punching\" has been devised for NAT traversal to facilitate peer-to-peer communication among end nodes located in distinct private networks. However, as the increasing demands for speed and security in networks, TCP-based hole punching schemes gradually show performance drawbacks. Therefore, we present a QUIC-based hole punching scheme for NAT traversal. Through a comparative analysis of the hole punching time between QUIC-based and TCP based protocols, we find that the QUIC-based scheme effectively reduces the hole punching time, exhibiting a pronounced advantage in weak network environments. Furthermore, in scenarios where the hole punched connection is disrupted due to factors such as network transitions or NAT timeouts, this paper evaluates two schemes for restoring the connection: QUIC connection migration and re-punching. Our results show that QUIC connection migration for connection restoration saves 2 RTTs compared to QUIC re-punching, and 3 RTTs compared to TCP re-punching, effectively reducing the computational resources consumption for re-punching.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "The paper has been accepted for oral presentation at the VTC2024-Fall Conference"
    },
    {
        "paper id": "2408.01792",
        "abstract url": "https://arxiv.org/abs/2408.01792",
        "title": "Optimizing Intrusion Detection System Performance Through Synergistic Hyperparameter Tuning and Advanced Data Processing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Intrusion detection is vital for securing computer networks against malicious activities. Traditional methods struggle to detect complex patterns and anomalies in network traffic effectively. To address this issue, we propose a system combining deep learning, data balancing (K-means + SMOTE), high-dimensional reduction (PCA and FCBF), and hyperparameter optimization (Extra Trees and BO-TPE) to enhance intrusion detection performance. By training on extensive datasets like CIC IDS 2018 and CIC IDS 2017, our models demonstrate robust performance and generalization. Notably, the ensemble model \"VGG19\" consistently achieves remarkable accuracy (99.26% on CIC-IDS2017 and 99.22% on CSE-CIC-IDS2018), outperforming other models.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "20 pages, 7 figures"
    },
    {
        "paper id": "2408.01794",
        "abstract url": "https://arxiv.org/abs/2408.01794",
        "title": "Efficient generation of odd order de Bruijn sequence with the same complement and reverse sequences",
        "rating": "-10",
        "keywords": [],
        "abstract": "Experimental results show that, when the order $n$ is odd, there are de Bruijn sequences such that the corresponding complement sequence and the reverse sequence are the same. In this paper, we propose one efficient method to generate such de Bruijn sequences. This solves an open problem asked by Fredricksen forty years ago for showing the existence of such de Bruijn sequences when the odd order $n >1$. Moreover, we refine a characterization of de Bruijn sequences with the same complement and reverse sequences and study the number of these de Bruijn sequences, as well as the distribution of de Bruijn sequences of the maximum linear complexity.",
        "subjects": [
            "cs.IT",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01805",
        "abstract url": "https://arxiv.org/abs/2408.01805",
        "title": "Billion-files File Systems (BfFS): A Comparison",
        "rating": "-10",
        "keywords": [],
        "abstract": "As the volume of data being produced is increasing at an exponential rate that needs to be processed quickly, it is reasonable that the data needs to be available very close to the compute devices to reduce transfer latency. Due to this need, local filesystems are getting close attention to understand their inner workings, performance, and more importantly their limitations. This study analyzes few popular Linux filesystems: EXT4, XFS, BtrFS, ZFS, and F2FS by creating, storing, and then reading back one billion files from the local filesystem. The study also captured and analyzed read/write throughput, storage blocks usage, disk space utilization and overheads, and other metrics useful for system designers and integrators. Furthermore, the study explored other side effects such as filesystem performance degradation during and after these large numbers of files and folders are created.",
        "subjects": [
            "cs.PF"
        ],
        "comment": "Paper is 9 pages. Source code is open and uploaded to Git, along with an Excel spreadsheet used for analysis"
    },
    {
        "paper id": "2408.01806",
        "abstract url": "https://arxiv.org/abs/2408.01806",
        "title": "Algebraic Geometry Codes for Distributed Matrix Multiplication Using Local Expansions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Code-based Distributed Matrix Multiplication (DMM) has been extensively studied in distributed computing for efficiently performing large-scale matrix multiplication using coding theoretic techniques. The communication cost and recovery threshold (i.e., the least number of successful worker nodes required to recover the product of two matrices) are two major challenges in coded DMM research. Several constructions based on Reed-Solomon (RS) codes are known, including Polynomial codes, MatDot codes, and PolyDot codes. However, these RS-based schemes are not efficient for small finite fields because the distributed order (i.e., the total number of worker nodes) is limited by the size of the underlying finite field. Algebraic geometry (AG) codes can have a code length exceeding the size of the finite field, which helps solve this problem. Some work has been done to generalize Polynomial and MatDot codes to AG codes, but the generalization of PolyDot codes to AGcodes still remains an open problem as far as we know. This is because functions of an algebraic curve do not behave as nicely as polynomials. In this work, by using local expansions of functions, we are able to generalize the three DMM schemes based on RS codes to AG codes. Specifically, we provide a construction of AG-based PolyDot codes for the first time. In addition, our AG-based Polynomial and MatDot codes achieve better recovery thresholds compared to previous AG-based DMM schemes while maintaining similar communication costs. Our constructions are based on a novel basis of the Riemann-Roch space using local expansions, which naturally generalizes the standard monomial basis of the univariate polynomial space in RS codes. In contrast, previous work used the non-gap numbers to construct a basis of the Riemann-Roch space, which can cause cancellation problems that prevent the conditions of PolyDot codes from being satisfied.",
        "subjects": [
            "cs.IT",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01810",
        "abstract url": "https://arxiv.org/abs/2408.01810",
        "title": "Demystifying Device-specific Compatibility Issues in Android Apps",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Android ecosystem is profoundly fragmented due to the frequent updates of the Android system and the prevalent customizations by mobile device manufacturers. Previous research primarily focused on identifying and repairing evolution-induced API compatibility issues, with limited consideration of devices-specific compatibility issues (DSC issues). To fill this gap, we conduct an empirical study of 197 DSC issues collected from 94 open-source repositories on GitHub. We introduce a new perspective for comprehending these issues by categorizing them into two principal groups, Functionality Breaks, and OEM Features, based on their manifestations and root causes. The functionality break issues disrupt standard Android system behaviors, lead to crashes or unexpected behaviors on specific devices, and require developers to implement workarounds to preserve the original functionality. The OEM feature issues involve the introduction of device-specific functionalities or features beyond the basic Android system. The different nature of functionality break issues and OEM feature issues lead to unique challenges in addressing them. Common solutions for functionality break issues involve calling additional APIs, substituting problematic ones, or using specific parameters, while resolving OEM feature issues often relies on Android inter-component communication methods and reflection, with additional unconventional strategies. Such observations highlight the distinctive challenges in addressing DSC issues in Android apps and will facilitate the future development of testing and analysis tools targeting these issues. Our study demonstrates that Functionality break and OEM feature issues have different characteristics, and future research may need to investigate them separately.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by ICSME'24"
    },
    {
        "paper id": "2408.01813",
        "abstract url": "https://arxiv.org/abs/2408.01813",
        "title": "Workshop on Information Theory and Related Fields -- In Memory of Ning Cai",
        "rating": "-10",
        "keywords": [],
        "abstract": "Sadly, our esteemed colleague and friend Ning Cai passed away on 25th May, 2023. In his memory, Ingo Alth\u00f6fer, Holger Boche, Christian Deppe, Jens Stoye, Ulrich Tamm, Andreas Winter, and Raymond Yeung have organized the \"Workshop on Information Theory and Related Fields\" at the Bielefeld ZiF (Center for Interdisciplinary Research). This special event will be held from 24th November to 26th November, 2023. The workshop aims to celebrate Ning Cai's remarkable contributions to the field of information theory and to provide a platform for discussing current research in related areas. Ning Cai's work has had a significant impact on many domains, and this gathering will bring together colleagues, collaborators, and young researchers who have been influenced by his pioneering efforts.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01815",
        "abstract url": "https://arxiv.org/abs/2408.01815",
        "title": "Facilitating the Parametric Definition of Geometric Properties in Programming-Based CAD",
        "rating": "-10",
        "keywords": [],
        "abstract": "Parametric Computer-aided design (CAD) enables the creation of reusable models by integrating variables into geometric properties, facilitating customization without a complete redesign. However, creating parametric designs in programming-based CAD presents significant challenges. Users define models in a code editor using a programming language, with the application generating a visual representation in a viewport. This process involves complex programming and arithmetic expressions to describe geometric properties, linking various object properties to create parametric designs. Unfortunately, these applications lack assistance, making the process unnecessarily demanding. We propose a solution that allows users to retrieve parametric expressions from the visual representation for reuse in the code, streamlining the design process. We demonstrated this concept through a proof-of-concept implemented in the programming-based CAD application, OpenSCAD, and conducted an experiment with 11 users. Our findings suggest that this solution could significantly reduce design errors, improve interactivity and engagement in the design process, and lower the entry barrier for newcomers by reducing the mathematical skills typically required in programming-based CAD applications",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01849",
        "abstract url": "https://arxiv.org/abs/2408.01849",
        "title": "A Tree Sampler for Bounded Context-Free Languages",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the following paper, we present a simple method for sampling trees with or without replacement from BCFLs. A BCFL is a context-free language (CFL) corresponding to an incomplete string with holes, which can be completed by valid terminals. To solve this problem, we introduce an algebraic datatype that compactly represents candidate parse forests for porous strings. Once constructed, sampling trees is a straightforward matter of sampling integers uniformly without replacement, then lazily decoding them into trees.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01894",
        "abstract url": "https://arxiv.org/abs/2408.01894",
        "title": "A Feature-Based Approach to Generating Comprehensive End-to-End Tests",
        "rating": "-10",
        "keywords": [],
        "abstract": "End-to-end (E2E) testing is essential for ensuring web application quality. However, manual test creation is time-consuming and current test generation techniques produce random tests. In this paper, we present AUTOE2E, a novel approach that leverages Large Language Models (LLMs) to automate the generation of semantically meaningful feature-driven E2E test cases for web applications. AUTOE2E intelligently infers potential features within a web application and translates them into executable test scenarios. Furthermore, we address a critical gap in the research community by introducing E2EBENCH, a new benchmark for automatically assessing the feature coverage of E2E test suites. Our evaluation on E2EBENCH demonstrates that AUTOE2E achieves an average feature coverage of 79%, outperforming the best baseline by 558%, highlighting its effectiveness in generating high-quality, comprehensive test cases.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01896",
        "abstract url": "https://arxiv.org/abs/2408.01896",
        "title": "Remote Staking with Economic Safety",
        "rating": "-10",
        "keywords": [],
        "abstract": "Proof-of-stake (PoS) blockchains require validators to lock their tokens as collateral, slashing these tokens if they are identified as protocol violators. PoS chains have mostly been secured by their native tokens. However, using only the native token upper-bounds the value eligible for staking by the market capitalization of the native token. In contrast, the remote staking of another crypto asset from a provider chain provides an avenue to improve the consumer chain's economic security. In this paper, we present the first known remote staking protocols with guaranteed optimal economic safety: whenever there is a safety violation on the consumer chain, at least one third of the provider's stake securing the consumer chain is slashed. To achieve this goal for a broad range of provider and consumer chains, two independent contributions are made: 1) a remote unbonding protocol that ensures slashing before the stake is unbonded on the provider chain if there is safety violation on the consumer chain; 2) a protocol to slash stake even without smart contracts on the provider chain. The remote staking protocol is analyzed and implemented in the case where the provider chain is Bitcoin and the consumer chain is a Cosmos SDK chain running the Tendermint consensus protocol.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01899",
        "abstract url": "https://arxiv.org/abs/2408.01899",
        "title": "Convergence Analysis of Weighted-Median Opinion Dynamics with Prejudice",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Friedkin-Johnsen (FJ) model introduces prejudice into the opinion evolution and has been successfully validated in many practical scenarios; however, due to its weighted average mechanism, only one prejudiced agent can always guide all unprejudiced agents synchronizing to its prejudice under the connected influence network, which may not be in line with some social realities. To fundamentally address the limitation of the weighted average mechanism, a weighted-median opinion dynamics has been recently proposed; however, its theoretical analysis is challenging due to its nonlinear nature. This paper studies the weighted-median opinion dynamics with prejudice, and obtains the convergence and convergence rate when all agents have prejudice, and a necessary and sufficient condition for asymptotic consensus when a portion of agents have prejudice. These results are the first time to analyze the discrete-time and synchronous opinion dynamics with the weighted median mechanism, and address the phenomenon of the FJ model that connectivity leads to consensus when a few agents with the same prejudice join in an unprejudiced group.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01906",
        "abstract url": "https://arxiv.org/abs/2408.01906",
        "title": "Binary $[n,(n\\pm1)/2]$ cyclic codes with good minimum distances from sequences",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, binary cyclic codes with parameters $[n,(n\\pm1)/2,\\geq \\sqrt{n}]$ have been a hot topic since their minimum distances have a square-root bound. In this paper, we construct four classes of binary cyclic codes $\\mathcal{C}_{\\mathcal{S},0}$, $\\mathcal{C}_{\\mathcal{S},1}$ and $\\mathcal{C}_{\\mathcal{D},0}$, $\\mathcal{C}_{\\mathcal{D},1}$ by using two families of sequences, and obtain some codes with parameters $[n,(n\\pm1)/2,\\geq \\sqrt{n}]$. For $m\\equiv2\\pmod4$, the code $\\mathcal{C}_{\\mathcal{S},0}$ has parameters $[2^m-1,2^{m-1},\\geq2^{\\frac{m}{2}}+2]$, and the code $\\mathcal{C}_{\\mathcal{D},0}$ has parameters $[2^m-1,2^{m-1},\\geq2^{\\frac{m}{2}}+2]$ if $h=1$ and $[2^m-1,2^{m-1},\\geq2^{\\frac{m}{2}}]$ if $h=2$.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01909",
        "abstract url": "https://arxiv.org/abs/2408.01909",
        "title": "Scaling Symbolic Execution to Large Software Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Static analysis is the analysis of a program without executing it, usually carried out by an automated tool. Symbolic execution is a popular static analysis technique used both in program verification and in bug detection software. It works by interpreting the code, introducing a symbol for each value unknown at compile time (e.g. user-given inputs), and carrying out calculations symbolically. The analysis engine strives to explore multiple execution paths simultaneously, although checking all paths is an intractable problem, due to the vast number of possibilities. We focus on an error finding framework called the Clang Static Analyzer, and the infrastructure built around it named CodeChecker. The emphasis is on achieving end-to-end scalability. This includes the run time and memory consumption of the analysis, bug presentation to the users, automatic false positive suppression, incremental analysis, pattern discovery in the results, and usage in continuous integration loops. We also outline future directions and open problems concerning these tools. While a rich literature exists on program verification software, error finding tools normally need to settle for survey papers on individual techniques. In this paper, we not only discuss individual methods, but also how these decisions interact and reinforce each other, creating a system that is greater than the sum of its parts. Although the Clang Static Analyzer can only handle C-family languages, the techniques introduced in this paper are mostly language-independent and applicable to other similar static analysis tools.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01923",
        "abstract url": "https://arxiv.org/abs/2408.01923",
        "title": "Scalable Signal Temporal Logic Guided Reinforcement Learning via Value Function Space Optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "The integration of reinforcement learning (RL) and formal methods has emerged as a promising framework for solving long-horizon planning problems. Conventional approaches typically involve abstraction of the state and action spaces and manually created labeling functions or predicates. However, the efficiency of these approaches deteriorates as the tasks become increasingly complex, which results in exponential growth in the size of labeling functions or predicates. To address these issues, we propose a scalable model-based RL framework, called VFSTL, which schedules pre-trained skills to follow unseen STL specifications without using hand-crafted predicates. Given a set of value functions obtained by goal-conditioned RL, we formulate an optimization problem to maximize the robustness value of Signal Temporal Logic (STL) defined specifications, which is computed using value functions as predicates. To further reduce the computation burden, we abstract the environment state space into the value function space (VFS). Then the optimization problem is solved by Model-Based Reinforcement Learning. Simulation results show that STL with value functions as predicates approximates the ground truth robustness and the planning in VFS directly achieves unseen specifications using data from sensors.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.01927",
        "abstract url": "https://arxiv.org/abs/2408.01927",
        "title": "Step-to-Charge: mW-scale power transfer to on-body devices for long channel (> 1m) with EQS Resonant Human Body Powering",
        "rating": "-10",
        "keywords": [],
        "abstract": "Current limits of harvested energy in wearables are governed by three fundamental quantities, the physical limits of available energy density in ambient powering, safety limits in intentional powering, and the size of the wearable device. Typical energy harvested, except for solar power in favorable outdoor conditions, ranges from 5 uW to a maximum of 100 - 200 uW depending upon the available energy. Further, traditional intentional powering methodologies using ultrasound and radio-frequency either have a severe limitation in range of powering or are inefficient due to high path loss in Non-Line-of-Sight scenarios due to absorption by the body. In this study, we propose a novel approach using the human body, the common medium connecting the wearable devices, as a channel to transfer power. We demonstrate Human Body Powering using ``Step-to-Charge,\" a first-of-its-kind non-radiative, meter-scale powering methodology using a floor-based source and the human body as the channel to transfer power at lower channel losses to charge and power wearable devices across the whole body. The proposed powering methodology allows more than 2 mW peak power to be transferred to a wearable device for >1m channel lengths, which is > 90X greater than the state-of-the-art over previous Human Body Powering attempts. Step-to-Charge enables the powering of a new, extended range of wearable devices across the human body, bringing us closer to enabling battery-less perpetual operation using Human Body Power transfer.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    }
]