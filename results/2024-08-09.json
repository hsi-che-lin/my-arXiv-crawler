[
    {
        "paper id": "2408.05364",
        "abstract url": "https://arxiv.org/abs/2408.05364",
        "title": "Spherical World-Locking for Audio-Visual Localization in Egocentric Videos",
        "rating": "2.5",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Egocentric videos provide comprehensive contexts for user and scene understanding, spanning multisensory perception to behavioral interaction. We propose Spherical World-Locking (SWL) as a general framework for egocentric scene representation, which implicitly transforms multisensory streams with respect to measurements of head orientation. Compared to conventional head-locked egocentric representations with a 2D planar field-of-view, SWL effectively offsets challenges posed by self-motion, allowing for improved spatial synchronization between input modalities. Using a set of multisensory embeddings on a worldlocked sphere, we design a unified encoder-decoder transformer architecture that preserves the spherical structure of the scene representation, without requiring expensive projections between image and world coordinate systems. We evaluate the effectiveness of the proposed framework on multiple benchmark tasks for egocentric video understanding, including audio-visual active speaker localization, auditory spherical source localization, and behavior anticipation in everyday activities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV2024"
    },
    {
        "paper id": "2408.04917",
        "abstract url": "https://arxiv.org/abs/2408.04917",
        "title": "Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Active learning (AL) aims to enhance model performance by selectively collecting highly informative data, thereby minimizing annotation costs. However, in practical scenarios, unlabeled data may contain out-of-distribution (OOD) samples, leading to wasted annotation costs if data is incorrectly selected. Recent research has explored methods to apply AL to open-set data, but these methods often require or incur unavoidable cost losses to minimize them. To address these challenges, we propose a novel selection strategy, CLIPN for AL (CLIPNAL), which minimizes cost losses without requiring OOD samples. CLIPNAL sequentially evaluates the purity and informativeness of data. First, it utilizes a pre-trained vision-language model to detect and exclude OOD data by leveraging linguistic and visual information of in-distribution (ID) data without additional training. Second, it selects highly informative data from the remaining ID data, and then the selected samples are annotated by human experts. Experimental results on datasets with various open-set conditions demonstrate that CLIPNAL achieves the lowest cost loss and highest performance across all scenarios. Code is available at https://github.com/DSBA-Lab/OpenAL.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04975",
        "abstract url": "https://arxiv.org/abs/2408.04975",
        "title": "\\textit{re}CSE: Portable Reshaping Features for Sentence Embedding in Self-supervised Contrastive Learning",
        "rating": "2",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "We propose \\textit{re}CSE, a self supervised contrastive learning sentence representation framework based on feature reshaping. This framework is different from the current advanced models that use discrete data augmentation methods, but instead reshapes the input features of the original sentence, aggregates the global information of each token in the sentence, and alleviates the common problems of representation polarity and GPU memory consumption linear increase in current advanced models. In addition, our \\textit{re}CSE has achieved competitive performance in semantic similarity tasks. And the experiment proves that our proposed feature reshaping method has strong universality, which can be transplanted to other self supervised contrastive learning frameworks and enhance their representation ability, even achieving state-of-the-art performance. Our code is available at https://github.com/heavenhellchen/reCSE.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05097",
        "abstract url": "https://arxiv.org/abs/2408.05097",
        "title": "Hyperbolic Learning with Multimodal Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Hyperbolic embeddings have demonstrated their effectiveness in capturing measures of uncertainty and hierarchical relationships across various deep-learning tasks, including image segmentation and active learning. However, their application in modern vision-language models (VLMs) has been limited. A notable exception is MERU, which leverages the hierarchical properties of hyperbolic space in the CLIP ViT-large model, consisting of hundreds of millions parameters. In our work, we address the challenges of scaling multi-modal hyperbolic models by orders of magnitude in terms of parameters (billions) and training complexity using the BLIP-2 architecture. Although hyperbolic embeddings offer potential insights into uncertainty not present in Euclidean embeddings, our analysis reveals that scaling these models is particularly difficult. We propose a novel training strategy for a hyperbolic version of BLIP-2, which allows to achieve comparable performance to its Euclidean counterpart, while maintaining stability throughout the training process and showing a meaningful indication of uncertainty with each embedding.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "ECCV 2024 - Beyond Euclidean Workshop"
    },
    {
        "paper id": "2408.05200",
        "abstract url": "https://arxiv.org/abs/2408.05200",
        "title": "TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "PEFT",
                "efficient fine-tuning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Language model continual learning (CL) has recently garnered significant interest due to its potential to adapt large language models (LLMs) to dynamic real-world environments without re-training. A key challenge in this field is catastrophic forgetting, where models lose previously acquired knowledge when learning new tasks. Existing methods commonly employ multiple parameter-efficient fine-tuning (PEFT) blocks to acquire task-specific knowledge for each task, but these approaches lack efficiency and overlook the potential for knowledge transfer through task interaction. In this paper, we present a novel CL framework for language models called Task Skill Localization and Consolidation (TaSL), which enhances knowledge transfer without relying on memory replay. TaSL first divides the model into `skill units' based on parameter dependencies, enabling more granular control. It then employs a novel group-wise skill localization technique to identify the importance distribution of skill units for a new task. By comparing this importance distribution with those from previous tasks, we implement a fine-grained skill consolidation strategy that retains task-specific knowledge, thereby preventing forgetting, and updates task-shared knowledge, which facilitates bi-directional knowledge transfer. As a result, TaSL achieves a superior balance between retaining previous knowledge and excelling in new tasks. TaSL also shows strong generalizability, suitable for general models and customizable for PEFT methods like LoRA. Additionally, it demonstrates notable extensibility, allowing integration with memory replay to further enhance performance. Extensive experiments on two CL benchmarks, with varying model sizes (from 220M to 7B), demonstrate the effectiveness of TaSL and its variants across different settings.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Extension of ACL 2024 paper titled: Continual Dialog State Tracking via Task Skill Localization and Consolidation"
    },
    {
        "paper id": "2408.05411",
        "abstract url": "https://arxiv.org/abs/2408.05411",
        "title": "How Does Audio Influence Visual Attention in Omnidirectional Videos? Database and Model",
        "rating": "2",
        "keywords": [
            [
                "audio-visual"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding and predicting viewer attention in omnidirectional videos (ODVs) is crucial for enhancing user engagement in virtual and augmented reality applications. Although both audio and visual modalities are essential for saliency prediction in ODVs, the joint exploitation of these two modalities has been limited, primarily due to the absence of large-scale audio-visual saliency databases and comprehensive analyses. This paper comprehensively investigates audio-visual attention in ODVs from both subjective and objective perspectives. Specifically, we first introduce a new audio-visual saliency database for omnidirectional videos, termed AVS-ODV database, containing 162 ODVs and corresponding eye movement data collected from 60 subjects under three audio modes including mute, mono, and ambisonics. Based on the constructed AVS-ODV database, we perform an in-depth analysis of how audio influences visual attention in ODVs. To advance the research on audio-visual saliency prediction for ODVs, we further establish a new benchmark based on the AVS-ODV database by testing numerous state-of-the-art saliency models, including visual-only models and audio-visual models. In addition, given the limitations of current models, we propose an innovative omnidirectional audio-visual saliency prediction network (OmniAVS), which is built based on the U-Net architecture, and hierarchically fuses audio and visual features from the multimodal aligned embedding space. Extensive experimental results demonstrate that the proposed OmniAVS model outperforms other state-of-the-art models on both ODV AVS prediction and traditional AVS predcition tasks. The AVS-ODV database and OmniAVS model will be released to facilitate future research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04883",
        "abstract url": "https://arxiv.org/abs/2408.04883",
        "title": "ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Open-vocabulary semantic segmentation requires models to effectively integrate visual representations with open-vocabulary semantic labels. While Contrastive Language-Image Pre-training (CLIP) models shine in recognizing visual concepts from text, they often struggle with segment coherence due to their limited localization ability. In contrast, Vision Foundation Models (VFMs) excel at acquiring spatially consistent local visual representations, yet they fall short in semantic understanding. This paper introduces ProxyCLIP, an innovative framework designed to harmonize the strengths of both CLIP and VFMs, facilitating enhanced open-vocabulary semantic segmentation. ProxyCLIP leverages the spatial feature correspondence from VFMs as a form of proxy attention to augment CLIP, thereby inheriting the VFMs' robust local consistency and maintaining CLIP's exceptional zero-shot transfer capacity. We propose an adaptive normalization and masking strategy to get the proxy attention from VFMs, allowing for adaptation across different VFMs. Remarkably, as a training-free approach, ProxyCLIP significantly improves the average mean Intersection over Union (mIoU) across eight benchmarks from 40.3 to 44.4, showcasing its exceptional efficacy in bridging the gap between spatial precision and semantic richness for the open-vocabulary segmentation task.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV 2024. Code available at https://github.com/mc-lan/ProxyCLIP"
    },
    {
        "paper id": "2408.04961",
        "abstract url": "https://arxiv.org/abs/2408.04961",
        "title": "In Defense of Lazy Visual Grounding for Open-Vocabulary Semantic Segmentation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "We present lazy visual grounding, a two-stage approach of unsupervised object mask discovery followed by object grounding, for open-vocabulary semantic segmentation. Plenty of the previous art casts this task as pixel-to-text classification without object-level comprehension, leveraging the image-to-text classification capability of pretrained vision-and-language models. We argue that visual objects are distinguishable without the prior text information as segmentation is essentially a vision task. Lazy visual grounding first discovers object masks covering an image with iterative Normalized cuts and then later assigns text on the discovered objects in a late interaction manner. Our model requires no additional training yet shows great performance on five public datasets: Pascal VOC, Pascal Context, COCO-object, COCO-stuff, and ADE 20K. Especially, the visually appealing segmentation results demonstrate the model capability to localize objects precisely. Paper homepage: https://cvlab.postech.ac.kr/research/lazygrounding",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV 2024"
    },
    {
        "paper id": "2408.05035",
        "abstract url": "https://arxiv.org/abs/2408.05035",
        "title": "Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "The Exame Nacional do Ensino M\u00e9dio (ENEM) is a pivotal test for Brazilian students, required for admission to a significant number of universities in Brazil. The test consists of four objective high-school level tests on Math, Humanities, Natural Sciences and Languages, and one writing essay. Students' answers to the test and to the accompanying socioeconomic status questionnaire are made public every year (albeit anonymized) due to transparency policies from the Brazilian Government. In the context of large language models (LLMs), these data lend themselves nicely to comparing different groups of humans with AI, as we can have access to human and machine answer distributions. We leverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4, and MariTalk, a model trained using Portuguese data, to humans, aiming to ascertain how their answers relate to real societal groups and what that may reveal about the model biases. We divide the human groups by using socioeconomic status (SES), and compare their answer distribution with LLMs for each question and for the essay. We find no significant biases when comparing LLM performance to humans on the multiple-choice Brazilian Portuguese tests, as the distance between model and human answers is mostly determined by the human accuracy. A similar conclusion is found by looking at the generated text as, when analyzing the essays, we observe that human and LLM essays differ in a few key factors, one being the choice of words where model essays were easily separable from human ones. The texts also differ syntactically, with LLM generated essays exhibiting, on average, smaller sentences and less thought units, among other differences. These results suggest that, for Brazilian Portuguese in the ENEM context, LLM outputs represent no group of humans, being significantly different from the answers from Brazilian students across all tests.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": "Accepted at the Seventh AAAI/ACM Conference on AI, Ethics and Society (AIES 2024). 14 pages, 4 figures"
    },
    {
        "paper id": "2408.05088",
        "abstract url": "https://arxiv.org/abs/2408.05088",
        "title": "UNIC: Universal Classification Models via Multi-teacher Distillation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Pretrained models have become a commodity and offer strong results on a broad range of tasks. In this work, we focus on classification and seek to learn a unique encoder able to take from several complementary pretrained models. We aim at even stronger generalization across a variety of classification tasks. We propose to learn such an encoder via multi-teacher distillation. We first thoroughly analyse standard distillation when driven by multiple strong teachers with complementary strengths. Guided by this analysis, we gradually propose improvements to the basic distillation setup. Among those, we enrich the architecture of the encoder with a ladder of expendable projectors, which increases the impact of intermediate features during distillation, and we introduce teacher dropping, a regularization mechanism that better balances the teachers' influence. Our final distillation strategy leads to student models of the same capacity as any of the teachers, while retaining or improving upon the performance of the best teacher for each task. Project page and code: https://europe.naverlabs.com/unic",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To be presented at ECCV 2024"
    },
    {
        "paper id": "2408.04872",
        "abstract url": "https://arxiv.org/abs/2408.04872",
        "title": "SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In-context learning (ICL) greatly improves the performance of large language models (LLMs) on various down-stream tasks, where the improvement highly depends on the quality of demonstrations. In this work, we introduce syntactic knowledge to select better in-context examples for machine translation (MT). We propose a new strategy, namely Syntax-augmented COverage-based In-context example selection (SCOI), leveraging the deep syntactic structure beyond conventional word matching. Specifically, we measure the set-level syntactic coverage by computing the coverage of polynomial terms with the help of a simplified tree-to-polynomial algorithm, and lexical coverage using word overlap. Furthermore, we devise an alternate selection approach to combine both coverage measures, taking advantage of syntactic and lexical information. We conduct experiments with two multi-lingual LLMs on six translation directions. Empirical results show that our proposed SCOI obtains the highest average COMET score among all learning-free methods, indicating that combining syntactic and lexical coverage successfully helps to select better in-context examples for MT.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "16 pages, 2 figures, 14 tables"
    },
    {
        "paper id": "2408.04873",
        "abstract url": "https://arxiv.org/abs/2408.04873",
        "title": "Unsupervised Episode Detection for Large-Scale News Events",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Episodic structures are inherently interpretable and adaptable to evolving large-scale key events. However, state-of-the-art automatic event detection methods overlook event episodes and, therefore, struggle with these crucial characteristics. This paper introduces a novel task, episode detection, aimed at identifying episodes from a news corpus containing key event articles. An episode describes a cohesive cluster of core entities (e.g., \"protesters\", \"police\") performing actions at a specific time and location. Furthermore, an episode is a significant part of a larger group of episodes under a particular key event. Automatically detecting episodes is challenging because, unlike key events and atomic actions, we cannot rely on explicit mentions of times and locations to distinguish between episodes or use semantic similarity to merge inconsistent episode co-references. To address these challenges, we introduce EpiMine, an unsupervised episode detection framework that (1) automatically identifies the most salient, key-event-relevant terms and segments, (2) determines candidate episodes in an article based on natural episodic partitions estimated through shifts in discriminative term combinations, and (3) refines and forms final episode clusters using large language model-based reasoning on the candidate episodes. We construct three diverse, real-world event datasets annotated at the episode level. EpiMine outperforms all baselines on these datasets by an average 59.2% increase across all metrics.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04879",
        "abstract url": "https://arxiv.org/abs/2408.04879",
        "title": "On the Element-Wise Representation and Reasoning in Zero-Shot Image Recognition: A Systematic Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Zero-shot image recognition (ZSIR) aims at empowering models to recognize and reason in unseen domains via learning generalized knowledge from limited data in the seen domain. The gist for ZSIR is to execute element-wise representation and reasoning from the input visual space to the target semantic space, which is a bottom-up modeling paradigm inspired by the process by which humans observe the world, i.e., capturing new concepts by learning and combining the basic components or shared characteristics. In recent years, element-wise learning techniques have seen significant progress in ZSIR as well as widespread application. However, to the best of our knowledge, there remains a lack of a systematic overview of this topic. To enrich the literature and provide a sound basis for its future development, this paper presents a broad review of recent advances in element-wise ZSIR. Concretely, we first attempt to integrate the three basic ZSIR tasks of object recognition, compositional recognition, and foundation model-based open-world recognition into a unified element-wise perspective and provide a detailed taxonomy and analysis of the main research approaches. Then, we collect and summarize some key information and benchmarks, such as detailed technical implementations and common datasets. Finally, we sketch out the wide range of its related applications, discuss vital challenges, and suggest potential future directions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "24 pages, 7 figures"
    },
    {
        "paper id": "2408.04891",
        "abstract url": "https://arxiv.org/abs/2408.04891",
        "title": "Clustering-friendly Representation Learning for Enhancing Salient Features",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, representation learning with contrastive learning algorithms has been successfully applied to challenging unlabeled datasets. However, these methods are unable to distinguish important features from unimportant ones under simply unsupervised settings, and definitions of importance vary according to the type of downstream task or analysis goal, such as the identification of objects or backgrounds. In this paper, we focus on unsupervised image clustering as the downstream task and propose a representation learning method that enhances features critical to the clustering task. We extend a clustering-friendly contrastive learning method and incorporate a contrastive analysis approach, which utilizes a reference dataset to separate important features from unimportant ones, into the design of loss functions. Conducting an experimental evaluation of image clustering for three datasets with characteristic backgrounds, we show that for all datasets, our method achieves higher clustering scores compared with conventional contrastive analysis and deep clustering methods.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "12 pages, 6 figures, 28th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD2024)"
    },
    {
        "paper id": "2408.04900",
        "abstract url": "https://arxiv.org/abs/2408.04900",
        "title": "Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication in Codenames",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Cultural differences in common ground may result in pragmatic failure and misunderstandings during communication. We develop our method Rational Speech Acts for Cross-Cultural Communication (RSA+C3) to resolve cross-cultural differences in common ground. To measure the success of our method, we study RSA+C3 in the collaborative referential game of Codenames Duet and show that our method successfully improves collaboration between simulated players of different cultures. Our contributions are threefold: (1) creating Codenames players using contrastive learning of an embedding space and LLM prompting that are aligned with human patterns of play, (2) studying culturally induced differences in common ground reflected in our trained models, and (3) demonstrating that our method RSA+C3 can ease cross-cultural communication in gameplay by inferring sociocultural context from interaction. Our code is publicly available at github.com/icwhite/codenames.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04905",
        "abstract url": "https://arxiv.org/abs/2408.04905",
        "title": "GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have achieved unprecedented success in the field of natural language processing. However, the black-box nature of their internal mechanisms has brought many concerns about their trustworthiness and interpretability. Recent research has discovered a class of abnormal tokens in the model's vocabulary space and named them \"glitch tokens\". Those tokens, once included in the input, may induce the model to produce incorrect, irrelevant, or even harmful results, drastically undermining the reliability and practicality of LLMs. In this work, we aim to enhance the understanding of glitch tokens and propose techniques for their detection and mitigation. We first reveal the characteristic features induced by glitch tokens on LLMs, which are evidenced by significant deviations in the distributions of attention patterns and dynamic information from intermediate model layers. Based on the insights, we develop GlitchProber, a tool for efficient glitch token detection and mitigation. GlitchProber utilizes small-scale sampling, principal component analysis for accelerated feature extraction, and a simple classifier for efficient vocabulary screening. Taking one step further, GlitchProber rectifies abnormal model intermediate layer values to mitigate the destructive effects of glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber demonstrates higher efficiency, precision, and recall compared to existing approaches, with an average F1 score of 0.86 and an average repair rate of 50.06%. GlitchProber unveils a novel path to address the challenges posed by glitch tokens and inspires future research toward more robust and interpretable LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04906",
        "abstract url": "https://arxiv.org/abs/2408.04906",
        "title": "Towards a Generative Approach for Emotion Detection and Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated impressive performance in mathematical and commonsense reasoning tasks using chain-of-thought (CoT) prompting techniques. But can they perform emotional reasoning by concatenating `Let's think step-by-step' to the input prompt? In this paper we investigate this question along with introducing a novel approach to zero-shot emotion detection and emotional reasoning using LLMs. Existing state of the art zero-shot approaches rely on textual entailment models to choose the most appropriate emotion label for an input text. We argue that this strongly restricts the model to a fixed set of labels which may not be suitable or sufficient for many applications where emotion analysis is required. Instead, we propose framing the problem of emotion analysis as a generative question-answering (QA) task. Our approach uses a two step methodology of generating relevant context or background knowledge to answer the emotion detection question step-by-step. Our paper is the first work on using a generative approach to jointly address the tasks of emotion detection and emotional reasoning for texts. We evaluate our approach on two popular emotion detection datasets and also release the fine-grained emotion labels and explanations for further training and fine-tuning of emotional reasoning systems.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04909",
        "abstract url": "https://arxiv.org/abs/2408.04909",
        "title": "Surveying the Landscape of Image Captioning Evaluation: A Comprehensive Taxonomy and Novel Ensemble Method",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "The task of image captioning has recently been gaining popularity, and with it the complex task of evaluating the quality of image captioning models. In this work, we present the first survey and taxonomy of over 70 different image captioning metrics and their usage in hundreds of papers. We find that despite the diversity of proposed metrics, the vast majority of studies rely on only five popular metrics, which we show to be weakly correlated with human judgements. Instead, we propose EnsembEval -- an ensemble of evaluation methods achieving the highest reported correlation with human judgements across 5 image captioning datasets, showing there is a lot of room for improvement by leveraging a diverse set of metrics.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04912",
        "abstract url": "https://arxiv.org/abs/2408.04912",
        "title": "AcousAF: Acoustic Sensing-Based Atrial Fibrillation Detection System for Mobile Phones",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Atrial fibrillation (AF) is characterized by irregular electrical impulses originating in the atria, which can lead to severe complications and even death. Due to the intermittent nature of the AF, early and timely monitoring of AF is critical for patients to prevent further exacerbation of the condition. Although ambulatory ECG Holter monitors provide accurate monitoring, the high cost of these devices hinders their wider adoption. Current mobile-based AF detection systems offer a portable solution. However, these systems have various applicability issues, such as being easily affected by environmental factors and requiring significant user effort. To overcome the above limitations, we present AcousAF, a novel AF detection system based on acoustic sensors of smartphones. Particularly, we explore the potential of pulse wave acquisition from the wrist using smartphone speakers and microphones. In addition, we propose a well-designed framework comprised of pulse wave probing, pulse wave extraction, and AF detection to ensure accurate and reliable AF detection. We collect data from 20 participants utilizing our custom data collection application on the smartphone. Extensive experimental results demonstrate the high performance of our system, with 92.8% accuracy, 86.9% precision, 87.4% recall, and 87.1% F1 Score.",
        "subjects": [
            "cs.SD",
            "cs.CE",
            "cs.ET",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Accepted for publication in Companion of the 2024 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp Companion '24)"
    },
    {
        "paper id": "2408.04941",
        "abstract url": "https://arxiv.org/abs/2408.04941",
        "title": "Quantitative Information Extraction from Humanitarian Documents",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Humanitarian action is accompanied by a mass of reports, summaries, news, and other documents. To guide its activities, important information must be quickly extracted from such free-text resources. Quantities, such as the number of people affected, amount of aid distributed, or the extent of infrastructure damage, are central to emergency response and anticipatory action. In this work, we contribute an annotated dataset for the humanitarian domain for the extraction of such quantitative information, along side its important context, including units it refers to, any modifiers, and the relevant event. Further, we develop a custom Natural Language Processing pipeline to extract the quantities alongside their units, and evaluate it in comparison to baseline and recent literature. The proposed model achieves a consistent improvement in the performance, especially in the documents pertaining to the Dominican Republic and select African countries. We make the dataset and code available to the research community to continue the improvement of NLP tools for the humanitarian domain.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04955",
        "abstract url": "https://arxiv.org/abs/2408.04955",
        "title": "Model Debiasing by Learnable Data Augmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep Neural Networks are well known for efficiently fitting training data, yet experiencing poor generalization capabilities whenever some kind of bias dominates over the actual task labels, resulting in models learning \"shortcuts\". In essence, such models are often prone to learn spurious correlations between data and labels. In this work, we tackle the problem of learning from biased data in the very realistic unsupervised scenario, i.e., when the bias is unknown. This is a much harder task as compared to the supervised case, where auxiliary, bias-related annotations, can be exploited in the learning process. This paper proposes a novel 2-stage learning pipeline featuring a data augmentation strategy able to regularize the training. First, biased/unbiased samples are identified by training over-biased models. Second, such subdivision (typically noisy) is exploited within a data augmentation framework, properly combining the original samples while learning mixing parameters, which has a regularization effect. Experiments on synthetic and realistic biased datasets show state-of-the-art classification accuracy, outperforming competing methods, ultimately proving robust performance on both biased and unbiased examples. Notably, being our training method totally agnostic to the level of bias, it also positively affects performance for any, even apparently unbiased, dataset, thus improving the model generalization regardless of the level of bias (or its absence) in the data.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04957",
        "abstract url": "https://arxiv.org/abs/2408.04957",
        "title": "LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Visual Spatial Description (VSD) aims to generate texts that describe the spatial relationships between objects within images. Traditional visual spatial relationship classification (VSRC) methods typically output the spatial relationship between two objects in an image, often neglecting world knowledge and lacking general language capabilities. In this paper, we propose a Large Language-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD, which is designed for the classification, description, and open-ended description of visual spatial relationships. Specifically, the model first constructs a VSD instruction-following dataset using given figure-caption pairs for the three tasks. It then employs LoRA to fine-tune a Large Language and Vision Assistant for VSD, which has 13 billion parameters and supports high-resolution images. Finally, a large language model (Qwen-2) is used to refine the generated sentences, enhancing their diversity and accuracy. LLaVA-VSD demonstrates excellent multimodal conversational capabilities and can follow open-ended instructions to assist with inquiries about object relationships in images.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04965",
        "abstract url": "https://arxiv.org/abs/2408.04965",
        "title": "Generalisation First, Memorisation Second? Memorisation Localisation for Natural Language Classification Tasks",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Memorisation is a natural part of learning from real-world data: neural models pick up on atypical input-output combinations and store those training examples in their parameter space. That this happens is well-known, but how and where are questions that remain largely unanswered. Given a multi-layered neural model, where does memorisation occur in the millions of parameters? Related work reports conflicting findings: a dominant hypothesis based on image classification is that lower layers learn generalisable features and that deeper layers specialise and memorise. Work from NLP suggests this does not apply to language models, but has been mainly focused on memorisation of facts. We expand the scope of the localisation question to 12 natural language classification tasks and apply 4 memorisation localisation techniques. Our results indicate that memorisation is a gradual process rather than a localised one, establish that memorisation is task-dependent, and give nuance to the generalisation first, memorisation second hypothesis.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Published in ACL Findings 2024; 19 pages total (9 in the main paper, 4 pages with limitations, acknowledgments and references, 6 pages with appendices)"
    },
    {
        "paper id": "2408.04983",
        "abstract url": "https://arxiv.org/abs/2408.04983",
        "title": "Get Confused Cautiously: Textual Sequence Memorization Erasure with Selective Entropy Maximization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have been found to memorize and recite some of the textual sequences from their training set verbatim, raising broad concerns about privacy and copyright issues when using LLMs. This Textual Sequence Memorization (TSM) phenomenon leads to a high demand to regulate LLM output to prevent it from generating certain memorized text to meet user requirements. However, our empirical study reveals that existing methods for TSM erasure fail to forget massive memorized samples without substantially jeopardizing the model utility. To achieve a better trade-off between the effectiveness of TSM erasure and model utility in LLMs, our paper proposes a new framework based on Entropy Maximization with Selective Optimization (EMSO), where the updated weights are chosen with a novel contrastive gradient metric without any participation of additional model or data. Our analysis shows that training with the entropy maximization loss has a more stable optimization process and better keeps model utility than existing methods. The contrastive gradient metric localizes the most influential weight for TSM erasure by taking both the gradient magnitude and direction into consideration. Extensive experiments across three model scales demonstrate that our method excels in handling large-scale forgetting requests while preserving model ability in language generation and reasoning.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "15 pages, 7 figures"
    },
    {
        "paper id": "2408.04998",
        "abstract url": "https://arxiv.org/abs/2408.04998",
        "title": "ProFuser: Progressive Fusion of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "While fusing the capacities and advantages of various large language models (LLMs) offers a pathway to construct more powerful and versatile models, a fundamental challenge is to properly select advantageous model during the training. Existing fusion methods primarily focus on the training mode that uses cross entropy on ground truth in a teacher-forcing setup to measure a model's advantage, which may provide limited insight towards model advantage. In this paper, we introduce a novel approach that enhances the fusion process by incorporating both the training and inference modes. Our method evaluates model advantage not only through cross entropy during training but also by considering inference outputs, providing a more comprehensive assessment. To combine the two modes effectively, we introduce ProFuser to progressively transition from inference mode to training mode. To validate ProFuser's effectiveness, we fused three models, including vicuna-7b-v1.5, Llama-2-7b-chat, and mpt-7b-8k-chat, and demonstrated the improved performance in knowledge, reasoning, and safety compared to baseline methods.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05023",
        "abstract url": "https://arxiv.org/abs/2408.05023",
        "title": "Investigating a Benchmark for Training-set free Evaluation of Linguistic Capabilities in Machine Reading Comprehension",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Performance of NLP systems is typically evaluated by collecting a large-scale dataset by means of crowd-sourcing to train a data-driven model and evaluate it on a held-out portion of the data. This approach has been shown to suffer from spurious correlations and the lack of challenging examples that represent the diversity of natural language. Instead, we examine a framework for evaluating optimised models in training-set free setting on synthetically generated challenge sets. We find that despite the simplicity of the generation method, the data can compete with crowd-sourced datasets with regard to naturalness and lexical diversity for the purpose of evaluating the linguistic capabilities of MRC models. We conduct further experiments and show that state-of-the-art language model-based MRC systems can learn to succeed on the challenge set correctly, although, without capturing the general notion of the evaluated phenomenon.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05029",
        "abstract url": "https://arxiv.org/abs/2408.05029",
        "title": "Collaborative Static-Dynamic Teaching: A Semi-Supervised Framework for Stripe-Like Space Target Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Stripe-like space target detection (SSTD) is crucial for space situational awareness. Traditional unsupervised methods often fail in low signal-to-noise ratio and variable stripe-like space targets scenarios, leading to weak generalization. Although fully supervised learning methods improve model generalization, they require extensive pixel-level labels for training. In the SSTD task, manually creating these labels is often inaccurate and labor-intensive. Semi-supervised learning (SSL) methods reduce the need for these labels and enhance model generalizability, but their performance is limited by pseudo-label quality. To address this, we introduce an innovative Collaborative Static-Dynamic Teacher (CSDT) SSL framework, which includes static and dynamic teacher models as well as a student model. This framework employs a customized adaptive pseudo-labeling (APL) strategy, transitioning from initial static teaching to adaptive collaborative teaching, guiding the student model's training. The exponential moving average (EMA) mechanism further enhances this process by feeding new stripe-like knowledge back to the dynamic teacher model through the student model, creating a positive feedback loop that continuously enhances the quality of pseudo-labels. Moreover, we present MSSA-Net, a novel SSTD network featuring a multi-scale dual-path convolution (MDPC) block and a feature map weighted attention (FMWA) block, designed to extract diverse stripe-like features within the CSDT SSL training framework. Extensive experiments verify the state-of-the-art performance of our framework on the AstroStripeSet and various ground-based and space-based real-world datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05032",
        "abstract url": "https://arxiv.org/abs/2408.05032",
        "title": "Livestock Fish Larvae Counting using DETR and YOLO based Deep Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Counting fish larvae is an important, yet demanding and time consuming, task in aquaculture. In order to address this problem, in this work, we evaluate four neural network architectures, including convolutional neural networks and transformers, in different sizes, in the task of fish larvae counting. For the evaluation, we present a new annotated image dataset with less data collection requirements than preceding works, with images of spotted sorubim and dourado larvae. By using image tiling techniques, we achieve a MAPE of 4.46% ($\\pm 4.70$) with an extra large real time detection transformer, and 4.71% ($\\pm 4.98$) with a medium-sized YOLOv8.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05042",
        "abstract url": "https://arxiv.org/abs/2408.05042",
        "title": "Benchmarking Conventional and Learned Video Codecs with a Low-Delay Configuration",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recent advances in video compression have seen significant coding performance improvements with the development of new standards and learning-based video codecs. However, most of these works focus on application scenarios that allow a certain amount of system delay (e.g., Random Access mode in MPEG codecs), which is not always acceptable for live delivery. This paper conducts a comparative study of state-of-the-art conventional and learned video coding methods based on a low delay configuration. Specifically, this study includes two MPEG standard codecs (H.266/VVC VTM and JVET ECM), two AOM codecs (AV1 libaom and AVM), and two recent neural video coding models (DCVC-DC and DCVC-FM). To allow a fair and meaningful comparison, the evaluation was performed on test sequences defined in the AOM and MPEG common test conditions in the YCbCr 4:2:0 color space. The evaluation results show that the JVET ECM codecs offer the best overall coding performance among all codecs tested, with a 16.1% (based on PSNR) average BD-rate saving over AOM AVM, and 11.0% over DCVC-FM. We also observed inconsistent performance with the learned video codecs, DCVC-DC and DCVC-FM, for test content with large background motions.",
        "subjects": [
            "cs.MM",
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05056",
        "abstract url": "https://arxiv.org/abs/2408.05056",
        "title": "Multi-dimensional Parameter Space Exploration for Streamline-specific Tractography",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "One of the unspoken challenges of tractography is choosing the right parameters for a given dataset or bundle. In order to tackle this challenge, we explore the multi-dimensional parameter space of tractography using streamline-specific parameters (SSP). We 1) validate a state-of-the-art probabilistic tracking method using per-streamline parameters on synthetic data, and 2) show how we can gain insights into the parameter space by focusing on streamline acceptance using real-world data. We demonstrate the potential added value of SSP to the current state of tractography by showing how SSP can be used to reveal patterns in the parameter space.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted at MICCAI 2024 International Workshop on Computational Diffusion MRI"
    },
    {
        "paper id": "2408.05057",
        "abstract url": "https://arxiv.org/abs/2408.05057",
        "title": "SELD-Mamba: Selective State-Space Model for Sound Event Localization and Detection with Source Distance Estimation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In the Sound Event Localization and Detection (SELD) task, Transformer-based models have demonstrated impressive capabilities. However, the quadratic complexity of the Transformer's self-attention mechanism results in computational inefficiencies. In this paper, we propose a network architecture for SELD called SELD-Mamba, which utilizes Mamba, a selective state-space model. We adopt the Event-Independent Network V2 (EINV2) as the foundational framework and replace its Conformer blocks with bidirectional Mamba blocks to capture a broader range of contextual information while maintaining computational efficiency. Additionally, we implement a two-stage training method, with the first stage focusing on Sound Event Detection (SED) and Direction of Arrival (DoA) estimation losses, and the second stage reintroducing the Source Distance Estimation (SDE) loss. Our experimental results on the 2024 DCASE Challenge Task3 dataset demonstrate the effectiveness of the selective state-space model in SELD and highlight the benefits of the two-stage training approach in enhancing SELD performance.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05086",
        "abstract url": "https://arxiv.org/abs/2408.05086",
        "title": "Generating novel experimental hypotheses from language models: A case study on cross-dative generalization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Neural network language models (LMs) have been shown to successfully capture complex linguistic knowledge. However, their utility for understanding language acquisition is still debated. We contribute to this debate by presenting a case study where we use LMs as simulated learners to derive novel experimental hypotheses to be tested with humans. We apply this paradigm to study cross-dative generalization (CDG): productive generalization of novel verbs across dative constructions (she pilked me the ball/she pilked the ball to me) -- acquisition of which is known to involve a large space of contextual features -- using LMs trained on child-directed speech. We specifically ask: \"what properties of the training exposure facilitate a novel verb's generalization to the (unmodeled) alternate construction?\" To answer this, we systematically vary the exposure context in which a novel dative verb occurs in terms of the properties of the theme and recipient, and then analyze the LMs' usage of the novel verb in the unmodeled dative construction. We find LMs to replicate known patterns of children's CDG, as a precondition to exploring novel hypotheses. Subsequent simulations reveal a nuanced role of the features of the novel verbs' exposure context on the LMs' CDG. We find CDG to be facilitated when the first postverbal argument of the exposure context is pronominal, definite, short, and conforms to the prototypical animacy expectations of the exposure dative. These patterns are characteristic of harmonic alignment in datives, where the argument with features ranking higher on the discourse prominence scale tends to precede the other. This gives rise to a novel hypothesis that CDG is facilitated insofar as the features of the exposure context -- in particular, its first postverbal argument -- are harmonically aligned. We conclude by proposing future experiments that can test this hypothesis in children.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05094",
        "abstract url": "https://arxiv.org/abs/2408.05094",
        "title": "Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The task of multi-objective alignment aims at balancing and controlling the different alignment objectives (e.g., helpfulness, harmlessness and honesty) of large language models to meet the personalized requirements of different users. However, previous methods tend to train multiple models to deal with various user preferences, with the number of trained models growing linearly with the number of alignment objectives and the number of different preferences. Meanwhile, existing methods are generally poor in extensibility and require significant re-training for each new alignment objective considered. Considering the limitation of previous approaches, we propose MCA (Multi-objective Contrastive Alignemnt), which constructs an expert prompt and an adversarial prompt for each objective to contrast at the decoding time and balances the objectives through combining the contrast. Our approach is verified to be superior to previous methods in obtaining a well-distributed Pareto front among different alignment objectives.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05101",
        "abstract url": "https://arxiv.org/abs/2408.05101",
        "title": "MooER: LLM-based Speech Recognition and Translation Models from Moore Threads",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we present MooER, a LLM-based large-scale automatic speech recognition (ASR) / automatic speech translation (AST) model of Moore Threads. A 5000h pseudo labeled dataset containing open source and self collected speech data is used for training. We achieve performance comparable to other open source models trained with up to hundreds of thousands of hours of labeled speech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggest that our model outperforms other open source Speech LLMs. A BLEU score of 25.2 can be obtained. The main contributions of this paper are summarized as follows. First, this paper presents a training strategy for encoders and LLMs on speech related tasks (including ASR and AST) using a small size of pseudo labeled data without any extra manual annotation and selection. Second, we release our ASR and AST models and plan to open-source our training code and strategy in the near future. Moreover, a model trained on 8wh scale training data is planned to be released later on.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05102",
        "abstract url": "https://arxiv.org/abs/2408.05102",
        "title": "How Well Do LLMs Identify Cultural Unity in Diversity?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Much work on the cultural awareness of large language models (LLMs) focuses on the models' sensitivity to geo-cultural diversity. However, in addition to cross-cultural differences, there also exists common ground across cultures. For instance, a bridal veil in the United States plays a similar cultural-relevant role as a honggaitou in China. In this study, we introduce a benchmark dataset CUNIT for evaluating decoder-only LLMs in understanding the cultural unity of concepts. Specifically, CUNIT consists of 1,425 evaluation examples building upon 285 traditional cultural-specific concepts across 10 countries. Based on a systematic manual annotation of cultural-relevant features per concept, we calculate the cultural association between any pair of cross-cultural concepts. Built upon this dataset, we design a contrastive matching task to evaluate the LLMs' capability to identify highly associated cross-cultural concept pairs. We evaluate 3 strong LLMs, using 3 popular prompting strategies, under the settings of either giving all extracted concept features or no features at all on CUNIT Interestingly, we find that cultural associations across countries regarding clothing concepts largely differ from food. Our analysis shows that LLMs are still limited to capturing cross-cultural associations between concepts compared to humans. Moreover, geo-cultural proximity shows a weak influence on model performance in capturing cross-cultural associations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "COLM 2024"
    },
    {
        "paper id": "2408.05126",
        "abstract url": "https://arxiv.org/abs/2408.05126",
        "title": "Large Language Models and Thematic Analysis: Human-AI Synergy in Researching Hate Speech on Social Media",
        "rating": "1",
        "keywords": [
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "In the dynamic field of artificial intelligence (AI), the development and application of Large Language Models (LLMs) for text analysis are of significant academic interest. Despite the promising capabilities of various LLMs in conducting qualitative analysis, their use in the humanities and social sciences has not been thoroughly examined. This article contributes to the emerging literature on LLMs in qualitative analysis by documenting an experimental study involving GPT-4. The study focuses on performing thematic analysis (TA) using a YouTube dataset derived from an EU-funded project, which was previously analyzed by other researchers. This dataset is about the representation of Roma migrants in Sweden during 2016, a period marked by the aftermath of the 2015 refugee crisis and preceding the Swedish national elections in 2017. Our study seeks to understand the potential of combining human intelligence with AI's scalability and efficiency, examining the advantages and limitations of employing LLMs in qualitative research within the humanities and social sciences. Additionally, we discuss future directions for applying LLMs in these fields.",
        "subjects": [
            "cs.HC",
            "cs.CL",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05146",
        "abstract url": "https://arxiv.org/abs/2408.05146",
        "title": "Performative Prediction on Games and Mechanism Design",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Predictions often influence the reality which they aim to predict, an effect known as performativity. Existing work focuses on accuracy maximization under this effect, but model deployment may have important unintended impacts, especially in multiagent scenarios. In this work, we investigate performative prediction in a concrete game-theoretic setting where social welfare is an alternative objective to accuracy maximization. We explore a collective risk dilemma scenario where maximising accuracy can negatively impact social welfare, when predicting collective behaviours. By assuming knowledge of a Bayesian agent behavior model, we then show how to achieve better trade-offs and use them for mechanism design.",
        "subjects": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ],
        "comment": "Accepted to ICML 2024 Workshop on Agentic Markets, Vienna, Austria"
    },
    {
        "paper id": "2408.05147",
        "abstract url": "https://arxiv.org/abs/2408.05147",
        "title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse decomposition of a neural network's latent representations into seemingly interpretable features. Despite recent excitement about their potential, research applications outside of industry are limited by the high cost of training a comprehensive suite of SAEs. In this work, we introduce Gemma Scope, an open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2 2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs on the Gemma 2 pre-trained models, but additionally release SAEs trained on instruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each SAE on standard metrics and release these results. We hope that by releasing these SAE weights, we can help make more ambitious safety and interpretability research easier for the community. Weights and a tutorial can be found at https://huggingface.co/google/gemma-scope and an interactive demo can be found at https://www.neuronpedia.org/gemma-scope",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "12 main text pages, and 14 pages of acknowledgements, references and appendices"
    },
    {
        "paper id": "2408.05159",
        "abstract url": "https://arxiv.org/abs/2408.05159",
        "title": "EasyInv: Toward Fast and Better DDIM Inversion",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces EasyInv, an easy yet novel approach that significantly advances the field of DDIM Inversion by addressing the inherent inefficiencies and performance limitations of traditional iterative optimization methods. At the core of our EasyInv is a refined strategy for approximating inversion noise, which is pivotal for enhancing the accuracy and reliability of the inversion process. By prioritizing the initial latent state, which encapsulates rich information about the original images, EasyInv steers clear of the iterative refinement of noise items. Instead, we introduce a methodical aggregation of the latent state from the preceding time step with the current state, effectively increasing the influence of the initial latent state and mitigating the impact of noise. We illustrate that EasyInv is capable of delivering results that are either on par with or exceed those of the conventional DDIM Inversion approach, especially under conditions where the model's precision is limited or computational resources are scarce. Concurrently, our EasyInv offers an approximate threefold enhancement regarding inference efficiency over off-the-shelf iterative optimization techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages not including reference"
    },
    {
        "paper id": "2408.05169",
        "abstract url": "https://arxiv.org/abs/2408.05169",
        "title": "Weak-Annotation of HAR Datasets using Vision Foundation Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "As wearable-based data annotation remains, to date, a tedious, time-consuming task requiring researchers to dedicate substantial time, benchmark datasets within the field of Human Activity Recognition in lack richness and size compared to datasets available within related fields. Recently, vision foundation models such as CLIP have gained significant attention, helping the vision community advance in finding robust, generalizable feature representations. With the majority of researchers within the wearable community relying on vision modalities to overcome the limited expressiveness of wearable data and accurately label their to-be-released benchmark datasets offline, we propose a novel, clustering-based annotation pipeline to significantly reduce the amount of data that needs to be annotated by a human annotator. We show that using our approach, the annotation of centroid clips suffices to achieve average labelling accuracies close to 90% across three publicly available HAR benchmark datasets. Using the weakly annotated datasets, we further demonstrate that we can match the accuracy scores of fully-supervised deep learning classifiers across all three benchmark datasets. Code as well as supplementary figures and results are publicly downloadable via github.com/mariusbock/weak_har.",
        "subjects": [
            "cs.HC",
            "cs.CV"
        ],
        "comment": "8 pages, 3 figures, accepted at ISWC'24: International Symposium on Wearable Computers, Oct, 2024"
    },
    {
        "paper id": "2408.05184",
        "abstract url": "https://arxiv.org/abs/2408.05184",
        "title": "Deep-change at AXOLOTL-24: Orchestrating WSD and WSI Models for Semantic Change Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper describes our solution of the first subtask from the AXOLOTL-24 shared task on Semantic Change Modeling. The goal of this subtask is to distribute a given set of usages of a polysemous word from a newer time period between senses of this word from an older time period and clusters representing gained senses of this word. We propose and experiment with three new methods solving this task. Our methods achieve SOTA results according to both official metrics of the first substask. Additionally, we develop a model that can tell if a given word usage is not described by any of the provided sense definitions. This model serves as a component in one of our methods, but can potentially be useful on its own.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05192",
        "abstract url": "https://arxiv.org/abs/2408.05192",
        "title": "Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The task of deciding whether two documents are written by the same author is challenging for both machines and humans. This task is even more challenging when the two documents are written about different topics (e.g. baseball vs. politics) or in different genres (e.g. a blog post vs. an academic article). For machines, the problem is complicated by the relative lack of real-world training examples that cross the topic boundary and the vanishing scarcity of cross-genre data. We propose targeted methods for training data selection and a novel learning curriculum that are designed to discourage a model's reliance on topic information for authorship attribution and correspondingly force it to incorporate information more robustly indicative of style no matter the topic. These refinements yield a 62.7% relative improvement in average cross-genre authorship attribution, as well as 16.6% in the per-genre condition.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05204",
        "abstract url": "https://arxiv.org/abs/2408.05204",
        "title": "Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs), including OpenAI's GPT-series, have made significant advancements in recent years. Known for their expertise across diverse subject areas and quick adaptability to user-provided prompts, LLMs hold unique potential as Personalized Learning (PL) tools. Despite this potential, their application in K-12 education remains largely unexplored. This paper presents one of the first randomized controlled trials (n = 23) to evaluate the effectiveness of GPT-4 in personalizing educational science texts for middle school students. In this study, GPT-4 was used to profile student learning preferences based on choices made during a training session. For the experimental group, GPT-4 was used to rewrite science texts to align with the student's predicted profile while, for students in the control group, texts were rewritten to contradict their learning preferences. The results of a Mann-Whitney U test showed that students significantly preferred (at the .10 level) the rewritten texts when they were aligned with their profile (p = .059). These findings suggest that GPT-4 can effectively interpret and tailor educational content to diverse learner preferences, marking a significant advancement in PL technology. The limitations of this study and ethical considerations for using artificial intelligence in education are also discussed.",
        "subjects": [
            "cs.HC",
            "cs.CL",
            "cs.CY"
        ],
        "comment": "20 pages, 3 figures"
    },
    {
        "paper id": "2408.05211",
        "abstract url": "https://arxiv.org/abs/2408.05211",
        "title": "VITA: Towards Open-Source Interactive Omni Multimodal LLM",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "The remarkable multimodal capabilities and interactive experience of GPT-4o underscore their necessity in practical applications, yet open-source models rarely excel in both areas. In this paper, we introduce VITA, the first-ever open-source Multimodal Large Language Model (MLLM) adept at simultaneous processing and analysis of Video, Image, Text, and Audio modalities, and meanwhile has an advanced multimodal interactive experience. Starting from Mixtral 8x7B as a language foundation, we expand its Chinese vocabulary followed by bilingual instruction tuning. We further endow the language model with visual and audio capabilities through two-stage multi-task learning of multimodal alignment and instruction tuning. VITA demonstrates robust foundational capabilities of multilingual, vision, and audio understanding, as evidenced by its strong performance across a range of both unimodal and multimodal benchmarks. Beyond foundational capabilities, we have made considerable progress in enhancing the natural multimodal human-computer interaction experience. To the best of our knowledge, we are the first to exploit non-awakening interaction and audio interrupt in MLLM. VITA is the first step for the open-source community to explore the seamless integration of multimodal understanding and interaction. While there is still lots of work to be done on VITA to get close to close-source counterparts, we hope that its role as a pioneer can serve as a cornerstone for subsequent research. Project Page: https://vita-home.github.io.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Project Page: https://vita-home.github.io"
    },
    {
        "paper id": "2408.05288",
        "abstract url": "https://arxiv.org/abs/2408.05288",
        "title": "The impact of internal variability on benchmarking deep learning climate emulators",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Full-complexity Earth system models (ESMs) are computationally very expensive, limiting their use in exploring the climate outcomes of multiple emission pathways. More efficient emulators that approximate ESMs can directly map emissions onto climate outcomes, and benchmarks are being used to evaluate their accuracy on standardized tasks and datasets. We investigate a popular benchmark in data-driven climate emulation, ClimateBench, on which deep learning-based emulators are currently achieving the best performance. We implement a linear regression-based emulator, akin to pattern scaling, and find that it outperforms the incumbent 100M-parameter deep learning foundation model, ClimaX, on 3 out of 4 regionally-resolved surface-level climate variables. While emulating surface temperature is expected to be predominantly linear, this result is surprising for emulating precipitation. We identify that this outcome is a result of high levels of internal variability in the benchmark targets. To address internal variability, we update the benchmark targets with ensemble averages from the MPI-ESM1.2-LR model that contain 50 instead of 3 climate simulations per emission pathway. Using the new targets, we show that linear pattern scaling continues to be more accurate on temperature, but can be outperformed by a deep learning-based model for emulating precipitation. We publish our code, data, and an interactive tutorial at github.com/blutjens/climate-emulator.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05321",
        "abstract url": "https://arxiv.org/abs/2408.05321",
        "title": "A Recurrent YOLOv8-based framework for Event-Based Object Detection",
        "rating": "1",
        "keywords": [
            [
                "memory-efficient"
            ],
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Object detection is crucial in various cutting-edge applications, such as autonomous vehicles and advanced robotics systems, primarily relying on data from conventional frame-based RGB sensors. However, these sensors often struggle with issues like motion blur and poor performance in challenging lighting conditions. In response to these challenges, event-based cameras have emerged as an innovative paradigm. These cameras, mimicking the human eye, demonstrate superior performance in environments with fast motion and extreme lighting conditions while consuming less power. This study introduces ReYOLOv8, an advanced object detection framework that enhances a leading frame-based detection system with spatiotemporal modeling capabilities. We implemented a low-latency, memory-efficient method for encoding event data to boost the system's performance. We also developed a novel data augmentation technique tailored to leverage the unique attributes of event data, thus improving detection accuracy. Our models outperformed all comparable approaches in the GEN1 dataset, focusing on automotive applications, achieving mean Average Precision (mAP) improvements of 5%, 2.8%, and 2.5% across nano, small, and medium scales, respectively.These enhancements were achieved while reducing the number of trainable parameters by an average of 4.43% and maintaining real-time processing speeds between 9.2ms and 15.5ms. On the PEDRo dataset, which targets robotics applications, our models showed mAP improvements ranging from 9% to 18%, with 14.5x and 3.8x smaller models and an average speed enhancement of 1.67x.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05326",
        "abstract url": "https://arxiv.org/abs/2408.05326",
        "title": "A Psychology-based Unified Dynamic Framework for Curriculum Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Directly learning from examples of random difficulty levels is often challenging for both humans and machine learning models. A more effective strategy involves exposing learners to examples in a progressive order, from easy to difficult. Curriculum Learning (CL) has been proposed to implement this strategy in machine learning model training. However, two key challenges persist in CL framework design: defining the difficulty of training data and determining the appropriate amount of data to input at each training step. This paper presents a Psychology-based Unified Dynamic Framework for Curriculum Learning (PUDF), drawing inspiration from psychometrics. We quantify the difficulty of training data by applying Item Response Theory (IRT) to responses from Artificial Crowds (AC). This theory-driven IRT-AC approach leads to global (i.e., model-independent) and interpretable difficulty values. Leveraging IRT, we propose a Dynamic Data Selection via Model Ability Estimation (DDS-MAE) strategy to schedule the appropriate amount of data during model training. Since our difficulty labeling and model ability estimation are based on a consistent theory, namely IRT, their values are comparable within the same scope, potentially leading to a faster convergence compared to the other CL methods. Experimental results demonstrate that fine-tuning pre-trained language models with PUDF enhances their performance on the GLUE benchmark. Moreover, PUDF surpasses other state-of-the-art (SOTA) CL methods on the GLUE benchmark. We further explore the components of PUDF, namely the difficulty measurer (IRT-AC) and the training scheduler (DDS-MAE) qualitatively and quantitatively. Lastly, we conduct an ablation study to clarify which components of PUDF contribute to faster convergence and higher accuracy.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05328",
        "abstract url": "https://arxiv.org/abs/2408.05328",
        "title": "From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study explores the potential of Large Language Models (LLMs), specifically GPT-4, to enhance objectivity in organizational task performance evaluations. Through comparative analyses across two studies, including various task performance outputs, we demonstrate that LLMs can serve as a reliable and even superior alternative to human raters in evaluating knowledge-based performance outputs, which are a key contribution of knowledge workers. Our results suggest that GPT ratings are comparable to human ratings but exhibit higher consistency and reliability. Additionally, combined multiple GPT ratings on the same performance output show strong correlations with aggregated human performance ratings, akin to the consensus principle observed in performance evaluation literature. However, we also find that LLMs are prone to contextual biases, such as the halo effect, mirroring human evaluative biases. Our research suggests that while LLMs are capable of extracting meaningful constructs from text-based data, their scope is currently limited to specific forms of performance evaluation. By highlighting both the potential and limitations of LLMs, our study contributes to the discourse on AI role in management studies and sets a foundation for future research to refine AI theoretical and practical applications in management.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.ET",
            "cs.HC",
            "econ.GN"
        ],
        "comment": "39 pages, 8 figures, 5 tables"
    },
    {
        "paper id": "2408.05334",
        "abstract url": "https://arxiv.org/abs/2408.05334",
        "title": "Revisiting Multi-Modal LLM Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "With the advent of multi-modal large language models (MLLMs), datasets used for visual question answering (VQA) and referring expression comprehension have seen a resurgence. However, the most popular datasets used to evaluate MLLMs are some of the earliest ones created, and they have many known problems, including extreme bias, spurious correlations, and an inability to permit fine-grained analysis. In this paper, we pioneer evaluating recent MLLMs (LLaVA 1.5, LLaVA-NeXT, BLIP2, InstructBLIP, GPT-4V, and GPT-4o) on datasets designed to address weaknesses in earlier ones. We assess three VQA datasets: 1) TDIUC, which permits fine-grained analysis on 12 question types; 2) TallyQA, which has simple and complex counting questions; and 3) DVQA, which requires optical character recognition for chart understanding. We also study VQDv1, a dataset that requires identifying all image regions that satisfy a given query. Our experiments reveal the weaknesses of many MLLMs that have not previously been reported. Our code is integrated into the widely used LAVIS framework for MLLM evaluation, enabling the rapid assessment of future MLLMs. Project webpage: https://kevinlujian.github.io/MLLM_Evaluations/",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05346",
        "abstract url": "https://arxiv.org/abs/2408.05346",
        "title": "DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Data-driven storytelling is a powerful method for conveying insights by combining narrative techniques with visualizations and text. These stories integrate visual aids, such as highlighted bars and lines in charts, along with textual annotations explaining insights. However, creating such stories requires a deep understanding of the data and meticulous narrative planning, often necessitating human intervention, which can be time-consuming and mentally taxing. While Large Language Models (LLMs) excel in various NLP tasks, their ability to generate coherent and comprehensive data stories remains underexplored. In this work, we introduce a novel task for data story generation and a benchmark containing 1,449 stories from diverse sources. To address the challenges of crafting coherent data stories, we propose a multiagent framework employing two LLM agents designed to replicate the human storytelling process: one for understanding and describing the data (Reflection), generating the outline, and narration, and another for verification at each intermediary step. While our agentic framework generally outperforms non-agentic counterparts in both model-based and human evaluations, the results also reveal unique challenges in data story generation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05409",
        "abstract url": "https://arxiv.org/abs/2408.05409",
        "title": "RSL-BA: Rolling Shutter Line Bundle Adjustment",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The line is a prevalent element in man-made environments, inherently encoding spatial structural information, thus making it a more robust choice for feature representation in practical applications. Despite its apparent advantages, previous rolling shutter bundle adjustment (RSBA) methods have only supported sparse feature points, which lack robustness, particularly in degenerate environments. In this paper, we introduce the first rolling shutter line-based bundle adjustment solution, RSL-BA. Specifically, we initially establish the rolling shutter camera line projection theory utilizing Pl\u00fccker line parameterization. Subsequently, we derive a series of reprojection error formulations which are stable and efficient. Finally, we theoretically and experimentally demonstrate that our method can prevent three common degeneracies, one of which is first discovered in this paper. Extensive synthetic and real data experiments demonstrate that our method achieves efficiency and accuracy comparable to existing point-based rolling shutter bundle adjustment solutions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04869",
        "abstract url": "https://arxiv.org/abs/2408.04869",
        "title": "UCB Exploration for Fixed-Budget Bayesian Best Arm Identification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study best-arm identification (BAI) in the fixed-budget setting. Adaptive allocations based on upper confidence bounds (UCBs), such as UCBE, are known to work well in BAI. However, it is well-known that its optimal regret is theoretically dependent on instances, which we show to be an artifact in many fixed-budget BAI problems. In this paper we propose an UCB exploration algorithm that is both theoretically and empirically efficient for the fixed budget BAI problem under a Bayesian setting. The key idea is to learn prior information, which can enhance the performance of UCB-based BAI algorithm as it has done in the cumulative regret minimization problem. We establish bounds on the failure probability and the simple regret for the Bayesian BAI problem, providing upper bounds of order $\\tilde{O}(\\sqrt{K/n})$, up to logarithmic factors, where $n$ represents the budget and $K$ denotes the number of arms. Furthermore, we demonstrate through empirical results that our approach consistently outperforms state-of-the-art baselines.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04903",
        "abstract url": "https://arxiv.org/abs/2408.04903",
        "title": "Axiomatic Characterisations of Sample-based Explainers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Explaining decisions of black-box classifiers is both important and computationally challenging. In this paper, we scrutinize explainers that generate feature-based explanations from samples or datasets. We start by presenting a set of desirable properties that explainers would ideally satisfy, delve into their relationships, and highlight incompatibilities of some of them. We identify the entire family of explainers that satisfy two key properties which are compatible with all the others. Its instances provide sufficient reasons, called weak abductive explanations.We then unravel its various subfamilies that satisfy subsets of compatible properties. Indeed, we fully characterize all the explainers that satisfy any subset of compatible properties. In particular, we introduce the first (broad family of) explainers that guarantee the existence of explanations and their global consistency.We discuss some of its instances including the irrefutable explainer and the surrogate explainer whose explanations can be found in polynomial time.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04907",
        "abstract url": "https://arxiv.org/abs/2408.04907",
        "title": "Causal Discovery of Linear Non-Gaussian Causal Models with Unobserved Confounding",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider linear non-Gaussian structural equation models that involve latent confounding. In this setting, the causal structure is identifiable, but, in general, it is not possible to identify the specific causal effects. Instead, a finite number of different causal effects result in the same observational distribution. Most existing algorithms for identifying these causal effects use overcomplete independent component analysis (ICA), which often suffers from convergence to local optima. Furthermore, the number of latent variables must be known a priori. To address these issues, we propose an algorithm that operates recursively rather than using overcomplete ICA. The algorithm first infers a source, estimates the effect of the source and its latent parents on their descendants, and then eliminates their influence from the data. For both source identification and effect size estimation, we use rank conditions on matrices formed from higher-order cumulants. We prove asymptotic correctness under the mild assumption that locally, the number of latent variables never exceeds the number of observed variables. Simulation studies demonstrate that our method achieves comparable performance to overcomplete ICA even though it does not know the number of latents in advance.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04911",
        "abstract url": "https://arxiv.org/abs/2408.04911",
        "title": "A Geometric Nash Approach in Tuning the Learning Rate in Q-Learning Algorithm",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes a geometric approach for estimating the $\u03b1$ value in Q learning. We establish a systematic framework that optimizes the \u03b1 parameter, thereby enhancing learning efficiency and stability. Our results show that there is a relationship between the learning rate and the angle between a vector T (total time steps in each episode of learning) and R (the reward vector for each episode). The concept of angular bisector between vectors T and R and Nash Equilibrium provide insight into estimating $\u03b1$ such that the algorithm minimizes losses arising from exploration-exploitation trade-off.",
        "subjects": [
            "cs.LG",
            "cs.GT",
            "econ.TH",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04933",
        "abstract url": "https://arxiv.org/abs/2408.04933",
        "title": "Variance-based sensitivity analysis in the presence of correlated input variables",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper we propose an extension of the classical Sobol' estimator for the estimation of variance based sensitivity indices. The approach assumes a linear correlation model between the input variables which is used to decompose the contribution of an input variable into a correlated and an uncorrelated part. This method provides sampling matrices following the original joint probability distribution which are used directly to compute the model output without any assumptions or approximations of the model response function.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": "presented at 5th International Conference on Reliable Engineering Computing (REC), Brno, Czech Republic, 13-15 June, 2012"
    },
    {
        "paper id": "2408.05006",
        "abstract url": "https://arxiv.org/abs/2408.05006",
        "title": "Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Debugging is a vital aspect of software development, yet the debugging capabilities of Large Language Models (LLMs) remain largely unexplored. This paper first introduces DEBUGEVAL, a comprehensive benchmark designed to evaluate the debugging capabilities of LLMs. DEBUGEVAL collects data from existing high-quality datasets and designs four different tasks to evaluate the debugging effectiveness, including BUG Localization, BUG Identification, Code Review, and Code Repair. Additionally, to enhance the code debugging ability of LLMs, this paper proposes a CoMmunicative Agent BaSed DaTa REfinement FRamework (MASTER), which generates the refined code debugging data for supervised finetuning. Specifically, MASTER employs the Code Quizzer to generate refined data according to the defined tasks of DEBUGEVAL. Then the Code Learner acts as a critic and reserves the generated problems that it can not solve. Finally, the Code Teacher provides a detailed Chain-of-Thought based solution to deal with the generated problem. We collect the synthesized data and finetune the Code Learner to enhance the debugging ability and conduct the NeuDebugger model. Our experiments evaluate various LLMs and NeuDebugger in the zero-shot setting on DEBUGEVAL. Experimental results demonstrate that these 7B-scale LLMs have weaker debugging capabilities, even these code-oriented LLMs. On the contrary, these larger models (over 70B) show convincing debugging ability. Our further analyses illustrate that MASTER is an effective method to enhance the code debugging ability by synthesizing data for Supervised Fine-Tuning (SFT) LLMs.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05019",
        "abstract url": "https://arxiv.org/abs/2408.05019",
        "title": "Instruction Tuning-free Visual Token Complement for Multimodal LLMs",
        "rating": "0.5",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "As the open community of large language models (LLMs) matures, multimodal LLMs (MLLMs) have promised an elegant bridge between vision and language. However, current research is inherently constrained by challenges such as the need for high-quality instruction pairs and the loss of visual information in image-to-text training objectives. To this end, we propose a Visual Token Complement framework (VTC) that helps MLLMs regain the missing visual features and thus improve response accuracy. Specifically, our VTC integrates text-to-image generation as a guide to identifying the text-irrelevant features, and a visual selector is then developed to generate complementary visual tokens to enrich the original visual input. Moreover, an iterative strategy is further designed to extract more visual information by iteratively using the visual selector without any additional training. Notably, the training pipeline requires no additional image-text pairs, resulting in a desired instruction tuning-free property. Both qualitative and quantitative experiments demonstrate the superiority and efficiency of our VTC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV2024 (20pages)"
    },
    {
        "paper id": "2408.05026",
        "abstract url": "https://arxiv.org/abs/2408.05026",
        "title": "Retrieval-augmented code completion for local projects using large language models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The use of large language models (LLMs) is becoming increasingly widespread among software developers. However, privacy and computational requirements are problematic with commercial solutions and the use of LLMs. In this work, we focus on using LLMs with around 160 million parameters that are suitable for local execution and augmentation with retrieval from local projects. We train two models based on the transformer architecture, the generative model GPT-2 and the retrieval-adapted RETRO model, on open-source Python files, and empirically evaluate and compare them, confirming the benefits of vector embedding based retrieval. Further, we improve our models' performance with In-context retrieval-augmented generation, which retrieves code snippets based on the Jaccard similarity of tokens. We evaluate In-context retrieval-augmented generation on larger models and conclude that, despite its simplicity, the approach is more suitable than using the RETRO architecture. We highlight the key role of proper tokenization in achieving the full potential of LLMs in code completion.",
        "subjects": [
            "cs.SE",
            "cs.LG"
        ],
        "comment": "28 pages, 14 figures"
    },
    {
        "paper id": "2408.05060",
        "abstract url": "https://arxiv.org/abs/2408.05060",
        "title": "GLEAMS: Bridging the Gap Between Local and Global Explanations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The explainability of machine learning algorithms is crucial, and numerous methods have emerged recently. Local, post-hoc methods assign an attribution score to each feature, indicating its importance for the prediction. However, these methods require recalculating explanations for each example. On the other side, while there exist global approaches they often produce explanations that are either overly simplistic and unreliable or excessively complex. To bridge this gap, we propose GLEAMS, a novel method that partitions the input space and learns an interpretable model within each sub-region, thereby providing both faithful local and global surrogates. We demonstrate GLEAMS' effectiveness on both synthetic and real-world data, highlighting its desirable properties and human-understandable insights.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05082",
        "abstract url": "https://arxiv.org/abs/2408.05082",
        "title": "Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Overfitting commonly occurs when applying deep neural networks (DNNs) on small-scale datasets, where DNNs do not generalize well from existing data to unseen data. The main reason resulting in overfitting is that small-scale datasets cannot reflect the situations of the real world. Label smoothing (LS) is an effective regularization method to prevent overfitting, avoiding it by mixing one-hot labels with uniform label vectors. However, LS only focuses on labels while ignoring the distribution of existing data. In this paper, we introduce the distributionally robust optimization (DRO) to LS, achieving shift the existing data distribution flexibly to unseen domains when training DNNs. Specifically, we prove that the regularization of LS can be extended to a regularization term for the DNNs parameters when integrating DRO. The regularization term can be utilized to shift existing data to unseen domains and generate new data. Furthermore, we propose an approximate gradient-iteration label smoothing algorithm (GI-LS) to achieve the findings and train DNNs. We prove that the shift for the existing data does not influence the convergence of GI-LS. Since GI-LS incorporates a series of hyperparameters, we further consider using Bayesian optimization (BO) to find the relatively optimal combinations of these hyperparameters. Taking small-scale anomaly classification tasks as a case, we evaluate GI-LS, and the results clearly demonstrate its superior performance.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05098",
        "abstract url": "https://arxiv.org/abs/2408.05098",
        "title": "Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Currently, neural-network processing in machine learning applications relies on layer synchronization, whereby neurons in a layer aggregate incoming currents from all neurons in the preceding layer, before evaluating their activation function. This is practiced even in artificial Spiking Neural Networks (SNNs), which are touted as consistent with neurobiology, in spite of processing in the brain being, in fact asynchronous. A truly asynchronous system however would allow all neurons to evaluate concurrently their threshold and emit spikes upon receiving any presynaptic current. Omitting layer synchronization is potentially beneficial, for latency and energy efficiency, but asynchronous execution of models previously trained with layer synchronization may entail a mismatch in network dynamics and performance. We present a study that documents and quantifies this problem in three datasets on our simulation environment that implements network asynchrony, and we show that models trained with layer synchronization either perform sub-optimally in absence of the synchronization, or they will fail to benefit from any energy and latency reduction, when such a mechanism is in place. We then \"make ends meet\" and address the problem with unlayered backprop, a novel backpropagation-based training method, for learning models suitable for asynchronous processing. We train with it models that use different neuron execution scheduling strategies, and we show that although their neurons are more reactive, these models consistently exhibit lower overall spike density (up to 50%), reach a correct decision faster (up to 2x) without integrating all spikes, and achieve superior accuracy (up to 10% higher). Our findings suggest that asynchronous event-based (neuromorphic) AI computing is indeed more efficient, but we need to seriously rethink how we train our SNN models, to benefit from it.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05100",
        "abstract url": "https://arxiv.org/abs/2408.05100",
        "title": "AI-driven Java Performance Testing: Balancing Result Quality with Testing Time",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Performance testing aims at uncovering efficiency issues of software systems. In order to be both effective and practical, the design of a performance test must achieve a reasonable trade-off between result quality and testing time. This becomes particularly challenging in Java context, where the software undergoes a warm-up phase of execution, due to just-in-time compilation. During this phase, performance measurements are subject to severe fluctuations, which may adversely affect quality of performance test results. However, these approaches often provide suboptimal estimates of the warm-up phase, resulting in either insufficient or excessive warm-up iterations, which may degrade result quality or increase testing time. There is still a lack of consensus on how to properly address this problem. Here, we propose and study an AI-based framework to dynamically halt warm-up iterations at runtime. Specifically, our framework leverages recent advances in AI for Time Series Classification (TSC) to predict the end of the warm-up phase during test execution. We conduct experiments by training three different TSC models on half a million of measurement segments obtained from JMH microbenchmark executions. We find that our framework significantly improves the accuracy of the warm-up estimates provided by state-of-practice and state-of-the-art methods. This higher estimation accuracy results in a net improvement in either result quality or testing time for up to +35.3% of the microbenchmarks. Our study highlights that integrating AI to dynamically estimate the end of the warm-up phase can enhance the cost-effectiveness of Java performance testing.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.LG",
            "cs.PF"
        ],
        "comment": "Accepted for publication in The 39th IEEE/ACM International Conference on Automated Software Engineering (ASE '24)"
    },
    {
        "paper id": "2408.05120",
        "abstract url": "https://arxiv.org/abs/2408.05120",
        "title": "Cautious Calibration in Binary Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Being cautious is crucial for enhancing the trustworthiness of machine learning systems integrated into decision-making pipelines. Although calibrated probabilities help in optimal decision-making, perfect calibration remains unattainable, leading to estimates that fluctuate between under- and overconfidence. This becomes a critical issue in high-risk scenarios, where even occasional overestimation can lead to extreme expected costs. In these scenarios, it is important for each predicted probability to lean towards underconfidence, rather than just achieving an average balance. In this study, we introduce the novel concept of cautious calibration in binary classification. This approach aims to produce probability estimates that are intentionally underconfident for each predicted probability. We highlight the importance of this approach in a high-risk scenario and propose a theoretically grounded method for learning cautious calibration maps. Through experiments, we explore and compare our method to various approaches, including methods originally not devised for cautious calibration but applicable in this context. We show that our approach is the most consistent in providing cautious estimates. Our work establishes a strong baseline for further developments in this novel framework.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to ECAI 2024"
    },
    {
        "paper id": "2408.05148",
        "abstract url": "https://arxiv.org/abs/2408.05148",
        "title": "Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Run-by-run variability in parallel programs caused by floating-point non-associativity (FPNA) has been known to significantly affect reproducibility in iterative algorithms, due to accumulating errors. Non-reproducibility negatively affects efficiency and effectiveness of correctness testing for stochastic programs. Recently, the sensitivity of deep learning (DL) training and inference pipelines to FPNA have been found to be extreme, and can prevent certification for commercial applications, accurate assessment of robustness and sensitivity, and bug detection. New approaches in scientific computing applications have coupled DL models with high-performance computing (HPC) simulations, leading to an aggravation of debugging and testing challenges. Here we perform an investigation of the statistical properties of FPNA within modern parallel programming models, analyze performance and productivity impacts of replacing atomic operations with deterministic alternatives on GPUs, and examine the recently-added deterministic options within the PyTorch framework within the context of GPU deployment, uncovering and quantifying the impacts of input parameters triggering run-by-run variability and reporting on the reliability and completeness of the documentation. Finally, we evaluate the strategy of exploiting automatic determinism provided by deterministic hardware, using the Groq LPU$^{TM}$ accelerator for inference portions of the DL pipeline. We demonstrate the benefits that this strategy can provide within reproducibility and correctness efforts.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05284",
        "abstract url": "https://arxiv.org/abs/2408.05284",
        "title": "Can a Bayesian Oracle Prevent Harm from an Agent?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Is there a way to design powerful AI systems based on machine learning methods that would satisfy probabilistic safety guarantees? With the long-term goal of obtaining a probabilistic guarantee that would apply in every context, we consider estimating a context-dependent bound on the probability of violating a given safety specification. Such a risk evaluation would need to be performed at run-time to provide a guardrail against dangerous actions of an AI. Noting that different plausible hypotheses about the world could produce very different outcomes, and because we do not know which one is right, we derive bounds on the safety violation probability predicted under the true but unknown hypothesis. Such bounds could be used to reject potentially dangerous actions. Our main results involve searching for cautious but plausible hypotheses, obtained by a maximization that involves Bayesian posteriors over hypotheses. We consider two forms of this result, in the iid case and in the non-iid case, and conclude with open problems towards turning such theoretical results into practical AI guardrails.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05285",
        "abstract url": "https://arxiv.org/abs/2408.05285",
        "title": "Semi-Supervised One-Shot Imitation Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "One-shot Imitation Learning~(OSIL) aims to imbue AI agents with the ability to learn a new task from a single demonstration. To supervise the learning, OSIL typically requires a prohibitively large number of paired expert demonstrations -- i.e. trajectories corresponding to different variations of the same semantic task. To overcome this limitation, we introduce the semi-supervised OSIL problem setting, where the learning agent is presented with a large dataset of trajectories with no task labels (i.e. an unpaired dataset), along with a small dataset of multiple demonstrations per semantic task (i.e. a paired dataset). This presents a more realistic and practical embodiment of few-shot learning and requires the agent to effectively leverage weak supervision from a large dataset of trajectories. Subsequently, we develop an algorithm specifically applicable to this semi-supervised OSIL setting. Our approach first learns an embedding space where different tasks cluster uniquely. We utilize this embedding space and the clustering it supports to self-generate pairings between trajectories in the large unpaired dataset. Through empirical results on simulated control tasks, we demonstrate that OSIL models trained on such self-generated pairings are competitive with OSIL models trained with ground-truth labels, presenting a major advancement in the label-efficiency of OSIL.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05307",
        "abstract url": "https://arxiv.org/abs/2408.05307",
        "title": "Audio-visual cross-modality knowledge transfer for machine learning-based in-situ monitoring in laser additive manufacturing",
        "rating": "0.5",
        "keywords": [
            [
                "Audio-visual"
            ],
            [
                "anomaly detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Various machine learning (ML)-based in-situ monitoring systems have been developed to detect laser additive manufacturing (LAM) process anomalies and defects. Multimodal fusion can improve in-situ monitoring performance by acquiring and integrating data from multiple modalities, including visual and audio data. However, multimodal fusion employs multiple sensors of different types, which leads to higher hardware, computational, and operational costs. This paper proposes a cross-modality knowledge transfer (CMKT) methodology that transfers knowledge from a source to a target modality for LAM in-situ monitoring. CMKT enhances the usefulness of the features extracted from the target modality during the training phase and removes the sensors of the source modality during the prediction phase. This paper proposes three CMKT methods: semantic alignment, fully supervised mapping, and semi-supervised mapping. Semantic alignment establishes a shared encoded space between modalities to facilitate knowledge transfer. It utilizes a semantic alignment loss to align the distributions of the same classes (e.g., visual defective and audio defective classes) and a separation loss to separate the distributions of different classes (e.g., visual defective and audio defect-free classes). The two mapping methods transfer knowledge by deriving the features of one modality from the other modality using fully supervised and semi-supervised learning. The proposed CMKT methods were implemented and compared with multimodal audio-visual fusion in an LAM in-situ anomaly detection case study. The semantic alignment method achieves a 98.4% accuracy while removing the audio modality during the prediction phase, which is comparable to the accuracy of multimodal fusion (98.2%).",
        "subjects": [
            "cs.CE",
            "cs.LG"
        ],
        "comment": "36 pages, 12 figures, 6 tables"
    },
    {
        "paper id": "2408.05344",
        "abstract url": "https://arxiv.org/abs/2408.05344",
        "title": "AI-assisted Coding with Cody: Lessons from Context Retrieval and Evaluation for Code Recommendations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we discuss a recently popular type of recommender system: an LLM-based coding assistant. Connecting the task of providing code recommendations in multiple formats to traditional RecSys challenges, we outline several similarities and differences due to domain specifics. We emphasize the importance of providing relevant context to an LLM for this use case and discuss lessons learned from context enhancements & offline and online evaluation of such AI-assisted coding systems.",
        "subjects": [
            "cs.IR",
            "cs.LG",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05345",
        "abstract url": "https://arxiv.org/abs/2408.05345",
        "title": "Explainable AI Reloaded: Challenging the XAI Status Quo in the Era of Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "When the initial vision of Explainable (XAI) was articulated, the most popular framing was to open the (proverbial) \"black-box\" of AI so that we could understand the inner workings. With the advent of Large Language Models (LLMs), the very ability to open the black-box is increasingly limited especially when it comes to non-AI expert end-users. In this paper, we challenge the assumption of \"opening\" the black-box in the LLM era and argue for a shift in our XAI expectations. Highlighting the epistemic blind spots of an algorithm-centered XAI view, we argue that a human-centered perspective can be a path forward. We operationalize the argument by synthesizing XAI research along three dimensions: explainability outside the black-box, explainability around the edges of the black box, and explainability that leverages infrastructural seams. We conclude with takeaways that reflexively inform XAI as a domain.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "Accepted to ACM HTTF 2024"
    },
    {
        "paper id": "2408.05373",
        "abstract url": "https://arxiv.org/abs/2408.05373",
        "title": "Evolutionary mechanisms that promote cooperation may not promote social welfare",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Understanding the emergence of prosocial behaviours among self-interested individuals is an important problem in many scientific disciplines. Various mechanisms have been proposed to explain the evolution of such behaviours, primarily seeking the conditions under which a given mechanism can induce highest levels of cooperation. As these mechanisms usually involve costs that alter individual payoffs, it is however possible that aiming for highest levels of cooperation might be detrimental for social welfare -- the later broadly defined as the total population payoff, taking into account all costs involved for inducing increased prosocial behaviours. Herein, by comparatively analysing the social welfare and cooperation levels obtained from stochastic evolutionary models of two well-established mechanisms of prosocial behaviour, namely, peer and institutional incentives, we demonstrate exactly that. We show that the objectives of maximising cooperation levels and the objectives of maximising social welfare are often misaligned. We argue for the need of adopting social welfare as the main optimisation objective when designing and implementing evolutionary mechanisms for social and collective goods.",
        "subjects": [
            "math.DS",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "nlin.AO"
        ],
        "comment": "21 pages, 5 figures"
    },
    {
        "paper id": "2408.05382",
        "abstract url": "https://arxiv.org/abs/2408.05382",
        "title": "Optimizing Portfolio with Two-Sided Transactions and Lending: A Reinforcement Learning Framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study presents a Reinforcement Learning (RL)-based portfolio management model tailored for high-risk environments, addressing the limitations of traditional RL models and exploiting market opportunities through two-sided transactions and lending. Our approach integrates a new environmental formulation with a Profit and Loss (PnL)-based reward function, enhancing the RL agent's ability in downside risk management and capital optimization. We implemented the model using the Soft Actor-Critic (SAC) agent with a Convolutional Neural Network with Multi-Head Attention (CNN-MHA). This setup effectively manages a diversified 12-crypto asset portfolio in the Binance perpetual futures market, leveraging USDT for both granting and receiving loans and rebalancing every 4 hours, utilizing market data from the preceding 48 hours. Tested over two 16-month periods of varying market volatility, the model significantly outperformed benchmarks, particularly in high-volatility scenarios, achieving higher return-to-risk ratios and demonstrating robust profitability. These results confirm the model's effectiveness in leveraging market dynamics and managing risks in volatile environments like the cryptocurrency market.",
        "subjects": [
            "q-fin.PM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05391",
        "abstract url": "https://arxiv.org/abs/2408.05391",
        "title": "SAMSA: Efficient Transformer for Many Data Modalities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The versatility of self-attention mechanism earned transformers great success in almost all data modalities, with limitations on the quadratic complexity and difficulty of training. Efficient transformers, on the other hand, often rely on clever data-modality-dependent construction to get over the quadratic complexity of transformers. This greatly hinders their applications on different data modalities, which is one of the pillars of contemporary foundational modeling. In this paper, we lay the groundwork for efficient foundational modeling by proposing SAMSA - SAMpling-Self-Attention, a context-aware linear complexity self-attention mechanism that works well on multiple data modalities. Our mechanism is based on a differentiable sampling without replacement method we discovered. This enables the self-attention module to attend to the most important token set, where the importance is defined by data. Moreover, as differentiability is not needed in inference, the sparse formulation of our method costs little time overhead, further lowering computational costs. In short, SAMSA achieved competitive or even SOTA results on many benchmarks, while being faster in inference, compared to other very specialized models. Against full self-attention, real inference time significantly decreases while performance ranges from negligible degradation to outperformance. We release our source code in the repository: https://github.com/HySonLab/SAMSA",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05393",
        "abstract url": "https://arxiv.org/abs/2408.05393",
        "title": "fastkqr: A Fast Algorithm for Kernel Quantile Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantile regression is a powerful tool for robust and heterogeneous learning that has seen applications in a diverse range of applied areas. However, its broader application is often hindered by the substantial computational demands arising from the non-smooth quantile loss function. In this paper, we introduce a novel algorithm named fastkqr, which significantly advances the computation of quantile regression in reproducing kernel Hilbert spaces. The core of fastkqr is a finite smoothing algorithm that magically produces exact regression quantiles, rather than approximations. To further accelerate the algorithm, we equip fastkqr with a novel spectral technique that carefully reutilizes matrix computations. In addition, we extend fastkqr to accommodate a flexible kernel quantile regression with a data-driven crossing penalty, addressing the interpretability challenges of crossing quantile curves at multiple levels. We have implemented fastkqr in a publicly available R package. Extensive simulations and real applications show that fastkqr matches the accuracy of state-of-the-art algorithms but can operate up to an order of magnitude faster.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05428",
        "abstract url": "https://arxiv.org/abs/2408.05428",
        "title": "Generalized Encouragement-Based Instrumental Variables for Counterfactual Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In causal inference, encouragement designs (EDs) are widely used to analyze causal effects, when randomized controlled trials (RCTs) are impractical or compliance to treatment cannot be perfectly enforced. Unlike RCTs, which directly allocate treatments, EDs randomly assign encouragement policies that positively motivate individuals to engage in a specific treatment. These random encouragements act as instrumental variables (IVs), facilitating the identification of causal effects through leveraging exogenous perturbations in discrete treatment scenarios. However, real-world applications of encouragement designs often face challenges such as incomplete randomization, limited experimental data, and significantly fewer encouragements compared to treatments, hindering precise causal effect estimation. To address this, this paper introduces novel theories and algorithms for identifying the Conditional Average Treatment Effect (CATE) using variations in encouragement. Further, by leveraging both observational and encouragement data, we propose a generalized IV estimator, named Encouragement-based Counterfactual Regression (EnCounteR), to effectively estimate the causal effects. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of EnCounteR over existing methods.",
        "subjects": [
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05430",
        "abstract url": "https://arxiv.org/abs/2408.05430",
        "title": "HoME: Hierarchy of Multi-Gate Experts for Multi-Task Learning at Kuaishou",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present the practical problems and the lessons learned at short-video services from Kuaishou. In industry, a widely-used multi-task framework is the Mixture-of-Experts (MoE) paradigm, which always introduces some shared and specific experts for each task and then uses gate networks to measure related experts' contributions. Although the MoE achieves remarkable improvements, we still observe three anomalies that seriously affect model performances in our iteration: (1) Expert Collapse: We found that experts' output distributions are significantly different, and some experts have over 90% zero activations with ReLU, making it hard for gate networks to assign fair weights to balance experts. (2) Expert Degradation: Ideally, the shared-expert aims to provide predictive information for all tasks simultaneously. Nevertheless, we find that some shared-experts are occupied by only one task, which indicates that shared-experts lost their ability but degenerated into some specific-experts. (3) Expert Underfitting: In our services, we have dozens of behavior tasks that need to be predicted, but we find that some data-sparse prediction tasks tend to ignore their specific-experts and assign large weights to shared-experts. The reason might be that the shared-experts can perceive more gradient updates and knowledge from dense tasks, while specific-experts easily fall into underfitting due to their sparse behaviors. Motivated by those observations, we propose HoME to achieve a simple, efficient and balanced MoE system for multi-task learning.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2408.05431",
        "abstract url": "https://arxiv.org/abs/2408.05431",
        "title": "Simple and Nearly-Optimal Sampling for Rank-1 Tensor Completion via Gauss-Jordan",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We revisit the sample and computational complexity of completing a rank-1 tensor in $\\otimes_{i=1}^{N} \\mathbb{R}^{d}$, given a uniformly sampled subset of its entries. We present a characterization of the problem (i.e. nonzero entries) which admits an algorithm amounting to Gauss-Jordan on a pair of random linear systems. For example, when $N = \u0398(1)$, we prove it uses no more than $m = O(d^2 \\log d)$ samples and runs in $O(md^2)$ time. Moreover, we show any algorithm requires $\u03a9(d\\log d)$ samples. By contrast, existing upper bounds on the sample complexity are at least as large as $d^{1.5} \u03bc^{\u03a9(1)} \\log^{\u03a9(1)} d$, where $\u03bc$ can be $\u0398(d)$ in the worst case. Prior work obtained these looser guarantees in higher rank versions of our problem, and tend to involve more complicated algorithms.",
        "subjects": [
            "cs.DS",
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.07089",
        "abstract url": "https://arxiv.org/abs/2408.07089",
        "title": "InfinityMATH: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT) methods have greatly enhanced language models' mathematical reasoning capabilities, facilitating their integration into instruction tuning datasets with LLMs. However, existing methods for large-scale dataset creation require substantial seed data and high computational costs for data synthesis, posing significant challenges for scalability. We introduce InfinityMATH, a scalable instruction tuning dataset for programmatic mathematical reasoning. The construction pipeline emphasizes decoupling numbers from mathematical problems to synthesize number-independent programs, enabling efficient and flexible scaling while minimizing dependency on specific numerical values. Fine-tuning experiments with open-source language and code models, such as Llama2 and CodeLlama, demonstrate the practical benefits of InfinityMATH. These fine-tuned models, showed significant relative improvements on both in-domain and out-of-domain benchmarks, ranging from 184.7% to 514.3% on average. Additionally, these models exhibited high robustness on the GSM8K+ and MATH+ benchmarks, which are enhanced version of test sets with simply the number variations. InfinityMATH ensures that models are more versatile and effective across a broader range of mathematical problems. The data is available at https://huggingface.co/datasets/flagopen/InfinityMATH.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted by CIKM 2024"
    },
    {
        "paper id": "2408.07090",
        "abstract url": "https://arxiv.org/abs/2408.07090",
        "title": "Persistence kernels for classification: A comparative study",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The aim of the present work is a comparative study of different persistence kernels applied to various classification problems. After some necessary preliminaries on homology and persistence diagrams, we introduce five different kernels that are then used to compare their performances of classification on various datasets. We also provide the Python codes for the reproducibility of results.",
        "subjects": [
            "cs.LG",
            "math.AT"
        ],
        "comment": "23 pages, 13 figures"
    },
    {
        "paper id": "2408.04948",
        "abstract url": "https://arxiv.org/abs/2408.04948",
        "title": "HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction",
        "rating": "0",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Extraction and interpretation of intricate information from unstructured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Retrieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents. We introduce a novel approach based on a combination, called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for information extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers. Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG individually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation. The proposed technique has applications beyond the financial domain",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "q-fin.ST",
            "stat.AP",
            "stat.ML"
        ],
        "comment": "9 pages, 2 figures, 5 tables"
    },
    {
        "paper id": "2408.04958",
        "abstract url": "https://arxiv.org/abs/2408.04958",
        "title": "Surgical-VQLA++: Adversarial Contrastive Learning for Calibrated Robust Visual Question-Localized Answering in Robotic Surgery",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Medical",
                "Surgical",
                "Surgery",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical visual question answering (VQA) bridges the gap between visual information and clinical decision-making, enabling doctors to extract understanding from clinical images and videos. In particular, surgical VQA can enhance the interpretation of surgical data, aiding in accurate diagnoses, effective education, and clinical interventions. However, the inability of VQA models to visually indicate the regions of interest corresponding to the given questions results in incomplete comprehension of the surgical scene. To tackle this, we propose the surgical visual question localized-answering (VQLA) for precise and context-aware responses to specific queries regarding surgical images. Furthermore, to address the strong demand for safety in surgical scenarios and potential corruptions in image acquisition and transmission, we propose a novel approach called Calibrated Co-Attention Gated Vision-Language (C$^2$G-ViL) embedding to integrate and align multimodal information effectively. Additionally, we leverage the adversarial sample-based contrastive learning strategy to boost our performance and robustness. We also extend our EndoVis-18-VQLA and EndoVis-17-VQLA datasets to broaden the scope and application of our data. Extensive experiments on the aforementioned datasets demonstrate the remarkable performance and robustness of our solution. Our solution can effectively combat real-world image corruption. Thus, our proposed approach can serve as an effective tool for assisting surgical education, patient care, and enhancing surgical outcomes.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted by Information Fusion. Code and data availability: https://github.com/longbai1006/Surgical-VQLAPlus"
    },
    {
        "paper id": "2408.04962",
        "abstract url": "https://arxiv.org/abs/2408.04962",
        "title": "DAFT-GAN: Dual Affine Transformation Generative Adversarial Network for Text-Guided Image Inpainting",
        "rating": "0",
        "keywords": [
            [
                "GAN",
                "Inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, there has been a significant focus on research related to text-guided image inpainting. However, the task remains challenging due to several constraints, such as ensuring alignment between the image and the text, and maintaining consistency in distribution between corrupted and uncorrupted regions. In this paper, thus, we propose a dual affine transformation generative adversarial network (DAFT-GAN) to maintain the semantic consistency for text-guided inpainting. DAFT-GAN integrates two affine transformation networks to combine text and image features gradually for each decoding block. Moreover, we minimize information leakage of uncorrupted features for fine-grained image generation by encoding corrupted and uncorrupted regions of the masked image separately. Our proposed model outperforms the existing GAN-based models in both qualitative and quantitative assessments with three benchmark datasets (MS-COCO, CUB, and Oxford) for text-guided image inpainting.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ACM MM'2024. 9 pages, 3 tables, 9 figures"
    },
    {
        "paper id": "2408.04967",
        "abstract url": "https://arxiv.org/abs/2408.04967",
        "title": "ADD 2023: Towards Audio Deepfake Detection and Analysis in the Wild",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The growing prominence of the field of audio deepfake detection is driven by its wide range of applications, notably in protecting the public from potential fraud and other malicious activities, prompting the need for greater attention and research in this area. The ADD 2023 challenge goes beyond binary real/fake classification by emulating real-world scenarios, such as the identification of manipulated intervals in partially fake audio and determining the source responsible for generating any fake audio, both with real-life implications, notably in audio forensics, law enforcement, and construction of reliable and trustworthy evidence. To further foster research in this area, in this article, we describe the dataset that was used in the fake game, manipulation region location and deepfake algorithm recognition tracks of the challenge. We also focus on the analysis of the technical methodologies by the top-performing participants in each task and note the commonalities and differences in their approaches. Finally, we discuss the current technical limitations as identified through the technical analysis, and provide a roadmap for future research directions. The dataset is available for download.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2408.04974",
        "abstract url": "https://arxiv.org/abs/2408.04974",
        "title": "XNN: Paradigm Shift in Mitigating Identity Leakage within Cloud-Enabled Deep Learning",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the domain of cloud-based deep learning, the imperative for external computational resources coexists with acute privacy concerns, particularly identity leakage. To address this challenge, we introduce XNN and XNN-d, pioneering methodologies that infuse neural network features with randomized perturbations, striking a harmonious balance between utility and privacy. XNN, designed for the training phase, ingeniously blends random permutation with matrix multiplication techniques to obfuscate feature maps, effectively shielding private data from potential breaches without compromising training integrity. Concurrently, XNN-d, devised for the inference phase, employs adversarial training to integrate generative adversarial noise. This technique effectively counters black-box access attacks aimed at identity extraction, while a distilled face recognition network adeptly processes the perturbed features, ensuring accurate identification. Our evaluation demonstrates XNN's effectiveness, significantly outperforming existing methods in reducing identity leakage while maintaining a high model accuracy.",
        "subjects": [
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05090",
        "abstract url": "https://arxiv.org/abs/2408.05090",
        "title": "Loc4Plan: Locating Before Planning for Outdoor Vision and Language Navigation",
        "rating": "0",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision and Language Navigation (VLN) is a challenging task that requires agents to understand instructions and navigate to the destination in a visual environment.One of the key challenges in outdoor VLN is keeping track of which part of the instruction was completed. To alleviate this problem, previous works mainly focus on grounding the natural language to the visual input, but neglecting the crucial role of the agent's spatial position information in the grounding process. In this work, we first explore the substantial effect of spatial position locating on the grounding of outdoor VLN, drawing inspiration from human navigation. In real-world navigation scenarios, before planning a path to the destination, humans typically need to figure out their current location. This observation underscores the pivotal role of spatial localization in the navigation process. In this work, we introduce a novel framework, Locating be for Planning (Loc4Plan), designed to incorporate spatial perception for action planning in outdoor VLN tasks. The main idea behind Loc4Plan is to perform the spatial localization before planning a decision action based on corresponding guidance, which comprises a block-aware spatial locating (BAL) module and a spatial-aware action planning (SAP) module. Specifically, to help the agent perceive its spatial location in the environment, we propose to learn a position predictor that measures how far the agent is from the next intersection for reflecting its position, which is achieved by the BAL module. After the locating process, we propose the SAP module to incorporate spatial information to ground the corresponding guidance and enhance the precision of action planning. Extensive experiments on the Touchdown and map2seq datasets show that the proposed Loc4Plan outperforms the SOTA methods.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2203.13838 by other authors"
    },
    {
        "paper id": "2408.05124",
        "abstract url": "https://arxiv.org/abs/2408.05124",
        "title": "Modeling Electromagnetic Signal Injection Attacks on Camera-based Smart Systems: Applications and Mitigation",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Numerous safety- or security-critical systems depend on cameras to perceive their surroundings, further allowing artificial intelligence (AI) to analyze the captured images to make important decisions. However, a concerning attack vector has emerged, namely, electromagnetic waves, which pose a threat to the integrity of these systems. Such attacks enable attackers to manipulate the images remotely, leading to incorrect AI decisions, e.g., autonomous vehicles missing detecting obstacles ahead resulting in collisions. The lack of understanding regarding how different systems react to such attacks poses a significant security risk. Furthermore, no effective solutions have been demonstrated to mitigate this threat. To address these gaps, we modeled the attacks and developed a simulation method for generating adversarial images. Through rigorous analysis, we confirmed that the effects of the simulated adversarial images are indistinguishable from those from real attacks. This method enables researchers and engineers to rapidly assess the susceptibility of various AI vision applications to these attacks, without the need for constructing complicated attack devices. In our experiments, most of the models demonstrated vulnerabilities to these attacks, emphasizing the need to enhance their robustness. Fortunately, our modeling and simulation method serves as a stepping stone toward developing more resilient models. We present a pilot study on adversarial training to improve their robustness against attacks, and our results demonstrate a significant improvement by recovering up to 91% performance, offering a promising direction for mitigating this threat.",
        "subjects": [
            "cs.CR",
            "cs.CV"
        ],
        "comment": "13 pages, 10 figures, 4 tables"
    },
    {
        "paper id": "2408.05141",
        "abstract url": "https://arxiv.org/abs/2408.05141",
        "title": "A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-augmented generation (RAG) is a framework enabling large language models (LLMs) to enhance their accuracy and reduce hallucinations by integrating external knowledge bases. In this paper, we introduce a hybrid RAG system enhanced through a comprehensive suite of optimizations that significantly improve retrieval quality, augment reasoning capabilities, and refine numerical computation ability. We refined the text chunks and tables in web pages, added attribute predictors to reduce hallucinations, conducted LLM Knowledge Extractor and Knowledge Graph Extractor, and finally built a reasoning strategy with all the references. We evaluated our system on the CRAG dataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and online evaluations demonstrate that our system significantly enhances complex reasoning capabilities. In local evaluations, we have significantly improved accuracy and reduced error rates compared to the baseline model, achieving a notable increase in scores. In the meanwhile, we have attained outstanding results in online assessments, demonstrating the performance and generalization capabilities of the proposed system. The source code for our system is released in \\url{https://gitlab.aicrowd.com/shizueyy/crag-new}.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": "Technical report for 3rd prize in Task 1 of Meta CRAG KDD Cup 2024"
    },
    {
        "paper id": "2408.05206",
        "abstract url": "https://arxiv.org/abs/2408.05206",
        "title": "Multi-Garment Customized Model Generation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces Multi-Garment Customized Model Generation, a unified framework based on Latent Diffusion Models (LDMs) aimed at addressing the unexplored task of synthesizing images with free combinations of multiple pieces of clothing. The method focuses on generating customized models wearing various targeted outfits according to different text prompts. The primary challenge lies in maintaining the natural appearance of the dressed model while preserving the complex textures of each piece of clothing, ensuring that the information from different garments does not interfere with each other. To tackle these challenges, we first developed a garment encoder, which is a trainable UNet copy with shared weights, capable of extracting detailed features of garments in parallel. Secondly, our framework supports the conditional generation of multiple garments through decoupled multi-garment feature fusion, allowing multiple clothing features to be injected into the backbone network, significantly alleviating conflicts between garment information. Additionally, the proposed garment encoder is a plug-and-play module that can be combined with other extension modules such as IP-Adapter and ControlNet, enhancing the diversity and controllability of the generated models. Extensive experiments demonstrate the superiority of our approach over existing alternatives, opening up new avenues for the task of generating images with multiple-piece clothing combinations",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05283",
        "abstract url": "https://arxiv.org/abs/2408.05283",
        "title": "MUSE: Multi-Knowledge Passing on the Edges, Boosting Knowledge Graph Completion",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge Graph Completion (KGC) aims to predict the missing information in the (head entity)-[relation]-(tail entity) triplet. Deep Neural Networks have achieved significant progress in the relation prediction task. However, most existing KGC methods focus on single features (e.g., entity IDs) and sub-graph aggregation, which cannot fully explore all the features in the Knowledge Graph (KG), and neglect the external semantic knowledge injection. To address these problems, we propose MUSE, a knowledge-aware reasoning model to learn a tailored embedding space in three dimensions for missing relation prediction through a multi-knowledge representation learning mechanism. Our MUSE consists of three parallel components: 1) Prior Knowledge Learning for enhancing the triplets' semantic representation by fine-tuning BERT; 2) Context Message Passing for enhancing the context messages of KG; 3) Relational Path Aggregation for enhancing the path representation from the head entity to the tail entity. Our experimental results show that MUSE significantly outperforms other baselines on four public datasets, such as over 5.50% improvement in H@1 and 4.20% improvement in MRR on the NELL995 dataset. The code and all datasets will be released via https://github.com/NxxTGT/MUSE.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05366",
        "abstract url": "https://arxiv.org/abs/2408.05366",
        "title": "DeepSpeak Dataset v1.0",
        "rating": "0",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We describe a large-scale dataset--{\\em DeepSpeak}--of real and deepfake footage of people talking and gesturing in front of their webcams. The real videos in this first version of the dataset consist of $9$ hours of footage from $220$ diverse individuals. Constituting more than 25 hours of footage, the fake videos consist of a range of different state-of-the-art face-swap and lip-sync deepfakes with natural and AI-generated voices. We expect to release future versions of this dataset with different and updated deepfake technologies. This dataset is made freely available for research and non-commercial uses; requests for commercial use will be considered.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05398",
        "abstract url": "https://arxiv.org/abs/2408.05398",
        "title": "PersonViT: Large-scale Self-supervised Vision Transformer for Person Re-Identificat",
        "rating": "0",
        "keywords": [
            [
                "Re-Identification"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Person Re-Identification (ReID) aims to retrieve relevant individuals in non-overlapping camera images and has a wide range of applications in the field of public safety. In recent years, with the development of Vision Transformer (ViT) and self-supervised learning techniques, the performance of person ReID based on self-supervised pre-training has been greatly improved. Person ReID requires extracting highly discriminative local fine-grained features of the human body, while traditional ViT is good at extracting context-related global features, making it difficult to focus on local human body features. To this end, this article introduces the recently emerged Masked Image Modeling (MIM) self-supervised learning method into person ReID, and effectively extracts high-quality global and local features through large-scale unsupervised pre-training by combining masked image modeling and discriminative contrastive learning, and then conducts supervised fine-tuning training in the person ReID task. This person feature extraction method based on ViT with masked image modeling (PersonViT) has the good characteristics of unsupervised, scalable, and strong generalization capabilities, overcoming the problem of difficult annotation in supervised person ReID, and achieves state-of-the-art results on publicly available benchmark datasets, including MSMT17, Market1501, DukeMTMC-reID, and Occluded-Duke. The code and pre-trained models of the PersonViT method are released at https://github.com/hustvl/PersonViT to promote further research in the person ReID fie",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05402",
        "abstract url": "https://arxiv.org/abs/2408.05402",
        "title": "Mesh deformation-based single-view 3D reconstruction of thin eyeglasses frames with differentiable rendering",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the support of Virtual Reality (VR) and Augmented Reality (AR) technologies, the 3D virtual eyeglasses try-on application is well on its way to becoming a new trending solution that offers a \"try on\" option to select the perfect pair of eyeglasses at the comfort of your own home. Reconstructing eyeglasses frames from a single image with traditional depth and image-based methods is extremely difficult due to their unique characteristics such as lack of sufficient texture features, thin elements, and severe self-occlusions. In this paper, we propose the first mesh deformation-based reconstruction framework for recovering high-precision 3D full-frame eyeglasses models from a single RGB image, leveraging prior and domain-specific knowledge. Specifically, based on the construction of a synthetic eyeglasses frame dataset, we first define a class-specific eyeglasses frame template with pre-defined keypoints. Then, given an input eyeglasses frame image with thin structure and few texture features, we design a keypoint detector and refiner to detect predefined keypoints in a coarse-to-fine manner to estimate the camera pose accurately. After that, using differentiable rendering, we propose a novel optimization approach for producing correct geometry by progressively performing free-form deformation (FFD) on the template mesh. We define a series of loss functions to enforce consistency between the rendered result and the corresponding RGB input, utilizing constraints from inherent structure, silhouettes, keypoints, per-pixel shading information, and so on. Experimental results on both the synthetic dataset and real images demonstrate the effectiveness of the proposed algorithm.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05404",
        "abstract url": "https://arxiv.org/abs/2408.05404",
        "title": "LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Metaphor Components Identification (MCI) contributes to enhancing machine understanding of metaphors, thereby advancing downstream natural language processing tasks. However, the complexity, diversity, and dependency on context and background knowledge pose significant challenges for MCI. Large language models (LLMs) offer new avenues for accurate comprehension of complex natural language texts due to their strong semantic analysis and extensive commonsense knowledge. In this research, a new LLM-based framework is proposed, named Linguistics-aware In-context Learning with Data Augmentation (LaiDA). Specifically, ChatGPT and supervised fine-tuning are utilized to tailor a high-quality dataset. LaiDA incorporates a simile dataset for pre-training. A graph attention network encoder generates linguistically rich feature representations to retrieve similar examples. Subsequently, LLM is fine-tuned with prompts that integrate linguistically similar examples. LaiDA ranked 2nd in Subtask 2 of NLPCC2024 Shared Task 9, demonstrating its effectiveness. Code and data are available at https://github.com/WXLJZ/LaiDA.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This paper has been accepted by NLPCC 2024 Shared Tasks"
    },
    {
        "paper id": "2408.05421",
        "abstract url": "https://arxiv.org/abs/2408.05421",
        "title": "EPAM-Net: An Efficient Pose-driven Attention-guided Multimodal Network for Video Action Recognition",
        "rating": "0",
        "keywords": [
            [
                "RGB-D",
                "skeleton"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Existing multimodal-based human action recognition approaches are either computationally expensive, which limits their applicability in real-time scenarios, or fail to exploit the spatial temporal information of multiple data modalities. In this work, we present an efficient pose-driven attention-guided multimodal network (EPAM-Net) for action recognition in videos. Specifically, we adapted X3D networks for both RGB and pose streams to capture spatio-temporal features from RGB videos and their skeleton sequences. Then skeleton features are utilized to help the visual network stream focusing on key frames and their salient spatial regions using a spatial temporal attention block. Finally, the scores of the two streams of the proposed network are fused for final classification. The experimental results show that our method achieves competitive performance on NTU-D 60 and NTU RGB-D 120 benchmark datasets. Moreover, our model provides a 6.2--9.9x reduction in FLOPs (floating-point operation, in number of multiply-adds) and a 9--9.6x reduction in the number of network parameters. The code will be available at https://github.com/ahmed-nady/Multimodal-Action-Recognition.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05440",
        "abstract url": "https://arxiv.org/abs/2408.05440",
        "title": "Content-decoupled Contrastive Learning-based Implicit Degradation Modeling for Blind Image Super-Resolution",
        "rating": "0",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Implicit degradation modeling-based blind super-resolution (SR) has attracted more increasing attention in the community due to its excellent generalization to complex degradation scenarios and wide application range. How to extract more discriminative degradation representations and fully adapt them to specific image features is the key to this task. In this paper, we propose a new Content-decoupled Contrastive Learning-based blind image super-resolution (CdCL) framework following the typical blind SR pipeline. This framework introduces negative-free contrastive learning technique for the first time to model the implicit degradation representation, in which a new cyclic shift sampling strategy is designed to ensure decoupling between content features and degradation features from the data perspective, thereby improving the purity and discriminability of the learned implicit degradation space. In addition, to improve the efficiency and effectiveness of implicit degradation-based blind super-resolving, we design a detail-aware implicit degradation adaption module with lower complexity, which adapts degradation information to the specific LR image from both channel and spatial perspectives. Extensive experiments on synthetic and real data prove that the proposed CdCL comprehensively improves the quantitative and qualitative results of contrastive learning-based implicit blind SR paradigm, and achieves SOTA PSNR in this field. Even if the number of parameters is halved, our method still achieves very competitive results.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.07091",
        "abstract url": "https://arxiv.org/abs/2408.07091",
        "title": "Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning",
        "rating": "0",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Textual graphs are ubiquitous in real-world applications, featuring rich text information with complex relationships, which enables advanced research across various fields. Textual graph representation learning aims to generate low-dimensional feature embeddings from textual graphs that can improve the performance of downstream tasks. A high-quality feature embedding should effectively capture both the structural and the textual information in a textual graph. However, most textual graph dataset benchmarks rely on word2vec techniques to generate feature embeddings, which inherently limits their capabilities. Recent works on textual graph representation learning can be categorized into two folds: supervised and unsupervised methods. Supervised methods finetune a language model on labeled nodes, which have limited capabilities when labeled data is scarce. Unsupervised methods, on the other hand, extract feature embeddings by developing complex training pipelines. To address these limitations, we propose a novel unified unsupervised learning autoencoder framework, named Node Level Graph AutoEncoder (NodeGAE). We employ language models as the backbone of the autoencoder, with pretraining on text reconstruction. Additionally, we add an auxiliary loss term to make the feature embeddings aware of the local graph structure. Our method maintains simplicity in the training process and demonstrates generalizability across diverse textual graphs and downstream tasks. We evaluate our method on two core graph representation learning downstream tasks: node classification and link prediction. Comprehensive experiments demonstrate that our approach substantially enhances the performance of diverse graph neural networks (GNNs) across multiple textual graph datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04870",
        "abstract url": "https://arxiv.org/abs/2408.04870",
        "title": "ConfusedPilot: Confused Deputy Risks in RAG-based LLMs",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Retrieval augmented generation (RAG) is a process where a large language model (LLM) retrieves useful information from a database and then generates the responses. It is becoming popular in enterprise settings for daily business operations. For example, Copilot for Microsoft 365 has accumulated millions of businesses. However, the security implications of adopting such RAG-based systems are unclear. In this paper, we introduce ConfusedPilot, a class of security vulnerabilities of RAG systems that confuse Copilot and cause integrity and confidentiality violations in its responses. First, we investigate a vulnerability that embeds malicious text in the modified prompt in RAG, corrupting the responses generated by the LLM. Second, we demonstrate a vulnerability that leaks secret data, which leverages the caching mechanism during retrieval. Third, we investigate how both vulnerabilities can be exploited to propagate misinformation within the enterprise and ultimately impact its operations, such as sales and manufacturing. We also discuss the root cause of these attacks by investigating the architecture of a RAG-based system. This study highlights the security vulnerabilities in today's RAG-based systems and proposes design guidelines to secure future RAG-based systems.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04895",
        "abstract url": "https://arxiv.org/abs/2408.04895",
        "title": "Better Not to Propagate: Understanding Edge Uncertainty and Over-smoothing in Signed Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Traditional Graph Neural Networks (GNNs) rely on network homophily, which can lead to performance degradation due to over-smoothing in many real-world heterophily scenarios. Recent studies analyze the smoothing effect (separability) after message-passing (MP), depending on the expectation of node features. Regarding separability gain, they provided theoretical backgrounds on over-smoothing caused by various propagation schemes, including positive, signed, and blocked MPs. More recently, by extending these theorems, some works have suggested improvements in signed propagation under multiple classes. However, prior works assume that the error ratio of all propagation schemes is fixed, failing to investigate this phenomenon correctly. To solve this problem, we propose a novel method for estimating homophily and edge error ratio, integrated with dynamic selection between blocked and signed propagation during training. Our theoretical analysis, supported by extensive experiments, demonstrates that blocking MP can be more effective than signed propagation under high edge error ratios, improving the performance in both homophilic and heterophilic graphs.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04913",
        "abstract url": "https://arxiv.org/abs/2408.04913",
        "title": "Knowledge Base Embeddings: Semantics and Theoretical Properties",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Research on knowledge graph embeddings has recently evolved into knowledge base embeddings, where the goal is not only to map facts into vector spaces but also constrain the models so that they take into account the relevant conceptual knowledge available. This paper examines recent methods that have been proposed to embed knowledge bases in description logic into vector spaces through the lens of their geometric-based semantics. We identify several relevant theoretical properties, which we draw from the literature and sometimes generalize or unify. We then investigate how concrete embedding methods fit in this theoretical framework.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": "This is an extended version of a paper appearing at the 21st International Conference on Principles of Knowledge Representation and Reasoning (KR 2024). 17 pages"
    },
    {
        "paper id": "2408.04916",
        "abstract url": "https://arxiv.org/abs/2408.04916",
        "title": "PTrajM: Efficient and Semantic-rich Trajectory Learning with Pretrained Trajectory-Mamba",
        "rating": "-0.5",
        "keywords": [
            [
                "Trajectory",
                "Vehicle"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Vehicle trajectories provide crucial movement information for various real-world applications. To better utilize vehicle trajectories, it is essential to develop a trajectory learning approach that can effectively and efficiently extract rich semantic information, including movement behavior and travel purposes, to support accurate downstream applications. However, creating such an approach presents two significant challenges. First, movement behavior are inherently spatio-temporally continuous, making them difficult to extract efficiently from irregular and discrete trajectory points. Second, travel purposes are related to the functionalities of areas and road segments traversed by vehicles. These functionalities are not available from the raw spatio-temporal trajectory features and are hard to extract directly from complex textual features associated with these areas and road segments. To address these challenges, we propose PTrajM, a novel method capable of efficient and semantic-rich vehicle trajectory learning. To support efficient modeling of movement behavior, we introduce Trajectory-Mamba as the learnable model of PTrajM, which effectively extracts continuous movement behavior while being more computationally efficient than existing structures. To facilitate efficient extraction of travel purposes, we propose a travel purpose-aware pre-training procedure, which enables PTrajM to discern the travel purposes of trajectories without additional computational resources during its embedding process. Extensive experiments on two real-world datasets and comparisons with several state-of-the-art trajectory learning methods demonstrate the effectiveness of PTrajM. Code is available at https://anonymous.4open.science/r/PTrajM-C973.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04931",
        "abstract url": "https://arxiv.org/abs/2408.04931",
        "title": "Privacy-Preserved Taxi Demand Prediction System Utilizing Distributed Data",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Accurate taxi-demand prediction is essential for optimizing taxi operations and enhancing urban transportation services. However, using customers' data in these systems raises significant privacy and security concerns. Traditional federated learning addresses some privacy issues by enabling model training without direct data exchange but often struggles with accuracy due to varying data distributions across different regions or service providers. In this paper, we propose CC-Net: a novel approach using collaborative learning enhanced with contrastive learning for taxi-demand prediction. Our method ensures high performance by enabling multiple parties to collaboratively train a demand-prediction model through hierarchical federated learning. In this approach, similar parties are clustered together, and federated learning is applied within each cluster. The similarity is defined without data exchange, ensuring privacy and security. We evaluated our approach using real-world data from five taxi service providers in Japan over fourteen months. The results demonstrate that CC-Net maintains the privacy of customers' data while improving prediction accuracy by at least 2.2% compared to existing techniques.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04996",
        "abstract url": "https://arxiv.org/abs/2408.04996",
        "title": "On the use of neurosymbolic AI for defending against cyber attacks",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "It is generally accepted that all cyber attacks cannot be prevented, creating a need for the ability to detect and respond to cyber attacks. Both connectionist and symbolic AI are currently being used to support such detection and response. In this paper, we make the case for combining them using neurosymbolic AI. We identify a set of challenges when using AI today and propose a set of neurosymbolic use cases we believe are both interesting research directions for the neurosymbolic AI community and can have an impact on the cyber security field. We demonstrate feasibility through two proof-of-concept experiments.",
        "subjects": [
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "Accepted to 18th International Conference on Neural-Symbolic Learning and Reasoning"
    },
    {
        "paper id": "2408.05025",
        "abstract url": "https://arxiv.org/abs/2408.05025",
        "title": "Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Retrieval Augmented Generation (RAG) is a technique commonly used to equip models with out of distribution knowledge. This process involves collecting, indexing, retrieving, and providing information to an LLM for generating responses. Despite its growing popularity due to its flexibility and low cost, the security implications of RAG have not been extensively studied. The data for such systems are often collected from public sources, providing an attacker a gateway for indirect prompt injections to manipulate the responses of the model. In this paper, we investigate the security of RAG systems against end-to-end indirect prompt manipulations. First, we review existing RAG framework pipelines, deriving a prototypical architecture and identifying critical parameters. We then examine prior works searching for techniques that attackers can use to perform indirect prompt manipulations. Finally, we implemented Rag 'n Roll, a framework to determine the effectiveness of attacks against end-to-end RAG applications. Our results show that existing attacks are mostly optimized to boost the ranking of malicious documents during the retrieval phase. However, a higher rank does not immediately translate into a reliable attack. Most attacks, against various configurations, settle around a 40% success rate, which could rise to 60% when considering ambiguous answers as successful attacks (those that include the expected benign one as well). Additionally, when using unoptimized documents, attackers deploying two of them (or more) for a target query can achieve similar results as those using optimized ones. Finally, exploration of the configuration space of a RAG showed limited impact in thwarting the attacks, where the most successful combination severely undermines functionality.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05054",
        "abstract url": "https://arxiv.org/abs/2408.05054",
        "title": "Graph Neural Networks as Ordering Heuristics for Parallel Graph Coloring",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The graph coloring problem asks for an assignment of the minimum number of distinct colors to vertices in an undirected graph with the constraint that no pair of adjacent vertices share the same color. The problem is a thoroughly studied NP-hard combinatorial problem with several real-world applications. As such, a number of greedy heuristics have been suggested that strike a good balance between coloring quality, execution time, and also parallel scalability. In this work, we introduce a graph neural network (GNN) based ordering heuristic and demonstrate that it outperforms existing greedy ordering heuristics both on quality and performance. Previous results have demonstrated that GNNs can produce high-quality colorings but at the expense of excessive running time. The current paper is the first that brings the execution time down to compete with existing greedy heuristics. Our GNN model is trained using both supervised and unsupervised techniques. The experimental results show that a 2-layer GNN model can achieve execution times between the largest degree first (LF) and smallest degree last (SL) ordering heuristics while outperforming both on coloring quality. Increasing the number of layers improves the coloring quality further, and it is only at four layers that SL becomes faster than the GNN. Finally, our GNN-based coloring heuristic achieves superior scaling in the parallel setting compared to both SL and LF.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05058",
        "abstract url": "https://arxiv.org/abs/2408.05058",
        "title": "Variational Bayesian Phylogenetic Inference with Semi-implicit Branch Length Distributions",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reconstructing the evolutionary history relating a collection of molecular sequences is the main subject of modern Bayesian phylogenetic inference. However, the commonly used Markov chain Monte Carlo methods can be inefficient due to the complicated space of phylogenetic trees, especially when the number of sequences is large. An alternative approach is variational Bayesian phylogenetic inference (VBPI) which transforms the inference problem into an optimization problem. While effective, the default diagonal lognormal approximation for the branch lengths of the tree used in VBPI is often insufficient to capture the complexity of the exact posterior. In this work, we propose a more flexible family of branch length variational posteriors based on semi-implicit hierarchical distributions using graph neural networks. We show that this semi-implicit construction emits straightforward permutation equivariant distributions, and therefore can handle the non-Euclidean branch length space across different tree topologies with ease. To deal with the intractable marginal probability of semi-implicit variational distributions, we develop several alternative lower bounds for stochastic optimization. We demonstrate the effectiveness of our proposed method over baseline methods on benchmark data examples, in terms of both marginal likelihood estimation and branch length posterior approximation.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "26 pages, 7 figures"
    },
    {
        "paper id": "2408.05075",
        "abstract url": "https://arxiv.org/abs/2408.05075",
        "title": "DeepInteraction++: Multi-Modality Interaction for Autonomous Driving",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Existing top-performance autonomous driving systems typically rely on the multi-modal fusion strategy for reliable scene understanding. This design is however fundamentally restricted due to overlooking the modality-specific strengths and finally hampering the model performance. To address this limitation, in this work, we introduce a novel modality interaction strategy that allows individual per-modality representations to be learned and maintained throughout, enabling their unique characteristics to be exploited during the whole perception pipeline. To demonstrate the effectiveness of the proposed strategy, we design DeepInteraction++, a multi-modal interaction framework characterized by a multi-modal representational interaction encoder and a multi-modal predictive interaction decoder. Specifically, the encoder is implemented as a dual-stream Transformer with specialized attention operation for information exchange and integration between separate modality-specific representations. Our multi-modal representational learning incorporates both object-centric, precise sampling-based feature alignment and global dense information spreading, essential for the more challenging planning task. The decoder is designed to iteratively refine the predictions by alternately aggregating information from separate representations in a unified modality-agnostic manner, realizing multi-modal predictive interaction. Extensive experiments demonstrate the superior performance of the proposed framework on both 3D object detection and end-to-end autonomous driving tasks. Our code is available at https://github.com/fudan-zvg/DeepInteraction.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Journal extension of NeurIPS 2022. arXiv admin note: text overlap with arXiv:2208.11112"
    },
    {
        "paper id": "2408.05087",
        "abstract url": "https://arxiv.org/abs/2408.05087",
        "title": "Bootstrap Latents of Nodes and Neighbors for Graph Self-Supervised Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Contrastive learning is a significant paradigm in graph self-supervised learning. However, it requires negative samples to prevent model collapse and learn discriminative representations. These negative samples inevitably lead to heavy computation, memory overhead and class collision, compromising the representation learning. Recent studies present that methods obviating negative samples can attain competitive performance and scalability enhancements, exemplified by bootstrapped graph latents (BGRL). However, BGRL neglects the inherent graph homophily, which provides valuable insights into underlying positive pairs. Our motivation arises from the observation that subtly introducing a few ground-truth positive pairs significantly improves BGRL. Although we can't obtain ground-truth positive pairs without labels under the self-supervised setting, edges in the graph can reflect noisy positive pairs, i.e., neighboring nodes often share the same label. Therefore, we propose to expand the positive pair set with node-neighbor pairs. Subsequently, we introduce a cross-attention module to predict the supportiveness score of a neighbor with respect to the anchor node. This score quantifies the positive support from each neighboring node, and is encoded into the training objective. Consequently, our method mitigates class collision from negative and noisy positive samples, concurrently enhancing intra-class compactness. Extensive experiments are conducted on five benchmark datasets and three downstream task node classification, node clustering, and node similarity search. The results demonstrate that our method generates node representations with enhanced intra-class compactness and achieves state-of-the-art performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by ECML PKDD 2024"
    },
    {
        "paper id": "2408.05093",
        "abstract url": "https://arxiv.org/abs/2408.05093",
        "title": "Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models",
        "rating": "-0.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Large language models (LLMs) have generated significant attention since their inception, finding applications across various academic and industrial domains. However, these models often suffer from the \"hallucination problem\", where outputs, though grammatically and logically coherent, lack factual accuracy or are entirely fabricated. A particularly troubling issue discovered and widely discussed recently is the numerical comparison error where multiple LLMs incorrectly infer that \"9.11$>$9.9\". We discovered that the order in which LLMs generate answers and reasoning impacts their consistency. Specifically, results vary significantly when an LLM generates an answer first and then provides the reasoning versus generating the reasoning process first and then the conclusion. Inspired by this, we propose a new benchmark method for assessing LLM consistency: comparing responses generated through these two different approaches. This benchmark effectively identifies instances where LLMs fabricate answers and subsequently generate justifications. Furthermore, we introduce a novel and straightforward prompt strategy designed to mitigate this issue. Experimental results demonstrate that this strategy improves performance across various LLMs compared to direct questioning. This work not only sheds light on a critical flaw in LLMs but also offers a practical solution to enhance their reliability.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "7 pages, submitted to AAAI25"
    },
    {
        "paper id": "2408.05330",
        "abstract url": "https://arxiv.org/abs/2408.05330",
        "title": "Neural Machine Unranking",
        "rating": "-0.5",
        "keywords": [
            [
                "unlearning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We tackle the problem of machine unlearning within neural information retrieval, termed Neural Machine UnRanking (NuMuR) for short. Many of the mainstream task- or model-agnostic approaches for machine unlearning were designed for classification tasks. First, we demonstrate that these methods perform poorly on NuMuR tasks due to the unique challenges posed by neural information retrieval. Then, we develop a methodology for NuMuR named Contrastive and Consistent Loss (CoCoL), which effectively balances the objectives of data forgetting and model performance retention. Experimental results demonstrate that CoCoL facilitates more effective and controllable data removal than existing techniques.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05419",
        "abstract url": "https://arxiv.org/abs/2408.05419",
        "title": "Interface Laplace Learning: Learnable Interface Term Helps Semi-Supervised Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a novel framework, called Interface Laplace learning, for graph-based semi-supervised learning. Motivated by the observation that an interface should exist between different classes where the function value is non-smooth, we introduce a Laplace learning model that incorporates an interface term. This model challenges the long-standing assumption that functions are smooth at all unlabeled points. In the proposed approach, we add an interface term to the Laplace learning model at the interface positions. We provide a practical algorithm to approximate the interface positions using k-hop neighborhood indices, and to learn the interface term from labeled data without artificial design. Our method is efficient and effective, and we present extensive experiments demonstrating that Interface Laplace learning achieves better performance than other recent semi-supervised learning approaches at extremely low label rates on the MNIST, FashionMNIST, and CIFAR-10 datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04874",
        "abstract url": "https://arxiv.org/abs/2408.04874",
        "title": "DG Comics: Semi-Automatically Authoring Graph Comics for Dynamic Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Comics are an effective method for sequential data-driven storytelling, especially for dynamic graphs -- graphs whose vertices and edges change over time. However, manually creating such comics is currently time-consuming, complex, and error-prone. In this paper, we propose DG Comics, a novel comic authoring tool for dynamic graphs that allows users to semi-automatically build and annotate comics. The tool uses a newly developed hierarchical clustering algorithm to segment consecutive snapshots of dynamic graphs while preserving their chronological order. It also presents rich information on both individuals and communities extracted from dynamic graphs in multiple views, where users can explore dynamic graphs and choose what to tell in comics. For evaluation, we provide an example and report the results of a user study and an expert review.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "To appear in IEEE Transactions on Visualization and Computer Graphics"
    },
    {
        "paper id": "2408.04889",
        "abstract url": "https://arxiv.org/abs/2408.04889",
        "title": "Deep joint source-channel coding for wireless point cloud transmission",
        "rating": "-1",
        "keywords": [
            [
                "point cloud"
            ]
        ],
        "abstract": "The growing demand for high-quality point cloud transmission over wireless networks presents significant challenges, primarily due to the large data sizes and the need for efficient encoding techniques. In response to these challenges, we introduce a novel system named Deep Point Cloud Semantic Transmission (PCST), designed for end-to-end wireless point cloud transmission. Our approach employs a progressive resampling framework using sparse convolution to project point cloud data into a semantic latent space. These semantic features are subsequently encoded through a deep joint source-channel (JSCC) encoder, generating the channel-input sequence. To enhance transmission efficiency, we use an adaptive entropy-based approach to assess the importance of each semantic feature, allowing transmission lengths to vary according to their predicted entropy. PCST is robust across diverse Signal-to-Noise Ratio (SNR) levels and supports an adjustable rate-distortion (RD) trade-off, ensuring flexible and efficient transmission. Experimental results indicate that PCST significantly outperforms traditional separate source-channel coding (SSCC) schemes, delivering superior reconstruction quality while achieving over a 50% reduction in bandwidth usage.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04898",
        "abstract url": "https://arxiv.org/abs/2408.04898",
        "title": "Object as a Service: Simplifying Cloud-Native Development through Serverless Object Abstraction",
        "rating": "-1",
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "The function-as-a-service (FaaS) paradigm is envisioned as the next generation of cloud computing systems that mitigate the burden for cloud-native application developers by abstracting them from cloud resource management. However, it does not deal with the application data aspects. As such, developers have to intervene and undergo the burden of managing the application data, often via separate cloud storage services. To further streamline cloud-native application development, in this work, we propose a new paradigm, known as Object as a Service (OaaS) that encapsulates application data and functions into the cloud object abstraction. OaaS relieves developers from resource and data management burden while offering built-in optimization features. Inspired by OOP, OaaS incorporates access modifiers and inheritance into the serverless paradigm that: (a) prevents developers from compromising the system via accidentally accessing underlying data; and (b) enables software reuse in cloud-native application development. Furthermore, OaaS natively supports dataflow semantics. It enables developers to define function workflows while transparently handling data navigation, synchronization, and parallelism issues. To establish the OaaS paradigm, we develop a platform named Oparaca that offers state abstraction for structured and unstructured data with consistency and fault-tolerant guarantees. We evaluated Oparaca under real-world settings against state-of-the-art platforms with respect to the imposed overhead, scalability, and ease of use. The results demonstrate that the object abstraction provided by OaaS can streamline flexible and scalable cloud-native application development with an insignificant overhead on the underlying serverless system.",
        "subjects": [
            "cs.DC",
            "cs.OS",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04922",
        "abstract url": "https://arxiv.org/abs/2408.04922",
        "title": "UAV-Enhanced Combination to Application: Comprehensive Analysis and Benchmarking of a Human Detection Dataset for Disaster Scenarios",
        "rating": "-1",
        "keywords": [
            [
                "UAV"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) have revolutionized search and rescue (SAR) operations, but the lack of specialized human detection datasets for training machine learning models poses a significant challenge.To address this gap, this paper introduces the Combination to Application (C2A) dataset, synthesized by overlaying human poses onto UAV-captured disaster scenes. Through extensive experimentation with state-of-the-art detection models, we demonstrate that models fine-tuned on the C2A dataset exhibit substantial performance improvements compared to those pre-trained on generic aerial datasets. Furthermore, we highlight the importance of combining the C2A dataset with general human datasets to achieve optimal performance and generalization across various scenarios. This points out the crucial need for a tailored dataset to enhance the effectiveness of SAR operations. Our contributions also include developing dataset creation pipeline and integrating diverse human poses and disaster scenes information to assess the severity of disaster scenarios. Our findings advocate for future developments, to ensure that SAR operations benefit from the most realistic and effective AI-assisted interventions possible.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "This Paper is accepted for 27th International Conference on Pattern Recognition (ICPR 2024)"
    },
    {
        "paper id": "2408.04940",
        "abstract url": "https://arxiv.org/abs/2408.04940",
        "title": "Capsule Vision 2024 Challenge: Multi-Class Abnormality Classification for Video Capsule Endoscopy",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present the Capsule Vision 2024 Challenge: Multi-Class Abnormality Classification for Video Capsule Endoscopy. It is being virtually organized by the Research Center for Medical Image Analysis and Artificial Intelligence (MIAAI), Department of Medicine, Danube Private University, Krems, Austria and Medical Imaging and Signal Analysis Hub (MISAHUB) in collaboration with the 9th International Conference on Computer Vision & Image Processing (CVIP 2024) being organized by the Indian Institute of Information Technology, Design and Manufacturing (IIITDM) Kancheepuram, Chennai, India. This document describes the overview of the challenge, its registration and rules, submission format, and the description of the utilized datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2408.04949",
        "abstract url": "https://arxiv.org/abs/2408.04949",
        "title": "CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "X-ray",
                "disease"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Due to domain shift, deep learning image classifiers perform poorly when applied to a domain different from the training one. For instance, a classifier trained on chest X-ray (CXR) images from one hospital may not generalize to images from another hospital due to variations in scanner settings or patient characteristics. In this paper, we introduce our CROCODILE framework, showing how tools from causality can foster a model's robustness to domain shift via feature disentanglement, contrastive learning losses, and the injection of prior knowledge. This way, the model relies less on spurious correlations, learns the mechanism bringing from images to prediction better, and outperforms baselines on out-of-distribution (OOD) data. We apply our method to multi-label lung disease classification from CXRs, utilizing over 750000 images from four datasets. Our bias-mitigation method improves domain generalization and fairness, broadening the applicability and reliability of deep learning models for a safer medical image analysis. Find our code at: https://github.com/gianlucarloni/crocodile.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "MICCAI 2024 UNSURE Workshop, Accepted for presentation, Submitted Manuscript Version, 10 pages"
    },
    {
        "paper id": "2408.04972",
        "abstract url": "https://arxiv.org/abs/2408.04972",
        "title": "Digital Semantic Communications: An Alternating Multi-Phase Training Strategy with Mask Attack",
        "rating": "-1",
        "keywords": [
            [
                "Attack"
            ]
        ],
        "abstract": "Semantic communication (SemComm) has emerged as new paradigm shifts.Most existing SemComm systems transmit continuously distributed signals in analog fashion.However, the analog paradigm is not compatible with current digital communication frameworks. In this paper, we propose an alternating multi-phase training strategy (AMP) to enable the joint training of the networks in the encoder and decoder through non-differentiable digital processes. AMP contains three training phases, aiming at feature extraction (FE), robustness enhancement (RE), and training-testing alignment (TTA), respectively. AMP contains three training phases, aiming at feature extraction (FE), robustness enhancement (RE), and training-testing alignment (TTA), respectively. In particular, in the FE stage, we learn the representation ability of semantic information by end-to-end training the encoder and decoder in an analog manner. When we take digital communication into consideration, the domain shift between digital and analog demands the fine-tuning for encoder and decoder. To cope with joint training process within the non-differentiable digital processes, we propose the alternation between updating the decoder individually and jointly training the codec in RE phase. To boost robustness further, we investigate a mask-attack (MATK) in RE to simulate an evident and severe bit-flipping effect in a differentiable manner. To address the training-testing inconsistency introduced by MATK, we employ an additional TTA phase, fine-tuning the decoder without MATK. Combining with AMP and an information restoration network, we propose a digital SemComm system for image transmission, named AMP-SC. Comparing with the representative benchmark, AMP-SC achieves $0.82 \\sim 1.65$dB higher average reconstruction performance among various representative datasets at different scales and a wide range of signal-to-noise ratio.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04976",
        "abstract url": "https://arxiv.org/abs/2408.04976",
        "title": "Exploiting the Lock: Leveraging MiG-V's Logic Locking for Secret-Data Extraction",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The MiG-V was designed for high-security applications and is the first commercially available logic-locked RISC-V processor on the market. In this context logic locking was used to protect the RISC-V processor design during the untrusted manufacturing process by using key-driven logic gates to obfuscate the original design. Although this method defends against malicious modifications, such as hardware Trojans, logic locking's impact on the RISC-V processor's data confidentiality during runtime has not been thoroughly examined. In this study, we evaluate the impact of logic locking on data confidentiality. By altering the logic locking key of the MiG-V while running SSL cryptographic algorithms, we identify data leakages resulting from the exploitation of the logic locking hardware. We show that changing a single bit of the logic locking key can expose 100% of the cryptographic encryption key. This research reveals a critical security flaw in logic locking, highlighting the need for comprehensive security assessments beyond logic locking key-recovery attacks.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "comment": "preprint accepted at the Philosophical Transactions of the Royal Society A, 13 pages"
    },
    {
        "paper id": "2408.04977",
        "abstract url": "https://arxiv.org/abs/2408.04977",
        "title": "Conceptual Design and Implementation of FIDO2 compatible Smart Card for Decentralized Financial Transaction System",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "With challenges and limitations associated with security in the fintech industry, the rise to the need for data protection increases. However, the current existing passwordless and password-based peer to peer transactions in online banking systems are vulnerable to advanced forms of digital attacks. The influx of modern data protection methods keeps better records of the transactions, but it still does not address the issue of authentication and account takeovers during transactions. To the address the mentioned issue, this paper proposes a novel and robust peer to peer transaction system which employs best cloud security practices, proper use of cryptography and trusted computing to mitigate common vulnerabilities. We will be implementing FIDO2 compatible Smart Card to securely authenticate the user using physical smart cards and store the records in the cloud which enables access control by allowing access only when an access is requested. The standard incorporates multiple layers of security on cloud computing models to ensure secrecy of the said data. Services of the standard adhere to regulations provides by the government and assures privacy to the information of the payee or the end-user. The whole system has been implemented in the Internet of Things scenario.",
        "subjects": [
            "cs.CR",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04990",
        "abstract url": "https://arxiv.org/abs/2408.04990",
        "title": "Stochastic Geometry Analysis of RIS-Assisted Cellular Networks with Reflective Intelligent Surfaces on Roads",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Reconfigurable intelligent surfaces (RISs) provide alternative routes for reflected signals to network users, offering numerous applications. This paper explores an innovative approach of strategically deploying RISs along road areas to leverage various propagation and blockage conditions present in cellular networks with roads. To address the local network geometries shown by such networks, we use a stochastic geometry framework, specifically the Cox point processes, to model the locations of RISs and vehicle users. Then, we define the coverage probability as the chance that either a base station or an RIS is in line of sight (LOS) of the typical user and that the LOS signal has a signal-to-noise ratio (SNR) greater than a threshold. We derive the coverage probability as a function of key parameters such as RIS density and path loss exponent. We observe that the network geometry highly affects the coverage and that the proposed RIS deployment effectively leverages the underlying difference of attenuation and blockage, significantly increasing the coverage of vehicle users in the network. With experimental results addressing the impact of key variables to network performance, this work serves as a versatile tool for designing, analyzing, and optimizing RIS-assisted cellular networks with many vehicles.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "accepted to IEEE Transactions on Communications"
    },
    {
        "paper id": "2408.05008",
        "abstract url": "https://arxiv.org/abs/2408.05008",
        "title": "DreamCouple: Exploring High Quality Text-to-3D Generation Via Rectified Flow",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian splatting",
                "NeRF"
            ],
            [
                "diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Score Distillation Sampling (SDS), which exploits pretrained text-to-image model diffusion models as priors to 3D model training, has achieved significant success. Currently, the flow-based diffusion model has become a new trend for generations. Yet, adapting SDS to flow-based diffusion models in 3D generation remains unexplored. Our work is aimed to bridge this gap. In this paper, we adapt SDS to rectified flow and re-examine the over-smoothing issue under this novel framework. The issue can be explained that the model learns an average of multiple ODE trajectories. Then we propose DreamCouple, which instead of randomly sampling noise, uses a rectified flow model to find the coupled noise. Its Unique Couple Matching (UCM) loss guides the model to learn different trajectories and thus solves the over-smoothing issue. We apply our method to both NeRF and 3D Gaussian splatting and achieve state-of-the-art performances. We also identify some other interesting open questions such as initialization issues for NeRF and faster training convergence. Our code will be released soon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Tech Report"
    },
    {
        "paper id": "2408.05020",
        "abstract url": "https://arxiv.org/abs/2408.05020",
        "title": "RadarPillars: Efficient Object Detection from 4D Radar Point Clouds",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "LiDAR",
                "Radar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automotive radar systems have evolved to provide not only range, azimuth and Doppler velocity, but also elevation data. This additional dimension allows for the representation of 4D radar as a 3D point cloud. As a result, existing deep learning methods for 3D object detection, which were initially developed for LiDAR data, are often applied to these radar point clouds. However, this neglects the special characteristics of 4D radar data, such as the extreme sparsity and the optimal utilization of velocity information. To address these gaps in the state-of-the-art, we present RadarPillars, a pillar-based object detection network. By decomposing radial velocity data, introducing PillarAttention for efficient feature extraction, and studying layer scaling to accommodate radar sparsity, RadarPillars significantly outperform state-of-the-art detection results on the View-of-Delft dataset. Importantly, this comes at a significantly reduced parameter count, surpassing existing methods in terms of efficiency and enabling real-time performance on edge devices.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This paper has been accepted at IEEE Intelligent Transportation Systems Conference (ITSC), 2024"
    },
    {
        "paper id": "2408.05022",
        "abstract url": "https://arxiv.org/abs/2408.05022",
        "title": "Robust Backstepping Control of a Quadrotor Unmanned Aerial Vehicle Under Colored Noises",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "Advances in software, sensor and microprocessor technologies have facilitated the production of quadrotor unmanned aerial vehicles. Quadrotor unmanned aerial vehicles are used in important missions such as search and rescue,fight against terrorism, fire fighting, surveillance and cargo transportation. While performing these tasks, Quadrotor unmanned aerial vehicles will have to operate in noisy environments that are not ideal. For this reason, a robust controller design that can control the altitude and position angles of the quadrotor in noisy environments is of great importance. In this research, firstly, a nonlinear model of the quadrotor was created using MATLAB software. Then, a backstepping controller design that is resistant to colored noises was realized. The designed backstepping controller was tested under white Gaussian noise, pink noise, brown noise, blue noise and purple noise. In addition, PID controller design and Lyapunov-based controller design were also carried out and their performances were compared with the backstepping controller. A comparative robustness analysis was performed by obtaining overshoot, rise time and settling time data of all three controllers. When the data obtained was examined, it was proven that the proposed backstepping controller had the least overshoot and shortest settling time under all noise types.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05024",
        "abstract url": "https://arxiv.org/abs/2408.05024",
        "title": "MIDI-to-Tab: Guitar Tablature Inference via Masked Language Modeling",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.CL",
                "cs.SD"
            ]
        ],
        "abstract": "Guitar tablatures enrich the structure of traditional music notation by assigning each note to a string and fret of a guitar in a particular tuning, indicating precisely where to play the note on the instrument. The problem of generating tablature from a symbolic music representation involves inferring this string and fret assignment per note across an entire composition or performance. On the guitar, multiple string-fret assignments are possible for most pitches, which leads to a large combinatorial space that prevents exhaustive search approaches. Most modern methods use constraint-based dynamic programming to minimize some cost function (e.g.\\ hand position movement). In this work, we introduce a novel deep learning solution to symbolic guitar tablature estimation. We train an encoder-decoder Transformer model in a masked language modeling paradigm to assign notes to strings. The model is first pre-trained on DadaGP, a dataset of over 25K tablatures, and then fine-tuned on a curated set of professionally transcribed guitar performances. Given the subjective nature of assessing tablature quality, we conduct a user study amongst guitarists, wherein we ask participants to rate the playability of multiple versions of tablature for the same four-bar excerpt. The results indicate our system significantly outperforms competing algorithms.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "cs.IR"
        ],
        "comment": "Reviewed pre-print accepted for publication at ISMIR 2024"
    },
    {
        "paper id": "2408.05027",
        "abstract url": "https://arxiv.org/abs/2408.05027",
        "title": "Vertex-critical graphs in co-gem-free graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "A graph $G$ is $k$-vertex-critical if $\u03c7(G)=k$ but $\u03c7(G-v)<k$ for all $v\\in V(G)$ and $(G,H)$-free if it contains no induced subgraph isomorphic to $G$ or $H$. We show that there are only finitely many $k$-vertex-critical (co-gem, $H$)-free graphs for all $k$ when $H$ is any graph of order $4$ by showing finiteness in the three remaining open cases, those are the cases when $H$ is $2P_2$, $K_3+P_1$, and $K_4$. For the first two cases we actually prove stronger results when forbidding graphs of order $5$ that contain the graphs of interest as induced subgraphs and employ a novel application of Sperner's Theorem on the number of antichains in a partially ordered set. Our result for $K_4$ uses exhaustive computer search and actually shows the stronger result that every $(\\text{co-gem, }K_4)$-free graph is $4$-colourable. Our results imply the existence of simple polynomial-time certifying algorithms to decide the $k$-colourability of (co-gem, $H$)-free graphs for all $k$ and all $H$ of order $4$ by searching the vertex-critical graphs as induced subgraphs.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05052",
        "abstract url": "https://arxiv.org/abs/2408.05052",
        "title": "Integrating Edge Information into Ground Truth for the Segmentation of the Optic Disc and Cup from Fundus Images",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Optic disc and cup segmentation helps in the diagnosis of glaucoma, myocardial infarction, and diabetic retinopathy. Most deep learning methods developed to perform segmentation tasks are built on top of a U-Net-based model architecture. Nevertheless, U-Net and its variants have a tendency to over-segment/ under-segment the required regions of interest. Since the most important outcome is the value of cup-to-disc ratio and not the segmented regions themselves, we are more concerned about the boundaries rather than the regions under the boundaries. This makes learning edges important as compared to learning the regions. In the proposed work, the authors aim to extract both edges of the optic disc and cup from the ground truth using a Laplacian filter. Next, edges are reconstructed to obtain an edge ground truth in addition to the optic disc-cup ground truth. Utilizing both ground truths, the authors study several U-Net and its variant architectures with and without optic disc and cup edges as target, along with the optic disc-cup ground truth for segmentation. The authors have used the REFUGE benchmark dataset and the Drishti-GS dataset to perform the study, and the results are tabulated for the dice and the Hausdorff distance metrics. In the case of the REFUGE dataset, the optic disc mean dice score has improved from 0.7425 to 0.8859 while the mean Hausdorff distance has reduced from 6.5810 to 3.0540 for the baseline U-Net model. Similarly, the optic cup mean dice score has improved from 0.6970 to 0.8639 while the mean Hausdorff distance has reduced from 5.2340 to 2.6323 for the same model. Similar improvement has been observed for the Drishti-GS dataset as well. Compared to the baseline U-Net and its variants (i.e) the Attention U-Net and the U-Net++, the models that learn integrated edges along with the optic disc and cup regions performed well in both validation and testing datasets.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05069",
        "abstract url": "https://arxiv.org/abs/2408.05069",
        "title": "Exploring Capability-Based Control Distributions of Human-Robot Teams Through Capability Deltas: Formalization and Implications",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "The implicit assumption that human and autonomous agents have certain capabilities is omnipresent in modern teaming concepts. However, none formalize these capabilities in a flexible and quantifiable way. In this paper, we propose Capability Deltas, which establish a quantifiable source to craft autonomous assistance systems in which one agent takes the leader and the other the supporter role. We deduct the quantification of human capabilities based on an established assessment and documentation procedure from occupational inclusion of people with disabilities. This allows us to quantify the delta, or gap, between a team's current capability and a requirement established by a work process. The concept is then extended to the multi-dimensional capability space, which then allows to formalize compensation behavior and assess required actions by the autonomous agent.",
        "subjects": [
            "cs.RO",
            "cs.HC",
            "eess.SY"
        ],
        "comment": "This work was accepted by the IEEE International Conference on Systems, Man, and Cybernetics, Kuching, Malaysia, 2024"
    },
    {
        "paper id": "2408.05074",
        "abstract url": "https://arxiv.org/abs/2408.05074",
        "title": "RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Health",
                "survival",
                "Cancer",
                "disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Accurate patient selection is critical in radiotherapy (RT) to prevent ineffective treatments. Traditional survival prediction models, relying on structured data, often lack precision. This study explores the potential of large language models (LLMs) to structure unstructured electronic health record (EHR) data, thereby improving survival prediction accuracy through comprehensive clinical information integration. Data from 34,276 patients treated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed, encompassing both structured and unstructured data. An open-source LLM was used to structure the unstructured EHR data via single-shot learning, with its performance compared against a domain-specific medical LLM and a smaller variant. Survival prediction models were developed using statistical, machine learning, and deep learning approaches, incorporating both structured and LLM-structured data. Clinical experts evaluated the accuracy of the LLM-structured data. The open-source LLM achieved 87.5% accuracy in structuring unstructured EHR data without additional training, significantly outperforming the domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMs were more effective, particularly in extracting clinically relevant features like general condition and disease extent, which closely correlated with patient survival. Incorporating LLM-structured clinical features into survival prediction models significantly improved accuracy, with the C-index of deep learning models increasing from 0.737 to 0.820. These models also became more interpretable by emphasizing clinically significant factors. This study shows that general-domain LLMs, even without specific medical training, can effectively structure large-scale unstructured EHR data, substantially enhancing the accuracy and interpretability of clinical predictive models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "23 pages, 2 tables, 4 figures"
    },
    {
        "paper id": "2408.05105",
        "abstract url": "https://arxiv.org/abs/2408.05105",
        "title": "Evaluating Layout Dimensionalities in PC+VR Asymmetric Collaborative Decision Making",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "With the commercialization of virtual/augmented reality (VR/AR) devices, there is an increasing interest in combining immersive and non-immersive devices (e.g., desktop computers) for asymmetric collaborations. While such asymmetric settings have been examined in social platforms, significant questions around layout dimensionality in data-driven decision-making remain underexplored. A crucial inquiry arises: although presenting a consistent 3D virtual world on both immersive and non-immersive platforms has been a common practice in social applications, does the same guideline apply to lay out data? Or should data placement be optimized locally according to each device's display capacity? This study aims to provide empirical insights into the user experience of asymmetric collaboration in data-driven decision-making. We tested practical dimensionality combinations between PC and VR, resulting in three conditions: PC2D+VR2D, PC2D+VR3D, and PC3D+VR3D. The results revealed a preference for PC2D+VR3D, and PC2D+VR2D led to the quickest task completion. Our investigation facilitates an in-depth discussion of the trade-offs associated with different layout dimensionalities in asymmetric collaborations.",
        "subjects": [
            "cs.HC",
            "cs.GR"
        ],
        "comment": "To be presented at ACM ISS 2024"
    },
    {
        "paper id": "2408.05108",
        "abstract url": "https://arxiv.org/abs/2408.05108",
        "title": "The LATIN-PGD methodology to nonlinear dynamics and quasi-brittle materials for future earthquake engineering applications",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper presents a first implementation of the LArge Time INcrement (LATIN) method along with the model reduction technique called Proper Generalized Decomposition (PGD) for solving nonlinear low-frequency dynamics problems when dealing with a quasi-brittle isotropic damage constitutive relations. The present paper uses the Time-Discontinuous Galerkin Method (TDGM) for computing the temporal contributions of the space-time separate-variables solution of the LATIN-PGD approach, which offers several advantages when considering a high number of DOFs in time. The efficiency of the method is tested for the case of a 3D bending beam, where results and benchmarks comparing LATIN-PGD to classical time-incremental Newmark/Quasi-Newton nonlinear solver are presented. This work represents a first step towards taking into account uncertainties and carrying out more complex parametric studies imposed by seismic risk assessment.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05176",
        "abstract url": "https://arxiv.org/abs/2408.05176",
        "title": "Modeling Transit in a Fully Integrated Agent-Based Framework: Methodology and Large-Scale Application",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "This study presents a transit routing, assignment, and simulation framework which is fully embedded in a multimodal, multi-agent transportation demand and supply modeling platform. POLARIS, a high-performance agent-based simulation platform, efficiently integrates advanced travel and freight demand modeling, dynamic traffic and transit assignment, and multimodal transportation simulation within a unified framework. We focus on POLARIS's transit routing, assignment, and simulation components, detailing its structural design and essential terminologies. We demonstrate how the model integrates upstream decision-making processes - activity generation, location and timing choices, and mode selection, particularly for transit-inclusive trips - followed by routing, assignment decisions, and the movement of travelers and vehicles within a multimodal network. This integration enables modeling of interactions among all agents, including travelers, vehicles, and transportation service providers. The study reviews literature on transportation system modeling tools, describes the transit modeling framework within POLARIS, and presents findings from large-scale analyses of various policy interventions. Results from numerical experiments reveal that measures such as congestion pricing, transit service improvements, first-mile-last-mile subsidies, increased e-commerce deliveries, and vehicle electrification significantly impact transit ridership, with some interactions between these levers exhibiting synergistic or canceling effects. The case study underscores the necessity of integrating transit modeling within a broader multimodal network simulation and decision-making context.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05183",
        "abstract url": "https://arxiv.org/abs/2408.05183",
        "title": "Uncontrolled learning: co-design of neuromorphic hardware topology for neuromorphic algorithms",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "Hardware-based neuromorphic computing remains an elusive goal with the potential to profoundly impact future technologies and deepen our understanding of emergent intelligence. The learning-from-mistakes algorithm is one of the few training algorithms inspired by the brain's simple learning rules, utilizing inhibition and pruning to demonstrate self-organized learning. Here we implement this algorithm in purely neuromorphic memristive hardware through a co-design process. This implementation requires evaluating hardware trade-offs and constraints. It has been shown that learning-from-mistakes successfully trains small networks to function as binary classifiers and perceptrons. However, without tailoring the hardware to the algorithm, performance decreases exponentially as the network size increases. When implementing neuromorphic algorithms on neuromorphic hardware, we investigate the trade-offs between depth, controllability, and capacity, the latter being the number of learnable patterns. We emphasize the significance of topology and the use of governing equations, demonstrating theoretical tools to aid in the co-design of neuromorphic hardware and algorithms. We provide quantitative techniques to evaluate the computational capacity of a neuromorphic device based on the measurements performed and the underlying circuit structure. This approach shows that breaking the symmetry of a neural network can increase both the controllability and average network capacity. By pruning the circuit, neuromorphic algorithms in all-memristive device circuits leverage stochastic resources to drive local contrast in network weights. Our combined experimental and simulation efforts explore the parameters that make a network suited for displaying emergent intelligence from simple rules.",
        "subjects": [
            "cond-mat.dis-nn",
            "cond-mat.stat-mech",
            "cs.AR",
            "cs.ET"
        ],
        "comment": "35 pages + 24 Supp Mat, 14 Figures; single column; references added"
    },
    {
        "paper id": "2408.05282",
        "abstract url": "https://arxiv.org/abs/2408.05282",
        "title": "Two-Edge Connectivity via Pac-Man Gluing",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We study the 2-edge-connected spanning subgraph (2-ECSS) problem: Given a graph $G$, compute a connected subgraph $H$ of $G$ with the minimum number of edges such that $H$ is spanning, i.e., $V(H) = V(G)$, and $H$ is 2-edge-connected, i.e., $H$ remains connected upon the deletion of any single edge, if such an $H$ exists. The $2$-ECSS problem is known to be NP-hard. In this work, we provide a polynomial-time $(\\frac 5 4 + \\varepsilon)$-approximation for the problem for an arbitrarily small $\\varepsilon>0$, improving the previous best approximation ratio of $\\frac{13}{10}+\\varepsilon$. Our improvement is based on two main innovations: First, we reduce solving the problem on general graphs to solving it on structured graphs with high vertex connectivity. This high vertex connectivity ensures the existence of a 4-matching across any bipartition of the vertex set with at least 10 vertices in each part. Second, we exploit this property in a later gluing step, where isolated 2-edge-connected components need to be merged without adding too many edges. Using the 4-matching property, we can repeatedly glue a huge component (containing at least 10 vertices) to other components. This step is reminiscent of the Pac-Man game, where a Pac-Man (a huge component) consumes all the dots (other components) as it moves through a maze. These two innovations lead to a significantly simpler algorithm and analysis for the gluing step compared to the previous best approximation algorithm, which required a long and tedious case analysis.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "30 pages"
    },
    {
        "paper id": "2408.05286",
        "abstract url": "https://arxiv.org/abs/2408.05286",
        "title": "Text a Bit Longer or Drive Now? Resuming Driving after Texting in Conditionally Automated Cars",
        "rating": "-1",
        "keywords": [
            [
                "automated driving"
            ]
        ],
        "abstract": "In this study, we focus on different strategies drivers use in terms of interleaving between driving and non-driving related tasks (NDRT) while taking back control from automated driving. We conducted two driving simulator experiments to examine how different cognitive demands of texting, priorities, and takeover time budgets affect drivers' takeover strategies. We also evaluated how different takeover strategies affect takeover performance. We found that the choice of takeover strategy was influenced by the priority and takeover time budget but not by the cognitive demand of the NDRT. The takeover strategy did not have any effect on takeover quality or NDRT engagement but influenced takeover timing.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05301",
        "abstract url": "https://arxiv.org/abs/2408.05301",
        "title": "Slow waltzing with REEM-C: a physical-social human-robot interaction study of robot-to-human communication",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Humans often work closely together and relay a wealth of information through physical interaction. Robots, on the other hand, have not yet been developed to work similarly closely with humans, and to effectively convey information when engaging in physical human-robot interaction (pHRI). This currently limits the potential of physical human-robot collaboration to solve real-world problems. This paper investigates the question of how to establish clear and intuitive robot-to-human communication, while ensuring human comfort during pHRI. We approach this question from the perspective of a leader-follower scenario, in which a full-body humanoid robot leads a slow waltz dance by signaling the next steps to a human partner. This is achieved through the development of a whole-body control framework combining admittance and impedance control, which allows for different communication modalities including haptic, visual, and audio signals. Participant experiments allowed to validate the performance of the controller, and to understand what types of communication work better in terms of effectiveness and comfort during robot-led pHRI.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2408.05308",
        "abstract url": "https://arxiv.org/abs/2408.05308",
        "title": "Moving past point-contacts: Extending the ALIP model to humanoids with non-trivial feet using hierarchical, full-body momentum control",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "The Angular-Momentum Linear Inverted Pendulum (ALIP) model is a promising motion planner for bipedal robots. However, it relies on two assumptions: (1) the robot has point-contact feet or passive ankles, and (2) the angular momentum around the center of mass, known as centroidal angular momentum, is negligible. This paper addresses the question of whether the ALIP paradigm can be applied to more general bipedal systems with complex foot geometry (e.g., flat feet) and nontrivial torso/limb inertia and mass distribution (e.g., non-centralized arms). In such systems, the dynamics introduce non-negligible centroidal momentum and contact wrenches at the feet, rendering the assumptions of the ALIP model invalid. This paper presents the ALIP planner for general bipedal robots with non-point-contact feet through the use of a task-space whole-body controller that regulates centroidal momentum, thereby ensuring that the robot's behavior aligns with the desired template dynamics. To demonstrate the effectiveness of our proposed approach, we conduct simulations using the Sarcos Guardian XO robot, which is a hybrid humanoid/exoskeleton with large, offset feet. The results demonstrate the practicality and effectiveness of our approach in achieving stable and versatile bipedal locomotion.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "7 pages, 9 figures"
    },
    {
        "paper id": "2408.05315",
        "abstract url": "https://arxiv.org/abs/2408.05315",
        "title": "Omobot: a low-cost mobile robot for autonomous search and fall detection",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Detecting falls among the elderly and alerting their community responders can save countless lives. We design and develop a low-cost mobile robot that periodically searches the house for the person being monitored and sends an email to a set of designated responders if a fall is detected. In this project, we make three novel design decisions and contributions. First, our custom-designed low-cost robot has advanced features like omnidirectional wheels, the ability to run deep learning models, and autonomous wireless charging. Second, we improve the accuracy of fall detection for the YOLOv8-Pose-nano object detection network by 6% and YOLOv8-Pose-large by 12%. We do so by transforming the images captured from the robot viewpoint (camera height 0.15m from the ground) to a typical human viewpoint (1.5m above the ground) using a principally computed Homography matrix. This improves network accuracy because the training dataset MS-COCO on which YOLOv8-Pose is trained is captured from a human-height viewpoint. Lastly, we improve the robot controller by learning a model that predicts the robot velocity from the input signal to the motor controller.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IEEE AIM-2024"
    },
    {
        "paper id": "2408.05338",
        "abstract url": "https://arxiv.org/abs/2408.05338",
        "title": "Gromov's Approximating Tree and the All-Pairs Bottleneck Paths Problem",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Given a pointed metric space $(X,\\mathsf{dist}, w)$ on $n$ points, its Gromov's approximating tree is a 0-hyperbolic pseudo-metric space $(X,\\mathsf{dist}_T)$ such that $\\mathsf{dist}(x,w)=\\mathsf{dist}_T(x,w)$ and $\\mathsf{dist}(x, y)-2 \u03b4\\log_2n \\leq \\mathsf{dist}_T (x, y) \\leq \\mathsf{dist}(x, y)$ for all $x, y \\in X$ where $\u03b4$ is the Gromov hyperbolicity of $X$. On the other hand, the all pairs bottleneck paths (APBP) problem asks, given an undirected graph with some capacities on its edges, to find the maximal path capacity between each pair of vertices. In this note, we prove: $\\bullet$ Computing Gromov's approximating tree for a metric space with $n+1$ points from its matrix of distances reduces to solving the APBP problem on an connected graph with $n$ vertices. $\\bullet$ There is an explicit algorithm that computes Gromov's approximating tree for a graph from its adjacency matrix in quadratic time. $\\bullet$ Solving the APBP problem on a weighted graph with $n$ vertices reduces to finding Gromov's approximating tree for a metric space with $n+1$ points from its distance matrix.",
        "subjects": [
            "cs.CG",
            "cs.CC",
            "cs.DM",
            "math.CO",
            "math.OC"
        ],
        "comment": "Version 1. Comments are welcome"
    },
    {
        "paper id": "2408.05349",
        "abstract url": "https://arxiv.org/abs/2408.05349",
        "title": "Some integer values in the spectra of burnt pancake graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Here we discuss spectral properties of the burnt pancake graph $\\mathbf{BP}_n$. More precisely, we prove that the adjacency spectrum of $\\mathbf{BP}_n$ contains all integer values in the set $\\{0, 1, \\ldots, n\\}\\setminus\\{\\left\\lfloor n/2 \\right\\rfloor\\}$",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "8 pages, 1 figure"
    },
    {
        "paper id": "2408.05365",
        "abstract url": "https://arxiv.org/abs/2408.05365",
        "title": "FiST-Financial Style Transfer with Hallucination and Creativity Control Framework",
        "rating": "-1",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Financial report generation using general purpose large language models pose two major challenges, including the lack of compound sentences and hallucinations. Advanced prompt engineering and retrieval augmented generation (RAG) techniques are incapable of curing the writing style discrepancies. In this work we propose a novel two-stage fine-tuning process wherein public domain financial reports are processed into prompt-completions and augmented using simple LLM prompts to then enable sectional financial report generation using minimal instructions and tabular data inputs. Our proposed fine-tuning framework results doubles the number of correct questions answers and reduces hallucinations by over 50%. Additionally, the two-stage fine tuned models have lower perplexity, improved ROUGE, TER and BLEU scores, higher creativity and knowledge density with lower uncertainty and cross entropy.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CE"
        ],
        "comment": "8 pages, 13 figures, 5 tables, conference"
    },
    {
        "paper id": "2408.05370",
        "abstract url": "https://arxiv.org/abs/2408.05370",
        "title": "Competitive Capacitated Online Recoloring",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper, we revisit the online recoloring problem introduced recently by Azar et al. In online recoloring, there is a fixed set $V$ of $n$ vertices and an initial coloring $c_0: V\\rightarrow [k]$ for some $k\\in \\mathbb{Z}^{>0}$. Under an online sequence $\u03c3$ of requests where each request is an edge $(u_t,v_t)$, a proper vertex coloring $c$ of the graph $G_t$ induced by requests until time $t$ needs to be maintained for all $t$; i.e., for any $(u,v)\\in G_t$, $c(u)\\neq c(v)$. The objective is to minimize the total weight of vertices recolored for the sequence $\u03c3$. We obtain the first competitive algorithms for capacitated online recoloring and fully dynamic recoloring. Our first set of results is for $2$-recoloring using algorithms that are $(1+\\varepsilon)$-resource augmented where $\\varepsilon\\in (0,1)$ is an arbitrarily small constant. Our main result is an $O(\\log n)$-competitive deterministic algorithm for weighted bipartite graphs, which is asymptotically optimal in light of an $\u03a9(\\log n)$ lower bound that holds for an unbounded amount of augmentation. We also present an $O(n\\log n)$-competitive deterministic algorithm for fully dynamic recoloring, which is optimal within an $O(\\log n)$ factor in light of a $\u03a9(n)$ lower bound that holds for an unbounded amount of augmentation. Our second set of results is for $\u0394$-recoloring in an $(1+\\varepsilon)$-overprovisioned setting where the maximum degree of $G_t$ is bounded by $(1-\\varepsilon)\u0394$ for all $t$, and each color assigned to at most $(1+\\varepsilon)\\frac{n}\u0394$ vertices, for an arbitrary $\\varepsilon > 0$. Our main result is an $O(1)$-competitive randomized algorithm for $\u0394= O(\\sqrt{n/\\log n})$. We also present an $O(\u0394)$-competitive deterministic algorithm for $\u0394\\le \\varepsilon n/2$. Both results are asymptotically optimal.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "comment": "Full version of an ESA '24 paper"
    },
    {
        "paper id": "2408.05384",
        "abstract url": "https://arxiv.org/abs/2408.05384",
        "title": "Nonlinear Propagation of Non-Gaussian Uncertainties: Theory and Applications to Spacecraft Trajectory Design",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "This paper presents a novel approach for propagating uncertainties in dynamical systems building on high-order Taylor expansions of the flow and moment-generating functions (MGFs). Unlike prior methods that focus on Gaussian distributions, our approach leverages the relationship between MGFs and distribution moments to extend high-order uncertainty propagation techniques to non-Gaussian scenarios. This significantly broadens the applicability of these methods to a wider range of problems and uncertainty types. High-order moment computations are performed one-off and symbolically, reducing the computational burden of the technique to the calculation of Taylor series coefficients around a nominal trajectory, achieved by efficiently integrating the system's variational equations. Furthermore, the use of the proposed approach in combination with event transition tensors, allows for accurate propagation of uncertainties at specific events, such as the landing surface of a celestial body, the crossing of a predefined Poincar\u00e9 section, or the trigger of an arbitrary event during the propagation. Via numerical simulations we demonstrate the effectiveness of our method in various astrodynamics applications, including the unperturbed and perturbed two-body problem, and the circular restricted three-body problem, showing that it accurately propagates non-Gaussian uncertainties both at future times and at event manifolds.",
        "subjects": [
            "physics.space-ph",
            "cs.SC",
            "math.PR",
            "nlin.CD"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05438",
        "abstract url": "https://arxiv.org/abs/2408.05438",
        "title": "Convergence Guarantee of Dynamic Programming for LTL Surrogate Reward",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Linear Temporal Logic (LTL) is a formal way of specifying complex objectives for planning problems modeled as Markov Decision Processes (MDPs). The planning problem aims to find the optimal policy that maximizes the satisfaction probability of the LTL objective. One way to solve the planning problem is to use the surrogate reward with two discount factors and dynamic programming, which bypasses the graph analysis used in traditional model-checking. The surrogate reward is designed such that its value function represents the satisfaction probability. However, in some cases where one of the discount factors is set to $1$ for higher accuracy, the computation of the value function using dynamic programming is not guaranteed. This work shows that a multi-step contraction always exists during dynamic programming updates, guaranteeing that the approximate value function will converge exponentially to the true value function. Thus, the computation of satisfaction probability is guaranteed.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Accepted for the 2024 Conference on Decision and Control (CDC)"
    },
    {
        "paper id": "2408.06381",
        "abstract url": "https://arxiv.org/abs/2408.06381",
        "title": "Assessment of Cell Nuclei AI Foundation Models in Kidney Pathology",
        "rating": "-1",
        "keywords": [
            [
                "whole slide"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Cell nuclei instance segmentation is a crucial task in digital kidney pathology. Traditional automatic segmentation methods often lack generalizability when applied to unseen datasets. Recently, the success of foundation models (FMs) has provided a more generalizable solution, potentially enabling the segmentation of any cell type. In this study, we perform a large-scale evaluation of three widely used state-of-the-art (SOTA) cell nuclei foundation models (Cellpose, StarDist, and CellViT). Specifically, we created a highly diverse evaluation dataset consisting of 2,542 kidney whole slide images (WSIs) collected from both human and rodent sources, encompassing various tissue types, sizes, and staining methods. To our knowledge, this is the largest-scale evaluation of its kind to date. Our quantitative analysis of the prediction distribution reveals a persistent performance gap in kidney pathology. Among the evaluated models, CellViT demonstrated superior performance in segmenting nuclei in kidney pathology. However, none of the foundation models are perfect; a performance gap remains in general nuclei segmentation for kidney pathology.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04867",
        "abstract url": "https://arxiv.org/abs/2408.04867",
        "title": "An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This research examines the use of Large Language Models (LLMs) in predicting time series, with a specific focus on the LLMTIME model. Despite the established effectiveness of LLMs in tasks such as text generation, language translation, and sentiment analysis, this study highlights the key challenges that large language models encounter in the context of time series prediction. We assess the performance of LLMTIME across multiple datasets and introduce classical almost periodic functions as time series to gauge its effectiveness. The empirical results indicate that while large language models can perform well in zero-shot forecasting for certain datasets, their predictive accuracy diminishes notably when confronted with diverse time series data and traditional signals. The primary finding of this study is that the predictive capacity of LLMTIME, similar to other LLMs, significantly deteriorates when dealing with time series data that contain both periodic and trend components, as well as when the signal comprises complex frequency components.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04963",
        "abstract url": "https://arxiv.org/abs/2408.04963",
        "title": "LiD-FL: Towards List-Decodable Federated Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning is often used in environments with many unverified participants. Therefore, federated learning under adversarial attacks receives significant attention. This paper proposes an algorithmic framework for list-decodable federated learning, where a central server maintains a list of models, with at least one guaranteed to perform well. The framework has no strict restriction on the fraction of honest workers, extending the applicability of Byzantine federated learning to the scenario with more than half adversaries. Under proper assumptions on the loss function, we prove a convergence theorem for our method. Experimental results, including image classification tasks with both convex and non-convex losses, demonstrate that the proposed algorithm can withstand the malicious majority under various attacks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "26 pages, 5 figures"
    },
    {
        "paper id": "2408.04969",
        "abstract url": "https://arxiv.org/abs/2408.04969",
        "title": "Towards aerodynamic surrogate modeling based on $\u03b2$-variational autoencoders",
        "rating": "-1.5",
        "keywords": [
            [
                "flight"
            ],
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Surrogate models combining dimensionality reduction and regression techniques are essential to reduce the need for costly high-fidelity CFD data. New approaches using $\u03b2$-Variational Autoencoder ($\u03b2$-VAE) architectures have shown promise in obtaining high-quality low-dimensional representations of high-dimensional flow data while enabling physical interpretation of their latent spaces. We propose a surrogate model based on latent space regression to predict pressure distributions on a transonic wing given the flight conditions: Mach number and angle of attack. The $\u03b2$-VAE model, enhanced with Principal Component Analysis (PCA), maps high-dimensional data to a low-dimensional latent space, showing a direct correlation with flight conditions. Regularization through $\u03b2$ requires careful tuning to improve the overall performance, while PCA pre-processing aids in constructing an effective latent space, improving autoencoder training and performance. Gaussian Process Regression is used to predict latent space variables from flight conditions, showing robust behavior independent of $\u03b2$, and the decoder reconstructs the high-dimensional pressure field data. This pipeline provides insight into unexplored flight conditions. Additionally, a fine-tuning process of the decoder further refines the model, reducing dependency on $\u03b2$ and enhancing accuracy. The structured latent space, robust regression performance, and significant improvements from fine-tuning collectively create a highly accurate and efficient surrogate model. Our methodology demonstrates the effectiveness of $\u03b2$-VAEs for aerodynamic surrogate modeling, offering a rapid, cost-effective, and reliable alternative for aerodynamic data prediction.",
        "subjects": [
            "cs.LG",
            "physics.flu-dyn"
        ],
        "comment": "18 pages, 12 figures"
    },
    {
        "paper id": "2408.05037",
        "abstract url": "https://arxiv.org/abs/2408.05037",
        "title": "A conformalized learning of a prediction set with applications to medical imaging classification",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Medical imaging classifiers can achieve high predictive accuracy, but quantifying their uncertainty remains an unresolved challenge, which prevents their deployment in medical clinics. We present an algorithm that can modify any classifier to produce a prediction set containing the true label with a user-specified probability, such as 90%. We train a network to predict an instance-based version of the Conformal Prediction threshold. The threshold is then conformalized to ensure the required coverage. We applied the proposed algorithm to several standard medical imaging classification datasets. The experimental results demonstrate that our method outperforms current approaches in terms of smaller average size of the prediction set while maintaining the desired coverage.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21st IEEE International Symposium on Biomedical Imaging (ISBI) camera-ready"
    },
    {
        "paper id": "2408.05040",
        "abstract url": "https://arxiv.org/abs/2408.05040",
        "title": "BoFire: Bayesian Optimization Framework Intended for Real Experiments",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial",
                "chemistry",
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Our open-source Python package BoFire combines Bayesian Optimization (BO) with other design of experiments (DoE) strategies focusing on developing and optimizing new chemistry. Previous BO implementations, for example as they exist in the literature or software, require substantial adaptation for effective real-world deployment in chemical industry. BoFire provides a rich feature-set with extensive configurability and realizes our vision of fast-tracking research contributions into industrial use via maintainable open-source software. Owing to quality-of-life features like JSON-serializability of problem formulations, BoFire enables seamless integration of BO into RESTful APIs, a common architecture component for both self-driving laboratories and human-in-the-loop setups. This paper discusses the differences between BoFire and other BO implementations and outlines ways that BO research needs to be adapted for real-world use in a chemistry setting.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "comment": "6 pages, 1 figure, 1 listing"
    },
    {
        "paper id": "2408.05065",
        "abstract url": "https://arxiv.org/abs/2408.05065",
        "title": "Masked adversarial neural network for cell type deconvolution in spatial transcriptomics",
        "rating": "-1.5",
        "keywords": [
            [
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurately determining cell type composition in disease-relevant tissues is crucial for identifying disease targets. Most existing spatial transcriptomics (ST) technologies cannot achieve single-cell resolution, making it challenging to accurately determine cell types. To address this issue, various deconvolution methods have been developed. Most of these methods use single-cell RNA sequencing (scRNA-seq) data from the same tissue as a reference to infer cell types in ST data spots. However, they often overlook the differences between scRNA-seq and ST data. To overcome this limitation, we propose a Masked Adversarial Neural Network (MACD). MACD employs adversarial learning to align real ST data with simulated ST data generated from scRNA-seq data. By mapping them into a unified latent space, it can minimize the differences between the two types of data. Additionally, MACD uses masking techniques to effectively learn the features of real ST data and mitigate noise. We evaluated MACD on 32 simulated datasets and 2 real datasets, demonstrating its accuracy in performing cell type deconvolution. All code and public datasets used in this paper are available at https://github.com/wenwenmin/MACD and https://zenodo.org/records/12804822.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05116",
        "abstract url": "https://arxiv.org/abs/2408.05116",
        "title": "Concept learning of parameterized quantum models from limited measurements",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Classical learning of the expectation values of observables for quantum states is a natural variant of learning quantum states or channels. While learning-theoretic frameworks establish the sample complexity and the number of measurement shots per sample required for learning such statistical quantities, the interplay between these two variables has not been adequately quantified before. In this work, we take the probabilistic nature of quantum measurements into account in classical modelling and discuss these quantities under a single unified learning framework. We provide provable guarantees for learning parameterized quantum models that also quantify the asymmetrical effects and interplay of the two variables on the performance of learning algorithms. These results show that while increasing the sample size enhances the learning performance of classical machines, even with single-shot estimates, the improvements from increasing measurements become asymptotically trivial beyond a constant factor. We further apply our framework and theoretical guarantees to study the impact of measurement noise on the classical surrogation of parameterized quantum circuit models. Our work provides new tools to analyse the operational influence of finite measurement noise in the classical learning of quantum systems.",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "16 + 8 pages, 4 figures"
    },
    {
        "paper id": "2408.05151",
        "abstract url": "https://arxiv.org/abs/2408.05151",
        "title": "Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Automatic modulation classification (AMC) is an effective way to deal with physical layer threats of the internet of things (IoT). However, there is often label mislabeling in practice, which significantly impacts the performance and robustness of deep neural networks (DNNs). In this paper, we propose a meta-learning guided label noise distillation method for robust AMC. Specifically, a teacher-student heterogeneous network (TSHN) framework is proposed to distill and reuse label noise. Based on the idea that labels are representations, the teacher network with trusted meta-learning divides and conquers untrusted label samples and then guides the student network to learn better by reassessing and correcting labels. Furthermore, we propose a multi-view signal (MVS) method to further improve the performance of hard-to-classify categories with few-shot trusted label samples. Extensive experimental results show that our methods can significantly improve the performance and robustness of signal AMC in various and complex label noise scenarios, which is crucial for securing IoT applications.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2408.05160",
        "abstract url": "https://arxiv.org/abs/2408.05160",
        "title": "Federated Hypergraph Learning with Hyperedge Completion",
        "rating": "-1.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hypergraph neural networks enhance conventional graph neural networks by capturing high-order relationships among nodes, which proves vital in data-rich environments where interactions are not merely pairwise. As data complexity and interconnectivity grow, it is common for graph-structured data to be split and stored in a distributed manner, underscoring the necessity of federated learning on subgraphs. In this work, we propose FedHGN, a novel algorithm for federated hypergraph learning. Our algorithm utilizes subgraphs of a hypergraph stored on distributed devices to train local HGNN models in a federated manner:by collaboratively developing an effective global HGNN model through sharing model parameters while preserving client privacy. Additionally, considering that hyperedges may span multiple clients, a pre-training step is employed before the training process in which cross-client hyperedge feature gathering is performed at the central server. In this way, the missing cross-client information can be supplemented from the central server during the node feature aggregation phase. Experimental results on seven real-world datasets confirm the effectiveness of our approach and demonstrate its performance advantages over traditional federated graph learning methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05165",
        "abstract url": "https://arxiv.org/abs/2408.05165",
        "title": "Higher-Order Temporal Network Prediction and Interpretation",
        "rating": "-1.5",
        "keywords": [
            [
                "forecast"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "A social interaction (so-called higher-order event/interaction) can be regarded as the activation of the hyperlink among the corresponding individuals. Social interactions can be, thus, represented as higher-order temporal networks, that record the higher-order events occurring at each time step over time. The prediction of higher-order interactions is usually overlooked in traditional temporal network prediction methods, where a higher-order interaction is regarded as a set of pairwise interactions. The prediction of future higher-order interactions is crucial to forecast and mitigate the spread the information, epidemics and opinion on higher-order social contact networks. In this paper, we propose novel memory-based models for higher-order temporal network prediction. By using these models, we aim to predict the higher-order temporal network one time step ahead, based on the network observed in the past. Importantly, we also intent to understand what network properties and which types of previous interactions enable the prediction. The design and performance analysis of these models are supported by our analysis of the memory property of networks, e.g., similarity of the network and activity of a hyperlink over time respectively. Our models assume that a target hyperlink's future activity (active or not) depends the past activity of the target link and of all or selected types of hyperlinks that overlap with the target. We then compare the performance of both models with a baseline utilizing a pairwise temporal network prediction method. In eight real-world networks, we find that both models consistently outperform the baseline and the refined model tends to perform the best. Our models also reveal how past interactions of the target hyperlink and different types of hyperlinks that overlap with the target contribute to the prediction of the target's future activity.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2309.04376"
    },
    {
        "paper id": "2408.05177",
        "abstract url": "https://arxiv.org/abs/2408.05177",
        "title": "Beyond Closure Models: Learning Chaotic-Systems via Physics-Informed Neural Operators",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurately predicting the long-term behavior of chaotic systems is crucial for various applications such as climate modeling. However, achieving such predictions typically requires iterative computations over a dense spatiotemporal grid to account for the unstable nature of chaotic systems, which is expensive and impractical in many real-world situations. An alternative approach to such a full-resolved simulation is using a coarse grid and then correcting its errors through a \\textit{closure model}, which approximates the overall information from fine scales not captured in the coarse-grid simulation. Recently, ML approaches have been used for closure modeling, but they typically require a large number of training samples from expensive fully-resolved simulations (FRS). In this work, we prove an even more fundamental limitation, i.e., the standard approach to learning closure models suffers from a large approximation error for generic problems, no matter how large the model is, and it stems from the non-uniqueness of the mapping. We propose an alternative end-to-end learning approach using a physics-informed neural operator (PINO) that overcomes this limitation by not using a closure model or a coarse-grid solver. We first train the PINO model on data from a coarse-grid solver and then fine-tune it with (a small amount of) FRS and physics-based losses on a fine grid. The discretization-free nature of neural operators means that they do not suffer from the restriction of a coarse grid that closure models face, and they can provably approximate the long-term statistics of chaotic systems. In our experiments, our PINO model achieves a 120x speedup compared to FRS with a relative error $\\sim 5\\%$. In contrast, the closure model coupled with a coarse-grid solver is $58$x slower than PINO while having a much higher error $\\sim205\\%$ when the closure model is trained on the same FRS dataset.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05178",
        "abstract url": "https://arxiv.org/abs/2408.05178",
        "title": "ECG-FM: An Open Electrocardiogram Foundation Model",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "cardiac"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The electrocardiogram (ECG) is a ubiquitous diagnostic test. Conventional task-specific ECG analysis models require large numbers of expensive ECG annotations or associated labels to train. Transfer learning techniques have been shown to improve generalization and reduce reliance on labeled data. We present ECG-FM, an open foundation model for ECG analysis, and conduct a comprehensive study performed on a dataset of 1.66 million ECGs sourced from both publicly available and private institutional sources. ECG-FM adopts a transformer-based architecture and is pretrained on 2.5 million samples using ECG-specific augmentations and contrastive learning, as well as a continuous signal masking objective. Our transparent evaluation includes a diverse range of downstream tasks, where we predict ECG interpretation labels, reduced left ventricular ejection fraction, and abnormal cardiac troponin. Affirming ECG-FM's effectiveness as a foundation model, we demonstrate how its command of contextual information results in strong performance, rich pretrained embeddings, and reliable interpretability. Due to a lack of open-weight practices, we highlight how ECG analysis is lagging behind other medical machine learning subfields in terms of foundation model adoption. Our code is available at https://github.com/bowang-lab/ECG-FM/.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "22 pages, 7 figures, 10 tables"
    },
    {
        "paper id": "2408.05195",
        "abstract url": "https://arxiv.org/abs/2408.05195",
        "title": "HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling",
        "rating": "-1.5",
        "keywords": [
            [
                "survival",
                "Whole Slide",
                "Cancer"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning in computational pathology (CPath) often aggregates patch-level predictions from multi-gigapixel Whole Slide Images (WSIs) to generate WSI-level prediction scores for crucial tasks such as survival prediction and drug effect prediction. However, current methods do not explicitly characterize distributional differences between patch sets within WSIs. We introduce HistoKernel, a novel Maximum Mean Discrepancy (MMD) kernel that measures distributional similarity between WSIs for enhanced prediction performance on downstream prediction tasks. Our comprehensive analysis demonstrates HistoKernel's effectiveness across various machine learning tasks, including retrieval (n = 9,362), drug sensitivity regression (n = 551), point mutation classification (n = 3,419), and survival analysis (n = 2,291), outperforming existing deep learning methods. Additionally, HistoKernel seamlessly integrates multi-modal data and offers a novel perturbation-based method for patch-level explainability. This work pioneers the use of kernel-based methods for WSI-level predictive modeling, opening new avenues for research. Code is available at https://github.com/pkeller00/HistoKernel.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "28 pages, 5 figures, 1 Table. Preprint for article in review at Nature Machine Intelligence"
    },
    {
        "paper id": "2408.05196",
        "abstract url": "https://arxiv.org/abs/2408.05196",
        "title": "Cell Morphology-Guided Small Molecule Generation with GFlowNets",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "High-content phenotypic screening, including high-content imaging (HCI), has gained popularity in the last few years for its ability to characterize novel therapeutics without prior knowledge of the protein target. When combined with deep learning techniques to predict and represent molecular-phenotype interactions, these advancements hold the potential to significantly accelerate and enhance drug discovery applications. This work focuses on the novel task of HCI-guided molecular design. Generative models for molecule design could be guided by HCI data, for example with a supervised model that links molecules to phenotypes of interest as a reward function. However, limited labeled data, combined with the high-dimensional readouts, can make training these methods challenging and impractical. We consider an alternative approach in which we leverage an unsupervised multimodal joint embedding to define a latent similarity as a reward for GFlowNets. The proposed model learns to generate new molecules that could produce phenotypic effects similar to those of the given image target, without relying on pre-annotated phenotypic labels. We demonstrate that the proposed method generates molecules with high morphological and structural similarity to the target, increasing the likelihood of similar biological activity, as confirmed by an independent oracle model.",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05205",
        "abstract url": "https://arxiv.org/abs/2408.05205",
        "title": "Kalman-Inspired Feature Propagation for Video Face Super-Resolution",
        "rating": "-1.5",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Despite the promising progress of face image super-resolution, video face super-resolution remains relatively under-explored. Existing approaches either adapt general video super-resolution networks to face datasets or apply established face image super-resolution models independently on individual video frames. These paradigms encounter challenges either in reconstructing facial details or maintaining temporal consistency. To address these issues, we introduce a novel framework called Kalman-inspired Feature Propagation (KEEP), designed to maintain a stable face prior over time. The Kalman filtering principles offer our method a recurrent ability to use the information from previously restored frames to guide and regulate the restoration process of the current frame. Extensive experiments demonstrate the effectiveness of our method in capturing facial details consistently across video frames. Code and video demo are available at https://jnjaby.github.io/projects/KEEP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024. Project page: https://jnjaby.github.io/projects/KEEP/"
    },
    {
        "paper id": "2408.05314",
        "abstract url": "https://arxiv.org/abs/2408.05314",
        "title": "rule4ml: An Open-Source Tool for Resource Utilization and Latency Estimation for ML Models on FPGA",
        "rating": "-1.5",
        "keywords": [
            [
                "FPGA"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Implementing Machine Learning (ML) models on Field-Programmable Gate Arrays (FPGAs) is becoming increasingly popular across various domains as a low-latency and low-power solution that helps manage large data rates generated by continuously improving detectors. However, developing ML models for FPGAs is time-consuming, as optimization requires synthesis to evaluate FPGA area and latency, making the process slow and repetitive. This paper introduces a novel method to predict the resource utilization and inference latency of Neural Networks (NNs) before their synthesis and implementation on FPGA. We leverage HLS4ML, a tool-flow that helps translate NNs into high-level synthesis (HLS) code, to synthesize a diverse dataset of NN architectures and train resource utilization and inference latency predictors. While HLS4ML requires full synthesis to obtain resource and latency insights, our method uses trained regression models for immediate pre-synthesis predictions. The prediction models estimate the usage of Block RAM (BRAM), Digital Signal Processors (DSP), Flip-Flops (FF), and Look-Up Tables (LUT), as well as the inference clock cycles. The predictors were evaluated on both synthetic and existing benchmark architectures and demonstrated high accuracy with R2 scores ranging between 0.8 and 0.98 on the validation set and sMAPE values between 10% and 30%. Overall, our approach provides valuable preliminary insights, enabling users to quickly assess the feasibility and efficiency of NNs on FPGAs, accelerating the development and deployment processes. The open-source repository can be found at https://github.com/IMPETUS-UdeS/rule4ml, while the datasets are publicly available at https://borealisdata.ca/dataverse/rule4ml.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05336",
        "abstract url": "https://arxiv.org/abs/2408.05336",
        "title": "Logically Constrained Robotics Transformers for Enhanced Perception-Action Planning",
        "rating": "-1.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the advent of large foundation model based planning, there is a dire need to ensure their output aligns with the stakeholder's intent. When these models are deployed in the real world, the need for alignment is magnified due to the potential cost to life and infrastructure due to unexpected faliures. Temporal Logic specifications have long provided a way to constrain system behaviors and are a natural fit for these use cases. In this work, we propose a novel approach to factor in signal temporal logic specifications while using autoregressive transformer models for trajectory planning. We also provide a trajectory dataset for pretraining and evaluating foundation models. Our proposed technique acheives 74.3 % higher specification satisfaction over the baselines.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "Robotics Science and Systems: Towards Safe Autonomy"
    },
    {
        "paper id": "2408.05357",
        "abstract url": "https://arxiv.org/abs/2408.05357",
        "title": "SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions",
        "rating": "-1.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The electric vehicle (EV) battery supply chain's vulnerability to disruptions necessitates advanced predictive analytics. We present SHIELD (Schema-based Hierarchical Induction for EV supply chain Disruption), a system integrating Large Language Models (LLMs) with domain expertise for EV battery supply chain risk assessment. SHIELD combines: (1) LLM-driven schema learning to construct a comprehensive knowledge library, (2) a disruption analysis system utilizing fine-tuned language models for event extraction, multi-dimensional similarity matching for schema matching, and Graph Convolutional Networks (GCNs) with logical constraints for prediction, and (3) an interactive interface for visualizing results and incorporating expert feedback to enhance decision-making. Evaluated on 12,070 paragraphs from 365 sources (2022-2023), SHIELD outperforms baseline GCNs and LLM+prompt methods (e.g., GPT-4o) in disruption prediction. These results demonstrate SHIELD's effectiveness in combining LLM capabilities with domain expertise for enhanced supply chain risk assessment.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": "30 pages, 11 figures, Project: https://f1y1113.github.io/MFI/"
    },
    {
        "paper id": "2408.05387",
        "abstract url": "https://arxiv.org/abs/2408.05387",
        "title": "EclipseNETs: a differentiable description of irregular eclipse conditions",
        "rating": "-1.5",
        "keywords": [
            [
                "thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the field of spaceflight mechanics and astrodynamics, determining eclipse regions is a frequent and critical challenge. This determination impacts various factors, including the acceleration induced by solar radiation pressure, the spacecraft power input, and its thermal state all of which must be accounted for in various phases of the mission design. This study leverages recent advances in neural image processing to develop fully differentiable models of eclipse regions for highly irregular celestial bodies. By utilizing test cases involving Solar System bodies previously visited by spacecraft, such as 433 Eros, 25143 Itokawa, 67P/Churyumov--Gerasimenko, and 101955 Bennu, we propose and study an implicit neural architecture defining the shape of the eclipse cone based on the Sun's direction. Employing periodic activation functions, we achieve high precision in modeling eclipse conditions. Furthermore, we discuss the potential applications of these differentiable models in spaceflight mechanics computations.",
        "subjects": [
            "cs.LG",
            "astro-ph.IM",
            "physics.space-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05406",
        "abstract url": "https://arxiv.org/abs/2408.05406",
        "title": "Efficient Quantum Gradient and Higher-order Derivative Estimation via Generalized Hadamard Test",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the context of Noisy Intermediate-Scale Quantum (NISQ) computing, parameterized quantum circuits (PQCs) represent a promising paradigm for tackling challenges in quantum sensing, optimal control, optimization, and machine learning on near-term quantum hardware. Gradient-based methods are crucial for understanding the behavior of PQCs and have demonstrated substantial advantages in the convergence rates of Variational Quantum Algorithms (VQAs) compared to gradient-free methods. However, existing gradient estimation methods, such as Finite Difference, Parameter Shift Rule, Hadamard Test, and Direct Hadamard Test, often yield suboptimal gradient circuits for certain PQCs. To address these limitations, we introduce the Flexible Hadamard Test, which, when applied to first-order gradient estimation methods, can invert the roles of ansatz generators and observables. This inversion facilitates the use of measurement optimization techniques to efficiently compute PQC gradients. Additionally, to overcome the exponential cost of evaluating higher-order partial derivatives, we propose the $k$-fold Hadamard Test, which computes the $k^{th}$-order partial derivative using a single circuit. Furthermore, we introduce Quantum Automatic Differentiation (QAD), a unified gradient method that adaptively selects the best gradient estimation technique for individual parameters within a PQC. This represents the first implementation, to our knowledge, that departs from the conventional practice of uniformly applying a single method to all parameters. Through rigorous numerical experiments, we demonstrate the effectiveness of our proposed first-order gradient methods, showing up to an $O(N)$ factor improvement in circuit execution count for real PQC applications. Our research contributes to the acceleration of VQA computations, offering practical utility in the NISQ era of quantum computing.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05427",
        "abstract url": "https://arxiv.org/abs/2408.05427",
        "title": "Detecting Masquerade Attacks in Controller Area Networks Using Graph Machine Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modern vehicles rely on a myriad of electronic control units (ECUs) interconnected via controller area networks (CANs) for critical operations. Despite their ubiquitous use and reliability, CANs are susceptible to sophisticated cyberattacks, particularly masquerade attacks, which inject false data that mimic legitimate messages at the expected frequency. These attacks pose severe risks such as unintended acceleration, brake deactivation, and rogue steering. Traditional intrusion detection systems (IDS) often struggle to detect these subtle intrusions due to their seamless integration into normal traffic. This paper introduces a novel framework for detecting masquerade attacks in the CAN bus using graph machine learning (ML). We hypothesize that the integration of shallow graph embeddings with time series features derived from CAN frames enhances the detection of masquerade attacks. We show that by representing CAN bus frames as message sequence graphs (MSGs) and enriching each node with contextual statistical attributes from time series, we can enhance detection capabilities across various attack patterns compared to using only graph-based features. Our method ensures a comprehensive and dynamic analysis of CAN frame interactions, improving robustness and efficiency. Extensive experiments on the ROAD dataset validate the effectiveness of our approach, demonstrating statistically significant improvements in the detection rates of masquerade attacks compared to a baseline that uses only graph-based features, as confirmed by Mann-Whitney U and Kolmogorov-Smirnov tests (p < 0.05).",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05437",
        "abstract url": "https://arxiv.org/abs/2408.05437",
        "title": "Predicting Long-Term Allograft Survival in Liver Transplant Recipients",
        "rating": "-1.5",
        "keywords": [
            [
                "Survival",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Liver allograft failure occurs in approximately 20% of liver transplant recipients within five years post-transplant, leading to mortality or the need for retransplantation. Providing an accurate and interpretable model for individualized risk estimation of graft failure is essential for improving post-transplant care. To this end, we introduce the Model for Allograft Survival (MAS), a simple linear risk score that outperforms other advanced survival models. Using longitudinal patient follow-up data from the United States (U.S.), we develop our models on 82,959 liver transplant recipients and conduct multi-site evaluations on 11 regions. Additionally, by testing on a separate non-U.S. cohort, we explore the out-of-distribution generalization performance of various models without additional fine-tuning, a crucial property for clinical deployment. We find that the most complex models are also the ones most vulnerable to distribution shifts despite achieving the best in-distribution performance. Our findings not only provide a strong risk score for predicting long-term graft failure but also suggest that the routine machine learning pipeline with only in-distribution held-out validation could create harmful consequences for patients at deployment.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at MLHC 2024"
    },
    {
        "paper id": "2408.04863",
        "abstract url": "https://arxiv.org/abs/2408.04863",
        "title": "Coding-PTMs: How to Find Optimal Code Pre-trained Models for Code Embedding in Vulnerability Detection?",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Vulnerability detection is garnering increasing attention in software engineering, since code vulnerabilities possibly pose significant security. Recently, reusing various code pre-trained models has become common for code embedding without providing reasonable justifications in vulnerability detection. The premise for casually utilizing pre-trained models (PTMs) is that the code embeddings generated by different PTMs would generate a similar impact on the performance. Is that TRUE? To answer this important question, we systematically investigate the effects of code embedding generated by ten different code PTMs on the performance of vulnerability detection, and get the answer, i.e., that is NOT true. We observe that code embedding generated by various code PTMs can indeed influence the performance and selecting an embedding technique based on parameter scales and embedding dimension is not reliable. Our findings highlight the necessity of quantifying and evaluating the characteristics of code embedding generated by various code PTMs to understand the effects. To achieve this goal, we analyze the numerical representation and data distribution of code embedding generated by different PTMs to evaluate differences and characteristics. Based on these insights, we propose Coding-PTMs, a recommendation framework to assist engineers in selecting optimal code PTMs for their specific vulnerability detection tasks. Specifically, we define thirteen code embedding metrics across three dimensions (i.e., statistics, norm, and distribution) for constructing a specialized code PTM recommendation dataset. We then employ a Random Forest classifier to train a recommendation model and identify the optimal code PTMs from the candidate model zoo.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by ASE 2024"
    },
    {
        "paper id": "2408.04865",
        "abstract url": "https://arxiv.org/abs/2408.04865",
        "title": "TEAdapter: Supply abundant guidance for controllable text-to-music generation",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "music",
                "text-to-music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Although current text-guided music generation technology can cope with simple creative scenarios, achieving fine-grained control over individual text-modality conditions remains challenging as user demands become more intricate. Accordingly, we introduce the TEAcher Adapter (TEAdapter), a compact plugin designed to guide the generation process with diverse control information provided by users. In addition, we explore the controllable generation of extended music by leveraging TEAdapter control groups trained on data of distinct structural functionalities. In general, we consider controls over global, elemental, and structural levels. Experimental results demonstrate that the proposed TEAdapter enables multiple precise controls and ensures high-quality music generation. Our module is also lightweight and transferable to any diffusion model architecture. Available code and demos will be found soon at https://github.com/Ashley1101/TEAdapter.",
        "subjects": [
            "cs.SD",
            "cs.MM",
            "eess.AS"
        ],
        "comment": "Accepted by ICME'24: IEEE International Conference on Multimedia and Expo"
    },
    {
        "paper id": "2408.04868",
        "abstract url": "https://arxiv.org/abs/2408.04868",
        "title": "ChatGPT Meets Iris Biometrics",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Biometrics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study utilizes the advanced capabilities of the GPT-4 multimodal Large Language Model (LLM) to explore its potential in iris recognition - a field less common and more specialized than face recognition. By focusing on this niche yet crucial area, we investigate how well AI tools like ChatGPT can understand and analyze iris images. Through a series of meticulously designed experiments employing a zero-shot learning approach, the capabilities of ChatGPT-4 was assessed across various challenging conditions including diverse datasets, presentation attacks, occlusions such as glasses, and other real-world variations. The findings convey ChatGPT-4's remarkable adaptability and precision, revealing its proficiency in identifying distinctive iris features, while also detecting subtle effects like makeup on iris recognition. A comparative analysis with Gemini Advanced - Google's AI model - highlighted ChatGPT-4's better performance and user experience in complex iris analysis tasks. This research not only validates the use of LLMs for specialized biometric applications but also emphasizes the importance of nuanced query framing and interaction design in extracting significant insights from biometric data. Our findings suggest a promising path for future research and the development of more adaptable, efficient, robust and interactive biometric security solutions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published at IJCB 2024"
    },
    {
        "paper id": "2408.04901",
        "abstract url": "https://arxiv.org/abs/2408.04901",
        "title": "CTE-MLO: Continuous-time and Efficient Multi-LiDAR Odometry with Localizability-aware Point Cloud Sampling",
        "rating": "-2",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "autonomous driving",
                "trajectory",
                "LiDAR"
            ]
        ],
        "abstract": "In recent years, LiDAR-based localization and mapping methods have achieved significant progress thanks to their reliable and real-time localization capability. Considering single LiDAR odometry often faces hardware failures and degradation in practical scenarios, Multi-LiDAR Odometry (MLO), as an emerging technology, is studied to enhance the performance of LiDAR-based localization and mapping systems. However, MLO can suffer from high computational complexity introduced by dense point clouds that are fused from multiple LiDARs, and the continuous-time measurement characteristic is constantly neglected by existing LiDAR odometry. This motivates us to develop a Continuous-Time and Efficient MLO, namely CTE-MLO, which can achieve accurate and real-time state estimation using multi-LiDAR measurements through a continuous-time perspective. In this paper, the Gaussian process estimation is naturally combined with the Kalman filter, which enables each LiDAR point in a point stream to query the corresponding continuous-time trajectory within its time instants. A decentralized multi-LiDAR synchronization scheme also be devised to combine points from separate LiDARs into a single point cloud without the requirement for primary LiDAR assignment. Moreover, with the aim of improving the real-time performance of MLO without sacrificing robustness, a point cloud sampling strategy is designed with the consideration of localizability. The effectiveness of the proposed method is demonstrated through various scenarios, including public datasets and real-world autonomous driving experiments. The results demonstrate that the proposed CTE-MLO can achieve high-accuracy continuous-time state estimations in real-time and is demonstratively competitive compared to other state-of-the-art methods.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04914",
        "abstract url": "https://arxiv.org/abs/2408.04914",
        "title": "GuidedNet: Semi-Supervised Multi-Organ Segmentation via Labeled Data Guide Unlabeled Data",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "medical",
                "diagnosis",
                "disease",
                "Organ"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semi-supervised multi-organ medical image segmentation aids physicians in improving disease diagnosis and treatment planning and reduces the time and effort required for organ annotation.Existing state-of-the-art methods train the labeled data with ground truths and train the unlabeled data with pseudo-labels. However, the two training flows are separate, which does not reflect the interrelationship between labeled and unlabeled data.To address this issue, we propose a semi-supervised multi-organ segmentation method called GuidedNet, which leverages the knowledge from labeled data to guide the training of unlabeled data. The primary goals of this study are to improve the quality of pseudo-labels for unlabeled data and to enhance the network's learning capability for both small and complex organs.A key concept is that voxel features from labeled and unlabeled data that are close to each other in the feature space are more likely to belong to the same class.On this basis, a 3D Consistent Gaussian Mixture Model (3D-CGMM) is designed to leverage the feature distributions from labeled data to rectify the generated pseudo-labels.Furthermore, we introduce a Knowledge Transfer Cross Pseudo Supervision (KT-CPS) strategy, which leverages the prior knowledge obtained from the labeled data to guide the training of the unlabeled data, thereby improving the segmentation accuracy for both small and complex organs. Extensive experiments on two public datasets, FLARE22 and AMOS, demonstrated that GuidedNet is capable of achieving state-of-the-art performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ACM MM2024, 10 pages, 5 figures"
    },
    {
        "paper id": "2408.04919",
        "abstract url": "https://arxiv.org/abs/2408.04919",
        "title": "SEA-SQL: Semantic-Enhanced Text-to-SQL with Adaptive Refinement",
        "rating": "-2",
        "keywords": [
            [
                "SQL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) have significantly contributed to the progress of the Text-to-SQL task. A common requirement in many of these works is the post-correction of SQL queries. However, the majority of this process entails analyzing error cases to develop prompts with rules that eliminate model bias. And there is an absence of execution verification for SQL queries. In addition, the prevalent techniques primarily depend on GPT-4 and few-shot prompts, resulting in expensive costs. To investigate the effective methods for SQL refinement in a cost-efficient manner, we introduce Semantic-Enhanced Text-to-SQL with Adaptive Refinement (SEA-SQL), which includes Adaptive Bias Elimination and Dynamic Execution Adjustment, aims to improve performance while minimizing resource expenditure with zero-shot prompts. Specifically, SEA-SQL employs a semantic-enhanced schema to augment database information and optimize SQL queries. During the SQL query generation, a fine-tuned adaptive bias eliminator is applied to mitigate inherent biases caused by the LLM. The dynamic execution adjustment is utilized to guarantee the executability of the bias eliminated SQL query. We conduct experiments on the Spider and BIRD datasets to demonstrate the effectiveness of this framework. The results demonstrate that SEA-SQL achieves state-of-the-art performance in the GPT3.5 scenario with 9%-58% of the generation cost. Furthermore, SEA-SQL is comparable to GPT-4 with only 0.9%-5.3% of the generation cost.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04924",
        "abstract url": "https://arxiv.org/abs/2408.04924",
        "title": "A Comprehensive System Architecture using Field Programmable Gate Arrays Technology, Dijkstra's Algorithm, and Edge Computing for Emergency Response in Smart Cities",
        "rating": "-2",
        "keywords": [
            [
                "FPGAs"
            ]
        ],
        "abstract": "Efficient emergency response systems are crucial for smart cities. But their implementation is highly challenging, particularly in regions like Chad where infrastructural constraints are prevalent. The urgency for optimized response times and resource allocation in emergency scenarios is magnified in these contexts, yet existing solutions often assume robust infrastructure and uninterrupted connectivity, which is not always available. Most of the time, they are based on system architectures pre-designed for other purposes. This paper addresses these critical challenges by proposing a comprehensive system architecture that integrates Field Programmable Gate Arrays (FPGAs), Dijkstra's algorithm, and Edge Computing. The objective is to enhance emergency response through accelerated route planning and resource allocation, addressing gaps left by traditional cloud-based systems. Methodologically, key characteristics of the desired system are identified, then its components are described and their integration is explained; the system leverages FPGA-based computations and a distributed implementation of Dijkstra's algorithm to compute the shortest paths rapidly, while Edge Computing ensures decentralized and resilient processing. A theoretical analysis highlights promising improvements in response times and resource management. The proposed system architecture not only enhances emergency response efficiency but is also adaptable to infrastructural constraints of Chadian-like environments.",
        "subjects": [
            "eess.SY",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04927",
        "abstract url": "https://arxiv.org/abs/2408.04927",
        "title": "Large Models for Aerial Edges: An Edge-Cloud Model Evolution and Communication Paradigm",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "The future sixth-generation (6G) of wireless networks is expected to surpass its predecessors by offering ubiquitous coverage through integrated air-ground facility deployments in both communication and computing domains. In this network, aerial facilities, such as unmanned aerial vehicles (UAVs), conduct artificial intelligence (AI) computations based on multi-modal data to support diverse applications including surveillance and environment construction. However, these multi-domain inference and content generation tasks require large AI models, demanding powerful computing capabilities, thus posing significant challenges for UAVs. To tackle this problem, we propose an integrated edge-cloud model evolution framework, where UAVs serve as edge nodes for data collection and edge model computation. Through wireless channels, UAVs collaborate with ground cloud servers, providing cloud model computation and model updating for edge UAVs. With limited wireless communication bandwidth, the proposed framework faces the challenge of information exchange scheduling between the edge UAVs and the cloud server. To tackle this, we present joint task allocation, transmission resource allocation, transmission data quantization design, and edge model update design to enhance the inference accuracy of the integrated air-ground edge-cloud model evolution framework by mean average precision (mAP) maximization. A closed-form lower bound on the mAP of the proposed framework is derived, and the solution to the mAP maximization problem is optimized accordingly. Simulations, based on results from vision-based classification experiments, consistently demonstrate that the mAP of the proposed framework outperforms both a centralized cloud model framework and a distributed edge model framework across various communication bandwidths and data sizes.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04979",
        "abstract url": "https://arxiv.org/abs/2408.04979",
        "title": "Mesh-based Object Tracking for Dynamic Semantic 3D Scene Graphs via Ray Tracing",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "6D"
            ],
            [
                "Graphs"
            ]
        ],
        "abstract": "In this paper, we present a novel method for 3D geometric scene graph generation using range sensors and RGB cameras. We initially detect instance-wise keypoints with a YOLOv8s model to compute 6D pose estimates of known objects by solving PnP. We use a ray tracing approach to track a geometric scene graph consisting of mesh models of object instances. In contrast to classical point-to-point matching, this leads to more robust results, especially under occlusions between objects instances. We show that using this hybrid strategy leads to robust self-localization, pre-segmentation of the range sensor data and accurate pose tracking of objects using the same environmental representation. All detected objects are integrated into a semantic scene graph. This scene graph then serves as a front end to a semantic mapping framework to allow spatial reasoning.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04994",
        "abstract url": "https://arxiv.org/abs/2408.04994",
        "title": "Improving 3D Cellular Positioning Integrity with Bayesian RAIM",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Ensuring positioning integrity amid faulty measurements is crucial for safety-critical applications, making receiver autonomous integrity monitoring (RAIM) indispensable. This paper introduces a Bayesian RAIM algorithm with a streamlined architecture for snapshot-type 3D cellular positioning. Unlike traditional frequentist-type RAIM algorithms, it computes the exact posterior probability density function (PDF) of the position vector as a Gaussian mixture (GM) model using efficient message passing along a factor graph. This Bayesian approach retains all crucial information from the measurements, eliminates the need to discard faulty measurements, and results in tighter protection levels (PLs) in 3D space and 1D/2D subspaces that meet target integrity risk (TIR) requirements. Numerical simulations demonstrate that the Bayesian RAIM algorithm significantly outperforms a baseline algorithm, achieving over $50\\%$ PL reduction at a comparable computational cost.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to IEEE Transactions on Vehicular Technology"
    },
    {
        "paper id": "2408.05001",
        "abstract url": "https://arxiv.org/abs/2408.05001",
        "title": "A Formal Approach For Modelling And Analysing Surgical Procedures (Extended Version)",
        "rating": "-2",
        "keywords": [
            [
                "Surgical",
                "surgery"
            ]
        ],
        "abstract": "Surgical procedures are often not \"standardised\" (i.e., defined in a unique and unambiguous way), but rather exist as implicit knowledge in the minds of the surgeon and the surgical team. This reliance extends to pre-surgery planning and effective communication during the procedure. We introduce a novel approach for the formal and automated analysis of surgical procedures, which we model as security ceremonies, leveraging well-established techniques developed for the analysis of such ceremonies. Mutations of a procedure are used to model variants and mistakes that members of the surgical team might make. Our approach allows us to automatically identify violations of the intended properties of a surgical procedure.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This is an extended version of the paper \"A Formal Approach For Modelling And Analysing Surgical Procedures\" that appeared in the proceedings of The 20th International Workshop on Security and Trust Management (STM 2024). 25 pages, 7 figures"
    },
    {
        "paper id": "2408.05064",
        "abstract url": "https://arxiv.org/abs/2408.05064",
        "title": "Analysis of a Delay-Tolerant Data Harvest Architecture Leveraging Low Earth Orbit Satellite Networks",
        "rating": "-2",
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "Reaching all regions of Earth, low Earth orbit (LEO) satellites can harvest delay-tolerant data from remotely located users on Earth without ground infrastructure. This work aims to assess a data harvest network architecture where users generate data and LEO satellites harvest data from users when passing by. By developing a novel stochastic geometry Cox point process model that simultaneously generates orbits and the motion of LEO satellite harvesters on them, we analyze key performance indices of such a network by deriving the following: (i) the average fraction of time that the typical user is served by LEO satellite harvesters, (ii) the average amount of data uploaded per each satellite pass, (iii) the maximum harvesting capacity of the proposed network model, and (iv) the delay distribution in the proposed network. These key metrics are given as functions of key network variables such as $\u03bb$ the mean number of orbits and $\u03bc$ the mean number of satellites per orbit. Providing rich comprehensive analytical results and practical interpretations of these results, this work assesses the potential of the delay-tolerant use of LEO satellites and also serves as a versatile framework to analyze, design, and optimize delay-tolerant LEO satellite networks.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "IEEE Journal on Selected Areas in Communications ( Volume: 42, Issue: 5, May 2024)"
    },
    {
        "paper id": "2408.05070",
        "abstract url": "https://arxiv.org/abs/2408.05070",
        "title": "Modeling and Analysis of Downlink Communications in a Heterogeneous LEO Satellite Network",
        "rating": "-2",
        "keywords": [
            [
                "remote sensing",
                "Satellite"
            ]
        ],
        "abstract": "Low Earth Orbit (LEO) satellite networks connect millions of devices on Earth and offer various services, such as data communications, remote sensing, and data harvesting. As the number of services increases, LEO satellite networks will continue to grow, and many LEO satellite network operators will share the same spectrum resources. We aim to examine the coexistence of such a future heterogeneous LEO satellite network by proposing a tractable spatial model and analyzing the basic performance of downlink communications. We model a heterogeneous LEO satellite network as Cox point processes, ensuring satellites are located on various orbits. Then, we analyze two different access technologies for such a heterogeneous satellite network: closed access and open access. For both cases, we derive the coverage probability and prove that the coverage probability of the open access scenario outperforms that of the closed access, and this coverage enhancement applies to all users. By providing essential network performance statistics as key distributional parameters and by presenting the fact that the Cox point process approximates a forthcoming future constellation with slight variation, the developed framework and analysis will serve as a tractable instrument to design, evaluate, and optimize heterogeneous LEO satellite networks with numerous constellations.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "IEEE Trans. Wireless Communications"
    },
    {
        "paper id": "2408.05092",
        "abstract url": "https://arxiv.org/abs/2408.05092",
        "title": "PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "facial"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The training phase of deep neural networks requires substantial resources and as such is often performed on cloud servers. However, this raises privacy concerns when the training dataset contains sensitive content, e.g., face images. In this work, we propose a method to perform the training phase of a deep learning model on both an edge device and a cloud server that prevents sensitive content being transmitted to the cloud while retaining the desired information. The proposed privacy-preserving method uses adversarial early exits to suppress the sensitive content at the edge and transmits the task-relevant information to the cloud. This approach incorporates noise addition during the training phase to provide a differential privacy guarantee. We extensively test our method on different facial datasets with diverse face attributes using various deep learning architectures, showcasing its outstanding performance. We also demonstrate the effectiveness of privacy preservation through successful defenses against different white-box and deep reconstruction attacks.",
        "subjects": [
            "cs.CV",
            "cs.CR",
            "cs.DC",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "16 pages, 16 figures, 6 tables"
    },
    {
        "paper id": "2408.05107",
        "abstract url": "https://arxiv.org/abs/2408.05107",
        "title": "Depth Helps: Improving Pre-trained RGB-based Policy with Depth Information Injection",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "robotic manipulation"
            ]
        ],
        "abstract": "3D perception ability is crucial for generalizable robotic manipulation. While recent foundation models have made significant strides in perception and decision-making with RGB-based input, their lack of 3D perception limits their effectiveness in fine-grained robotic manipulation tasks. To address these limitations, we propose a Depth Information Injection ($\\bold{DI}^{\\bold{2}}$) framework that leverages the RGB-Depth modality for policy fine-tuning, while relying solely on RGB images for robust and efficient deployment. Concretely, we introduce the Depth Completion Module (DCM) to extract the spatial prior knowledge related to depth information and generate virtual depth information from RGB inputs to aid policy deployment. Further, we propose the Depth-Aware Codebook (DAC) to eliminate noise and reduce the cumulative error from the depth prediction. In the inference phase, this framework employs RGB inputs and accurately predicted depth data to generate the manipulation action. We conduct experiments on simulated LIBERO environments and real-world scenarios, and the experiment results prove that our method could effectively enhance the pre-trained RGB-based policy with 3D perception ability for robotic manipulation. The website is released at https://gewu-lab.github.io/DepthHelps-IROS2024.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "accepted by IROS 2024"
    },
    {
        "paper id": "2408.05109",
        "abstract url": "https://arxiv.org/abs/2408.05109",
        "title": "A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?",
        "rating": "-2",
        "keywords": [
            [
                "SQL"
            ]
        ],
        "abstract": "Translating users' natural language queries (NL) into SQL queries (i.e., NL2SQL) can significantly reduce barriers to accessing relational databases and support various commercial applications. The performance of NL2SQL has been greatly enhanced with the emergence of Large Language Models (LLMs). In this survey, we provide a comprehensive review of NL2SQL techniques powered by LLMs, covering its entire lifecycle from the following four aspects: (1) Model: NL2SQL translation techniques that tackle not only NL ambiguity and under-specification, but also properly map NL with database schema and instances; (2) Data: From the collection of training data, data synthesis due to training data scarcity, to NL2SQL benchmarks; (3) Evaluation: Evaluating NL2SQL methods from multiple angles using different metrics and granularities; and (4) Error Analysis: analyzing NL2SQL errors to find the root cause and guiding NL2SQL models to evolve. Moreover, we provide a rule of thumb for developing NL2SQL solutions. Finally, we discuss the research challenges and open problems of NL2SQL in the LLMs era.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05111",
        "abstract url": "https://arxiv.org/abs/2408.05111",
        "title": "Optimal Distributed Multi-Robot Communication-Aware Trajectory Planning using Alternating Direction Method of Multipliers",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "This paper presents a distributed, optimal, communication-aware trajectory planning algorithm for multi-robot systems. Building on prior work, it addresses the multi-robot communication-aware trajectory planning problem using a general optimisation framework that imposes linear constraints on changes in robot positions to ensure communication performance and collision avoidance. In this paper, the optimisation problem is solved distributively by separating the communication performance constraint through an economic approach. Here, the current communication budget is distributed equally among the robots, and the robots are allowed to trade parts of their budgets with each other. The separated optimisation problem is then solved using the consensus alternating direction method of multipliers. The method was verified through simulation in an inspection task problem.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05113",
        "abstract url": "https://arxiv.org/abs/2408.05113",
        "title": "Proceedings of the 21st International Conference on Quantum Physics and Logic",
        "rating": "-2",
        "keywords": [
            [
                "Quantum",
                "Physics"
            ]
        ],
        "abstract": "This volume contains the proceedings of the 21st International Conference on Quantum Physics and Logic (QPL 2024), which was held from July 15th to 19th, 2024, in Buenos Aires, Argentina, organized jointly by Universidad de Buenos Aires and Universidad Nacional de Quilmes. QPL is an annual conference that brings together academic and industry researchers working on the mathematical foundations of quantum computation, quantum physics, and related areas. The main focus is on the use of algebraic and categorical structures, formal languages, semantic methods, as well as other mathematical and computer scientific techniques applicable to the study of physical systems, physical processes, and their composition.",
        "subjects": [
            "quant-ph",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05117",
        "abstract url": "https://arxiv.org/abs/2408.05117",
        "title": "Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "disease",
                "Retinal",
                "physiological"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Early detection of dementia, such as Alzheimer's disease (AD) or mild cognitive impairment (MCI), is essential to enable timely intervention and potential treatment. Accurate detection of AD/MCI is challenging due to the high complexity, cost, and often invasive nature of current diagnostic techniques, which limit their suitability for large-scale population screening. Given the shared embryological origins and physiological characteristics of the retina and brain, retinal imaging is emerging as a potentially rapid and cost-effective alternative for the identification of individuals with or at high risk of AD. In this paper, we present a novel PolarNet+ that uses retinal optical coherence tomography angiography (OCTA) to discriminate early-onset AD (EOAD) and MCI subjects from controls. Our method first maps OCTA images from Cartesian coordinates to polar coordinates, allowing approximate sub-region calculation to implement the clinician-friendly early treatment of diabetic retinopathy study (ETDRS) grid analysis. We then introduce a multi-view module to serialize and analyze the images along three dimensions for comprehensive, clinically useful information extraction. Finally, we abstract the sequence embedding into a graph, transforming the detection task into a general graph classification problem. A regional relationship module is applied after the multi-view module to excavate the relationship between the sub-regions. Such regional relationship analyses validate known eye-brain links and reveal new discriminative patterns.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05156",
        "abstract url": "https://arxiv.org/abs/2408.05156",
        "title": "Neuromorphic Keyword Spotting with Pulse Density Modulation MEMS Microphones",
        "rating": "-2",
        "keywords": [
            [
                "bio-inspired"
            ]
        ],
        "abstract": "The Keyword Spotting (KWS) task involves continuous audio stream monitoring to detect predefined words, requiring low energy devices for continuous processing. Neuromorphic devices effectively address this energy challenge. However, the general neuromorphic KWS pipeline, from microphone to Spiking Neural Network (SNN), entails multiple processing stages. Leveraging the popularity of Pulse Density Modulation (PDM) microphones in modern devices and their similarity to spiking neurons, we propose a direct microphone-to-SNN connection. This approach eliminates intermediate stages, notably reducing computational costs. The system achieved an accuracy of 91.54\\% on the Google Speech Command (GSC) dataset, surpassing the state-of-the-art for the Spiking Speech Command (SSC) dataset which is a bio-inspired encoded GSC. Furthermore, the observed sparsity in network activity and connectivity indicates potential for remarkably low energy consumption in a neuromorphic device implementation.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "Accepted at INTERSPEECH 2024"
    },
    {
        "paper id": "2408.05185",
        "abstract url": "https://arxiv.org/abs/2408.05185",
        "title": "Efficient Unit Commitment Constraint Screening under Uncertainty",
        "rating": "-2",
        "keywords": [
            [
                "forecasting"
            ]
        ],
        "abstract": "Day-ahead unit commitment (UC) is a fundamental task for power system operators, where generator statuses and power dispatch are determined based on the forecasted nodal net demands. The uncertainty inherent in renewables and load forecasting requires the use of techniques in optimization under uncertainty to find more resilient and reliable UC solutions. However, the solution procedure of such specialized optimization may differ from the deterministic UC. The original constraint screening approach can be unreliable and inefficient for them. Thus, in this work we design a novel screening approach under the forecasting uncertainty. Our approach accommodates such uncertainties in both chance-constrained and robust forms, and can greatly reduce the UC instance size by screening out non-binding constraints. To further improve the screening efficiency, we utilize the multi-parametric programming theory to convert the underlying optimization problem of the screening model to a piecewise affine function. A multi-area screening approach is further developed to handle the computational intractability issues for large-scale problems. We verify the proposed method's performance on a variety of UC setups and uncertainty situations. Experimental results show that our robust screening procedure can guarantee better feasibility, while the CC screening can produce more efficient reduced models. The average screening time for a single line flow constraint can be accelerated by 71.2X to 131.3X using our proposed method.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "In submission, 11 pages, 10 figures"
    },
    {
        "paper id": "2408.05191",
        "abstract url": "https://arxiv.org/abs/2408.05191",
        "title": "Cross-Domain Learning for Video Anomaly Detection with Limited Supervision",
        "rating": "-2",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Crime"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video Anomaly Detection (VAD) automates the identification of unusual events, such as security threats in surveillance videos. In real-world applications, VAD models must effectively operate in cross-domain settings, identifying rare anomalies and scenarios not well-represented in the training data. However, existing cross-domain VAD methods focus on unsupervised learning, resulting in performance that falls short of real-world expectations. Since acquiring weak supervision, i.e., video-level labels, for the source domain is cost-effective, we conjecture that combining it with external unlabeled data has notable potential to enhance cross-domain performance. To this end, we introduce a novel weakly-supervised framework for Cross-Domain Learning (CDL) in VAD that incorporates external data during training by estimating its prediction bias and adaptively minimizing that using the predicted uncertainty. We demonstrate the effectiveness of the proposed CDL framework through comprehensive experiments conducted in various configurations on two large-scale VAD datasets: UCF-Crime and XD-Violence. Our method significantly surpasses the state-of-the-art works in cross-domain evaluations, achieving an average absolute improvement of 19.6% on UCF-Crime and 12.87% on XD-Violence.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05207",
        "abstract url": "https://arxiv.org/abs/2408.05207",
        "title": "Design and Fabrication of Soft Locomotion Robots based on Spatial Compliant Mechanisms",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "Soft robotics has emerged as a promising technology that holds great potential for various application areas. This is due to soft materials unique properties, including flexibility, safety, and shock absorption, among others. Despite many advancement in the field, the development of effective design methodologies and production techniques for soft robots remains a challenge. Although numerous robot prototypes have been proposed in recent years, their designs are often complex and difficult to produce. As such, there is a need for more efficient and unified design approaches that can facilitate the production of soft robots with desirable properties. In this paper, we propose a method for designing soft robots using elastic beams and spatial compliant mechanisms. The method is based on an evolutionary approach that enables the creation of designs with both high motion and force transmission ratios. Specifically, we focus on the development of locomotion mechanisms using a central linear actuator. Our approach involves the use of commonly available plastic materials and a 3D printer to manufacture the designs. We demonstrate the feasibility of our approach by presenting experimental results that show successful production and real world operation. Overall, our findings suggest that the use of elastic beams and an evolutionary approach can facilitate the creation of soft robots with desirable locomotion properties, including fast locomotion up to 3.7 body lengths per second, locomotion with a payload, and underwater locomotion. This method has the potential to enable the development of more efficient and practical soft robots for various applications.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "20 pages, 11 figures"
    },
    {
        "paper id": "2408.05331",
        "abstract url": "https://arxiv.org/abs/2408.05331",
        "title": "Automated flakiness detection in quantum software bug reports",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "A flaky test yields inconsistent results upon repetition, posing a significant challenge to software developers. An extensive study of their presence and characteristics has been done in classical computer software but not quantum computer software. In this paper, we outline challenges and potential solutions for the automated detection of flaky tests in bug reports of quantum software. We aim to raise awareness of flakiness in quantum software and encourage the software engineering community to work collaboratively to solve this emerging challenge.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "3 pages, accepted by the 4th International Workshop on Quantum Software Engineering and Technology (co-located with QCE24)"
    },
    {
        "paper id": "2408.05347",
        "abstract url": "https://arxiv.org/abs/2408.05347",
        "title": "Hybrid Efficient Unsupervised Anomaly Detection for Early Pandemic Case Identification",
        "rating": "-2",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "X-ray"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Unsupervised anomaly detection is a promising technique for identifying unusual patterns in data without the need for labeled training examples. This approach is particularly valuable for early case detection in epidemic management, especially when early-stage data are scarce. This research introduces a novel hybrid method for anomaly detection that combines distance and density measures, enhancing its applicability across various infectious diseases. Our method is especially relevant in pandemic situations, as demonstrated during the COVID-19 crisis, where traditional supervised classification methods fall short due to limited data. The efficacy of our method is evaluated using COVID-19 chest X-ray data, where it significantly outperforms established unsupervised techniques. It achieves an average AUC of 77.43%, surpassing the AUC of Isolation Forest at 73.66% and KNN at 52.93%. These results highlight the potential of our hybrid anomaly detection method to improve early detection capabilities in diverse epidemic scenarios, thereby facilitating more effective and timely responses.",
        "subjects": [
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05385",
        "abstract url": "https://arxiv.org/abs/2408.05385",
        "title": "Expected $1.x$-Makespan-Optimal MAPF on Grids in Low-Poly Time",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "graphs"
            ]
        ],
        "abstract": "Multi-Agent Path Finding (MAPF) is NP-hard to solve optimally, even on graphs, suggesting no polynomial-time algorithms can compute exact optimal solutions for them. This raises a natural question: How optimal can polynomial-time algorithms reach? Whereas algorithms for computing constant-factor optimal solutions have been developed, the constant factor is generally very large, limiting their application potential. In this work, among other breakthroughs, we propose the first low-polynomial-time MAPF algorithms delivering $1$-$1.5$ (resp., $1$-$1.67$) asymptotic makespan optimality guarantees for 2D (resp., 3D) grids for random instances at a very high $1/3$ agent density, with high probability. Moreover, when regularly distributed obstacles are introduced, our methods experience no performance degradation. These methods generalize to support $100\\%$ agent density. Regardless of the dimensionality and density, our high-quality methods are enabled by a unique hierarchical integration of two key building blocks. At the higher level, we apply the labeled Grid Rearrangement Algorithm (RTA), capable of performing efficient reconfiguration on grids through row/column shuffles. At the lower level, we devise novel methods that efficiently simulate row/column shuffles returned by RTA. Our implementations of RTA-based algorithms are highly effective in extensive numerical evaluations, demonstrating excellent scalability compared to other SOTA methods. For example, in 3D settings, \\rta-based algorithms readily scale to grids with over $370,000$ vertices and over $120,000$ agents and consistently achieve conservative makespan optimality approaching $1.5$, as predicted by our theoretical analysis.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2201.08976"
    },
    {
        "paper id": "2408.05412",
        "abstract url": "https://arxiv.org/abs/2408.05412",
        "title": "Style-Preserving Lip Sync via Audio-Aware Style Reference",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Audio-driven lip sync has recently drawn significant attention due to its widespread application in the multimedia domain. Individuals exhibit distinct lip shapes when speaking the same utterance, attributed to the unique speaking styles of individuals, posing a notable challenge for audio-driven lip sync. Earlier methods for such task often bypassed the modeling of personalized speaking styles, resulting in sub-optimal lip sync conforming to the general styles. Recent lip sync techniques attempt to guide the lip sync for arbitrary audio by aggregating information from a style reference video, yet they can not preserve the speaking styles well due to their inaccuracy in style aggregation. This work proposes an innovative audio-aware style reference scheme that effectively leverages the relationships between input audio and reference audio from style reference video to address the style-preserving audio-driven lip sync. Specifically, we first develop an advanced Transformer-based model adept at predicting lip motion corresponding to the input audio, augmented by the style information aggregated through cross-attention layers from style reference video. Afterwards, to better render the lip motion into realistic talking face video, we devise a conditional latent diffusion model, integrating lip motion through modulated convolutional layers and fusing reference facial images via spatial cross-attention layers. Extensive experiments validate the efficacy of the proposed approach in achieving precise lip sync, preserving speaking styles, and generating high-fidelity, realistic talking face videos.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "submitted to IEEE Transactions on Image Processing(TIP)"
    },
    {
        "paper id": "2408.05418",
        "abstract url": "https://arxiv.org/abs/2408.05418",
        "title": "Ankle Exoskeletons May Hinder Standing Balance in Simple Models of Older and Younger Adults",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Humans rely on ankle torque to maintain standing balance, particularly in the presence of small to moderate perturbations. Reductions in maximum torque (MT) production and maximum rate of torque development (MRTD) occur at the ankle with age, diminishing stability. Ankle exoskeletons are powered orthotic devices that may assist older adults by compensating for reduced muscle force and power production capabilities. They may also be able to assist with ankle strategies used for balance. However, no studies have investigated the effect of such devices on balance in older adults. Here, we model the effect ankle exoskeletons have on stability in physics-based models of healthy young and old adults, focusing on the mitigation of age-related deficits such as reduced MT and MRTD. We show that an ankle exoskeleton moderately reduces feasible stability boundaries in users who have full ankle strength. For individuals with age-related deficits, there is a trade-off. While exoskeletons augment stability in low velocity conditions, they reduce stability in some high velocity conditions. Our results suggest that well-established control strategies must still be experimentally validated in older adults.",
        "subjects": [
            "physics.med-ph",
            "cs.RO"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2408.05426",
        "abstract url": "https://arxiv.org/abs/2408.05426",
        "title": "SAM-FNet: SAM-Guided Fusion Network for Laryngo-Pharyngeal Tumor Detection",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cancer",
                "disease",
                "Tumor",
                "endoscopic",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Laryngo-pharyngeal cancer (LPC) is a highly fatal malignant disease affecting the head and neck region. Previous studies on endoscopic tumor detection, particularly those leveraging dual-branch network architectures, have shown significant advancements in tumor detection. These studies highlight the potential of dual-branch networks in improving diagnostic accuracy by effectively integrating global and local (lesion) feature extraction. However, they are still limited in their capabilities to accurately locate the lesion region and capture the discriminative feature information between the global and local branches. To address these issues, we propose a novel SAM-guided fusion network (SAM-FNet), a dual-branch network for laryngo-pharyngeal tumor detection. By leveraging the powerful object segmentation capabilities of the Segment Anything Model (SAM), we introduce the SAM into the SAM-FNet to accurately segment the lesion region. Furthermore, we propose a GAN-like feature optimization (GFO) module to capture the discriminative features between the global and local branches, enhancing the fusion feature complementarity. Additionally, we collect two LPC datasets from the First Affiliated Hospital (FAHSYSU) and the Sixth Affiliated Hospital (SAHSYSU) of Sun Yat-sen University. The FAHSYSU dataset is used as the internal dataset for training the model, while the SAHSYSU dataset is used as the external dataset for evaluating the model's performance. Extensive experiments on both datasets of FAHSYSU and SAHSYSU demonstrate that the SAM-FNet can achieve competitive results, outperforming the state-of-the-art counterparts. The source code of SAM-FNet is available at the URL of https://github.com/VVJia/SAM-FNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05436",
        "abstract url": "https://arxiv.org/abs/2408.05436",
        "title": "A Methodological and Structural Review of Hand Gesture Recognition Across Diverse Data Modalities",
        "rating": "-2",
        "keywords": [
            [
                "Depth",
                "skeleton"
            ],
            [
                "EEG"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Researchers have been developing Hand Gesture Recognition (HGR) systems to enhance natural, efficient, and authentic human-computer interaction, especially benefiting those who rely solely on hand gestures for communication. Despite significant progress, the automatic and precise identification of hand gestures remains a considerable challenge in computer vision. Recent studies have focused on specific modalities like RGB images, skeleton data, and spatiotemporal interest points. This paper provides a comprehensive review of HGR techniques and data modalities from 2014 to 2024, exploring advancements in sensor technology and computer vision. We highlight accomplishments using various modalities, including RGB, Skeleton, Depth, Audio, EMG, EEG, and Multimodal approaches and identify areas needing further research. We reviewed over 200 articles from prominent databases, focusing on data collection, data settings, and gesture representation. Our review assesses the efficacy of HGR systems through their recognition accuracy and identifies a gap in research on continuous gesture recognition, indicating the need for improved vision-based gesture systems. The field has experienced steady research progress, including advancements in hand-crafted features and deep learning (DL) techniques. Additionally, we report on the promising developments in HGR methods and the area of multimodal approaches. We hope this survey will serve as a potential guideline for diverse data modality-based HGR research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05051",
        "abstract url": "https://arxiv.org/abs/2408.05051",
        "title": "A GNN Model with Adaptive Weights for Session-Based Recommendation Systems",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Session-based recommendation systems aim to model users' interests based on their sequential interactions to predict the next item in an ongoing session. In this work, we present a novel approach that can be used in session-based recommendations (SBRs). Our goal is to enhance the prediction accuracy of an existing session-based recommendation model, the SR-GNN model, by introducing an adaptive weighting mechanism applied to the graph neural network (GNN) vectors. This mechanism is designed to incorporate various types of side information obtained through different methods during the study. Items are assigned varying degrees of importance within each session as a result of the weighting mechanism. We hypothesize that this adaptive weighting strategy will contribute to more accurate predictions and thus improve the overall performance of SBRs in different scenarios. The adaptive weighting strategy can be utilized to address the cold start problem in SBRs by dynamically adjusting the importance of items in each session, thus providing better recommendations in cold start situations, such as for new users or newly added items. Our experimental evaluations on the Dressipi dataset demonstrate the effectiveness of the proposed approach compared to traditional models in enhancing the user experience and highlighting its potential to optimize the recommendation results in real-world applications.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "7 pages, 7 tables, 2 figures, and 3 equations"
    },
    {
        "paper id": "2408.05061",
        "abstract url": "https://arxiv.org/abs/2408.05061",
        "title": "A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares",
        "rating": "-2.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "SQL"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper we argue that a jailbroken GenAI model can cause substantial harm to GenAI-powered applications and facilitate PromptWare, a new type of attack that flips the GenAI model's behavior from serving an application to attacking it. PromptWare exploits user inputs to jailbreak a GenAI model to force/perform malicious activity within the context of a GenAI-powered application. First, we introduce a naive implementation of PromptWare that behaves as malware that targets Plan & Execute architectures (a.k.a., ReAct, function calling). We show that attackers could force a desired execution flow by creating a user input that produces desired outputs given that the logic of the GenAI-powered application is known to attackers. We demonstrate the application of a DoS attack that triggers the execution of a GenAI-powered assistant to enter an infinite loop that wastes money and computational resources on redundant API calls to a GenAI engine, preventing the application from providing service to a user. Next, we introduce a more sophisticated implementation of PromptWare that we name Advanced PromptWare Threat (APwT) that targets GenAI-powered applications whose logic is unknown to attackers. We show that attackers could create user input that exploits the GenAI engine's advanced AI capabilities to launch a kill chain in inference time consisting of six steps intended to escalate privileges, analyze the application's context, identify valuable assets, reason possible malicious activities, decide on one of them, and execute it. We demonstrate the application of APwT against a GenAI-powered e-commerce chatbot and show that it can trigger the modification of SQL tables, potentially leading to unauthorized discounts on the items sold to the user.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "Website, see https://sites.google.com/view/promptware"
    },
    {
        "paper id": "2408.05131",
        "abstract url": "https://arxiv.org/abs/2408.05131",
        "title": "Range Membership Inference Attacks",
        "rating": "-2.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning models can leak private information about their training data, but the standard methods to measure this risk, based on membership inference attacks (MIAs), have a major limitation. They only check if a given data point \\textit{exactly} matches a training point, neglecting the potential of similar or partially overlapping data revealing the same private information. To address this issue, we introduce the class of range membership inference attacks (RaMIAs), testing if the model was trained on any data in a specified range (defined based on the semantics of privacy). We formulate the RaMIAs game and design a principled statistical test for its complex hypotheses. We show that RaMIAs can capture privacy loss more accurately and comprehensively than MIAs on various types of data, such as tabular, image, and language. RaMIA paves the way for a more comprehensive and meaningful privacy auditing of machine learning algorithms.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05136",
        "abstract url": "https://arxiv.org/abs/2408.05136",
        "title": "Cycle-Configuration: A Novel Graph-theoretic Descriptor Set for Molecular Inference",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a novel family of descriptors of chemical graphs, named cycle-configuration (CC), that can be used in the standard \"two-layered (2L) model\" of mol-infer, a molecular inference framework based on mixed integer linear programming (MILP) and machine learning (ML). Proposed descriptors capture the notion of ortho/meta/para patterns that appear in aromatic rings, which has been impossible in the framework so far. Computational experiments show that, when the new descriptors are supplied, we can construct prediction functions of similar or better performance for all of the 27 tested chemical properties. We also provide an MILP formulation that asks for a chemical graph with desired properties under the 2L model with CC descriptors (2L+CC model). We show that a chemical graph with up to 50 non-hydrogen vertices can be inferred in a practical time.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05149",
        "abstract url": "https://arxiv.org/abs/2408.05149",
        "title": "AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset",
        "rating": "-2.5",
        "keywords": [
            [
                "Attack"
            ],
            [
                "Named Entity Recognition"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Cyber-attack attribution is an important process that allows experts to put in place attacker-oriented countermeasures and legal actions. The analysts mainly perform attribution manually, given the complex nature of this task. AI and, more specifically, Natural Language Processing (NLP) techniques can be leveraged to support cybersecurity analysts during the attribution process. However powerful these techniques are, they need to deal with the lack of datasets in the attack attribution domain. In this work, we will fill this gap and will provide, to the best of our knowledge, the first dataset on cyber-attack attribution. We designed our dataset with the primary goal of extracting attack attribution information from cybersecurity texts, utilizing named entity recognition (NER) methodologies from the field of NLP. Unlike other cybersecurity NER datasets, ours offers a rich set of annotations with contextual details, including some that span phrases and sentences. We conducted extensive experiments and applied NLP techniques to demonstrate the dataset's effectiveness for attack attribution. These experiments highlight the potential of Large Language Models (LLMs) capabilities to improve the NER tasks in cybersecurity datasets for cyber-attack attribution.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "Submitted to WISE 2024"
    },
    {
        "paper id": "2408.05170",
        "abstract url": "https://arxiv.org/abs/2408.05170",
        "title": "Decoding Quantum LDPC Codes Using Graph Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a novel decoding method for Quantum Low-Density Parity-Check (QLDPC) codes based on Graph Neural Networks (GNNs). Similar to the Belief Propagation (BP)-based QLDPC decoders, the proposed GNN-based QLDPC decoder exploits the sparse graph structure of QLDPC codes and can be implemented as a message-passing decoding algorithm. We compare the proposed GNN-based decoding algorithm against selected classes of both conventional and neural-enhanced QLDPC decoding algorithms across several QLDPC code designs. The simulation results demonstrate excellent performance of GNN-based decoders along with their low complexity compared to competing methods.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "cs.LG"
        ],
        "comment": "Accepted for GLOBECOM 2024"
    },
    {
        "paper id": "2408.05258",
        "abstract url": "https://arxiv.org/abs/2408.05258",
        "title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is pivotal for understanding cellular heterogeneity. However, the high sparsity and complex noise patterns inherent in scRNA-seq data present significant challenges for traditional clustering methods. To address these issues, we propose a deep clustering method, Attention-Enhanced Structural Deep Embedding Graph Clustering (scASDC), which integrates multiple advanced modules to improve clustering accuracy and robustness.Our approach employs a multi-layer graph convolutional network (GCN) to capture high-order structural relationships between cells, termed as the graph autoencoder module. To mitigate the oversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module that extracts content information from the data and learns latent representations of gene expression. These modules are further integrated through an attention fusion mechanism, ensuring effective combination of gene expression and structural information at each layer of the GCN. Additionally, a self-supervised learning module is incorporated to enhance the robustness of the learned embeddings. Extensive experiments demonstrate that scASDC outperforms existing state-of-the-art methods, providing a robust and effective solution for single-cell clustering tasks. Our method paves the way for more accurate and meaningful analysis of single-cell RNA sequencing data, contributing to better understanding of cellular heterogeneity and biological processes. All code and public datasets used in this paper are available at \\url{https://github.com/wenwenmin/scASDC} and \\url{https://zenodo.org/records/12814320}.",
        "subjects": [
            "q-bio.GN",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05435",
        "abstract url": "https://arxiv.org/abs/2408.05435",
        "title": "SuperEncoder: Towards Universal Neural Approximate Quantum State Preparation",
        "rating": "-2.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Numerous quantum algorithms operate under the assumption that classical data has already been converted into quantum states, a process termed Quantum State Preparation (QSP). However, achieving precise QSP requires a circuit depth that scales exponentially with the number of qubits, making it a substantial obstacle in harnessing quantum advantage. Recent research suggests using a Parameterized Quantum Circuit (PQC) to approximate a target state, offering a more scalable solution with reduced circuit depth compared to precise QSP. Despite this, the need for iterative updates of circuit parameters results in a lengthy runtime, limiting its practical application. In this work, we demonstrate that it is possible to leverage a pre-trained neural network to directly generate the QSP circuit for arbitrary quantum state, thereby eliminating the significant overhead of online iterations. Our study makes a steady step towards a universal neural designer for approximate QSP.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.07709",
        "abstract url": "https://arxiv.org/abs/2408.07709",
        "title": "Pretrained-Guided Conditional Diffusion Models for Microbiome Data Analysis",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cancer",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Emerging evidence indicates that human cancers are intricately linked to human microbiomes, forming an inseparable connection. However, due to limited sample sizes and significant data loss during collection for various reasons, some machine learning methods have been proposed to address the issue of missing data. These methods have not fully utilized the known clinical information of patients to enhance the accuracy of data imputation. Therefore, we introduce mbVDiT, a novel pre-trained conditional diffusion model for microbiome data imputation and denoising, which uses the unmasked data and patient metadata as conditional guidance for imputating missing values. It is also uses VAE to integrate the the other public microbiome datasets to enhance model performance. The results on the microbiome datasets from three different cancer types demonstrate the performance of our methods in comparison with existing methods.",
        "subjects": [
            "q-bio.GN",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05372",
        "abstract url": "https://arxiv.org/abs/2408.05372",
        "title": "PRISM Lite: A lightweight model for interactive 3D placenta segmentation in ultrasound",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Placenta volume measured from 3D ultrasound (3DUS) images is an important tool for tracking the growth trajectory and is associated with pregnancy outcomes. Manual segmentation is the gold standard, but it is time-consuming and subjective. Although fully automated deep learning algorithms perform well, they do not always yield high-quality results for each case. Interactive segmentation models could address this issue. However, there is limited work on interactive segmentation models for the placenta. Despite their segmentation accuracy, these methods may not be feasible for clinical use as they require relatively large computational power which may be especially prohibitive in low-resource environments, or on mobile devices. In this paper, we propose a lightweight interactive segmentation model aiming for clinical use to interactively segment the placenta from 3DUS images in real-time. The proposed model adopts the segmentation from our fully automated model for initialization and is designed in a human-in-the-loop manner to achieve iterative improvements. The Dice score and normalized surface Dice are used as evaluation metrics. The results show that our model can achieve superior performance in segmentation compared to state-of-the-art models while using significantly fewer parameters. Additionally, the proposed model is much faster for inference and robust to poor initial masks. The code is available at https://github.com/MedICL-VU/PRISM-placenta.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05375",
        "abstract url": "https://arxiv.org/abs/2408.05375",
        "title": "Enhancing Representation Learning of EEG Data with Masked Autoencoders",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "EEG"
            ]
        ],
        "abstract": "Self-supervised learning has been a powerful training paradigm to facilitate representation learning. In this study, we design a masked autoencoder (MAE) to guide deep learning models to learn electroencephalography (EEG) signal representation. Our MAE includes an encoder and a decoder. A certain proportion of input EEG signals are randomly masked and sent to our MAE. The goal is to recover these masked signals. After this self-supervised pre-training, the encoder is fine-tuned on downstream tasks. We evaluate our MAE on EEGEyeNet gaze estimation task. We find that the MAE is an effective brain signal learner. It also significantly improves learning efficiency. Compared to the model without MAE pre-training, the pre-trained one achieves equal performance with 1/3 the time of training and outperforms it in half the training time. Our study shows that self-supervised learning is a promising research direction for EEG-based applications as other fields (natural language processing, computer vision, robotics, etc.), and thus we expect foundation models to be successful in EEG domain.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06382",
        "abstract url": "https://arxiv.org/abs/2408.06382",
        "title": "FedRobo: Federated Learning Driven Autonomous Inter Robots Communication For Optimal Chemical Sprays",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "Federated Learning"
            ],
            [
                "Chemical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Federated Learning enables robots to learn from each other's experiences without relying on centralized data collection. Each robot independently maintains a model of crop conditions and chemical spray effectiveness, which is periodically shared with other robots in the fleet. A communication protocol is designed to optimize chemical spray applications by facilitating the exchange of information about crop conditions, weather, and other critical factors. The federated learning algorithm leverages this shared data to continuously refine the chemical spray strategy, reducing waste and improving crop yields. This approach has the potential to revolutionize the agriculture industry by offering a scalable and efficient solution for crop protection. However, significant challenges remain, including the development of a secure and robust communication protocol, the design of a federated learning algorithm that effectively integrates data from multiple sources, and ensuring the safety and reliability of autonomous robots. The proposed cluster-based federated learning approach also effectively reduces the computational load on the global server and minimizes communication overhead among clients.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.DC",
            "cs.RO"
        ],
        "comment": "This research article is going to be submitted to a best-fit conference. We are looking for a conference"
    },
    {
        "paper id": "2408.04910",
        "abstract url": "https://arxiv.org/abs/2408.04910",
        "title": "Unleashing Artificial Cognition: Integrating Multiple AI Systems",
        "rating": "-3.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this study, we present an innovative fusion of language models and query analysis techniques to unlock cognition in artificial intelligence. Our system seamlessly integrates a Chess engine with a language model, enabling it to predict moves and provide strategic explanations. Leveraging a vector database to achieve retrievable answer generation, our OpenSI AI system elucidates its decision-making process, bridging the gap between raw computation and human-like understanding. Our choice of Chess as the demonstration environment underscores the versatility of our approach. Beyond Chess, our system holds promise for diverse applications, from medical diagnostics to financial forecasting.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05416",
        "abstract url": "https://arxiv.org/abs/2408.05416",
        "title": "High-fidelity and Lip-synced Talking Face Synthesis via Landmark-based Diffusion Model",
        "rating": "-4",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "facial"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Audio-driven talking face video generation has attracted increasing attention due to its huge industrial potential. Some previous methods focus on learning a direct mapping from audio to visual content. Despite progress, they often struggle with the ambiguity of the mapping process, leading to flawed results. An alternative strategy involves facial structural representations (e.g., facial landmarks) as intermediaries. This multi-stage approach better preserves the appearance details but suffers from error accumulation due to the independent optimization of different stages. Moreover, most previous methods rely on generative adversarial networks, prone to training instability and mode collapse. To address these challenges, our study proposes a novel landmark-based diffusion model for talking face generation, which leverages facial landmarks as intermediate representations while enabling end-to-end optimization. Specifically, we first establish the less ambiguous mapping from audio to landmark motion of lip and jaw. Then, we introduce an innovative conditioning module called TalkFormer to align the synthesized motion with the motion represented by landmarks via differentiable cross-attention, which enables end-to-end optimization for improved lip synchronization. Besides, TalkFormer employs implicit feature warping to align the reference image features with the target motion for preserving more appearance details. Extensive experiments demonstrate that our approach can synthesize high-fidelity and lip-synced talking face videos, preserving more subject appearance details from the reference image.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "submitted to IEEE Transactions on Image Processing(TIP)"
    },
    {
        "paper id": "2408.06380",
        "abstract url": "https://arxiv.org/abs/2408.06380",
        "title": "Runtime Verification Containers for Publish/Subscribe Networks",
        "rating": "-4",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "robotics"
            ],
            [
                "industrial",
                "IoT"
            ]
        ],
        "abstract": "Publish/subscribe (pub/sub) networks are a cornerstone of modern distributed systems, playing a crucial role in applications like the Internet of Things (IoT) and robotics. While runtime verification techniques seem ideal for ensuring the correctness of such highly dynamic and large-scale networks, integrating runtime monitors seamlessly into real-world industrial use cases presents significant challenges. This paper studies modern containerization technology to deploy runtime verification tools to monitor publish/subscribe networks with a performance focus. Runtime verification containers are lightweight and deployable alongside other containerized publisher and subscriber participants. Each runtime verification container monitors message flow, enabling runtime verification of network behavior. We comprehensively benchmark the container-based approach using several experiments and a real-world case study from the software-defined vehicle domain.",
        "subjects": [
            "cs.DC",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05351",
        "abstract url": "https://arxiv.org/abs/2408.05351",
        "title": "Distributed Quantum Computing for Chemical Applications",
        "rating": "-5",
        "keywords": [
            [
                "depth"
            ],
            [
                "chemistry",
                "Chemical"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "In recent years, interest in quantum computing has increased due to technological advances in quantum hardware and algorithms. Despite the promises of quantum advantage, the applicability of quantum devices has been limited to few qubits on hardware that experiences decoherence due to noise. One proposed method to get around this challenge is distributed quantum computing (DQC). Like classical distributed computing, DQC aims at increasing compute power by spreading the compute processes across many devices, with the goal to minimize the noise and circuit depth required by quantum devices. In this paper, we cover the fundamental concepts of DQC and provide insight into where the field of DQC stands with respect to the field of chemistry -- a field which can potentially be used to demonstrate quantum advantage on noisy-intermediate scale quantum devices.",
        "subjects": [
            "quant-ph",
            "eess.SY",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05425",
        "abstract url": "https://arxiv.org/abs/2408.05425",
        "title": "Modeling Multi-Step Scientific Processes with Graph Transformer Networks",
        "rating": "-5.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "Graph"
            ],
            [
                "biology"
            ],
            [
                "chemistry"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work presents the use of graph learning for the prediction of multi-step experimental outcomes for applications across experimental research, including material science, chemistry, and biology. The viability of geometric learning for regression tasks was benchmarked against a collection of linear models through a combination of simulated and real-world data training studies. First, a selection of five arbitrarily designed multi-step surrogate functions were developed to reflect various features commonly found within experimental processes. A graph transformer network outperformed all tested linear models in scenarios that featured hidden interactions between process steps and sequence dependent features, while retaining equivalent performance in sequence agnostic scenarios. Then, a similar comparison was applied to real-world literature data on algorithm guided colloidal atomic layer deposition. Using the complete reaction sequence as training data, the graph neural network outperformed all linear models in predicting the three spectral properties for most training set sizes. Further implementation of graph neural networks and geometric representation of scientific processes for the prediction of experiment outcomes could lead to algorithm driven navigation of higher dimension parameter spaces and efficient exploration of more dynamic systems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04884",
        "abstract url": "https://arxiv.org/abs/2408.04884",
        "title": "Enhancing Relevance of Embedding-based Retrieval at Walmart",
        "rating": "-10",
        "keywords": [],
        "abstract": "Embedding-based neural retrieval (EBR) is an effective search retrieval method in product search for tackling the vocabulary gap between customer search queries and products. The initial launch of our EBR system at Walmart yielded significant gains in relevance and add-to-cart rates [1]. However, despite EBR generally retrieving more relevant products for reranking, we have observed numerous instances of relevance degradation. Enhancing retrieval performance is crucial, as it directly influences product reranking and affects the customer shopping experience. Factors contributing to these degradations include false positives/negatives in the training data and the inability to handle query misspellings. To address these issues, we present several approaches to further strengthen the capabilities of our EBR model in terms of retrieval relevance. We introduce a Relevance Reward Model (RRM) based on human relevance feedback. We utilize RRM to remove noise from the training data and distill it into our EBR model through a multi-objective loss. In addition, we present the techniques to increase the performance of our EBR model, such as typo-aware training, and semi-positive generation. The effectiveness of our EBR is demonstrated through offline relevance evaluation, online AB tests, and successful deployments to live production. [1] Alessandro Magnani, Feng Liu, Suthee Chaidaroon, Sachin Yadav, Praveen Reddy Suram, Ajit Puthenputhussery, Sijie Chen, Min Xie, Anirudh Kashi, Tony Lee, et al. 2022. Semantic retrieval at walmart. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 3495-3503.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "8 pages, 3 figures, CIKM 2024"
    },
    {
        "paper id": "2408.04886",
        "abstract url": "https://arxiv.org/abs/2408.04886",
        "title": "Automated PMC-based Power Modeling Methodology for Modern Mobile GPUs",
        "rating": "-10",
        "keywords": [],
        "abstract": "The rise of machine learning workload on smartphones has propelled GPUs into one of the most power-hungry components of modern smartphones and elevates the need for optimizing the GPU power draw by mobile apps. Optimizing the power consumption of mobile GPUs in turn requires accurate estimation of their power draw during app execution. In this paper, we observe that the prior-art, utilization-frequency based GPU models cannot capture the diverse micro-architectural usage of modern mobile GPUs.We show that these models suffer poor modeling accuracy under diverse GPU workload, and study whether performance monitoring counter (PMC)-based models recently proposed for desktop/server GPUs can be applied to accurately model mobile GPU power. Our study shows that the PMCs that come with dominating mobile GPUs used in modern smartphones are sufficient to model mobile GPU power, but exhibit multicollinearity if used altogether. We present APGPM, the mobile GPU power modeling methodology that automatically selects an optimal set of PMCs that maximizes the GPU power model accuracy. Evaluation on two representative mobile GPUs shows that APGPM-generated GPU power models reduce the MAPE modeling error of prior-art by 1.95x to 2.66x (i.e., by 11.3% to 15.4%) while using only 4.66% to 20.41% of the total number of available PMCs.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04887",
        "abstract url": "https://arxiv.org/abs/2408.04887",
        "title": "Relevance Filtering for Embedding-based Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "In embedding-based retrieval, Approximate Nearest Neighbor (ANN) search enables efficient retrieval of similar items from large-scale datasets. While maximizing recall of relevant items is usually the goal of retrieval systems, a low precision may lead to a poor search experience. Unlike lexical retrieval, which inherently limits the size of the retrieved set through keyword matching, dense retrieval via ANN search has no natural cutoff. Moreover, the cosine similarity scores of embedding vectors are often optimized via contrastive or ranking losses, which make them difficult to interpret. Consequently, relying on top-K or cosine-similarity cutoff is often insufficient to filter out irrelevant results effectively. This issue is prominent in product search, where the number of relevant products is often small. This paper introduces a novel relevance filtering component (called \"Cosine Adapter\") for embedding-based retrieval to address this challenge. Our approach maps raw cosine similarity scores to interpretable scores using a query-dependent mapping function. We then apply a global threshold on the mapped scores to filter out irrelevant results. We are able to significantly increase the precision of the retrieved set, at the expense of a small loss of recall. The effectiveness of our approach is demonstrated through experiments on both public MS MARCO dataset and internal Walmart product search data. Furthermore, online A/B testing on the Walmart site validates the practical value of our approach in real-world e-commerce settings.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "8 pages, 3 figures, CIKM 2024"
    },
    {
        "paper id": "2408.04888",
        "abstract url": "https://arxiv.org/abs/2408.04888",
        "title": "Locally Private Histograms in All Privacy Regimes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Frequency estimation, a.k.a. histograms, is a workhorse of data analysis, and as such has been thoroughly studied under differentially privacy. In particular, computing histograms in the local model of privacy has been the focus of a fruitful recent line of work, and various algorithms have been proposed, achieving the order-optimal $\\ell_\\infty$ error in the high-privacy (small $\\varepsilon$) regime while balancing other considerations such as time- and communication-efficiency. However, to the best of our knowledge, the picture is much less clear when it comes to the medium- or low-privacy regime (large $\\varepsilon$), despite its increased relevance in practice. In this paper, we investigate locally private histograms, and the very related distribution learning task, in this medium-to-low privacy regime, and establish near-tight (and somewhat unexpected) bounds on the $\\ell_\\infty$ error achievable. Our theoretical findings emerge from a novel analysis, which appears to improve bounds across the board for the locally private histogram problem. We back our theoretical findings by an empirical comparison of existing algorithms in all privacy regimes, to assess their typical performance and behaviour beyond the worst-case setting.",
        "subjects": [
            "cs.DS",
            "cs.CR",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04902",
        "abstract url": "https://arxiv.org/abs/2408.04902",
        "title": "Algorithms for Markov Binomial Chains",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study algorithms to analyze a particular class of Markov population processes that is often used in epidemiology. More specifically, Markov binomial chains are the model that arises from stochastic time-discretizations of classical compartmental models. In this work we formalize this class of Markov population processes and focus on the problem of computing the expected time to termination in a given such model. Our theoretical contributions include proving that Markov binomial chains whose flow of individuals through compartments is acyclic almost surely terminate. We give a PSPACE algorithm for the problem of approximating the time to termination and a direct algorithm for the exact problem in the Blum-Shub-Smale model of computation. Finally, we provide a natural encoding of Markov binomial chains into a common input language for probabilistic model checkers. We implemented the latter encoding and present some initial empirical results showcasing what formal methods can do for practicing epidemilogists.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04908",
        "abstract url": "https://arxiv.org/abs/2408.04908",
        "title": "Energy performance of LR-FHSS: analysis and evaluation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Long Range-Frequency Hopping Spread Spectrum (LR-FHSS) is a pivotal advancement in the LoRaWAN protocol, designed to enhance the network's capacity and robustness, particularly in densely populated environments. Although energy consumption is paramount in LoRaWAN-based end-devices, there are currently no studies in the literature, to our knowledge, that model the impact of this novel mechanism on energy consumption. In this article, we provide a comprehensive energy consumption analytical model of LR-FHSS, focusing on three critical metrics: average current consumption, battery lifetime, and energy efficiency of data transmission. The model is based on measurements performed on real hardware in a fully operational LR-FHSS network. While in our evaluation, LR-FHSS can show worse consumption figures than LoRa, we found that with optimal configuration, the battery lifetime of LR-FHSS end-devices can reach 2.5 years for a 50-minute notification period. For the most energy-efficient payload size, this lifespan can be extended to a theoretical maximum of up to 16 years with a one-day notification interval using a cell-coin battery.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04918",
        "abstract url": "https://arxiv.org/abs/2408.04918",
        "title": "Engaging Developers in Exploratory Unit Testing through Gamification",
        "rating": "-10",
        "keywords": [],
        "abstract": "Exploratory testing, known for its flexibility and ability to uncover unexpected issues, often faces challenges in maintaining systematic coverage and producing reproducible results. To address these challenges, we investigate whether gamification of testing directly in the Integrated Development Environment (IDE) can guide exploratory testing. We therefore show challenges and quests generated by the Gamekins gamification system to make testing more engaging and seamlessly blend it with regular coding tasks. In a 60-minute experiment, we evaluated Gamekins' impact on test suite quality and bug detection. The results show that participants actively interacted with the tool, achieving nearly 90% line coverage and detecting 11 out of 14 bugs. Additionally, participants reported enjoying the experience, indicating that gamification can enhance developer participation in testing and improve software quality.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04920",
        "abstract url": "https://arxiv.org/abs/2408.04920",
        "title": "On the Number of Non-equivalent Parameterized Squares in a String",
        "rating": "-10",
        "keywords": [],
        "abstract": "A string $s$ is called a parameterized square when $s = xy$ for strings $x$, $y$ and $x$ and $y$ are parameterized equivalent. Kociumaka et al. showed the number of parameterized squares, which are non-equivalent in parameterized equivalence, in a string of length $n$ that contains $\u03c3$ distinct characters is at most $2 \u03c3! n$ [TCS 2016]. In this paper, we show that the maximum number of non-equivalent parameterized squares is less than $\u03c3n$, which significantly improves the best-known upper bound by Kociumaka et al.",
        "subjects": [
            "cs.DS",
            "cs.DM"
        ],
        "comment": "Accepted for SPIRE 2024"
    },
    {
        "paper id": "2408.04923",
        "abstract url": "https://arxiv.org/abs/2408.04923",
        "title": "Synthetic Grid Generator: Synthesizing Large-Scale Power Distribution Grids using Open Street Map",
        "rating": "-10",
        "keywords": [],
        "abstract": "Nowadays, various stakeholders involved in the analysis of electric power distribution grids face difficulties in the data acquisition related to the grid topology and parameters of grid assets. To mitigate the problem and possibly accelerate the accomplishment of grid studies without access to real data, we propose a novel approach for generating synthetic distribution grids (Syngrids) of (almost) arbitrary size replicating the characteristics of real medium- and low-voltage distribution networks. The method enables large-scale testing without incurring the burden of retrieving and pre-processing real-world data. The proposed algorithm exploits the publicly available information of Open Street Map (OSM). By leveraging geospatial data of real buildings and road networks, the approach allows to construct a Syngrid of chosen size with realistic topology and electrical parameters. It is shown that typical power-flow and short-circuit calculations can be performed on Syngrids ensuring convergence. Within the context of validating the effectiveness of the algorithm and the meaningful similarity of the output to real grids, the topological and electrical characteristics of a Syngrid are compared to their real-world counterparts. Finally, an open-source web platform named as Synthetic Grid Generator (SGG) and based on the proposed algorithm can be used by various stakeholders for the creation of synthetic grids.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2408.04929",
        "abstract url": "https://arxiv.org/abs/2408.04929",
        "title": "Tight Time Complexities in Parallel Stochastic Optimization with Arbitrary Computation Dynamics",
        "rating": "-10",
        "keywords": [],
        "abstract": "In distributed stochastic optimization, where parallel and asynchronous methods are employed, we establish optimal time complexities under virtually any computation behavior of workers/devices/CPUs/GPUs, capturing potential disconnections due to hardware and network delays, time-varying computation powers, and any possible fluctuations and trends of computation speeds. These real-world scenarios are formalized by our new universal computation model. Leveraging this model and new proof techniques, we discover tight lower bounds that apply to virtually all synchronous and asynchronous methods, including Minibatch SGD, Asynchronous SGD (Recht et al., 2011), and Picky SGD (Cohen et al., 2021). We show that these lower bounds, up to constant factors, are matched by the optimal Rennala SGD and Malenia SGD methods (Tyurin & Richt\u00e1rik, 2023).",
        "subjects": [
            "math.OC",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04936",
        "abstract url": "https://arxiv.org/abs/2408.04936",
        "title": "Hybrid lunar ISRU plant: a comparative analysis with carbothermal reduction and water extraction",
        "rating": "-10",
        "keywords": [],
        "abstract": "To establish a self-sustained human presence in space and to explore deeper into the solar system, extensive research has been conducted on In-Situ Resource Utilization (ISRU) systems. Past studies have proposed and researched many technologies to produce oxygen from regolith, such as carbothermal reduction and water extraction from icy regolith, to utilize it for astronauts' life support and as the propellant of space systems. However, determining the most promising technology remains challenging due to uncertainties in the lunar environment and processing methods. To better understand the lunar environment and ISRU operations, it is crucial to gather more information. Motivated by this need for information gathering, this paper proposes a new ISRU plant architecture integrating carbothermal reduction of dry regolith and water extraction from icy regolith. Two different hybrid plant architectures integrating both technologies (1) in parallel and (2) in series are examined. The former involves mining and processing in both a Permanently Shadowed Region (PSR) and a peak of eternal light in parallel, while the latter solely mines in a PSR. In this series hybrid architecture, the dry regolith tailings from water extraction are further processed by carbothermal reduction. This paper conducts a comparative analysis of the landed mass and required power of each plant architecture utilizing subsystem-level models. Furthermore, based on uncertain parameters such as resource content in regolith, the potential performance range of each plant was discovered through Monte Carlo simulations. The result indicates the benefit of the series hybrid architecture in terms of regolith excavation rate, while its mass cost seems the highest among the studied architectures.",
        "subjects": [
            "physics.chem-ph",
            "eess.SY"
        ],
        "comment": "26 pages, 21 figures, 7 tables, under review by Acta Astronautica"
    },
    {
        "paper id": "2408.04939",
        "abstract url": "https://arxiv.org/abs/2408.04939",
        "title": "Demystifying and Detecting Cryptographic Defects in Ethereum Smart Contracts",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ethereum has officially provided a set of system-level cryptographic APIs to enhance smart contracts with cryptographic capabilities. These APIs have been utilized in over 10% of Ethereum transactions, motivating developers to implement various on-chain cryptographic tasks, such as digital signatures. However, since developers may not always be cryptographic experts, their ad-hoc and potentially defective implementations could compromise the theoretical guarantees of cryptography, leading to real-world security issues. To mitigate this threat, we conducted the first study aimed at demystifying and detecting cryptographic defects in smart contracts. Through the analysis of 2,406 real-world security reports, we defined nine types of cryptographic defects in smart contracts with detailed descriptions and practical detection patterns. Based on this categorization, we proposed CrySol, a fuzzing-based tool to automate the detection of cryptographic defects in smart contracts. It combines transaction replaying and dynamic taint analysis to extract fine-grained crypto-related semantics and employs crypto-specific strategies to guide the test case generation process. Furthermore, we collected a large-scale dataset containing 25,745 real-world crypto-related smart contracts and evaluated CrySol's effectiveness on it. The result demonstrated that CrySol achieves an overall precision of 95.4% and a recall of 91.2%. Notably, CrySol revealed that 5,847 (22.7%) out of 25,745 smart contracts contain at least one cryptographic defect, highlighting the prevalence of these defects.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.04951",
        "abstract url": "https://arxiv.org/abs/2408.04951",
        "title": "CSI-Free Position Optimization for Movable Antenna Communication Systems: A Black-Box Optimization Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "Movable antenna (MA) is a new technology which leverages local movement of antennas to improve channel qualities and enhance the communication performance. Nevertheless, to fully realize the potential of MA systems, complete channel state information (CSI) between the transmitter-MA and the receiver-MA is required, which involves estimating a large number of channel parameters and incurs an excessive amount of training overhead. To address this challenge, in this paper, we propose a CSI-free MA position optimization method. The basic idea is to treat position optimization as a black-box optimization problem and calculate the gradient of the unknown objective function using zeroth-order (ZO) gradient approximation techniques. Simulation results show that the proposed ZO-based method, through adaptively adjusting the position of the MA, can achieve a favorable signal-to-noise-ratio (SNR) using a smaller number of position measurements than the CSI-based approach. Such a merit makes the proposed algorithm more adaptable to fast-changing propagation channels.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 4 figures, submitted for possible IEEE publication"
    },
    {
        "paper id": "2408.04964",
        "abstract url": "https://arxiv.org/abs/2408.04964",
        "title": "Searching in Euclidean Spaces with Predictions",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of searching for a target at some unknown location in $\\mathbb{R}^d$ when additional information regarding the position of the target is available in the form of predictions. In our setting, predictions come as approximate distances to the target: for each point $p\\in \\mathbb{R}^d$ that the searcher visits, we obtain a value $\u03bb(p)$ such that $|p\\mathbf{t}|\\le \u03bb(p) \\le c\\cdot |p\\mathbf{t}|$, where $c\\ge 1$ is a fixed constant, $\\mathbf{t}$ is the position of the target, and $|p\\mathbf{t}|$ is the Euclidean distance of $p$ to $\\mathbf{t}$. The cost of the search is the length of the path followed by the searcher. Our main positive result is a strategy that achieves $(12c)^{d+1}$-competitive ratio, even when the constant $c$ is unknown. We also give a lower bound of roughly $(c/16)^{d-1}$ on the competitive ratio of any search strategy in $\\mathbb{R}^d$.",
        "subjects": [
            "cs.CG"
        ],
        "comment": "19 pages, WAOA 24"
    },
    {
        "paper id": "2408.04978",
        "abstract url": "https://arxiv.org/abs/2408.04978",
        "title": "Looking Back, Moving Forward: A First-Person Perspective Of How Past Artificial Intelligence Encounters Shape Today's Creative Practice",
        "rating": "-10",
        "keywords": [],
        "abstract": "This visual narrative is a first-person reflection of the previous pictorial at the 1st International Workshop on Explainable AI for the Arts (XAIxArts) at ACM Creativity and Cognition 2023. The initial workshop pictorial explored a relationship between researcher and artificial intelligence, navigating creative challenges throughout the 2023 teaching block. It concluded by raising crucial questions regarding attribution transparency, the ethical dimensions of the creative process, and the delicate balance between inspiration and plagiarism. Subsequent discussions at the workshop yielded valuable insights, particularly concerning interpreting the creative journey. This follow-up visual narrative reflects the enduring impact of Makayla Lewis's interaction with AI. A self-portrait that delves into the interplay of creativity and introspection.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "6 Pages, 7 Figures, Explainable AI for the Arts Workshop 2024 (XAIxArts 2024)"
    },
    {
        "paper id": "2408.04981",
        "abstract url": "https://arxiv.org/abs/2408.04981",
        "title": "Early Exit Strategies for Approximate k-NN Search in Dense Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "Learned dense representations are a popular family of techniques for encoding queries and documents using high-dimensional embeddings, which enable retrieval by performing approximate k nearest-neighbors search (A-kNN). A popular technique for making A-kNN search efficient is based on a two-level index, where the embeddings of documents are clustered offline and, at query processing, a fixed number N of clusters closest to the query is visited exhaustively to compute the result set. In this paper, we build upon state-of-the-art for early exit A-kNN and propose an unsupervised method based on the notion of patience, which can reach competitive effectiveness with large efficiency gains. Moreover, we discuss a cascade approach where we first identify queries that find their nearest neighbor within the closest t << N clusters, and then we decide how many more to visit based on our patience approach or other state-of-the-art strategies. Reproducible experiments employing state-of-the-art dense retrieval models and publicly available resources show that our techniques improve the A-kNN efficiency with up to 5x speedups while achieving negligible effectiveness losses. All the code used is available at https://github.com/francescobusolin/faiss_pEE",
        "subjects": [
            "cs.IR"
        ],
        "comment": "6 pages, published at CIKM 2024"
    },
    {
        "paper id": "2408.04999",
        "abstract url": "https://arxiv.org/abs/2408.04999",
        "title": "MathPartner: An Artificial Intelligence Cloud Service",
        "rating": "-10",
        "keywords": [],
        "abstract": "In a broad sense, artificial intelligence is a service to find a solution to complex intellectual problems. In this sense, the MathPartner service provides artificial intelligence that allows us to formulate questions and receive answers to questions formulated in a mathematical language. For mathematicians and physicists today, such a language is \\LaTeX. The MathPartner service uses a dialect of \\LaTeX, which is called Mathpar. The service is a cloud-based computer algebra system and provides users with the opportunity to solve many mathematical problems. In this publication, we focus only on a small class of extremum problems, which are widely applied in economics, management, logistics, and in many engineering fields. In particular, we consider the shortest path problem and discuss an algorithm that is based on the tropical mathematics. The ability to work with many types of classical and tropical algebras, which are freely available to users, is an important distinguishing feature of this intelligent tool for symbolic-numerical calculations. We also consider the use of the simplex algorithm for solving optimization problems.",
        "subjects": [
            "cs.SC"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2408.05012",
        "abstract url": "https://arxiv.org/abs/2408.05012",
        "title": "Complete Dynamic Logic of Communicating Hybrid Programs",
        "rating": "-10",
        "keywords": [],
        "abstract": "This article presents a relatively complete proof calculus for the dynamic logic of communicating hybrid programs dLCHP. Beyond traditional hybrid systems mixing discrete and continuous dynamics, communicating hybrid programs feature parallel interactions of hybrid systems. This not only compounds the subtleties of hybrid and parallel systems but adds the truly simultaneous synchronized evolution of parallel hybrid dynamics as a new challenge. To enable compositional reasoning about communicating hybrid programs nevertheless, dLCHP combines differential dynamic logic dL and assumption-commitment reasoning. To maintain the logical essence of dynamic logic axiomatizations, dLCHP's proof calculus presents a new modal logic view onto ac-reasoning. This modal view drives a decomposition of classical monolithic proof rules for parallel systems reasoning into new modular axioms, which yields better flexibility and simplifies soundness arguments. Adequacy of the proof calculus is shown by two completeness results: First, dLCHP is complete relative to the logic of communication traces and differential equation properties. This result proves the new modular modal view sufficient for reasoning about parallel hybrid systems, and captures modular strategies for reasoning about concrete parallel hybrid systems. The second result proof-theoretically aligns dLCHP and dL by proving that reasoning about parallel hybrid systems is exactly as hard as reasoning about hybrid systems, continuous systems, or discrete systems. This completeness result reveals the possibility of representational succinctness in parallel hybrid systems proofs.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05033",
        "abstract url": "https://arxiv.org/abs/2408.05033",
        "title": "Approximate Distributed Monitoring under Partial Synchrony: Balancing Speed and Accuracy",
        "rating": "-10",
        "keywords": [],
        "abstract": "In distributed systems with processes that do not share a global clock, \\emph{partial synchrony} is achieved by clock synchronization that guarantees bounded clock skew among all applications. Existing solutions for distributed runtime verification under partial synchrony against temporal logic specifications are exact but suffer from significant computational overhead. In this paper, we propose an \\emph{approximate} distributed monitoring algorithm for Signal Temporal Logic (STL) that mitigates this issue by abstracting away potential interleaving behaviors. This conservative abstraction enables a significant speedup of the distributed monitors, albeit with a tradeoff in accuracy. We address this tradeoff with a methodology that combines our approximate monitor with its exact counterpart, resulting in enhanced efficiency without sacrificing precision. We evaluate our approach with multiple experiments, showcasing its efficacy in both real-world applications and synthetic examples.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "Full version of the paper to appear in RV 2024"
    },
    {
        "paper id": "2408.05123",
        "abstract url": "https://arxiv.org/abs/2408.05123",
        "title": "Sportify: Question Answering with Embedded Visualizations and Personified Narratives for Sports Video",
        "rating": "-10",
        "keywords": [],
        "abstract": "As basketball's popularity surges, fans often find themselves confused and overwhelmed by the rapid game pace and complexity. Basketball tactics, involving a complex series of actions, require substantial knowledge to be fully understood. This complexity leads to a need for additional information and explanation, which can distract fans from the game. To tackle these challenges, we present Sportify, a Visual Question Answering system that integrates narratives and embedded visualization for demystifying basketball tactical questions, aiding fans in understanding various game aspects. We propose three novel action visualizations (i.e., Pass, Cut, and Screen) to demonstrate critical action sequences. To explain the reasoning and logic behind players' actions, we leverage a large-language model (LLM) to generate narratives. We adopt a storytelling approach for complex scenarios from both first and third-person perspectives, integrating action visualizations. We evaluated Sportify with basketball fans to investigate its impact on understanding of tactics, and how different personal perspectives of narratives impact the understanding of complex tactic with action visualizations. Our evaluation with basketball fans demonstrates Sportify's capability to deepen tactical insights and amplify the viewing experience. Furthermore, third-person narration assists people in getting in-depth game explanations while first-person narration enhances fans' game engagement",
        "subjects": [
            "cs.HC"
        ],
        "comment": "14 pages, 8 figures, conference"
    },
    {
        "paper id": "2408.05128",
        "abstract url": "https://arxiv.org/abs/2408.05128",
        "title": "Is ChatGPT a Good Software Librarian? An Exploratory Study on the Use of ChatGPT for Software Library Recommendations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software libraries play a critical role in the functionality, efficiency, and maintainability of software systems. As developers increasingly rely on Large Language Models (LLMs) to streamline their coding processes, the effectiveness of these models in recommending appropriate libraries becomes crucial yet remains largely unexplored. In this paper, we assess the effectiveness of ChatGPT as a software librarian and identify areas for improvement. We conducted an empirical study using GPT-3.5 Turbo to generate Python code for 10,000 Stack Overflow questions. Our findings show that ChatGPT uses third-party libraries nearly 10% more often than human developers, favoring widely adopted and well-established options. However, 14.2% of the recommended libraries had restrictive copyleft licenses, which were not explicitly communicated by ChatGPT. Additionally, 6.5% of the libraries did not work out of the box, leading to potential developer confusion and wasted time. While ChatGPT can be an effective software librarian, it should be improved by providing more explicit information on maintainability metrics and licensing. We recommend that developers implement rigorous dependency management practices and double-check library licenses before integrating LLM-generated code into their projects.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Submitted"
    },
    {
        "paper id": "2408.05129",
        "abstract url": "https://arxiv.org/abs/2408.05129",
        "title": "Unboxing Default Argument Breaking Changes in 1 + 2 Data Science Libraries",
        "rating": "-10",
        "keywords": [],
        "abstract": "Data Science (DS) has become a cornerstone for modern software, enabling data-driven decisions to improve companies services. Following modern software development practices, data scientists use third-party libraries to support their tasks. As the APIs provided by these tools often require an extensive list of arguments to be set up, data scientists rely on default values to simplify their usage. It turns out that these default values can change over time, leading to a specific type of breaking change, defined as Default Argument Breaking Change (DABC). This work reveals 93 DABCs in three Python libraries frequently used in Data Science tasks -- Scikit Learn, NumPy, and Pandas -- studying their potential impact on more than 500K client applications. We find out that the occurrence of DABCs varies significantly depending on the library; 35% of Scikit Learn clients are affected, while only 0.13% of NumPy clients are impacted. The main reason for introducing DABCs is to enhance API maintainability, but they often change the function's behavior. We discuss the importance of managing DABCs in third-party DS libraries and provide insights for developers to mitigate the potential impact of these changes in their applications.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "38 pages, 3 figures, 13 tables"
    },
    {
        "paper id": "2408.05143",
        "abstract url": "https://arxiv.org/abs/2408.05143",
        "title": "A reduced simulation applied to viscoelastic fatigue of polymers using a time multi-scale approach based on Partition of Unity method",
        "rating": "-10",
        "keywords": [],
        "abstract": "The simulation of viscoelastic time-evolution problems described by a large number of internal variables and with a large spectrum of relaxation times requires high computational resources for their resolution. Furthermore, the internal variables evolution is described by a set of linear differential equations which involves many time scales. In this context, the use of a space-time PGD approximation is proposed here to boost their resolution, where the temporal functions are constructed following a multi-scale strategy along with the Partition of Unity method, in order to catch each dynamic efficiently. The feasibility and the robustness of the method are discussed in the case of a polymer in a non-equilibrium state under cyclic loading.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05152",
        "abstract url": "https://arxiv.org/abs/2408.05152",
        "title": "Sparsity-Preserving Encodings for Straggler-Optimal Distributed Matrix Computations at the Edge",
        "rating": "-10",
        "keywords": [],
        "abstract": "Matrix computations are a fundamental building-block of edge computing systems, with a major recent uptick in demand due to their use in AI/ML training and inference procedures. Existing approaches for distributing matrix computations involve allocating coded combinations of submatrices to worker nodes, to build resilience to slower nodes, called stragglers. In the edge learning context, however, these approaches will compromise sparsity properties that are often present in the original matrices found at the edge server. In this study, we consider the challenge of augmenting such approaches to preserve input sparsity when distributing the task across edge devices, thereby retaining the associated computational efficiency enhancements. First, we find a lower bound on the weight of coding, i.e., the number of submatrices to be combined to obtain coded submatrices, to provide the resilience to the maximum possible number of straggler devices (for given number of devices and their storage constraints). Next we propose distributed matrix computation schemes which meet the exact lower bound on the weight of the coding. Numerical experiments conducted in Amazon Web Services (AWS) validate our assertions regarding straggler mitigation and computation speed for sparse matrices.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2308.04331"
    },
    {
        "paper id": "2408.05163",
        "abstract url": "https://arxiv.org/abs/2408.05163",
        "title": "MADE-WIC: Multiple Annotated Datasets for Exploring Weaknesses In Code",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present MADE-WIC, a large dataset of functions and their comments with multiple annotations for technical debt and code weaknesses leveraging different state-of-the-art approaches. It contains about 860K code functions and more than 2.7M related comments from 12 open-source projects. To the best of our knowledge, no such dataset is publicly available. MADE-WIC aims to provide researchers with a curated dataset on which to test and compare tools designed for the detection of code weaknesses and technical debt. As we have fused existing datasets, researchers have the possibility to evaluate the performance of their tools by also controlling the bias related to the annotation definition and dataset construction. The demonstration video can be retrieved at https://www.youtube.com/watch?v=GaQodPrcb6E.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted at ASE@Tool Demonstrations"
    },
    {
        "paper id": "2408.05190",
        "abstract url": "https://arxiv.org/abs/2408.05190",
        "title": "Parameterized Verification of Timed Networks with Clock Invariants",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider parameterized verification problems for networks of timed automata (TAs) that communicate via disjunctive guards or lossy broadcast. To this end, we first consider disjunctive timed networks (DTNs), i.e., networks of TAs that communicate via location guards that enable a transition only if there is another process in a certain location. We solve for the first time the general case with clock invariants, and establish the decidability of the parameterized verification problem for local trace properties and for reachability of global configurations; Moreover, we prove that, surprisingly and unlike in other settings, this model is equivalent to lossy broadcast networks.",
        "subjects": [
            "cs.FL"
        ],
        "comment": "31 pages, 7 figures"
    },
    {
        "paper id": "2408.05304",
        "abstract url": "https://arxiv.org/abs/2408.05304",
        "title": "Beyond Diversity:Computing for Inclusive Software",
        "rating": "-10",
        "keywords": [],
        "abstract": "This chapter presents, from our research on inclusive software within the context of a diversity and inclusion based STEM program at the University of Victoria, INSPIRE: STEM for Social Impact (hereafter Inspire). In a society with an ever increasing reliance on technology, we often neglect the fact that software development processes and practices unintentionally marginalize certain groups of end users. While the Inspire program and its first iteration in 2022 are described in detail in CHAPTER 26, here we describe our insights from an analysis of the development processes and practices used by the teams. We found that empathy-based requirements gathering techniques and certain influences on the software development teams' motivation levels impact the teams' ability to build inclusive software. This chapter begins with an explanation of the Inspire program and a discussion on what the term ``inclusive software'' actually means in our context before highlighting useful practices for designing inclusive software.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05316",
        "abstract url": "https://arxiv.org/abs/2408.05316",
        "title": "Towards Verifying Exact Conditions of Density Functional Theory Approximations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Density Functional Theory (DFT) is used extensively in the computation of electronic properties of matter, with various applications. Approximating the exchange-correlation (XC) functional is the key to the Kohn-Sham DFT approach, the basis of most DFT calculations. The choice of this density functional approximation (DFA) depends crucially on the particular system under study, which has resulted in the development of hundreds of DFAs. Though the exact density functional is not known, researchers have discovered analytical properties of this exact functional. Furthermore, these exact conditions are used when designing DFAs. We present XCVerifier, the first approach for verifying whether a DFA implementation satisfies the DFT exact conditions. XCVerifier was evaluated on five DFAs from the popular Libxc library and seven exact conditions from recent work. XCVerifier was able to verify or find violations for a majority of the DFA/condition pairs, demonstrating the feasibility of using formal methods to verify DFA implementations.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05319",
        "abstract url": "https://arxiv.org/abs/2408.05319",
        "title": "Learning-based Parameterized Barrier Function for Safety-Critical Control of Unknown Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the increasing complexity of real-world systems and varying environmental uncertainties, it is difficult to build an accurate dynamic model, which poses challenges especially for safety-critical control. In this paper, a learning-based control policy is proposed to ensure the safety of systems with unknown disturbances through control barrier functions (CBFs). First, the disturbance is predicted by Gaussian process (GP) regression, whose prediction performance is guaranteed by a deterministic error bound. Then, a novel control strategy using GP-based parameterized high-order control barrier functions (GP-P-HOCBFs) is proposed via a shrunk original safe set based on the prediction error bound. In comparison to existing methods that involve adding strict robust safety terms to the HOCBF condition, the proposed method offers more flexibility to deal with the conservatism and the feasibility of solving quadratic problems within the CBF framework. Finally, the effectiveness of the proposed method is demonstrated by simulations on Franka Emika manipulator.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05332",
        "abstract url": "https://arxiv.org/abs/2408.05332",
        "title": "Monero Traceability Heuristics: Wallet Application Bugs and the Mordinal-P2Pool Perspective",
        "rating": "-10",
        "keywords": [],
        "abstract": "Privacy-focused cryptoassets like Monero are intentionally difficult to trace. Over the years, several traceability heuristics have been proposed, most of which have been rendered ineffective with subsequent protocol upgrades. Between 2019 and 2023, Monero wallet application bugs \"Differ By One\" and \"10 Block Decoy Bug\" have been observed and identified and discussed in the Monero community. In addition, a decentralized mining pool named P2Pool has proliferated, and a controversial UTXO NFT imitation known as Mordinals has been tried for Monero. In this paper, we systematically describe the traceability heuristics that have emerged from these developments, and evaluate their quality based on ground truth, and through pairwise comparisons. We also explore the temporal perspective, and show which of these heuristics have been applicable over the past years, what fraction of decoys could be eliminated and what the remaining effective ring size is. Our findings illustrate that most of the heuristics have a high precision, that the \"10 Block Decoy Bug\" and the Coinbase decoy identification heuristics have had the most impact between 2019 and 2023, and that the former could be used to evaluate future heuristics, if they are also applicable during that time frame.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 11 figures, author version of IEEE International Conference on Blockchain and Cryptocurrency 2024 paper"
    },
    {
        "paper id": "2408.05379",
        "abstract url": "https://arxiv.org/abs/2408.05379",
        "title": "Temporal Analysis and Repair of Flaky Dockerfiles",
        "rating": "-10",
        "keywords": [],
        "abstract": "Dockerfile flakiness, characterized by inconsistent build behavior without Dockerfile or project source code changes, poses significant challenges in Continuous Integration and Delivery (CI/CD) pipelines. This issue can lead to unreliable deployments and increased debugging efforts, yet it remains underexplored in current research. We conduct a systematic analysis of Dockerfile flakiness, presenting a comprehensive taxonomy of common flakiness categories, including dependency-related errors and server connectivity issues. Furthermore, we introduce FlakiDock, a tool leveraging large language models and retrieval-augmented generation techniques with dynamic analysis and an iterative feedback loop to automatically repair flaky Dockerfiles. Our evaluation shows that FlakiDock achieves a 73.55% repair accuracy, outperforming existing tools such as PARFUM by 12,581% and GPT-4-based prompting by 94.63%. These results underscore the effectiveness of FlakiDock in addressing Dockerfile flakiness and improving build reliability.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05388",
        "abstract url": "https://arxiv.org/abs/2408.05388",
        "title": "Report on the 1st Workshop on Large Language Model for Evaluation in Information Retrieval (LLM4Eval 2024) at SIGIR 2024",
        "rating": "-10",
        "keywords": [],
        "abstract": "The first edition of the workshop on Large Language Model for Evaluation in Information Retrieval (LLM4Eval 2024) took place in July 2024, co-located with the ACM SIGIR Conference 2024 in the USA (SIGIR 2024). The aim was to bring information retrieval researchers together around the topic of LLMs for evaluation in information retrieval that gathered attention with the advancement of large language models and generative AI. Given the novelty of the topic, the workshop was focused around multi-sided discussions, namely panels and poster sessions of the accepted proceedings papers.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "LLM4Eval Workshop Report"
    },
    {
        "paper id": "2408.05410",
        "abstract url": "https://arxiv.org/abs/2408.05410",
        "title": "Effects of Vote Delegation in Blockchains: Who Wins?",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates which alternative benefits from vote delegation in binary collective decisions within blockchains. We begin by examining two extreme cases of voting weight distributions: Equal-Weight (EW), where each voter has equal voting weight, and Dominant-Weight (DW), where a single voter holds a majority of the voting weights before any delegation occurs. We show that vote delegation tends to benefit the ex-ante minority under EW, i.e., the alternative with a lower initial probability of winning. The converse holds under DW distribution. Through numerical simulations, we extend our findings to arbitrary voting weight distributions, showing that vote delegation benefits the ex-ante majority when it leads to a more balanced distribution of voting weights. Finally, in large communities where all agents have equal voting weight, vote delegation has a negligible impact on the outcome. These insights provide practical guidance for governance decisions in blockchains.",
        "subjects": [
            "cs.GT",
            "econ.TH"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05422",
        "abstract url": "https://arxiv.org/abs/2408.05422",
        "title": "Sparsely Pre-transformed Polar Codes for Low-Latency SCL Decoding",
        "rating": "-10",
        "keywords": [],
        "abstract": "Deep polar codes, employing multi-layered polar kernel pre-transforms in series, are recently introduced variants of pre-transformed polar codes. These codes have demonstrated the ability to reduce the number of minimum weight codewords, thereby closely achieving finite-block length capacity with successive cancellation list (SCL) decoders in certain scenarios. However, when the list size of the SCL decoder is small, which is crucial for low-latency communication applications, the reduction in the number of minimum weight codewords does not necessarily improve decoding performance. To address this limitation, we propose an alternative pre-transform technique to enhance the suitability of polar codes for SCL decoders with practical list sizes. Leveraging the fact that the SCL decoding error event set can be decomposed into two exclusive error event sets, our approach applies two different types of pre-transformations, each targeting the reduction of one of the two error event sets. Extensive simulation results under various block lengths and code rates have demonstrated that our codes consistently outperform all existing state-of-the-art pre-transformed polar codes, including CRC-aided polar codes and polarization-adjusted convolutional codes, when decoded using SCL decoders with small list sizes.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2408.05432",
        "abstract url": "https://arxiv.org/abs/2408.05432",
        "title": "Simpler is More: Efficient Top-K Nearest Neighbors Search on Large Road Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Top-k Nearest Neighbors (kNN) problem on road network has numerous applications on location-based services. As direct search using the Dijkstra's algorithm results in a large search space, a plethora of complex-index-based approaches have been proposed to speedup the query processing. However, even with the current state-of-the-art approach, long query processing delays persist, along with significant space overhead and prohibitively long indexing time. In this paper, we depart from the complex index designs prevalent in existing literature and propose a simple index named KNN-Index. With KNN-Index, we can answer a kNN query optimally and progressively with small and size-bounded index. To improve the index construction performance, we propose a bidirectional construction algorithm which can effectively share the common computation during the construction. Theoretical analysis and experimental results on real road networks demonstrate the superiority of KNN-Index over the state-of-the-art approach in query processing performance, index size, and index construction efficiency.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "15 pages, 15 figures"
    },
    {
        "paper id": "2408.05439",
        "abstract url": "https://arxiv.org/abs/2408.05439",
        "title": "Humboldt: Metadata-Driven Extensible Data Discovery",
        "rating": "-10",
        "keywords": [],
        "abstract": "Data discovery is crucial for data management and analysis and can benefit from better utilization of metadata. For example, users may want to search data using queries like ``find the tables created by Alex and endorsed by Mike that contain sales numbers.'' They may also want to see how the data they view relates to other data, its lineage, or the quality and compliance of its upstream datasets, all metadata. Yet, effectively surfacing metadata through interactive user interfaces (UIs) to augment data discovery poses challenges. Constantly revamping UIs with each update to metadata sources (or providers) consumes significant development resources and lacks scalability and extensibility. In response, we introduce Humboldt, a new framework enabling interactive data systems to effectively leverage metadata for data discovery and rapidly evolve their UIs to support metadata changes. Humboldt decouples metadata sources from the implementation of data discovery UIs that support search and dataset visualization using metadata fields. It automatically generates interactive data discovery interfaces from declarative specifications, avoiding costly metadata-specific (re)implementations.",
        "subjects": [
            "cs.DB",
            "cs.HC"
        ],
        "comment": "TaDA Workshop at VLDB 2024"
    },
    {
        "paper id": "2408.07023",
        "abstract url": "https://arxiv.org/abs/2408.07023",
        "title": "Verifiable Decentralized IPFS Cluster: Unlocking Trustworthy Data Permanency for Off-Chain Storage",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Decentralized Applications, off-chain storage solutions such as the InterPlanetary File System (IPFS) are crucial in overcoming Blockchain storage limitations. However, the assurance of data permanency in IPFS relies on the pinning of data, which comes with trust issues and potential single points of failure. This paper introduces Verifiable Decentralized IPFS Clusters (VDICs) to enhance off-chain storage reliability with verifiable data permanency guarantees. VDICs leverage Decentralized Identifier, Verifiable Credentials, and IPFS Clusters to create a trustworthy ecosystem where the storage of pinned data is transparent and verifiable. Performance evaluations demonstrate that VDICs are competitive with traditional pinning services. Real-life use cases validate their feasibility and practicality for providers of Decentralized Applications focused on ensuring data permanency.",
        "subjects": [
            "cs.DC",
            "cs.CR"
        ],
        "comment": null
    }
]