[
    {
        "paper id": "2408.06569",
        "abstract url": "https://arxiv.org/abs/2408.06569",
        "title": "Social Debiasing for Fair Multi-modal LLMs",
        "rating": "3",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "social biases"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Multi-modal Large Language Models (MLLMs) have advanced significantly, offering powerful vision-language understanding capabilities. However, these models often inherit severe social biases from their training datasets, leading to unfair predictions based on attributes like race and gender. This paper addresses the issue of social biases in MLLMs by i) Introducing a comprehensive Counterfactual dataset with Multiple Social Concepts (CMSC), which provides a more diverse and extensive training set compared to existing datasets. ii) Proposing an Anti-Stereotype Debiasing strategy (ASD). Our method works by revisiting the MLLM training process, rescaling the autoregressive loss function, and improving data sampling methods to counteract biases. Through extensive experiments on various MLLMs, our CMSC dataset and ASD method demonstrate a significant reduction in social biases while maintaining the models' original performance.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06610",
        "abstract url": "https://arxiv.org/abs/2408.06610",
        "title": "CROME: Cross-Modal Adapters for Efficient Multimodal LLM",
        "rating": "3",
        "keywords": [
            [
                "parameter efficiency"
            ],
            [
                "vision-language"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) demonstrate remarkable image-language capabilities, but their widespread use faces challenges in cost-effective training and adaptation. Existing approaches often necessitate expensive language model retraining and limited adaptability. Additionally, the current focus on zero-shot performance improvements offers insufficient guidance for task-specific tuning. We propose CROME, an efficient vision-language instruction tuning framework. It features a novel gated cross-modal adapter that effectively combines visual and textual representations prior to input into a frozen LLM. This lightweight adapter, trained with minimal parameters, enables efficient cross-modal understanding. Notably, CROME demonstrates superior zero-shot performance on standard visual question answering and instruction-following benchmarks. Moreover, it yields fine-tuning with exceptional parameter efficiency, competing with task-specific specialist state-of-the-art methods. CROME demonstrates the potential of pre-LM alignment for building scalable, adaptable, and parameter-efficient multimodal models.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05955",
        "abstract url": "https://arxiv.org/abs/2408.05955",
        "title": "Probabilistic Vision-Language Representation for Weakly Supervised Temporal Action Localization",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Weakly supervised temporal action localization (WTAL) aims to detect action instances in untrimmed videos using only video-level annotations. Since many existing works optimize WTAL models based on action classification labels, they encounter the task discrepancy problem (i.e., localization-by-classification). To tackle this issue, recent studies have attempted to utilize action category names as auxiliary semantic knowledge through vision-language pre-training (VLP). However, there are still areas where existing research falls short. Previous approaches primarily focused on leveraging textual information from language models but overlooked the alignment of dynamic human action and VLP knowledge in a joint space. Furthermore, the deterministic representation employed in previous studies struggles to capture fine-grained human motions. To address these problems, we propose a novel framework that aligns human action knowledge and VLP knowledge in a probabilistic embedding space. Moreover, we propose intra- and inter-distribution contrastive learning to enhance the probabilistic embedding space based on statistical similarities. Extensive experiments and ablation studies reveal that our method significantly outperforms all previous state-of-the-art methods. Code is available at https://github.com/sejong-rcv/PVLR.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ACM MM 2024"
    },
    {
        "paper id": "2408.06158",
        "abstract url": "https://arxiv.org/abs/2408.06158",
        "title": "OmniCLIP: Adapting CLIP for Video Recognition with Spatial-Temporal Omni-Scale Feature Learning",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent Vision-Language Models (VLMs) \\textit{e.g.} CLIP have made great progress in video recognition. Despite the improvement brought by the strong visual backbone in extracting spatial features, CLIP still falls short in capturing and integrating spatial-temporal features which is essential for video recognition. In this paper, we propose OmniCLIP, a framework that adapts CLIP for video recognition by focusing on learning comprehensive features encompassing spatial, temporal, and dynamic spatial-temporal scales, which we refer to as omni-scale features. This is achieved through the design of spatial-temporal blocks that include parallel temporal adapters (PTA), enabling efficient temporal modeling. Additionally, we introduce a self-prompt generator (SPG) module to capture dynamic object spatial features. The synergy between PTA and SPG allows OmniCLIP to discern varying spatial information across frames and assess object scales over time. We have conducted extensive experiments in supervised video recognition, few-shot video recognition, and zero-shot recognition tasks. The results demonstrate the effectiveness of our method, especially with OmniCLIP achieving a top-1 accuracy of 74.30\\% on HMDB51 in a 16-shot setting, surpassing the recent MotionPrompt approach even with full training data. The code is available at \\url{https://github.com/XiaoBuL/OmniCLIP}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECAI-2024"
    },
    {
        "paper id": "2408.06259",
        "abstract url": "https://arxiv.org/abs/2408.06259",
        "title": "Context-aware Visual Storytelling with Visual Prefix Tuning and Contrastive Learning",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Visual storytelling systems generate multi-sentence stories from image sequences. In this task, capturing contextual information and bridging visual variation bring additional challenges. We propose a simple yet effective framework that leverages the generalization capabilities of pretrained foundation models, only training a lightweight vision-language mapping network to connect modalities, while incorporating context to enhance coherence. We introduce a multimodal contrastive objective that also improves visual relevance and story informativeness. Extensive experimental results, across both automatic metrics and human evaluations, demonstrate that the stories generated by our framework are diverse, coherent, informative, and interesting.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": "18 pages, 12 figures, accepted by INLG 2024"
    },
    {
        "paper id": "2408.06303",
        "abstract url": "https://arxiv.org/abs/2408.06303",
        "title": "Long-Form Answers to Visual Questions from Blind and Low Vision People",
        "rating": "2",
        "keywords": [
            [
                "Vision language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Vision language models can now generate long-form answers to questions about images - long-form visual question answers (LFVQA). We contribute VizWiz-LF, a dataset of long-form answers to visual questions posed by blind and low vision (BLV) users. VizWiz-LF contains 4.2k long-form answers to 600 visual questions, collected from human expert describers and six VQA models. We develop and annotate functional roles of sentences of LFVQA and demonstrate that long-form answers contain information beyond the question answer such as explanations and suggestions. We further conduct automatic and human evaluations with BLV and sighted people to evaluate long-form answers. BLV people perceive both human-written and generated long-form answers to be plausible, but generated answers often hallucinate incorrect visual details, especially for unanswerable visual questions (e.g., blurry or irrelevant images). To reduce hallucinations, we evaluate the ability of VQA models to abstain from answering unanswerable questions across multiple prompting strategies.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": "COLM 2024"
    },
    {
        "paper id": "2408.06567",
        "abstract url": "https://arxiv.org/abs/2408.06567",
        "title": "AquilaMoE: Efficient Training for MoE Models with Scale-Up and Scale-Out Strategies",
        "rating": "2",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, with the rapid application of large language models across various fields, the scale of these models has gradually increased, and the resources required for their pre-training have grown exponentially. Training an LLM from scratch will cost a lot of computation resources while scaling up from a smaller model is a more efficient approach and has thus attracted significant attention. In this paper, we present AquilaMoE, a cutting-edge bilingual 8*16B Mixture of Experts (MoE) language model that has 8 experts with 16 billion parameters each and is developed using an innovative training methodology called EfficientScale. This approach optimizes performance while minimizing data requirements through a two-stage process. The first stage, termed Scale-Up, initializes the larger model with weights from a pre-trained smaller model, enabling substantial knowledge transfer and continuous pretraining with significantly less data. The second stage, Scale-Out, uses a pre-trained dense model to initialize the MoE experts, further enhancing knowledge transfer and performance. Extensive validation experiments on 1.8B and 7B models compared various initialization schemes, achieving models that maintain and reduce loss during continuous pretraining. Utilizing the optimal scheme, we successfully trained a 16B model and subsequently the 8*16B AquilaMoE model, demonstrating significant improvements in performance and training efficiency.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06622",
        "abstract url": "https://arxiv.org/abs/2408.06622",
        "title": "ActPrompt: In-Domain Feature Adaptation via Action Cues for Video Temporal Grounding",
        "rating": "2",
        "keywords": [
            [
                "vision-language",
                "VLM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video temporal grounding is an emerging topic aiming to identify specific clips within videos. In addition to pre-trained video models, contemporary methods utilize pre-trained vision-language models (VLM) to capture detailed characteristics of diverse scenes and objects from video frames. However, as pre-trained on images, VLM may struggle to distinguish action-sensitive patterns from static objects, making it necessary to adapt them to specific data domains for effective feature representation over temporal grounding. We address two primary challenges to achieve this goal. Specifically, to mitigate high adaptation costs, we propose an efficient preliminary in-domain fine-tuning paradigm for feature adaptation, where downstream-adaptive features are learned through several pretext tasks. Furthermore, to integrate action-sensitive information into VLM, we introduce Action-Cue-Injected Temporal Prompt Learning (ActPrompt), which injects action cues into the image encoder of VLM for better discovering action-sensitive patterns. Extensive experiments demonstrate that ActPrompt is an off-the-shelf training framework that can be effectively applied to various SOTA methods, resulting in notable improvements. The complete code used in this study is provided in the supplementary materials.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2408.06302",
        "abstract url": "https://arxiv.org/abs/2408.06302",
        "title": "Finding Patterns in Ambiguity: Interpretable Stress Testing in the Decision~Boundary",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "The increasing use of deep learning across various domains highlights the importance of understanding the decision-making processes of these black-box models. Recent research focusing on the decision boundaries of deep classifiers, relies on generated synthetic instances in areas of low confidence, uncovering samples that challenge both models and humans. We propose a novel approach to enhance the interpretability of deep binary classifiers by selecting representative samples from the decision boundary - prototypes - and applying post-model explanation algorithms. We evaluate the effectiveness of our approach through 2D visualizations and GradientSHAP analysis. Our experiments demonstrate the potential of the proposed method, revealing distinct and compact clusters and diverse prototypes that capture essential features that lead to low-confidence decisions. By offering a more aggregated view of deep classifiers' decision boundaries, our work contributes to the responsible development and deployment of reliable machine learning systems.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "To be published in the Responsible Generative AI workshop at CVPR"
    },
    {
        "paper id": "2408.06437",
        "abstract url": "https://arxiv.org/abs/2408.06437",
        "title": "HAT: History-Augmented Anchor Transformer for Online Temporal Action Localization",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Online video understanding often relies on individual frames, leading to frame-by-frame predictions. Recent advancements such as Online Temporal Action Localization (OnTAL), extend this approach to instance-level predictions. However, existing methods mainly focus on short-term context, neglecting historical information. To address this, we introduce the History-Augmented Anchor Transformer (HAT) Framework for OnTAL. By integrating historical context, our framework enhances the synergy between long-term and short-term information, improving the quality of anchor features crucial for classification and localization. We evaluate our model on both procedural egocentric (PREGO) datasets (EGTEA and EPIC) and standard non-PREGO OnTAL datasets (THUMOS and MUSES). Results show that our model outperforms state-of-the-art approaches significantly on PREGO datasets and achieves comparable or slightly superior performance on non-PREGO datasets, underscoring the importance of leveraging long-term history, especially in procedural and egocentric action scenarios. Code is available at: https://github.com/sakibreza/ECCV24-HAT/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV 2024"
    },
    {
        "paper id": "2408.05923",
        "abstract url": "https://arxiv.org/abs/2408.05923",
        "title": "Image Denoising Using Green Channel Prior",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Image denoising is an appealing and challenging task, in that noise statistics of real-world observations may vary with local image contents and different image channels. Specifically, the green channel usually has twice the sampling rate in raw data. To handle noise variances and leverage such channel-wise prior information, we propose a simple and effective green channel prior-based image denoising (GCP-ID) method, which integrates GCP into the classic patch-based denoising framework. Briefly, we exploit the green channel to guide the search for similar patches, which aims to improve the patch grouping quality and encourage sparsity in the transform domain. The grouped image patches are then reformulated into RGGB arrays to explicitly characterize the density of green samples. Furthermore, to enhance the adaptivity of GCP-ID to various image contents, we cast the noise estimation problem into a classification task and train an effective estimator based on convolutional neural networks (CNNs). Experiments on real-world datasets demonstrate the competitive performance of the proposed GCP-ID method for image and video denoising applications in both raw and sRGB spaces. Our code is available at https://github.com/ZhaomingKong/GCP-ID.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2402.08235"
    },
    {
        "paper id": "2408.05926",
        "abstract url": "https://arxiv.org/abs/2408.05926",
        "title": "BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Multimodal Dialogue Response Generation (MDRG) is a recently proposed task where the model needs to generate responses in texts, images, or a blend of both based on the dialogue context. Due to the lack of a large-scale dataset specifically for this task and the benefits of leveraging powerful pre-trained models, previous work relies on the text modality as an intermediary step for both the image input and output of the model rather than adopting an end-to-end approach. However, this approach can overlook crucial information about the image, hindering 1) image-grounded text response and 2) consistency of objects in the image response. In this paper, we propose BI-MDRG that bridges the response generation path such that the image history information is utilized for enhanced relevance of text responses to the image content and the consistency of objects in sequential image responses. Through extensive experiments on the multimodal dialogue benchmark dataset, we show that BI-MDRG can effectively increase the quality of multimodal dialogue. Additionally, recognizing the gap in benchmark datasets for evaluating the image consistency in multimodal dialogue, we have created a curated set of 300 dialogues annotated to track object consistency across conversations.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2408.05936",
        "abstract url": "https://arxiv.org/abs/2408.05936",
        "title": "Multi-scale Contrastive Adaptor Learning for Segmenting Anything in Underperformed Scenes",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Foundational vision models, such as the Segment Anything Model (SAM), have achieved significant breakthroughs through extensive pre-training on large-scale visual datasets. Despite their general success, these models may fall short in specialized tasks with limited data, and fine-tuning such large-scale models is often not feasible. Current strategies involve incorporating adaptors into the pre-trained SAM to facilitate downstream task performance with minimal model adjustment. However, these strategies can be hampered by suboptimal learning approaches for the adaptors. In this paper, we introduce a novel Multi-scale Contrastive Adaptor learning method named MCA-SAM, which enhances adaptor performance through a meticulously designed contrastive learning framework at both token and sample levels. Our Token-level Contrastive adaptor (TC-adaptor) focuses on refining local representations by improving the discriminability of patch tokens, while the Sample-level Contrastive adaptor (SC-adaptor) amplifies global understanding across different samples. Together, these adaptors synergistically enhance feature comparison within and across samples, bolstering the model's representational strength and its ability to adapt to new tasks. Empirical results demonstrate that MCA-SAM sets new benchmarks, outperforming existing methods in three challenging domains: camouflage object detection, shadow segmentation, and polyp segmentation. Specifically, MCA-SAM exhibits substantial relative performance enhancements, achieving a 20.0% improvement in MAE on the COD10K dataset, a 6.0% improvement in MAE on the CAMO dataset, a 15.4% improvement in BER on the ISTD dataset, and a 7.9% improvement in mDice on the Kvasir-SEG dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05952",
        "abstract url": "https://arxiv.org/abs/2408.05952",
        "title": "Optimizing Vision Transformers with Data-Free Knowledge Transfer",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The groundbreaking performance of transformers in Natural Language Processing (NLP) tasks has led to their replacement of traditional Convolutional Neural Networks (CNNs), owing to the efficiency and accuracy achieved through the self-attention mechanism. This success has inspired researchers to explore the use of transformers in computer vision tasks to attain enhanced long-term semantic awareness. Vision transformers (ViTs) have excelled in various computer vision tasks due to their superior ability to capture long-distance dependencies using the self-attention mechanism. Contemporary ViTs like Data Efficient Transformers (DeiT) can effectively learn both global semantic information and local texture information from images, achieving performance comparable to traditional CNNs. However, their impressive performance comes with a high computational cost due to very large number of parameters, hindering their deployment on devices with limited resources like smartphones, cameras, drones etc. Additionally, ViTs require a large amount of data for training to achieve performance comparable to benchmark CNN models. Therefore, we identified two key challenges in deploying ViTs on smaller form factor devices: the high computational requirements of large models and the need for extensive training data. As a solution to these challenges, we propose compressing large ViT models using Knowledge Distillation (KD), which is implemented data-free to circumvent limitations related to data availability. Additionally, we conducted experiments on object detection within the same environment in addition to classification tasks. Based on our analysis, we found that datafree knowledge distillation is an effective method to overcome both issues, enabling the deployment of ViTs on less resourceconstrained devices.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05953",
        "abstract url": "https://arxiv.org/abs/2408.05953",
        "title": "A Simple Task-aware Contrastive Local Descriptor Selection Strategy for Few-shot Learning between inter class and intra class",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot image classification aims to classify novel classes with few labeled samples. Recent research indicates that deep local descriptors have better representational capabilities. These studies recognize the impact of background noise on classification performance. They typically filter query descriptors using all local descriptors in the support classes or engage in bidirectional selection between local descriptors in support and query sets. However, they ignore the fact that background features may be useful for the classification performance of specific tasks. This paper proposes a novel task-aware contrastive local descriptor selection network (TCDSNet). First, we calculate the contrastive discriminative score for each local descriptor in the support class, and select discriminative local descriptors to form a support descriptor subset. Finally, we leverage support descriptor subsets to adaptively select discriminative query descriptors for specific tasks. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on both general and fine-grained datasets.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Submitted to ICANN 2024"
    },
    {
        "paper id": "2408.05956",
        "abstract url": "https://arxiv.org/abs/2408.05956",
        "title": "Boosting Adverse Weather Crowd Counting via Multi-queue Contrastive Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Currently, most crowd counting methods have outstanding performance under normal weather conditions. However, they often struggle to maintain their performance in extreme and adverse weather conditions due to significant differences in the domain and a lack of adverse weather images for training. To address this issue and enhance the model's robustness in adverse weather, we propose a two-stage crowd counting method. Specifically, in the first stage, we introduce a multi-queue MoCo contrastive learning strategy to tackle the problem of weather class imbalance. This strategy facilitates the learning of weather-aware representations by the model. In the second stage, we propose to refine the representations under the guidance of contrastive learning, enabling the conversion of the weather-aware representations to the normal weather domain. While significantly improving the robustness, our method only marginally increases the weight of the model. In addition, we also create a new synthetic adverse weather dataset. Extensive experimental results show that our method achieves competitive performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2408.05964",
        "abstract url": "https://arxiv.org/abs/2408.05964",
        "title": "Target Detection of Safety Protective Gear Using the Improved YOLOv5",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In high-risk railway construction, personal protective equipment monitoring is critical but challenging due to small and frequently obstructed targets. We propose YOLO-EA, an innovative model that enhances safety measure detection by integrating ECA into its backbone's convolutional layers, improving discernment of minuscule objects like hardhats. YOLO-EA further refines target recognition under occlusion by replacing GIoU with EIoU loss. YOLO-EA's effectiveness was empirically substantiated using a dataset derived from real-world railway construction site surveillance footage. It outperforms YOLOv5, achieving 98.9% precision and 94.7% recall, up 2.5% and 0.5% respectively, while maintaining real-time performance at 70.774 fps. This highly efficient and precise YOLO-EA holds great promise for practical application in intricate construction scenarios, enforcing stringent safety compliance during complex railway construction projects.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05966",
        "abstract url": "https://arxiv.org/abs/2408.05966",
        "title": "Freehand Sketch Generation from Mechanical Components",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Drawing freehand sketches of mechanical components on multimedia devices for AI-based engineering modeling has become a new trend. However, its development is being impeded because existing works cannot produce suitable sketches for data-driven research. These works either generate sketches lacking a freehand style or utilize generative models not originally designed for this task resulting in poor effectiveness. To address this issue, we design a two-stage generative framework mimicking the human sketching behavior pattern, called MSFormer, which is the first time to produce humanoid freehand sketches tailored for mechanical components. The first stage employs Open CASCADE technology to obtain multi-view contour sketches from mechanical components, filtering perturbing signals for the ensuing generation process. Meanwhile, we design a view selector to simulate viewpoint selection tasks during human sketching for picking out information-rich sketches. The second stage translates contour sketches into freehand sketches by a transformer-based generator. To retain essential modeling features as much as possible and rationalize stroke distribution, we introduce a novel edge-constraint stroke initialization. Furthermore, we utilize a CLIP vision encoder and a new loss function incorporating the Hausdorff distance to enhance the generalizability and robustness of the model. Extensive experiments demonstrate that our approach achieves state-of-the-art performance for generating freehand sketches in the mechanical domain. Project page: https://mcfreeskegen.github.io .",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.MM"
        ],
        "comment": "Published at ACM Multimedia (ACM MM) 2024"
    },
    {
        "paper id": "2408.05974",
        "abstract url": "https://arxiv.org/abs/2408.05974",
        "title": "Unseen No More: Unlocking the Potential of CLIP for Generative Zero-shot HOI Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Zero-shot human-object interaction (HOI) detector is capable of generalizing to HOI categories even not encountered during training. Inspired by the impressive zero-shot capabilities offered by CLIP, latest methods strive to leverage CLIP embeddings for improving zero-shot HOI detection. However, these embedding-based methods train the classifier on seen classes only, inevitably resulting in seen-unseen confusion for the model during inference. Besides, we find that using prompt-tuning and adapters further increases the gap between seen and unseen accuracy. To tackle this challenge, we present the first generation-based model using CLIP for zero-shot HOI detection, coined HOIGen. It allows to unlock the potential of CLIP for feature generation instead of feature extraction only. To achieve it, we develop a CLIP-injected feature generator in accordance with the generation of human, object and union features. Then, we extract realistic features of seen samples and mix them with synthetic features together, allowing the model to train seen and unseen classes jointly. To enrich the HOI scores, we construct a generative prototype bank in a pairwise HOI recognition branch, and a multi-knowledge prototype bank in an image-wise HOI recognition branch, respectively. Extensive experiments on HICO-DET benchmark demonstrate our HOIGen achieves superior performance for both seen and unseen classes under various zero-shot settings, compared with other top-performing methods. Code is available at: https://github.com/soberguo/HOIGen",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ACM MM 2024"
    },
    {
        "paper id": "2408.05976",
        "abstract url": "https://arxiv.org/abs/2408.05976",
        "title": "Global-to-Local Support Spectrums for Language Model Explainability",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Existing sample-based methods, like influence functions and representer points, measure the importance of a training point by approximating the effect of its removal from training. As such, they are skewed towards outliers and points that are very close to the decision boundaries. The explanations provided by these methods are often static and not specific enough for different test points. In this paper, we propose a method to generate an explanation in the form of support spectrums which are based on two main ideas: the support sets and a global-to-local importance measure. The support set is the set of training points, in the predicted class, that ``lie in between'' the test point and training points in the other classes. They indicate how well the test point can be distinguished from the points not in the predicted class. The global-to-local importance measure is obtained by decoupling existing methods into the global and local components which are then used to select the points in the support set. Using this method, we are able to generate explanations that are tailored to specific test points. In the experiments, we show the effectiveness of the method in image classification and text generation tasks.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06000",
        "abstract url": "https://arxiv.org/abs/2408.06000",
        "title": "An Analysis for Image-to-Image Translation and Style Transfer",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "With the development of generative technologies in deep learning, a large number of image-to-image translation and style transfer models have emerged at an explosive rate in recent years. These two technologies have made significant progress and can generate realistic images. However, many communities tend to confuse the two, because both generate the desired image based on the input image and both cover the two definitions of content and style. In fact, there are indeed significant differences between the two, and there is currently a lack of clear explanations to distinguish the two technologies, which is not conducive to the advancement of technology. We hope to serve the entire community by introducing the differences and connections between image-to-image translation and style transfer. The entire discussion process involves the concepts, forms, training modes, evaluation processes, and visualization results of the two technologies. Finally, we conclude that image-to-image translation divides images by domain, and the types of images in the domain are limited, and the scope involved is small, but the conversion ability is strong and can achieve strong semantic changes. Style transfer divides image types by single image, and the scope involved is large, but the transfer ability is limited, and it transfers more texture and color of the image.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06014",
        "abstract url": "https://arxiv.org/abs/2408.06014",
        "title": "A Sharpness Based Loss Function for Removing Out-of-Focus Blur",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The success of modern Deep Neural Network (DNN) approaches can be attributed to the use of complex optimization criteria beyond standard losses such as mean absolute error (MAE) or mean squared error (MSE). In this work, we propose a novel method of utilising a no-reference sharpness metric Q introduced by Zhu and Milanfar for removing out-of-focus blur from images. We also introduce a novel dataset of real-world out-of-focus images for assessing restoration models. Our fine-tuned method produces images with a 7.5 % increase in perceptual quality (LPIPS) as compared to a standard model trained only on MAE. Furthermore, we observe a 6.7 % increase in Q (reflecting sharper restorations) and 7.25 % increase in PSNR over most state-of-the-art (SOTA) methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "6 pages, IEEE MMSP"
    },
    {
        "paper id": "2408.06018",
        "abstract url": "https://arxiv.org/abs/2408.06018",
        "title": "Uncertainty-Informed Volume Visualization using Implicit Neural Representation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The increasing adoption of Deep Neural Networks (DNNs) has led to their application in many challenging scientific visualization tasks. While advanced DNNs offer impressive generalization capabilities, understanding factors such as model prediction quality, robustness, and uncertainty is crucial. These insights can enable domain scientists to make informed decisions about their data. However, DNNs inherently lack ability to estimate prediction uncertainty, necessitating new research to construct robust uncertainty-aware visualization techniques tailored for various visualization tasks. In this work, we propose uncertainty-aware implicit neural representations to model scalar field data sets effectively and comprehensively study the efficacy and benefits of estimated uncertainty information for volume visualization tasks. We evaluate the effectiveness of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout (MCDropout). These techniques enable uncertainty-informed volume visualization in scalar field data sets. Our extensive exploration across multiple data sets demonstrates that uncertainty-aware models produce informative volume visualization results. Moreover, integrating prediction uncertainty enhances the trustworthiness of our DNN model, making it suitable for robustly analyzing and visualizing real-world scientific volumetric data sets.",
        "subjects": [
            "cs.GR",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "To appear in IEEE Workshop on Uncertainty Visualization in conjunction with IEEE VIS 2024, Florida, USA"
    },
    {
        "paper id": "2408.06021",
        "abstract url": "https://arxiv.org/abs/2408.06021",
        "title": "ClickAttention: Click Region Similarity Guided Interactive Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Interactive segmentation algorithms based on click points have garnered significant attention from researchers in recent years. However, existing studies typically use sparse click maps as model inputs to segment specific target objects, which primarily affect local regions and have limited abilities to focus on the whole target object, leading to increased times of clicks. In addition, most existing algorithms can not balance well between high performance and efficiency. To address this issue, we propose a click attention algorithm that expands the influence range of positive clicks based on the similarity between positively-clicked regions and the whole input. We also propose a discriminative affinity loss to reduce the attention coupling between positive and negative click regions to avoid an accuracy decrease caused by mutual interference between positive and negative clicks. Extensive experiments demonstrate that our approach is superior to existing methods and achieves cutting-edge performance in fewer parameters. An interactive demo and all reproducible codes will be released at https://github.com/hahamyt/ClickAttention.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06024",
        "abstract url": "https://arxiv.org/abs/2408.06024",
        "title": "Layer-Specific Optimization: Sensitivity Based Convolution Layers Basis Search",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural network models have a complex architecture and are overparameterized. The number of parameters is more than the whole dataset, which is highly resource-consuming. This complicates their application and limits its usage on different devices. Reduction in the number of network parameters helps to reduce the size of the model, but at the same time, thoughtlessly applied, can lead to a deterioration in the quality of the network. One way to reduce the number of model parameters is matrix decomposition, where a matrix is represented as a product of smaller matrices. In this paper, we propose a new way of applying the matrix decomposition with respect to the weights of convolutional layers. The essence of the method is to train not all convolutions, but only the subset of convolutions (basis convolutions), and represent the rest as linear combinations of the basis ones. Experiments on models from the ResNet family and the CIFAR-10 dataset demonstrate that basis convolutions can not only reduce the size of the model but also accelerate the forward and backward passes of the network. Another contribution of this work is that we propose a fast method for selecting a subset of network layers in which the use of matrix decomposition does not degrade the quality of the final model.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "math.NA"
        ],
        "comment": "Increase the size of matrix pictures for better UX in PDF view"
    },
    {
        "paper id": "2408.06043",
        "abstract url": "https://arxiv.org/abs/2408.06043",
        "title": "Enhancing Dialogue Speech Recognition with Robust Contextual Awareness via Noise Representation Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent dialogue systems rely on turn-based spoken interactions, requiring accurate Automatic Speech Recognition (ASR). Errors in ASR can significantly impact downstream dialogue tasks. To address this, using dialogue context from user and agent interactions for transcribing subsequent utterances has been proposed. This method incorporates the transcription of the user's speech and the agent's response as model input, using the accumulated context generated by each turn. However, this context is susceptible to ASR errors because it is generated by the ASR model in an auto-regressive fashion. Such noisy context can further degrade the benefits of context input, resulting in suboptimal ASR performance. In this paper, we introduce Context Noise Representation Learning (CNRL) to enhance robustness against noisy context, ultimately improving dialogue speech recognition accuracy. To maximize the advantage of context awareness, our approach includes decoder pre-training using text-based dialogue data and noise representation learning for a context encoder. Based on the evaluation of speech dialogues, our method shows superior results compared to baselines. Furthermore, the strength of our approach is highlighted in noisy environments where user speech is barely audible due to real-world noise, relying on contextual information to transcribe the input accurately.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "11 pages, 2 figures, Accepted to SIGDIAL2024"
    },
    {
        "paper id": "2408.06053",
        "abstract url": "https://arxiv.org/abs/2408.06053",
        "title": "PyNeuralFx: A Python Package for Neural Audio Effect Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We present PyNeuralFx, an open-source Python toolkit designed for research on neural audio effect modeling. The toolkit provides an intuitive framework and offers a comprehensive suite of features, including standardized implementation of well-established model architectures, loss functions, and easy-to-use visualization tools. As such, it helps promote reproducibility for research on neural audio effect modeling, and enable in-depth performance comparison of different models, offering insight into the behavior and operational characteristics of models through DSP methodology. The toolkit can be found at https://github.com/ytsrt66589/pyneuralfx.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "toolkit paper"
    },
    {
        "paper id": "2408.06054",
        "abstract url": "https://arxiv.org/abs/2408.06054",
        "title": "Parallel transport on matrix manifolds and Exponential Action",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We express parallel transport for several common matrix Lie groups with a family of pseudo-Riemannian metrics in terms of matrix exponential and exponential actions. The expression for parallel transport is preserved by taking the quotient under certain scenarios. In particular, for a Stiefel manifold of orthogonal matrices of size $n\\times d$, we give an expression for parallel transport along a geodesic from time zero to $t$, that could be computed with time complexity of $O(nd^2)$ for small $t$, and of $O(td^3)$ for large t, contributing a step in a long-standing open problem in matrix manifolds. A similar result holds for flag manifolds with the canonical metric. We also show the parallel transport formulas for the generalized linear group, and the special orthogonal group under these metrics.",
        "subjects": [
            "math.NA",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06062",
        "abstract url": "https://arxiv.org/abs/2408.06062",
        "title": "On Tables with Numbers, with Numbers",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper is a critical reflection on the epistemic culture of contemporary computational linguistics, framed in the context of its growing obsession with tables with numbers. We argue against tables with numbers on the basis of their epistemic irrelevance, their environmental impact, their role in enabling and exacerbating social inequalities, and their deep ties to commercial applications and profit-driven research. We substantiate our arguments with empirical evidence drawn from a meta-analysis of computational linguistics research over the last decade.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "v2: corrected Figure 2 scale and caption (thanks go to Ernest Davis)"
    },
    {
        "paper id": "2408.06065",
        "abstract url": "https://arxiv.org/abs/2408.06065",
        "title": "An Investigation Into Explainable Audio Hate Speech Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Research on hate speech has predominantly revolved around detection and interpretation from textual inputs, leaving verbal content largely unexplored. While there has been limited exploration into hate speech detection within verbal acoustic speech inputs, the aspect of interpretability has been overlooked. Therefore, we introduce a new task of explainable audio hate speech detection. Specifically, we aim to identify the precise time intervals, referred to as audio frame-level rationales, which serve as evidence for hate speech classification. Towards this end, we propose two different approaches: cascading and End-to-End (E2E). The cascading approach initially converts audio to transcripts, identifies hate speech within these transcripts, and subsequently locates the corresponding audio time frames. Conversely, the E2E approach processes audio utterances directly, which allows it to pinpoint hate speech within specific time frames. Additionally, due to the lack of explainable audio hate speech datasets that include audio frame-level rationales, we curated a synthetic audio dataset to train our models. We further validated these models on actual human speech utterances and found that the E2E approach outperforms the cascading method in terms of the audio frame Intersection over Union (IoU) metric. Furthermore, we observed that including frame-level rationales significantly enhances hate speech detection accuracy for the E2E approach. \\textbf{Disclaimer} The reader may encounter content of an offensive or hateful nature. However, given the nature of the work, this cannot be avoided.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted to SIGDIAL 2024"
    },
    {
        "paper id": "2408.06120",
        "abstract url": "https://arxiv.org/abs/2408.06120",
        "title": "How ChatGPT Changed the Media's Narratives on AI: A Semi-Automated Narrative Analysis Through Frame Semantics",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "The recent explosion of attention to AI is arguably one of the biggest in the technology's media coverage. To investigate the effects it has on the discourse, we perform a mixed-method frame semantics-based analysis on a dataset of more than 49,000 sentences collected from 5846 news articles that mention AI. The dataset covers the twelve-month period centred around the launch of OpenAI's chatbot ChatGPT and is collected from the most visited open-access English-language news publishers. Our findings indicate that during the half year succeeding the launch, media attention rose tenfold$\\unicode{x2014}$from already historically high levels. During this period, discourse has become increasingly centred around experts and political leaders, and AI has become more closely associated with dangers and risks. A deeper review of the data also suggests a qualitative shift in the types of threat AI is thought to represent, as well as the anthropomorphic qualities ascribed to it.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": "18 pages, 6 figures and 2 appendices (5 pages)"
    },
    {
        "paper id": "2408.06124",
        "abstract url": "https://arxiv.org/abs/2408.06124",
        "title": "Utilize Transformers for translating Wikipedia category names",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "On Wikipedia, articles are categorized to aid readers in navigating content efficiently. The manual creation of new categories can be laborious and time-intensive. To tackle this issue, we built language models to translate Wikipedia categories from English to Vietnamese with a dataset containing 15,000 English-Vietnamese category pairs. Subsequently, small to medium-scale Transformer pre-trained models with a sequence-to-sequence architecture were fine-tuned for category translation. The experiments revealed that OPUS-MT-en-vi surpassed other models, attaining the highest performance with a BLEU score of 0.73, despite its smaller model storage. We expect our paper to be an alternative solution for translation tasks with limited computer resources.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2408.06150",
        "abstract url": "https://arxiv.org/abs/2408.06150",
        "title": "LipidBERT: A Lipid Language Model Pre-trained on METiS de novo Lipid Library",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this study, we generate and maintain a database of 10 million virtual lipids through METiS's in-house de novo lipid generation algorithms and lipid virtual screening techniques. These virtual lipids serve as a corpus for pre-training, lipid representation learning, and downstream task knowledge transfer, culminating in state-of-the-art LNP property prediction performance. We propose LipidBERT, a BERT-like model pre-trained with the Masked Language Model (MLM) and various secondary tasks. Additionally, we compare the performance of embeddings generated by LipidBERT and PhatGPT, our GPT-like lipid generation model, on downstream tasks. The proposed bilingual LipidBERT model operates in two languages: the language of ionizable lipid pre-training, using in-house dry-lab lipid structures, and the language of LNP fine-tuning, utilizing in-house LNP wet-lab data. This dual capability positions LipidBERT as a key AI-based filter for future screening tasks, including new versions of METiS de novo lipid libraries and, more importantly, candidates for in vivo testing for orgran-targeting LNPs. To the best of our knowledge, this is the first successful demonstration of the capability of a pre-trained language model on virtual lipids and its effectiveness in downstream tasks using web-lab data. This work showcases the clever utilization of METiS's in-house de novo lipid library as well as the power of dry-wet lab integration.",
        "subjects": [
            "cs.CL",
            "physics.chem-ph",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06186",
        "abstract url": "https://arxiv.org/abs/2408.06186",
        "title": "Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The capability to generate diverse text is a key challenge facing large language models (LLMs). Thus far, diversity has been studied via metrics such as $n$-gram diversity or diversity of BERT embeddings. However, for these kinds of diversity, the user has little control over the dimensions along which diversity is considered. For example, in the poetry domain, one might desire diversity in terms of rhyme and meter, whereas in the code domain, one might desire diversity in terms of the kinds of expressions used to solve a problem. We propose a diversity metric called structural diversity, where the user provides a mapping from generated text to features capturing the kinds of diversity that they care about. In addition, we propose a novel strategy called chain-of-specification (CoS) prompting for improving diversity by first having the LLM generate a specification encoding one instance of structural features, and then prompting the LLM to generate text that satisfies these features; notably, our strategy works with blackbox LLMs. In our experiments, we show that for structural diversity in the poetry and code domains, CoS significantly improves diversity compared to several baselines.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06264",
        "abstract url": "https://arxiv.org/abs/2408.06264",
        "title": "Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Neural network models for audio tasks, such as automatic speech recognition (ASR) and acoustic scene classification (ASC), are susceptible to noise contamination for real-life applications. To improve audio quality, an enhancement module, which can be developed independently, is explicitly used at the front-end of the target audio applications. In this paper, we present an end-to-end learning solution to jointly optimise the models for audio enhancement (AE) and the subsequent applications. To guide the optimisation of the AE module towards a target application, and especially to overcome difficult samples, we make use of the sample-wise performance measure as an indication of sample importance. In experiments, we consider four representative applications to evaluate our training paradigm, i.e., ASR, speech command recognition (SCR), speech emotion recognition (SER), and ASC. These applications are associated with speech and non-speech tasks concerning semantic and non-semantic features, transient and global information, and the experimental results indicate that our proposed approach can considerably boost the noise robustness of the models, especially at low signal-to-noise ratios (SNRs), for a wide range of computer audition tasks in everyday-life noisy environments.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06266",
        "abstract url": "https://arxiv.org/abs/2408.06266",
        "title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are often aligned using contrastive alignment objectives and preference pair datasets. The interaction between model, paired data, and objective makes alignment a complicated procedure, sometimes producing subpar results. We study this and find that (i) preference data gives a better learning signal when the underlying responses are contrastive, and (ii) alignment objectives lead to better performance when they specify more control over the model during training. Based on these insights, we introduce Contrastive Learning from AI Revisions (CLAIR), a data-creation method which leads to more contrastive preference pairs, and Anchored Preference Optimization (APO), a controllable and more stable alignment objective. We align Llama-3-8B-Instruct using various comparable datasets and alignment objectives and measure MixEval-Hard scores, which correlate highly with human judgments. The CLAIR preferences lead to the strongest performance out of all datasets, and APO consistently outperforms less controllable objectives. Our best model, trained on 32K CLAIR preferences with APO, improves Llama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code is available at https://github.com/ContextualAI/CLAIR_and_APO.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06273",
        "abstract url": "https://arxiv.org/abs/2408.06273",
        "title": "FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated prowess in a wide range of tasks. However, many LLMs exhibit significant performance discrepancies between high- and low-resource languages. To mitigate this challenge, we present FuxiTranyu, an open-source multilingual LLM, which is designed to satisfy the need of the research community for balanced and high-performing multilingual capabilities. FuxiTranyu-8B, the base model with 8 billion parameters, is trained from scratch on a meticulously balanced multilingual data repository that contains 600 billion tokens covering 43 natural languages and 16 programming languages. In addition to the base model, we also develop two instruction-tuned models: FuxiTranyu-8B-SFT that is fine-tuned on a diverse multilingual instruction dataset, and FuxiTranyu-8B-DPO that is further refined with DPO on a preference dataset for enhanced alignment ability. Extensive experiments on a wide range of multilingual benchmarks demonstrate the competitive performance of FuxiTranyu against existing multilingual LLMs, e.g., BLOOM-7B, PolyLM-13B, Llama-2-Chat-7B and Mistral-7B-Instruct. Interpretability analyses at both the neuron and representation level suggest that FuxiTranyu is able to learn consistent multilingual representations across different languages. To promote further research into multilingual LLMs and their working mechanisms, we release both the base and instruction-tuned FuxiTranyu models together with 58 pretraining checkpoints at HuggingFace and Github.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06281",
        "abstract url": "https://arxiv.org/abs/2408.06281",
        "title": "MovieSum: An Abstractive Summarization Dataset for Movie Screenplays",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Movie screenplay summarization is challenging, as it requires an understanding of long input contexts and various elements unique to movies. Large language models have shown significant advancements in document summarization, but they often struggle with processing long input contexts. Furthermore, while television transcripts have received attention in recent studies, movie screenplay summarization remains underexplored. To stimulate research in this area, we present a new dataset, MovieSum, for abstractive summarization of movie screenplays. This dataset comprises 2200 movie screenplays accompanied by their Wikipedia plot summaries. We manually formatted the movie screenplays to represent their structural elements. Compared to existing datasets, MovieSum possesses several distinctive features: (1) It includes movie screenplays, which are longer than scripts of TV episodes. (2) It is twice the size of previous movie screenplay datasets. (3) It provides metadata with IMDb IDs to facilitate access to additional external knowledge. We also show the results of recently released large language models applied to summarization on our dataset to provide a detailed baseline.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "ACL 2024 Findings"
    },
    {
        "paper id": "2408.06305",
        "abstract url": "https://arxiv.org/abs/2408.06305",
        "title": "From SAM to SAM 2: Exploring Improvements in Meta's Segment Anything Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Segment Anything Model (SAM), introduced to the computer vision community by Meta in April 2023, is a groundbreaking tool that allows automated segmentation of objects in images based on prompts such as text, clicks, or bounding boxes. SAM excels in zero-shot performance, segmenting unseen objects without additional training, stimulated by a large dataset of over one billion image masks. SAM 2 expands this functionality to video, leveraging memory from preceding and subsequent frames to generate accurate segmentation across entire videos, enabling near real-time performance. This comparison shows how SAM has evolved to meet the growing need for precise and efficient segmentation in various applications. The study suggests that future advancements in models like SAM will be crucial for improving computer vision technology.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06332",
        "abstract url": "https://arxiv.org/abs/2408.06332",
        "title": "Animate, or Inanimate, That is the Question for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The cognitive essence of humans is deeply intertwined with the concept of animacy, which plays an essential role in shaping their memory, vision, and multi-layered language understanding. Although animacy appears in language via nuanced constraints on verbs and adjectives, it is also learned and refined through extralinguistic information. Similarly, we assume that the LLMs' limited abilities to understand natural language when processing animacy are motivated by the fact that these models are trained exclusively on text. Hence, the question this paper aims to answer arises: can LLMs, in their digital wisdom, process animacy in a similar way to what humans would do? We then propose a systematic analysis via prompting approaches. In particular, we probe different LLMs by prompting them using animate, inanimate, usual, and stranger contexts. Results reveal that, although LLMs have been trained predominantly on textual data, they exhibit human-like behavior when faced with typical animate and inanimate entities in alignment with earlier studies. Hence, LLMs can adapt to understand unconventional situations by recognizing oddities as animated without needing to interface with unspoken cognitive triggers humans rely on to break down animations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06333",
        "abstract url": "https://arxiv.org/abs/2408.06333",
        "title": "FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Open Domain Question Answering (ODQA) has been advancing rapidly in recent times, driven by significant developments in dense passage retrieval and pretrained language models. Current models typically incorporate the FiD framework, which is composed by a neural retriever alongside an encoder-decoder neural reader. In the answer generation process, the retriever will retrieve numerous passages (around 100 for instance), each of which is then individually encoded by the encoder. Subsequently, the decoder makes predictions based on these encoded passages. Nevertheless, this framework can be relatively time-consuming, particularly due to the extensive length of the gathered passages. To address this, we introduce FastFiD in this paper, a novel approach that executes sentence selection on the encoded passages. This aids in retaining valuable sentences while reducing the context length required for generating answers. Experiments on three commonly used datasets (Natural Questions, TriviaQA and ASQA) demonstrate that our method can enhance the inference speed by 2.3X-5.7X, while simultaneously maintaining the model's performance. Moreover, an in-depth analysis of the model's attention reveals that the selected sentences indeed hold a substantial contribution towards the final answer. The codes are publicly available at https://github.com/thunlp/FastFiD.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "ACL 2024 Main Conference"
    },
    {
        "paper id": "2408.06335",
        "abstract url": "https://arxiv.org/abs/2408.06335",
        "title": "LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper explores humor detection through a linguistic lens, prioritizing syntactic, semantic, and contextual features over computational methods in Natural Language Processing. We categorize features into syntactic, semantic, and contextual dimensions, including lexicons, structural statistics, Word2Vec, WordNet, and phonetic style. Our proposed model, Colbert, utilizes BERT embeddings and parallel hidden layers to capture sentence congruity. By combining syntactic, semantic, and contextual features, we train Colbert for humor detection. Feature engineering examines essential syntactic and semantic features alongside BERT embeddings. SHAP interpretations and decision trees identify influential features, revealing that a holistic approach improves humor detection accuracy on unseen data. Integrating linguistic cues from different dimensions enhances the model's ability to understand humor complexity beyond traditional computational methods.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06450",
        "abstract url": "https://arxiv.org/abs/2408.06450",
        "title": "Evaluating Language Models for Efficient Code Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce Differential Performance Evaluation (DPE), a framework designed to reliably evaluate Large Language Models (LLMs) for efficient code generation. Traditional coding benchmarks often fail to provide reliable insights into code efficiency, due to their reliance on simplistic test inputs and the absence of effective compound metrics. DPE addresses these issues by focusing on efficiency-demanding programming tasks and establishing an insightful compound metric for performance evaluation. DPE operates in two phases: To curate efficiency datasets, it selects efficiency-demanding tasks from existing coding benchmarks and generates computationally expensive inputs to stress the efficiency of LLM solutions. To assess the code efficiency, DPE profiles the new solution and compares it globally against a set of reference solutions that exhibit distinct efficiency levels, where the matched level defines its efficiency score. As a proof of concept, we use DPE to create EvalPerf, a benchmark with 121 performance-challenging coding tasks. Our comprehensive evaluation draws interesting findings on the efficiency impact of model sizes, instruction tuning, and prompting. For example, while the scaling law fails to account for code efficiency, general instruction tuning benefits both code correctness and efficiency. We also evaluate the evaluation by examining the effectiveness of DPE, showing that EvalPerf is reliable and convenient to use even across platforms.",
        "subjects": [
            "cs.SE",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06458",
        "abstract url": "https://arxiv.org/abs/2408.06458",
        "title": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We propose a novel in-context learning algorithm for building autonomous decision-making language agents. The language agent continuously attempts to solve the same task by self-correcting each time the task fails. Our selected language agent demonstrates the ability to solve tasks in a text-based game environment. Our results show that the gemma-2-9b-it language model, using our proposed method, can successfully complete two of six tasks that failed in the first attempt. This highlights the effectiveness of our approach in enhancing the problem-solving capabilities of a single language model through self-correction, paving the way for more advanced autonomous agents. The code is publicly available at https://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06474",
        "abstract url": "https://arxiv.org/abs/2408.06474",
        "title": "TOGGL: Transcribing Overlapping Speech with Staggered Labeling",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Transcribing the speech of multiple overlapping speakers typically requires separating the audio into multiple streams and recognizing each one independently. More recent work jointly separates and transcribes, but requires a separate decoding component for each speaker. We propose the TOGGL model to simultaneously transcribe the speech of multiple speakers. The TOGGL model uses special output tokens to attribute the speech to each speaker with only a single decoder. Our approach generalizes beyond two speakers, even when trained only on two-speaker data. We demonstrate superior performance compared to competing approaches on a conversational speech dataset. Our approach also improves performance on single-speaker audio.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2408.06484",
        "abstract url": "https://arxiv.org/abs/2408.06484",
        "title": "Cross-Lingual Conversational Speech Summarization with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Cross-lingual conversational speech summarization is an important problem, but suffers from a dearth of resources. While transcriptions exist for a number of languages, translated conversational speech is rare and datasets containing summaries are non-existent. We build upon the existing Fisher and Callhome Spanish-English Speech Translation corpus by supplementing the translations with summaries. The summaries are generated using GPT-4 from the reference translations and are treated as ground truth. The task is to generate similar summaries in the presence of transcription and translation errors. We build a baseline cascade-based system using open-source speech recognition and machine translation models. We test a range of LLMs for summarization and analyze the impact of transcription and translation errors. Adapting the Mistral-7B model for this task performs significantly better than off-the-shelf models and matches the performance of GPT-4.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06494",
        "abstract url": "https://arxiv.org/abs/2408.06494",
        "title": "What Color Scheme is More Effective in Assisting Readers to Locate Information in a Color-Coded Article?",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Color coding, a technique assigning specific colors to cluster information types, has proven advantages in aiding human cognitive activities, especially reading and comprehension. The rise of Large Language Models (LLMs) has streamlined document coding, enabling simple automatic text labeling with various schemes. This has the potential to make color-coding more accessible and benefit more users. However, the impact of color choice on information seeking is understudied. We conducted a user study assessing various color schemes' effectiveness in LLM-coded text documents, standardizing contrast ratios to approximately 5.55:1 across schemes. Participants performed timed information-seeking tasks in color-coded scholarly abstracts. Results showed non-analogous and yellow-inclusive color schemes improved performance, with the latter also being more preferred by participants. These findings can inform better color scheme choices for text annotation. As LLMs advance document coding, we advocate for more research focusing on the \"color\" aspect of color-coding techniques.",
        "subjects": [
            "cs.HC",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06502",
        "abstract url": "https://arxiv.org/abs/2408.06502",
        "title": "Prompt Recovery for Image Generation Models: A Comparative Study of Discrete Optimizers",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recovering natural language prompts for image generation models, solely based on the generated images is a difficult discrete optimization problem. In this work, we present the first head-to-head comparison of recent discrete optimization techniques for the problem of prompt inversion. We evaluate Greedy Coordinate Gradients (GCG), PEZ , Random Search, AutoDAN and BLIP2's image captioner across various evaluation metrics related to the quality of inverted prompts and the quality of the images generated by the inverted prompts. We find that focusing on the CLIP similarity between the inverted prompts and the ground truth image acts as a poor proxy for the similarity between ground truth image and the image generated by the inverted prompts. While the discrete optimizers effectively minimize their objectives, simply using responses from a well-trained captioner often leads to generated images that more closely resemble those produced by the original prompts.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "9 Pages, 4 Figures"
    },
    {
        "paper id": "2408.06527",
        "abstract url": "https://arxiv.org/abs/2408.06527",
        "title": "Chain-of-Strategy Planning with LLMs: Aligning the Generation of Psychotherapy Dialogue with Strategy in Motivational Interviewing",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) have shown promise in generating psychotherapeutic dialogues, especially in Motivational Interviewing (MI). However, how to employ strategies, a set of motivational interviewing (MI) skills, to generate therapeutic-adherent conversations with explainability is underexplored. We propose an approach called strategy-aware dialogue generation with Chain-of-Strategy (CoS) planning, which first predicts MI strategies as reasoning and utilizes these strategies to guide the subsequent dialogue generation. It brings the potential for controllable and explainable generation in psychotherapy by aligning the generated MI dialogues with therapeutic strategies. Extensive experiments including automatic and human evaluations are conducted to validate the effectiveness of the MI strategy. Our findings demonstrate the potential of LLMs in producing strategically aligned dialogues and suggest directions for practical applications in psychotherapeutic settings.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06537",
        "abstract url": "https://arxiv.org/abs/2408.06537",
        "title": "Introducing the NewsPaLM MBR and QE Dataset: LLM-Generated High-Quality Parallel Data Outperforms Traditional Web-Crawled Data",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent research in neural machine translation (NMT) has shown that training on high-quality machine-generated data can outperform training on human-generated data. This work accompanies the first-ever release of a LLM-generated, MBR-decoded and QE-reranked dataset with both sentence-level and multi-sentence examples. We perform extensive experiments to demonstrate the quality of our dataset in terms of its downstream impact on NMT model performance. We find that training from scratch on our (machine-generated) dataset outperforms training on the (web-crawled) WMT'23 training dataset (which is 300 times larger), and also outperforms training on the top-quality subset of the WMT'23 training dataset. We also find that performing self-distillation by finetuning the LLM which generated this dataset outperforms the LLM's strong few-shot baseline. These findings corroborate the quality of our dataset, and demonstrate the value of high-quality machine-generated data in improving performance of NMT models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06574",
        "abstract url": "https://arxiv.org/abs/2408.06574",
        "title": "SparkRA: A Retrieval-Augmented Knowledge Service System Based on Spark Large Language Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown remarkable achievements across various language tasks.To enhance the performance of LLMs in scientific literature services, we developed the scientific literature LLM (SciLit-LLM) through pre-training and supervised fine-tuning on scientific literature, building upon the iFLYTEK Spark LLM. Furthermore, we present a knowledge service system Spark Research Assistant (SparkRA) based on our SciLit-LLM. SparkRA is accessible online and provides three primary functions: literature investigation, paper reading, and academic writing. As of July 30, 2024, SparkRA has garnered over 50,000 registered users, with a total usage count exceeding 1.3 million.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06578",
        "abstract url": "https://arxiv.org/abs/2408.06578",
        "title": "OpenEP: Open-Ended Future Event Prediction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Future event prediction (FEP) is a long-standing and crucial task in the world, as understanding the evolution of events enables early risk identification, informed decision-making, and strategic planning. Existing work typically treats event prediction as classification tasks and confines the outcomes of future events to a fixed scope, such as yes/no questions, candidate set, and taxonomy, which is difficult to include all possible outcomes of future events. In this paper, we introduce OpenEP (an Open-Ended Future Event Prediction task), which generates flexible and diverse predictions aligned with real-world scenarios. This is mainly reflected in two aspects: firstly, the predictive questions are diverse, covering different stages of event development and perspectives; secondly, the outcomes are flexible, without constraints on scope or format. To facilitate the study of this task, we construct OpenEPBench, an open-ended future event prediction dataset. For question construction, we pose questions from seven perspectives, including location, time, event development, event outcome, event impact, event response, and other, to facilitate an in-depth analysis and understanding of the comprehensive evolution of events. For outcome construction, we collect free-form text containing the outcomes as ground truth to provide semantically complete and detail-enriched outcomes. Furthermore, we propose StkFEP, a stakeholder-enhanced future event prediction framework, that incorporates event characteristics for open-ended settings. Our method extracts stakeholders involved in events to extend questions to gather diverse information. We also collect historically events that are relevant and similar to the question to reveal potential evolutionary patterns. Experiment results indicate that accurately predicting future events in open-ended settings is challenging for existing LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06627",
        "abstract url": "https://arxiv.org/abs/2408.06627",
        "title": "WorldScribe: Towards Context-Aware Live Visual Descriptions",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Automated live visual descriptions can aid blind people in understanding their surroundings with autonomy and independence. However, providing descriptions that are rich, contextual, and just-in-time has been a long-standing challenge in accessibility. In this work, we develop WorldScribe, a system that generates automated live real-world visual descriptions that are customizable and adaptive to users' contexts: (i) WorldScribe's descriptions are tailored to users' intents and prioritized based on semantic relevance. (ii) WorldScribe is adaptive to visual contexts, e.g., providing consecutively succinct descriptions for dynamic scenes, while presenting longer and detailed ones for stable settings. (iii) WorldScribe is adaptive to sound contexts, e.g., increasing volume in noisy environments, or pausing when conversations start. Powered by a suite of vision, language, and sound recognition models, WorldScribe introduces a description generation pipeline that balances the tradeoffs between their richness and latency to support real-time use. The design of WorldScribe is informed by prior work on providing visual descriptions and a formative study with blind participants. Our user study and subsequent pipeline evaluation show that WorldScribe can provide real-time and fairly accurate visual descriptions to facilitate environment understanding that is adaptive and customized to users' contexts. Finally, we discuss the implications and further steps toward making live visual descriptions more context-aware and humanized.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "UIST 2024"
    },
    {
        "paper id": "2408.06629",
        "abstract url": "https://arxiv.org/abs/2408.06629",
        "title": "Fast Information Streaming Handler (FisH): A Unified Seismic Neural Network for Single Station Real-Time Earthquake Early Warning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing EEW approaches often treat phase picking, location estimation, and magnitude estimation as separate tasks, lacking a unified framework. Additionally, most deep learning models in seismology rely on full three-component waveforms and are not suitable for real-time streaming data. To address these limitations, we propose a novel unified seismic neural network called Fast Information Streaming Handler (FisH). FisH is designed to process real-time streaming seismic data and generate simultaneous results for phase picking, location estimation, and magnitude estimation in an end-to-end fashion. By integrating these tasks within a single model, FisH simplifies the overall process and leverages the nonlinear relationships between tasks for improved performance. The FisH model utilizes RetNet as its backbone, enabling parallel processing during training and recurrent handling during inference. This capability makes FisH suitable for real-time applications, reducing latency in EEW systems. Extensive experiments conducted on the STEAD benchmark dataset provide strong validation for the effectiveness of our proposed FisH model. The results demonstrate that FisH achieves impressive performance across multiple seismic event detection and characterization tasks. Specifically, it achieves an F1 score of 0.99/0.96. Also, FisH demonstrates precise earthquake location estimation, with location error of only 6.0km, a distance error of 2.6km, and a back-azimuth error of 19\u00b0. The model also exhibits accurate earthquake magnitude estimation, with a magnitude error of just 0.14. Additionally, FisH is capable of generating real-time estimations, providing location and magnitude estimations with a location error of 8.06km and a magnitude error of 0.18 within a mere 3 seconds after the P-wave arrives.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06634",
        "abstract url": "https://arxiv.org/abs/2408.06634",
        "title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates 'base factors', such as financial metric growth and earnings transcripts, with 'external factors', including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted F1, and Matthews correlation coefficient (MCC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a 'Hold' option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI-driven financial analysis tools.",
        "subjects": [
            "q-fin.CP",
            "cs.CL",
            "cs.LG",
            "q-fin.ST"
        ],
        "comment": "Accepted by 2024 6th International Conference on Data-driven Optimization of Complex Systems"
    },
    {
        "paper id": "2408.07277",
        "abstract url": "https://arxiv.org/abs/2408.07277",
        "title": "Speech vs. Transcript: Does It Matter for Human Annotators in Speech Summarization?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Reference summaries for abstractive speech summarization require human annotation, which can be performed by listening to an audio recording or by reading textual transcripts of the recording. In this paper, we examine whether summaries based on annotators listening to the recordings differ from those based on annotators reading transcripts. Using existing intrinsic evaluation based on human evaluation, automatic metrics, LLM-based evaluation, and a retrieval-based reference-free method. We find that summaries are indeed different based on the source modality, and that speech-based summaries are more factually consistent and information-selective than transcript-based summaries. Meanwhile, transcript-based summaries are impacted by recognition errors in the source, and expert-written summaries are more informative and reliable. We make all the collected data and analysis code public(https://github.com/cmu-mlsp/interview_humanssum) to facilitate the reproduction of our work and advance research in this area.",
        "subjects": [
            "cs.CL",
            "cs.HC",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted to ACL 2024 Main Conference"
    },
    {
        "paper id": "2408.05924",
        "abstract url": "https://arxiv.org/abs/2408.05924",
        "title": "Adapting a Foundation Model for Space-based Tasks",
        "rating": "0.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "robotics",
                "robot",
                "navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Foundation models, e.g., large language models, possess attributes of intelligence which offer promise to endow a robot with the contextual understanding necessary to navigate complex, unstructured tasks in the wild. In the future of space robotics, we see three core challenges which motivate the use of a foundation model adapted to space-based applications: 1) Scalability of ground-in-the-loop operations; 2) Generalizing prior knowledge to novel environments; and 3) Multi-modality in tasks and sensor data. Therefore, as a first-step towards building a foundation model for space-based applications, we automatically label the AI4Mars dataset to curate a language annotated dataset of visual-question-answer tuples. We fine-tune a pretrained LLaVA checkpoint on this dataset to endow a vision-language model with the ability to perform spatial reasoning and navigation on Mars' surface. In this work, we demonstrate that 1) existing vision-language models are deficient visual reasoners in space-based applications, and 2) fine-tuning a vision-language model on extraterrestrial data significantly improves the quality of responses even with a limited training dataset of only a few thousand samples.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05927",
        "abstract url": "https://arxiv.org/abs/2408.05927",
        "title": "A Simple Early Exiting Framework for Accelerated Sampling in Diffusion Models",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Diffusion models have shown remarkable performance in generation problems over various domains including images, videos, text, and audio. A practical bottleneck of diffusion models is their sampling speed, due to the repeated evaluation of score estimation networks during the inference. In this work, we propose a novel framework capable of adaptively allocating compute required for the score estimation, thereby reducing the overall sampling time of diffusion models. We observe that the amount of computation required for the score estimation may vary along the time step for which the score is estimated. Based on this observation, we propose an early-exiting scheme, where we skip the subset of parameters in the score estimation network during the inference, based on a time-dependent exit schedule. Using the diffusion models for image synthesis, we show that our method could significantly improve the sampling throughput of the diffusion models without compromising image quality. Furthermore, we also demonstrate that our method seamlessly integrates with various types of solvers for faster sampling, capitalizing on their compatibility to enhance overall efficiency. The source code and our experiments are available at \\url{https://github.com/taehong-moon/ee-diffusion}",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2408.05959",
        "abstract url": "https://arxiv.org/abs/2408.05959",
        "title": "Markov Senior -- Learning Markov Junior Grammars to Generate User-specified Content",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Markov Junior is a probabilistic programming language used for procedural content generation across various domains. However, its reliance on manually crafted and tuned probabilistic rule sets, also called grammars, presents a significant bottleneck, diverging from approaches that allow rule learning from examples. In this paper, we propose a novel solution to this challenge by introducing a genetic programming-based optimization framework for learning hierarchical rule sets automatically. Our proposed method ``Markov Senior'' focuses on extracting positional and distance relations from single input samples to construct probabilistic rules to be used by Markov Junior. Using a Kullback-Leibler divergence-based fitness measure, we search for grammars to generate content that is coherent with the given sample. To enhance scalability, we introduce a divide-and-conquer strategy that enables the efficient generation of large-scale content. We validate our approach through experiments in generating image-based content and Super Mario levels, demonstrating its flexibility and effectiveness. In this way, ``Markov Senior'' allows for the wider application of Markov Junior for tasks in which an example may be available, but the design of a generative rule set is infeasible.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "8 pages, to be published in the Proceedings of the IEEE Conference on Games 2024, demo implementation can be found here: https://github.com/ADockhorn/MarkovSenior"
    },
    {
        "paper id": "2408.05960",
        "abstract url": "https://arxiv.org/abs/2408.05960",
        "title": "Match Point AI: A Novel AI Framework for Evaluating Data-Driven Tennis Strategies",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Many works in the domain of artificial intelligence in games focus on board or video games due to the ease of reimplementing their mechanics. Decision-making problems in real-world sports share many similarities to such domains. Nevertheless, not many frameworks on sports games exist. In this paper, we present the tennis match simulation environment \\textit{Match Point AI}, in which different agents can compete against real-world data-driven bot strategies. Next to presenting the framework, we highlight its capabilities by illustrating, how MCTS can be used in Match Point AI to optimize the shot direction selection problem in tennis. While the framework will be extended in the future, first experiments already reveal that generated shot-by-shot data of simulated tennis matches show realistic characteristics when compared to real-world data. At the same time, reasonable shot placement strategies emerge, which share similarities to the ones found in real-world tennis matches.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "4 pages, 1 page abstract, short paper, to be published in Proceedings of the IEEE Conference on Games 2024"
    },
    {
        "paper id": "2408.05990",
        "abstract url": "https://arxiv.org/abs/2408.05990",
        "title": "Parameters Inference for Nonlinear Wave Equations with Markovian Switching",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional partial differential equations with constant coefficients often struggle to capture abrupt changes in real-world phenomena, leading to the development of variable coefficient PDEs and Markovian switching models. Recently, research has introduced the concept of PDEs with Markov switching models, established their well-posedness and presented numerical methods. However, there has been limited discussion on parameter estimation for the jump coefficients in these models. This paper addresses this gap by focusing on parameter inference for the wave equation with Markovian switching. We propose a Bayesian statistical framework using discrete sparse Bayesian learning to establish its convergence and a uniform error bound. Our method requires fewer assumptions and enables independent parameter inference for each segment by allowing different underlying structures for the parameter estimation problem within each segmented time interval. The effectiveness of our approach is demonstrated through three numerical cases, which involve noisy spatiotemporal data from different wave equations with Markovian switching. The results show strong performance in parameter estimation for variable coefficient PDEs.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06003",
        "abstract url": "https://arxiv.org/abs/2408.06003",
        "title": "LUT Tensor Core: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As large language model (LLM) inference demands ever-greater resources, there is a rapid growing trend of using low-bit weights to shrink memory usage and boost inference efficiency. However, these low-bit LLMs introduce the need for mixed-precision matrix multiplication (mpGEMM), which is a crucial yet under-explored operation that involves multiplying lower-precision weights with higher-precision activations. Unfortunately, current hardware does not natively support mpGEMM, resulting in indirect and inefficient dequantization-based implementations. To address the mpGEMM requirements in low-bit LLMs, we explored the lookup table (LUT)-based approach for mpGEMM. However, a conventional LUT implementation falls short of its potential. To fully harness the power of LUT-based mpGEMM, we introduce LUT Tensor Core, a software-hardware co-design optimized for low-bit LLM inference. Specifically, we introduce software-based operator fusion and table symmetrization techniques to optimize table precompute and table storage, respectively. Then, LUT Tensor Core proposes the hardware design featuring an elongated tiling shape design to enhance table reuse and a bit-serial design to support various precision combinations in mpGEMM. Moreover, we design an end-to-end compilation stack with new instructions for LUT-based mpGEMM, enabling efficient LLM compilation and optimizations. The evaluation on low-bit LLMs (e.g., BitNet, LLAMA) shows that LUT Tensor Core achieves more than a magnitude of improvements on both compute density and energy efficiency.",
        "subjects": [
            "cs.AR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06051",
        "abstract url": "https://arxiv.org/abs/2408.06051",
        "title": "Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Defining and measuring decision-making styles, also known as playstyles, is crucial in gaming, where these styles reflect a broad spectrum of individuality and diversity. However, finding a universally applicable measure for these styles poses a challenge. Building on Playstyle Distance, the first unsupervised metric to measure playstyle similarity based on game screens and raw actions, we introduce three enhancements to increase accuracy: multiscale analysis with varied state granularity, a perceptual kernel rooted in psychology, and the utilization of the intersection-over-union method for efficient evaluation. These innovations not only advance measurement precision but also offer insights into human cognition of similarity. Across two racing games and seven Atari games, our techniques significantly improve the precision of zero-shot playstyle classification, achieving an accuracy exceeding 90 percent with fewer than 512 observation-action pairs, which is less than half an episode of these games. Furthermore, our experiments with 2048 and Go demonstrate the potential of discrete playstyle measures in puzzle and board games. We also develop an algorithm for assessing decision-making diversity using these measures. Our findings improve the measurement of end-to-end game analysis and the evolution of artificial intelligence for diverse playstyles.",
        "subjects": [
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "TMLR 08/2024 https://openreview.net/forum?id=30C9AWBW49"
    },
    {
        "paper id": "2408.06068",
        "abstract url": "https://arxiv.org/abs/2408.06068",
        "title": "Online Optimization of Curriculum Learning Schedules using Evolutionary Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We propose RHEA CL, which combines Curriculum Learning (CL) with Rolling Horizon Evolutionary Algorithms (RHEA) to automatically produce effective curricula during the training of a reinforcement learning agent. RHEA CL optimizes a population of curricula, using an evolutionary algorithm, and selects the best-performing curriculum as the starting point for the next training epoch. Performance evaluations are conducted after every curriculum step in all environments. We evaluate the algorithm on the \\textit{DoorKey} and \\textit{DynamicObstacles} environments within the Minigrid framework. It demonstrates adaptability and consistent improvement, particularly in the early stages, while reaching a stable performance later that is capable of outperforming other curriculum learners. In comparison to other curriculum schedules, RHEA CL has been shown to yield performance improvements for the final Reinforcement learning (RL) agent at the cost of additional evaluation during training.",
        "subjects": [
            "cs.AI",
            "cs.NE"
        ],
        "comment": "8 pages including abstract, to be published in the Proceedings of the IEEE Conference on Games 2024"
    },
    {
        "paper id": "2408.06069",
        "abstract url": "https://arxiv.org/abs/2408.06069",
        "title": "Fully Bayesian Differential Gaussian Processes through Stochastic Differential Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Traditional deep Gaussian processes model the data evolution using a discrete hierarchy, whereas differential Gaussian processes (DIFFGPs) represent the evolution as an infinitely deep Gaussian process. However, prior DIFFGP methods often overlook the uncertainty of kernel hyperparameters and assume them to be fixed and time-invariant, failing to leverage the unique synergy between continuous-time models and approximate inference. In this work, we propose a fully Bayesian approach that treats the kernel hyperparameters as random variables and constructs coupled stochastic differential equations (SDEs) to learn their posterior distribution and that of inducing points. By incorporating estimation uncertainty on hyperparameters, our method enhances the model's flexibility and adaptability to complex dynamics. Additionally, our approach provides a time-varying, comprehensive, and realistic posterior approximation through coupling variables using SDE methods. Experimental results demonstrate the advantages of our method over traditional approaches, showcasing its superior performance in terms of flexibility, accuracy, and other metrics. Our work opens up exciting research avenues for advancing Bayesian inference and offers a powerful modeling tool for continuous-time Gaussian processes.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06099",
        "abstract url": "https://arxiv.org/abs/2408.06099",
        "title": "Approximating Discrimination Within Models When Faced With Several Non-Binary Sensitive Attributes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Discrimination mitigation with machine learning (ML) models could be complicated because multiple factors may interweave with each other including hierarchically and historically. Yet few existing fairness measures are able to capture the discrimination level within ML models in the face of multiple sensitive attributes. To bridge this gap, we propose a fairness measure based on distances between sets from a manifold perspective, named as 'harmonic fairness measure via manifolds (HFM)' with two optional versions, which can deal with a fine-grained discrimination evaluation for several sensitive attributes of multiple values. To accelerate the computation of distances of sets, we further propose two approximation algorithms named 'Approximation of distance between sets for one sensitive attribute with multiple values (ApproxDist)' and 'Approximation of extended distance between sets for several sensitive attributes with multiple values (ExtendDist)' to respectively resolve bias evaluation of one single sensitive attribute with multiple values and that of several sensitive attributes with multiple values. Moreover, we provide an algorithmic effectiveness analysis for ApproxDist under certain assumptions to explain how well it could work. The empirical results demonstrate that our proposed fairness measure HFM is valid and approximation algorithms (i.e., ApproxDist and ExtendDist) are effective and efficient.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": "The first two authors contributed equally, listed in alphabetical order. arXiv admin note: substantial text overlap with arXiv:2405.09251"
    },
    {
        "paper id": "2408.06102",
        "abstract url": "https://arxiv.org/abs/2408.06102",
        "title": "Contexts Matter: An Empirical Study on Contextual Influence in Fairness Testing for Deep Learning Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Background: Fairness testing for deep learning systems has been becoming increasingly important. However, much work assumes perfect context and conditions from the other parts: well-tuned hyperparameters for accuracy; rectified bias in data, and mitigated bias in the labeling. Yet, these are often difficult to achieve in practice due to their resource-/labour-intensive nature. Aims: In this paper, we aim to understand how varying contexts affect fairness testing outcomes. Method:We conduct an extensive empirical study, which covers $10,800$ cases, to investigate how contexts can change the fairness testing result at the model level against the existing assumptions. We also study why the outcomes were observed from the lens of correlation/fitness landscape analysis. Results: Our results show that different context types and settings generally lead to a significant impact on the testing, which is mainly caused by the shifts of the fitness landscape under varying contexts. Conclusions: Our findings provide key insights for practitioners to evaluate the test generators and hint at future research directions.",
        "subjects": [
            "cs.SE",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "Received by ESEM 24"
    },
    {
        "paper id": "2408.06110",
        "abstract url": "https://arxiv.org/abs/2408.06110",
        "title": "RISurConv: Rotation Invariant Surface Attention-Augmented Convolutions for 3D Point Cloud Classification and Segmentation",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Despite the progress on 3D point cloud deep learning, most prior works focus on learning features that are invariant to translation and point permutation, and very limited efforts have been devoted for rotation invariant property. Several recent studies achieve rotation invariance at the cost of lower accuracies. In this work, we close this gap by proposing a novel yet effective rotation invariant architecture for 3D point cloud classification and segmentation. Instead of traditional pointwise operations, we construct local triangle surfaces to capture more detailed surface structure, based on which we can extract highly expressive rotation invariant surface properties which are then integrated into an attention-augmented convolution operator named RISurConv to generate refined attention features via self-attention layers. Based on RISurConv we build an effective neural network for 3D point cloud analysis that is invariant to arbitrary rotations while maintaining high accuracy. We verify the performance on various benchmarks with supreme results obtained surpassing the previous state-of-the-art by a large margin. We achieve an overall accuracy of 96.0% (+4.7%) on ModelNet40, 93.1% (+12.8%) on ScanObjectNN, and class accuracies of 91.5% (+3.6%), 82.7% (+5.1%), and 78.5% (+9.2%) on the three categories of the FG3D dataset for the fine-grained classification task. Additionally, we achieve 81.5% (+1.0%) mIoU on ShapeNet for the segmentation task. Code is available here: https://github.com/cszyzhang/RISurConv",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024 (oral)"
    },
    {
        "paper id": "2408.06199",
        "abstract url": "https://arxiv.org/abs/2408.06199",
        "title": "Dynamic Blocked Clause Elimination for Projected Model Counting",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we explore the application of blocked clause elimination for projected model counting. This is the problem of determining the number of models ||\\exists X.\u03a3|| of a propositional formula \u03a3 after eliminating a given set X of variables existentially. Although blocked clause elimination is a well-known technique for SAT solving, its direct application to model counting is challenging as in general it changes the number of models. However, we demonstrate, by focusing on projected variables during the blocked clause search, that blocked clause elimination can be leveraged while preserving the correct model count. To take advantage of blocked clause elimination in an efficient way during model counting, a novel data structure and associated algorithms are introduced. Our proposed approach is implemented in the model counter d4. Our experiments demonstrate the computational benefits of our new method of blocked clause elimination for projected model counting.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "LIPIcs, Volume 305, SAT 2024"
    },
    {
        "paper id": "2408.06202",
        "abstract url": "https://arxiv.org/abs/2408.06202",
        "title": "Strategy Game-Playing with Size-Constrained State Abstraction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Playing strategy games is a challenging problem for artificial intelligence (AI). One of the major challenges is the large search space due to a diverse set of game components. In recent works, state abstraction has been applied to search-based game AI and has brought significant performance improvements. State abstraction techniques rely on reducing the search space, e.g., by aggregating similar states. However, the application of these abstractions is hindered because the quality of an abstraction is difficult to evaluate. Previous works hence abandon the abstraction in the middle of the search to not bias the search to a local optimum. This mechanism introduces a hyper-parameter to decide the time to abandon the current state abstraction. In this work, we propose a size-constrained state abstraction (SCSA), an approach that limits the maximum number of nodes being grouped together. We found that with SCSA, the abstraction is not required to be abandoned. Our empirical results on $3$ strategy games show that the SCSA agent outperforms the previous methods and yields robust performance over different games. Codes are open-sourced at \\url{https://github.com/GAIGResearch/Stratega}.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "8 pages, to be published in Proceedings of the Conference on Games 2024, codes are open-sourced at https://github.com/GAIGResearch/Stratega"
    },
    {
        "paper id": "2408.06210",
        "abstract url": "https://arxiv.org/abs/2408.06210",
        "title": "Certified Safe: A Schematic for Approval Regulation of Frontier AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Recent and unremitting capability advances have been accompanied by calls for comprehensive, rather than patchwork, regulation of frontier artificial intelligence (AI). Approval regulation is emerging as a promising candidate. An approval regulation scheme is one in which a firm cannot legally market, or in some cases develop, a product without explicit approval from a regulator on the basis of experiments performed upon the product that demonstrate its safety. This approach is used successfully by the FDA and FAA. Further, its application to frontier AI has been publicly supported by many prominent stakeholders. This report proposes an approval regulation schematic for only the largest AI projects in which scrutiny begins before training and continues through to post-deployment monitoring. The centerpieces of the schematic are two major approval gates, the first requiring approval for large-scale training and the second for deployment. Five main challenges make implementation difficult: noncompliance through unsanctioned deployment, specification of deployment readiness requirements, reliable model experimentation, filtering out safe models before the process, and minimizing regulatory overhead. This report makes a number of crucial recommendations to increase the feasibility of approval regulation, some of which must be followed urgently if such a regime is to succeed in the near future. Further recommendations, produced by this report's analysis, may improve the effectiveness of any regulatory regime for frontier AI.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06212",
        "abstract url": "https://arxiv.org/abs/2408.06212",
        "title": "Computability of Classification and Deep Learning: From Theoretical Limits to Practical Feasibility through Quantization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The unwavering success of deep learning in the past decade led to the increasing prevalence of deep learning methods in various application fields. However, the downsides of deep learning, most prominently its lack of trustworthiness, may not be compatible with safety-critical or high-responsibility applications requiring stricter performance guarantees. Recently, several instances of deep learning applications have been shown to be subject to theoretical limitations of computability, undermining the feasibility of performance guarantees when employed on real-world computers. We extend the findings by studying computability in the deep learning framework from two perspectives: From an application viewpoint in the context of classification problems and a general limitation viewpoint in the context of training neural networks. In particular, we show restrictions on the algorithmic solvability of classification problems that also render the algorithmic detection of failure in computations in a general setting infeasible. Subsequently, we prove algorithmic limitations in training deep neural networks even in cases where the underlying problem is well-behaved. Finally, we end with a positive observation, showing that in quantized versions of classification and deep network training, computability restrictions do not arise or can be overcome to a certain degree.",
        "subjects": [
            "cs.LG",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06226",
        "abstract url": "https://arxiv.org/abs/2408.06226",
        "title": "A Large-Scale Study of Model Integration in ML-Enabled Software Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The rise of machine learning (ML) and its embedding in systems has drastically changed the engineering of software-intensive systems. Traditionally, software engineering focuses on manually created artifacts such as source code and the process of creating them, as well as best practices for integrating them, i.e., software architectures. In contrast, the development of ML artifacts, i.e. ML models, comes from data science and focuses on the ML models and their training data. However, to deliver value to end users, these ML models must be embedded in traditional software, often forming complex topologies. In fact, ML-enabled software can easily incorporate many different ML models. While the challenges and practices of building ML-enabled systems have been studied to some extent, beyond isolated examples, little is known about the characteristics of real-world ML-enabled systems. Properly embedding ML models in systems so that they can be easily maintained or reused is far from trivial. We need to improve our empirical understanding of such systems, which we address by presenting the first large-scale study of real ML-enabled software systems, covering over 2,928 open source systems on GitHub. We classified and analyzed them to determine their characteristics, as well as their practices for reusing ML models and related code, and the architecture of these systems. Our findings provide practitioners and researchers with insight into practices for embedding and integrating ML models, bringing data science and software engineering closer together.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06229",
        "abstract url": "https://arxiv.org/abs/2408.06229",
        "title": "A Comprehensive Case Study on the Performance of Machine Learning Methods on the Classification of Solar Panel Electroluminescence Images",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Photovoltaics (PV) are widely used to harvest solar energy, an important form of renewable energy. Photovoltaic arrays consist of multiple solar panels constructed from solar cells. Solar cells in the field are vulnerable to various defects, and electroluminescence (EL) imaging provides effective and non-destructive diagnostics to detect those defects. We use multiple traditional machine learning and modern deep learning models to classify EL solar cell images into different functional/defective categories. Because of the asymmetry in the number of functional vs. defective cells, an imbalanced label problem arises in the EL image data. The current literature lacks insights on which methods and metrics to use for model training and prediction. In this paper, we comprehensively compare different machine learning and deep learning methods under different performance metrics on the classification of solar cell EL images from monocrystalline and polycrystalline modules. We provide a comprehensive discussion on different metrics. Our results provide insights and guidelines for practitioners in selecting prediction methods and performance metrics.",
        "subjects": [
            "stat.AP",
            "cs.LG"
        ],
        "comment": "30 pages, 14 figures"
    },
    {
        "paper id": "2408.06257",
        "abstract url": "https://arxiv.org/abs/2408.06257",
        "title": "Reciprocal Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We demonstrate that a wide array of machine learning algorithms are specific instances of one single paradigm: reciprocal learning. These instances range from active learning over multi-armed bandits to self-training. We show that all these algorithms do not only learn parameters from data but also vice versa: They iteratively alter training data in a way that depends on the current model fit. We introduce reciprocal learning as a generalization of these algorithms using the language of decision theory. This allows us to study under what conditions they converge. The key is to guarantee that reciprocal learning contracts such that the Banach fixed-point theorem applies. In this way, we find that reciprocal learning algorithms converge at linear rates to an approximately optimal model under relatively mild assumptions on the loss function, if their predictions are probabilistic and the sample adaption is both non-greedy and either randomized or regularized. We interpret these findings and provide corollaries that relate them to specific active learning, self-training, and bandit algorithms.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "41 pages, 3 figures"
    },
    {
        "paper id": "2408.06258",
        "abstract url": "https://arxiv.org/abs/2408.06258",
        "title": "Deep Learning System Boundary Testing through Latent Space Style Mixing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Evaluating the behavioral frontier of deep learning (DL) systems is crucial for understanding their generalizability and robustness. However, boundary testing is challenging due to their high-dimensional input space. Generative artificial intelligence offers a promising solution by modeling data distribution within compact latent space representations, thereby facilitating finer-grained explorations. In this work, we introduce MIMICRY, a novel black-box system-agnostic test generator that leverages these latent representations to generate frontier inputs for the DL systems under test. Specifically, MIMICRY uses style-based generative adversarial networks trained to learn the representation of inputs with disentangled features. This representation enables embedding style-mixing operations between a source and a target input, combining their features to explore the boundary between them. We evaluated the effectiveness of different MIMICRY configurations in generating boundary inputs for four popular DL image classification systems. Our results show that manipulating the latent space allows for effective and efficient exploration of behavioral frontiers. As opposed to a model-based baseline, MIMICRY generates a higher quality frontier of behaviors which includes more and closer inputs. Additionally, we assessed the validity of these inputs, revealing a high validity rate according to human assessors.",
        "subjects": [
            "cs.SE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06297",
        "abstract url": "https://arxiv.org/abs/2408.06297",
        "title": "LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study a robust online convex optimization framework, where an adversary can introduce outliers by corrupting loss functions in an arbitrary number of rounds k, unknown to the learner. Our focus is on a novel setting allowing unbounded domains and large gradients for the losses without relying on a Lipschitz assumption. We introduce the Log Exponential Adjusted Robust and iNvex (LEARN) loss, a non-convex (invex) robust loss function to mitigate the effects of outliers and develop a robust variant of the online gradient descent algorithm by leveraging the LEARN loss. We establish tight regret guarantees (up to constants), in a dynamic setting, with respect to the uncorrupted rounds and conduct experiments to validate our theory. Furthermore, we present a unified analysis framework for developing online optimization algorithms for non-convex (invex) losses, utilizing it to provide regret bounds with respect to the LEARN loss, which may be of independent interest.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06318",
        "abstract url": "https://arxiv.org/abs/2408.06318",
        "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs) have brought autonomous agents closer to artificial general intelligence (AGI) due to their promising generalization and emergent capabilities. There is, however, a lack of studies on how LLM-based agents behave, why they could potentially fail, and how to improve them, particularly in demanding real-world planning tasks. In this paper, as an effort to fill the gap, we present our study using a realistic benchmark, TravelPlanner, where an agent must meet multiple constraints to generate accurate plans. We leverage this benchmark to address four key research questions: (1) are LLM agents robust enough to lengthy and noisy contexts when it comes to reasoning and planning? (2) can few-shot prompting adversely impact the performance of LLM agents in scenarios with long context? (3) can we rely on refinement to improve plans, and (4) can fine-tuning LLMs with both positive and negative feedback lead to further improvement? Our comprehensive experiments indicate that, firstly, LLMs often fail to attend to crucial parts of a long context, despite their ability to handle extensive reference information and few-shot examples; secondly, they still struggle with analyzing the long plans and cannot provide accurate feedback for refinement; thirdly, we propose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and negative feedback, resulting in substantial gains over Supervised Fine-Tuning (SFT). Our findings offer in-depth insights to the community on various aspects related to real-world planning applications.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "13 pages, 2 figures, 4 tables"
    },
    {
        "paper id": "2408.06401",
        "abstract url": "https://arxiv.org/abs/2408.06401",
        "title": "High-dimensional optimization for multi-spiked tensor PCA",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the dynamics of two local optimization algorithms, online stochastic gradient descent (SGD) and gradient flow, within the framework of the multi-spiked tensor model in the high-dimensional regime. This multi-index model arises from the tensor principal component analysis (PCA) problem, which aims to infer $r$ unknown, orthogonal signal vectors within the $N$-dimensional unit sphere through maximum likelihood estimation from noisy observations of an order-$p$ tensor. We determine the number of samples and the conditions on the signal-to-noise ratios (SNRs) required to efficiently recover the unknown spikes from natural initializations. Specifically, we distinguish between three types of recovery: exact recovery of each spike, recovery of a permutation of all spikes, and recovery of the correct subspace spanned by the signal vectors. We show that with online SGD, it is possible to recover all spikes provided a number of sample scaling as $N^{p-2}$, aligning with the computational threshold identified in the rank-one tensor PCA problem [Ben Arous, Gheissari, Jagannath 2020, 2021]. For gradient flow, we show that the algorithmic threshold to efficiently recover the first spike is also of order $N^{p-2}$. However, recovering the subsequent directions requires the number of samples to scale as $N^{p-1}$. Our results are obtained through a detailed analysis of a low-dimensional system that describes the evolution of the correlations between the estimators and the spikes. In particular, the hidden vectors are recovered one by one according to a sequential elimination phenomenon: as one correlation exceeds a critical threshold, all correlations sharing a row or column index decrease and become negligible, allowing the subsequent correlation to grow and become macroscopic. The sequence in which correlations become macroscopic depends on their initial values and on the associated SNRs.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06421",
        "abstract url": "https://arxiv.org/abs/2408.06421",
        "title": "Neural Networks as Spin Models: From Glass to Hidden Order Through Training",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We explore a one-to-one correspondence between a neural network (NN) and a statistical mechanical spin model where neurons are mapped to Ising spins and weights to spin-spin couplings. The process of training an NN produces a family of spin Hamiltonians parameterized by training time. We study the magnetic phases and the melting transition temperature as training progresses. First, we prove analytically that the common initial state before training--an NN with independent random weights--maps to a layered version of the classical Sherrington-Kirkpatrick spin glass exhibiting a replica symmetry breaking. The spin-glass-to-paramagnet transition temperature is calculated. Further, we use the Thouless-Anderson-Palmer (TAP) equations--a theoretical technique to analyze the landscape of energy minima of random systems--to determine the evolution of the magnetic phases on two types of NNs (one with continuous and one with binarized activations) trained on the MNIST dataset. The two NN types give rise to similar results, showing a quick destruction of the spin glass and the appearance of a phase with a hidden order, whose melting transition temperature $T_c$ grows as a power law in training time. We also discuss the properties of the spectrum of the spin system's bond matrix in the context of rich vs. lazy learning. We suggest that this statistical mechanical view of NNs provides a useful unifying perspective on the training process, which can be viewed as selecting and strengthening a symmetry-broken state associated with the training task.",
        "subjects": [
            "cond-mat.dis-nn",
            "cs.LG",
            "nlin.AO"
        ],
        "comment": "18 pages, 9 figures"
    },
    {
        "paper id": "2408.06425",
        "abstract url": "https://arxiv.org/abs/2408.06425",
        "title": "Bayesian Learning in a Nonlinear Multiscale State-Space Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The ubiquity of multiscale interactions in complex systems is well-recognized, with development and heredity serving as a prime example of how processes at different temporal scales influence one another. This work introduces a novel multiscale state-space model to explore the dynamic interplay between systems interacting across different time scales, with feedback between each scale. We propose a Bayesian learning framework to estimate unknown states by learning the unknown process noise covariances within this multiscale model. We develop a Particle Gibbs with Ancestor Sampling (PGAS) algorithm for inference and demonstrate through simulations the efficacy of our approach.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Corrected a typo"
    },
    {
        "paper id": "2408.06431",
        "abstract url": "https://arxiv.org/abs/2408.06431",
        "title": "Addressing the Unforeseen Harms of Technology CCC Whitepaper",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Recent years have seen increased awareness of the potential significant impacts of computing technologies, both positive and negative. This whitepaper explores how to address possible harmful consequences of computing technologies that might be difficult to anticipate, and thereby mitigate or address. It starts from the assumption that very few harms due to technology are intentional or deliberate; rather, the vast majority result from failure to recognize and respond to them prior to deployment. Nonetheless, there are concrete steps that can be taken to address the difficult problem of anticipating and responding to potential harms from new technologies.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06452",
        "abstract url": "https://arxiv.org/abs/2408.06452",
        "title": "Wireless Channel Aware Data Augmentation Methods for Deep Leaning-Based Indoor Localization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Indoor localization is a challenging problem that - unlike outdoor localization - lacks a universal and robust solution. Machine Learning (ML), particularly Deep Learning (DL), methods have been investigated as a promising approach. Although such methods bring remarkable localization accuracy, they heavily depend on the training data collected from the environment. The data collection is usually a laborious and time-consuming task, but Data Augmentation (DA) can be used to alleviate this issue. In this paper, different from previously used DA, we propose methods that utilize the domain knowledge about wireless propagation channels and devices. The methods exploit the typical hardware component drift in the transceivers and/or the statistical behavior of the channel, in combination with the measured Power Delay Profile (PDP). We comprehensively evaluate the proposed methods to demonstrate their effectiveness. This investigation mainly focuses on the impact of factors such as the number of measurements, augmentation proportion, and the environment of interest impact the effectiveness of the different DA methods. We show that in the low-data regime (few actual measurements available), localization accuracy increases up to 50%, matching non-augmented results in the high-data regime. In addition, the proposed methods may outperform the measurement-only high-data performance by up to 33% using only 1/4 of the amount of measured data. We also exhibit the effect of different training data distribution and quality on the effectiveness of DA. Finally, we demonstrate the power of the proposed methods when employed along with Transfer Learning (TL) to address the data scarcity in target and/or source environments.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": "13 pages, 14 figures"
    },
    {
        "paper id": "2408.06512",
        "abstract url": "https://arxiv.org/abs/2408.06512",
        "title": "Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We present the Learned Ranking Function (LRF), a system that takes short-term user-item behavior predictions as input and outputs a slate of recommendations that directly optimizes for long-term user satisfaction. Most previous work is based on optimizing the hyperparameters of a heuristic function. We propose to model the problem directly as a slate optimization problem with the objective of maximizing long-term user satisfaction. We also develop a novel constraint optimization algorithm that stabilizes objective trade-offs for multi-objective optimization. We evaluate our approach with live experiments and describe its deployment on YouTube.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "RecSys 24"
    },
    {
        "paper id": "2408.06525",
        "abstract url": "https://arxiv.org/abs/2408.06525",
        "title": "The NP-hardness of the Gromov-Wasserstein distance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This note addresses the property frequently mentioned in the literature that the Gromov-Wasserstein (GW) distance is NP-hard. We provide the details on the non-convex nature of the GW optimization problem that imply NP-hardness of the GW distance between finite spaces for any instance of an input data. We further illustrate the non-convexity of the problem with several explicit examples.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06526",
        "abstract url": "https://arxiv.org/abs/2408.06526",
        "title": "Operator Learning Using Random Features: A Tool for Scientific Computing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Supervised operator learning centers on the use of training data, in the form of input-output pairs, to estimate maps between infinite-dimensional spaces. It is emerging as a powerful tool to complement traditional scientific computing, which may often be framed in terms of operators mapping between spaces of functions. Building on the classical random features methodology for scalar regression, this paper introduces the function-valued random features method. This leads to a supervised operator learning architecture that is practical for nonlinear problems yet is structured enough to facilitate efficient training through the optimization of a convex, quadratic cost. Due to the quadratic structure, the trained model is equipped with convergence guarantees and error and complexity bounds, properties that are not readily available for most other operator learning architectures. At its core, the proposed approach builds a linear combination of random operators. This turns out to be a low-rank approximation of an operator-valued kernel ridge regression algorithm, and hence the method also has strong connections to Gaussian process regression. The paper designs function-valued random features that are tailored to the structure of two nonlinear operator learning benchmark problems arising from parametric partial differential equations. Numerical results demonstrate the scalability, discretization invariance, and transferability of the function-valued random features method.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "stat.ML"
        ],
        "comment": "36 pages, 1 table, 9 figures. SIGEST version of SIAM J. Sci. Comput. Vol. 43 No. 5 (2021) pp. A3212-A3243, hence text overlap with arXiv:2005.10224"
    },
    {
        "paper id": "2408.06540",
        "abstract url": "https://arxiv.org/abs/2408.06540",
        "title": "Dynamic Exclusion of Low-Fidelity Data in Bayesian Optimization for Autonomous Beamline Alignment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Aligning beamlines at synchrotron light sources is a high-dimensional, expensive-to-sample optimization problem, as beams are focused using a series of dynamic optical components. Bayesian Optimization is an efficient machine learning approach to finding global optima of beam quality, but the model can easily be impaired by faulty data points caused by the beam going off the edge of the sensor or by background noise. This study, conducted at the National Synchrotron Light Source II (NSLS-II) facility at Brookhaven National Laboratory (BNL), is an investigation of methods to identify untrustworthy readings of beam quality and discourage the optimization model from seeking out points likely to yield low-fidelity beams. The approaches explored include dynamic pruning using loss analysis of size and position models and a lengthscale-based genetic algorithm to determine which points to include in the model for optimal fit. Each method successfully classified high and low fidelity points. This research advances BNL's mission to tackle our nation's energy challenges by providing scientists at all beamlines with access to higher quality beams, and faster convergence to these optima for their experiments.",
        "subjects": [
            "physics.acc-ph",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "12 pages, 6 figure sets"
    },
    {
        "paper id": "2408.06542",
        "abstract url": "https://arxiv.org/abs/2408.06542",
        "title": "Value of Information and Reward Specification in Active Inference and POMDPs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Expected free energy (EFE) is a central quantity in active inference which has recently gained popularity due to its intuitive decomposition of the expected value of control into a pragmatic and an epistemic component. While numerous conjectures have been made to justify EFE as a decision making objective function, the most widely accepted is still its intuitiveness and resemblance to variational free energy in approximate Bayesian inference. In this work, we take a bottom up approach and ask: taking EFE as given, what's the resulting agent's optimality gap compared with a reward-driven reinforcement learning (RL) agent, which is well understood? By casting EFE under a particular class of belief MDP and using analysis tools from RL theory, we show that EFE approximates the Bayes optimal RL policy via information value. We discuss the implications for objective specification of active inference agents.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06544",
        "abstract url": "https://arxiv.org/abs/2408.06544",
        "title": "Variance-Reduced Cascade Q-learning: Algorithms and Sample Complexity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the problem of estimating the optimal Q-function of $\u03b3$-discounted Markov decision processes (MDPs) under the synchronous setting, where independent samples for all state-action pairs are drawn from a generative model at each iteration. We introduce and analyze a novel model-free algorithm called Variance-Reduced Cascade Q-learning (VRCQ). VRCQ comprises two key building blocks: (i) the established direct variance reduction technique and (ii) our proposed variance reduction scheme, Cascade Q-learning. By leveraging these techniques, VRCQ provides superior guarantees in the $\\ell_\\infty$-norm compared with the existing model-free stochastic approximation-type algorithms. Specifically, we demonstrate that VRCQ is minimax optimal. Additionally, when the action set is a singleton (so that the Q-learning problem reduces to policy evaluation), it achieves non-asymptotic instance optimality while requiring the minimum number of samples theoretically possible. Our theoretical results and their practical implications are supported by numerical experiments.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.07098",
        "abstract url": "https://arxiv.org/abs/2408.07098",
        "title": "QTypeMix: Enhancing Multi-Agent Cooperative Strategies through Heterogeneous and Homogeneous Value Decomposition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In multi-agent cooperative tasks, the presence of heterogeneous agents is familiar. Compared to cooperation among homogeneous agents, collaboration requires considering the best-suited sub-tasks for each agent. However, the operation of multi-agent systems often involves a large amount of complex interaction information, making it more challenging to learn heterogeneous strategies. Related multi-agent reinforcement learning methods sometimes use grouping mechanisms to form smaller cooperative groups or leverage prior domain knowledge to learn strategies for different roles. In contrast, agents should learn deeper role features without relying on additional information. Therefore, we propose QTypeMix, which divides the value decomposition process into homogeneous and heterogeneous stages. QTypeMix learns to extract type features from local historical observations through the TE loss. In addition, we introduce advanced network structures containing attention mechanisms and hypernets to enhance the representation capability and achieve the value decomposition process. The results of testing the proposed method on 14 maps from SMAC and SMACv2 show that QTypeMix achieves state-of-the-art performance in tasks of varying difficulty.",
        "subjects": [
            "cs.MA",
            "cs.AI"
        ],
        "comment": "16 pages, 8 figures"
    },
    {
        "paper id": "2408.05928",
        "abstract url": "https://arxiv.org/abs/2408.05928",
        "title": "Adapting General Disentanglement-Based Speaker Anonymization for Enhanced Emotion Preservation",
        "rating": "0",
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "A general disentanglement-based speaker anonymization system typically separates speech into content, speaker, and prosody features using individual encoders. This paper explores how to adapt such a system when a new speech attribute, for example, emotion, needs to be preserved to a greater extent. While existing systems are good at anonymizing speaker embeddings, they are not designed to preserve emotion. Two strategies for this are examined. First, we show that integrating emotion embeddings from a pre-trained emotion encoder can help preserve emotional cues, even though this approach slightly compromises privacy protection. Alternatively, we propose an emotion compensation strategy as a post-processing step applied to anonymized speaker embeddings. This conceals the original speaker's identity and reintroduces the emotional traits lost during speaker embedding anonymization. Specifically, we model the emotion attribute using support vector machines to learn separate boundaries for each emotion. During inference, the original speaker embedding is processed in two ways: one, by an emotion indicator to predict emotion and select the emotion-matched SVM accurately; and two, by a speaker anonymizer to conceal speaker characteristics. The anonymized speaker embedding is then modified along the corresponding SVM boundary towards an enhanced emotional direction to save the emotional cues. The proposed strategies are also expected to be useful for adapting a general disentanglement-based speaker anonymization system to preserve other target paralinguistic attributes, with potential for a range of downstream tasks.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05940",
        "abstract url": "https://arxiv.org/abs/2408.05940",
        "title": "Spb3DTracker: A Robust LiDAR-Based Person Tracker for Noisy Environment",
        "rating": "0",
        "keywords": [
            [
                "LiDAR",
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Person detection and tracking (PDT) has seen significant advancements with 2D camera-based systems in the autonomous vehicle field, leading to widespread adoption of these algorithms. However, growing privacy concerns have recently emerged as a major issue, prompting a shift towards LiDAR-based PDT as a viable alternative. Within this domain, \"Tracking-by-Detection\" (TBD) has become a prominent methodology. Despite its effectiveness, LiDAR-based PDT has not yet achieved the same level of performance as camera-based PDT. This paper examines key components of the LiDAR-based PDT framework, including detection post-processing, data association, motion modeling, and lifecycle management. Building upon these insights, we introduce SpbTrack, a robust person tracker designed for diverse environments. Our method achieves superior performance on noisy datasets and state-of-the-art results on KITTI Dataset benchmarks and custom office indoor dataset among LiDAR-based trackers.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "17 pages, 5 figures"
    },
    {
        "paper id": "2408.05948",
        "abstract url": "https://arxiv.org/abs/2408.05948",
        "title": "ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid advancement of Large Language Models (LLMs) and conversational assistants necessitates dynamic, scalable, and configurable conversational datasets for training and evaluation. These datasets must accommodate diverse user interaction modes, including text and voice, each presenting unique modeling challenges. Knowledge Graphs (KGs), with their structured and evolving nature, offer an ideal foundation for current and precise knowledge. Although human-curated KG-based conversational datasets exist, they struggle to keep pace with the rapidly changing user information needs. We present ConvKGYarn, a scalable method for generating up-to-date and configurable conversational KGQA datasets. Qualitative psychometric analyses confirm our method can generate high-quality datasets rivaling a popular conversational KGQA dataset while offering it at scale and covering a wide range of human-interaction configurations. We showcase its utility by testing LLMs on diverse conversations - exploring model behavior on conversational KGQA sets with different configurations grounded in the same KG fact set. Our results highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate parametric knowledge of LLMs, thus offering a robust solution to the constantly evolving landscape of conversational assistants.",
        "subjects": [
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06019",
        "abstract url": "https://arxiv.org/abs/2408.06019",
        "title": "HeadGAP: Few-shot 3D Head Avatar via Generalizable Gaussian Priors",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "Avatar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we present a novel 3D head avatar creation approach capable of generalizing from few-shot in-the-wild data with high-fidelity and animatable robustness. Given the underconstrained nature of this problem, incorporating prior knowledge is essential. Therefore, we propose a framework comprising prior learning and avatar creation phases. The prior learning phase leverages 3D head priors derived from a large-scale multi-view dynamic dataset, and the avatar creation phase applies these priors for few-shot personalization. Our approach effectively captures these priors by utilizing a Gaussian Splatting-based auto-decoder network with part-based dynamic modeling. Our method employs identity-shared encoding with personalized latent codes for individual identities to learn the attributes of Gaussian primitives. During the avatar creation phase, we achieve fast head avatar personalization by leveraging inversion and fine-tuning strategies. Extensive experiments demonstrate that our model effectively exploits head priors and successfully generalizes them to few-shot personalization, achieving photo-realistic rendering quality, multi-view consistency, and stable animation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://headgap.github.io/"
    },
    {
        "paper id": "2408.06047",
        "abstract url": "https://arxiv.org/abs/2408.06047",
        "title": "BooW-VTON: Boosting In-the-Wild Virtual Try-On via Mask-Free Pseudo Data Training",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image-based virtual try-on is an increasingly popular and important task to generate realistic try-on images of specific person. Existing methods always employ an accurate mask to remove the original garment in the source image, thus achieving realistic synthesized images in simple and conventional try-on scenarios based on powerful diffusion model. Therefore, acquiring suitable mask is vital to the try-on performance of these methods. However, obtaining precise inpainting masks, especially for complex wild try-on data containing diverse foreground occlusions and person poses, is not easy as Figure 1-Top shows. This difficulty often results in poor performance in more practical and challenging real-life scenarios, such as the selfie scene shown in Figure 1-Bottom. To this end, we propose a novel training paradigm combined with an efficient data augmentation method to acquire large-scale unpaired training data from wild scenarios, thereby significantly facilitating the try-on performance of our model without the need for additional inpainting masks. Besides, a try-on localization loss is designed to localize a more accurate try-on area to obtain more reasonable try-on results. It is noted that our method only needs the reference cloth image, source pose image and source person image as input, which is more cost-effective and user-friendly compared to existing methods. Extensive qualitative and quantitative experiments have demonstrated superior performance in wild scenarios with such a low-demand input.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06070",
        "abstract url": "https://arxiv.org/abs/2408.06070",
        "title": "ControlNeXt: Powerful and Efficient Control for Image and Video Generation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have demonstrated remarkable and robust abilities in both image and video generation. To achieve greater control over generated results, researchers introduce additional architectures, such as ControlNet, Adapters and ReferenceNet, to integrate conditioning controls. However, current controllable generation methods often require substantial additional computational resources, especially for video generation, and face challenges in training or exhibit weak control. In this paper, we propose ControlNeXt: a powerful and efficient method for controllable image and video generation. We first design a more straightforward and efficient architecture, replacing heavy additional branches with minimal additional cost compared to the base model. Such a concise structure also allows our method to seamlessly integrate with other LoRA weights, enabling style alteration without the need for additional training. As for training, we reduce up to 90% of learnable parameters compared to the alternatives. Furthermore, we propose another method called Cross Normalization (CN) as a replacement for Zero-Convolution' to achieve fast and stable training convergence. We have conducted various experiments with different base models across images and videos, demonstrating the robustness of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "controllable generation"
    },
    {
        "paper id": "2408.06071",
        "abstract url": "https://arxiv.org/abs/2408.06071",
        "title": "A-BDD: Leveraging Data Augmentations for Safe Autonomous Driving in Adverse Weather and Lighting",
        "rating": "0",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "High-autonomy vehicle functions rely on machine learning (ML) algorithms to understand the environment. Despite displaying remarkable performance in fair weather scenarios, perception algorithms are heavily affected by adverse weather and lighting conditions. To overcome these difficulties, ML engineers mainly rely on comprehensive real-world datasets. However, the difficulties in real-world data collection for critical areas of the operational design domain (ODD) often means synthetic data is required for perception training and safety validation. Thus, we present A-BDD, a large set of over 60,000 synthetically augmented images based on BDD100K that are equipped with semantic segmentation and bounding box annotations (inherited from the BDD100K dataset). The dataset contains augmented data for rain, fog, overcast and sunglare/shadow with varying intensity levels. We further introduce novel strategies utilizing feature-based image quality metrics like FID and CMMD, which help identify useful augmented and real-world data for ML training and testing. By conducting experiments on A-BDD, we provide evidence that data augmentations can play a pivotal role in closing performance gaps in adverse weather and lighting conditions.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06079",
        "abstract url": "https://arxiv.org/abs/2408.06079",
        "title": "Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the significant advances that deep neural networks (DNNs) have achieved in various visual tasks, they still exhibit vulnerability to adversarial examples, leading to serious security concerns. Recent adversarial training techniques have utilized inverse adversarial attacks to generate high-confidence examples, aiming to align the distributions of adversarial examples with the high-confidence regions of their corresponding classes. However, in this paper, our investigation reveals that high-confidence outputs under inverse adversarial attacks are correlated with biased feature activation. Specifically, training with inverse adversarial examples causes the model's attention to shift towards background features, introducing a spurious correlation bias. To address this bias, we propose Debiased High-Confidence Adversarial Training (DHAT), a novel approach that not only aligns the logits of adversarial examples with debiased high-confidence logits obtained from inverse adversarial examples, but also restores the model's attention to its normal state by enhancing foreground logit orthogonality. Extensive experiments demonstrate that DHAT achieves state-of-the-art performance and exhibits robust generalization capabilities across various vision datasets. Additionally, DHAT can seamlessly integrate with existing advanced adversarial training techniques for improving the performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06083",
        "abstract url": "https://arxiv.org/abs/2408.06083",
        "title": "Towards Robust Monocular Depth Estimation in Non-Lambertian Surfaces",
        "rating": "0",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the field of monocular depth estimation (MDE), many models with excellent zero-shot performance in general scenes emerge recently. However, these methods often fail in predicting non-Lambertian surfaces, such as transparent or mirror (ToM) surfaces, due to the unique reflective properties of these regions. Previous methods utilize externally provided ToM masks and aim to obtain correct depth maps through direct in-painting of RGB images. These methods highly depend on the accuracy of additional input masks, and the use of random colors during in-painting makes them insufficiently robust. We are committed to incrementally enabling the baseline model to directly learn the uniqueness of non-Lambertian surface regions for depth estimation through a well-designed training framework. Therefore, we propose non-Lambertian surface regional guidance, which constrains the predictions of MDE model from the gradient domain to enhance its robustness. Noting the significant impact of lighting on this task, we employ the random tone-mapping augmentation during training to ensure the network can predict correct results for varying lighting inputs. Additionally, we propose an optional novel lighting fusion module, which uses Variational Autoencoders to fuse multiple images and obtain the most advantageous input RGB image for depth estimation when multi-exposure images are available. Our method achieves accuracy improvements of 33.39% and 5.21% in zero-shot testing on the Booster and Mirror3D dataset for non-Lambertian surfaces, respectively, compared to the Depth Anything V2. The state-of-the-art performance of 90.75 in delta1.05 within the ToM regions on the TRICKY2024 competition test set demonstrates the effectiveness of our approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06087",
        "abstract url": "https://arxiv.org/abs/2408.06087",
        "title": "Building Decision Making Models Through Language Model Regime",
        "rating": "0",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We propose a novel approach for decision making problems leveraging the generalization capabilities of large language models (LLMs). Traditional methods such as expert systems, planning algorithms, and reinforcement learning often exhibit limited generalization, typically requiring the training of new models for each unique task. In contrast, LLMs demonstrate remarkable success in generalizing across varied language tasks, inspiring a new strategy for training decision making models. Our approach, referred to as \"Learning then Using\" (LTU), entails a two-stage process. Initially, the \\textit{learning} phase develops a robust foundational decision making model by integrating diverse knowledge from various domains and decision making contexts. The subsequent \\textit{using} phase refines this foundation model for specific decision making scenarios. Distinct from other studies that employ LLMs for decision making through supervised learning, our LTU method embraces a versatile training methodology that combines broad pre-training with targeted fine-tuning. Experiments in e-commerce domains such as advertising and search optimization have shown that LTU approach outperforms traditional supervised learning regimes in decision making capabilities and generalization. The LTU approach is the first practical training architecture for both single-step and multi-step decision making tasks combined with LLMs, which can be applied beyond game and robot domains. It provides a robust and adaptable framework for decision making, enhances the effectiveness and flexibility of various systems in tackling various challenges.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06123",
        "abstract url": "https://arxiv.org/abs/2408.06123",
        "title": "DPDETR: Decoupled Position Detection Transformer for Infrared-Visible Object Detection",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Infrared-visible object detection aims to achieve robust object detection by leveraging the complementary information of infrared and visible image pairs. However, the commonly existing modality misalignment problem presents two challenges: fusing misalignment complementary features is difficult, and current methods cannot accurately locate objects in both modalities under misalignment conditions. In this paper, we propose a Decoupled Position Detection Transformer (DPDETR) to address these problems. Specifically, we explicitly formulate the object category, visible modality position, and infrared modality position to enable the network to learn the intrinsic relationships and output accurate positions of objects in both modalities. To fuse misaligned object features accurately, we propose a Decoupled Position Multispectral Cross-attention module that adaptively samples and aggregates multispectral complementary features with the constraint of infrared and visible reference positions. Additionally, we design a query-decoupled Multispectral Decoder structure to address the optimization gap among the three kinds of object information in our task and propose a Decoupled Position Contrastive DeNosing Training strategy to enhance the DPDETR's ability to learn decoupled positions. Experiments on DroneVehicle and KAIST datasets demonstrate significant improvements compared to other state-of-the-art methods. The code will be released at https://github.com/gjj45/DPDETR.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06190",
        "abstract url": "https://arxiv.org/abs/2408.06190",
        "title": "FruitNeRF: A Unified Neural Radiance Field based Fruit Counting Framework",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud",
                "radiance fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce FruitNeRF, a unified novel fruit counting framework that leverages state-of-the-art view synthesis methods to count any fruit type directly in 3D. Our framework takes an unordered set of posed images captured by a monocular camera and segments fruit in each image. To make our system independent of the fruit type, we employ a foundation model that generates binary segmentation masks for any fruit. Utilizing both modalities, RGB and semantic, we train a semantic neural radiance field. Through uniform volume sampling of the implicit Fruit Field, we obtain fruit-only point clouds. By applying cascaded clustering on the extracted point cloud, our approach achieves precise fruit count.The use of neural radiance fields provides significant advantages over conventional methods such as object tracking or optical flow, as the counting itself is lifted into 3D. Our method prevents double counting fruit and avoids counting irrelevant fruit.We evaluate our methodology using both real-world and synthetic datasets. The real-world dataset consists of three apple trees with manually counted ground truths, a benchmark apple dataset with one row and ground truth fruit location, while the synthetic dataset comprises various fruit types including apple, plum, lemon, pear, peach, and mango.Additionally, we assess the performance of fruit counting using the foundation model compared to a U-Net.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://meyerls.github.io/fruit_nerf/"
    },
    {
        "paper id": "2408.06195",
        "abstract url": "https://arxiv.org/abs/2408.06195",
        "title": "Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces rStar, a self-play mutual reasoning approach that significantly improves reasoning capabilities of small language models (SLMs) without fine-tuning or superior models. rStar decouples reasoning into a self-play mutual generation-discrimination process. First, a target SLM augments the Monte Carlo Tree Search (MCTS) with a rich set of human-like reasoning actions to construct higher quality reasoning trajectories. Next, another SLM, with capabilities similar to the target SLM, acts as a discriminator to verify each trajectory generated by the target SLM. The mutually agreed reasoning trajectories are considered mutual consistent, thus are more likely to be correct. Extensive experiments across five SLMs demonstrate rStar can effectively solve diverse reasoning problems, including GSM8K, GSM-Hard, MATH, SVAMP, and StrategyQA. Remarkably, rStar boosts GSM8K accuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% for Mistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct. Code will be available at https://github.com/zhentingqi/rStar.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06248",
        "abstract url": "https://arxiv.org/abs/2408.06248",
        "title": "Rethinking Video with a Universal Event-Based Representation",
        "rating": "0",
        "keywords": [
            [
                "event camera"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Traditionally, video is structured as a sequence of discrete image frames. Recently, however, a novel video sensing paradigm has emerged which eschews video frames entirely. These \"event\" sensors aim to mimic the human vision system with asynchronous sensing, where each pixel has an independent, sparse data stream. While these cameras enable high-speed and high-dynamic-range sensing, researchers often revert to a framed representation of the event data for existing applications, or build bespoke applications for a particular camera's event data type. At the same time, classical video systems have significant computational redundancy at the application layer, since pixel samples are repeated across frames in the uncompressed domain. To address the shortcomings of existing systems, I introduce Address, Decimation, \u0394t Event Representation (AD\u0394ER, pronounced \"adder\"), a novel intermediate video representation and system framework. The framework transcodes a variety of framed and event camera sources into a single event-based representation, which supports source-modeled lossy compression and backward compatibility with traditional frame-based applications. I demonstrate that AD\u0394ER achieves state-of-the-art application speed and compression performance for scenes with high temporal redundancy. Crucially, I describe how AD\u0394ER unlocks an entirely new control mechanism for computer vision: application speed can correlate with both the scene content and the level of lossy compression. Finally, I discuss the implications for event-based video on large-scale video surveillance and resource-constrained sensing.",
        "subjects": [
            "cs.MM",
            "cs.CV"
        ],
        "comment": "137 pages. PhD dissertation at the University of North Carolina, Chapel Hill"
    },
    {
        "paper id": "2408.06286",
        "abstract url": "https://arxiv.org/abs/2408.06286",
        "title": "Mipmap-GS: Let Gaussians Deform with Scale-specific Mipmap for Anti-aliasing Rendering",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting (3DGS) has attracted great attention in novel view synthesis because of its superior rendering efficiency and high fidelity. However, the trained Gaussians suffer from severe zooming degradation due to non-adjustable representation derived from single-scale training. Though some methods attempt to tackle this problem via post-processing techniques such as selective rendering or filtering techniques towards primitives, the scale-specific information is not involved in Gaussians. In this paper, we propose a unified optimization method to make Gaussians adaptive for arbitrary scales by self-adjusting the primitive properties (e.g., color, shape and size) and distribution (e.g., position). Inspired by the mipmap technique, we design pseudo ground-truth for the target scale and propose a scale-consistency guidance loss to inject scale information into 3D Gaussians. Our method is a plug-in module, applicable for any 3DGS models to solve the zoom-in and zoom-out aliasing. Extensive experiments demonstrate the effectiveness of our method. Notably, our method outperforms 3DGS in PSNR by an average of 9.25 dB for zoom-in and 10.40 dB for zoom-out on the NeRF Synthetic dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2408.06292",
        "abstract url": "https://arxiv.org/abs/2408.06292",
        "title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "One of the grand challenges of artificial general intelligence is developing agents capable of conducting scientific research and discovering new knowledge. While frontier models have already been used as aides to human scientists, e.g. for brainstorming ideas, writing code, or prediction tasks, they still conduct only a small part of the scientific process. This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than $15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems. Our code is open-sourced at https://github.com/SakanaAI/AI-Scientist",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06321",
        "abstract url": "https://arxiv.org/abs/2408.06321",
        "title": "EqNIO: Subequivariant Neural Inertial Odometry",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Presently, neural networks are widely employed to accurately estimate 2D displacements and associated uncertainties from Inertial Measurement Unit (IMU) data that can be integrated into stochastic filter networks like the Extended Kalman Filter (EKF) as measurements and uncertainties for the update step in the filter. However, such neural approaches overlook symmetry which is a crucial inductive bias for model generalization. This oversight is notable because (i) physical laws adhere to symmetry principles when considering the gravity axis, meaning there exists the same transformation for both the physical entity and the resulting trajectory, and (ii) displacements should remain equivariant to frame transformations when the inertial frame changes. To address this, we propose a subequivariant framework by: (i) deriving fundamental layers such as linear and nonlinear layers for a subequivariant network, designed to handle sequences of vectors and scalars, (ii) employing the subequivariant network to predict an equivariant frame for the sequence of inertial measurements. This predicted frame can then be utilized for extracting invariant features through projection, which are integrated with arbitrary network architectures, (iii) transforming the invariant output by frame transformation to obtain equivariant displacements and covariances. We demonstrate the effectiveness and generalization of our Equivariant Framework on a filter-based approach with TLIO architecture for TLIO and Aria datasets, and an end-to-end deep learning approach with RONIN architecture for RONIN, RIDI and OxIOD datasets.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "26 pages"
    },
    {
        "paper id": "2408.06398",
        "abstract url": "https://arxiv.org/abs/2408.06398",
        "title": "Synthetic Photography Detection: A Visual Guidance for Identifying Synthetic Images Created by AI",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CY",
                "cs.CV"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) tools have become incredibly powerful in generating synthetic images. Of particular concern are generated images that resemble photographs as they aspire to represent real world events. Synthetic photographs may be used maliciously by a broad range of threat actors, from scammers to nation-state actors, to deceive, defraud, and mislead people. Mitigating this threat usually involves answering a basic analytic question: Is the photograph real or synthetic? To address this, we have examined the capabilities of recent generative diffusion models and have focused on their flaws: visible artifacts in generated images which reveal their synthetic origin to the trained eye. We categorize these artifacts, provide examples, discuss the challenges in detecting them, suggest practical applications of our work, and outline future research directions.",
        "subjects": [
            "cs.CY",
            "cs.CV"
        ],
        "comment": "27 pages, 25 figures"
    },
    {
        "paper id": "2408.06468",
        "abstract url": "https://arxiv.org/abs/2408.06468",
        "title": "FoVNet: Configurable Field-of-View Speech Enhancement with Low Computation and Distortion for Smart Glasses",
        "rating": "0",
        "keywords": [
            [
                "Speech Enhancement"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper presents a novel multi-channel speech enhancement approach, FoVNet, that enables highly efficient speech enhancement within a configurable field of view (FoV) of a smart-glasses user without needing specific target-talker(s) directions. It advances over prior works by enhancing all speakers within any given FoV, with a hybrid signal processing and deep learning approach designed with high computational efficiency. The neural network component is designed with ultra-low computation (about 50 MMACS). A multi-channel Wiener filter and a post-processing module are further used to improve perceptual quality. We evaluate our algorithm with a microphone array on smart glasses, providing a configurable, efficient solution for augmented hearing on energy-constrained devices. FoVNet excels in both computational efficiency and speech quality across multiple scenarios, making it a promising solution for smart glasses applications.",
        "subjects": [
            "cs.SD",
            "cs.MM",
            "eess.AS",
            "eess.SP"
        ],
        "comment": "Accepted by INTERSPEECH2024"
    },
    {
        "paper id": "2408.06576",
        "abstract url": "https://arxiv.org/abs/2408.06576",
        "title": "CTISum: A New Benchmark Dataset For Cyber Threat Intelligence Summarization",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Cyber Threat Intelligence (CTI) summarization task requires the system to generate concise and accurate highlights from raw intelligence data, which plays an important role in providing decision-makers with crucial information to quickly detect and respond to cyber threats in the cybersecurity domain. However, efficient techniques for summarizing CTI reports, including facts, analytical insights, attack processes, etc., have largely been unexplored, primarily due to the lack of available dataset. To this end, we present CTISum, a new benchmark for CTI summarization task. Considering the importance of attack process, a novel fine-grained subtask of attack process summarization is proposed to enable defenders to assess risk, identify security gaps, vulnerabilities, and so on. Specifically, we first design a multi-stage annotation pipeline to gather and annotate the CTI data, and then benchmark the CTISum with a collection of extractive and abstractive summarization methods. Experimental results show that current state-of-the-art models exhibit limitations when applied to CTISum, underscoring the fact that automatically producing concise summaries of CTI reports remains an open research challenge.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06592",
        "abstract url": "https://arxiv.org/abs/2408.06592",
        "title": "ActiveNeRF: Learning Accurate 3D Geometry by Active Pattern Projection",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "NeRFs have achieved incredible success in novel view synthesis. However, the accuracy of the implicit geometry is unsatisfactory because the passive static environmental illumination has low spatial frequency and cannot provide enough information for accurate geometry reconstruction. In this work, we propose ActiveNeRF, a 3D geometry reconstruction framework, which improves the geometry quality of NeRF by actively projecting patterns of high spatial frequency onto the scene using a projector which has a constant relative pose to the camera. We design a learnable active pattern rendering pipeline which jointly learns the scene geometry and the active pattern. We find that, by adding the active pattern and imposing its consistency across different views, our proposed method outperforms state of the art geometry reconstruction methods qualitatively and quantitatively in both simulation and real experiments. Code is avaliable at https://github.com/hcp16/active_nerf",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 10 figures"
    },
    {
        "paper id": "2408.06596",
        "abstract url": "https://arxiv.org/abs/2408.06596",
        "title": "GeoFormer: Learning Point Cloud Completion with Tri-Plane Integrated Transformer",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Point cloud completion aims to recover accurate global geometry and preserve fine-grained local details from partial point clouds. Conventional methods typically predict unseen points directly from 3D point cloud coordinates or use self-projected multi-view depth maps to ease this task. However, these gray-scale depth maps cannot reach multi-view consistency, consequently restricting the performance. In this paper, we introduce a GeoFormer that simultaneously enhances the global geometric structure of the points and improves the local details. Specifically, we design a CCM Feature Enhanced Point Generator to integrate image features from multi-view consistent canonical coordinate maps (CCMs) and align them with pure point features, thereby enhancing the global geometry feature. Additionally, we employ the Multi-scale Geometry-aware Upsampler module to progressively enhance local details. This is achieved through cross attention between the multi-scale features extracted from the partial input and the features derived from previously estimated points. Extensive experiments on the PCN, ShapeNet-55/34, and KITTI benchmarks demonstrate that our GeoFormer outperforms recent methods, achieving the state-of-the-art performance. Our code is available at \\href{https://github.com/Jinpeng-Yu/GeoFormer}{https://github.com/Jinpeng-Yu/GeoFormer}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted by the 32nd ACM International Conference on Multimedia (MM'24)"
    },
    {
        "paper id": "2408.06604",
        "abstract url": "https://arxiv.org/abs/2408.06604",
        "title": "MV-DETR: Multi-modality indoor object detection by Multi-View DEtecton TRansformers",
        "rating": "0",
        "keywords": [
            [
                "3d",
                "RGBD",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a novel MV-DETR pipeline which is effective while efficient transformer based detection method. Given input RGBD data, we notice that there are super strong pretraining weights for RGB data while less effective works for depth related data. First and foremost , we argue that geometry and texture cues are both of vital importance while could be encoded separately. Secondly, we find that visual texture feature is relatively hard to extract compared with geometry feature in 3d space. Unfortunately, single RGBD dataset with thousands of data is not enough for training an discriminating filter for visual texture feature extraction. Last but certainly not the least, we designed a lightweight VG module consists of a visual textual encoder, a geometry encoder and a VG connector. Compared with previous state of the art works like V-DETR, gains from pretrained visual encoder could be seen. Extensive experiments on ScanNetV2 dataset shows the effectiveness of our method. It is worth mentioned that our method achieve 78\\% AP which create new state of the art on ScanNetv2 benchmark.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06621",
        "abstract url": "https://arxiv.org/abs/2408.06621",
        "title": "Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning and memorization capabilities via pretraining on massive textual corpora. However, training LLMs on human-written text entails significant risk of privacy and copyright violations, which demands an efficient machine unlearning framework to remove knowledge of sensitive data without retraining the model from scratch. While Gradient Ascent (GA) is widely used for unlearning by reducing the likelihood of generating unwanted information, the unboundedness of increasing the cross-entropy loss causes not only unstable optimization, but also catastrophic forgetting of knowledge that needs to be retained. We also discover its joint application under low-rank adaptation results in significantly suboptimal computational cost vs. generative performance trade-offs. In light of this limitation, we propose two novel techniques for robust and cost-efficient unlearning on LLMs. We first design an Inverted Hinge loss that suppresses unwanted tokens by increasing the probability of the next most likely token, thereby retaining fluency and structure in language generation. We also propose to initialize low-rank adapter weights based on Fisher-weighted low-rank approximation, which induces faster unlearning and better knowledge retention by allowing model updates to be focused on parameters that are important in generating textual data we wish to remove.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2408.06625",
        "abstract url": "https://arxiv.org/abs/2408.06625",
        "title": "DePatch: Towards Robust Adversarial Patch for Evading Person Detectors in the Real World",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent years have seen an increasing interest in physical adversarial attacks, which aim to craft deployable patterns for deceiving deep neural networks, especially for person detectors. However, the adversarial patterns of existing patch-based attacks heavily suffer from the self-coupling issue, where a degradation, caused by physical transformations, in any small patch segment can result in a complete adversarial dysfunction, leading to poor robustness in the complex real world. Upon this observation, we introduce the Decoupled adversarial Patch (DePatch) attack to address the self-coupling issue of adversarial patches. Specifically, we divide the adversarial patch into block-wise segments, and reduce the inter-dependency among these segments through randomly erasing out some segments during the optimization. We further introduce a border shifting operation and a progressive decoupling strategy to improve the overall attack capabilities. Extensive experiments demonstrate the superior performance of our method over other physical adversarial attacks, especially in the real world.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06631",
        "abstract url": "https://arxiv.org/abs/2408.06631",
        "title": "IFShip: A Large Vision-Language Model for Interpretable Fine-grained Ship Classification via Domain Knowledge-Enhanced Instruction Tuning",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "remote sensing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "End-to-end interpretation is currently the prevailing paradigm for remote sensing fine-grained ship classification (RS-FGSC) task. However, its inference process is uninterpretable, leading to criticism as a black box model. To address this issue, we propose a large vision-language model (LVLM) named IFShip for interpretable fine-grained ship classification. Unlike traditional methods, IFShip excels in interpretability by accurately conveying the reasoning process of FGSC in natural language. Specifically, we first design a domain knowledge-enhanced Chain-of-Thought (COT) prompt generation mechanism. This mechanism is used to semi-automatically construct a task-specific instruction-following dataset named TITANIC-FGS, which emulates human-like logical decision-making. We then train the IFShip model using task instructions tuned with the TITANIC-FGS dataset. Building on IFShip, we develop an FGSC visual chatbot that redefines the FGSC problem as a step-by-step reasoning task and conveys the reasoning process in natural language. Experimental results reveal that the proposed method surpasses state-of-the-art FGSC algorithms in both classification interpretability and accuracy. Moreover, compared to LVLMs like LLaVA and MiniGPT-4, our approach demonstrates superior expertise in the FGSC task. It provides an accurate chain of reasoning when fine-grained ship types are recognizable to the human eye and offers interpretable explanations when they are not.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06632",
        "abstract url": "https://arxiv.org/abs/2408.06632",
        "title": "EditScribe: Non-Visual Image Editing with Natural Language Verification Loops",
        "rating": "0",
        "keywords": [
            [
                "Image Editing"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Image editing is an iterative process that requires precise visual evaluation and manipulation for the output to match the editing intent. However, current image editing tools do not provide accessible interaction nor sufficient feedback for blind and low vision individuals to achieve this level of control. To address this, we developed EditScribe, a prototype system that makes image editing accessible using natural language verification loops powered by large multimodal models. Using EditScribe, the user first comprehends the image content through initial general and object descriptions, then specifies edit actions using open-ended natural language prompts. EditScribe performs the image edit, and provides four types of verification feedback for the user to verify the performed edit, including a summary of visual changes, AI judgement, and updated general and object descriptions. The user can ask follow-up questions to clarify and probe into the edits or verification feedback, before performing another edit. In a study with ten blind or low-vision users, we found that EditScribe supported participants to perform and verify image edit actions non-visually. We observed different prompting strategies from participants, and their perceptions on the various types of verification feedback. Finally, we discuss the implications of leveraging natural language verification loops to make visual authoring non-visually accessible.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "ASSETS 2024"
    },
    {
        "paper id": "2408.06633",
        "abstract url": "https://arxiv.org/abs/2408.06633",
        "title": "A lightweight YOLOv5-FFM model for occlusion pedestrian detection",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The development of autonomous driving technology must be inseparable from pedestrian detection. Because of the fast speed of the vehicle, the accuracy and real-time performance of the pedestrian detection algorithm are very important. YOLO, as an efficient and simple one-stage target detection method, is often used for pedestrian detection in various environments. However, this series of detectors face some challenges, such as excessive computation and undesirable detection rate when facing occluded pedestrians. In this paper, we propose an improved lightweight YOLOv5 model to deal with these problems. This model can achieve better pedestrian detection accuracy with fewer floating-point operations (FLOPs), especially for occluded targets. In order to achieve the above goals, we made improvements based on the YOLOv5 model framework and introduced Ghost module and SE block. Furthermore, we designed a local feature fusion module (FFM) to deal with occlusion in pedestrian detection. To verify the validity of our method, two datasets, Citypersons and CUHK Occlusion, were selected for the experiment. The experimental results show that, compared with the original yolov5s model, the average precision (AP) of our method is significantly improved, while the number of parameters is reduced by 27.9% and FLOPs are reduced by 19.0%.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06635",
        "abstract url": "https://arxiv.org/abs/2408.06635",
        "title": "IDRetracor: Towards Visual Forensics Against Malicious Face Swapping",
        "rating": "0",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The face swapping technique based on deepfake methods poses significant social risks to personal identity security. While numerous deepfake detection methods have been proposed as countermeasures against malicious face swapping, they can only output binary labels (Fake/Real) for distinguishing fake content without reliable and traceable evidence. To achieve visual forensics and target face attribution, we propose a novel task named face retracing, which considers retracing the original target face from the given fake one via inverse mapping. Toward this goal, we propose an IDRetracor that can retrace arbitrary original target identities from fake faces generated by multiple face swapping methods. Specifically, we first adopt a mapping resolver to perceive the possible solution space of the original target face for the inverse mappings. Then, we propose mapping-aware convolutions to retrace the original target face from the fake one. Such convolutions contain multiple kernels that can be combined under the control of the mapping resolver to tackle different face swapping mappings dynamically. Extensive experiments demonstrate that the IDRetracor exhibits promising retracing performance from both quantitative and qualitative perspectives.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05920",
        "abstract url": "https://arxiv.org/abs/2408.05920",
        "title": "Urban Region Pre-training and Prompting: A Graph-based Approach",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Urban region representation is crucial for various urban downstream tasks. However, despite the proliferation of methods and their success, acquiring general urban region knowledge and adapting to different tasks remains challenging. Previous work often neglects the spatial structures and functional layouts between entities, limiting their ability to capture transferable knowledge across regions. Further, these methods struggle to adapt effectively to specific downstream tasks, as they do not adequately address the unique features and relationships required for different downstream tasks. In this paper, we propose a $\\textbf{G}$raph-based $\\textbf{U}$rban $\\textbf{R}$egion $\\textbf{P}$re-training and $\\textbf{P}$rompting framework ($\\textbf{GURPP}$) for region representation learning. Specifically, we first construct an urban region graph that integrates detailed spatial entity data for more effective urban region representation. Then, we develop a subgraph-centric urban region pre-training model to capture the heterogeneous and transferable patterns of interactions among entities. To further enhance the adaptability of these embeddings to different tasks, we design two graph-based prompting methods to incorporate explicit/hidden task knowledge. Extensive experiments on various urban region prediction tasks and different cities demonstrate the superior performance of our GURPP framework. The implementation is available at this repository: https://anonymous.4open.science/r/GURPP.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05941",
        "abstract url": "https://arxiv.org/abs/2408.05941",
        "title": "Multimodal Large Language Models for Phishing Webpage Detection and Identification",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "To address the challenging problem of detecting phishing webpages, researchers have developed numerous solutions, in particular those based on machine learning (ML) algorithms. Among these, brand-based phishing detection that uses models from Computer Vision to detect if a given webpage is imitating a well-known brand has received widespread attention. However, such models are costly and difficult to maintain, as they need to be retrained with labeled dataset that has to be regularly and continuously collected. Besides, they also need to maintain a good reference list of well-known websites and related meta-data for effective performance. In this work, we take steps to study the efficacy of large language models (LLMs), in particular the multimodal LLMs, in detecting phishing webpages. Given that the LLMs are pretrained on a large corpus of data, we aim to make use of their understanding of different aspects of a webpage (logo, theme, favicon, etc.) to identify the brand of a given webpage and compare the identified brand with the domain name in the URL to detect a phishing attack. We propose a two-phase system employing LLMs in both phases: the first phase focuses on brand identification, while the second verifies the domain. We carry out comprehensive evaluations on a newly collected dataset. Our experiments show that the LLM-based system achieves a high detection rate at high precision; importantly, it also provides interpretable evidence for the decisions. Our system also performs significantly better than a state-of-the-art brand-based phishing detection system while demonstrating robustness against two known adversarial attacks.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "To appear in eCrime 2024"
    },
    {
        "paper id": "2408.06029",
        "abstract url": "https://arxiv.org/abs/2408.06029",
        "title": "Graph Clustering with Cross-View Feature Propagation",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph clustering is a fundamental and challenging learning task, which is conventionally approached by grouping similar vertices based on edge structure and feature similarity.In contrast to previous methods, in this paper, we investigate how multi-view feature propagation can influence cluster discovery in graph data.To this end, we present Graph Clustering With Cross-View Feature Propagation (GCCFP), a novel method that leverages multi-view feature propagation to enhance cluster identification in graph data.GCCFP employs a unified objective function that utilizes graph topology and multi-view vertex features to determine vertex cluster membership, regularized by a module that supports key latent feature propagation. We derive an iterative algorithm to optimize this function, prove model convergence within a finite number of iterations, and analyze its computational complexity. Our experiments on various real-world graphs demonstrate the superior clustering performance of GCCFP compared to well-established methods, manifesting its effectiveness across different scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06036",
        "abstract url": "https://arxiv.org/abs/2408.06036",
        "title": "Peaking into the Black-box: Prediction Intervals Give Insight into Data-driven Quadrotor Model Reliability",
        "rating": "-0.5",
        "keywords": [
            [
                "flight"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Ensuring the reliability and validity of data-driven quadrotor model predictions is essential for their accepted and practical use. This is especially true for grey- and black-box models wherein the mapping of inputs to predictions is not transparent and subsequent reliability notoriously difficult to ascertain. Nonetheless, such techniques are frequently and successfully used to identify quadrotor models. Prediction intervals (PIs) may be employed to provide insight into the consistency and accuracy of model predictions. This paper estimates such PIs for polynomial and Artificial Neural Network (ANN) quadrotor aerodynamic models. Two existing ANN PI estimation techniques - the bootstrap method and the quality driven method - are validated numerically for quadrotor aerodynamic models using an existing high-fidelity quadrotor simulation. Quadrotor aerodynamic models are then identified on real quadrotor flight data to demonstrate their utility and explore their sensitivity to model interpolation and extrapolation. It is found that the ANN-based PIs widen considerably when extrapolating and remain constant, or shrink, when interpolating. While this behaviour also occurs for the polynomial PIs, it is of lower magnitude. The estimated PIs establish probabilistic bounds within which the quadrotor model outputs will likely lie, subject to modelling and measurement uncertainties that are reflected through the PI widths.",
        "subjects": [
            "eess.SY",
            "cs.AI"
        ],
        "comment": "Presented at AIAA SciTech Forum 2023 in National Harbor, MD, USA"
    },
    {
        "paper id": "2408.06039",
        "abstract url": "https://arxiv.org/abs/2408.06039",
        "title": "Spacetime $E(n)$-Transformer: Equivariant Attention for Spatio-temporal Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We introduce an $E(n)$-equivariant Transformer architecture for spatio-temporal graph data. By imposing rotation, translation, and permutation equivariance inductive biases in both space and time, we show that the Spacetime $E(n)$-Transformer (SET) outperforms purely spatial and temporal models without symmetry-preserving properties. We benchmark SET against said models on the charged $N$-body problem, a simple physical system with complex dynamics. While existing spatio-temporal graph neural networks focus on sequential modeling, we empirically demonstrate that leveraging underlying domain symmetries yields considerable improvements for modeling dynamical systems on graphs.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06050",
        "abstract url": "https://arxiv.org/abs/2408.06050",
        "title": "What Ails Generative Structure-based Drug Design: Too Little or Too Much Expressivity?",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Several generative models with elaborate training and sampling procedures have been proposed recently to accelerate structure-based drug design (SBDD); however, perplexingly, their empirical performance turns out to be suboptimal. We seek to better understand this phenomenon from both theoretical and empirical perspectives. Since most of these models apply graph neural networks (GNNs), one may suspect that they inherit the representational limitations of GNNs. We analyze this aspect, establishing the first such results for protein-ligand complexes. A plausible counterview may attribute the underperformance of these models to their excessive parameterizations, inducing expressivity at the expense of generalization. We also investigate this possibility with a simple metric-aware approach that learns an economical surrogate for affinity to infer an unlabelled molecular graph and optimizes for labels conditioned on this graph and molecular properties. The resulting model achieves state-of-the-art results using 100x fewer trainable parameters and affords up to 1000x speedup. Collectively, our findings underscore the need to reassess and redirect the existing paradigm and efforts for SBDD.",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": "25 pages, 11 figures"
    },
    {
        "paper id": "2408.06063",
        "abstract url": "https://arxiv.org/abs/2408.06063",
        "title": "TruVRF: Towards Triple-Granularity Verification on Machine Unlearning",
        "rating": "-0.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The concept of the right to be forgotten has led to growing interest in machine unlearning, but reliable validation methods are lacking, creating opportunities for dishonest model providers to mislead data contributors. Traditional invasive methods like backdoor injection are not feasible for legacy data. To address this, we introduce TruVRF, a non-invasive unlearning verification framework operating at class-, volume-, and sample-level granularities. TruVRF includes three Unlearning-Metrics designed to detect different types of dishonest servers: Neglecting, Lazy, and Deceiving. Unlearning-Metric-I checks class alignment, Unlearning-Metric-II verifies sample count, and Unlearning-Metric-III confirms specific sample deletion. Evaluations on three datasets show TruVRF's robust performance, with over 90% accuracy for Metrics I and III, and a 4.8% to 8.2% inference deviation for Metric II. TruVRF also demonstrates generalizability and practicality across various conditions and with state-of-the-art unlearning frameworks like SISA and Amnesiac Unlearning.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06101",
        "abstract url": "https://arxiv.org/abs/2408.06101",
        "title": "Generalization capabilities of MeshGraphNets to unseen geometries for fluid dynamics",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This works investigates the generalization capabilities of MeshGraphNets (MGN) [Pfaff et al. Learning Mesh-Based Simulation with Graph Networks. ICML 2021] to unseen geometries for fluid dynamics, e.g. predicting the flow around a new obstacle that was not part of the training data. For this purpose, we create a new benchmark dataset for data-driven computational fluid dynamics (CFD) which extends DeepMind's flow around a cylinder dataset by including different shapes and multiple objects. We then use this new dataset to extend the generalization experiments conducted by DeepMind on MGNs by testing how well an MGN can generalize to different shapes. In our numerical tests, we show that MGNs can sometimes generalize well to various shapes by training on a dataset of one obstacle shape and testing on a dataset of another obstacle shape.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.NA",
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06310",
        "abstract url": "https://arxiv.org/abs/2408.06310",
        "title": "OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Ontology alignment is integral to achieving semantic interoperability as the number of available ontologies covering intersecting domains is increasing. This paper proposes OWL2Vec4OA, an extension of the ontology embedding system OWL2Vec*. While OWL2Vec* has emerged as a powerful technique for ontology embedding, it currently lacks a mechanism to tailor the embedding to the ontology alignment task. OWL2Vec4OA incorporates edge confidence values from seed mappings to guide the random walk strategy. We present the theoretical foundations, implementation details, and experimental evaluation of our proposed extension, demonstrating its potential effectiveness for ontology alignment tasks.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Submitted to a conference"
    },
    {
        "paper id": "2408.06465",
        "abstract url": "https://arxiv.org/abs/2408.06465",
        "title": "Kernel Sum of Squares for Data Adapted Kernel Learning of Dynamical Systems from Data: A global optimization approach",
        "rating": "-0.5",
        "keywords": [
            [
                "Kernel Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper examines the application of the Kernel Sum of Squares (KSOS) method for enhancing kernel learning from data, particularly in the context of dynamical systems. Traditional kernel-based methods, despite their theoretical soundness and numerical efficiency, frequently struggle with selecting optimal base kernels and parameter tuning, especially with gradient-based methods prone to local optima. KSOS mitigates these issues by leveraging a global optimization framework with kernel-based surrogate functions, thereby achieving more reliable and precise learning of dynamical systems. Through comprehensive numerical experiments on the Logistic Map, Henon Map, and Lorentz System, KSOS is shown to consistently outperform gradient descent in minimizing the relative-$\u03c1$ metric and improving kernel accuracy. These results highlight KSOS's effectiveness in predicting the behavior of chaotic dynamical systems, demonstrating its capability to adapt kernels to underlying dynamics and enhance the robustness and predictive power of kernel-based approaches, making it a valuable asset for time series analysis in various scientific fields.",
        "subjects": [
            "cs.LG",
            "math.DS",
            "math.OC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06503",
        "abstract url": "https://arxiv.org/abs/2408.06503",
        "title": "Decentralized Cooperation in Heterogeneous Multi-Agent Reinforcement Learning via Graph Neural Network-Based Intrinsic Motivation",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multi-agent Reinforcement Learning (MARL) is emerging as a key framework for various sequential decision-making and control tasks. Unlike their single-agent counterparts, multi-agent systems necessitate successful cooperation among the agents. The deployment of these systems in real-world scenarios often requires decentralized training, a diverse set of agents, and learning from infrequent environmental reward signals. These challenges become more pronounced under partial observability and the lack of prior knowledge about agent heterogeneity. While notable studies use intrinsic motivation (IM) to address reward sparsity or cooperation in decentralized settings, those dealing with heterogeneity typically assume centralized training, parameter sharing, and agent indexing. To overcome these limitations, we propose the CoHet algorithm, which utilizes a novel Graph Neural Network (GNN) based intrinsic motivation to facilitate the learning of heterogeneous agent policies in decentralized settings, under the challenges of partial observability and reward sparsity. Evaluation of CoHet in the Multi-agent Particle Environment (MPE) and Vectorized Multi-Agent Simulator (VMAS) benchmarks demonstrates superior performance compared to the state-of-the-art in a range of cooperative multi-agent scenarios. Our research is supplemented by an analysis of the impact of the agent dynamics model on the intrinsic motivation module, insights into the performance of different CoHet variants, and its robustness to an increasing number of heterogeneous agents.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2408.06509",
        "abstract url": "https://arxiv.org/abs/2408.06509",
        "title": "Fooling SHAP with Output Shuffling Attacks",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Explainable AI~(XAI) methods such as SHAP can help discover feature attributions in black-box models. If the method reveals a significant attribution from a ``protected feature'' (e.g., gender, race) on the model output, the model is considered unfair. However, adversarial attacks can subvert the detection of XAI methods. Previous approaches to constructing such an adversarial model require access to underlying data distribution, which may not be possible in many practical scenarios. We relax this constraint and propose a novel family of attacks, called shuffling attacks, that are data-agnostic. The proposed attack strategies can adapt any trained machine learning model to fool Shapley value-based explanations. We prove that Shapley values cannot detect shuffling attacks. However, algorithms that estimate Shapley values, such as linear SHAP and SHAP, can detect these attacks with varying degrees of effectiveness. We demonstrate the efficacy of the attack strategies by comparing the performance of linear SHAP and SHAP using real-world datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06536",
        "abstract url": "https://arxiv.org/abs/2408.06536",
        "title": "A Comparison of Imitation Learning Algorithms for Bimanual Manipulation",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Amidst the wide popularity of imitation learning algorithms in robotics, their properties regarding hyperparameter sensitivity, ease of training, data efficiency, and performance have not been well-studied in high-precision industry-inspired environments. In this work, we demonstrate the limitations and benefits of prominent imitation learning approaches and analyze their capabilities regarding these properties. We evaluate each algorithm on a complex bimanual manipulation task involving an over-constrained dynamics system in a setting involving multiple contacts between the manipulated object and the environment. While we find that imitation learning is well suited to solve such complex tasks, not all algorithms are equal in terms of handling environmental and hyperparameter perturbations, training requirements, performance, and ease of use. We investigate the empirical influence of these key characteristics by employing a carefully designed experimental procedure and learning environment. Paper website: https://bimanual-imitation.github.io/",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06603",
        "abstract url": "https://arxiv.org/abs/2408.06603",
        "title": "Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Temporal knowledge graph completion aims to infer the missing facts in temporal knowledge graphs. Current approaches usually embed factual knowledge into continuous vector space and apply geometric operations to learn potential patterns in temporal knowledge graphs. However, these methods only adopt a single operation, which may have limitations in capturing the complex temporal dynamics present in temporal knowledge graphs. Therefore, we propose a simple but effective method, i.e. TCompoundE, which is specially designed with two geometric operations, including time-specific and relation-specific operations. We provide mathematical proofs to demonstrate the ability of TCompoundE to encode various relation patterns. Experimental results show that our proposed model significantly outperforms existing temporal knowledge graph embedding models. Our code is available at https://github.com/nk-ruiying/TCompoundE.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06620",
        "abstract url": "https://arxiv.org/abs/2408.06620",
        "title": "Unveiling the Flaws: A Critical Analysis of Initialization Effect on Time Series Anomaly Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning for time-series anomaly detection (TSAD) has gained significant attention over the past decade. Despite the reported improvements in several papers, the practical application of these models remains limited. Recent studies have cast doubt on these models, attributing their results to flawed evaluation techniques. However, the impact of initialization has largely been overlooked. This paper provides a critical analysis of the initialization effects on TSAD model performance. Our extensive experiments reveal that TSAD models are highly sensitive to hyperparameters such as window size, seed number, and normalization. This sensitivity often leads to significant variability in performance, which can be exploited to artificially inflate the reported efficacy of these models. We demonstrate that even minor changes in initialization parameters can result in performance variations that overshadow the claimed improvements from novel model architectures. Our findings highlight the need for rigorous evaluation protocols and transparent reporting of preprocessing steps to ensure the reliability and fairness of anomaly detection methods. This paper calls for a more cautious interpretation of TSAD advancements and encourages the development of more robust and transparent evaluation practices to advance the field and its practical applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.07097",
        "abstract url": "https://arxiv.org/abs/2408.07097",
        "title": "Attention Please: What Transformer Models Really Learn for Process Prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Predictive process monitoring aims to support the execution of a process during runtime with various predictions about the further evolution of a process instance. In the last years a plethora of deep learning architectures have been established as state-of-the-art for different prediction targets, among others the transformer architecture. The transformer architecture is equipped with a powerful attention mechanism, assigning attention scores to each input part that allows to prioritize most relevant information leading to more accurate and contextual output. However, deep learning models largely represent a black box, i.e., their reasoning or decision-making process cannot be understood in detail. This paper examines whether the attention scores of a transformer based next-activity prediction model can serve as an explanation for its decision-making. We find that attention scores in next-activity prediction models can serve as explainers and exploit this fact in two proposed graph-based explanation approaches. The gained insights could inspire future work on the improvement of predictive business process models as well as enabling a neural network based mining of process models from event logs.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05938",
        "abstract url": "https://arxiv.org/abs/2408.05938",
        "title": "Deep Geometric Moments Promote Shape Consistency in Text-to-3D Generation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "To address the data scarcity associated with 3D assets, 2D-lifting techniques such as Score Distillation Sampling (SDS) have become a widely adopted practice in text-to-3D generation pipelines. However, the diffusion models used in these techniques are prone to viewpoint bias and thus lead to geometric inconsistencies such as the Janus problem. To counter this, we introduce MT3D, a text-to-3D generative model that leverages a high-fidelity 3D object to overcome viewpoint bias and explicitly infuse geometric understanding into the generation pipeline. Firstly, we employ depth maps derived from a high-quality 3D model as control signals to guarantee that the generated 2D images preserve the fundamental shape and structure, thereby reducing the inherent viewpoint bias. Next, we utilize deep geometric moments to ensure geometric consistency in the 3D representation explicitly. By incorporating geometric details from a 3D asset, MT3D enables the creation of diverse and geometrically consistent objects, thereby improving the quality and usability of our 3D representations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 8 figures"
    },
    {
        "paper id": "2408.05945",
        "abstract url": "https://arxiv.org/abs/2408.05945",
        "title": "MV2DFusion: Leveraging Modality-Specific Object Semantics for Multi-Modal 3D Detection",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rise of autonomous vehicles has significantly increased the demand for robust 3D object detection systems. While cameras and LiDAR sensors each offer unique advantages--cameras provide rich texture information and LiDAR offers precise 3D spatial data--relying on a single modality often leads to performance limitations. This paper introduces MV2DFusion, a multi-modal detection framework that integrates the strengths of both worlds through an advanced query-based fusion mechanism. By introducing an image query generator to align with image-specific attributes and a point cloud query generator, MV2DFusion effectively combines modality-specific object semantics without biasing toward one single modality. Then the sparse fusion process can be accomplished based on the valuable object semantics, ensuring efficient and accurate object detection across various scenarios. Our framework's flexibility allows it to integrate with any image and point cloud-based detectors, showcasing its adaptability and potential for future advancements. Extensive evaluations on the nuScenes and Argoverse2 datasets demonstrate that MV2DFusion achieves state-of-the-art performance, particularly excelling in long-range detection scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05950",
        "abstract url": "https://arxiv.org/abs/2408.05950",
        "title": "Robust online reconstruction of continuous-time signals from a lean spike train ensemble code",
        "rating": "-1",
        "keywords": [
            [
                "biologically"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Sensory stimuli in animals are encoded into spike trains by neurons, offering advantages such as sparsity, energy efficiency, and high temporal resolution. This paper presents a signal processing framework that deterministically encodes continuous-time signals into biologically feasible spike trains, and addresses the questions about representable signal classes and reconstruction bounds. The framework considers encoding of a signal through spike trains generated by an ensemble of neurons using a convolve-then-threshold mechanism with various convolution kernels. A closed-form solution to the inverse problem, from spike trains to signal reconstruction, is derived in the Hilbert space of shifted kernel functions, ensuring sparse representation of a generalized Finite Rate of Innovation (FRI) class of signals. Additionally, inspired by real-time processing in biological systems, an efficient iterative version of the optimal reconstruction is formulated that considers only a finite window of past spikes, ensuring robustness of the technique to ill-conditioned encoding; convergence guarantees of the windowed reconstruction to the optimal solution are then provided. Experiments on a large audio dataset demonstrate excellent reconstruction accuracy at spike rates as low as one-fifth of the Nyquist rate, while showing clear competitive advantage in comparison to state-of-the-art sparse coding techniques in the low spike rate regime.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "22 pages, including a 9-page appendix, 8 figures. A GitHub link to the project implementation is embedded in the paper"
    },
    {
        "paper id": "2408.05961",
        "abstract url": "https://arxiv.org/abs/2408.05961",
        "title": "Cross-Spectral Analysis of Bivariate Graph Signals",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "With the advancements in technology and monitoring tools, we often encounter multivariate graph signals, which can be seen as the realizations of multivariate graph processes, and revealing the relationship between their constituent quantities is one of the important problems. To address this issue, we propose a cross-spectral analysis tool for bivariate graph signals. The main goal of this study is to extend the scope of spectral analysis of graph signals to multivariate graph signals. In this study, we define joint weak stationarity graph processes and introduce graph cross-spectral density and coherence for multivariate graph processes. We propose several estimators for the cross-spectral density and investigate the theoretical properties of the proposed estimators. Furthermore, we demonstrate the effectiveness of the proposed estimators through numerical experiments, including simulation studies and a real data application. Finally, as an interesting extension, we discuss robust spectral analysis of graph signals in the presence of outliers.",
        "subjects": [
            "stat.ME",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05968",
        "abstract url": "https://arxiv.org/abs/2408.05968",
        "title": "Nob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "The rise of Large Language Models (LLMs) has triggered legal and ethical concerns, especially regarding the unauthorized use of copyrighted materials in their training datasets. This has led to lawsuits against tech companies accused of using protected content without permission. Membership Inference Attacks (MIAs) aim to detect whether specific documents were used in a given LLM pretraining, but their effectiveness is undermined by biases such as time-shifts and n-gram overlaps. This paper addresses the evaluation of MIAs on LLMs with partially inferable training sets, under the ex-post hypothesis, which acknowledges inherent distributional biases between members and non-members datasets. We propose and validate algorithms to create ``non-biased'' and ``non-classifiable'' datasets for fairer MIA assessment. Experiments using the Gutenberg dataset on OpenLamma and Pythia show that neutralizing known biases alone is insufficient. Our methods produce non-biased ex-post datasets with AUC-ROC scores comparable to those previously obtained on genuinely random datasets, validating our approach. Globally, MIAs yield results close to random, with only one being effective on both random and our datasets, but its performance decreases when bias is removed.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05977",
        "abstract url": "https://arxiv.org/abs/2408.05977",
        "title": "The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI",
        "rating": "-1",
        "keywords": [
            [
                "Psychological"
            ],
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Psychological trauma can manifest following various distressing events and is captured in diverse online contexts. However, studies traditionally focus on a single aspect of trauma, often neglecting the transferability of findings across different scenarios. We address this gap by training language models with progressing complexity on trauma-related datasets, including genocide-related court data, a Reddit dataset on post-traumatic stress disorder (PTSD), counseling conversations, and Incel forum posts. Our results show that the fine-tuned RoBERTa model excels in predicting traumatic events across domains, slightly outperforming large language models like GPT-4. Additionally, SLALOM-feature scores and conceptual explanations effectively differentiate and cluster trauma-related language, highlighting different trauma aspects and identifying sexual abuse and experiences related to death as a common traumatic event across all datasets. This transferability is crucial as it allows for the development of tools to enhance trauma detection and intervention in diverse populations and settings.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06002",
        "abstract url": "https://arxiv.org/abs/2408.06002",
        "title": "Generative Design of Multimodal Soft Pneumatic Actuators",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "The recent advancements in machine learning techniques have steered us towards the data-driven design of products. Motivated by this objective, the present study proposes an automated design methodology that employs data-driven methods to generate new designs of soft actuators. One of the bottlenecks in the data-driven automated design process is having publicly available data to train the model. Due to its unavailability, a synthetic data set of soft pneumatic network (Pneu-net) actuators has been created. The parametric design data set for the training of the generative model is created using data augmentation. Next, the Gaussian mixture model has been applied to generate novel parametric designs of Pneu-net actuators. The distance-based metric defines the novelty and diversity of the generated designs. In addition, it is noteworthy that the model has the potential to generate a multimodal Pneu-net actuator that could perform in-plane bending and out-of-plane twisting. Later, the novel design is passed through finite element analysis to evaluate the quality of the generated design. Moreover, the trajectory of each category of Pneu-net actuators evaluates the performance of the generated Pneu-net actuators and emphasizes the necessity of multimodal actuation. The proposed model could accelerate the design of new soft robots by selecting a soft actuator from the developed novel pool of soft actuators.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06022",
        "abstract url": "https://arxiv.org/abs/2408.06022",
        "title": "Controlling Surprisal in Music Generation via Information Content Curve Matching",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In recent years, the quality and public interest in music generation systems have grown, encouraging research into various ways to control these systems. We propose a novel method for controlling surprisal in music generation using sequence models. To achieve this goal, we define a metric called Instantaneous Information Content (IIC). The IIC serves as a proxy function for the perceived musical surprisal (as estimated from a probabilistic model) and can be calculated at any point within a music piece. This enables the comparison of surprisal across different musical content even if the musical events occur in irregular time intervals. We use beam search to generate musical material whose IIC curve closely approximates a given target IIC. We experimentally show that the IIC correlates with harmonic and rhythmic complexity and note density. The correlation decreases with the length of the musical context used for estimating the IIC. Finally, we conduct a qualitative user study to test if human listeners can identify the IIC curves that have been used as targets when generating the respective musical material. We provide code for creating IIC interpolations and IIC visualizations on https://github.com/muthissar/iic.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "8 pages, 4 figures, 2 tables, accepted at the 25th Int. Society for Music Information Retrieval Conf., San Francisco, USA, 2024"
    },
    {
        "paper id": "2408.06025",
        "abstract url": "https://arxiv.org/abs/2408.06025",
        "title": "A novel metric for detecting quadrotor loss-of-control",
        "rating": "-1",
        "keywords": [
            [
                "flight"
            ]
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) are becoming an integral part of both industry and society. In particular, the quadrotor is now invaluable across a plethora of fields and recent developments, such as the inclusion of aerial manipulators, only extends their versatility. As UAVs become more widespread, preventing loss-of-control (LOC) is an ever growing concern. Unfortunately, LOC is not clearly defined for quadrotors, or indeed, many other autonomous systems. Moreover, any existing definitions are often incomplete and restrictive. A novel metric, based on actuator capabilities, is introduced to detect LOC in quadrotors. The potential of this metric for LOC detection is demonstrated through both simulated and real quadrotor flight data. It is able to detect LOC induced by actuator faults without explicit knowledge of the occurrence and nature of the failure. The proposed metric is also sensitive enough to detect LOC in more nuanced cases, where the quadrotor remains undamaged but nevertheless losses control through an aggressive yawing manoeuvre. As the metric depends only on system and actuator models, it is sufficiently general to be applied to other systems.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Presented at the International Conference on Robotics and Automation (ICRA) 2024 in Yokohama, Japan"
    },
    {
        "paper id": "2408.06040",
        "abstract url": "https://arxiv.org/abs/2408.06040",
        "title": "ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "In the rapidly evolving fields of natural language processing and computer vision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yet challenging task. The quest for models that can seamlessly integrate and interpret multimodal data is more pressing than ever. Imagine a system that can understand language with the depth and nuance of human cognition, while simultaneously interpreting the rich visual context of the world around it. We present ARPA, an architecture that fuses the unparalleled contextual understanding of large language models with the advanced feature extraction capabilities of transformers, which then pass through a custom Graph Neural Network (GNN) layer to learn intricate relationships and subtle nuances within the data. This innovative architecture not only sets a new benchmark in visual word disambiguation but also introduces a versatile framework poised to transform how linguistic and visual data interact by harnessing the synergistic strengths of its components, ensuring robust performance even in the most complex disambiguation scenarios. Through a series of experiments and comparative analysis, we reveal the substantial advantages of our model, underscoring its potential to redefine standards in the field. Beyond its architectural prowess, our architecture excels through experimental enrichments, including sophisticated data augmentation and multi-modal training techniques. ARPA's introduction marks a significant milestone in visual word disambiguation, offering a compelling solution that bridges the gap between linguistic and visual modalities. We invite researchers and practitioners to explore the capabilities of our model, envisioning a future where such hybrid models drive unprecedented advancements in artificial intelligence.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06044",
        "abstract url": "https://arxiv.org/abs/2408.06044",
        "title": "DiagESC: Dialogue Synthesis for Integrating Depression Diagnosis into Emotional Support Conversation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "Diagnosis",
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Dialogue systems for mental health care aim to provide appropriate support to individuals experiencing mental distress. While extensive research has been conducted to deliver adequate emotional support, existing studies cannot identify individuals who require professional medical intervention and cannot offer suitable guidance. We introduce the Diagnostic Emotional Support Conversation task for an advanced mental health management system. We develop the DESC dataset to assess depression symptoms while maintaining user experience by utilizing task-specific utterance generation prompts and a strict filtering algorithm. Evaluations by professional psychological counselors indicate that DESC has a superior ability to diagnose depression than existing data. Additionally, conversational quality evaluation reveals that DESC maintains fluent, consistent, and coherent dialogues.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by SIGDIAL 2024"
    },
    {
        "paper id": "2408.06061",
        "abstract url": "https://arxiv.org/abs/2408.06061",
        "title": "Quantum Algorithms for Compositional Text Processing",
        "rating": "-1",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Quantum computing and AI have found a fruitful intersection in the field of natural language processing. We focus on the recently proposed DisCoCirc framework for natural language, and propose a quantum adaptation, QDisCoCirc. This is motivated by a compositional approach to rendering AI interpretable: the behavior of the whole can be understood in terms of the behavior of parts, and the way they are put together. For the model-native primitive operation of text similarity, we derive quantum algorithms for fault-tolerant quantum computers to solve the task of question-answering within QDisCoCirc, and show that this is BQP-hard; note that we do not consider the complexity of question-answering in other natural language processing models. Assuming widely-held conjectures, implementing the proposed model classically would require super-polynomial resources. Therefore, it could provide a meaningful demonstration of the power of practical quantum processors. The model construction builds on previous work in compositional quantum natural language processing. Word embeddings are encoded as parameterized quantum circuits, and compositionality here means that the quantum circuits compose according to the linguistic structure of the text. We outline a method for evaluating the model on near-term quantum processors, and elsewhere we report on a recent implementation of this on quantum hardware. In addition, we adapt a quantum algorithm for the closest vector problem to obtain a Grover-like speedup in the fault-tolerant regime for our model. This provides an unconditional quadratic speedup over any classical algorithm in certain circumstances, which we will verify empirically in future work.",
        "subjects": [
            "quant-ph",
            "cs.CL"
        ],
        "comment": "In Proceedings QPL 2024, arXiv:2408.05113"
    },
    {
        "paper id": "2408.06072",
        "abstract url": "https://arxiv.org/abs/2408.06072",
        "title": "CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "Text-to-Video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce CogVideoX, a large-scale diffusion transformer model designed for generating videos based on text prompts. To efficently model video data, we propose to levearge a 3D Variational Autoencoder (VAE) to compress videos along both spatial and temporal dimensions. To improve the text-video alignment, we propose an expert transformer with the expert adaptive LayerNorm to facilitate the deep fusion between the two modalities. By employing a progressive training technique, CogVideoX is adept at producing coherent, long-duration videos characterized by significant motions. In addition, we develop an effective text-video data processing pipeline that includes various data preprocessing strategies and a video captioning method. It significantly helps enhance the performance of CogVideoX, improving both generation quality and semantic alignment. Results show that CogVideoX demonstrates state-of-the-art performance across both multiple machine metrics and human evaluations. The model weights of both the 3D Causal VAE and CogVideoX are publicly available at https://github.com/THUDM/CogVideo.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06075",
        "abstract url": "https://arxiv.org/abs/2408.06075",
        "title": "Five Pitfalls When Assessing Synthetic Medical Images with Reference Metrics",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Reference metrics have been developed to objectively and quantitatively compare two images. Especially for evaluating the quality of reconstructed or compressed images, these metrics have shown very useful. Extensive tests of such metrics on benchmarks of artificially distorted natural images have revealed which metric best correlate with human perception of quality. Direct transfer of these metrics to the evaluation of generative models in medical imaging, however, can easily lead to pitfalls, because assumptions about image content, image data format and image interpretation are often very different. Also, the correlation of reference metrics and human perception of quality can vary strongly for different kinds of distortions and commonly used metrics, such as SSIM, PSNR and MAE are not the best choice for all situations. We selected five pitfalls that showcase unexpected and probably undesired reference metric scores and discuss strategies to avoid them.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "10 pages, 5 figures, accepted at Deep Generative Models workshop @ MICCAI 2024"
    },
    {
        "paper id": "2408.06078",
        "abstract url": "https://arxiv.org/abs/2408.06078",
        "title": "CoFAR Clutter Estimation using Covariance-Free Bayesian Learning",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "A cognitive fully adaptive radar (CoFAR) adapts its behavior on its own within a short period of time in response to changes in the target environment. For the CoFAR to function properly, it is critical to understand its operating environment through estimation of the clutter channel impulse response (CCIR). In general, CCIR is sparse but prior works either ignore it or estimate the CCIR by imposing sparsity as an explicit constraint in their optimization problem. In this paper, contrary to these studies, we develop covariance-free Bayesian learning (CoFBL) techniques for estimating sparse CCIR in a CoFAR system. In particular, we consider a multiple measurement vector scenario and estimate a simultaneously sparse (row sparse) CCIR matrix. Our CoFBL framework reduces the complexity of conventional sparse Bayesian learning through the use of the diagonal element estimation rule and conjugate gradient descent algorithm. We show that the framework is applicable to various forms of CCIR sparsity models: group, joint, and joint-cum-group. We evaluate our method through numerical experiments on a data set generated using RFView, a high-fidelity modeling and simulation tool. We derive Bayesian Cram\u00e9r-Rao bounds for the various considered scenarios to benchmark the performance of our algorithms. Our results demonstrate that the proposed CoFBL-based approaches perform better than the existing popular approaches such as multiple focal underdetermined system solver and simultaneous orthogonal matching pursuit.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06105",
        "abstract url": "https://arxiv.org/abs/2408.06105",
        "title": "Text2Interaction: Establishing Safe and Preferable Human-Robot Interaction",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Adjusting robot behavior to human preferences can require intensive human feedback, preventing quick adaptation to new users and changing circumstances. Moreover, current approaches typically treat user preferences as a reward, which requires a manual balance between task success and user satisfaction. To integrate new user preferences in a zero-shot manner, our proposed Text2Interaction framework invokes large language models to generate a task plan, motion preferences as Python code, and parameters of a safe controller. By maximizing the combined probability of task completion and user satisfaction instead of a weighted sum of rewards, we can reliably find plans that fulfill both requirements. We find that 83% of users working with Text2Interaction agree that it integrates their preferences into the robot's plan, and 94% prefer Text2Interaction over the baseline. Our ablation study shows that Text2Interaction aligns better with unseen preferences than other baselines while maintaining a high success rate.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06133",
        "abstract url": "https://arxiv.org/abs/2408.06133",
        "title": "Uncovering the Role of Support Infrastructure in Clickbait PDF Campaigns",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Clickbait PDFs, an entry point for multiple Web attacks, are distributed via SEO poisoning and rank high in search results due to being massively uploaded on abused or compromised websites. The central role of these hosts in the distribution of clickbait PDFs remains understudied, and it is unclear whether attackers differentiate the types of hosting for PDF uploads, how long they rely on hosts, and how affected parties respond to abuse. To address this, we conducted real-time analyses on hosts, collecting data on 4,648,939 clickbait PDFs served by 177,835 hosts over 17 months. Our results revealed a diverse infrastructure, with hosts falling into three main hosting types. We also identified at scale the presence of eight software components which facilitate file uploads and which are likely exploited for clickbait PDF distribution. We contact affected parties to report the misuse of their resources via a large-scale vulnerability notification. While we observed some effectiveness in terms of number of cleaned-up PDFs following the notification, long-term improvement in this infrastructure remained insignificant. This finding raises questions about the hosting providers' role in combating abuse and the actual impact of vulnerability notifications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Published at Euro S&P 2024"
    },
    {
        "paper id": "2408.06137",
        "abstract url": "https://arxiv.org/abs/2408.06137",
        "title": "MR3D-Net: Dynamic Multi-Resolution 3D Sparse Voxel Grid Fusion for LiDAR-Based Collective Perception",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Voxel"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The safe operation of automated vehicles depends on their ability to perceive the environment comprehensively. However, occlusion, sensor range, and environmental factors limit their perception capabilities. To overcome these limitations, collective perception enables vehicles to exchange information. However, fusing this exchanged information is a challenging task. Early fusion approaches require large amounts of bandwidth, while intermediate fusion approaches face interchangeability issues. Late fusion of shared detections is currently the only feasible approach. However, it often results in inferior performance due to information loss. To address this issue, we propose MR3D-Net, a dynamic multi-resolution 3D sparse voxel grid fusion backbone architecture for LiDAR-based collective perception. We show that sparse voxel grids at varying resolutions provide a meaningful and compact environment representation that can adapt to the communication bandwidth. MR3D-Net achieves state-of-the-art performance on the OPV2V 3D object detection benchmark while reducing the required bandwidth by up to 94% compared to early fusion. Code is available at https://github.com/ekut-es/MR3D-Net",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at IEEE ITSC 2024"
    },
    {
        "paper id": "2408.06142",
        "abstract url": "https://arxiv.org/abs/2408.06142",
        "title": "Med42-v2: A Suite of Clinical LLMs",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "healthcare",
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Med42-v2 introduces a suite of clinical large language models (LLMs) designed to address the limitations of generic models in healthcare settings. These models are built on Llama3 architecture and fine-tuned using specialized clinical data. They underwent multi-stage preference alignment to effectively respond to natural prompts. While generic models are often preference-aligned to avoid answering clinical queries as a precaution, Med42-v2 is specifically trained to overcome this limitation, enabling its use in clinical settings. Med42-v2 models demonstrate superior performance compared to the original Llama3 models in both 8B and 70B parameter configurations and GPT-4 across various medical benchmarks. These LLMs are developed to understand clinical queries, perform reasoning tasks, and provide valuable assistance in clinical environments. The models are now publicly available at \\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06143",
        "abstract url": "https://arxiv.org/abs/2408.06143",
        "title": "Motion Planning for Minimally Actuated Serial Robots",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Modern manipulators are acclaimed for their precision but often struggle to operate in confined spaces. This limitation has driven the development of hyper-redundant and continuum robots. While these present unique advantages, they face challenges in, for instance, weight, mechanical complexity, modeling and costs. The Minimally Actuated Serial Robot (MASR) has been proposed as a light-weight, low-cost and simpler alternative where passive joints are actuated with a Mobile Actuator (MA) moving along the arm. Yet, Inverse Kinematics (IK) and a general motion planning algorithm for the MASR have not be addressed. In this letter, we propose the MASR-RRT* motion planning algorithm specifically developed for the unique kinematics of MASR. The main component of the algorithm is a data-based model for solving the IK problem while considering minimal traverse of the MA. The model is trained solely using the forward kinematics of the MASR and does not require real data. With the model as a local-connection mechanism, MASR-RRT* minimizes a cost function expressing the action time. In a comprehensive analysis, we show that MASR-RRT* is superior in performance to the straight-forward implementation of the standard RRT*. Experiments on a real robot in different environments with obstacles validate the proposed algorithm.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06145",
        "abstract url": "https://arxiv.org/abs/2408.06145",
        "title": "Efficient and Scalable Point Cloud Generation with Sparse Point-Voxel Diffusion Models",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Voxel",
                "Point Cloud"
            ],
            [
                "Diffusion",
                "super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose a novel point cloud U-Net diffusion architecture for 3D generative modeling capable of generating high-quality and diverse 3D shapes while maintaining fast generation times. Our network employs a dual-branch architecture, combining the high-resolution representations of points with the computational efficiency of sparse voxels. Our fastest variant outperforms all non-diffusion generative approaches on unconditional shape generation, the most popular benchmark for evaluating point cloud generative models, while our largest model achieves state-of-the-art results among diffusion methods, with a runtime approximately 70% of the previously state-of-the-art PVD. Beyond unconditional generation, we perform extensive evaluations, including conditional generation on all categories of ShapeNet, demonstrating the scalability of our model to larger datasets, and implicit generation which allows our network to produce high quality point clouds on fewer timesteps, further decreasing the generation time. Finally, we evaluate the architecture's performance in point cloud completion and super-resolution. Our model excels in all tasks, establishing it as a state-of-the-art diffusion U-Net for point cloud generative modeling. The code is publicly available at https://github.com/JohnRomanelis/SPVD.git.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06152",
        "abstract url": "https://arxiv.org/abs/2408.06152",
        "title": "Palantir: Towards Efficient Super Resolution for Ultra-high-definition Live Streaming",
        "rating": "-1",
        "keywords": [
            [
                "Super Resolution"
            ],
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Neural enhancement through super-resolution deep neural networks opens up new possibilities for ultra-high-definition live streaming over existing encoding and networking infrastructure. Yet, the heavy SR DNN inference overhead leads to severe deployment challenges. To reduce the overhead, existing systems propose to apply DNN-based SR only on selected anchor frames while upscaling non-anchor frames via the lightweight reusing-based SR approach. However, frame-level scheduling is coarse-grained and fails to deliver optimal efficiency. In this work, we propose Palantir, the first neural-enhanced UHD live streaming system with fine-grained patch-level scheduling. In the presented solutions, two novel techniques are incorporated to make good scheduling decisions for inference overhead optimization and reduce the scheduling latency. Firstly, under the guidance of our pioneering and theoretical analysis, Palantir constructs a directed acyclic graph (DAG) for lightweight yet accurate quality estimation under any possible anchor patch set. Secondly, to further optimize the scheduling latency, Palantir improves parallelizability by refactoring the computation subprocedure of the estimation process into a sparse matrix-matrix multiplication operation. The evaluation results suggest that Palantir incurs a negligible scheduling latency accounting for less than 5.7% of the end-to-end latency requirement. When compared to the state-of-the-art real-time frame-level scheduling strategy, Palantir reduces the energy overhead of SR-integrated mobile clients by 38.1% at most (and 22.4% on average) and the monetary costs of cloud-based SR by 80.1% at most (and 38.4% on average).",
        "subjects": [
            "cs.MM",
            "cs.AI",
            "cs.CV",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06157",
        "abstract url": "https://arxiv.org/abs/2408.06157",
        "title": "Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent 3D novel view synthesis (NVS) methods are limited to single-object-centric scenes generated from new viewpoints and struggle with complex environments. They often require extensive 3D data for training, lacking generalization beyond training distribution. Conversely, 3D-free methods can generate text-controlled views of complex, in-the-wild scenes using a pretrained stable diffusion model without tedious fine-tuning, but lack camera control. In this paper, we introduce HawkI++, a method capable of generating camera-controlled viewpoints from a single input image. HawkI++ excels in handling complex and diverse scenes without additional 3D data or extensive training. It leverages widely available pretrained NVS models for weak guidance, integrating this knowledge into a 3D-free view synthesis approach to achieve the desired results efficiently. Our experimental results demonstrate that HawkI++ outperforms existing models in both qualitative and quantitative evaluations, providing high-fidelity and consistent novel view synthesis at desired camera angles across a wide variety of scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 7 figures"
    },
    {
        "paper id": "2408.06163",
        "abstract url": "https://arxiv.org/abs/2408.06163",
        "title": "ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "X-ray",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Dual-energy computed tomography (DECT) has been widely used to obtain quantitative elemental composition of imaged subjects for personalized and precise medical diagnosis. Compared with existing high-end DECT leveraging advanced X-ray source and/or detector technologies, the use of the sequentially-scanning data acquisition scheme to implement DECT may make broader impact on clinical practice because this scheme requires no specialized hardware designs. However, since the concentration of iodinated contrast agent in the imaged subject varies over time, sequentially-scanned data sets acquired at two tube potentials are temporally inconsistent. As existing material decomposition approaches for DECT assume that the data sets acquired at two tube potentials are temporally consistent, the violation of this assumption results in inaccurate quantification accuracy of iodine concentration. In this work, we developed a technique to achieve sequentially-scanning DECT imaging using high temporal resolution image reconstruction and temporal extrapolation, ACCELERATION in short, to address the technical challenge induced by temporal inconsistency of sequentially-scanned data sets and improve iodine quantification accuracy in sequentially-scanning DECT. ACCELERATION has been validated and evaluated using numerical simulation data sets generated from clinical human subject exams. Results demonstrated the improvement of iodine quantification accuracy using ACCELERATION.",
        "subjects": [
            "physics.med-ph",
            "cs.AI",
            "cs.CV",
            "physics.ins-det"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06167",
        "abstract url": "https://arxiv.org/abs/2408.06167",
        "title": "Blind-Match: Efficient Homomorphic Encryption-Based 1:N Matching for Privacy-Preserving Biometric Identification",
        "rating": "-1",
        "keywords": [
            [
                "Biometric"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present Blind-Match, a novel biometric identification system that leverages homomorphic encryption (HE) for efficient and privacy-preserving 1:N matching. Blind-Match introduces a HE-optimized cosine similarity computation method, where the key idea is to divide the feature vector into smaller parts for processing rather than computing the entire vector at once. By optimizing the number of these parts, Blind-Match minimizes execution time while ensuring data privacy through HE. Blind-Match achieves superior performance compared to state-of-the-art methods across various biometric datasets. On the LFW face dataset, Blind-Match attains a 99.63% Rank-1 accuracy with a 128-dimensional feature vector, demonstrating its robustness in face recognition tasks. For fingerprint identification, Blind-Match achieves a remarkable 99.55% Rank-1 accuracy on the PolyU dataset, even with a compact 16-dimensional feature vector, significantly outperforming the state-of-the-art method, Blind-Touch, which achieves only 59.17%. Furthermore, Blind-Match showcases practical efficiency in large-scale biometric identification scenarios, such as Naver Cloud's FaceSign, by processing 6,144 biometric samples in 0.74 seconds using a 128-dimensional feature vector.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": "Accepted to CIKM 2024 (Applied Research Track)"
    },
    {
        "paper id": "2408.06196",
        "abstract url": "https://arxiv.org/abs/2408.06196",
        "title": "On Categories of Nested Conditions",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Nested conditions are used, among other things, as a graphical way to express first order formulas ruling the applicability of a graph transformation rule to a given match. In this paper, we propose (for the first time) a notion of structural morphism among nested conditions, consistent with the entailment of the corresponding formulas. This reveals a structural weakness of the existing definition of nested conditions, which we overcome by proposing a new notion of span-based nested conditions, embedding the original ones. We also introduce morphisms for the latter, showing that those form a richer structure by organising the various models in a number of categories suitably related by functors.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06223",
        "abstract url": "https://arxiv.org/abs/2408.06223",
        "title": "On Effects of Steering Latent Representation for Large Language Model Unlearning",
        "rating": "-1",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Representation Misdirection for Unlearning (RMU), which steers model representation in the intermediate layer to a target random representation, is an effective method for large language model (LLM) unlearning. Despite its high performance, the underlying cause and explanation remain underexplored. In this paper, we first theoretically demonstrate that steering forget representations in the intermediate layer reduces token confidence, causing LLMs to generate wrong or nonsense responses. Second, we investigate how the coefficient influences the alignment of forget-sample representations with the random direction and hint at the optimal coefficient values for effective unlearning across different network layers. Third, we show that RMU unlearned models are robust against adversarial jailbreak attacks. Last, our empirical analysis shows that RMU is less effective when applied to the middle and later layers in LLMs. To resolve this drawback, we propose Adaptive RMU -- a simple yet effective alternative method that makes unlearning effective with most layers. Extensive experiments demonstrate that Adaptive RMU significantly improves the unlearning performance compared to prior art while incurring no additional computational cost.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "15 pages, 5 figures, 8 tables"
    },
    {
        "paper id": "2408.06227",
        "abstract url": "https://arxiv.org/abs/2408.06227",
        "title": "FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks",
        "rating": "-1",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces FLEURS-R, a speech restoration applied version of the Few-shot Learning Evaluation of Universal Representations of Speech (FLEURS) corpus. FLEURS-R maintains an N-way parallel speech corpus in 102 languages as FLEURS, with improved audio quality and fidelity by applying the speech restoration model Miipher. The aim of FLEURS-R is to advance speech technology in more languages and catalyze research including text-to-speech (TTS) and other speech generation tasks in low-resource languages. Comprehensive evaluations with the restored speech and TTS baseline models trained from the new corpus show that the new corpus obtained significantly improved speech quality while maintaining the semantic contents of the speech. The corpus is publicly released via Hugging Face.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06235",
        "abstract url": "https://arxiv.org/abs/2408.06235",
        "title": "Correlation Weighted Prototype-based Self-Supervised One-Shot Segmentation of Medical Images",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "CT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical image segmentation is one of the domains where sufficient annotated data is not available. This necessitates the application of low-data frameworks like few-shot learning. Contemporary prototype-based frameworks often do not account for the variation in features within the support and query images, giving rise to a large variance in prototype alignment. In this work, we adopt a prototype-based self-supervised one-way one-shot learning framework using pseudo-labels generated from superpixels to learn the semantic segmentation task itself. We use a correlation-based probability score to generate a dynamic prototype for each query pixel from the bag of prototypes obtained from the support feature map. This weighting scheme helps to give a higher weightage to contextually related prototypes. We also propose a quadrant masking strategy in the downstream segmentation task by utilizing prior domain information to discard unwanted false positives. We present extensive experimentations and evaluations on abdominal CT and MR datasets to show that the proposed simple but potent framework performs at par with the state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ICPR 2024"
    },
    {
        "paper id": "2408.06244",
        "abstract url": "https://arxiv.org/abs/2408.06244",
        "title": "3D Reconstruction of Protein Structures from Multi-view AFM Images using Neural Radiance Fields (NeRFs)",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in deep learning for predicting 3D protein structures have shown promise, particularly when leveraging inputs like protein sequences and Cryo-Electron microscopy (Cryo-EM) images. However, these techniques often fall short when predicting the structures of protein complexes (PCs), which involve multiple proteins. In our study, we investigate using atomic force microscopy (AFM) combined with deep learning to predict the 3D structures of PCs. AFM generates height maps that depict the PCs in various random orientations, providing a rich information for training a neural network to predict the 3D structures. We then employ the pre-trained UpFusion model (which utilizes a conditional diffusion model for synthesizing novel views) to train an instance-specific NeRF model for 3D reconstruction. The performance of UpFusion is evaluated through zero-shot predictions of 3D protein structures using AFM images. The challenge, however, lies in the time-intensive and impractical nature of collecting actual AFM images. To address this, we use a virtual AFM imaging process that transforms a `PDB' protein file into multi-view 2D virtual AFM images via volume rendering techniques. We extensively validate the UpFusion architecture using both virtual and actual multi-view AFM images. Our results include a comparison of structures predicted with varying numbers of views and different sets of views. This novel approach holds significant potential for enhancing the accuracy of protein complex structure predictions with further fine-tuning of the UpFusion network.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06246",
        "abstract url": "https://arxiv.org/abs/2408.06246",
        "title": "Stable-BC: Controlling Covariate Shift with Stable Behavior Cloning",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Behavior cloning is a common imitation learning paradigm. Under behavior cloning the robot collects expert demonstrations, and then trains a policy to match the actions taken by the expert. This works well when the robot learner visits states where the expert has already demonstrated the correct action; but inevitably the robot will also encounter new states outside of its training dataset. If the robot learner takes the wrong action at these new states it could move farther from the training data, which in turn leads to increasingly incorrect actions and compounding errors. Existing works try to address this fundamental challenge by augmenting or enhancing the training data. By contrast, in our paper we develop the control theoretic properties of behavior cloned policies. Specifically, we consider the error dynamics between the system's current state and the states in the expert dataset. From the error dynamics we derive model-based and model-free conditions for stability: under these conditions the robot shapes its policy so that its current behavior converges towards example behaviors in the expert dataset. In practice, this results in Stable-BC, an easy to implement extension of standard behavior cloning that is provably robust to covariate shift. We demonstrate the effectiveness of our algorithm in simulations with interactive, nonlinear, and visual environments. We also conduct experiments where a robot arm uses Stable-BC to play air hockey. See our website here: https://collab.me.vt.edu/Stable-BC/",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06265",
        "abstract url": "https://arxiv.org/abs/2408.06265",
        "title": "EyeSight Hand: Design of a Fully-Actuated Dexterous Robot Hand with Integrated Vision-Based Tactile Sensors and Compliant Actuation",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "In this work, we introduce the EyeSight Hand, a novel 7 degrees of freedom (DoF) humanoid hand featuring integrated vision-based tactile sensors tailored for enhanced whole-hand manipulation. Additionally, we introduce an actuation scheme centered around quasi-direct drive actuation to achieve human-like strength and speed while ensuring robustness for large-scale data collection. We evaluate the EyeSight Hand on three challenging tasks: bottle opening, plasticine cutting, and plate pick and place, which require a blend of complex manipulation, tool use, and precise force application. Imitation learning models trained on these tasks, with a novel vision dropout strategy, showcase the benefits of tactile feedback in enhancing task success rates. Our results reveal that the integration of tactile sensing dramatically improves task performance, underscoring the critical role of tactile information in dexterous manipulation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06272",
        "abstract url": "https://arxiv.org/abs/2408.06272",
        "title": "A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution",
        "rating": "-1",
        "keywords": [
            [
                "Attack"
            ]
        ],
        "abstract": "In the constantly evolving field of cybersecurity, it is imperative for analysts to stay abreast of the latest attack trends and pertinent information that aids in the investigation and attribution of cyber-attacks. In this work, we introduce the first question-answering (QA) model and its application that provides information to the cybersecurity experts about cyber-attacks investigations and attribution. Our QA model is based on Retrieval Augmented Generation (RAG) techniques together with a Large Language Model (LLM) and provides answers to the users' queries based on either our knowledge base (KB) that contains curated information about cyber-attacks investigations and attribution or on outside resources provided by the users. We have tested and evaluated our QA model with various types of questions, including KB-based, metadata-based, specific documents from the KB, and external sources-based questions. We compared the answers for KB-based questions with those from OpenAI's GPT-3.5 and the latest GPT-4o LLMs. Our proposed QA model outperforms OpenAI's GPT models by providing the source of the answers and overcoming the hallucination limitations of the GPT models, which is critical for cyber-attack investigation and attribution. Additionally, our analysis showed that when the RAG QA model is given few-shot examples rather than zero-shot instructions, it generates better answers compared to cases where no examples are supplied in addition to the query.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted at SECAI 2024 (ESORICS 2024)"
    },
    {
        "paper id": "2408.06276",
        "abstract url": "https://arxiv.org/abs/2408.06276",
        "title": "Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation",
        "rating": "-1",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks, generating significant interest in their application to recommendation systems. However, existing methods have not fully capitalized on the potential of LLMs, often constrained by limited input information or failing to fully utilize their advanced reasoning capabilities. To address these limitations, we introduce EXP3RT, a novel LLM-based recommender designed to leverage rich preference information contained in user and item reviews. EXP3RT is basically fine-tuned through distillation from a teacher LLM to perform three key tasks in order: EXP3RT first extracts and encapsulates essential subjective preferences from raw reviews, aggregates and summarizes them according to specific criteria to create user and item profiles. It then generates detailed step-by-step reasoning followed by predicted rating, i.e., reasoning-enhanced rating prediction, by considering both subjective and objective information from user/item profiles and item descriptions. This personalized preference reasoning from EXP3RT enhances rating prediction accuracy and also provides faithful and reasonable explanations for recommendation. Extensive experiments show that EXP3RT outperforms existing methods on both rating prediction and candidate item reranking for top-k recommendation, while significantly enhancing the explainability of recommendation systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06285",
        "abstract url": "https://arxiv.org/abs/2408.06285",
        "title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare",
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Medical dialogue systems (MDS) enhance patient-physician communication, improve healthcare accessibility, and reduce costs. However, acquiring suitable data to train these systems poses significant challenges. Privacy concerns prevent the use of real conversations, necessitating synthetic alternatives. Synthetic dialogue generation from publicly available clinical notes offers a promising solution to this issue, providing realistic data while safeguarding privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot prompting and a feedback loop to generate and refine high-quality synthetic dialogues. The feedback consists of weighted evaluation scores for similarity and extractiveness. The iterative process ensures dialogues meet predefined thresholds, achieving superior extractiveness as a result of the feedback loop. Additionally, evaluation shows that the generated dialogues excel in factuality metric compared to the baselines and has comparable diversity scores with GPT4.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06308",
        "abstract url": "https://arxiv.org/abs/2408.06308",
        "title": "Dynamic Traffic Assignment for Public Transport with Vehicle Capacities",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "Traffic assignment is a core component of many urban transport planning tools. It is used to determine how traffic is distributed over a transportation network. We study the task of computing traffic assignments for public transport: Given a public transit network, a timetable, vehicle capacities and a demand (i.e. a list of passengers, each with an associated origin, destination, and departure time), the goal is to predict the resulting passenger flow and the corresponding load of each vehicle. Microscopic stochastic simulation of individual passengers is a standard, but computationally expensive approach. Briem et al. (2017) have shown that a clever adaptation of the Connection Scan Algorithm (CSA) can lead to highly efficient traffic assignment algorithms, but ignores vehicle capacities, resulting in overcrowded vehicles. Taking their work as a starting point, we here propose a new and extended model that guarantees capacity-feasible assignments and incorporates dynamic network congestion effects such as crowded vehicles, denied boarding, and dwell time delays. Moreover, we also incorporate learning and adaptation of individual passengers based on their experience with the network. Applications include studying the evolution of perceived travel times as a result of adaptation, the impact of an increase in capacity, or network effects due to changes in the timetable such as the addition or the removal of a service or a whole line. The proposed framework has been experimentally evaluated with public transport networks of G\u00f6ttingen and Stuttgart (Germany). The simulation proves to be highly efficient. On a standard PC the computation of a traffic assignment takes just a few seconds per simulation day.",
        "subjects": [
            "cs.DS",
            "cs.DM"
        ],
        "comment": "Short version accepted at ATMOS 2024"
    },
    {
        "paper id": "2408.06324",
        "abstract url": "https://arxiv.org/abs/2408.06324",
        "title": "Online Vehicle Routing with Pickups and Deliveries under Time-Dependent Travel-Time Constraints",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "The Vehicle Routing Problem with pickups, deliveries and spatiotemporal service constraints ($VRPPDSTC$) is a quite challenging algorithmic problem that can be dealt with in either an offline or an online fashion. In this work, we focus on a generalization, called $VRPPDSTCtd$, in which the travel-time metric is \\emph{time-dependent}: the traversal-time per road segment (represented as a directed arc) is determined by some function of the departure-time from its tail towards its head. Time-dependence makes things much more complicated, even for the simpler problem of computing earliest-arrival-time paths which is a crucial subroutine to be solved (numerous times) by $VRPPDSTCtd$ schedulers. We propose two \\emph{online} schedulers of requests to workers, one which is a time-dependent variant of the classical Plain-Insertion heuristic, and an extension of it trying to digest some sort of forecasts for future demands for service. We enrich these two online schedulers with two additional heuristics, one targeting for distance-balanced assignments of work loads to the workers and another that makes local-search-improvements to the produced solutions. We conduct a careful experimental evaluation of the proposed algorithms on a real-world instance, with or without these heuristics, and compare their quality with human-curated assignments provided by professional experts (human operators at actual pickup-and-delivery control centers), and also with feasible solutions constructed from a relaxed MILP formulation of $VRPPDSTCtd$, which is also introduced in this paper. Our findings are quite encouraging, demonstrating that the proposed algorithms produce solutions which (i) are significant improvements over the human-curated assignments, and (ii) have overall quality pretty close to that of the (extremely time-consuming) solutions provided by an exact solver for the MILP formulation.",
        "subjects": [
            "cs.CE",
            "cs.DS"
        ],
        "comment": "25 pages, extended version of the ATMOS 2024 accepted paper"
    },
    {
        "paper id": "2408.06327",
        "abstract url": "https://arxiv.org/abs/2408.06327",
        "title": "VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Large Multimodal Models (LMMs) have ushered in a new era in artificial intelligence, merging capabilities in both language and vision to form highly capable Visual Foundation Agents. These agents are postulated to excel across a myriad of tasks, potentially approaching general artificial intelligence. However, existing benchmarks fail to sufficiently challenge or showcase the full potential of LMMs in complex, real-world environments. To address this gap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering benchmark specifically designed to train and evaluate LMMs as visual foundation agents across diverse scenarios, including Embodied, Graphical User Interface, and Visual Design, with tasks formulated to probe the depth of LMMs' understanding and interaction capabilities. Through rigorous testing across nine proprietary LMM APIs and eight open models, we demonstrate the considerable yet still developing agent capabilities of these models. Additionally, VAB constructs a trajectory training set constructed through hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and Human Demonstrations, promoting substantial performance improvements in LMMs through behavior cloning. Our work not only aims to benchmark existing models but also provides a solid foundation for future development into visual foundation agents. Code, train \\& test data, and part of fine-tuned open LMMs are available at \\url{https://github.com/THUDM/VisualAgentBench}.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06328",
        "abstract url": "https://arxiv.org/abs/2408.06328",
        "title": "HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Moving object segmentation (MOS) using a 3D light detection and ranging (LiDAR) sensor is crucial for scene understanding and identification of moving objects. Despite the availability of various types of 3D LiDAR sensors in the market, MOS research still predominantly focuses on 3D point clouds from mechanically spinning omnidirectional LiDAR sensors. Thus, we are, for example, lacking a dataset with MOS labels for point clouds from solid-state LiDAR sensors which have irregular scanning patterns. In this paper, we present a labeled dataset, called \\textit{HeLiMOS}, that enables to test MOS approaches on four heterogeneous LiDAR sensors, including two solid-state LiDAR sensors. Furthermore, we introduce a novel automatic labeling method to substantially reduce the labeling effort required from human annotators. To this end, our framework exploits an instance-aware static map building approach and tracking-based false label filtering. Finally, we provide experimental results regarding the performance of commonly used state-of-the-art MOS approaches on HeLiMOS that suggest a new direction for a sensor-agnostic MOS, which generally works regardless of the type of LiDAR sensors used to capture 3D point clouds. Our dataset is available at https://sites.google.com/view/helimos.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst. (IROS) 2024"
    },
    {
        "paper id": "2408.06336",
        "abstract url": "https://arxiv.org/abs/2408.06336",
        "title": "Moo-ving Beyond Tradition: Revolutionizing Cattle Behavioural Phenotyping with Pose Estimation Techniques",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The cattle industry has been a major contributor to the economy of many countries, including the US and Canada. The integration of Artificial Intelligence (AI) has revolutionized this sector, mirroring its transformative impact across all industries by enabling scalable and automated monitoring and intervention practices. AI has also introduced tools and methods that automate many tasks previously performed by human labor with the help of computer vision, including health inspections. Among these methods, pose estimation has a special place; pose estimation is the process of finding the position of joints in an image of animals. Analyzing the pose of animal subjects enables precise identification and tracking of the animal's movement and the movements of its body parts. By summarizing the video and imagery data into movement and joint location using pose estimation and then analyzing this information, we can address the scalability challenge in cattle management, focusing on health monitoring, behavioural phenotyping and welfare concerns. Our study reviews recent advancements in pose estimation methodologies, their applicability in improving the cattle industry, existing challenges, and gaps in this field. Furthermore, we propose an initiative to enhance open science frameworks within this field of study by launching a platform designed to connect industry and academia.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06423",
        "abstract url": "https://arxiv.org/abs/2408.06423",
        "title": "Evaluating Language Models on Entity Disambiguation in Tables",
        "rating": "-1",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Tables are crucial containers of information, but understanding their meaning may be challenging. Indeed, recently, there has been a focus on Semantic Table Interpretation (STI), i.e., the task that involves the semantic annotation of tabular data to disambiguate their meaning. Over the years, there has been a surge in interest in data-driven approaches based on deep learning that have increasingly been combined with heuristic-based approaches. In the last period, the advent of Large Language Models (LLMs) has led to a new category of approaches for table annotation. The interest in this research field, characterised by multiple challenges, has led to a proliferation of approaches employing different techniques. However, these approaches have not been consistently evaluated on a common ground, making evaluation and comparison difficult. This work proposes an extensive evaluation of four state-of-the-art (SOTA) approaches - Alligator (formerly s-elBat), Dagobah, TURL, and TableLlama; the first two belong to the family of heuristic-based algorithms, while the others are respectively encoder-only and decoder-only LLMs. The primary objective is to measure the ability of these approaches to solve the entity disambiguation task, with the ultimate aim of charting new research paths in the field.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06447",
        "abstract url": "https://arxiv.org/abs/2408.06447",
        "title": "S-SAM: SVD-based Fine-Tuning of Segment Anything Model for Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "CT",
                "x-ray",
                "endoscopic"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical image segmentation has been traditionally approached by training or fine-tuning the entire model to cater to any new modality or dataset. However, this approach often requires tuning a large number of parameters during training. With the introduction of the Segment Anything Model (SAM) for prompted segmentation of natural images, many efforts have been made towards adapting it efficiently for medical imaging, thus reducing the training time and resources. However, these methods still require expert annotations for every image in the form of point prompts or bounding box prompts during training and inference, making it tedious to employ them in practice. In this paper, we propose an adaptation technique, called S-SAM, that only trains parameters equal to 0.4% of SAM's parameters and at the same time uses simply the label names as prompts for producing precise masks. This not only makes tuning SAM more efficient than the existing adaptation methods but also removes the burden of providing expert prompts. We call this modified version S-SAM and evaluate it on five different modalities including endoscopic images, x-ray, ultrasound, CT, and histology images. Our experiments show that S-SAM outperforms state-of-the-art methods as well as existing SAM adaptation methods while tuning a significantly less number of parameters. We release the code for S-SAM at https://github.com/JayParanjape/SVDSAM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in MICCAI 2024"
    },
    {
        "paper id": "2408.06457",
        "abstract url": "https://arxiv.org/abs/2408.06457",
        "title": "Advanced Vision Transformers and Open-Set Learning for Robust Mosquito Classification: A Novel Approach to Entomological Studies",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Mosquito-related diseases pose a significant threat to global public health, necessitating efficient and accurate mosquito classification for effective surveillance and control. This work presents an innovative approach to mosquito classification by leveraging state-of-the-art vision transformers and open-set learning techniques. A novel framework has been introduced that integrates Transformer-based deep learning models with comprehensive data augmentation and preprocessing methods, enabling robust and precise identification of ten mosquito species. The Swin Transformer model achieves the best performance for traditional closed-set learning with 99.80\\% accuracy and 0.998 F1 score. The lightweight MobileViT technique attains an almost similar accuracy of 98.90\\% with significantly reduced parameters and model complexities. Next, the applied deep learning models' adaptability and generalizability in a static environment have been enhanced by using new classes of data samples during the inference stage that have not been included in the training set. The proposed framework's ability to handle unseen classes like insects similar to mosquitoes, even humans, through open-set learning further enhances its practical applicability employing the OpenMax technique and Weibull distribution. The traditional CNN model, Xception, outperforms the latest transformer with higher accuracy and F1 score for open-set learning. The study's findings highlight the transformative potential of advanced deep-learning architectures in entomology, providing a strong groundwork for future research and development in mosquito surveillance and vector control. The implications of this work extend beyond mosquito classification, offering valuable insights for broader ecological and environmental monitoring applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages, 15 figures"
    },
    {
        "paper id": "2408.06459",
        "abstract url": "https://arxiv.org/abs/2408.06459",
        "title": "InfLocNet: Enhanced Lung Infection Localization and Disease Detection from Chest X-Ray Images Using Lightweight Deep Learning",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "X-Ray",
                "Disease",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In recent years, the integration of deep learning techniques into medical imaging has revolutionized the diagnosis and treatment of lung diseases, particularly in the context of COVID-19 and pneumonia. This paper presents a novel, lightweight deep learning based segmentation-classification network designed to enhance the detection and localization of lung infections using chest X-ray images. By leveraging the power of transfer learning with pre-trained VGG-16 weights, our model achieves robust performance even with limited training data. The architecture incorporates refined skip connections within the UNet++ framework, reducing semantic gaps and improving precision in segmentation tasks. Additionally, a classification module is integrated at the end of the encoder block, enabling simultaneous classification and segmentation. This dual functionality enhances the model's versatility, providing comprehensive diagnostic insights while optimizing computational efficiency. Experimental results demonstrate that our proposed lightweight network outperforms existing methods in terms of accuracy and computational requirements, making it a viable solution for real-time and resource constrained medical imaging applications. Furthermore, the streamlined design facilitates easier hyperparameter tuning and deployment on edge devices. This work underscores the potential of advanced deep learning architectures in improving clinical outcomes through precise and efficient medical image analysis. Our model achieved remarkable results with an Intersection over Union (IoU) of 93.59% and a Dice Similarity Coefficient (DSC) of 97.61% in lung area segmentation, and an IoU of 97.67% and a DSC of 87.61% for infection region localization. Additionally, it demonstrated high accuracy of 93.86% and sensitivity of 89.55% in detecting chest diseases, highlighting its efficacy and reliability.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06467",
        "abstract url": "https://arxiv.org/abs/2408.06467",
        "title": "Generalization Enhancement Strategies to Enable Cross-year Cropland Mapping with Convolutional Neural Networks Trained Using Historical Samples",
        "rating": "-1",
        "keywords": [
            [
                "satellite",
                "agricultural"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The accuracy of mapping agricultural fields across large areas is steadily improving with high-resolution satellite imagery and deep learning (DL) models, even in regions where fields are small and geometrically irregular. However, developing effective DL models often requires large, expensive label datasets, typically available only for specific years or locations. This limits the ability to create annual maps essential for agricultural monitoring, as domain shifts occur between years and regions due to changes in farming practices and environmental conditions. The challenge is to design a model flexible enough to account for these shifts without needing yearly labels. While domain adaptation techniques or semi-supervised training are common solutions, we explored enhancing the model's generalization power. Our results indicate that a holistic approach is essential, combining methods to improve generalization. Specifically, using an area-based loss function, such as Tversky-focal loss (TFL), significantly improved predictions across multiple years. The use of different augmentation techniques helped to encode different types of invariance, particularly photometric augmentations encoded invariance to brightness changes, though they increased false positives. The combination of photometric augmentation, TFL loss, and MC-dropout produced the best results, although dropout alone led to more false negatives in subsequent year predictions. Additionally, the choice of input normalization had a significant impact, with the best results obtained when statistics were calculated either locally or across the entire dataset over all bands (lab and gab). We developed a workflow that enabled a U-Net model to generate effective multi-year crop maps over large areas. Our code, available at: https://github.com/agroimpacts/cnn-generalization-enhancement, will be regularly updated with improvements.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06476",
        "abstract url": "https://arxiv.org/abs/2408.06476",
        "title": "Passivity-Based Gain-Scheduled Control with Scheduling Matrices",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This paper considers gain-scheduling of very strictly passive (VSP) subcontrollers using scheduling matrices. The use of scheduling matrices, over scalar scheduling signals, realizes greater design freedom, which in turn can improve closed-loop performance. The form and properties of the scheduling matrices such that the overall gain-scheduled controller is VSP are explicitly discussed. The proposed gain-scheduled VSP controller is used to control a rigid two-link robot subject to model uncertainty where robust input-output stability is assured via the passivity theorem. Numerical simulation results highlight the greater design freedom, resulting in improved performance, when scheduling matrices are used over scalar scheduled signals.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "To be published in IEEE Conference on Control Technology and Applications (CCTA) 2024"
    },
    {
        "paper id": "2408.06489",
        "abstract url": "https://arxiv.org/abs/2408.06489",
        "title": "Path Partitions of Phylogenetic Networks",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "In phylogenetics, evolution is traditionally represented in a tree-like manner. However, phylogenetic networks can be more appropriate for representing evolutionary events such as hybridization, horizontal gene transfer, and others. In particular, the class of forest-based networks was recently introduced to represent introgression, in which genes are swapped between between species. A network is forest-based if it can be obtained by adding arcs to a collection of trees, so that the endpoints of the new arcs are in different trees. This contrasts with so-called tree-based networks, which are formed by adding arcs within a single tree. We are interested in the computational complexity of recognizing forest-based networks, which was recently left as an open problem by Huber et al. Forest-based networks coincide with directed acyclic graphs that can be partitioned into induced paths, each ending at a leaf of the original graph. Several types of path partitions have been studied in the graph theory literature, but to our knowledge this type of leaf induced path partition has not been considered before. The study of forest-based networks in terms of these partitions allows us to establish closer relationships between phylogenetics and algorithmic graph theory, and to provide answers to problems in both fields. We show that deciding whether a network is forest-based is NP-complete, even on input networks that are tree-based, binary, and have only three leaves. This shows that partitioning a directed acyclic graph into three induced paths is NP-complete, answering a recent question of Ferneau et al. We then show that the problem is polynomial-time solvable on binary networks with two leaves and on the class of orchards. Finally, for undirected graphs, we introduce unrooted forest-based networks and provide hardness results for this class as well.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06500",
        "abstract url": "https://arxiv.org/abs/2408.06500",
        "title": "Music2Latent: Consistency Autoencoders for Latent Audio Compression",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Efficient audio representations in a compressed continuous latent space are critical for generative audio modeling and Music Information Retrieval (MIR) tasks. However, some existing audio autoencoders have limitations, such as multi-stage training procedures, slow iterative sampling, or low reconstruction quality. We introduce Music2Latent, an audio autoencoder that overcomes these limitations by leveraging consistency models. Music2Latent encodes samples into a compressed continuous latent space in a single end-to-end training process while enabling high-fidelity single-step reconstruction. Key innovations include conditioning the consistency model on upsampled encoder outputs at all levels through cross connections, using frequency-wise self-attention to capture long-range frequency dependencies, and employing frequency-wise learned scaling to handle varying value distributions across frequencies at different noise levels. We demonstrate that Music2Latent outperforms existing continuous audio autoencoders in sound quality and reconstruction accuracy while achieving competitive performance on downstream MIR tasks using its latent representations. To our knowledge, this represents the first successful attempt at training an end-to-end consistency autoencoder model.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Accepted to ISMIR 2024"
    },
    {
        "paper id": "2408.06518",
        "abstract url": "https://arxiv.org/abs/2408.06518",
        "title": "Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models",
        "rating": "-1",
        "keywords": [
            [
                "diagnosing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite their wide adoption, the biases and unintended behaviors of language models remain poorly understood. In this paper, we identify and characterize a phenomenon never discussed before, which we call semantic leakage, where models leak irrelevant information from the prompt into the generation in unexpected ways. We propose an evaluation setting to detect semantic leakage both by humans and automatically, curate a diverse test suite for diagnosing this behavior, and measure significant semantic leakage in 13 flagship models. We also show that models exhibit semantic leakage in languages besides English and across different settings and generation scenarios. This discovery highlights yet another type of bias in language models that affects their generation patterns and behavior.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06520",
        "abstract url": "https://arxiv.org/abs/2408.06520",
        "title": "Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities in various language tasks, making them promising candidates for decision-making in robotics. Inspired by Hierarchical Reinforcement Learning (HRL), we propose Hierarchical in-Context Reinforcement Learning (HCRL), a novel framework that decomposes complex tasks into sub-tasks using an LLM-based high-level policy, in which a complex task is decomposed into sub-tasks by a high-level policy on-the-fly. The sub-tasks, defined by goals, are assigned to the low-level policy to complete. Once the LLM agent determines that the goal is finished, a new goal will be proposed. To improve the agent's performance in multi-episode execution, we propose Hindsight Modular Reflection (HMR), where, instead of reflecting on the full trajectory, we replace the task objective with intermediate goals and let the agent reflect on shorter trajectories to improve reflection efficiency. We evaluate the decision-making ability of the proposed HCRL in three benchmark environments--ALFWorld, Webshop, and HotpotQA. Results show that HCRL can achieve 9%, 42%, and 10% performance improvement in 5 episodes of execution over strong in-context learning baselines.",
        "subjects": [
            "cs.RO",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06522",
        "abstract url": "https://arxiv.org/abs/2408.06522",
        "title": "DriveStats: a Mobile Platform to Frame Effective Sustainable Driving Displays",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Phone applications to track vehicle information have become more common place, providing insights into fuel consumption, vehicle status, and sustainable driving behaviorsHowever, to test what resonates with drivers without deep vehicle integration requires a proper research instrument. We built DriveStats: a reusable library (and encompassing an mobile app) to monitor driving trips and display related information. By providing estimated cost/emission reductions in a goal directed framework, we demonstrate how information utility can increase over the course of a 10 day diary study with a group of North American participants. Participants were initially interested in monetary savings reported increased utility for emissions-related information with increased app usage and resulted in self-reported sustainable behavior change. The DriveStats package can be used as a research probe for a plurality of mobility studies (driving, cycling, walking, etc.) for supporting mobile transportation research.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06577",
        "abstract url": "https://arxiv.org/abs/2408.06577",
        "title": "Prompt Tuning as User Inherent Profile Inference Machine",
        "rating": "-1",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "recommendation"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have exhibited significant promise in recommender systems by empowering user profiles with their extensive world knowledge and superior reasoning capabilities. However, LLMs face challenges like unstable instruction compliance, modality gaps, and high inference latency, leading to textual noise and limiting their effectiveness in recommender systems. To address these challenges, we propose UserIP-Tuning, which uses prompt-tuning to infer user profiles. It integrates the causal relationship between user profiles and behavior sequences into LLMs' prompts. And employs expectation maximization to infer the embedded latent profile, minimizing textual noise by fixing the prompt template. Furthermore, A profile quantization codebook bridges the modality gap by categorizing profile embeddings into collaborative IDs, which are pre-stored for online deployment. This improves time efficiency and reduces memory usage. Experiments on four public datasets show that UserIP-Tuning outperforms state-of-the-art recommendation algorithms. Additional tests and case studies confirm its effectiveness, robustness, and transferability.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06583",
        "abstract url": "https://arxiv.org/abs/2408.06583",
        "title": "An Event Structure-aware Generative Model for Biomedical Event Extraction",
        "rating": "-1",
        "keywords": [
            [
                "Biomedical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Biomedical Event Extraction (BEE) is a challenging task that involves modeling complex relationships between fine-grained entities in biomedical text. BEE has traditionally been formulated as a classification problem. With the recent technological advancements in large language models (LLMs), generation-based models that cast event extraction as a sequence generation problem have attracted much attention from the NLP research communities. However, current generative models often overlook the importance of cross-instance information from complex event structures such as nested events and overlapping events, which contribute quite significantly in the benchmark datasets. In this paper, we propose an event structure-aware generative model called GenBEE, which can capture complex event structures in biomedical text for biomedical event extraction. In particular, GenBEE constructs event prompts that distill knowledge from LLMs for incorporating both label semantics and argument dependency relationships into the proposed model. In addition, GenBEE also generates prefixes with event structural prompts to incorporate structural features for improving the model's overall performance. We have evaluated the proposed GenBEE model on three widely used biomedical event extraction benchmark datasets, namely MLEE, GE11, and PHEE. Experimental results show that GenBEE has achieved state-of-the-art performance on the MLEE and GE11 datasets, and achieved competitive results when compared to the state-of-the-art classification-based models on the PHEE dataset.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 4 figures, 6 tables"
    },
    {
        "paper id": "2408.06598",
        "abstract url": "https://arxiv.org/abs/2408.06598",
        "title": "A Perspective on Large Language Models, Intelligent Machines, and Knowledge Acquisition",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are known for their remarkable ability to generate synthesized 'knowledge', such as text documents, music, images, etc. However, there is a huge gap between LLM's and human capabilities for understanding abstract concepts and reasoning. We discuss these issues in a larger philosophical context of human knowledge acquisition and the Turing test. In addition, we illustrate the limitations of LLMs by analyzing GPT-4 responses to questions ranging from science and math to common sense reasoning. These examples show that GPT-4 can often imitate human reasoning, even though it lacks understanding. However, LLM responses are synthesized from a large LLM model trained on all available data. In contrast, human understanding is based on a small number of abstract concepts. Based on this distinction, we discuss the impact of LLMs on acquisition of human knowledge and education.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06600",
        "abstract url": "https://arxiv.org/abs/2408.06600",
        "title": "Deep Inertia $L_p$ Half-Quadratic Splitting Unrolling Network for Sparse View CT Reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "CT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Sparse view computed tomography (CT) reconstruction poses a challenging ill-posed inverse problem, necessitating effective regularization techniques. In this letter, we employ $L_p$-norm ($0<p<1$) regularization to induce sparsity and introduce inertial steps, leading to the development of the inertial $L_p$-norm half-quadratic splitting algorithm. We rigorously prove the convergence of this algorithm. Furthermore, we leverage deep learning to initialize the conjugate gradient method, resulting in a deep unrolling network with theoretical guarantees. Our extensive numerical experiments demonstrate that our proposed algorithm surpasses existing methods, particularly excelling in fewer scanned views and complex noise conditions.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "This paper was accepted by IEEE Signal Processing Letters on July 28, 2024"
    },
    {
        "paper id": "2408.06608",
        "abstract url": "https://arxiv.org/abs/2408.06608",
        "title": "Potamoi: Accelerating Neural Rendering via a Unified Streaming Architecture",
        "rating": "-1",
        "keywords": [
            [
                "NeRF"
            ]
        ],
        "abstract": "Neural Radiance Field (NeRF) has emerged as a promising alternative for photorealistic rendering. Despite recent algorithmic advancements, achieving real-time performance on today's resource-constrained devices remains challenging. In this paper, we identify the primary bottlenecks in current NeRF algorithms and introduce a unified algorithm-architecture co-design, Potamoi, designed to accommodate various NeRF algorithms. Specifically, we introduce a runtime system featuring a plug-and-play algorithm, SpaRW, which significantly reduces the per-frame computational workload and alleviates compute inefficiencies. Furthermore, our unified streaming pipeline coupled with customized hardware support effectively tames both SRAM and DRAM inefficiencies by minimizing repetitive DRAM access and completely eliminating SRAM bank conflicts. When evaluated against a baseline utilizing a dedicated DNN accelerator, our framework demonstrates a speed-up and energy reduction of 53.1$\\times$ and 67.7$\\times$, respectively, all while maintaining high visual quality with less than a 1.0 dB reduction in peak signal-to-noise ratio.",
        "subjects": [
            "cs.AR",
            "cs.GR"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2404.11852"
    },
    {
        "paper id": "2408.07020",
        "abstract url": "https://arxiv.org/abs/2408.07020",
        "title": "Source Separation of Multi-source Raw Music using a Residual Quantized Variational Autoencoder",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "I developed a neural audio codec model based on the residual quantized variational autoencoder architecture. I train the model on the Slakh2100 dataset, a standard dataset for musical source separation, composed of multi-track audio. The model can separate audio sources, achieving almost SoTA results with much less computing power. The code is publicly available at github.com/LeonardoBerti00/Source-Separation-of-Multi-source-Music-using-Residual-Quantizad-Variational-Autoencoder",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "cs.MM",
            "eess.AS"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2408.07096",
        "abstract url": "https://arxiv.org/abs/2408.07096",
        "title": "OFL-W3: A One-shot Federated Learning System on Web 3.0",
        "rating": "-1",
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "Federated Learning (FL) addresses the challenges posed by data silos, which arise from privacy, security regulations, and ownership concerns. Despite these barriers, FL enables these isolated data repositories to participate in collaborative learning without compromising privacy or security. Concurrently, the advancement of blockchain technology and decentralized applications (DApps) within Web 3.0 heralds a new era of transformative possibilities in web development. As such, incorporating FL into Web 3.0 paves the path for overcoming the limitations of data silos through collaborative learning. However, given the transaction speed constraints of core blockchains such as Ethereum (ETH) and the latency in smart contracts, employing one-shot FL, which minimizes client-server interactions in traditional FL to a single exchange, is considered more apt for Web 3.0 environments. This paper presents a practical one-shot FL system for Web 3.0, termed OFL-W3. OFL-W3 capitalizes on blockchain technology by utilizing smart contracts for managing transactions. Meanwhile, OFL-W3 utilizes the Inter-Planetary File System (IPFS) coupled with Flask communication, to facilitate backend server operations to use existing one-shot FL algorithms. With the integration of the incentive mechanism, OFL-W3 showcases an effective implementation of one-shot FL on Web 3.0, offering valuable insights and future directions for AI combined with Web 3.0 studies.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "VLDB 24 demo paper"
    },
    {
        "paper id": "2408.05933",
        "abstract url": "https://arxiv.org/abs/2408.05933",
        "title": "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the growing demand for offline PDF chatbots in automotive industrial production environments, optimizing the deployment of large language models (LLMs) in local, low-performance settings has become increasingly important. This study focuses on enhancing Retrieval-Augmented Generation (RAG) techniques for processing complex automotive industry documents using locally deployed Ollama models. Based on the Langchain framework, we propose a multi-dimensional optimization approach for Ollama's local RAG implementation. Our method addresses key challenges in automotive document processing, including multi-column layouts and technical specifications. We introduce improvements in PDF processing, retrieval mechanisms, and context compression, tailored to the unique characteristics of automotive industry documents. Additionally, we design custom classes supporting embedding pipelines and an agent supporting self-RAG based on LangGraph best practices. To evaluate our approach, we constructed a proprietary dataset comprising typical automotive industry documents, including technical reports and corporate regulations. We compared our optimized RAG model and self-RAG agent against a naive RAG baseline across three datasets: our automotive industry dataset, QReCC, and CoQA. Results demonstrate significant improvements in context precision, context recall, answer relevancy, and faithfulness, with particularly notable performance on the automotive industry dataset. Our optimization scheme provides an effective solution for deploying local RAG systems in the automotive sector, addressing the specific needs of PDF chatbots in industrial production environments. This research has important implications for advancing information processing and intelligent production in the automotive industry.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05992",
        "abstract url": "https://arxiv.org/abs/2408.05992",
        "title": "Transfer learning of state-based potential games for process optimization in decentralized manufacturing systems",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a novel transfer learning approach in state-based potential games (TL-SbPGs) for enhancing distributed self-optimization in manufacturing systems. The approach focuses on the practical relevant industrial setting where sharing and transferring gained knowledge among similar-behaved players improves the self-learning mechanism in large-scale systems. With TL-SbPGs, the gained knowledge can be reused by other players to optimize their policies, thereby improving the learning outcomes of the players and accelerating the learning process. To accomplish this goal, we develop transfer learning concepts and similarity criteria for players, which offer two distinct settings: (a) predefined similarities between players and (b) dynamically inferred similarities between players during training. We formally prove the applicability of the SbPG framework in transfer learning. Additionally, we introduce an efficient method to determine the optimal timing and weighting of the transfer learning procedure during the training phase. Through experiments on a laboratory-scale testbed, we demonstrate that TL-SbPGs significantly boost production efficiency while reducing power consumption of the production schedules while also outperforming native SbPGs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.GT"
        ],
        "comment": "This pre-print was submitted to Computers in Industry on May 02, 2024"
    },
    {
        "paper id": "2408.06042",
        "abstract url": "https://arxiv.org/abs/2408.06042",
        "title": "Understanding Byzantine Robustness in Federated Learning with A Black-box Server",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Federated learning (FL) becomes vulnerable to Byzantine attacks where some of participators tend to damage the utility or discourage the convergence of the learned model via sending their malicious model updates. Previous works propose to apply robust rules to aggregate updates from participators against different types of Byzantine attacks, while at the same time, attackers can further design advanced Byzantine attack algorithms targeting specific aggregation rule when it is known. In practice, FL systems can involve a black-box server that makes the adopted aggregation rule inaccessible to participants, which can naturally defend or weaken some Byzantine attacks. In this paper, we provide an in-depth understanding on the Byzantine robustness of the FL system with a black-box server. Our investigation demonstrates the improved Byzantine robustness of a black-box server employing a dynamic defense strategy. We provide both empirical evidence and theoretical analysis to reveal that the black-box server can mitigate the worst-case attack impact from a maximum level to an expectation level, which is attributed to the inherent inaccessibility and randomness offered by a black-box server.The source code is available at https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense to promote further research in the community.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "We have released code on https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense"
    },
    {
        "paper id": "2408.06067",
        "abstract url": "https://arxiv.org/abs/2408.06067",
        "title": "Don't You (Project Around Discs)? Neural Network Surrogate and Projected Gradient Descent for Calibrating an Intervertebral Disc Finite Element Model",
        "rating": "-1.5",
        "keywords": [
            [
                "diagnosing"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurate calibration of finite element (FE) models of human intervertebral discs (IVDs) is essential for their reliability and application in diagnosing and planning treatments for spinal conditions. Traditional calibration methods are computationally intensive, requiring iterative, derivative-free optimization algorithms that often take hours or days to converge. This study addresses these challenges by introducing a novel, efficient, and effective calibration method for an L4-L5 IVD FE model using a neural network (NN) surrogate. The NN surrogate predicts simulation outcomes with high accuracy, outperforming other machine learning models, and significantly reduces the computational cost associated with traditional FE simulations. Next, a Projected Gradient Descent (PGD) approach guided by gradients of the NN surrogate is proposed to efficiently calibrate FE models. Our method explicitly enforces feasibility with a projection step, thus maintaining material bounds throughout the optimization process. The proposed method is evaluated against state-of-the-art Genetic Algorithm (GA) and inverse model baselines on synthetic and in vitro experimental datasets. Our approach demonstrates superior performance on synthetic data, achieving a Mean Absolute Error (MAE) of 0.06 compared to the baselines' MAE of 0.18 and 0.54, respectively. On experimental specimens, our method outperforms the baseline in 5 out of 6 cases. Most importantly, our approach reduces calibration time to under three seconds, compared to up to 8 days per sample required by traditional calibration. Such efficiency paves the way for applying more complex FE models, enabling accurate patient-specific simulations and advancing spinal treatment planning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under submission. Project code: https://github.com/matanat/IVD-CalibNN/"
    },
    {
        "paper id": "2408.06121",
        "abstract url": "https://arxiv.org/abs/2408.06121",
        "title": "A Methodological Report on Anomaly Detection on Dynamic Knowledge Graphs",
        "rating": "-1.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we explore different approaches to anomaly detection on dynamic knowledge graphs, specifically in a microservices environment for Kubernetes applications. Our approach explores three dynamic knowledge graph representations: sequential data, one-hop graph structure, and two-hop graph structure, with each representation incorporating increasingly complex structural information. Each phase includes different machine learning and deep learning models. We empirically analyse their performance and propose an approach based on ensemble learning of these models. Our approach significantly outperforms the baseline on the ISWC 2024 Dynamic Knowledge Graph Anomaly Detection dataset, providing a robust solution for anomaly detection in dynamic complex data.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06139",
        "abstract url": "https://arxiv.org/abs/2408.06139",
        "title": "Curio: A Dataflow-Based Framework for Collaborative Urban Visual Analytics",
        "rating": "-1.5",
        "keywords": [
            [
                "grammar"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Over the past decade, several urban visual analytics systems and tools have been proposed to tackle a host of challenges faced by cities, in areas as diverse as transportation, weather, and real estate. Many of these tools have been designed through collaborations with urban experts, aiming to distill intricate urban analysis workflows into interactive visualizations and interfaces. However, the design, implementation, and practical use of these tools still rely on siloed approaches, resulting in bespoke applications that are difficult to reproduce and extend. At the design level, these tools undervalue rich data workflows from urban experts, typically treating them only as data providers and evaluators. At the implementation level, they lack interoperability with other technical frameworks. At the practical use level, they tend to be narrowly focused on specific fields, inadvertently creating barriers to cross-domain collaboration. To address these gaps, we present Curio, a framework for collaborative urban visual analytics. Curio uses a dataflow model with multiple abstraction levels (code, grammar, GUI elements) to facilitate collaboration across the design and implementation of visual analytics components. The framework allows experts to intertwine data preprocessing, management, and visualization stages while tracking the provenance of code and visualizations. In collaboration with urban experts, we evaluate Curio through a diverse set of usage scenarios targeting urban accessibility, urban microclimate, and sunlight access. These scenarios use different types of data and domain methodologies to illustrate Curio's flexibility in tackling pressing societal challenges. Curio is available at https://urbantk.org/curio.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": "Accepted at IEEE VIS 2024. Source code available at https://urbantk.org/curio"
    },
    {
        "paper id": "2408.06220",
        "abstract url": "https://arxiv.org/abs/2408.06220",
        "title": "A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring",
        "rating": "-1.5",
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a novel digital twin framework for predictive maintenance of long-term physical systems. Using monitoring tire health as an application, we show how the digital twin framework can be used to enhance automotive safety and efficiency, and how the technical challenges can be overcome using a three-step approach. Firstly, for managing the data complexity over a long operation span, we employ data reduction techniques to concisely represent physical tires using historical performance and usage data. Relying on these data, for fast real-time prediction, we train a transformer-based model offline on our concise dataset to predict future tire health over time, represented as Remaining Casing Potential (RCP). Based on our architecture, our model quantifies both epistemic and aleatoric uncertainty, providing reliable confidence intervals around predicted RCP. Secondly, to incorporate real-time data, we update the predictive model in the digital twin framework, ensuring its accuracy throughout its life span with the aid of hybrid modeling and the use of discrepancy function. Thirdly, to assist decision making in predictive maintenance, we implement a Tire State Decision Algorithm, which strategically determines the optimal timing for tire replacement based on RCP forecasted by our transformer model. This approach ensures our digital twin accurately predicts system health, continually refines its digital representation, and supports predictive maintenance decisions. Our framework effectively embodies a physical system, leveraging big data and machine learning for predictive maintenance, model updates, and decision-making.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "comment": "Paper accepted at ASME IDETC 2024, and fast-tracked for ASME Journal of Computing and Information Science in Engineering"
    },
    {
        "paper id": "2408.06261",
        "abstract url": "https://arxiv.org/abs/2408.06261",
        "title": "Open-Source Molecular Processing Pipeline for Generating Molecules",
        "rating": "-1.5",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Generative models for molecules have shown considerable promise for use in computational chemistry, but remain difficult to use for non-experts. For this reason, we introduce open-source infrastructure for easily building generative molecular models into the widely used DeepChem [Ramsundar et al., 2019] library with the aim of creating a robust and reusable molecular generation pipeline. In particular, we add high quality PyTorch [Paszke et al., 2019] implementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao and Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our implementations show strong performance comparable with past work [Kuznetsov and Polykovskiy, 2021, Cao and Kipf, 2022].",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.BM"
        ],
        "comment": "Presented at the 2024 Molecular Machine Learning Conference (MoML 2024)"
    },
    {
        "paper id": "2408.06291",
        "abstract url": "https://arxiv.org/abs/2408.06291",
        "title": "Mambular: A Sequential Model for Tabular Deep Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The analysis of tabular data has traditionally been dominated by gradient-boosted decision trees (GBDTs), known for their proficiency with mixed categorical and numerical features. However, recent deep learning innovations are challenging this dominance. We introduce Mambular, an adaptation of the Mamba architecture optimized for tabular data. We extensively benchmark Mambular against state-of-the-art models, including neural networks and tree-based methods, and demonstrate its competitive performance across diverse datasets. Additionally, we explore various adaptations of Mambular to understand its effectiveness for tabular data. We investigate different pooling strategies, feature interaction mechanisms, and bi-directional processing. Our analysis shows that interpreting features as a sequence and passing them through Mamba layers results in surprisingly performant models. The results highlight Mambulars potential as a versatile and powerful architecture for tabular data analysis, expanding the scope of deep learning applications in this domain. The source code is available at https://github.com/basf/mamba-tabular.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06316",
        "abstract url": "https://arxiv.org/abs/2408.06316",
        "title": "Body Transformer: Leveraging Robot Embodiment for Policy Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, the transformer architecture has become the de facto standard for machine learning algorithms applied to natural language processing and computer vision. Despite notable evidence of successful deployment of this architecture in the context of robot learning, we claim that vanilla transformers do not fully exploit the structure of the robot learning problem. Therefore, we propose Body Transformer (BoT), an architecture that leverages the robot embodiment by providing an inductive bias that guides the learning process. We represent the robot body as a graph of sensors and actuators, and rely on masked attention to pool information throughout the architecture. The resulting architecture outperforms the vanilla transformer, as well as the classical multilayer perceptron, in terms of task completion, scaling properties, and computational efficiency when representing either imitation or reinforcement learning policies. Additional material including the open-source code is available at https://sferrazza.cc/bot_site.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06341",
        "abstract url": "https://arxiv.org/abs/2408.06341",
        "title": "Is it a work or leisure travel? Applying text classification to identify work-related travel on social networks",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "In today's digital era, the use of Social Networks (SNs) and Location-Based SNs (LBSNs) has become integral for travelers seeking Points of Interest (POI) and sharing travel experiences. This trend is supported by the fact that a significant majority of American travelers utilize SNs during their trips. However, the abundance of information available on these platforms presents a challenge in identifying the best options. To address this issue, Recommender Systems (RS) are commonly employed to suggest POIs based on user history, with the integration of contextual information enhancing the quality of recommendations. Notably, incorporating user travel purpose, which is often overlooked but holds potential in characterizing travelers' behavior, can lead to more tailored recommendations. In this study, we propose a model to predict whether a trip is leisure or work-related, utilizing state-of-the-art Automatic Text Classification (ATC) models such as BERT, RoBERTa, and BART to enhance the understanding of user travel purposes and improve recommendation accuracy in specific travel scenarios.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "2 pages, 3 tables"
    },
    {
        "paper id": "2408.06396",
        "abstract url": "https://arxiv.org/abs/2408.06396",
        "title": "Design Proteins Using Large Language Models: Enhancements and Comparative Analyses",
        "rating": "-1.5",
        "keywords": [
            [
                "biologically"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Pre-trained LLMs have demonstrated substantial capabilities across a range of conventional natural language processing (NLP) tasks, such as summarization and entity recognition. In this paper, we explore the application of LLMs in the generation of high-quality protein sequences. Specifically, we adopt a suite of pre-trained LLMs, including Mistral-7B1, Llama-2-7B2, Llama-3-8B3, and gemma-7B4, to produce valid protein sequences. All of these models are publicly available.5 Unlike previous work in this field, our approach utilizes a relatively small dataset comprising 42,000 distinct human protein sequences. We retrain these models to process protein-related data, ensuring the generation of biologically feasible protein structures. Our findings demonstrate that even with limited data, the adapted models exhibit efficiency comparable to established protein-focused models such as ProGen varieties, ProtGPT2, and ProLLaMA, which were trained on millions of protein sequences. To validate and quantify the performance of our models, we conduct comparative analyses employing standard metrics such as pLDDT, RMSD, TM-score, and REU. Furthermore, we commit to making the trained versions of all four models publicly available, fostering greater transparency and collaboration in the field of computational biology.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "This paper has been accepted for presentation at Language and Molecules ACL 2024"
    },
    {
        "paper id": "2408.06397",
        "abstract url": "https://arxiv.org/abs/2408.06397",
        "title": "Distributed Stackelberg Strategies in State-based Potential Games for Autonomous Decentralized Learning Manufacturing Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This article describes a novel game structure for autonomously optimizing decentralized manufacturing systems with multi-objective optimization challenges, namely Distributed Stackelberg Strategies in State-Based Potential Games (DS2-SbPG). DS2-SbPG integrates potential games and Stackelberg games, which improves the cooperative trade-off capabilities of potential games and the multi-objective optimization handling by Stackelberg games. Notably, all training procedures remain conducted in a fully distributed manner. DS2-SbPG offers a promising solution to finding optimal trade-offs between objectives by eliminating the complexities of setting up combined objective optimization functions for individual players in self-learning domains, particularly in real-world industrial settings with diverse and numerous objectives between the sub-systems. We further prove that DS2-SbPG constitutes a dynamic potential game that results in corresponding converge guarantees. Experimental validation conducted on a laboratory-scale testbed highlights the efficacy of DS2-SbPG and its two variants, such as DS2-SbPG for single-leader-follower and Stack DS2-SbPG for multi-leader-follower. The results show significant reductions in power consumption and improvements in overall performance, which signals the potential of DS2-SbPG in real-world applications.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "comment": "This pre-print was submitted to IEEE Transactions on Systems, Man, and Cybernetics: Systems on July 31, 2024"
    },
    {
        "paper id": "2408.06400",
        "abstract url": "https://arxiv.org/abs/2408.06400",
        "title": "MetMamba: Regional Weather Forecasting with Spatial-Temporal Mamba Model",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Learning based Weather Prediction (DLWP) models have been improving rapidly over the last few years, surpassing state of the art numerical weather forecasts by significant margins. While much of the optimization effort is focused on training curriculum to extend forecast range in the global context, two aspects remains less explored: limited area modeling and better backbones for weather forecasting. We show in this paper that MetMamba, a DLWP model built on a state-of-the-art state-space model, Mamba, offers notable performance gains and unique advantages over other popular backbones using traditional attention mechanisms and neural operators. We also demonstrate the feasibility of deep learning based limited area modeling via coupled training with a global host model.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": "Typo and grammar; Minor elaboration and clarifications; Use full organization name in the author section"
    },
    {
        "paper id": "2408.06402",
        "abstract url": "https://arxiv.org/abs/2408.06402",
        "title": "PhaGO: Protein function annotation for bacteriophages by integrating the genomic context",
        "rating": "-1.5",
        "keywords": [
            [
                "biology"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Bacteriophages are viruses that target bacteria, playing a crucial role in microbial ecology. Phage proteins are important in understanding phage biology, such as virus infection, replication, and evolution. Although a large number of new phages have been identified via metagenomic sequencing, many of them have limited protein function annotation. Accurate function annotation of phage proteins presents several challenges, including their inherent diversity and the scarcity of annotated ones. Existing tools have yet to fully leverage the unique properties of phages in annotating protein functions. In this work, we propose a new protein function annotation tool for phages by leveraging the modular genomic structure of phage genomes. By employing embeddings from the latest protein foundation models and Transformer to capture contextual information between proteins in phage genomes, PhaGO surpasses state-of-the-art methods in annotating diverged proteins and proteins with uncommon functions by 6.78% and 13.05% improvement, respectively. PhaGO can annotate proteins lacking homology search results, which is critical for characterizing the rapidly accumulating phage genomes. We demonstrate the utility of PhaGO by identifying 688 potential holins in phages, which exhibit high structural conservation with known holins. The results show the potential of PhaGO to extend our understanding of newly discovered phages.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "17 pages,6 figures"
    },
    {
        "paper id": "2408.06445",
        "abstract url": "https://arxiv.org/abs/2408.06445",
        "title": "Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Long-term traffic flow forecasting plays a crucial role in intelligent transportation as it allows traffic managers to adjust their decisions in advance. However, the problem is challenging due to spatio-temporal correlations and complex dynamic patterns in continuous-time stream data. Neural Differential Equations (NDEs) are among the state-of-the-art methods for learning continuous-time traffic dynamics. However, the traditional NDE models face issues in long-term traffic forecasting due to failures in capturing delayed traffic patterns, dynamic edge (location-to-location correlation) patterns, and abrupt trend patterns. To fill this gap, we propose a new NDE architecture called Multi-View Neural Differential Equations. Our model captures current states, delayed states, and trends in different state variables (views) by learning latent multiple representations within Neural Differential Equations. Extensive experiments conducted on several real-world traffic datasets demonstrate that our proposed method outperforms the state-of-the-art and achieves superior prediction accuracy for long-term forecasting and robustness with noisy or missing inputs.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06602",
        "abstract url": "https://arxiv.org/abs/2408.06602",
        "title": "Super-intelligence or Superstition? Exploring Psychological Factors Underlying Unwarranted Belief in AI Predictions",
        "rating": "-1.5",
        "keywords": [
            [
                "Psychological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This study investigates psychological factors influencing belief in AI predictions about personal behavior, comparing it to belief in astrology and personality-based predictions. Through an experiment with 238 participants, we examined how cognitive style, paranormal beliefs, AI attitudes, personality traits, and other factors affect perceived validity, reliability, usefulness, and personalization of predictions from different sources. Our findings reveal that belief in AI predictions is positively correlated with belief in predictions based on astrology and personality psychology. Notably, paranormal beliefs and positive AI attitudes significantly increased perceived validity, reliability, usefulness, and personalization of AI predictions. Conscientiousness was negatively correlated with belief in predictions across all sources, and interest in the prediction topic increased believability across predictions. Surprisingly, cognitive style did not significantly influence belief in predictions. These results highlight the \"rational superstition\" phenomenon in AI, where belief is driven more by mental heuristics and intuition than critical evaluation. We discuss implications for designing AI systems and communication strategies that foster appropriate trust and skepticism. This research contributes to our understanding of the psychology of human-AI interaction and offers insights for the design and deployment of AI systems.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.07100",
        "abstract url": "https://arxiv.org/abs/2408.07100",
        "title": "Pattern-Matching Dynamic Memory Network for Dual-Mode Traffic Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, deep learning has increasingly gained attention in the field of traffic prediction. Existing traffic prediction models often rely on GCNs or attention mechanisms with O(N^2) complexity to dynamically extract traffic node features, which lack efficiency and are not lightweight. Additionally, these models typically only utilize historical data for prediction, without considering the impact of the target information on the prediction. To address these issues, we propose a Pattern-Matching Dynamic Memory Network (PM-DMNet). PM-DMNet employs a novel dynamic memory network to capture traffic pattern features with only O(N) complexity, significantly reducing computational overhead while achieving excellent performance. The PM-DMNet also introduces two prediction methods: Recursive Multi-step Prediction (RMP) and Parallel Multi-step Prediction (PMP), which leverage the time features of the prediction targets to assist in the forecasting process. Furthermore, a transfer attention mechanism is integrated into PMP, transforming historical data features to better align with the predicted target states, thereby capturing trend changes more accurately and reducing errors. Extensive experiments demonstrate the superiority of the proposed model over existing benchmarks. The source codes are available at: https://github.com/wengwenchao123/PM-DMNet.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05934",
        "abstract url": "https://arxiv.org/abs/2408.05934",
        "title": "A Mathematical Model for Skin Sympathetic Nerve Activity Simulation",
        "rating": "-2",
        "keywords": [
            [
                "health",
                "disease",
                "cardiac"
            ]
        ],
        "abstract": "Autonomic nervous system is important for cardiac function regulation. Modeling of autonomic cardiac regulation can contribute to health tracking and disease management. This study proposed a mathematical model that simulates autonomic cardiac regulation response to Valsalva Maneuver, which is a commonly used test that provokes the autonomic nervous system. Dataset containing skin sympathetic nervous activity extracted from healthy participants' ECG was used to validate the model. In the data collection procedure, each participant was required to perform Valsalva Maneuver. The preliminary result of modeling for one subject is presented, and the model validation result showed that the root measure square error between the simulated and measured average skin sympathetic nervous activity is 0.01mV. The model is expected to be further developed, evaluated using the dataset including 41 subjects, and ultimately applied for capturing the early signs of cardiac dysfunction in the future.",
        "subjects": [
            "physics.med-ph",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05939",
        "abstract url": "https://arxiv.org/abs/2408.05939",
        "title": "UniPortrait: A Unified Framework for Identity-Preserving Single- and Multi-Human Image Personalization",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents UniPortrait, an innovative human image personalization framework that unifies single- and multi-ID customization with high face fidelity, extensive facial editability, free-form input description, and diverse layout generation. UniPortrait consists of only two plug-and-play modules: an ID embedding module and an ID routing module. The ID embedding module extracts versatile editable facial features with a decoupling strategy for each ID and embeds them into the context space of diffusion models. The ID routing module then combines and distributes these embeddings adaptively to their respective regions within the synthesized image, achieving the customization of single and multiple IDs. With a carefully designed two-stage training scheme, UniPortrait achieves superior performance in both single- and multi-ID customization. Quantitative and qualitative experiments demonstrate the advantages of our method over existing approaches as well as its good scalability, e.g., the universal compatibility with existing generative control tools. The project page is at https://aigcdesigngroup.github.io/UniPortrait-Page/ .",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Tech report; Project page: https://aigcdesigngroup.github.io/UniPortrait-Page/"
    },
    {
        "paper id": "2408.05996",
        "abstract url": "https://arxiv.org/abs/2408.05996",
        "title": "Value-based Proactive Caching for Sensing Data in Internet of Vehicles",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Sensing data (SD) plays an important role in safe-related applications for Internet of Vehicles. Proactively caching required sensing data (SD) is a pivotal strategy for alleviating network congestion and improving data accessibility. Despite merits, existing studies predominantly address SD caching within a single time slot, which may not be scalable to scenarios involving multi-slots. Furthermore, the oversight of service capacity at caching nodes could lead to significant queuing delays in SD reception. To tackle these limitations, we jointly consider the problem of anchoring caching placement and requests allocation for SD. A value model incorporating both temporal and spacial characteristics is first proposed to estimate the significance of different caching decisions. Subsequently, a stochastic integer nonlinear programming model is provided to optimize the long-term system performance, which is converted into a series of online optimization problem by leveraging the Lyapunov method and linearized via introducing auxiliary variables. To expedite the solution, we provide a binary quantum particle swarm optimization based algorithm with quadratic time complexity. Numerical investigations demonstrate the superiority of proposed algorithms compared with other schemes in terms of energy consumption, response latency, and cache-hit ratio.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "14 pages,10 figures"
    },
    {
        "paper id": "2408.06010",
        "abstract url": "https://arxiv.org/abs/2408.06010",
        "title": "DEEPTalk: Dynamic Emotion Embedding for Probabilistic Speech-Driven 3D Face Animation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Speech-driven 3D facial animation has garnered lots of attention thanks to its broad range of applications. Despite recent advancements in achieving realistic lip motion, current methods fail to capture the nuanced emotional undertones conveyed through speech and produce monotonous facial motion. These limitations result in blunt and repetitive facial animations, reducing user engagement and hindering their applicability. To address these challenges, we introduce DEEPTalk, a novel approach that generates diverse and emotionally rich 3D facial expressions directly from speech inputs. To achieve this, we first train DEE (Dynamic Emotion Embedding), which employs probabilistic contrastive learning to forge a joint emotion embedding space for both speech and facial motion. This probabilistic framework captures the uncertainty in interpreting emotions from speech and facial motion, enabling the derivation of emotion vectors from its multifaceted space. Moreover, to generate dynamic facial motion, we design TH-VQVAE (Temporally Hierarchical VQ-VAE) as an expressive and robust motion prior overcoming limitations of VAEs and VQ-VAEs. Utilizing these strong priors, we develop DEEPTalk, A talking head generator that non-autoregressively predicts codebook indices to create dynamic facial motion, incorporating a novel emotion consistency loss. Extensive experiments on various datasets demonstrate the effectiveness of our approach in creating diverse, emotionally expressive talking faces that maintain accurate lip-sync. Source code will be made publicly available soon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "First two authors contributed equally"
    },
    {
        "paper id": "2408.06113",
        "abstract url": "https://arxiv.org/abs/2408.06113",
        "title": "IIT Bombay Racing Driverless: Autonomous Driving Stack for Formula Student AI",
        "rating": "-2",
        "keywords": [
            [
                "Autonomous Driving",
                "LiDAR",
                "vehicle"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "This work presents the design and development of IIT Bombay Racing's Formula Student style autonomous racecar algorithm capable of running at the racing events of Formula Student-AI, held in the UK. The car employs a cutting-edge sensor suite of the compute unit NVIDIA Jetson Orin AGX, 2 ZED2i stereo cameras, 1 Velodyne Puck VLP16 LiDAR and SBG Systems Ellipse N GNSS/INS IMU. It features deep learning algorithms and control systems to navigate complex tracks and execute maneuvers without any human intervention. The design process involved extensive simulations and testing to optimize the vehicle's performance and ensure its safety. The algorithms have been tested on a small scale, in-house manufactured 4-wheeled robot and on simulation software. The results obtained for testing various algorithms in perception, simultaneous localization and mapping, path planning and controls have been detailed.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 19 figures"
    },
    {
        "paper id": "2408.06115",
        "abstract url": "https://arxiv.org/abs/2408.06115",
        "title": "Measurement Study of Programmable Network Coding in Cloud-native 5G and Beyond Networks",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Emerging 5G/6G use cases span various industries, necessitating flexible solutions that leverage emerging technologies to meet diverse and stringent application requirements under changing network conditions. The standard 5G RAN solution, retransmission, reduces packet loss but can increase transmission delay in the process. Random Linear Network Coding (RLNC) offers an alternative by proactively sending combinations of original packets, thus reducing both delay and packet loss. Current research often only simulates the integration of RLNC in 5G while we implement and evaluate our approach on real commercially available hardware in a real-world deployment. We introduce Flexible Network Coding (FlexNC), which enables the flexible fusion of several RLNC protocols by incorporating a forwarder with multiple RLNC nodes. Network operators can configure FlexNC based on network conditions and application requirements. To further boost network programmability, our Recoder in the Network (RecNet) leverages intermediate network nodes to join the coding process. Both the proposed algorithms have been implemented on OpenAirInterface and extensively tested with traffic from different applications in a real network. While FlexNC adapts to various application needs of latency and packet loss, RecNet significantly minimizes packet loss for a remote user with minimal increase in delay compared to pure RLNC.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06148",
        "abstract url": "https://arxiv.org/abs/2408.06148",
        "title": "Coverage measurement in model-based testing of web applications: Tool support and an industrial experience report",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "There are many widely used tools for measuring test-coverage and code-coverage. Test coverage is the ratio of requirements or other non-code artifacts covered by a test suite, while code-coverage is the ratio of source code covered by tests. Almost all coverage tools show a few certain subset of coverage values, and almost always either test-coverage or code-coverage measures. In a large-scale industrial web-application-testing setting, we were faced with the need to \"integrate\" several types of coverage data (including front-end and back-end code coverage with requirements coverage), and to see all of them \"live\" as large model-based test suites were running. By being unable to find any off-the-shelf toolset to address the above need, we have developed an open-source test coverage tool, specific for MBT, named MBTCover. In addition to code coverage, the tool measures and reports requirements and model coverage, \"live\" as a given MBT test suite is executing. In this paper, we present the features of the MBTCover tool and our experience from using it in multiple large test-automation projects in practice. Other software test engineers, who conduct web application testing and MBT, may find the tool useful in their projects.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06170",
        "abstract url": "https://arxiv.org/abs/2408.06170",
        "title": "Zero-shot 3D Segmentation of Abdominal Organs in CT Scans Using Segment Anything Model 2: Adapting Video Tracking Capabilities for 3D Medical Imaging",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "CT",
                "organ"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: This study aimed to evaluate the zero-shot performance of Segment Anything Model 2 (SAM 2) in 3D segmentation of abdominal organs in CT scans, leveraging its video tracking capabilities for volumetric medical imaging. Materials and Methods: Using a subset of the TotalSegmentator CT dataset (n=123) from 8 different institutions, we assessed SAM 2's ability to segment 8 abdominal organs. Segmentation was initiated from three different Z-coordinate levels (caudal, mid, and cranial levels) of each organ. Performance was measured using the Dice similarity coefficient (DSC). We also analyzed organ volumes to contextualize the results. Results: As a zero-shot approach, larger organs with clear boundaries demonstrated high segmentation performance, with mean(median) DSCs as follows: liver 0.821(0.898), left kidney 0.870(0.921), right kidney 0.862(0.935), and spleen 0.891(0.932). Smaller or less defined structures showed lower performance: gallbladder 0.531(0.590), pancreas 0.361(0.359), and adrenal glands 0.203-0.308(0.109-0.231). Significant differences in DSC were observed depending on the starting initial slice of segmentation for different organs. A moderate positive correlation was observed between volume size and DSCs (Spearman's rs = 0.731, P <.001 at caudal-level). DSCs exhibited high variability within organs, ranging from near 0 to almost 1.0, indicating substantial inconsistency in segmentation performance between scans. Conclusion: SAM 2 demonstrated promising zero-shot performance in segmenting certain abdominal organs in CT scans, particularly larger organs with clear boundaries. The model's ability to segment previously unseen targets without additional training highlights its potential for cross-domain generalization in medical imaging. However, improvements are needed for smaller and less defined structures.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "16 pages, 6 figures (including 1 supplemental figure), 3 tables"
    },
    {
        "paper id": "2408.06201",
        "abstract url": "https://arxiv.org/abs/2408.06201",
        "title": "Investigating Characteristics of Media Recommendation Solicitation in r/ifyoulikeblank",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Despite the existence of search-based recommender systems like Google, Netflix, and Spotify, online users sometimes may turn to crowdsourced recommendations in places like the r/ifyoulikeblank subreddit. In this exploratory study, we probe why users go to r/ifyoulikeblank, how they look for recommendation, and how the subreddit users respond to recommendation requests. To answer, we collected sample posts from r/ifyoulikeblank and analyzed them using a qualitative approach. Our analysis reveals that users come to this subreddit for various reasons, such as exhausting popular search systems, not knowing what or how to search for an item, and thinking crowd have better knowledge than search systems. Examining users query and their description, we found novel information users provide during recommendation seeking using r/ifyoulikeblank. For example, sometimes they ask for artifacts recommendation based on the tools used to create them. Or, sometimes indicating a recommendation seeker's time constraints can help better suit recommendations to their needs. Finally, recommendation responses and interactions revealed patterns of how requesters and responders refine queries and recommendations. Our work informs future intelligent recommender systems design.",
        "subjects": [
            "cs.HC",
            "cs.IR"
        ],
        "comment": "page 23"
    },
    {
        "paper id": "2408.06254",
        "abstract url": "https://arxiv.org/abs/2408.06254",
        "title": "Data-Efficient Prediction of Minimum Operating Voltage via Inter- and Intra-Wafer Variation Alignment",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Predicting the minimum operating voltage ($V_{min}$) of chips stands as a crucial technique in enhancing the speed and reliability of manufacturing testing flow. However, existing $V_{min}$ prediction methods often overlook various sources of variations in both training and deployment phases. Notably, the neglect of wafer zone-to-zone (intra-wafer) variations and wafer-to-wafer (inter-wafer) variations, compounded by process variations, diminishes the accuracy, data efficiency, and reliability of $V_{min}$ predictors. To address this gap, we introduce a novel data-efficient $V_{min}$ prediction flow, termed restricted bias alignment (RBA), which incorporates a novel variation alignment technique. Our approach concurrently estimates inter- and intra-wafer variations. Furthermore, we propose utilizing class probe data to model inter-wafer variations for the first time. We empirically demonstrate RBA's effectiveness and data efficiency on an industrial 16nm automotive chip dataset.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06289",
        "abstract url": "https://arxiv.org/abs/2408.06289",
        "title": "Tolerant testing stabilizer states",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We consider the following task: suppose an algorithm is given copies of an unknown $n$-qubit quantum state $|\u03c8\\rangle$ promised $(i)$ $|\u03c8\\rangle$ is $\\varepsilon_1$-close to a stabilizer state in fidelity or $(ii)$ $|\u03c8\\rangle$ is $\\varepsilon_2$-far from all stabilizer states, decide which is the case. We give a $\\textsf{poly}(1/\\varepsilon_1)$-sample and $n\\cdot \\textsf{poly}(1/\\varepsilon_1)$-time algorithm for this task for every $\\varepsilon_1>0$ and $\\varepsilon_2\\leq 2^{-\\textsf{poly}(1/\\varepsilon_1)}$. Our proof includes a new definition of Gowers norm for quantum states, an inverse theorem for the Gowers-$3$ norm of states and new bounds on stabilizer covering for structured subsets of Paulis using results in additive combinatorics.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.DS"
        ],
        "comment": "35 pages, 2 figures"
    },
    {
        "paper id": "2408.06331",
        "abstract url": "https://arxiv.org/abs/2408.06331",
        "title": "Integration of blockchain in smart systems: problems and opportunities for real-time sensor data storage",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The internet of things (IoT) and other emerging ubiquitous technologies are supporting the rapid spread of smart systems, which has underlined the need for safe, open, and decentralized data storage solutions. With its inherent decentralization and immutability, blockchain offers itself as a potential solution for these requirements. However, the practicality of incorporating blockchain into real-time sensor data storage systems is a topic that demands in-depth examination. While blockchain promises unmatched data security and auditability, some intrinsic qualities, namely scalability restrictions, transactional delays, and escalating storage demands, impede its seamless deployment in high-frequency, voluminous data contexts typical of real-time sensors. This essay launches a methodical investigation into these difficulties, illuminating their underlying causes, potential effects, and potential countermeasures. In addition, we present a novel pragmatic experimental setup and analysis of blockchain for smart system applications, with an extended discussion of the benefits and disadvantages of deploying blockchain based solutions for smart system ecosystems.",
        "subjects": [
            "cs.NI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06403",
        "abstract url": "https://arxiv.org/abs/2408.06403",
        "title": "From Diagnostic CT to DTI Tractography labels: Using Deep Learning for Corticospinal Tract Injury Assessment and Outcome Prediction in Intracerebral Haemorrhage",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Surgical",
                "surgery",
                "CT",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The preservation of the corticospinal tract (CST) is key to good motor recovery after stroke. The gold standard method of assessing the CST with imaging is diffusion tensor tractography. However, this is not available for most intracerebral haemorrhage (ICH) patients. Non-contrast CT scans are routinely available in most ICH diagnostic pipelines, but delineating white matter from a CT scan is challenging. We utilise nnU-Net, trained on paired diagnostic CT scans and high-directional diffusion tractography maps, to segment the CST from diagnostic CT scans alone, and we show our model reproduces diffusion based tractography maps of the CST with a Dice similarity coefficient of 57%. Surgical haematoma evacuation is sometimes performed after ICH, but published clinical trials to date show that whilst surgery reduces mortality, there is no evidence of improved functional recovery. Restricting surgery to patients with an intact CST may reveal a subset of patients for whom haematoma evacuation improves functional outcome. We investigated the clinical utility of our model in the MISTIE III clinical trial dataset. We found that our model's CST integrity measure significantly predicted outcome after ICH in the acute and chronic time frames, therefore providing a prognostic marker for patients to whom advanced diffusion tensor imaging is unavailable. This will allow for future probing of subgroups who may benefit from surgery.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "physics.med-ph"
        ],
        "comment": "Accepted to Miccai Switch Workshop"
    },
    {
        "paper id": "2408.06429",
        "abstract url": "https://arxiv.org/abs/2408.06429",
        "title": "Wavelet based inpainting detection",
        "rating": "-2",
        "keywords": [
            [
                "inpainting",
                "image editing"
            ],
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the advancement in image editing tools, manipulating digital images has become alarmingly easy. Inpainting, which is used to remove objects or fill in parts of an image, serves as a powerful tool for both image restoration and forgery. This paper introduces a novel approach for detecting image inpainting forgeries by combining DT-CWT with Hierarchical Feature segmentation and with noise inconsistency analysis. The DT-CWT offers several advantages for this task, including inherent shift-invariance, which makes it robust to minor manipulations during the inpainting process, and directional selectivity, which helps capture subtle artifacts introduced by inpainting in specific frequency bands and orientations. By first applying color image segmentation and then analyzing for each segment, noise inconsistency obtained via DT-CW we can identify patterns indicative of inpainting forgeries. The proposed method is evaluated on a benchmark dataset created for this purpose and is compared with existing forgery detection techniques. Our approach demonstrates superior results compared with SOTA in detecting inpainted images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06449",
        "abstract url": "https://arxiv.org/abs/2408.06449",
        "title": "Tactile Melodies: A Desk-Mounted Haptics for Perceiving Musical Experiences",
        "rating": "-2",
        "keywords": [
            [
                "music"
            ]
        ],
        "abstract": "This paper introduces a novel interface for experiencing music through haptic impulses to the palm of the hand. It presents a practical implementation of the system exploring the realm of musical haptics through the translation of MIDI data from a Digital Audio Workstation (DAW) into haptic sensations, from a set of haptic actuators, in real-time. It also includes a suitable music-to-haptic mapping strategy to translate notes from musical instruments to haptic feedback. The haptic actuators, placed strategically on the palmar surface of the hand allowed users to perceive music and were able to identify melody and rhythm of different musical compositions. A pilot user study conducted intended to assess the accuracy of the interface by testing the participants to select the correct audio presentation from the haptic presentation of the same musical composition. It presents a comparative study, differentiating between those with prior musical background and those without, in identifying the correct audio counterpart solely through haptic inputs. This pilot study delves into how users perceive and interpret haptic feedback within the context of musical compositions. The study showed promising results in enriching our understanding of user responses to haptic feedback in musical scenarios and exploring the intricacies of user experience with the system and its impact on musical interpretation.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "23 pages, 14 figures"
    },
    {
        "paper id": "2408.06463",
        "abstract url": "https://arxiv.org/abs/2408.06463",
        "title": "Statistical Quality Comparison of the Bitstrings Generated by a Physical Unclonable Function across Xilinx, Altera and Microsemi Devices",
        "rating": "-2",
        "keywords": [
            [
                "industrial",
                "IoT",
                "FPGA"
            ]
        ],
        "abstract": "Entropy or randomness represents a foundational security property in security-related operations, such as key generation. Key generation in turn is central to security protocols such as authentication and encryption. Physical unclonable functions (PUF) are hardware-based primitives that can serve as key generation engines in modern microelectronic devices and applications. PUFs derive entropy from manufacturing variations that exist naturally within and across otherwise identical copies of a device. However, the levels of random variations that represent entropy, which are strongly correlated to the quality of the PUF-generated bitstrings, vary from one manufacturer to another. In this paper, we evaluate entropy across a set of devices manufactured by three mainstream FPGA vendors, Xilinx, Altera and Microsemi. The devices selected for evaluation are considered low-end commercial devices to make the analysis relevant to IoT applications. The SiRF PUF is used in the evaluation, and is constructed nearly identically across the three vendor devices, setting aside minor differences that exist in certain logic element primitives used within the PUF architecture, and which have only a minor impact on our comparative analysis. The SiRF PUF uses a high-resolution time-to-digital converter (TDC) crafted from high-speed carry-chain logic embedded within each device to measure path delays in an engineered netlist of logic gates as a source of entropy. Therefore, our analysis includes an evaluation of actual path delay variation as it exists across the three device classes, as well as a statistical evaluation of the PUF-generated bitstrings. A reliablity analysis is also provided using data collected in industrial-standard temperature experiments to round out the evaluation of important statistical properties of the PUF.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "15 pages, 22 figures, IEEE journal"
    },
    {
        "paper id": "2408.06469",
        "abstract url": "https://arxiv.org/abs/2408.06469",
        "title": "Design and architecture of the IBM Quantum Engine Compiler",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "In this work, we describe the design and architecture of the open-source Quantum Engine Compiler (qe-compiler) currently used in production for IBM Quantum systems. The qe-compiler is built using LLVM's Multi-Level Intermediate Representation (MLIR) framework and includes definitions for several dialects to represent parameterized quantum computation at multiple levels of abstraction. The compiler also provides Python bindings and a diagnostic system. An open-source LALR lexer and parser built using Bison and Flex generates an Abstract Syntax Tree that is translated to a high-level MLIR dialect. An extensible hierarchical target system for modeling the heterogeneous nature of control systems at compilation time is included. Target-based and generic compilation passes are added using a pipeline interface to translate the input down to low-level intermediate representations (including LLVM IR) and can take advantage of LLVM backends and tooling to generate machine executable binaries. The qe-compiler is built to be extensible, maintainable, performant, and scalable to support the future of quantum computing.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": "To be published in the proceedings of the IEEE International Conference on Quantum Computing and Engineering 2024 (QCE24)"
    },
    {
        "paper id": "2408.06481",
        "abstract url": "https://arxiv.org/abs/2408.06481",
        "title": "UniT: Unified Tactile Representation for Robot Learning",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "UniT is a novel approach to tactile representation learning, using VQVAE to learn a compact latent space and serve as the tactile representation. It uses tactile images obtained from a single simple object to train the representation with transferability and generalizability. This tactile representation can be zero-shot transferred to various downstream tasks, including perception tasks and manipulation policy learning. Our benchmarking on an in-hand 3D pose estimation task shows that UniT outperforms existing visual and tactile representation learning methods. Additionally, UniT's effectiveness in policy learning is demonstrated across three real-world tasks involving diverse manipulated objects and complex robot-object-environment interactions. Through extensive experimentation, UniT is shown to be a simple-to-train, plug-and-play, yet widely effective method for tactile representation learning. For more details, please refer to our open-source repository https://github.com/ZhengtongXu/UniT and the project website https://zhengtongxu.github.io/unifiedtactile.github.io/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06507",
        "abstract url": "https://arxiv.org/abs/2408.06507",
        "title": "Benchmarking tree species classification from proximally-sensed laser scanning data: introducing the FOR-species20K dataset",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "drone"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Proximally-sensed laser scanning offers significant potential for automated forest data capture, but challenges remain in automatically identifying tree species without additional ground data. Deep learning (DL) shows promise for automation, yet progress is slowed by the lack of large, diverse, openly available labeled datasets of single tree point clouds. This has impacted the robustness of DL models and the ability to establish best practices for species classification. To overcome these challenges, the FOR-species20K benchmark dataset was created, comprising over 20,000 tree point clouds from 33 species, captured using terrestrial (TLS), mobile (MLS), and drone laser scanning (ULS) across various European forests, with some data from other regions. This dataset enables the benchmarking of DL models for tree species classification, including both point cloud-based (PointNet++, MinkNet, MLP-Mixer, DGCNNs) and multi-view image-based methods (SimpleView, DetailView, YOLOv5). 2D image-based models generally performed better (average OA = 0.77) than 3D point cloud-based models (average OA = 0.72), with consistent results across different scanning platforms and sensors. The top model, DetailView, was particularly robust, handling data imbalances well and generalizing effectively across tree sizes. The FOR-species20K dataset, available at https://zenodo.org/records/13255198, is a key resource for developing and benchmarking DL models for tree species classification using laser scanning data, providing a foundation for future advancements in the field.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06543",
        "abstract url": "https://arxiv.org/abs/2408.06543",
        "title": "HDRGS: High Dynamic Range Gaussian Splatting",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF"
            ],
            [
                "HDR"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recent years have witnessed substantial advancements in the field of 3D reconstruction from 2D images, particularly following the introduction of the neural radiance field (NeRF) technique. However, reconstructing a 3D high dynamic range (HDR) radiance field, which aligns more closely with real-world conditions, from 2D multi-exposure low dynamic range (LDR) images continues to pose significant challenges. Approaches to this issue fall into two categories: grid-based and implicit-based. Implicit methods, using multi-layer perceptrons (MLP), face inefficiencies, limited solvability, and overfitting risks. Conversely, grid-based methods require significant memory and struggle with image quality and long training times. In this paper, we introduce Gaussian Splatting-a recent, high-quality, real-time 3D reconstruction technique-into this domain. We further develop the High Dynamic Range Gaussian Splatting (HDR-GS) method, designed to address the aforementioned challenges. This method enhances color dimensionality by including luminance and uses an asymmetric grid for tone-mapping, swiftly and precisely converting pixel irradiance to color. Our approach improves HDR scene recovery accuracy and integrates a novel coarse-to-fine strategy to speed up model convergence, enhancing robustness against sparse viewpoints and exposure extremes, and preventing local optima. Extensive testing confirms that our method surpasses current state-of-the-art techniques in both synthetic and real-world scenarios. Code will be released at \\url{https://github.com/WuJH2001/HDRGS}",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06568",
        "abstract url": "https://arxiv.org/abs/2408.06568",
        "title": "MORCoRA: Multi-Objective Refactoring Recommendation Considering Review Availability",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Background: Search-based refactoring involves searching for a sequence of refactorings to achieve specific objectives. Although a typical objective is improving code quality, a different perspective is also required; the searched sequence must undergo review before being applied and may not be applied if the review fails or is postponed due to no proper reviewers. Aim: Therefore, it is essential to ensure that the searched sequence of refactorings can be reviewed promptly by reviewers who meet two criteria: 1) having enough expertise and 2) being free of heavy workload. The two criteria are regarded as the review availability of the refactoring sequence. Method: We propose MORCoRA, a multi-objective search-based technique that can search for code quality improvable, semantic preserved, and high review availability possessed refactoring sequences and corresponding proper reviewers. Results: We evaluate MORCoRA on six open-source repositories. The quantitative analysis reveals that MORCoRA can effectively recommend refactoring sequences that fit the requirements. The qualitative analysis demonstrates that the refactorings recommended by MORCoRA can enhance code quality and effectively address code smells. Furthermore, the recommended reviewers for those refactorings possess high expertise and are available to review. Conclusions: We recommend that refactoring recommenders consider both the impact on quality improvement and the developer resources required for review when recommending refactorings.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Preprint of an article accepted to be published in International Journal of Software Engineering and Knowledge Engineering, (C) 2024 World Scientific Publishing Company, https://www.worldscientific.com/worldscinet/ijseke"
    },
    {
        "paper id": "2408.06586",
        "abstract url": "https://arxiv.org/abs/2408.06586",
        "title": "Breaking Limits of Line-of-Sight MIMO Capacity in 6G Wireless Communications",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Multiple-input-multiple-output (MIMO) has been proved its success for the fourth generation (4G) long term evolution (LTE) and is one of the key technical enablers for evolved mobile broadband (eMBB) in the fifth generation (5G) wireless communications. However, along with the number of antennas eventually increased to be extremely large and one-hop communication distance gradually reduced, how to significantly increase the capacity for line-of-sight (LOS) MIMO becomes more and more urgent. In this article, we introduce the quasi-fractal uniform circular array (QF-UCA) antenna structure based MIMO wireless communications, which can adequately exploit the potential of MIMO in LOS channel and greatly increase the capacity with low complexity demodulation schemes. Specifically, three advantages regarding QF-UCA based LOS MIMO are reviewed. Then, research challenges on transceiver alignment, low-rank channel matrix, extended dimensions of QF-UCA, maximum number of orthogonal streams, and the corresponding potential solutions are discussed. Compared with traditional scattering-depended MIMO communications, the QF-UCA based LOS MIMO wireless communication can achieve high-efficient transmission in LOS channel.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06601",
        "abstract url": "https://arxiv.org/abs/2408.06601",
        "title": "HiRegEx: Interactive Visual Query and Exploration of Multivariate Hierarchical Data",
        "rating": "-2",
        "keywords": [
            [
                "grammar"
            ]
        ],
        "abstract": "When using exploratory visual analysis to examine multivariate hierarchical data, users often need to query data to narrow down the scope of analysis. However, formulating effective query expressions remains a challenge for multivariate hierarchical data, particularly when datasets become very large. To address this issue, we develop a declarative grammar, HiRegEx (Hierarchical data Regular Expression), for querying and exploring multivariate hierarchical data. Rooted in the extended multi-level task topology framework for tree visualizations (e-MLTT), HiRegEx delineates three query targets (node, path, and subtree) and two aspects for querying these targets (features and positions), and uses operators developed based on classical regular expressions for query construction. Based on the HiRegEx grammar, we develop an exploratory framework for querying and exploring multivariate hierarchical data and integrate it into the TreeQueryER prototype system. The exploratory framework includes three major components: top-down pattern specification, bottom-up data-driven inquiry, and context-creation data overview. We validate the expressiveness of HiRegEx with the tasks from the e-MLTT framework and showcase the utility and effectiveness of TreeQueryER system through a case study involving expert users in the analysis of a citation tree dataset.",
        "subjects": [
            "cs.HC",
            "cs.GR"
        ],
        "comment": "11 pages, 8 figures, accepted at IEEE VIS 2024"
    },
    {
        "paper id": "2408.06618",
        "abstract url": "https://arxiv.org/abs/2408.06618",
        "title": "Generalized knowledge-enhanced framework for biomedical entity and relation extraction",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "biomedical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, there has been an increasing number of frameworks developed for biomedical entity and relation extraction. This research effort aims to address the accelerating growth in biomedical publications and the intricate nature of biomedical texts, which are written for mainly domain experts. To handle these challenges, we develop a novel framework that utilizes external knowledge to construct a task-independent and reusable background knowledge graph for biomedical entity and relation extraction. The design of our model is inspired by how humans learn domain-specific topics. In particular, humans often first acquire the most basic and common knowledge regarding a field to build the foundational knowledge and then use that as a basis for extending to various specialized topics. Our framework employs such common-knowledge-sharing mechanism to build a general neural-network knowledge graph that is learning transferable to different domain-specific biomedical texts effectively. Experimental evaluations demonstrate that our model, equipped with this generalized and cross-transferable knowledge base, achieves competitive performance benchmarks, including BioRelEx for binding interaction detection and ADE for Adverse Drug Effect identification.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.07103",
        "abstract url": "https://arxiv.org/abs/2408.07103",
        "title": "Orbital-Angular-Momentum Embedded Massive MIMO: Achieving Multiplicative Spectrum-Efficiency for mmWave Communications",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "By enabling very high bandwidth for radio communications, the millimeter-wave (mmWave), which can easily be integrated with massive-multiple-input-multiple-output (massive-MIMO) due to small antenna size, has been attracting growing attention as a candidate for the fifth-generation (5G) and 5G-beyond wireless communications networks. On the other hand, the communication over the orthogonal states/modes of orbital angular momentum (OAM) is a subset of the solutions offered by massive-MIMO communications. Traditional massive-MIMO based mmWave communications did not concern the potential spectrum-efficiency-gain (SE-gain) offered by orthogonal states of OAM. However, the highly expecting maximum SE-gain for OAM and massive-MIMO communications is the product of SE-gains offered by OAM and multiplexing-MIMO. In this paper, we propose the OAM-embedded-MIMO (OEM) communication framework to obtain the multiplicative SE-gain for joint OAM and massive-MIMO based mmWave wireless communications. We design the parabolic antenna for each uniform circular array antenna to converge OAM signals. Then, we develop the mode-decomposition and multiplexing-detection scheme to obtain the transmit signal on each OAM-mode of each transmit antenna. Also, we develop the OEM-water-filling power allocation policy to achieve the maximum multiplicative SE-gain for OEM communications. The extensive simulations obtained validate and evaluate our developed parabolic antenna based converging method, mode-decomposition and multiplexing-detection scheme, and OEM-water-filling policy, showing that our proposed OEM mmWave communications can significantly increase the spectrum-efficiency as compared with traditional massive-MIMO based mmWave communications.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06027",
        "abstract url": "https://arxiv.org/abs/2408.06027",
        "title": "A Comprehensive Survey on EEG-Based Emotion Recognition: A Graph-Based Perspective",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "EEG",
                "psychological",
                "physiological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Compared to other modalities, electroencephalogram (EEG) based emotion recognition can intuitively respond to emotional patterns in the human brain and, therefore, has become one of the most focused tasks in affective computing. The nature of emotions is a physiological and psychological state change in response to brain region connectivity, making emotion recognition focus more on the dependency between brain regions instead of specific brain regions. A significant trend is the application of graphs to encapsulate such dependency as dynamic functional connections between nodes across temporal and spatial dimensions. Concurrently, the neuroscientific underpinnings behind this dependency endow the application of graphs in this field with a distinctive significance. However, there is neither a comprehensive review nor a tutorial for constructing emotion-relevant graphs in EEG-based emotion recognition. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of graph-related methods in this field from a methodological perspective. We propose a unified framework for graph applications in this field and categorize these methods on this basis. Finally, based on previous studies, we also present several open challenges and future directions in this field.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06240",
        "abstract url": "https://arxiv.org/abs/2408.06240",
        "title": "Decentralized Health Intelligence Network (DHIN)",
        "rating": "-2.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "medical",
                "Health",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Decentralized Health Intelligence Network (DHIN) is a theoretical framework addressing significant challenges of health data sovereignty and AI utilization in healthcare caused by data fragmentation across providers and institutions. It establishes a sovereign architecture for healthcare provision as a prerequisite to a sovereign health network, then facilitates effective AI utilization by overcoming barriers to accessing diverse medical data sources. This comprehensive framework leverages: 1) self-sovereign identity architecture coupled with a personal health record (PHR) as a prerequisite for health data sovereignty; 2) a scalable federated learning (FL) protocol implemented on a public blockchain for decentralized AI training in healthcare, where health data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution. This framework ensures that no entity can prevent or control access to training on health data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party. It supports effective AI training in healthcare, allowing patients to maintain control over their health data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial healthcare algorithms. Patients receive rewards into their digital wallets as an incentive to opt-in to the FL protocol, with a long-term roadmap to funding decentralized insurance solutions. This approach introduces a novel, self-financed healthcare model that adapts to individual needs, complements existing systems, and redefines universal coverage. It highlights the potential to transform healthcare data management and AI utilization while empowering patients.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CY",
            "cs.DC",
            "cs.ET"
        ],
        "comment": "17 pages, 7 figures. arXiv admin note: substantial text overlap with arXiv:2407.02461"
    },
    {
        "paper id": "2408.06277",
        "abstract url": "https://arxiv.org/abs/2408.06277",
        "title": "Multi-marginal Schr\u00f6dinger Bridges with Iterative Reference",
        "rating": "-2.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "biology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Practitioners frequently aim to infer an unobserved population trajectory using sample snapshots at multiple time points. For instance, in single-cell sequencing, scientists would like to learn how gene expression evolves over time. But sequencing any cell destroys that cell. So we cannot access any cell's full trajectory, but we can access snapshot samples from many cells. Stochastic differential equations are commonly used to analyze systems with full individual-trajectory access; since here we have only sample snapshots, these methods are inapplicable. The deep learning community has recently explored using Schr\u00f6dinger bridges (SBs) and their extensions to estimate these dynamics. However, these methods either (1) interpolate between just two time points or (2) require a single fixed reference dynamic within the SB, which is often just set to be Brownian motion. But learning piecewise from adjacent time points can fail to capture long-term dependencies. And practitioners are typically able to specify a model class for the reference dynamic but not the exact values of the parameters within it. So we propose a new method that (1) learns the unobserved trajectories from sample snapshots across multiple time points and (2) requires specification only of a class of reference dynamics, not a single fixed one. In particular, we suggest an iterative projection method inspired by Schr\u00f6dinger bridges; we alternate between learning a piecewise SB on the unobserved trajectories and using the learned SB to refine our best guess for the dynamics within the reference class. We demonstrate the advantages of our method via a well-known simulated parametric model from ecology, simulated and real data from systems biology, and real motion-capture data.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06300",
        "abstract url": "https://arxiv.org/abs/2408.06300",
        "title": "Inverse designing metamaterials with programmable nonlinear functional responses in graph space",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Material responses to static and dynamic stimuli, represented as nonlinear curves, are design targets for engineering functionalities like structural support, impact protection, and acoustic and photonic bandgaps. Three-dimensional metamaterials offer significant tunability due to their internal structure, yet existing methods struggle to capture their complex behavior-to-structure relationships. We present GraphMetaMat, a graph-based framework capable of designing three-dimensional metamaterials with programmable responses and arbitrary manufacturing constraints. Integrating graph networks, physics biases, reinforcement learning, and tree search, GraphMetaMat can target stress-strain curves spanning four orders of magnitude and complex behaviors, as well as viscoelastic transmission responses with varying attenuation gaps. GraphMetaMat can create cushioning materials for protective equipment and vibration-damping panels for electric vehicles, outperforming commercial materials, and enabling the automatic design of materials with on-demand functionalities.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": "19 pages, 5 figures"
    },
    {
        "paper id": "2408.06486",
        "abstract url": "https://arxiv.org/abs/2408.06486",
        "title": "Implicit Neural Representation For Accurate CFD Flow Field Prediction",
        "rating": "-2.5",
        "keywords": [
            [
                "memory-efficient"
            ],
            [
                "3D"
            ],
            [
                "graph"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the plethora of deep learning frameworks for flow field prediction, most of them deal with flow fields on regular domains, and although the best ones can cope with irregular domains, they mostly rely on graph networks, so that real industrial applications remain currently elusive. We present a deep learning framework for 3D flow field prediction applied to blades of aircraft engine turbines and compressors. Crucially, we view any 3D field as a function from coordinates that is modeled by a neural network we call the backbone-net. It inherits the property of coordinate-based MLPs, namely the discretization-agnostic representation of flow fields in domains of arbitrary topology at infinite resolution. First, we demonstrate the performance of the backbone-net solo in regressing 3D steady simulations of single blade rows in various flow regimes: it can accurately render important flow characteristics such as boundary layers, wakes and shock waves. Second, we introduce a hyper-net that maps the surface mesh of a blade to the parameters of the backbone-net. By doing so, the flow solution can be directly predicted from the blade geometry, irrespective of its parameterization. Together, backbone-net and hyper-net form a highly-accurate memory-efficient data-driven proxy to CFD solvers with good generalization on unseen geometries.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "comment": "ECCOMAS CONGRESS 2024, 9th European Congress on Computational Methods in Applied Sciences and Engineering"
    },
    {
        "paper id": "2408.06549",
        "abstract url": "https://arxiv.org/abs/2408.06549",
        "title": "Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) is a distributed machine learning approach that enables devices to collaboratively train models without sharing their local data, ensuring user privacy and scalability. However, applying FL to real-world data presents challenges, particularly as most existing FL research focuses on unimodal data. Multimodal Federated Learning (MFL) has emerged to address these challenges, leveraging modality-specific encoder models to process diverse datasets. Current MFL methods often uniformly allocate computational frequencies across all modalities, which is inefficient for IoT devices with limited resources. In this paper, we propose FlexMod, a novel approach to enhance computational efficiency in MFL by adaptively allocating training resources for each modality encoder based on their importance and training requirements. We employ prototype learning to assess the quality of modality encoders, use Shapley values to quantify the importance of each modality, and adopt the Deep Deterministic Policy Gradient (DDPG) method from deep reinforcement learning to optimize the allocation of training resources. Our method prioritizes critical modalities, optimizing model performance and resource utilization. Experimental results on three real-world datasets demonstrate that our proposed method significantly improves the performance of MFL models.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "Submitted to IEEE TMC, under review"
    },
    {
        "paper id": "2408.05981",
        "abstract url": "https://arxiv.org/abs/2408.05981",
        "title": "CAD-Mesher: A Convenient, Accurate, Dense Mesh-based Mapping Module in SLAM for Dynamic Environments",
        "rating": "-3",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Most LiDAR odometry and SLAM systems construct maps in point clouds, which are discrete and sparse when zoomed in, making them not directly suitable for navigation. Mesh maps represent a dense and continuous map format with low memory consumption, which can approximate complex structures with simple elements, attracting significant attention of researchers in recent years. However, most implementations operate under a static environment assumption. In effect, moving objects cause ghosting, potentially degrading the quality of meshing. To address these issues, we propose a plug-and-play meshing module adapting to dynamic environments, which can easily integrate with various LiDAR odometry to generally improve the pose estimation accuracy of odometry. In our meshing module, a novel two-stage coarse-to-fine dynamic removal method is designed to effectively filter dynamic objects, generating consistent, accurate, and dense mesh maps. To our best know, this is the first mesh construction method with explicit dynamic removal. Additionally, conducive to Gaussian process in mesh construction, sliding window-based keyframe aggregation and adaptive downsampling strategies are used to ensure the uniformity of point cloud. We evaluate the localization and mapping accuracy on five publicly available datasets. Both qualitative and quantitative results demonstrate the superiority of our method compared with the state-of-the-art algorithms. The code and introduction video are publicly available at https://yaepiii.github.io/CAD-Mesher/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "9 pages, 7 figures"
    },
    {
        "paper id": "2408.05985",
        "abstract url": "https://arxiv.org/abs/2408.05985",
        "title": "Diffuse-UDA: Addressing Unsupervised Domain Adaptation in Medical Image Segmentation with Appearance and Structure Aligned Diffusion Models",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "Diffusion"
            ],
            [
                "Medical",
                "healthcare"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The scarcity and complexity of voxel-level annotations in 3D medical imaging present significant challenges, particularly due to the domain gap between labeled datasets from well-resourced centers and unlabeled datasets from less-resourced centers. This disparity affects the fairness of artificial intelligence algorithms in healthcare. We introduce Diffuse-UDA, a novel method leveraging diffusion models to tackle Unsupervised Domain Adaptation (UDA) in medical image segmentation. Diffuse-UDA generates high-quality image-mask pairs with target domain characteristics and various structures, thereby enhancing UDA tasks. Initially, pseudo labels for target domain samples are generated. Subsequently, a specially tailored diffusion model, incorporating deformable augmentations, is trained on image-label or image-pseudo-label pairs from both domains. Finally, source domain labels guide the diffusion model to generate image-label pairs for the target domain. Comprehensive evaluations on several benchmarks demonstrate that Diffuse-UDA outperforms leading UDA and semi-supervised strategies, achieving performance close to or even surpassing the theoretical upper bound of models trained directly on target domain data. Diffuse-UDA offers a pathway to advance the development and deployment of AI systems in medical imaging, addressing disparities between healthcare environments. This approach enables the exploration of innovative AI-driven diagnostic tools, improves outcomes, saves time, and reduces human error.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05997",
        "abstract url": "https://arxiv.org/abs/2408.05997",
        "title": "Formalizing the Cryptographic Migration Problem",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "With the advancements in quantum computing, transitioning to post-quantum cryptography is becoming increasingly critical to maintain the security of modern systems. This paper introduces a formal definition of the cryptographic migration problem and explores its complexities using a suitable directed graph model. Characteristics of the resulting migration graphs are analyzed and trade-offs discussed. By using classical mathematical results from combinatorics, probability theory and combinatorial analysis, we assess the challenges of migrating ``random'' large cryptographic IT-infrastructures. We show that any sufficiently large migration project that follows our model has an intrinsic complexity, either due to many dependent (comparatively easy) migration steps or due to at least one complicated migration step. This proves that in a suitable sense cryptographic migration is hard in general.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06049",
        "abstract url": "https://arxiv.org/abs/2408.06049",
        "title": "Hardware Architecture Design of Model-Based Image Reconstruction Towards Palm-size Photoacoustic Tomography",
        "rating": "-3",
        "keywords": [
            [
                "biomedical",
                "clinical"
            ],
            [
                "FPGA"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Photoacoustic (PA) imaging technology combines the advantages of optical imaging and ultrasound imaging, showing great potential in biomedical applications. Many preclinical studies and clinical applications urgently require fast, high-quality, low-cost and portable imaging system. Translating advanced image reconstruction algorithms into hardware implementations is highly desired. However, existing iterative PA image reconstructions, although exhibit higher accuracy than delay-and-sum algorithm, suffer from high computational cost. In this paper, we introduce a model-based hardware acceleration architecture based on superposed Wave (s-Wave) for palm-size PA tomography (palm-PAT), aiming at enhancing both the speed and performance of image reconstruction at a much lower system cost. To achieve this, we propose an innovative data reuse method that significantly reduces hardware storage resource consumption. We conducted experiments by FPGA implementation of the algorithm, using both phantoms and in vivo human finger data to verify the feasibility of the proposed method. The results demonstrate that our proposed architecture can substantially reduce system cost while maintaining high imaging performance. The hardware-accelerated implementation of the model-based algorithm achieves a speedup of up to approximately 270 times compared to the CPU, while the corresponding energy efficiency ratio is improved by more than 2700 times.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "11 pages, 13 figures"
    },
    {
        "paper id": "2408.06082",
        "abstract url": "https://arxiv.org/abs/2408.06082",
        "title": "AutoCheck: Automatically Identifying Variables for Checkpointing by Data Dependency Analysis",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Checkpoint/Restart (C/R) has been widely deployed in numerous HPC systems, Clouds, and industrial data centers, which are typically operated by system engineers. Nevertheless, there is no existing approach that helps system engineers without domain expertise, and domain scientists without system fault tolerance knowledge identify those critical variables accounted for correct application execution restoration in a failure for C/R. To address this problem, we propose an analytical model and a tool (AutoCheck) that can automatically identify critical variables to checkpoint for C/R. AutoCheck relies on first, analytically tracking and optimizing data dependency between variables and other application execution state, and second, a set of heuristics that identify critical variables for checkpointing from the refined data dependency graph (DDG). AutoCheck allows programmers to pinpoint critical variables to checkpoint quickly within a few minutes. We evaluate AutoCheck on 14 representative HPC benchmarks, demonstrating that AutoCheck can efficiently identify correct critical variables to checkpoint.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "11 pages, 7 figures, 4 tables"
    },
    {
        "paper id": "2408.06207",
        "abstract url": "https://arxiv.org/abs/2408.06207",
        "title": "Multi-tree Quantum Routing in Realistic Topologies",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "In entanglement distribution networks, communication between two nodes necessitates the generation of end-to-end entanglement by entanglement swapping at intermediate nodes. Efficiently creating end-to-end entanglements over long distances is a key objective. In our prior study on asynchronous routing, we enhanced these entanglement rates by leveraging solely the local knowledge of the entanglement links of a node. This was achieved by creating a tree structure, particularly a destination-oriented directed acyclic graph (DODAG) or a spanning tree, eliminating synchronous operations and conserving unused entanglement links. In this article, we present a multi-tree approach with multiple DODAGs designed to improve end-to-end entanglement rates in large-scale networks, specifically catering to a range of network topologies, including grids and barbells, as well as realistic topologies found in research testbeds like ESnet and Internet2. Our simulations show a marked improvement in end-to-end entanglement rates for specific topologies compared to the single-tree method. This study underscores the promise of asynchronous routing schemes in quantum networks, highlighting the effectiveness of asynchronous routing across different network topologies and proposing a superior routing tactic.",
        "subjects": [
            "cs.NI",
            "quant-ph"
        ],
        "comment": "This article has been accepted for publication in IEEE Communications Magazine"
    },
    {
        "paper id": "2408.06245",
        "abstract url": "https://arxiv.org/abs/2408.06245",
        "title": "Latent Disentanglement for Low Light Image Enhancement",
        "rating": "-3",
        "keywords": [
            [
                "UAV"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Many learning-based low-light image enhancement (LLIE) algorithms are based on the Retinex theory. However, the Retinex-based decomposition techniques in such models introduce corruptions which limit their enhancement performance. In this paper, we propose a Latent Disentangle-based Enhancement Network (LDE-Net) for low light vision tasks. The latent disentanglement module disentangles the input image in latent space such that no corruption remains in the disentangled Content and Illumination components. For LLIE task, we design a Content-Aware Embedding (CAE) module that utilizes Content features to direct the enhancement of the Illumination component. For downstream tasks (e.g. nighttime UAV tracking and low-light object detection), we develop an effective light-weight enhancer based on the latent disentanglement framework. Comprehensive quantitative and qualitative experiments demonstrate that our LDE-Net significantly outperforms state-of-the-art methods on various LLIE benchmarks. In addition, the great results obtained by applying our framework on the downstream tasks also demonstrate the usefulness of our latent disentanglement design.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06274",
        "abstract url": "https://arxiv.org/abs/2408.06274",
        "title": "Sparsity Based Multi-Source Robust 3D Localization Using a Moving Receiver",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "MUSIC"
            ]
        ],
        "abstract": "Accurately localizing multiple sources is a critical task with various applications in wireless communications, such as emergency services including natural post-disaster search and rescue operations. However, the scenarios where the receiver is moving, are not addressed by recent studies. This paper tackles the angle of arrival (AOA) 3D-localization problem for multiple sparse signal sources with a moving receiver having limited antennas, potentially outnumbered by the sources. First, an energy detector algorithm is proposed to exploit the sparsity of the signal to eliminate the noisy samples of the signals. Subsequently, elevation and azimuth AOAs of sources are roughly estimated using two dimensional multiple signal classification (2D-MUSIC) method. Next, an algorithm is proposed to refine and estimate the elevation and azimuth AOAs more accurately. To this end, we propose a sparse recovery algorithm to exploit the sparsity feature of the signals. Then, we propose a phase smoothing algorithm to refine the estimations in the output of sparse recovery algorithm. Finally, K-SVD algorithm is employed to find the accurate elevation and azimuth AOAs of sources. For localization, a new multi-source 3D-localization algorithm is proposed to estimate the positions of sources in a sequence of time windows. Extensive simulations are carried out to demonstrate the effectiveness of the proposed framework.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06295",
        "abstract url": "https://arxiv.org/abs/2408.06295",
        "title": "Dual Threats in RIS-Aided RF-UOWC Mixed Networks: Secrecy Performance Analysis under Simultaneous RF and UOWC Eavesdropping",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "In the dynamic realm of 6G technology, emphasizing security is essential, particularly for optimizing high-performance communication. A notable strategy involves the use of reconfigurable intelligent surfaces (RISs), an emerging and cost-efficient technology aimed at fortifying incoming signals, broadening coverage, and ultimately improving the overall performance of systems. In this paper, we introduce a comprehensive framework to analyze the secrecy performance of an RIS-assisted mixed radio frequency (RF) - underwater optical wireless communication (UOWC) network. Here, all the RF links undergo alpha-mu fading distribution, whereas the UOWC links experience a mixture of Exponential Generalized Gamma distribution. Specifically, we examine three potential eavesdropping situations: 1) eavesdropping on the RF link, 2) eavesdropping on the UOWC link, and 3) a simultaneous eavesdropping attack affecting both RF and UOWC links. To achieve this, we derive novel mathematical expressions such as average secrecy capacity, secrecy outage probability, strictly positive secrecy capacity, and effective secrecy throughput in closed form. Using these derived expressions, we carry out an investigation to assess the influences of fading parameters, pointing errors, receiver detection technique, underwater turbulence severity, and water salinity on the system. Furthermore, our study investigates the significance of RIS in improving secrecy performance due to the proposed model. To provide deeper insights, we also perform asymptotic analysis for the high signal-to-noise region. Finally, to verify our analytical results, we conduct Monte Carlo simulation using a computer-based technique.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06296",
        "abstract url": "https://arxiv.org/abs/2408.06296",
        "title": "Hound: Locating Cryptographic Primitives in Desynchronized Side-Channel Traces Using Deep-Learning",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "FPGA"
            ]
        ],
        "abstract": "Side-channel attacks allow to extract sensitive information from cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. Starting from the raw side-channel trace, the preprocessing of the side-channel trace to pinpoint the time at which each cryptographic primitive is executed, and, then, to re-align all the collected data to this specific time represent a critical step to setup a successful side-channel attack. The use of hiding techniques has been widely adopted as a low-cost solution to hinder the preprocessing of side-channel traces thus limiting side-channel attacks in real scenarios. This work introduces Hound, a novel deep learning-based pipeline to locate the execution of cryptographic primitives within the side-channel trace even in the presence of trace deformations introduced by the use of dynamic frequency scaling actuators. Hound has been validated through successful attacks on various cryptographic primitives executed on an FPGA-based system-on-chip incorporating a RISC-V CPU, while dynamic frequency scaling is active. Experimental results demonstrate the possibility of identifying the cryptographic primitives in DFS-deformed side-channel traces.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted for presentation by ICCD'24"
    },
    {
        "paper id": "2408.06427",
        "abstract url": "https://arxiv.org/abs/2408.06427",
        "title": "Quantification of Multi-Compartment Flow with Spectral Diffusion MRI",
        "rating": "-3",
        "keywords": [
            [
                "voxel"
            ],
            [
                "Diffusion"
            ],
            [
                "MRI"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: Estimation of multi-compartment intravoxel flow in fD in ml/100g/min with multi-b-value diffusion weighted imaging and a multi-Gaussian model in the kidneys. Theory and Methods: A multi-Gaussian model of intravoxel flow using water transport time to quantify fD is presented and simulated. Multi-compartment anisotropic DWI signal is simulated analyzed with (1) a rigid bi-exponential, (2) a rigid tri-exponential, and (3) diffusion spectrum imaging model of intravoxel incoherent motion (spectral diffusion). The application is demonstrated in a two-center study of 54 kidney allografts with 9 b-value advanced DWI that were split by function (CKD-EPI 2021 eGFR<45ml/min/1.73m2) and fibrosis (Banff 2017 interstitial fibrosis and tubular atrophy score 0-6). Results: Spectral diffusion demonstrated strong correlation to truth for simulated three-compartment anisotropic diffusion (y=1.08x+0.1, R2=0.71) and two-compartment anisotropic diffusion (y=0.91x+0.6, R2=0.74), outperforming rigid models in cases of variable compartment number. Use of a fixed regularization parameter set to \u03bb=0.1 increased computation up to 208-fold and agreed with voxel-wise cross-validated regularization (concordance correlation coefficient=0.99). Spectral diffusion of renal allografts showed significant increase in tissue parenchyma compartment fD (f-stat=3.86, p=0.02). Tubular fD was significantly decreased in allografts with impaired function (Mann-Whitney Utest t-stat=-2.14, p=0.04). Conclusions: Quantitative multi-compartment intravoxel flow can be estimated in ml/100g/min with fD from multi-Gaussian diffusion, even with moderate anisotropy such as in kidneys. The use of spectral diffusion with a multi-Gaussian model and a fixed regularization parameter shows promise in organs such as the kidney with variable numbers of physiologic compartments.",
        "subjects": [
            "physics.med-ph",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06614",
        "abstract url": "https://arxiv.org/abs/2408.06614",
        "title": "ViMo: Generating Motions from Casual Videos",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "music"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Although humans have the innate ability to imagine multiple possible actions from videos, it remains an extraordinary challenge for computers due to the intricate camera movements and montages. Most existing motion generation methods predominantly rely on manually collected motion datasets, usually tediously sourced from motion capture (Mocap) systems or Multi-View cameras, unavoidably resulting in a limited size that severely undermines their generalizability. Inspired by recent advance of diffusion models, we probe a simple and effective way to capture motions from videos and propose a novel Video-to-Motion-Generation framework (ViMo) which could leverage the immense trove of untapped video content to produce abundant and diverse 3D human motions. Distinct from prior work, our videos could be more causal, including complicated camera movements and occlusions. Striking experimental results demonstrate the proposed model could generate natural motions even for videos where rapid movements, varying perspectives, or frequent occlusions might exist. We also show this work could enable three important downstream applications, such as generating dancing motions according to arbitrary music and source video style. Extensive experimental results prove that our model offers an effective and scalable way to generate diversity and realistic motions. Code and demos will be public soon.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05982",
        "abstract url": "https://arxiv.org/abs/2408.05982",
        "title": "Exploring and Learning Structure: Active Inference Approach in Navigational Agents",
        "rating": "-3.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "Graph"
            ],
            [
                "biologically"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Drawing inspiration from animal navigation strategies, we introduce a novel computational model for navigation and mapping, rooted in biologically inspired principles. Animals exhibit remarkable navigation abilities by efficiently using memory, imagination, and strategic decision-making to navigate complex and aliased environments. Building on these insights, we integrate traditional cognitive mapping approaches with an Active Inference Framework (AIF) to learn an environment structure in a few steps. Through the incorporation of topological mapping for long-term memory and AIF for navigation planning and structure learning, our model can dynamically apprehend environmental structures and expand its internal map with predicted beliefs during exploration. Comparative experiments with the Clone-Structured Graph (CSCG) model highlight our model's ability to rapidly learn environmental structures in a single episode, with minimal navigation overlap. this is achieved without prior knowledge of the dimensions of the environment or the type of observations, showcasing its robustness and effectiveness in navigating ambiguous environments.",
        "subjects": [
            "cs.AI",
            "cs.NE",
            "cs.RO"
        ],
        "comment": "IWAI workshop 2024"
    },
    {
        "paper id": "2408.06183",
        "abstract url": "https://arxiv.org/abs/2408.06183",
        "title": "Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability",
        "rating": "-3.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "SVM",
                "support vector machine"
            ],
            [
                "medical",
                "Disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cardiovascular diseases are a leading cause of mortality worldwide, highlighting the need for accurate diagnostic methods. This study benchmarks centralized and federated machine learning algorithms for heart disease classification using the UCI dataset which includes 920 patient records from four hospitals in the USA, Hungary and Switzerland. Our benchmark is supported by Shapley-value interpretability analysis to quantify features' importance for classification. In the centralized setup, various binary classification algorithms are trained on pooled data, with a support vector machine (SVM) achieving the highest testing accuracy of 83.3\\%, surpassing the established benchmark of 78.7\\% with logistic regression. Additionally, federated learning algorithms with four clients (hospitals) are explored, leveraging the dataset's natural partition to enhance privacy without sacrificing accuracy. Federated SVM, an uncommon approach in the literature, achieves a top testing accuracy of 73.8\\%. Our interpretability analysis aligns with existing medical knowledge of heart disease indicators. Overall, this study establishes a benchmark for efficient and interpretable pre-screening tools for heart disease while maintaining patients' privacy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06262",
        "abstract url": "https://arxiv.org/abs/2408.06262",
        "title": "DUNE: A Machine Learning Deep UNet++ based Ensemble Approach to Monthly, Seasonal and Annual Climate Forecasting",
        "rating": "-3.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Capitalizing on the recent availability of ERA5 monthly averaged long-term data records of mean atmospheric and climate fields based on high-resolution reanalysis, deep-learning architectures offer an alternative to physics-based daily numerical weather predictions for subseasonal to seasonal (S2S) and annual means. A novel Deep UNet++-based Ensemble (DUNE) neural architecture is introduced, employing multi-encoder-decoder structures with residual blocks. When initialized from a prior month or year, this architecture produced the first AI-based global monthly, seasonal, or annual mean forecast of 2-meter temperatures (T2m) and sea surface temperatures (SST). ERA5 monthly mean data is used as input for T2m over land, SST over oceans, and solar radiation at the top of the atmosphere for each month of 40 years to train the model. Validation forecasts are performed for an additional two years, followed by five years of forecast evaluations to account for natural annual variability. AI-trained inference forecast weights generate forecasts in seconds, enabling ensemble seasonal forecasts. Root Mean Squared Error (RMSE), Anomaly Correlation Coefficient (ACC), and Heidke Skill Score (HSS) statistics are presented globally and over specific regions. These forecasts outperform persistence, climatology, and multiple linear regression for all domains. DUNE forecasts demonstrate comparable statistical accuracy to NOAA's operational monthly and seasonal probabilistic outlook forecasts over the US but at significantly higher resolutions. RMSE and ACC error statistics for other recent AI-based daily forecasts also show superior performance for DUNE-based forecasts. The DUNE model's application to an ensemble data assimilation cycle shows comparable forecast accuracy with a single high-resolution model, potentially eliminating the need for retraining on extrapolated datasets.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph"
        ],
        "comment": "Excluding Appendix: 18 pages, 14 figures"
    },
    {
        "paper id": "2408.06030",
        "abstract url": "https://arxiv.org/abs/2408.06030",
        "title": "Developing Smart MAVs for Autonomous Inspection in GPS-denied Constructions",
        "rating": "-4",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "robotics"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Smart Micro Aerial Vehicles (MAVs) have transformed infrastructure inspection by enabling efficient, high-resolution monitoring at various stages of construction, including hard-to-reach areas. Traditional manual operation of drones in GPS-denied environments, such as industrial facilities and infrastructure, is labour-intensive, tedious and prone to error. This study presents an innovative framework for smart MAV inspections in such complex and GPS-denied indoor environments. The framework features a hierarchical perception and planning system that identifies regions of interest and optimises task paths. It also presents an advanced MAV system with enhanced localisation and motion planning capabilities, integrated with Neural Reconstruction technology for comprehensive 3D reconstruction of building structures. The effectiveness of the framework was empirically validated in a 4,000 square meters indoor infrastructure facility with an interior length of 80 metres, a width of 50 metres and a height of 7 metres. The main structure consists of columns and walls. Experimental results show that our MAV system performs exceptionally well in autonomous inspection tasks, achieving a 100\\% success rate in generating and executing scan paths. Extensive experiments validate the manoeuvrability of our developed MAV, achieving a 100\\% success rate in motion planning with a tracking error of less than 0.1 metres. In addition, the enhanced reconstruction method using 3D Gaussian Splatting technology enables the generation of high-fidelity rendering models from the acquired data. Overall, our novel method represents a significant advancement in the use of robotics for infrastructure inspection.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06106",
        "abstract url": "https://arxiv.org/abs/2408.06106",
        "title": "Optical RISs Improve the Secret Key Rate of Free-Space QKD in HAP-to-UAV Scenarios",
        "rating": "-4",
        "keywords": [
            [
                "UAV"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Large optical reconfigurable intelligent surfaces (ORISs) are proposed for employment on building rooftops to facilitate free-space quantum key distribution (QKD) between high-altitude platforms (HAPs) and low-altitude platforms (LAPs). Due to practical constraints, the communication terminals can only be positioned beneath the LAPs, preventing direct upward links to HAPs. By deploying ORISs on rooftops to reflect the beam arriving from HAPs towards LAPs from below, reliable HAP-to-LAP links can be established. To accurately characterize the optical beam propagation, we develop an analytical channel model based on extended Huygens-Fresnel principles for representing both the atmospheric turbulence effects and the hovering fluctuations of LAPs. This model facilitates adaptive ORIS beam-width control through linear, quadratic, and focusing phase shifts, which are capable of effectively mitigating the detrimental effects of beam broadening and pointing errors (PE). Furthermore, we derive a closed-form expression for the information-theoretic bound of the QKD secret key rate (SKR) of the HAP-to-LAP links. Our findings demonstrate that quadratic phase shifts enhance the SKR at high HAP-ORIS zenith angles or mild PE conditions by narrowing the beam to optimal sizes. By contrast, linear phase shifts are advantageous at low HAP-ORIS zenith angles under moderate-to-high PE by diverging the beam to mitigate LAP fluctuations.",
        "subjects": [
            "eess.SP",
            "physics.optics"
        ],
        "comment": "16 pages, 7 figures, 3 tables"
    },
    {
        "paper id": "2408.06197",
        "abstract url": "https://arxiv.org/abs/2408.06197",
        "title": "Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption",
        "rating": "-4",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "medical",
                "healthcare"
            ]
        ],
        "abstract": "In sectors such as finance and healthcare, where data governance is subject to rigorous regulatory requirements, the exchange and utilization of data are particularly challenging. Federated Learning (FL) has risen as a pioneering distributed machine learning paradigm that enables collaborative model training across multiple institutions while maintaining data decentralization. Despite its advantages, FL is vulnerable to adversarial threats, particularly poisoning attacks during model aggregation, a process typically managed by a central server. However, in these systems, neural network models still possess the capacity to inadvertently memorize and potentially expose individual training instances. This presents a significant privacy risk, as attackers could reconstruct private data by leveraging the information contained in the model itself. Existing solutions fall short of providing a viable, privacy-preserving BRFL system that is both completely secure against information leakage and computationally efficient. To address these concerns, we propose Lancelot, an innovative and computationally efficient BRFL framework that employs fully homomorphic encryption (FHE) to safeguard against malicious client activities while preserving data privacy. Our extensive testing, which includes medical imaging diagnostics and widely-used public image datasets, demonstrates that Lancelot significantly outperforms existing methods, offering more than a twenty-fold increase in processing speed, all while maintaining data privacy.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": "26 pages"
    },
    {
        "paper id": "2408.06185",
        "abstract url": "https://arxiv.org/abs/2408.06185",
        "title": "Hi-SAM: A high-scalable authentication model for satellite-ground Zero-Trust system using mean field game",
        "rating": "-4.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "IoT"
            ],
            [
                "satellite"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "As more and more Internet of Thing (IoT) devices are connected to satellite networks, the Zero-Trust Architecture brings dynamic security to the satellite-ground system, while frequent authentication creates challenges for system availability. To make the system's accommodate more IoT devices, this paper proposes a high-scalable authentication model (Hi-SAM). Hi-SAM introduces the Proof-of-Work idea to authentication, which allows device to obtain the network resource based on frequency. To optimize the frequency, mean field game is used for competition among devices, which can reduce the decision space of large-scale population games. And a dynamic time-range message authentication code is designed for security. From the test at large population scales, Hi-SAM is superior in the optimization of authentication workload and the anomaly detection efficiency.",
        "subjects": [
            "eess.SY",
            "cs.CY",
            "cs.GT",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06524",
        "abstract url": "https://arxiv.org/abs/2408.06524",
        "title": "From Graphs to Qubits: A Critical Review of Quantum Graph Neural Networks",
        "rating": "-4.5",
        "keywords": [
            [
                "GNNs",
                "Graphs"
            ],
            [
                "chemistry"
            ],
            [
                "Quantum",
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantum Graph Neural Networks (QGNNs) represent a novel fusion of quantum computing and Graph Neural Networks (GNNs), aimed at overcoming the computational and scalability challenges inherent in classical GNNs that are powerful tools for analyzing data with complex relational structures but suffer from limitations such as high computational complexity and over-smoothing in large-scale applications. Quantum computing, leveraging principles like superposition and entanglement, offers a pathway to enhanced computational capabilities. This paper critically reviews the state-of-the-art in QGNNs, exploring various architectures. We discuss their applications across diverse fields such as high-energy physics, molecular chemistry, finance and earth sciences, highlighting the potential for quantum advantage. Additionally, we address the significant challenges faced by QGNNs, including noise, decoherence, and scalability issues, proposing potential strategies to mitigate these problems. This comprehensive review aims to provide a foundational understanding of QGNNs, fostering further research and development in this promising interdisciplinary field.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "21 pages, 9 figures, 2 tables. arXiv admin note: text overlap with arXiv:1909.12264 by other authors"
    },
    {
        "paper id": "2408.07099",
        "abstract url": "https://arxiv.org/abs/2408.07099",
        "title": "Bearing Fault Diagnosis using Graph Sampling and Aggregation Network",
        "rating": "-4.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Diagnosis"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Bearing fault diagnosis technology has a wide range of practical applications in industrial production, energy and other fields. Timely and accurate detection of bearing faults plays an important role in preventing catastrophic accidents and ensuring product quality. Traditional signal analysis techniques and deep learning-based fault detection algorithms do not take into account the intricate correlation between signals, making it difficult to further improve detection accuracy. To address this problem, we introduced Graph Sampling and Aggregation (GraphSAGE) network and proposed GraphSAGE-based Bearing fault Diagnosis (GSABFD) algorithm. The original vibration signal is firstly sliced through a fixed size non-overlapping sliding window, and the sliced data is feature transformed using signal analysis methods; then correlations are constructed for the transformed vibration signal and further transformed into vertices in the graph; then the GraphSAGE network is used for training; finally the fault level of the object is calculated in the output layer of the network. The proposed algorithm is compared with five advanced algorithms in a real-world public dataset for experiments, and the results show that the GSABFD algorithm improves the AUC value by 5% compared with the next best algorithm.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06007",
        "abstract url": "https://arxiv.org/abs/2408.06007",
        "title": "Quantum Annealing-Based Algorithm for Efficient Coalition Formation Among LEO Satellites",
        "rating": "-5",
        "keywords": [
            [
                "graph"
            ],
            [
                "satellite"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "The increasing number of Low Earth Orbit (LEO) satellites, driven by lower manufacturing and launch costs, is proving invaluable for Earth observation missions and low-latency internet connectivity. However, as the number of satellites increases, the number of communication links to maintain also rises, making the management of this vast network increasingly challenging and highlighting the need for clustering satellites into efficient groups as a promising solution. This paper formulates the clustering of LEO satellites as a coalition structure generation (CSG) problem and leverages quantum annealing to solve it. We represent the satellite network as a graph and obtain the optimal partitions using a hybrid quantum-classical algorithm called GCS-Q. The algorithm follows a top-down approach by iteratively splitting the graph at each step using a quadratic unconstrained binary optimization (QUBO) formulation. To evaluate our approach, we utilize real-world three-line element set (TLE/3LE) data for Starlink satellites from Celestrak. Our experiments, conducted using the D-Wave Advantage annealer and the state-of-the-art solver Gurobi, demonstrate that the quantum annealer significantly outperforms classical methods in terms of runtime while maintaining the solution quality. The performance achieved with quantum annealers surpasses the capabilities of classical computers, highlighting the transformative potential of quantum computing in optimizing the management of large-scale satellite networks.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.DM",
            "cs.MA"
        ],
        "comment": "6 pages, 4 figures"
    },
    {
        "paper id": "2408.06175",
        "abstract url": "https://arxiv.org/abs/2408.06175",
        "title": "Towards Unconstrained Collision Injury Protection Data Sets: Initial Surrogate Experiments for the Human Hand",
        "rating": "-5",
        "keywords": [
            [
                "robot"
            ],
            [
                "biomechanical",
                "physiological"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Safety for physical human-robot interaction (pHRI) is a major concern for all application domains. While current standardization for industrial robot applications provide safety constraints that address the onset of pain in blunt impacts, these impact thresholds are difficult to use on edged or pointed impactors. The most severe injuries occur in constrained contact scenarios, where crushing is possible. Nevertheless, situations potentially resulting in constrained contact only occur in certain areas of a workspace and design or organisational approaches can be used to avoid them. What remains are risks to the human physical integrity caused by unconstrained accidental contacts, which are difficult to avoid while maintaining robot motion efficiency. Nevertheless, the probability and severity of injuries occurring with edged or pointed impacting objects in unconstrained collisions is hardly researched. In this paper, we propose an experimental setup and procedure using two pendulums modeling human hands and arms and robots to understand the injury potential of unconstrained collisions of human hands with edged objects. Based on our previous studies, we use pig feet as ex vivo surrogate samples - as these closely resemble the physiological characteristics of human hands - to create an initial injury database on the severity of injuries caused by unconstrained edged or pointed impacts. The use of such experimental setups and procedures in addition to other research on the occurrence of injuries in humans will eventually lead to a complete understanding of the biomechanical injury potential in pHRI.",
        "subjects": [
            "cs.RO",
            "cs.DB"
        ],
        "comment": "This work is a preprint and accepted at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) and has been submitted to the IEEE for publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2408.06553",
        "abstract url": "https://arxiv.org/abs/2408.06553",
        "title": "Centralization vs. decentralization in multi-robot coverage: Ground robots under UAV supervision",
        "rating": "-5",
        "keywords": [
            [
                "robotics",
                "robot"
            ],
            [
                "UAV"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "In swarm robotics, decentralized control is often proposed as a more scalable and fault-tolerant alternative to centralized control. However, centralized behaviors are often faster and more efficient than their decentralized counterparts. In any given application, the goals and constraints of the task being solved should guide the choice to use centralized control, decentralized control, or a combination of the two. Currently, the tradeoffs that exist between centralization and decentralization have not been thoroughly studied. In this paper, we investigate these tradeoffs for multi-robot coverage, and find that they are more nuanced than expected. For instance, our findings reinforce the expectation that more decentralized control will provide better scalability, but contradict the expectation that more decentralized control will perform better in environments with randomized obstacles. Beginning with a group of fully independent ground robots executing coverage, we add unmanned aerial vehicles as supervisors and progressively increase the degree to which the supervisors use centralized control, in terms of access to global information and a central coordinating entity. We compare, using the multi-robot physics-based simulation environment ARGoS, the following four control approaches: decentralized control, hybrid control, centralized control, and predetermined control. In comparing the ground robots performing the coverage task, we assess the speed and efficiency advantages of centralization -- in terms of coverage completeness and coverage uniformity -- and we assess the scalability and fault tolerance advantages of decentralization. We also assess the energy expenditure disadvantages of centralization due to different energy consumption rates of ground robots and unmanned aerial vehicles, according to the specifications of robots available off-the-shelf.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "IRIDIA, Universite Libre de Bruxelles, Brussels, Belgium, 2021"
    },
    {
        "paper id": "2408.05942",
        "abstract url": "https://arxiv.org/abs/2408.05942",
        "title": "On the Exactness of SDP Relaxation for Quadratic Assignment Problem",
        "rating": "-10",
        "keywords": [],
        "abstract": "Quadratic assignment problem (QAP) is a fundamental problem in combinatorial optimization and finds numerous applications in operation research, computer vision, and pattern recognition. However, it is a very well-known NP-hard problem to find the global minimizer to the QAP. In this work, we study the semidefinite relaxation (SDR) of the QAP and investigate when the SDR recovers the global minimizer. In particular, we consider the two input matrices satisfy a simple signal-plus-noise model, and show that when the noise is sufficiently smaller than the signal, then the SDR is exact, i.e., it recovers the global minimizer to the QAP. It is worth noting that this sufficient condition is purely algebraic and does not depend on any statistical assumption of the input data. We apply our bound to several statistical models such as correlated Gaussian Wigner model. Despite the sub-optimality in theory under those models, empirical studies show the remarkable performance of the SDR. Our work could be the first step towards a deeper understanding of the SDR exactness for the QAP.",
        "subjects": [
            "math.OC",
            "cs.IT",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05944",
        "abstract url": "https://arxiv.org/abs/2408.05944",
        "title": "Uncertainty Quantification of Spectral Estimator and MLE for Orthogonal Group Synchronization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Orthogonal group synchronization aims to recover orthogonal group elements from their noisy pairwise measurements. It has found numerous applications including computer vision, imaging science, and community detection. Due to the orthogonal constraints, it is often challenging to find the least squares estimator in presence of noise. In the recent years, semidefinite relaxation (SDR) and spectral methods have proven to be powerful tools in recovering the group elements. In particular, under additive Gaussian noise, the SDR exactly produces the maximum likelihood estimator (MLE), and both MLE and spectral methods are able to achieve near-optimal statistical error. In this work, we take one step further to quantify the uncertainty of the MLE and spectral estimators by considering their distributions. By leveraging the orthogonality constraints in the likelihood function, we obtain a second-order expansion of the MLE and spectral estimator with the leading terms as an anti-symmetric Gaussian random matrix that is on the tangent space of the orthogonal matrix. This also implies state-of-the-art min-max risk bounds as a by-product. Our works provide a general theoretical framework that is potentially useful to find an approximate distribution of the estimators arising from many statistical inference problems with manifold constraints. The numerical experiments confirm our theoretical contribution.",
        "subjects": [
            "math.ST",
            "cs.IT",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05954",
        "abstract url": "https://arxiv.org/abs/2408.05954",
        "title": "Parameterized Verification of Systems with Precise (0,1)-Counter Abstraction",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce a new framework for verifying systems with a parametric number of concurrently running processes. The systems we consider are well-structured with respect to a specific well-quasi order. This allows us to decide a wide range of verification problems, including control-state reachability, coverability, and target, in a fixed finite abstraction of the infinite state-space, called a 01-counter system. We show that several systems from the parameterized verification literature fall into this class, including reconfigurable broadcast networks (or systems with lossy broadcast), disjunctive systems, synchronizations and systems with a fixed number of shared finite-domain variables. Our framework provides a simple and unified explanation for the properties of these systems, which have so far been investigated separately. Additionally, it extends and improves on a range of the existing results, and gives rise to other systems with similar properties.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05962",
        "abstract url": "https://arxiv.org/abs/2408.05962",
        "title": "HiCCL: A Hierarchical Collective Communication Library",
        "rating": "-10",
        "keywords": [],
        "abstract": "HiCCL (Hierarchical Collective Communication Library) addresses the growing complexity and diversity in high-performance network architectures. As GPU systems have envolved into networks of GPUs with different multilevel communication hierarchies, optimizing each collective function for a specific system has become a challenging task. Consequently, many collective libraries struggle to adapt to different hardware and software, especially across systems from different vendors. HiCCL's library design decouples the collective communication logic from network-specific optimizations through a compositional API. The communication logic is composed using multicast, reduction, and fence primitives, which are then factorized for a specified network hieararchy using only point-to-point operations within a level. Finally, striping and pipelining optimizations applied as specified for streamlining the execution. Performance evaluation of HiCCL across four different machines$\\unicode{x2014}$two with Nvidia GPUs, one with AMD GPUs, and one with Intel GPUs$\\unicode{x2014}$demonstrates an average 17$\\times$ higher throughput than the collectives of highly specialized GPU-aware MPI implementations, and competitive throughput with those of vendor-specific libraries (NCCL, RCCL, and OneCCL), while providing portability across all four machines.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05965",
        "abstract url": "https://arxiv.org/abs/2408.05965",
        "title": "Time-limited H2-optimal Model Order Reduction of Linear Systems with Quadratic Outputs",
        "rating": "-10",
        "keywords": [],
        "abstract": "An important class of dynamical systems with several practical applications is linear systems with quadratic outputs. These models have the same state equation as standard linear time-invariant systems but differ in their output equations, which are nonlinear quadratic functions of the system states. When dealing with models of exceptionally high order, the computational demands for simulation and analysis can become overwhelming. In such cases, model order reduction proves to be a useful technique, as it allows for constructing a reduced-order model that accurately represents the essential characteristics of the original high-order system while significantly simplifying its complexity. In time-limited model order reduction, the main goal is to maintain the output response of the original system within a specific time range in the reduced-order model. To assess the error within this time interval, a mathematical expression for the time-limited $\\mathcal{H}_2$-norm is derived in this paper. This norm acts as a measure of the accuracy of the reduced-order model within the specified time range. Subsequently, the necessary conditions for achieving a local optimum of the time-limited $\\mathcal{H}_2$ norm error are derived. The inherent inability to satisfy these optimality conditions within the Petrov-Galerkin projection framework is also discussed. After that, a stationary point iteration algorithm based on the optimality conditions and Petrov-Galerkin projection is proposed. Upon convergence, this algorithm fulfills three of the four optimality conditions. To demonstrate the effectiveness of the proposed algorithm, a numerical example is provided that showcases its ability to effectively approximate the original high-order model within the desired time interval.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05970",
        "abstract url": "https://arxiv.org/abs/2408.05970",
        "title": "Comparison of uncertainty propagation techniques in small-body environment",
        "rating": "-10",
        "keywords": [],
        "abstract": "Close-proximity exploration of small celestial bodies is crucial for the comprehensive and accurate characterization of their properties. However, the complex and uncertain dynamical environment around them contributes to a rapid dispersion of uncertainty and the emergence of non-Gaussian distributions. Therefore, to ensure safe operations, a precise understanding of uncertainty propagation becomes imperative. In this work, the dynamical environment is analyzed around two asteroids, Apophis, which will perform a close flyby to Earth in 2029, and Eros, which has been already explored by past missions. The performance of different uncertainty propagation methods (Linear Covariance Propagation, Unscented Transformation, and Polynomial Chaos Expansion) are compared in various scenarios of close-proximity operations around the two asteroids. Findings are discussed in terms of propagation accuracy and computational efficiency depending on the dynamical environment. By exploring these methodologies, this work contributes to the broader goal of ensuring the safety and effectiveness of spacecraft operations during close-proximity exploration of small celestial bodies.",
        "subjects": [
            "astro-ph.EP",
            "astro-ph.IM",
            "eess.SY",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05975",
        "abstract url": "https://arxiv.org/abs/2408.05975",
        "title": "A Metascience Study of the Impact of Low-Code Techniques in Modeling Publications",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the last years, model-related publications have been exploring the application of modeling techniques in different domains. Initially focused on UML and the Model-Driven Architecture approach, the literature has been evolving towards the usage of more general concepts such as Model-Driven Development or Model-Driven Engineering. With the emergence of Low-Code software development platforms, the modeling community has been studying how these two fields may combine and benefit from each other, thus leading to the publication of a number of works in recent years. In this paper, we present a metascience study of Low-Code. Our study has a two-fold approach: (1) to examine the composition (size and diversity) of the emerging Low-Code community; and (2) to investigate how this community differs from the \"classical\" model-driven community in terms of people, venues, and types of publications. Through this study, we aim to benefit the low-code community by helping them better understand its relationship with the broader modeling community. Ultimately, we hope to trigger a discussion about the current and possible future evolution of the low-code community as part of its consolidation as a new research field.",
        "subjects": [
            "cs.SE",
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.05988",
        "abstract url": "https://arxiv.org/abs/2408.05988",
        "title": "Eigenvalue Based Active User Enumeration for Grant-Free Access Under Carrier Frequency Offsets",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates a grant-free non-orthogonal multiple access (GF-NOMA) system in the presence of carrier frequency offsets. We propose two schemes for enumerating active users in such a GF-NOMA system, which is equivalent to estimating the sparsity level. Both schemes utilize a short common pilot and the eigenvalues of the sample covariance matrix of the received signal. The two schemes differ in their treatment of noise variance: one exploits known variance information, while the other is designed to function without this knowledge. Simulation results demonstrate the effectiveness of the proposed schemes in terms of the normalized mean-squared error.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2408.06006",
        "abstract url": "https://arxiv.org/abs/2408.06006",
        "title": "Harmonic Stability Analysis of Microgrids with Converter-Interfaced Distributed Energy Resources, Part I: Modelling and Theoretical Foundations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes a method for the Harmonic Stability Assessment (HSA) of power systems with a high share of Converter-Interfaced Distributed Energy Resources (CIDERs). To this end, the Harmonic State-Space (HSS) model of a generic power system is formulated by combining the HSS models of the resources and the grid in closed-loop configuration. The HSS model of the resources is obtained from the Linear Time Periodic (LTP) models of the CIDER components transformed to frequency domain using Fourier theory and Toeplitz matrices. Notably, the HSS of a CIDER is capable of representing the coupling between harmonic frequencies in detail. The HSS model of the grid is derived from the dynamic equations of the individual branch and shunt elements. The system matrix of the HSS models on power-system or resource level is employed for eigenvalue analysis in the context of HSA. A sensitivity analysis of the eigenvalue loci w.r.t. changes in model parameters, and a classification of eigenvalues into control-design variant, control-design invariant, and design invariant eigenvalues is proposed. A case of harmonic instability is identified by the HSA and validated via Time-Domain Simulations (TDS) in Simulink.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06008",
        "abstract url": "https://arxiv.org/abs/2408.06008",
        "title": "Harmonic Stability Analysis of Microgrids with Converter-Interfaced Distributed Energy Resources, Part II: Case Studies",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Part I of this paper a method for the Harmonic Stability Assessment (HSA) of power systems with a high share of Converter-Interfaced Distributed Energy Resources (CIDERs) was proposed. Specifically, the Harmonic State-Space (HSS) model of a generic power system is derived through combination of the components HSS models. The HSS models of CIDERs and grid are based on Linear Time-Periodic (LTP) models, capable of representing the coupling between different harmonics. In Part II, the HSA of a grid-forming, and two grid-following CIDERs (i.e., ex- and including the DC-side modelling) is performed. More precisely, the classification of the eigenvalues, the impact of the maximum harmonic order on the locations of the eigenvalues, and the sensitivity curves of the eigenvalues w.r.t. to control parameters are provided. These analyses allow to study the physical meaning and origin of the CIDERs eigenvalues. Additionally, the HSA is performed for a representative example system derived from the CIGRE low-voltage benchmark system. A case of harmonic instability is identified through the system eigenvalues, and validated with Time-Domain Simulations (TDS) in Simulink. It is demonstrated that, as opposed to stability analyses based on Linear Time-Invariant (LTI) models, the HSA is suitable for the detection of harmonic instability.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06017",
        "abstract url": "https://arxiv.org/abs/2408.06017",
        "title": "HyperCAN: Hypernetwork-Driven Deep Parameterized Constitutive Models for Metamaterials",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce HyperCAN, a machine learning framework that utilizes hypernetworks to construct adaptable constitutive artificial neural networks for a wide range of beam-based metamaterials exhibiting diverse mechanical behavior under finite deformations. HyperCAN integrates an input convex network that models the nonlinear stress-strain map of a truss lattice, while ensuring adherence to fundamental mechanics principles, along with a hypernetwork that dynamically adjusts the parameters of the convex network as a function of the lattice topology and geometry. This unified framework demonstrates robust generalization in predicting the mechanical behavior of previously unseen metamaterial designs and loading scenarios well beyond the training domain. We show how HyperCAN can be integrated into multiscale simulations to accurately capture the highly nonlinear responses of large-scale truss metamaterials, closely matching fully resolved simulations while significantly reducing computational costs. This offers new efficient opportunities for the multiscale design and optimization of truss metamaterials.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06028",
        "abstract url": "https://arxiv.org/abs/2408.06028",
        "title": "BPMN Analyzer 2.0: Instantaneous, Comprehensible, and Fixable Control Flow Analysis for Realistic BPMN Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many business process models contain control flow errors, such as deadlocks or livelocks, which hinder proper execution. In this paper, we introduce a new tool that can instantaneously identify control flow errors in BPMN models, make them understandable for modelers, and suggest corrections to resolve them. We demonstrate that detection is instantaneous by benchmarking our tool against synthetic BPMN models with increasing size and state space complexity, as well as realistic models. Moreover, the tool directly displays detected errors in the model, including an interactive visualization, and suggests fixes to resolve them. The tool is open source, extensible, and integrated into a popular BPMN modeling tool.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2407.03965"
    },
    {
        "paper id": "2408.06034",
        "abstract url": "https://arxiv.org/abs/2408.06034",
        "title": "The landscape of ontologies in materials science and engineering: A survey and evaluation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ontologies are widely used in materials science to describe experiments, processes, material properties, and experimental and computational workflows. Numerous online platforms are available for accessing and sharing ontologies in Materials Science and Engineering (MSE). Additionally, several surveys of these ontologies have been conducted. However, these studies often lack comprehensive analysis and quality control metrics. This paper provides an overview of ontologies used in Materials Science and Engineering to assist domain experts in selecting the most suitable ontology for a given purpose. Sixty selected ontologies are analyzed and compared based on the requirements outlined in this paper. Statistical data on ontology reuse and key metrics are also presented. The evaluation results provide valuable insights into the strengths and weaknesses of the investigated MSE ontologies. This enables domain experts to select suitable ontologies and to incorporate relevant terms from existing resources.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06035",
        "abstract url": "https://arxiv.org/abs/2408.06035",
        "title": "Syntax-Guided Automated Program Repair for Hyperproperties",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of automatically repairing infinite-state software programs w.r.t. temporal hyperproperties. As a first step, we present a repair approach for the temporal logic HyperLTL based on symbolic execution, constraint generation, and syntax-guided synthesis of repair expression (SyGuS). To improve the repair quality, we introduce the notation of a transparent repair that aims to find a patch that is as close as possible to the original program. As a practical realization, we develop an iterative repair approach. Here, we search for a sequence of repairs that are closer and closer to the original program's behavior. We implement our method in a prototype and report on encouraging experimental results using off-the-shelf SyGuS solvers.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "comment": "CAV 2024"
    },
    {
        "paper id": "2408.06037",
        "abstract url": "https://arxiv.org/abs/2408.06037",
        "title": "Hyperion: Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution",
        "rating": "-10",
        "keywords": [],
        "abstract": "The rapid advancement of blockchain platforms has significantly accelerated the growth of decentralized applications (DApps). Similar to traditional applications, DApps integrate front-end descriptions that showcase their features to attract users, and back-end smart contracts for executing their business logic. However, inconsistencies between the features promoted in front-end descriptions and those actually implemented in the contract can confuse users and undermine DApps's trustworthiness. In this paper, we first conducted an empirical study to identify seven types of inconsistencies, each exemplified by a real-world DApp. Furthermore, we introduce HYPERION, an approach designed to automatically identify inconsistencies between front-end descriptions and back-end code implementation in DApps. This method leverages a fine-tuned large language model LLaMA2 to analyze DApp descriptions and employs dataflow-guided symbolic execution for contract bytecode analysis. Finally, HYPERION reports the inconsistency based on predefined detection patterns. The experiment on our ground truth dataset consisting of 54 DApps shows that HYPERION reaches 84.06% overall recall and 92.06% overall precision in reporting DApp inconsistencies. We also implement HYPERION to analyze 835 real-world DApps. The experimental results show that HYPERION discovers 459 real-world DApps containing at least one inconsistency.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by ICSE 2025"
    },
    {
        "paper id": "2408.06045",
        "abstract url": "https://arxiv.org/abs/2408.06045",
        "title": "DC-DC Converters Optimization in Case of Large Variation in the Load",
        "rating": "-10",
        "keywords": [],
        "abstract": "The method for controlling a DC-DC converter is proposed to ensures the high quality control at large fluctuations in load currents by using differential gain control coefficients and second derivative control. Various implementations of balancing the currents of a multiphase DC-DC converter are discussed, with a focus on achieving accurate current regulation without introducing additional delay in the control system. Stochastic particle swarm optimization method is used to find optimal values of the PID controller parameters. An automatic constraint-handling in optimization are also discussed as relevant techniques in the field.",
        "subjects": [
            "eess.SY",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06080",
        "abstract url": "https://arxiv.org/abs/2408.06080",
        "title": "Sequential sampling without comparison to boundary through model-free reinforcement learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Although evidence integration to the boundary model has successfully explained a wide range of behavioral and neural data in decision making under uncertainty, how animals learn and optimize the boundary remains unresolved. Here, we propose a model-free reinforcement learning algorithm for perceptual decisions under uncertainty that dispenses entirely with the concepts of decision boundary and evidence accumulation. Our model learns whether to commit to a decision given the available evidence or continue sampling information at a cost. We reproduced the canonical features of perceptual decision-making such as dependence of accuracy and reaction time on evidence strength, modulation of speed-accuracy trade-off by payoff regime, and many others. By unifying learning and decision making within the same framework, this model can account for unstable behavior during training as well as stabilized post-training behavior, opening the door to revisiting the extensive volumes of discarded training data in the decision science literature.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06084",
        "abstract url": "https://arxiv.org/abs/2408.06084",
        "title": "A Practical System Architecture for Contract Automation: Design and Uses",
        "rating": "-10",
        "keywords": [],
        "abstract": "While the blockchain-based smart contract has become a hot topic of research over the last decade, not the least in the context of Industry 4.0, it now has well-known legal and technical shortcomings that currently prohibit its real-world application. These shortcomings come from (1) that a smart contract is a computer program, not a document describing legal obligations, and (2) that blockchain-based systems are complicated to use and operate. In this paper, we present a refined and extended summary of our work taking key technologies from the blockchain sphere and applying them to the ricardian contract, which is a traditional contract in digital form with machine-readable parameters. By putting the ricardian contract in the context of our contract network architecture, we facilitate the infrastructure required for contracts to be offered, negotiated, performed, renegotiated and terminated in a completely digital and automatable fashion. Our architecture circumvents the legal issues of blockchains by facilitating an artifact very much alike a traditional contract, as well as its operational complexity by requiring consensus only between nodes representing directly involved parties. To demonstrate its utility, we also present how it could be used for (1) private data purchasing, (2) treasury management, (3) order-driven manufacturing and (4) automated device on-boarding.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "11 pages, 9 figures"
    },
    {
        "paper id": "2408.06086",
        "abstract url": "https://arxiv.org/abs/2408.06086",
        "title": "A Generalised $\u03bb$-Core Concept for Normal Form Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this note we develop a generalisation of the $\u03bb$-Core solution for non-cooperative games in normal form. We show that this generalised $\u03bb$-Core is non-empty for the class of separable games that admit a socially optimal Nash equilibrium. Examples are provided that indicate that non-emptiness of the generalised $\u03bb$-Core cannot be expected for large classes of normal form games.",
        "subjects": [
            "cs.GT",
            "econ.TH"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06107",
        "abstract url": "https://arxiv.org/abs/2408.06107",
        "title": "Augmented Library: Toward Enriching Physical Library Experience Using HMD-Based Augmented Reality",
        "rating": "-10",
        "keywords": [],
        "abstract": "Despite the rise of digital libraries and online reading platforms, physical libraries still offer unique benefits for education and community engagement. However, due to the convenience of digital resources, physical library visits, especially by college students, have declined. This underscores the need to better engage these users. Augmented Reality (AR) could potentially bridge the gap between the physical and digital worlds. In this paper, we present \\textit{Augmented Library}, an HMD-based AR system designed to revitalize the physical library experience. By creating interactive features that enhance book discovery, encourage community engagement, and cater to diverse user needs, \\textit{Augmented Library} combines digital convenience with physical libraries' rich experiences. This paper discusses the development of the system and preliminary user feedback on its impact on student engagement in physical libraries.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "5 pages, 3 figures"
    },
    {
        "paper id": "2408.06109",
        "abstract url": "https://arxiv.org/abs/2408.06109",
        "title": "Inferring directed spectral information flow between mixed-frequency time series",
        "rating": "-10",
        "keywords": [],
        "abstract": "Identifying directed spectral information flow between multivariate time series is important for many applications in finance, climate, geophysics and neuroscience. Spectral Granger causality (SGC) is a prediction-based measure characterizing directed information flow at specific oscillatory frequencies. However, traditional vector autoregressive (VAR) approaches are insufficient to assess SGC when time series have mixed frequencies (MF) or are coupled by nonlinearity. Here we propose a time-frequency canonical correlation analysis approach (\"MF-TFCCA\") to assess the strength and driving frequency of spectral information flow. We validate the approach with intensive computer simulations on MF time series under various interaction conditions and assess statistical significance of the estimate with surrogate data. We further apply MF-TFCCA to real-life finance, climate and neuroscience data. Our analysis framework provides an exploratory and computationally efficient approach to quantify directed information flow between MF time series in the presence of complex and nonlinear interactions.",
        "subjects": [
            "eess.SP",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06117",
        "abstract url": "https://arxiv.org/abs/2408.06117",
        "title": "Modelling of measuring systems -- From white box models to cognitive approaches",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mathematical models of measuring systems and processes play an essential role in metrology and practical measurements. They form the basis for understanding and evaluating measurements, their results and their trustworthiness. Classic analytical parametric modelling is based on largely complete knowledge of measurement technology and the measurement process. But due to digital transformation towards the Internet of Things (IIoT) with an increasing number of intensively and flexibly networked measurement systems and consequently ever larger amounts of data to be processed, data-based modelling approaches have gained enormous importance. This has led to new approaches in measurement technology and industry like Digital Twins, Self-X Approaches, Soft Sensor Technology and Data and Information Fusion. In the future, data-based modelling will be increasingly dominated by intelligent, cognitive systems. Evaluating of the accuracy, trustworthiness and the functional uncertainty of the corresponding models is required. This paper provides a concise overview of modelling in metrology from classical white box models to intelligent, cognitive data-driven solutions identifying advantages and limitations. Additionally, the approaches to merge trustworthiness and metrological uncertainty will be discussed.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 13 figures, 1 table, XXIV IMEKO World Congress - Think Metrology, August 26 - 29, 2024, Hamburg, Germany"
    },
    {
        "paper id": "2408.06130",
        "abstract url": "https://arxiv.org/abs/2408.06130",
        "title": "FaasMeter: Energy-First Serverless Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Functions as a Service has emerged as a popular abstraction for a wide range of cloud applications and an important cloud workload. We present the design and implementation of FaasMeter, a FaaS control plane which provides energy monitoring, accounting, control, and pricing as first-class operations. The highly diverse and dynamic workloads of FaaS create additional complexity to measuring and controlling energy usage which FaasMeter can mitigate. We develop a new statistical energy disaggregation approach to provide accurate and complete energy footprints for functions, despite using noisy and coarse-grained system-level power (not just CPU power readings). Our accurate and robust footprints are achieved by combining conventional power models with Kalman filters and Shapley values. FaasMeter is a full-spectrum energy profiler, and fairly attributes energy of shared resources to functions (such as energy used by the control plane itself). We develop new energy profiling validation metrics, and show that FaasMeter's energy footprints are accurate to within 1\\% of carefully obtained marginal energy ground truth measurements.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "11 figures, 15 pages"
    },
    {
        "paper id": "2408.06134",
        "abstract url": "https://arxiv.org/abs/2408.06134",
        "title": "Learned Indexes with Distribution Smoothing via Virtual Points",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent research on learned indexes has created a new perspective for indexes as models that map keys to their respective storage locations. These learned indexes are created to approximate the cumulative distribution function of the key set, where using only a single model may have limited accuracy. To overcome this limitation, a typical method is to use multiple models, arranged in a hierarchical manner, where the query performance depends on two aspects: (i) traversal time to find the correct model and (ii) search time to find the key in the selected model. Such a method may cause some key space regions that are difficult to model to be placed at deeper levels in the hierarchy. To address this issue, we propose an alternative method that modifies the key space as opposed to any structural or model modifications. This is achieved through making the key set more learnable (i.e., smoothing the distribution) by inserting virtual points. Further, we develop an algorithm named CSV to integrate our virtual point insertion method into existing learned indexes, reducing both their traversal and search time. We implement CSV on state-of-the-art learned indexes and evaluate them on real-world datasets. The extensive experimental results show significant query performance improvement for the keys in deeper levels of the index structures at a low storage cost.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06140",
        "abstract url": "https://arxiv.org/abs/2408.06140",
        "title": "An anisotropic, brittle damage model for finite strains with a generic damage tensor regularization",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper establishes a universal framework for the nonlocal modeling of anisotropic damage at finite strains. By the combination of two recent works, the new framework allows for the flexible incorporation of different established hyperelastic finite strain material formulations into anisotropic damage whilst ensuring mesh-independent results by employing a generic set of micromorphic gradient-extensions. First, the anisotropic damage model, generally satisfying the damage growth criterion, is investigated for the specific choice of a Neo-Hookean material on a single element. Next, the model is applied with different gradient-extensions in structural simulations of an asymmetrically notched specimen to identify an efficient choice in the form of a volumetric-deviatoric regularization. Thereafter, the universal framework, which is without loss of generality here specified for a Neo-Hookean material with a volumetric-deviatoric gradient-extension, successfully serves for the complex simulation of a pressure loaded rotor blade. After acceptance of the manuscript, we make the codes of the material subroutines accessible to the public at https://doi.org/10.5281/zenodo.11171630.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06141",
        "abstract url": "https://arxiv.org/abs/2408.06141",
        "title": "[Draft] High-order observers and high-order state-estimation-based properties of discrete-event systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "State-estimation-based properties are central properties in discrete-event systems modeled by labeled finite-state automata studied over the past 3 decades. Most existing results are based on a single agent who knows the structure of a system and can observe a subset of events and estimate the system's state based on the system's structure and the agent's observation to the system. The main tool used to do state estimation and verify state-estimation-based properties is called \\emph{observer} which is the powerset construction originally proposed by Rabin and Scott in 1959, used to determinize a nondeterministic finite automaton with $\\varepsilon$-transitions. In this paper, we consider labeled finite-state automata, extend the state-estimation-based properties from a single agent to a finite ordered set of agents and also extend the original observer to \\emph{high-order observer} based on the original observer and our \\emph{concurrent composition}. As a result, a general framework on high-order state-estimation-based properties have been built and a basic tool has also been built to verify such properties. This general framework contains many basic properties as its members such as state-based opacity, critical observability, determinism, high-order opacity, etc. Special cases for which verification can be done more efficiently are also discussed. In our general framework, the system's structure is publicly known to all agents $A_1,\\dots,A_n$, each agent $A_i$ has its own observable event set $E_i$, and additionally knows all its preceding agents' observable events but can only observe its own observable events. The intuitive meaning of our high-order observer is what agent $A_n$ knows about what $A_{n-1}$ knows about \\dots what $A_2$ knows about $A_1$'s state estimate of the system.",
        "subjects": [
            "cs.FL"
        ],
        "comment": "32 pages, 38 figures"
    },
    {
        "paper id": "2408.06144",
        "abstract url": "https://arxiv.org/abs/2408.06144",
        "title": "A pragmatic look at education and training of software test engineers: Further cooperation of academia and industry is needed",
        "rating": "-10",
        "keywords": [],
        "abstract": "Alongside software testing education in universities, a great extent of effort and resources are spent on software-testing training activities in industry. For example, there are several international certification schemes in testing, such as those provided by the International Software Testing Qualifications Board (ISTQB), which have been issued to more than 914K testers so far. To train the highly qualified test engineers of tomorrow, it is important for both university educators and trainers in industry to be aware of the status of software testing education in academia versus its training in industry, to analyze the relationships of these two approaches, and to assess ways on how to improve the education / training landscape. For that purpose, this paper provides a pragmatic overview of the issue, presents several recommendations, and hopes to trigger further discussions in the community, between industry and academia, on how to further improve the status-quo, and to find further best practices for more effective education and training of software testers. The paper is based on combined ~40 years of the two authors' technical experience in test engineering, and their ~30 years of experience in providing testing education and training in more than six countries.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06146",
        "abstract url": "https://arxiv.org/abs/2408.06146",
        "title": "Spectral Sparsification by Deterministic Discrepancy Walk",
        "rating": "-10",
        "keywords": [],
        "abstract": "Spectral sparsification and discrepancy minimization are two well-studied areas that are closely related. Building on recent connections between these two areas, we generalize the \"deterministic discrepancy walk\" framework by Pesenti and Vladu [SODA~23] for vector discrepancy to matrix discrepancy, and use it to give a simpler proof of the matrix partial coloring theorem of Reis and Rothvoss [SODA~20]. Moreover, we show that this matrix discrepancy framework provides a unified approach for various spectral sparsification problems, from stronger notions including unit-circle approximation and singular-value approximation to weaker notions including graphical spectral sketching and effective resistance sparsification. In all of these applications, our framework produces improved results with a simpler and deterministic analysis.",
        "subjects": [
            "cs.DS",
            "math.CO"
        ],
        "comment": "32 pages"
    },
    {
        "paper id": "2408.06164",
        "abstract url": "https://arxiv.org/abs/2408.06164",
        "title": "Prototyping and Experimental Results for ISAC-based Channel Knowledge Map",
        "rating": "-10",
        "keywords": [],
        "abstract": "Channel knowledge map (CKM) is a novel approach for achieving environment-aware communication and sensing. This paper presents an integrated sensing and communication (ISAC)-based CKM prototype system, demonstrating the mutualistic relationship between ISAC and CKM. The system consists of an ISAC base station (BS), a user equipment (UE), and a server. By using a shared orthogonal frequency division multiplexing (OFDM) waveform over the millimeter wave (mmWave) band, the ISAC BS is able to communicate with the UE while simultaneously sensing the environment and acquiring the UE's location. The prototype showcases the complete process of the construction and application of the ISAC-based CKM. For CKM construction phase, the BS stores the UE's channel feedback information in a database indexed by the UE's location, including beam indices and channel gain. For CKM application phase, the BS looks up the best beam index from the CKM based on the UE's location to achieve training-free mmWave beam alignment. The experimental results show that ISAC can be used to construct or update CKM while communicating with UEs, and the pre-learned CKM can assist ISAC for training-free beam alignment.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06208",
        "abstract url": "https://arxiv.org/abs/2408.06208",
        "title": "Event-triggered moving horizon estimation for nonlinear systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work proposes an event-triggered moving horizon estimation (ET-MHE) scheme for general nonlinear systems. The key components of the proposed scheme are a novel event-triggering mechanism (ETM) and the suitable design of the MHE cost function. The main characteristic of our method is that the MHE's nonlinear optimization problem is only solved when the ETM triggers the transmission of measured data to the remote state estimator. If no event occurs, then the current state estimate results from an open-loop prediction using the system dynamics. Furthermore, we show robust global exponential stability of the ET-MHE under a suitable detectability condition. Finally, we illustrate the applicability of the proposed method in terms of a nonlinear benchmark example, where we achieved similar estimation performance compared to standard MHE using 86% less computational resources.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06213",
        "abstract url": "https://arxiv.org/abs/2408.06213",
        "title": "Batched Ranged Random Integer Generation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pseudorandom values are often generated as 64-bit binary words. These random words need to be converted into ranged values without statistical bias. We present an efficient algorithm to generate multiple independent uniformly-random bounded integers from a single uniformly-random binary word, without any bias. In the common case, our method uses one multiplication and no division operations per value produced. In practice, our algorithm can more than double the speed of unbiased random shuffling for small to moderately large arrays.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "software: https://github.com/lemire/batched_random"
    },
    {
        "paper id": "2408.06219",
        "abstract url": "https://arxiv.org/abs/2408.06219",
        "title": "120 Domain-Specific Languages for Security",
        "rating": "-10",
        "keywords": [],
        "abstract": "Security engineering, from security requirements engineering to the implementation of cryptographic protocols, is often supported by domain-specific languages (DSLs). Unfortunately, a lack of knowledge about these DSLs, such as which security aspects are addressed and when, hinders their effective use and further research. This systematic literature review examines 120 security-oriented DSLs based on six research questions concerning security aspects and goals, language-specific characteristics, integration into the software development lifecycle (SDLC), and effectiveness of the DSLs. We observe a high degree of fragmentation, which leads to opportunities for integration. We also need to improve the usability and evaluation of security DSLs.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06222",
        "abstract url": "https://arxiv.org/abs/2408.06222",
        "title": "ARCADE: An Augmented Reality Display Environment for Multimodal Interaction with Conversational Agents",
        "rating": "-10",
        "keywords": [],
        "abstract": "Making the interaction with embodied conversational agents accessible in a ubiquitous and natural manner is not only a question of the underlying software but also brings challenges in terms of the technical system that is used to display them. To this end, we present our spatial augmented reality system ARCADE, which can be utilized like a conventional monitor for displaying virtual agents as well as additional content. With its optical-see-through display, ARCADE creates the illusion of the agent being in the room similarly to a human. The applicability of our system is demonstrated in two different dialogue scenarios, which are included in the video accompanying this paper at https://youtu.be/9nH4c4Q-ooE.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06224",
        "abstract url": "https://arxiv.org/abs/2408.06224",
        "title": "A Multi-Year Grey Literature Review on AI-assisted Test Automation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context: Test Automation (TA) techniques are crucial for quality assurance in software engineering but face limitations such as high test suite maintenance costs and the need for extensive programming skills. Artificial Intelligence (AI) offers new opportunities to address these issues through automation and improved practices. Objectives: This study surveys grey literature to explore how AI is adopted in TA, focusing on the problems it solves, its solutions, and the available tools. Additionally, the study gathers expert insights to understand AI's current and future role in TA. Methods: We reviewed over 3,600 grey literature sources over five years, including blogs, white papers, and user manuals, and finally filtered 342 documents to develop taxonomies of TA problems and AI solutions. We also cataloged 100 AI-driven TA tools and interviewed five expert software testers to gain insights into AI's current and future role in TA. Results: The study found that manual test code development and maintenance are the main challenges in TA. In contrast, automated test generation and self-healing test scripts are the most common AI solutions. We identified 100 AI-based TA tools, with Applitools, Testim, Functionize, AccelQ, and Mabl being the most adopted in practice. Conclusion: This paper offers a detailed overview of AI's impact on TA through grey literature analysis and expert interviews. It presents new taxonomies of TA problems and AI solutions, provides a catalog of AI-driven tools, and relates solutions to problems and tools to solutions. Interview insights further revealed the state and future potential of AI in TA. Our findings support practitioners in selecting TA tools and guide future research directions.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06230",
        "abstract url": "https://arxiv.org/abs/2408.06230",
        "title": "The Distributionally Robust Infinite-Horizon LQR",
        "rating": "-10",
        "keywords": [],
        "abstract": "We explore the infinite-horizon Distributionally Robust (DR) linear-quadratic control. While the probability distribution of disturbances is unknown and potentially correlated over time, it is confined within a Wasserstein-2 ball of a radius $r$ around a known nominal distribution. Our goal is to devise a control policy that minimizes the worst-case expected Linear-Quadratic Regulator (LQR) cost among all probability distributions of disturbances lying in the Wasserstein ambiguity set. We obtain the optimality conditions for the optimal DR controller and show that it is non-rational. Despite lacking a finite-order state-space representation, we introduce a computationally tractable fixed-point iteration algorithm. Our proposed method computes the optimal controller in the frequency domain to any desired fidelity. Moreover, for any given finite order, we use a convex numerical method to compute the best rational approximation (in $H_\\infty$-norm) to the optimal non-rational DR controller. This enables efficient time-domain implementation by finite-order state-space controllers and addresses the computational hurdles associated with the finite-horizon approaches to DR-LQR problems, which typically necessitate solving a Semi-Definite Program (SDP) with a dimension scaling with the time horizon. We provide numerical simulations to showcase the effectiveness of our approach.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "Accepted at CDC 2024"
    },
    {
        "paper id": "2408.06241",
        "abstract url": "https://arxiv.org/abs/2408.06241",
        "title": "Sequential non-determinism in tile self-assembly: a general framework and an application to efficient temperature-1 self-assembly of squares",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we work in a 2D version of the probabilistic variant of Winfree's abstract Tile Assembly Model defined by Chandran, Gopalkrishnan and Reif (SICOMP 2012) in which attaching tiles are sampled uniformly with replacement. First, we develop a framework called ``sequential non-determinism'' for analyzing the probabilistic correctness of a non-deterministic, temperature-1 tile assembly system (TAS) in which most (but not all) tile attachments are deterministic and the non-deterministic attachments always occur in a specific order. Our main sequential non-determinism result equates the probabilistic correctness of such a TAS to a finite product of probabilities, each of which 1) corresponds to the probability of the correct type of tile attaching at a point where it is possible for two different types to attach, and 2) ignores all other tile attachments that do not affect the non-deterministic attachment. We then show that sequential non-determinism allows for efficient and geometrically expressive self-assembly. To that end, we constructively prove that for any positive integer $N$ and any real $\u03b4\\in (0,1)$, there exists a TAS that self-assembles into an $N \\times N$ square with probability at least $1 - \u03b4$ using only $O\\left( \\log N + \\log \\frac{1}\u03b4 \\right)$ types of tiles. Our bound improves upon the previous state-of-the-art bound for this problem by Cook, Fu and Schweller (SODA 2011).",
        "subjects": [
            "cs.DS",
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06253",
        "abstract url": "https://arxiv.org/abs/2408.06253",
        "title": "Learning in Time-Varying Monotone Network Games with Dynamic Populations",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present a framework for multi-agent learning in a nonstationary dynamic network environment. More specifically, we examine projected gradient play in smooth monotone repeated network games in which the agents' participation and connectivity vary over time. We model this changing system with a stochastic network which takes a new independent realization at each repetition. We show that the strategy profile learned by the agents through projected gradient dynamics over the sequence of network realizations converges to a Nash equilibrium of the game in which players minimize their expected cost, almost surely and in the mean-square sense. We then show that the learned strategy profile is an almost Nash equilibrium of the game played by the agents at each stage of the repeated game with high probability. Using these two results, we derive non-asymptotic bounds on the regret incurred by the agents.",
        "subjects": [
            "cs.GT",
            "eess.SY",
            "math.DS"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2408.06269",
        "abstract url": "https://arxiv.org/abs/2408.06269",
        "title": "Testing the Isotropic Cauchy Hypothesis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Isotropic $\u03b1$-stable distributions are central in the theory of heavy-tailed distributions and play a role similar to that of the Gaussian density among finite second-moment laws. Given a sequence of $n$ observations, we are interested in characterizing the performance of Likelihood Ratio Tests where two hypotheses are plausible for the observed quantities: either isotropic Cauchy or isotropic Gaussian. Under various setups, we show that the probability of error of such detectors is not always exponentially decaying with $n$ with the leading term in the exponent shown to be logarithmic instead and we determine the constants in that leading term. Perhaps surprisingly, the optimal Bayesian probabilities of error are found to exhibit different asymptotic behaviors.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06275",
        "abstract url": "https://arxiv.org/abs/2408.06275",
        "title": "Robust Instance Optimal Phase-Only Compressed Sensing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Phase-only compressed sensing (PO-CS) is concerned with the recovery of structured signals from the phases of complex measurements. Recent results show that structured signals in the standard sphere $\\mathbb{S}^{n-1}$ can be exactly recovered from complex Gaussian phases, by recasting PO-CS as linear compressed sensing and then applying existing solvers such as basis pursuit. Known guarantees are either non-uniform or do not tolerate model error. We show that this linearization approach is more powerful than the prior results indicate. First, it achieves uniform instance optimality: Under complex Gaussian matrix with a near-optimal number of rows, this approach uniformly recovers all signals in $\\mathbb{S}^{n-1}$ with errors proportional to the model errors of the signals. Specifically, for sparse recovery there exists an efficient estimator $\\mathbf{x}^\\sharp$ and some universal constant $C$ such that $\\|\\mathbf{x}^\\sharp-\\mathbf{x}\\|_2\\le \\frac{C\u03c3_s(\\mathbf{x})_1}{\\sqrt{s}}~(\\forall\\mathbf{x}\\in\\mathbb{S}^{n-1})$, where $\u03c3_s(\\mathbf{x})_1=\\min_{\\mathbf{u}\\in\u03a3^n_s}\\|\\mathbf{u}-\\mathbf{x}\\|_1$ is the model error under $\\ell_1$-norm. Second, the instance optimality is robust to small dense disturbances and sparse corruptions that arise before or after capturing the phases. As an extension, we also propose to recast sparsely corrupted PO-CS as a linear corrupted sensing problem and show that this achieves perfect reconstruction of the signals. Our results resemble the instance optimal guarantees in linear compressed sensing and, to our knowledge, are the first results of this kind for a non-linear sensing scenario.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06282",
        "abstract url": "https://arxiv.org/abs/2408.06282",
        "title": "A characterization for an almost MDS code to be a near MDS code and a proof of the Geng-Yang-Zhang-Zhou conjecture",
        "rating": "-10",
        "keywords": [],
        "abstract": "Let $\\mathbb{F}_q$ be the finite field of $q$ elements, where $q=p^{m}$ with $p$ being a prime number and $m$ being a positive integer. Let $\\mathcal{C}_{(q, n, \u03b4, h)}$ be a class of BCH codes of length $n$ and designed $\u03b4$. A linear code $\\mathcal{C}$ is said to be maximum distance separable (MDS) if the minimum distance $d=n-k+1$. If $d=n-k$, then $\\mathcal{C}$ is called an almost MDS (AMDS) code. Moreover, if both of $\\mathcal{C}$ and its dual code $\\mathcal{C}^{\\bot}$ are AMDS, then $\\mathcal{C}$ is called a near MDS (NMDS) code. In [A class of almost MDS codes, {\\it Finite Fields Appl.} {\\bf 79} (2022), \\#101996], Geng, Yang, Zhang and Zhou proved that the BCH code $\\mathcal{C}_{(q, q+1,3,4)}$ is an almost MDS code, where $q=3^m$ and $m$ is an odd integer, and they also showed that its parameters is $[q+1, q-3, 4]$. Furthermore, they proposed a conjecture stating that the dual code $\\mathcal{C}^{\\bot}_{(q, q+1, 3, 4)}$ is also an AMDS code with parameters $[q+1, 4, q-3]$. In this paper, we first present a characterization for the dual code of an almost MDS code to be an almost MDS code. Then we use this result to show that the Geng-Yang-Zhang-Zhou conjecture is true. Our result together with the Geng-Yang-Zhang-Zhou theorem implies that the BCH code $\\mathcal{C}_{(q, q+1,3,4)}$ is a near MDS code.",
        "subjects": [
            "cs.IT",
            "math.NT"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2408.06288",
        "abstract url": "https://arxiv.org/abs/2408.06288",
        "title": "RIS-Aided Free-Space Optics Communications in A2G Networks over Inverted Gamma-Gamma Turbulent Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the advent of sixth-generation networks, reconfigurable intelligent surfaces (RISs) have revolutionized wireless communications through dynamic electromagnetic wave manipulation, thereby facilitating the adaptability and unparalleled control of real-time performance evaluations. This study proposed a framework to analyze the performance of RIS-assisted free-space optics (FSO) communication over doubly inverted Gamma-Gamma (IGGG) distributions with pointing error impairments. Furthermore, a special scenario addressing secure communication in the potential presence of an eavesdropper. Consequently, we derived closed-form expressions for the outage probability, average bit error rate, average channel capacity, average secrecy capacity, and secrecy outage probability by employing an asymptotic analysis to provide deeper insights into the influence of various system parameters. Finally, we verified our analytical results through appropriate numerical simulations.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06294",
        "abstract url": "https://arxiv.org/abs/2408.06294",
        "title": "AniBalloons: Animated Chat Balloons as Affective Augmentation for Social Messaging and Chatbot Interaction",
        "rating": "-10",
        "keywords": [],
        "abstract": "Despite being prominent and ubiquitous, message-based interaction is limited in nonverbally conveying emotions. Besides emoticons or stickers, messaging users continue seeking richer options for affective communication. Recent research explored using chat balloons' shape and color to communicate emotional states. However, little work explored whether and how chat-balloon animations could be designed to convey emotions. We present the design of AniBalloons, 30 chat-balloon animations conveying Joy, Anger, Sadness, Surprise, Fear, and Calmness. Using AniBalloons as a research means, we conducted three studies to assess the animations' affect recognizability and emotional properties (N = 40), and probe how animated chat balloons would influence communication experience in typical scenarios including instant messaging (N = 72) and chatbot service (N = 70). Our exploration contributes a set of chat-balloon animations to complement non-nonverbal affective communication for a range of message-based interfaces, and empirical insights into how animated chat balloons might mediate particular conversation experiences (e.g., perceived interpersonal closeness, or chatbot personality).",
        "subjects": [
            "cs.HC"
        ],
        "comment": "under the 2nd review after minor revision by International Journal of Human-Computer Studies"
    },
    {
        "paper id": "2408.06304",
        "abstract url": "https://arxiv.org/abs/2408.06304",
        "title": "Control-Flow Attestation: Concepts, Solutions, and Open Challenges",
        "rating": "-10",
        "keywords": [],
        "abstract": "Control-flow attestation unifies the worlds of control-flow integrity and platform attestation by measuring and reporting a target's run-time behaviour to a verifier. Trust assurances in the target are provided by testing whether its execution follows an authorised control-flow path. The problem has been explored in various settings, such as assessing the trustworthiness of cyber-physical systems, Internet of Things devices, cloud platforms, and many others. Despite a significant number of proposals being made in recent years, the area remains fragmented, addressing different adversarial behaviours, verification paradigms, and deployment challenges. In this paper, we present the first survey of control-flow attestation, examining the core ideas and solutions in state-of-the-art schemes. In total, we survey over 30 papers published between 2016-2024, consolidate and compare their key features, and pose several challenges and recommendations for future research in the area.",
        "subjects": [
            "cs.CR",
            "cs.AR",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06428",
        "abstract url": "https://arxiv.org/abs/2408.06428",
        "title": "Large Language Models for Secure Code Assessment: A Multi-Language Empirical Study",
        "rating": "-10",
        "keywords": [],
        "abstract": "Most vulnerability detection studies focus on datasets of vulnerabilities in C/C++ code, offering limited language diversity. Thus, the effectiveness of deep learning methods, including large language models (LLMs), in detecting software vulnerabilities beyond these languages is still largely unexplored. In this paper, we evaluate the effectiveness of LLMs in detecting and classifying Common Weakness Enumerations (CWE) using different prompt and role strategies. Our experimental study targets six state-of-the-art pre-trained LLMs (GPT-3.5- Turbo, GPT-4 Turbo, GPT-4o, CodeLLama-7B, CodeLLama- 13B, and Gemini 1.5 Pro) and five programming languages: Python, C, C++, Java, and JavaScript. We compiled a multi-language vulnerability dataset from different sources, to ensure representativeness. Our results showed that GPT-4o achieves the highest vulnerability detection and CWE classification scores using a few-shot setting. Aside from the quantitative results of our study, we developed a library called CODEGUARDIAN integrated with VSCode which enables developers to perform LLM-assisted real-time vulnerability analysis in real-world security scenarios. We have evaluated CODEGUARDIAN with a user study involving 22 developers from the industry. Our study showed that, by using CODEGUARDIAN, developers are more accurate and faster at detecting vulnerabilities.",
        "subjects": [
            "cs.SE",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06432",
        "abstract url": "https://arxiv.org/abs/2408.06432",
        "title": "BFTBrain: Adaptive BFT Consensus with Reinforcement Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents BFTBrain, a reinforcement learning (RL) based Byzantine fault-tolerant (BFT) system that provides significant operational benefits: a plug-and-play system suitable for a broad set of hardware and network configurations, and adjusts effectively in real-time to changing fault scenarios and workloads. BFTBrain adapts to system conditions and application needs by switching between a set of BFT protocols in real-time. Two main advances contribute to BFTBrain's agility and performance. First, BFTBrain is based on a systematic, thorough modeling of metrics that correlate the performance of the studied BFT protocols with varying fault scenarios and workloads. These metrics are fed as features to BFTBrain's RL engine in order to choose the best-performing BFT protocols in real-time. Second, BFTBrain coordinates RL in a decentralized manner which is resilient to adversarial data pollution, where nodes share local metering values and reach the same learning output by consensus. As a result, in addition to providing significant operational benefits, BFTBrain improves throughput over fixed protocols by $18\\%$ to $119\\%$ under dynamic conditions and outperforms state-of-the-art learning based approaches by $44\\%$ to $154\\%$.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "To appear in 22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI), April 2025"
    },
    {
        "paper id": "2408.06455",
        "abstract url": "https://arxiv.org/abs/2408.06455",
        "title": "Massively Parallel Minimum Spanning Tree in General Metric Spaces",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the minimum spanning tree (MST) problem in the massively parallel computation (MPC) model. Our focus is particularly on the *strictly sublinear* regime of MPC where the space per machine is $O(n^\u03b4)$. Here $n$ is the number of vertices and constant $\u03b4\\in (0, 1)$ can be made arbitrarily small. The MST problem admits a simple and folklore $O(\\log n)$-round algorithm in the MPC model. When the weights can be arbitrary, this matches a conditional lower bound of $\u03a9(\\log n)$ which follows from a well-known 1vs2-Cycle conjecture. As such, much of the literature focuses on breaking the logarithmic barrier in more structured variants of the problem, such as when the vertices correspond to points in low- [ANOY14, STOC'14] or high-dimensional Euclidean spaces [JMNZ, SODA'24]. In this work, we focus more generally on metric spaces. Namely, all pairwise weights are provided and guaranteed to satisfy the triangle inequality, but are otherwise unconstrained. We show that for any $\\varepsilon > 0$, a $(1+\\varepsilon)$-approximate MST can be found in $O(\\log \\frac{1}{\\varepsilon} + \\log \\log n)$ rounds, which is the first $o(\\log n)$-round algorithm for finding any constant approximation in this setting. Other than being applicable to more general weight functions, our algorithm also slightly improves the $O(\\log \\log n \\cdot \\log \\log \\log n)$ round-complexity of [JMNZ24, SODA'24] and significantly improves its approximation from a large constant to $1+\\varepsilon$. On the lower bound side, we prove that under the 1vs2-Cycle conjecture, $\u03a9(\\log \\frac{1}{\\varepsilon})$ rounds are needed for finding a $(1+\\varepsilon)$-approximate MST in general metrics. It is worth noting that while many existing lower bounds in the MPC model under the 1vs2-Cycle conjecture only hold against \"component stable\" algorithms, our lower bound applies to *all* algorithms.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06460",
        "abstract url": "https://arxiv.org/abs/2408.06460",
        "title": "Evaluating Privacy Measures for Load Hiding",
        "rating": "-10",
        "keywords": [],
        "abstract": "In smart grids, the use of smart meters to measure electricity consumption at a household level raises privacy concerns. To address them, researchers have designed various load hiding algorithms that manipulate the electricity consumption measured. To compare how well these algorithms preserve privacy, various privacy measures have been proposed. However, there currently is no consensus on which privacy measure is most appropriate to use. In this study, we aim to identify the most effective privacy measure(s) for load hiding algorithms. We have crafted a series of experiments to assess the effectiveness of these measures. found 20 of the 25 measures studied to be ineffective. Next, focused on the well-known \"appliance usage\" secret, we have designed synthetic data to find the measure that best deals with this secret. We observe that such a measure, a variant of mutual information, actually exists.",
        "subjects": [
            "cs.CR",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06475",
        "abstract url": "https://arxiv.org/abs/2408.06475",
        "title": "Quasi-Monte Carlo Beyond Hardy-Krause",
        "rating": "-10",
        "keywords": [],
        "abstract": "The classical approaches to numerically integrating a function $f$ are Monte Carlo (MC) and quasi-Monte Carlo (QMC) methods. MC methods use random samples to evaluate $f$ and have error $O(\u03c3(f)/\\sqrt{n})$, where $\u03c3(f)$ is the standard deviation of $f$. QMC methods are based on evaluating $f$ at explicit point sets with low discrepancy, and as given by the classical Koksma-Hlawka inequality, they have error $\\widetilde{O}(\u03c3_{\\mathsf{HK}}(f)/n)$, where $\u03c3_{\\mathsf{HK}}(f)$ is the variation of $f$ in the sense of Hardy and Krause. These two methods have distinctive advantages and shortcomings, and a fundamental question is to find a method that combines the advantages of both. In this work, we give a simple randomized algorithm that produces QMC point sets with the following desirable features: (1) It achieves substantially better error than given by the classical Koksma-Hlawka inequality. In particular, it has error $\\widetilde{O}(\u03c3_{\\mathsf{SO}}(f)/n)$, where $\u03c3_{\\mathsf{SO}}(f)$ is a new measure of variation that we introduce, which is substantially smaller than the Hardy-Krause variation. (2) The algorithm only requires random samples from the underlying distribution, which makes it as flexible as MC. (3) It automatically achieves the best of both MC and QMC (and the above improvement over Hardy-Krause variation) in an optimal way. (4) The algorithm is extremely efficient, with an amortized $\\widetilde{O}(1)$ runtime per sample. Our method is based on the classical transference principle in geometric discrepancy, combined with recent algorithmic innovations in combinatorial discrepancy that besides producing low-discrepancy colorings, also guarantee certain subgaussian properties. This allows us to bypass several limitations of previous works in bridging the gap between MC and QMC methods and go beyond the Hardy-Krause variation.",
        "subjects": [
            "cs.DS",
            "cs.CG",
            "cs.DM",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06478",
        "abstract url": "https://arxiv.org/abs/2408.06478",
        "title": "Theorem-Carrying-Transaction: Runtime Certification to Ensure Safety for Smart Contract Transactions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Security bugs and trapdoors in smart contracts have been impacting the Ethereum community since its inception. Conceptually, the 1.45-million Ethereum's contracts form a single \"gigantic program\" whose behaviors are determined by the complex reference-topology between the contracts. Can the Ethereum community be assured that this gigantic program conforms to its design-level safety properties, despite unforeseeable code-level intricacies? Static code verification is inadequate due to the program's gigantic scale and high polymorphism. In this paper, we present a viable technological roadmap for the community toward this ambitious goal. Our technology, called Theorem-Carrying-Transaction (TCT), combines the benefits of concrete execution and symbolic proofs. Under the TCT protocol, every transaction carries a theorem that proves its adherence to the specified properties in the invoked contracts, and the runtime system checks the theorem before executing the transaction. Once a property is specified in a contract, it can be treated confidently as an unconditional guarantee made by the contract. As case studies, we demonstrate that TCT secures token contracts without foreseeing code-level intricacies like integer overflow and reentrancy. TCT is also successfully applied to a Uniswap codebase, showcasing a complex decentralized finance (DeFi) scenario. Our prototype incurs a negligible runtime overhead, two orders of magnitude lower than a state-of-the-art approach.",
        "subjects": [
            "cs.CR",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06480",
        "abstract url": "https://arxiv.org/abs/2408.06480",
        "title": "Dynamic Equivalent Identification of Interconnected Areas Using Disturbance records from Synchro phasor Measurement Units",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a methodology for modelling a dynamic equivalent of an external area is presented. The equivalent consists of a generator with series impedance and a parallel load (generalized Ward equivalent), integrating control systems such as the Automatic Voltage Regulator (AVR) and the Speed Regulator (GOV) in a test system known as PST-16. The main objective is to identify the parameters of the control systems and other parameters inherent to the generator so that the response of the equivalent system is similar to the response of the complete system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "in Spanish language"
    },
    {
        "paper id": "2408.06483",
        "abstract url": "https://arxiv.org/abs/2408.06483",
        "title": "Clock Auctions Augmented with Unreliable Advice",
        "rating": "-10",
        "keywords": [],
        "abstract": "We provide the first analysis of clock auctions through the learning-augmented framework. Deferred-acceptance clock auctions are a compelling class of mechanisms satisfying a unique list of highly practical properties, including obvious strategy-proofness, transparency, and unconditional winner privacy, making them particularly well-suited for real-world applications. However, early work that evaluated their performance from a worst-case analysis standpoint concluded that no deterministic clock auction can achieve much better than an $O(\\log n)$ approximation of the optimal social welfare (where $n$ is the number of bidders participating in the auction), even in seemingly very simple settings. To overcome this overly pessimistic impossibility result, which heavily depends on the assumption that the designer has no information regarding the preferences of the participating bidders, we leverage the learning-augmented framework. This framework assumes that the designer is provided with some advice regarding what the optimal solution may be. This advice may be the product of machine-learning algorithms applied to historical data, so it can provide very useful guidance, but it can also be highly unreliable. Our main results are learning-augmented clock auctions that use this advice to achieve much stronger performance guarantees whenever the advice is accurate (known as consistency), while simultaneously maintaining worst-case guarantees even if this advice is arbitrarily inaccurate (known as robustness). Specifically, for the standard notion of consistency, we provide a clock auction that achieves the best of both worlds: $(1+\u03b5)$-consistency for any constant $\u03b5> 0$ and $O(\\log n)$ robustness. We then also consider a much stronger notion of consistency and provide an auction that achieves the optimal trade-off between this notion of consistency and robustness.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06505",
        "abstract url": "https://arxiv.org/abs/2408.06505",
        "title": "Multilingual Crowd-Based Requirements Engineering Using Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "A central challenge for ensuring the success of software projects is to assure the convergence of developers' and users' views. While the availability of large amounts of user data from social media, app store reviews, and support channels bears many benefits, it still remains unclear how software development teams can effectively use this data. We present an LLM-powered approach called DeeperMatcher that helps agile teams use crowd-based requirements engineering (CrowdRE) in their issue and task management. We are currently implementing a command-line tool that enables developers to match issues with relevant user reviews. We validated our approach on an existing English dataset from a well-known open-source project. Additionally, to check how well DeeperMatcher works for other languages, we conducted a single-case mechanism experiment alongside developers of a local project that has issues and user feedback in Brazilian Portuguese. Our preliminary analysis indicates that the accuracy of our approach is highly dependent on the text embedding method used. We discuss further refinements needed for reliable crowd-based requirements engineering with multilingual support.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted to the Insightful Ideas and Emerging Results Track of the 38th Brazilian Symposium on Software Engineering (SBES 2024)"
    },
    {
        "paper id": "2408.06506",
        "abstract url": "https://arxiv.org/abs/2408.06506",
        "title": "TacSL: A Library for Visuotactile Sensor Simulation and Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "For both humans and robots, the sense of touch, known as tactile sensing, is critical for performing contact-rich manipulation tasks. Three key challenges in robotic tactile sensing are 1) interpreting sensor signals, 2) generating sensor signals in novel scenarios, and 3) learning sensor-based policies. For visuotactile sensors, interpretation has been facilitated by their close relationship with vision sensors (e.g., RGB cameras). However, generation is still difficult, as visuotactile sensors typically involve contact, deformation, illumination, and imaging, all of which are expensive to simulate; in turn, policy learning has been challenging, as simulation cannot be leveraged for large-scale data collection. We present \\textbf{TacSL} (\\textit{taxel}), a library for GPU-based visuotactile sensor simulation and learning. \\textbf{TacSL} can be used to simulate visuotactile images and extract contact-force distributions over $200\\times$ faster than the prior state-of-the-art, all within the widely-used Isaac Gym simulator. Furthermore, \\textbf{TacSL} provides a learning toolkit containing multiple sensor models, contact-intensive training environments, and online/offline algorithms that can facilitate policy learning for sim-to-real applications. On the algorithmic side, we introduce a novel online reinforcement-learning algorithm called asymmetric actor-critic distillation (\\sysName), designed to effectively and efficiently learn tactile-based policies in simulation that can transfer to the real world. Finally, we demonstrate the utility of our library and algorithms by evaluating the benefits of distillation and multimodal sensing for contact-rich manip ulation tasks, and most critically, performing sim-to-real transfer. Supplementary videos and results are at \\url{https://iakinola23.github.io/tacsl/}.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06511",
        "abstract url": "https://arxiv.org/abs/2408.06511",
        "title": "Modeling and Simulation of Traffic on I-485 via Linear Systems and Iterative Methods",
        "rating": "-10",
        "keywords": [],
        "abstract": "Iterative methods such as Jacobi, Gauss-Seidel, and Successive Over-Relaxation (SOR) are fundamental tools in solving large systems of linear equations across various scientific fields, particularly in the field of data science which has become increasingly relevant in the past decade. Iterative methods' use of matrix multiplication rather than matrix inverses makes them ideal for solving large systems quickly. Our research explores the factors of each method that define their respective strengths, limitations, and convergence behaviors to understand how these methods address drawbacks encountered when performing matrix operations by hand, as well as how they can be used in real world applications. After implementing each method by hand to understand how the algorithms work, we developed a Python program that assesses a user-given matrix based on each method's specific convergence criteria. The program compares the spectral radii of all three methods and chooses to execute whichever will yield the fastest convergence rate. Our research revealed the importance of mathematical modeling and understanding specific properties of the coefficient matrix. We observed that Gauss-Seidel is usually the most efficient method because it is faster than Jacobi and doesn't have as strict requirements as SOR, however SOR is ideal in terms of computation speed. We applied the knowledge we gained to create a traffic flow model of the I-485 highway in Charlotte. After creating a program that generates the matrix for this model, we were able to iteratively approximate the flow of cars through neighboring exits using data from the N.C. Department of Transportation. This information identifies which areas are the most congested and can be used to inform future infrastructure development.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06513",
        "abstract url": "https://arxiv.org/abs/2408.06513",
        "title": "De-cluttering Scatterplots with Integral Images",
        "rating": "-10",
        "keywords": [],
        "abstract": "Scatterplots provide a visual representation of bivariate data (or 2D embeddings of multivariate data) that allows for effective analyses of data dependencies, clusters, trends, and outliers. Unfortunately, classical scatterplots suffer from scalability issues, since growing data sizes eventually lead to overplotting and visual clutter on a screen with a fixed resolution, which hinders the data analysis process. We propose an algorithm that compensates for irregular sample distributions by a smooth transformation of the scatterplot's visual domain. Our algorithm evaluates the scatterplot's density distribution to compute a regularization mapping based on integral images of the rasterized density function. The mapping preserves the samples' neighborhood relations. Few regularization iterations suffice to achieve a nearly uniform sample distribution that efficiently uses the available screen space. We further propose approaches to visually convey the transformation that was applied to the scatterplot and compare them in a user study. We present a novel parallel algorithm for fast GPU-based integral-image computation, which allows for integrating our de-cluttering approach into interactive visual data analysis systems.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "14 pages, 11 figures, accepted at IEEE Transactions on Visualization and Computer Graphics (TVCG)"
    },
    {
        "paper id": "2408.06516",
        "abstract url": "https://arxiv.org/abs/2408.06516",
        "title": "Quantifying Phase Unbalance and Coordination Impacts on Distribution Network Flexibility",
        "rating": "-10",
        "keywords": [],
        "abstract": "The increasing integration of distributed energy resources (DER) provides distribution system operators (DSO) with new flexible resources to support more efficient operation and planning of distribution networks. To utilise these resources, various DER flexibility aggregation methods have been proposed in the literature, such as aggregated P-Q flexibility areas at the interface with other networks. However, whereas focusing on estimating the limits of flexibility services, existing studies make the critical assumption that all available flexible units are perfectly coordinated to jointly provide flexibility and manage network constraints. Moreover, due to the extensive use of single-phase power flow analysis, the impacts of phase unbalance on DER flexibility aggregation remain largely unexplored. To address these gaps in knowledge, this work proposes a framework for modelling flexibility services in low voltage (LV) distribution networks which enables explicitly imposing voltage unbalance and phase coordination constraints. The simulations, performed for an illustrative 5-bus system and a real 221-bus LV network in the UK, demonstrate that a significant share (over 30%) of total aggregated DER flexibility potential may be unavailable due to voltage unbalances and lack of coordination between DER connected to different phases.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06541",
        "abstract url": "https://arxiv.org/abs/2408.06541",
        "title": "Interactive Coding with Small Memory and Improved Rate",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we study two-party interactive coding for adversarial noise, when both parties have limited memory. We show how to convert any adaptive protocol $\u03a0$ into a protocol $\u03a0'$ that is robust to an $\u03b5$-fraction of adversarial corruptions, not too much longer than $\u03a0$, and which uses small space. More precisely, if $\u03a0$ requires space $\\log(s)$ and has $|\u03a0|$ rounds of communication, then $\u03a0'$ requires $O_\u03b5(\\log s \\log |\u03a0|)$ memory, and has $$|\u03a0'| = |\u03a0|\\cdot\\left( 1 + O\\left( \\sqrt{ \u03b5\\log \\log 1/\u03b5} \\right)\\right)$$ rounds of communication. The above matches the best known communication rate, even for protocols with no space restrictions.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06545",
        "abstract url": "https://arxiv.org/abs/2408.06545",
        "title": "Optimal Preprocessing for Joint Detection and Classification of Wireless Communication Signals in Congested Spectrum Using Computer Vision Methods",
        "rating": "-10",
        "keywords": [],
        "abstract": "The joint detection and classification of RF signals has been a critical problem in the field of wideband RF spectrum sensing. Recent advancements in deep learning models have revolutionized this field, remarkably through the application of state-of-the-art computer vision algorithms such as YOLO (You Only Look Once) and DETR (Detection Transformer) to the spectrogram images. This paper focuses on optimizing the preprocessing stage to enhance the performance of these computer vision models. Specifically, we investigated the generation of training spectrograms via the classical Short-Time Fourier Transform (STFT) approach, examining four classical STFT parameters: FFT size, window type, window length, and overlapping ratio. Our study aims to maximize the mean average precision (mAP) scores of YOLOv10 models in detecting and classifying various digital modulation signals within a congested spectrum environment. Firstly, our results reveal that additional zero padding in FFT does not enhance detection and classification accuracy and introduces unnecessary computational cost. Secondly, our results indicated that there exists an optimal window size that balances the trade-offs between and the time and frequency resolution, with performance losses of approximately 10% and 30% if the window size is four or eight times off from the optimal. Thirdly, regarding the choice of window functions, the Hamming window yields optimal performance, with non-optimal windows resulting in up to a 10% accuracy loss. Finally, we found a 10% accuracy score performance gap between using 10% and 90% overlap. These findings highlight the potential for significant performance improvements through optimized spectrogram parameters when applying computer vision models to the problem of wideband RF spectrum sensing.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06546",
        "abstract url": "https://arxiv.org/abs/2408.06546",
        "title": "Misfitting With AI: How Blind People Verify and Contest AI Errors",
        "rating": "-10",
        "keywords": [],
        "abstract": "Blind people use artificial intelligence-enabled visual assistance technologies (AI VAT) to gain visual access in their everyday lives, but these technologies are embedded with errors that may be difficult to verify non-visually. Previous studies have primarily explored sighted users' understanding of AI output and created vision-dependent explainable AI (XAI) features. We extend this body of literature by conducting an in-depth qualitative study with 26 blind people to understand their verification experiences and preferences. We begin by describing errors blind people encounter, highlighting how AI VAT fails to support complex document layouts, diverse languages, and cultural artifacts. We then illuminate how blind people make sense of AI through experimenting with AI VAT, employing non-visual skills, strategically including sighted people, and cross-referencing with other devices. Participants provided detailed opportunities for designing accessible XAI, such as affordances to support contestation. Informed by disability studies framework of misfitting and fitting, we unpacked harmful assumptions with AI VAT, underscoring the importance of celebrating disabled ways of knowing. Lastly, we offer practical takeaways for Responsible AI practice to push the field of accessible XAI forward.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "To Appear in ASSETS 2024"
    },
    {
        "paper id": "2408.06550",
        "abstract url": "https://arxiv.org/abs/2408.06550",
        "title": "Stretch or Vibrate? Rendering Spatial Information of Static and Moving Objects in VR via Haptic Feedback for Blind People",
        "rating": "-10",
        "keywords": [],
        "abstract": "Perceiving spatial information of a virtual object (e.g., direction, distance) is critical yet challenging for blind users seeking an immersive virtual reality experience. To facilitate VR accessibility for blind users, in this paper, we investigate the effectiveness of two types of haptic cues--vibrotactile and skin-stretch cues--in conveying the spatial information of a virtual object when applied to the dorsal side of a blind user's hand. We conducted a user study with 10 blind users to investigate how they perceive static and moving objects in VR with a custom-made haptic apparatus. Our results reveal that blind users can more accurately understand an object's location and movement when receiving skin-stretch cues, as opposed to vibrotactile cues. We discuss the pros and cons of both types of haptic cues and conclude with design recommendations for future haptic solutions for VR accessibility.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06552",
        "abstract url": "https://arxiv.org/abs/2408.06552",
        "title": "HaptoFloater: Visuo-Haptic Augmented Reality by Embedding Imperceptible Color Vibration Signals for Tactile Display Control in a Mid-Air Image",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose HaptoFloater, a low-latency mid-air visuo-haptic augmented reality (VHAR) system that utilizes imperceptible color vibrations. When adding tactile stimuli to the visual information of a mid-air image, the user should not perceive the latency between the tactile and visual information. However, conventional tactile presentation methods for mid-air images, based on camera-detected fingertip positioning, introduce latency due to image processing and communication. To mitigate this latency, we use a color vibration technique; humans cannot perceive the vibration when the display alternates between two different color stimuli at a frequency of 25 Hz or higher. In our system, we embed this imperceptible color vibration into the mid-air image formed by a micromirror array plate, and a photodiode on the fingertip device directly detects this color vibration to provide tactile stimulation. Thus, our system allows for the tactile perception of multiple patterns on a mid-air image in 59.5 ms. In addition, we evaluate the visual-haptic delay tolerance on a mid-air display using our VHAR system and a tactile actuator with a single pattern and faster response time. The results of our user study indicate a visual-haptic delay tolerance of 110.6 ms, which is considerably larger than the latency associated with systems using multiple tactile patterns.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "10 pages, 11 figures"
    },
    {
        "paper id": "2408.06556",
        "abstract url": "https://arxiv.org/abs/2408.06556",
        "title": "An improved point-to-surface contact algorithm with penalty method for peridynamics",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is significantly challenging to obtain accurate contact forces in peridynamics (PD) simulations due to the difficulty of surface particles identification, particularly for complex geometries. Here, an improved point-to-surface contact model is proposed for PD with high accuracy. First, the outer surface is identified using the eigenvalue method and then we construct a Verlet list to identify potential contact particle pairs efficiently. Subsequently, a point-to-surface contact search algorithm is utilized to determine precise contact locations with the penalty function method calculating the contact force. Finally, the accuracy of this point-to-surface contact model is validated through several representative contact examples. The results demonstrate that the point-to-surface contact model model can predict contact forces and deformations with high accuracy, aligning well with the classical Hertz contact theory solutions. This work presents a contact model for PD that automatically recognizes external surface particles and accurately calculates the contact force, which provides guidance for the study of multi-body contact as well as complex contact situations.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "27 pages, 27 figures, 1 table"
    },
    {
        "paper id": "2408.06558",
        "abstract url": "https://arxiv.org/abs/2408.06558",
        "title": "Can Wireless Environmental Information Decrease Pilot Overhead: A CSI Prediction Example",
        "rating": "-10",
        "keywords": [],
        "abstract": "Channel state information (CSI) is crucial for massive multi-input multi-output (MIMO) system. As the antenna scale increases, acquiring CSI results in significantly higher system overhead. In this letter, we propose a novel channel prediction method which utilizes wireless environmental information with pilot pattern optimization for CSI prediction (WEI-CSIP). Specifically, scatterers around the mobile station (MS) are abstracted from environmental information using multiview images. Then, an environmental feature map is extracted by a convolutional neural network (CNN). Additionally, the deep probabilistic subsampling (DPS) network acquires an optimal fixed pilot pattern. Finally, a CNN-based channel prediction network is designed to predict the complete CSI, using the environmental feature map and partial CSI. Simulation results show that the WEI-CSIP can reduce pilot overhead from 1/5 to 1/8, while improving prediction accuracy with normalized mean squared error reduced to 0.0113, an improvement of 83.2% compared to traditional channel prediction methods.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06570",
        "abstract url": "https://arxiv.org/abs/2408.06570",
        "title": "An Infrastructure Cost Optimised Algorithm for Partitioning of Microservices",
        "rating": "-10",
        "keywords": [],
        "abstract": "The evolution and advances made in the field of Cloud engineering influence the constant changes in software application development cycle and practices. Software architecture has evolved along with other domains and capabilities of software engineering. As migrating applications into the cloud is universally adopted by the software industry, microservices have proven to be the most suitable and widely accepted architecture pattern for applications deployed on distributed cloud. Their efficacy is enabled by both technical benefits like reliability, fault isolation, scalability and productivity benefits like ease of asset maintenance and clear ownership boundaries which in turn lead to fewer interdependencies and shorter development cycles thereby resulting in faster time to market. Though microservices have been established as an architecture pattern over the last decade, many organizations fail to optimize the architecture design to maximize efficiency. In some cases, the complexity of migrating an existing application into the microservices architecture becomes overwhelmingly complex and expensive. Additionally, automation and tool support for this problem are still at an early stage as there isn't a single well-acknowledged pattern or tool which could support the decomposition. This paper discusses a few impactful previous research and survey efforts to identify the lack of infrastructure cost optimization as a parameter in any of the approaches present. This paper proposes an Infrastructure-optimised predictive algorithm for partitioning monolithic software into microservices. It also summarizes the scope for future research opportunities within the area of microservices architecture and distributed cloud networks.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2408.06579",
        "abstract url": "https://arxiv.org/abs/2408.06579",
        "title": "Understanding Power Consumption Metric on Heterogeneous Memory Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Contemporary memory systems contain a variety of memory types, each possessing distinct characteristics. This trend empowers applications to opt for memory types aligning with developer's desired behavior. As a result, developers gain flexibility to tailor their applications to specific needs, factoring in attributes like latency, bandwidth, and power consumption. Our research centers on the aspect of power consumption within memory systems. We introduce an approach that equips developers with comprehensive insights into the power consumption of individual memory types. Additionally, we propose an ordered hierarchy of memory types. Through this methodology, developers can make informed decisions for efficient memory usage aligned with their unique requirements.",
        "subjects": [
            "cs.PF",
            "cs.DC"
        ],
        "comment": "ICPADS 2023"
    },
    {
        "paper id": "2408.06584",
        "abstract url": "https://arxiv.org/abs/2408.06584",
        "title": "Fast Transceiver Design for RIS-Assisted MIMO mmWave Wireless Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Due to high bandwidth and small antenna size, millimeter-wave (mmWave) integrated line-of-sight (LOS) multiple-input-multiple-output (MIMO) systems have attracted much attention. Reconfigurable intelligent surfaces (RISs), which have the potential to change the characteristics of incident electromagnetic waves with low power cost, can improve the performance or the MIMO mmWave wireless communications. Uniform circular array (UCA) is an effective antenna structure with low complexity transceiver. In this paper, UCA based RIS-assisted MIMO mmWave wireless communications with transmit UCA, the RIS UCAs, and receive UCA are investigated. Since the rotation angles between the transceiver make the channel matrix noncirculant, an algorithm is developed to derive the ranges of the rotation angles based on an acceptable error and reduce the impact of rotation angles on channel matrix. Then, we propose a low-complexity precoding scheme at the transmitter, phase designs at the RIS UCAs, and a phase compensation scheme at the receiver, which can convert the channel matrix into an equivalent circulant channel matrix with a small error. Then, a fast symbol-wise maximum likelihood (ML) detection scheme is proposed to recover the signals with low computational complexity. Simulation results are presented to illustrate the theory.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06585",
        "abstract url": "https://arxiv.org/abs/2408.06585",
        "title": "SSAAM: Sentiment Signal-based Asset Allocation Method with Causality Information",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study demonstrates whether financial text is useful for tactical asset allocation using stocks by using natural language processing to create polarity indexes in financial news. In this study, we performed clustering of the created polarity indexes using the change-point detection algorithm. In addition, we constructed a stock portfolio and rebalanced it at each change point utilizing an optimization algorithm. Consequently, the asset allocation method proposed in this study outperforms the comparative approach. This result suggests that the polarity index helps construct the equity asset allocation method.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06588",
        "abstract url": "https://arxiv.org/abs/2408.06588",
        "title": "Orbital-Angular-Momentum Versus MIMO: Orthogonality, Degree of Freedom,and Capacity",
        "rating": "-10",
        "keywords": [],
        "abstract": "The plane wave based wireless communications have becoming more and more matured, along with the well utilization of the traditional resources such as time and frequency. To further increase the capacity for rapidly increasing capacity demand of wireless communications, it is potential to use the twist wave, which has the orbital angular momentum (OAM). In this paper, we discuss the OAM based wireless communications in the aspect of orthogonality, degree of freedom (DoF), and capacity, where both the transmitter and the receiver use uniform circular array (UCA) antennas. In particular, we compare OAM based wireless communications with multiple-input-multiple-output (MIMO) based wireless communications in terms of DoF and capacity. Numerical results are presented to validate and evaluate that the DoF of OAM based wireless communications is greater than or equal to that of correlated MIMO based wireless communications when the transmitter and the receiver antennas are aligned well. The OAM based wireless communications can achieve larger capacity than the correlated MIMO in high signal-to-noise ratio (SNR) region under line-of-sight scenario.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06597",
        "abstract url": "https://arxiv.org/abs/2408.06597",
        "title": "Line Spectral Estimation with Unlimited Sensing",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the paper, we consider the line spectral estimation problem in an unlimited sensing framework (USF), where a modulo analog-to-digital converter (ADC) is employed to fold the input signal back into a bounded interval before quantization. Such an operation is mathematically equivalent to taking the modulo of the input signal with respect to the interval. To overcome the noise sensitivity of higher-order difference-based methods, we explore the properties of the first-order difference of modulo samples, and develop two line spectral estimation algorithms based on first-order difference, which are robust against noise. Specifically, we show that, with a high probability, the first-order difference of the original samples is equivalent to that of the modulo samples. By utilizing this property, line spectral estimation is solved via a robust sparse signal recovery approach. The second algorithms is built on our finding that, with a sufficiently high sampling rate, the first-order difference of the original samples can be decomposed as a sum of the first-order difference of the modulo samples and a sequence whose elements are confined to be three possible values. This decomposition enables us to formulate the line spectral estimation problem as a mixed integer linear program that can be efficiently solved. Simulation results show that both proposed methods are robust against noise and achieve a significant performance improvement over the higher-order difference-based method.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.06628",
        "abstract url": "https://arxiv.org/abs/2408.06628",
        "title": "Mathematical Optimization of Resolution Improvement in Structured Light data by Periodic Scanning Motion: Application for Feedback during Lunar Landing",
        "rating": "-10",
        "keywords": [],
        "abstract": "This research explores the enhancement of lunar landing precision through an advanced structured light system, integrating machine learning, Iterative Learning Control (ILC) and Structured Illumination Microscopy (SIM) techniques. By employing Moire fringe patterns for high-precision scanning maneuvers, the study addresses the limitations of conventional structured light systems. A nonlinear mathematical optimization model is developed to refine the world model, optimizing oscillation frequency and amplitude to improve resolution. The findings suggest that this approach can double the conventional resolution, promising significant advancements in the accuracy of lunar landings, with potential real-time application.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "5 pages, 2 figures"
    }
]