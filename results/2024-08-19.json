[
    {
        "paper id": "2408.10433",
        "abstract url": "https://arxiv.org/abs/2408.10433",
        "title": "CLIP-DPO: Vision-Language Models as a Source of Preference for Fixing Hallucinations in LVLMs",
        "rating": "2.5",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Despite recent successes, LVLMs or Large Vision Language Models are prone to hallucinating details like objects and their properties or relations, limiting their real-world deployment. To address this and improve their robustness, we present CLIP-DPO, a preference optimization method that leverages contrastively pre-trained Vision-Language (VL) embedding models, such as CLIP, for DPO-based optimization of LVLMs. Unlike prior works tackling LVLM hallucinations, our method does not rely on paid-for APIs, and does not require additional training data or the deployment of other external LVLMs. Instead, starting from the initial pool of supervised fine-tuning data, we generate a diverse set of predictions, which are ranked based on their CLIP image-text similarities, and then filtered using a robust rule-based approach to obtain a set of positive and negative pairs for DPO-based training. We applied CLIP-DPO fine-tuning to the MobileVLM-v2 family of models and to LlaVA-1.5, in all cases observing significant improvements in terms of hallucination reduction over baseline models. We also observe better performance for zero-shot classification, suggesting improved grounding capabilities, and verify that the original performance on standard LVLM benchmarks is overall preserved.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ECCV 2024"
    },
    {
        "paper id": "2408.09706",
        "abstract url": "https://arxiv.org/abs/2408.09706",
        "title": "MePT: Multi-Representation Guided Prompt Tuning for Vision-Language Model",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in pre-trained Vision-Language Models (VLMs) have highlighted the significant potential of prompt tuning for adapting these models to a wide range of downstream tasks. However, existing prompt tuning methods typically map an image to a single representation, limiting the model's ability to capture the diverse ways an image can be described. To address this limitation, we investigate the impact of visual prompts on the model's generalization capability and introduce a novel method termed Multi-Representation Guided Prompt Tuning (MePT). Specifically, MePT employs a three-branch framework that focuses on diverse salient regions, uncovering the inherent knowledge within images which is crucial for robust generalization. Further, we employ efficient self-ensemble techniques to integrate these versatile image representations, allowing MePT to learn all conditional, marginal, and fine-grained distributions effectively. We validate the effectiveness of MePT through extensive experiments, demonstrating significant improvements on both base-to-novel class prediction and domain generalization tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09709",
        "abstract url": "https://arxiv.org/abs/2408.09709",
        "title": "Dataset Distillation for Histopathology Image Classification",
        "rating": "2",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) have exhibited remarkable success in the field of histopathology image analysis. On the other hand, the contemporary trend of employing large models and extensive datasets has underscored the significance of dataset distillation, which involves compressing large-scale datasets into a condensed set of synthetic samples, offering distinct advantages in improving training efficiency and streamlining downstream applications. In this work, we introduce a novel dataset distillation algorithm tailored for histopathology image datasets (Histo-DD), which integrates stain normalisation and model augmentation into the distillation progress. Such integration can substantially enhance the compatibility with histopathology images that are often characterised by high colour heterogeneity. We conduct a comprehensive evaluation of the effectiveness of the proposed algorithm and the generated histopathology samples in both patch-level and slide-level classification tasks. The experimental results, carried out on three publicly available WSI datasets, including Camelyon16, TCGA-IDH, and UniToPath, demonstrate that the proposed Histo-DD can generate more informative synthetic patches than previous coreset selection and patch sampling methods. Moreover, the synthetic samples can preserve discriminative information, substantially reduce training efforts, and exhibit architecture-agnostic properties. These advantages indicate that synthetic samples can serve as an alternative to large-scale datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09787",
        "abstract url": "https://arxiv.org/abs/2408.09787",
        "title": "Anim-Director: A Large Multimodal Model Powered Agent for Controllable Animation Video Generation",
        "rating": "2",
        "keywords": [
            [
                "visual-language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Traditional animation generation methods depend on training generative models with human-labelled data, entailing a sophisticated multi-stage pipeline that demands substantial human effort and incurs high training costs. Due to limited prompting plans, these methods typically produce brief, information-poor, and context-incoherent animations. To overcome these limitations and automate the animation process, we pioneer the introduction of large multimodal models (LMMs) as the core processor to build an autonomous animation-making agent, named Anim-Director. This agent mainly harnesses the advanced understanding and reasoning capabilities of LMMs and generative AI tools to create animated videos from concise narratives or simple instructions. Specifically, it operates in three main stages: Firstly, the Anim-Director generates a coherent storyline from user inputs, followed by a detailed director's script that encompasses settings of character profiles and interior/exterior descriptions, and context-coherent scene descriptions that include appearing characters, interiors or exteriors, and scene events. Secondly, we employ LMMs with the image generation tool to produce visual images of settings and scenes. These images are designed to maintain visual consistency across different scenes using a visual-language prompting method that combines scene descriptions and images of the appearing character and setting. Thirdly, scene images serve as the foundation for producing animated videos, with LMMs generating prompts to guide this process. The whole process is notably autonomous without manual intervention, as the LMMs interact seamlessly with generative tools to generate prompts, evaluate visual quality, and select the best one to optimize the final output.",
        "subjects": [
            "cs.CL",
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted by SIGGRAPH Asia 2024, Project and Codes: https://github.com/HITsz-TMG/Anim-Director"
    },
    {
        "paper id": "2408.09856",
        "abstract url": "https://arxiv.org/abs/2408.09856",
        "title": "TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning",
                "GPU memory"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "While Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have effectively addressed GPU memory constraints during fine-tuning, their performance often falls short, especially in multidimensional task scenarios. To address this issue, one straightforward solution is to introduce task-specific LoRA modules as domain experts, leveraging the modeling of multiple experts' capabilities and thus enhancing the general capability of multi-task learning. Despite promising, these additional components often add complexity to the training and inference process, contravening the efficient characterization of PEFT designed for. Considering this, we introduce an innovative PEFT method, TeamLoRA, consisting of a collaboration and competition module for experts, and thus achieving the right balance of effectiveness and efficiency: (i) For collaboration, a novel knowledge-sharing and -organizing mechanism is devised to appropriately reduce the scale of matrix operations, thereby boosting the training and inference speed. (ii) For competition, we propose leveraging a game-theoretic interaction mechanism for experts, encouraging experts to transfer their domain-specific knowledge while facing diverse downstream tasks, and thus enhancing the performance. By doing so, TeamLoRA elegantly connects the experts as a \"Team\" with internal collaboration and competition, enabling a faster and more accurate PEFT paradigm for multi-task learning. To validate the superiority of TeamLoRA, we curate a comprehensive multi-task evaluation(CME) benchmark to thoroughly assess the capability of multi-task learning. Experiments conducted on our CME and other benchmarks indicate the effectiveness and efficiency of TeamLoRA. Our project is available at https://github.com/Lin-Tianwei/TeamLoRA.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09984",
        "abstract url": "https://arxiv.org/abs/2408.09984",
        "title": "Boosting Open-Domain Continual Learning via Leveraging Intra-domain Category-aware Prototype",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite recent progress in enhancing the efficacy of Open-Domain Continual Learning (ODCL) in Vision-Language Models (VLM), failing to (1) correctly identify the Task-ID of a test image and (2) use only the category set corresponding to the Task-ID, while preserving the knowledge related to each domain, cannot address the two primary challenges of ODCL: forgetting old knowledge and maintaining zero-shot capabilities, as well as the confusions caused by category-relatedness between domains. In this paper, we propose a simple yet effective solution: leveraging intra-domain category-aware prototypes for ODCL in CLIP (DPeCLIP), where the prototype is the key to bridging the above two processes. Concretely, we propose a training-free Task-ID discriminator method, by utilizing prototypes as classifiers for identifying Task-IDs. Furthermore, to maintain the knowledge corresponding to each domain, we incorporate intra-domain category-aware prototypes as domain prior prompts into the training process. Extensive experiments conducted on 11 different datasets demonstrate the effectiveness of our approach, achieving 2.37% and 1.14% average improvement in class-incremental and task-incremental settings, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10012",
        "abstract url": "https://arxiv.org/abs/2408.10012",
        "title": "CLIPCleaner: Cleaning Noisy Labels with CLIP",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Learning with Noisy labels (LNL) poses a significant challenge for the Machine Learning community. Some of the most widely used approaches that select as clean samples for which the model itself (the in-training model) has high confidence, e.g., `small loss', can suffer from the so called `self-confirmation' bias. This bias arises because the in-training model, is at least partially trained on the noisy labels. Furthermore, in the classification case, an additional challenge arises because some of the label noise is between classes that are visually very similar (`hard noise'). This paper addresses these challenges by proposing a method (\\textit{CLIPCleaner}) that leverages CLIP, a powerful Vision-Language (VL) model for constructing a zero-shot classifier for efficient, offline, clean sample selection. This has the advantage that the sample selection is decoupled from the in-training model and that the sample selection is aware of the semantic and visual similarities between the classes due to the way that CLIP is trained. We provide theoretical justifications and empirical evidence to demonstrate the advantages of CLIP for LNL compared to conventional pre-trained models. Compared to current methods that combine iterative sample selection with various techniques, \\textit{CLIPCleaner} offers a simple, single-step approach that achieves competitive or superior performance on benchmark datasets. To the best of our knowledge, this is the first time a VL model has been used for sample selection to address the problem of Learning with Noisy Labels (LNL), highlighting their potential in the domain.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ACMMM2024"
    },
    {
        "paper id": "2408.10188",
        "abstract url": "https://arxiv.org/abs/2408.10188",
        "title": "LongVILA: Scaling Long-Context Visual Language Models for Long Videos",
        "rating": "2",
        "keywords": [
            [
                "Visual Language",
                "VLMs"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Long-context capability is critical for multi-modal foundation models, especially for long video understanding. We introduce LongVILA, a full-stack solution for long-context visual-language models by co-designing the algorithm and system. For model training, we upgrade existing VLMs to support long video understanding by incorporating two additional stages, i.e., long context extension and long supervised fine-tuning. However, training on long video is computationally and memory intensive. We introduce the long-context Multi-Modal Sequence Parallelism (MM-SP) system that efficiently parallelizes long video training and inference, enabling 2M context length training on 256 GPUs without any gradient checkpointing. LongVILA efficiently extends the number of video frames of VILA from 8 to 1024, improving the long video captioning score from 2.00 to 3.26 (out of 5), achieving 99.5% accuracy in 1400-frame (274k context length) video needle-in-a-haystack. LongVILA-8B demonstrates consistent accuracy improvements on long videos in the VideoMME benchmark as the number of frames increases. Besides, MM-SP is 2.1x - 5.7x faster than ring sequence parallelism and 1.1x - 1.4x faster than Megatron with context parallelism + tensor parallelism. Moreover, it seamlessly integrates with Hugging Face Transformers.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Code and models are available at https://github.com/NVlabs/VILA/blob/main/LongVILA.md"
    },
    {
        "paper id": "2408.10202",
        "abstract url": "https://arxiv.org/abs/2408.10202",
        "title": "SANER: Annotation-free Societal Attribute Neutralizer for Debiasing CLIP",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large-scale vision-language models, such as CLIP, are known to contain harmful societal bias regarding protected attributes (e.g., gender and age). In this paper, we aim to address the problems of societal bias in CLIP. Although previous studies have proposed to debias societal bias through adversarial learning or test-time projecting, our comprehensive study of these works identifies two critical limitations: 1) loss of attribute information when it is explicitly disclosed in the input and 2) use of the attribute annotations during debiasing process. To mitigate societal bias in CLIP and overcome these limitations simultaneously, we introduce a simple-yet-effective debiasing method called SANER (societal attribute neutralizer) that eliminates attribute information from CLIP text features only of attribute-neutral descriptions. Experimental results show that SANER, which does not require attribute annotations and preserves original information for attribute-specific descriptions, demonstrates superior debiasing ability than the existing methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10204",
        "abstract url": "https://arxiv.org/abs/2408.10204",
        "title": "Criticality Leveraged Adversarial Training (CLAT) for Boosted Performance via Parameter Efficiency",
        "rating": "2",
        "keywords": [
            [
                "Parameter Efficiency"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Adversarial training enhances neural network robustness but suffers from a tendency to overfit and increased generalization errors on clean data. This work introduces CLAT, an innovative approach that mitigates adversarial overfitting by introducing parameter efficiency into the adversarial training process, improving both clean accuracy and adversarial robustness. Instead of tuning the entire model, CLAT identifies and fine-tunes robustness-critical layers - those predominantly learning non-robust features - while freezing the remaining model to enhance robustness. It employs dynamic critical layer selection to adapt to changes in layer criticality throughout the fine-tuning process. Empirically, CLAT can be applied on top of existing adversarial training methods, significantly reduces the number of trainable parameters by approximately 95%, and achieves more than a 2% improvement in adversarial robustness compared to baseline methods.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "9 pages + appendix/ additional experiments"
    },
    {
        "paper id": "2408.10383",
        "abstract url": "https://arxiv.org/abs/2408.10383",
        "title": "BrewCLIP: A Bifurcated Representation Learning Framework for Audio-Visual Retrieval",
        "rating": "2",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Previous methods for audio-image matching generally fall into one of two categories: pipeline models or End-to-End models. Pipeline models first transcribe speech and then encode the resulting text; End-to-End models encode speech directly. Generally, pipeline models outperform end-to-end models, but the intermediate transcription necessarily discards some potentially useful non-textual information. In addition to textual information, speech can convey details such as accent, mood, and and emphasis, which should be effectively captured in the encoded representation. In this paper, we investigate whether non-textual information, which is overlooked by pipeline-based models, can be leveraged to improve speech-image matching performance. We thoroughly analyze and compare End-to-End models, pipeline models, and our proposed dual-channel model for robust audio-image retrieval on a variety of datasets. Our approach achieves a substantial performance gain over the previous state-of-the-art by leveraging strong pretrained models, a prompting mechanism and a bifurcated design.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09919",
        "abstract url": "https://arxiv.org/abs/2408.09919",
        "title": "Long-Tail Temporal Action Segmentation with Group-wise Temporal Logit Adjustment",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Procedural activity videos often exhibit a long-tailed action distribution due to varying action frequencies and durations. However, state-of-the-art temporal action segmentation methods overlook the long tail and fail to recognize tail actions. Existing long-tail methods make class-independent assumptions and struggle to identify tail classes when applied to temporal segmentation frameworks. This work proposes a novel group-wise temporal logit adjustment~(G-TLA) framework that combines a group-wise softmax formulation while leveraging activity information and action ordering for logit adjustment. The proposed framework significantly improves in segmenting tail actions without any performance loss on head actions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2408.09933",
        "abstract url": "https://arxiv.org/abs/2408.09933",
        "title": "SZU-AFS Antispoofing System for the ASVspoof 5 Challenge",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "This paper presents the SZU-AFS anti-spoofing system, designed for Track 1 of the ASVspoof 5 Challenge under open conditions. The system is built with four stages: selecting a baseline model, exploring effective data augmentation (DA) methods for fine-tuning, applying a co-enhancement strategy based on gradient norm aware minimization (GAM) for secondary fine-tuning, and fusing logits scores from the two best-performing fine-tuned models. The system utilizes the Wav2Vec2 front-end feature extractor and the AASIST back-end classifier as the baseline model. During model fine-tuning, three distinct DA policies have been investigated: single-DA, random-DA, and cascade-DA. Moreover, the employed GAM-based co-enhancement strategy, designed to fine-tune the augmented model at both data and optimizer levels, helps the Adam optimizer find flatter minima, thereby boosting model generalization. Overall, the final fusion system achieves a minDCF of 0.115 and an EER of 4.04% on the evaluation set.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "8 pages, 2 figures, ASVspoof 5 Workshop (Interspeech2024 Satellite)"
    },
    {
        "paper id": "2408.09701",
        "abstract url": "https://arxiv.org/abs/2408.09701",
        "title": "Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The use of Large Language Models (LLMs) for program code generation has gained substantial attention, but their biases and limitations with non-English prompts challenge global inclusivity. This paper investigates the complexities of multilingual prompt-based code generation. Our evaluations of LLMs, including CodeLLaMa and CodeGemma, reveal significant disparities in code quality for non-English prompts; we also demonstrate the inadequacy of simple approaches like prompt translation, bootstrapped data augmentation, and fine-tuning. To address this, we propose a zero-shot cross-lingual approach using a neural projection technique, integrating a cross-lingual encoder like LASER artetxe2019massively to map multilingual embeddings from it into the LLM's token space. This method requires training only on English data and scales effectively to other languages. Results on a translated and quality-checked MBPP dataset show substantial improvements in code quality. This research promotes a more inclusive code generation landscape by empowering LLMs with multilingual capabilities to support the diverse linguistic spectrum in programming.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2408.09720",
        "abstract url": "https://arxiv.org/abs/2408.09720",
        "title": "Pedestrian Attribute Recognition: A New Benchmark Dataset and A Large Language Model Augmented Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Pedestrian Attribute Recognition (PAR) is one of the indispensable tasks in human-centered research. However, existing datasets neglect different domains (e.g., environments, times, populations, and data sources), only conducting simple random splits, and the performance of these datasets has already approached saturation. In the past five years, no large-scale dataset has been opened to the public. To address this issue, this paper proposes a new large-scale, cross-domain pedestrian attribute recognition dataset to fill the data gap, termed MSP60K. It consists of 60,122 images and 57 attribute annotations across eight scenarios. Synthetic degradation is also conducted to further narrow the gap between the dataset and real-world challenging scenarios. To establish a more rigorous benchmark, we evaluate 17 representative PAR models under both random and cross-domain split protocols on our dataset. Additionally, we propose an innovative Large Language Model (LLM) augmented PAR framework, named LLM-PAR. This framework processes pedestrian images through a Vision Transformer (ViT) backbone to extract features and introduces a multi-embedding query Transformer to learn partial-aware features for attribute classification. Significantly, we enhance this framework with LLM for ensemble learning and visual feature augmentation. Comprehensive experiments across multiple PAR benchmark datasets have thoroughly validated the efficacy of our proposed framework. The dataset and source code accompanying this paper will be made publicly available at \\url{https://github.com/Event-AHU/OpenPAR}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "MSP60K PAR Benchmark Dataset, LLM based PAR model, In Peer Review"
    },
    {
        "paper id": "2408.09734",
        "abstract url": "https://arxiv.org/abs/2408.09734",
        "title": "Mutually-Aware Feature Learning for Few-Shot Object Counting",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot object counting has garnered significant attention for its practicality as it aims to count target objects in a query image based on given exemplars without the need for additional training. However, there is a shortcoming in the prevailing extract-and-match approach: query and exemplar features lack interaction during feature extraction since they are extracted unaware of each other and later correlated based on similarity. This can lead to insufficient target awareness of the extracted features, resulting in target confusion in precisely identifying the actual target when multiple class objects coexist. To address this limitation, we propose a novel framework, Mutually-Aware FEAture learning(MAFEA), which encodes query and exemplar features mutually aware of each other from the outset. By encouraging interaction between query and exemplar features throughout the entire pipeline, we can obtain target-aware features that are robust to a multi-category scenario. Furthermore, we introduce a background token to effectively associate the target region of query with exemplars and decouple its background region from them. Our extensive experiments demonstrate that our model reaches a new state-of-the-art performance on the two challenging benchmarks, FSCD-LVIS and FSC-147, with a remarkably reduced degree of the target confusion problem.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Submitted to Pattern Recognition"
    },
    {
        "paper id": "2408.09742",
        "abstract url": "https://arxiv.org/abs/2408.09742",
        "title": "Paired Completion: Flexible Quantification of Issue-framing at Scale with LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Detecting and quantifying issue framing in textual discourse - the perspective one takes to a given topic (e.g. climate science vs. denialism, misogyny vs. gender equality) - is highly valuable to a range of end-users from social and political scientists to program evaluators and policy analysts. However, conceptual framing is notoriously challenging for automated natural language processing (NLP) methods since the words and phrases used by either `side' of an issue are often held in common, with only subtle stylistic flourishes separating their use. Here we develop and rigorously evaluate new detection methods for issue framing and narrative analysis within large text datasets. By introducing a novel application of next-token log probabilities derived from generative large language models (LLMs) we show that issue framing can be reliably and efficiently detected in large corpora with only a few examples of either perspective on a given issue, a method we call `paired completion'. Through 192 independent experiments over three novel, synthetic datasets, we evaluate paired completion against prompt-based LLM methods and labelled methods using traditional NLP and recent LLM contextual embeddings. We additionally conduct a cost-based analysis to mark out the feasible set of performant methods at production-level scales, and a model bias analysis. Together, our work demonstrates a feasible path to scalable, accurate and low-bias issue-framing in large corpora.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "econ.GN"
        ],
        "comment": "9 pages, 4 figures"
    },
    {
        "paper id": "2408.09754",
        "abstract url": "https://arxiv.org/abs/2408.09754",
        "title": "Efficient onboard multi-task AI architecture based on self-supervised learning",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "There is growing interest towards the use of AI directly onboard satellites for quick analysis and rapid response to critical events such as natural disasters. This paper presents a blueprint to the mission designer for the development of a modular and efficient deep learning payload to address multiple onboard inference tasks. In particular, we design a self-supervised lightweight backbone that provides features to efficient task-specific heads. The latter can be developed independently and with reduced data labeling requirements thanks to the frozen backbone. Experiments on three sample tasks of cloud segmentation, flood detection, and marine debris classification on a 7W embedded system show competitive results with inference quality close to high-complexity state-of-the-art models and high throughput in excess of 8 Mpx/s.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09773",
        "abstract url": "https://arxiv.org/abs/2408.09773",
        "title": "Are Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have been found to produce hallucinations when the question exceeds their internal knowledge boundaries. A reliable model should have a clear perception of its knowledge boundaries, providing correct answers within its scope and refusing to answer when it lacks knowledge. Existing research on LLMs' perception of their knowledge boundaries typically uses either the probability of the generated tokens or the verbalized confidence as the model's confidence in its response. However, these studies overlook the differences and connections between the two. In this paper, we conduct a comprehensive analysis and comparison of LLMs' probabilistic perception and verbalized perception of their factual knowledge boundaries. First, we investigate the pros and cons of these two perceptions. Then, we study how they change under questions of varying frequencies. Finally, we measure the correlation between LLMs' probabilistic confidence and verbalized confidence. Experimental results show that 1) LLMs' probabilistic perception is generally more accurate than verbalized perception but requires an in-domain validation set to adjust the confidence threshold. 2) Both perceptions perform better on less frequent questions. 3) It is challenging for LLMs to accurately express their internal confidence in natural language.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09775",
        "abstract url": "https://arxiv.org/abs/2408.09775",
        "title": "Faster Adaptive Decentralized Learning Algorithms",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Decentralized learning recently has received increasing attention in machine learning due to its advantages in implementation simplicity and system robustness, data privacy. Meanwhile, the adaptive gradient methods show superior performances in many machine learning tasks such as training neural networks. Although some works focus on studying decentralized optimization algorithms with adaptive learning rates, these adaptive decentralized algorithms still suffer from high sample complexity. To fill these gaps, we propose a class of faster adaptive decentralized algorithms (i.e., AdaMDOS and AdaMDOF) for distributed nonconvex stochastic and finite-sum optimization, respectively. Moreover, we provide a solid convergence analysis framework for our methods. In particular, we prove that our AdaMDOS obtains a near-optimal sample complexity of $\\tilde{O}(\u03b5^{-3})$ for finding an $\u03b5$-stationary solution of nonconvex stochastic optimization. Meanwhile, our AdaMDOF obtains a near-optimal sample complexity of $O(\\sqrt{n}\u03b5^{-2})$ for finding an $\u03b5$-stationary solution of nonconvex finite-sum optimization, where $n$ denotes the sample size. To the best of our knowledge, our AdaMDOF algorithm is the first adaptive decentralized algorithm for nonconvex finite-sum optimization. Some experimental results demonstrate efficiency of our algorithms.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "ICML 2024 (Spotlight)"
    },
    {
        "paper id": "2408.09777",
        "abstract url": "https://arxiv.org/abs/2408.09777",
        "title": "Summarizing long regulatory documents with a multi-step pipeline",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Due to their length and complexity, long regulatory texts are challenging to summarize. To address this, a multi-step extractive-abstractive architecture is proposed to handle lengthy regulatory documents more effectively. In this paper, we show that the effectiveness of a two-step architecture for summarizing long regulatory texts varies significantly depending on the model used. Specifically, the two-step architecture improves the performance of decoder-only models. For abstractive encoder-decoder models with short context lengths, the effectiveness of an extractive step varies, whereas for long-context encoder-decoder models, the extractive step worsens their performance. This research also highlights the challenges of evaluating generated texts, as evidenced by the differing results from human and automated evaluations. Most notably, human evaluations favoured language models pretrained on legal text, while automated metrics rank general-purpose language models higher. The results underscore the importance of selecting the appropriate summarization strategy based on model architecture and context length.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2408.09786",
        "abstract url": "https://arxiv.org/abs/2408.09786",
        "title": "Cross-composition Feature Disentanglement for Compositional Zero-shot Learning",
        "rating": "1",
        "keywords": [
            [
                "vision-language",
                "VLM"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Disentanglement of visual features of primitives (i.e., attributes and objects) has shown exceptional results in Compositional Zero-shot Learning (CZSL). However, due to the feature divergence of an attribute (resp. object) when combined with different objects (resp. attributes), it is challenging to learn disentangled primitive features that are general across different compositions. To this end, we propose the solution of cross-composition feature disentanglement, which takes multiple primitive-sharing compositions as inputs and constrains the disentangled primitive features to be general across these compositions. More specifically, we leverage a compositional graph to define the overall primitive-sharing relationships between compositions, and build a task-specific architecture upon the recently successful large pre-trained vision-language model (VLM) CLIP, with dual cross-composition disentangling adapters (called L-Adapter and V-Adapter) inserted into CLIP's frozen text and image encoders, respectively. Evaluation on three popular CZSL benchmarks shows that our proposed solution significantly improves the performance of CZSL, and its components have been verified by solid ablation studies.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "work in progress"
    },
    {
        "paper id": "2408.09794",
        "abstract url": "https://arxiv.org/abs/2408.09794",
        "title": "AutoML-guided Fusion of Entity and LLM-based representations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large semantic knowledge bases are grounded in factual knowledge. However, recent approaches to dense text representations (embeddings) do not efficiently exploit these resources. Dense and robust representations of documents are essential for effectively solving downstream classification and retrieval tasks. This work demonstrates that injecting embedded information from knowledge bases can augment the performance of contemporary Large Language Model (LLM)-based representations for the task of text classification. Further, by considering automated machine learning (AutoML) with the fused representation space, we demonstrate it is possible to improve classification accuracy even if we use low-dimensional projections of the original representation space obtained via efficient matrix factorization. This result shows that significantly faster classifiers can be achieved with minimal or no loss in predictive performance, as demonstrated using five strong LLM baselines on six diverse real-life datasets.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09810",
        "abstract url": "https://arxiv.org/abs/2408.09810",
        "title": "Efficient Area-based and Speaker-Agnostic Source Separation",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces an area-based source separation method designed for virtual meeting scenarios. The aim is to preserve speech signals from an unspecified number of sources within a defined spatial area in front of a linear microphone array, while suppressing all other sounds. Therefore, we employ an efficient neural network architecture adapted for multi-channel input to encompass the predefined target area. To evaluate the approach, training data and specific test scenarios including multiple target and interfering speakers, as well as background noise are simulated. All models are rated according to DNSMOS and scale-invariant signal-to-distortion ratio. Our experiments show that the proposed method separates speech from multiple speakers within the target area well, besides being of very low complexity, intended for real-time processing. In addition, a power reduction heatmap is used to demonstrate the networks' ability to identify sources located within the target area. We put our approach in context with a well-established baseline for speaker-speaker separation and discuss its strengths and challenges.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Preprint. Accepted to the International Workshop on Acoustic Signal Enhancement (IWAENC 2024)"
    },
    {
        "paper id": "2408.09819",
        "abstract url": "https://arxiv.org/abs/2408.09819",
        "title": "CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the society and 2) a collection of Chinese moral anomies from various newspapers and academic papers on morality. With these sources, we aim to create a moral evaluation dataset characterized by diversity and authenticity. We develop a morality taxonomy and a set of fundamental moral principles that are not only rooted in traditional Chinese culture but also consistent with contemporary societal norms. To facilitate efficient construction and annotation of instances in CMoralEval, we establish a platform with AI-assisted instance generation to streamline the annotation process. These help us curate CMoralEval that encompasses both explicit moral scenarios (14,964 instances) and moral dilemma scenarios (15,424 instances), each with instances from different data sources. We conduct extensive experiments with CMoralEval to examine a variety of Chinese LLMs. Experiment results demonstrate that CMoralEval is a challenging benchmark for Chinese LLMs. The dataset is publicly available at \\url{https://github.com/tjunlp-lab/CMoralEval}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted by ACL 2024 (Findings)"
    },
    {
        "paper id": "2408.09846",
        "abstract url": "https://arxiv.org/abs/2408.09846",
        "title": "Continual Dialogue State Tracking via Reason-of-Select Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge. Dialogue State Tracking (DST), vital in these systems, often involves learning new services and confronting catastrophic forgetting, along with a critical capability loss termed the \"Value Selection Quandary.\" To address these challenges, we introduce the Reason-of-Select (RoS) distillation method by enhancing smaller models with a novel 'meta-reasoning' capability. Meta-reasoning employs an enhanced multi-domain perspective, combining fragments of meta-knowledge from domain-specific dialogues during continual learning. This transcends traditional single-perspective reasoning. The domain bootstrapping process enhances the model's ability to dissect intricate dialogues from multiple possible values. Its domain-agnostic property aligns data distribution across different domains, effectively mitigating forgetting. Additionally, two novel improvements, \"multi-value resolution\" strategy and Semantic Contrastive Reasoning Selection method, significantly enhance RoS by generating DST-specific selection chains and mitigating hallucinations in teachers' reasoning, ensuring effective and reliable knowledge transfer. Extensive experiments validate the exceptional performance and robust generalization capabilities of our method. The source code is provided for reproducibility.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to ACL 2024 Findings"
    },
    {
        "paper id": "2408.09849",
        "abstract url": "https://arxiv.org/abs/2408.09849",
        "title": "Importance Weighting Can Help Large Language Models Self-Improve",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown remarkable capability in numerous tasks and applications. However, fine-tuning LLMs using high-quality datasets under external supervision remains prohibitively expensive. In response, LLM self-improvement approaches have been vibrantly developed recently. The typical paradigm of LLM self-improvement involves training LLM on self-generated data, part of which may be detrimental and should be filtered out due to the unstable data quality. While current works primarily employs filtering strategies based on answer correctness, in this paper, we demonstrate that filtering out correct but with high distribution shift extent (DSE) samples could also benefit the results of self-improvement. Given that the actual sample distribution is usually inaccessible, we propose a new metric called DS weight to approximate DSE, inspired by the Importance Weighting methods. Consequently, we integrate DS weight with self-consistency to comprehensively filter the self-generated samples and fine-tune the language model. Experiments show that with only a tiny valid set (up to 5\\% size of the training set) to compute DS weight, our approach can notably promote the reasoning ability of current LLM self-improvement methods. The resulting performance is on par with methods that rely on external supervision from pre-trained reward models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09853",
        "abstract url": "https://arxiv.org/abs/2408.09853",
        "title": "Self-Directed Turing Test for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The Turing test examines whether AIs can exhibit human-like behaviour in natural language conversations. Traditional Turing tests adopt a rigid dialogue format where each participant sends only one message each time and require continuous human involvement to direct the entire interaction with the test subject. This fails to reflect a natural conversational style and hinders the evaluation of Large Language Models (LLMs) in complex and prolonged dialogues. This paper proposes the Self-Directed Turing Test, which extends the original test with a burst dialogue format, allowing more dynamic exchanges by multiple consecutive messages. It further efficiently reduces human workload by having the LLM self-direct the majority of the test process, iteratively generating dialogues that simulate its interaction with humans. With the pseudo-dialogue history, the model then engages in a shorter dialogue with a human, which is paired with a human-human conversation on the same topic to be judged using questionnaires. We introduce the X-Turn Pass-Rate metric to assess the human likeness of LLMs across varying durations. While LLMs like GPT-4 initially perform well, achieving pass rates of 51.9% and 38.9% during 3 turns and 10 turns of dialogues respectively, their performance drops as the dialogue progresses, which underscores the difficulty in maintaining consistency in the long term.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09857",
        "abstract url": "https://arxiv.org/abs/2408.09857",
        "title": "TaSL: Continual Dialog State Tracking via Task Skill Localization and Consolidation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "A practical dialogue system requires the capacity for ongoing skill acquisition and adaptability to new tasks while preserving prior knowledge. However, current methods for Continual Dialogue State Tracking (DST), a crucial function of dialogue systems, struggle with the catastrophic forgetting issue and knowledge transfer between tasks. We present TaSL, a novel framework for task skill localization and consolidation that enables effective knowledge transfer without relying on memory replay. TaSL uses a novel group-wise technique to pinpoint task-specific and task-shared areas. Additionally, a fine-grained skill consolidation strategy protects task-specific knowledge from being forgotten while updating shared knowledge for bi-directional knowledge transfer. As a result, TaSL strikes a balance between preserving previous knowledge and excelling at new tasks. Comprehensive experiments on various backbones highlight the significant performance improvements of TaSL over existing state-of-the-art methods. The source code is provided for reproducibility.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to ACL 2024 Main Conference"
    },
    {
        "paper id": "2408.09869",
        "abstract url": "https://arxiv.org/abs/2408.09869",
        "title": "Docling Technical Report",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "This technical report introduces Docling, an easy to use, self-contained, MIT-licensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.",
        "subjects": [
            "cs.CL",
            "cs.CV",
            "cs.SE"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2206.01062"
    },
    {
        "paper id": "2408.09895",
        "abstract url": "https://arxiv.org/abs/2408.09895",
        "title": "Performance Law of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Guided by the belief of the scaling law, large language models (LLMs) have achieved impressive performance in recent years. However, scaling law only gives a qualitative estimation of loss, which is influenced by various factors such as model architectures, data distributions, tokenizers, and computation precision. Thus, estimating the real performance of LLMs with different training settings rather than loss may be quite useful in practical development. In this article, we present an empirical equation named \"Performance Law\" to directly predict the MMLU score of an LLM, which is a widely used metric to indicate the general capability of LLMs in real-world conversations and applications. Based on only a few key hyperparameters of the LLM architecture and the size of training data, we obtain a quite accurate MMLU prediction of various LLMs with diverse sizes and architectures developed by different organizations in different years. Performance law can be used to guide the choice of LLM architecture and the effective allocation of computational resources without extensive experiments.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Personal opinions of the authors"
    },
    {
        "paper id": "2408.09914",
        "abstract url": "https://arxiv.org/abs/2408.09914",
        "title": "Active Learning for Identifying Disaster-Related Tweets: A Comparison with Keyword Filtering and Generic Fine-Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Information from social media can provide essential information for emergency response during natural disasters in near real-time. However, it is difficult to identify the disaster-related posts among the large amounts of unstructured data available. Previous methods often use keyword filtering, topic modelling or classification-based techniques to identify such posts. Active Learning (AL) presents a promising sub-field of Machine Learning (ML) that has not been used much in the field of text classification of social media content. This study therefore investigates the potential of AL for identifying disaster-related Tweets. We compare a keyword filtering approach, a RoBERTa model fine-tuned with generic data from CrisisLex, a base RoBERTa model trained with AL and a fine-tuned RoBERTa model trained with AL regarding classification performance. For testing, data from CrisisLex and manually labelled data from the 2021 flood in Germany and the 2023 Chile forest fires were considered. The results show that generic fine-tuning combined with 10 rounds of AL outperformed all other approaches. Consequently, a broadly applicable model for the identification of disaster-related Tweets could be trained with very little labelling effort. The model can be applied to use cases beyond this study and provides a useful tool for further research in social media analysis.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Submitted for the Intelligent Systems Conference (IntelliSys 2024). The version of record of this contribution is published in the Springer series Lecture Notes in Networks and Systems, and is available online at https://doi.org/10.1007/978-3-031-66428-1_8. This preprint has not undergone peer review or any post-submission improvements or corrections. 13 pages, 2 figures"
    },
    {
        "paper id": "2408.09916",
        "abstract url": "https://arxiv.org/abs/2408.09916",
        "title": "Attribution Analysis Meets Model Editing: Advancing Knowledge Correction in Vision Language Models with VisEdit",
        "rating": "1",
        "keywords": [
            [
                "Vision Language"
            ],
            [
                "Model Editing"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Model editing aims to correct outdated or erroneous knowledge in large models without costly retraining. Recent research discovered that the mid-layer representation of the subject's final token in a prompt has a strong influence on factual predictions, and developed Large Language Model (LLM) editing techniques based on this observation. However, for Vision-LLMs (VLLMs), how visual representations impact the predictions from a decoder-only language model remains largely unexplored. To the best of our knowledge, model editing for VLLMs has not been extensively studied in the literature. In this work, we employ the contribution allocation and noise perturbation methods to measure the contributions of visual representations for token predictions. Our attribution analysis shows that visual representations in mid-to-later layers that are highly relevant to the prompt contribute significantly to predictions. Based on these insights, we propose VisEdit, a novel model editor for VLLMs that effectively corrects knowledge by editing intermediate visual representations in regions important to the edit prompt. We evaluated VisEdit using multiple VLLM backbones and public VLLM editing benchmark datasets. The results show the superiority of VisEdit over the strong baselines adapted from existing state-of-the-art editors for LLMs.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09929",
        "abstract url": "https://arxiv.org/abs/2408.09929",
        "title": "Data Augmentation of Contrastive Learning is Estimating Positive-incentive Noise",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Inspired by the idea of Positive-incentive Noise (Pi-Noise or $\u03c0$-Noise) that aims at learning the reliable noise beneficial to tasks, we scientifically investigate the connection between contrastive learning and $\u03c0$-noise in this paper. By converting the contrastive loss to an auxiliary Gaussian distribution to quantitatively measure the difficulty of the specific contrastive model under the information theory framework, we properly define the task entropy, the core concept of $\u03c0$-noise, of contrastive learning. It is further proved that the predefined data augmentation in the standard contrastive learning paradigm can be regarded as a kind of point estimation of $\u03c0$-noise. Inspired by the theoretical study, a framework that develops a $\u03c0$-noise generator to learn the beneficial noise (instead of estimation) as data augmentations for contrast is proposed. The designed framework can be applied to diverse types of data and is also completely compatible with the existing contrastive models. From the visualization, we surprisingly find that the proposed method successfully learns effective augmentations.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09939",
        "abstract url": "https://arxiv.org/abs/2408.09939",
        "title": "\"Image, Tell me your story!\" Predicting the original meta-context of visual misinformation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "To assist human fact-checkers, researchers have developed automated approaches for visual misinformation detection. These methods assign veracity scores by identifying inconsistencies between the image and its caption, or by detecting forgeries in the image. However, they neglect a crucial point of the human fact-checking process: identifying the original meta-context of the image. By explaining what is actually true about the image, fact-checkers can better detect misinformation, focus their efforts on check-worthy visual content, engage in counter-messaging before misinformation spreads widely, and make their explanation more convincing. Here, we fill this gap by introducing the task of automated image contextualization. We create 5Pils, a dataset of 1,676 fact-checked images with question-answer pairs about their original meta-context. Annotations are based on the 5 Pillars fact-checking framework. We implement a first baseline that grounds the image in its original meta-context using the content of the image and textual evidence retrieved from the open web. Our experiments show promising results while highlighting several open challenges in retrieval and reasoning. We make our code and data publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint. Code available at https://github.com/UKPLab/5pils"
    },
    {
        "paper id": "2408.09945",
        "abstract url": "https://arxiv.org/abs/2408.09945",
        "title": "Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating Adequacy, Fluency, and Elegance",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown remarkable performance in general translation tasks. However, the increasing demand for high-quality translations that are not only adequate but also fluent and elegant. To assess the extent to which current LLMs can meet these demands, we introduce a suitable benchmark for translating classical Chinese poetry into English. This task requires not only adequacy in translating culturally and historically significant content but also a strict adherence to linguistic fluency and poetic elegance. Our study reveals that existing LLMs fall short of this task. To address these issues, we propose RAT, a \\textbf{R}etrieval-\\textbf{A}ugmented machine \\textbf{T}ranslation method that enhances the translation process by incorporating knowledge related to classical poetry. Additionally, we propose an automatic evaluation metric based on GPT-4, which better assesses translation quality in terms of adequacy, fluency, and elegance, overcoming the limitations of traditional metrics. Our dataset and code will be made available.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2408.09946",
        "abstract url": "https://arxiv.org/abs/2408.09946",
        "title": "Microscopic Analysis on LLM players via Social Deduction Game",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent studies have begun developing autonomous game players for social deduction games using large language models (LLMs). When building LLM players, fine-grained evaluations are crucial for addressing weaknesses in game-playing abilities. However, existing studies have often overlooked such assessments. Specifically, we point out two issues with the evaluation methods employed. First, game-playing abilities have typically been assessed through game-level outcomes rather than specific event-level skills; Second, error analyses have lacked structured methodologies. To address these issues, we propose an approach utilizing a variant of the SpyFall game, named SpyGame. We conducted an experiment with four LLMs, analyzing their gameplay behavior in SpyGame both quantitatively and qualitatively. For the quantitative analysis, we introduced eight metrics to resolve the first issue, revealing that these metrics are more effective than existing ones for evaluating the two critical skills: intent identification and camouflage. In the qualitative analysis, we performed thematic analysis to resolve the second issue. This analysis identifies four major categories that affect gameplay of LLMs. Additionally, we demonstrate how these categories complement and support the findings from the quantitative analysis.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Under review, 10 pages"
    },
    {
        "paper id": "2408.09948",
        "abstract url": "https://arxiv.org/abs/2408.09948",
        "title": "Caption-Driven Explorations: Aligning Image and Text Embeddings through Human-Inspired Foveated Vision",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Understanding human attention is crucial for vision science and AI. While many models exist for free-viewing, less is known about task-driven image exploration. To address this, we introduce CapMIT1003, a dataset with captions and click-contingent image explorations, to study human attention during the captioning task. We also present NevaClip, a zero-shot method for predicting visual scanpaths by combining CLIP models with NeVA algorithms. NevaClip generates fixations to align the representations of foveated visual stimuli and captions. The simulated scanpaths outperform existing human attention models in plausibility for captioning and free-viewing tasks. This research enhances the understanding of human attention and advances scanpath prediction models.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2305.12380"
    },
    {
        "paper id": "2408.10007",
        "abstract url": "https://arxiv.org/abs/2408.10007",
        "title": "P3P: Pseudo-3D Pre-training for Scaling 3D Masked Autoencoders",
        "rating": "1",
        "keywords": [
            [
                "training-efficient"
            ],
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D pre-training is crucial to 3D perception tasks. However, limited by the difficulties in collecting clean 3D data, 3D pre-training consistently faced data scaling challenges. Inspired by semi-supervised learning leveraging limited labeled data and a large amount of unlabeled data, in this work, we propose a novel self-supervised pre-training framework utilizing the real 3D data and the pseudo-3D data lifted from images by a large depth estimation model. Another challenge lies in the efficiency. Previous methods such as Point-BERT and Point-MAE, employ k nearest neighbors to embed 3D tokens, requiring quadratic time complexity. To efficiently pre-train on such a large amount of data, we propose a linear-time-complexity token embedding strategy and a training-efficient 2D reconstruction target. Our method achieves state-of-the-art performance in 3D classification and few-shot learning while maintaining high pre-training and downstream fine-tuning efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under review. Pre-print"
    },
    {
        "paper id": "2408.10013",
        "abstract url": "https://arxiv.org/abs/2408.10013",
        "title": "TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading",
        "rating": "1",
        "keywords": [
            [
                "GPU memory"
            ]
        ],
        "abstract": "The growth rate of the GPU memory capacity has not been able to keep up with that of the size of large language models (LLMs), hindering the model training process. In particular, activations -- the intermediate tensors produced during forward propagation and reused in backward propagation -- dominate the GPU memory use. To address this challenge, we propose TBA to efficiently offload activations to high-capacity NVMe SSDs. This approach reduces GPU memory usage without impacting performance by adaptively overlapping data transfers with computation. TBA is compatible with popular deep learning frameworks like PyTorch, Megatron, and DeepSpeed, and it employs techniques such as tensor deduplication, forwarding, and adaptive offloading to further enhance efficiency. We conduct extensive experiments on GPT, BERT, and T5. Results demonstrate that TBA effectively reduces 47% of the activation peak memory usage. At the same time, TBA perfectly overlaps the I/O with the computation and incurs negligible performance overhead. We introduce the recompute-offload-keep (ROK) curve to compare the TBA offloading with other two tensor placement strategies, keeping activations in memory and layerwise full recomputation. We find that TBA achieves better memory savings than layerwise full recomputation while retaining the performance of keeping the activations in memory.",
        "subjects": [
            "cs.DC",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10046",
        "abstract url": "https://arxiv.org/abs/2408.10046",
        "title": "Exploiting Fine-Grained Prototype Distribution for Boosting Unsupervised Class Incremental Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The dynamic nature of open-world scenarios has attracted more attention to class incremental learning (CIL). However, existing CIL methods typically presume the availability of complete ground-truth labels throughout the training process, an assumption rarely met in practical applications. Consequently, this paper explores a more challenging problem of unsupervised class incremental learning (UCIL). The essence of addressing this problem lies in effectively capturing comprehensive feature representations and discovering unknown novel classes. To achieve this, we first model the knowledge of class distribution by exploiting fine-grained prototypes. Subsequently, a granularity alignment technique is introduced to enhance the unsupervised class discovery. Additionally, we proposed a strategy to minimize overlap between novel and existing classes, thereby preserving historical knowledge and mitigating the phenomenon of catastrophic forgetting. Extensive experiments on the five datasets demonstrate that our approach significantly outperforms current state-of-the-art methods, indicating the effectiveness of the proposed method.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10096",
        "abstract url": "https://arxiv.org/abs/2408.10096",
        "title": "Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Low resource of parallel data is the key challenge of accent conversion(AC) problem in which both the pronunciation units and prosody pattern need to be converted. We propose a two-stage generative framework \"convert-and-speak\" in which the conversion is only operated on the semantic token level and the speech is synthesized conditioned on the converted semantic token with a speech generative model in target accent domain. The decoupling design enables the \"speaking\" module to use massive amount of target accent speech and relieves the parallel data required for the \"conversion\" module. Conversion with the bridge of semantic token also relieves the requirement for the data with text transcriptions and unlocks the usage of language pre-training technology to further efficiently reduce the need of parallel accent speech data. To reduce the complexity and latency of \"speaking\", a single-stage AR generative model is designed to achieve good quality as well as lower computation cost. Experiments on Indian-English to general American-English conversion show that the proposed framework achieves state-of-the-art performance in accent similarity, speech quality, and speaker maintenance with only 15 minutes of weakly parallel data which is not constrained to the same speaker. Extensive experimentation with diverse accent types suggests that this framework possesses a high degree of adaptability, making it readily scalable to accommodate other accents with low-resource data. Audio samples are available at https://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "9 pages, ACM MM2024(accepted)"
    },
    {
        "paper id": "2408.10125",
        "abstract url": "https://arxiv.org/abs/2408.10125",
        "title": "Video Object Segmentation via SAM 2: The 4th Solution for LSVOS Challenge VOS Track",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video Object Segmentation (VOS) task aims to segmenting a particular object instance throughout the entire video sequence given only the object mask of the first frame. Recently, Segment Anything Model 2 (SAM 2) is proposed, which is a foundation model towards solving promptable visual segmentation in images and videos. SAM 2 builds a data engine, which improves model and data via user interaction, to collect the largest video segmentation dataset to date. SAM 2 is a simple transformer architecture with streaming memory for real-time video processing, which trained on the date provides strong performance across a wide range of tasks. In this work, we evaluate the zero-shot performance of SAM 2 on the more challenging VOS datasets MOSE and LVOS. Without fine-tuning on the training set, SAM 2 achieved 75.79 J&F on the test set and ranked 4th place for 6th LSVOS Challenge VOS Track.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2408.00714"
    },
    {
        "paper id": "2408.10128",
        "abstract url": "https://arxiv.org/abs/2408.10128",
        "title": "Advancing Voice Cloning for Nepali: Leveraging Transfer Learning in a Low-Resource Language",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Voice cloning is a prominent feature in personalized speech interfaces. A neural vocal cloning system can mimic someone's voice using just a few audio samples. Both speaker encoding and speaker adaptation are topics of research in the field of voice cloning. Speaker adaptation relies on fine-tuning a multi-speaker generative model, which involves training a separate model to infer a new speaker embedding used for speaker encoding. Both methods can achieve excellent performance, even with a small number of cloning audios, in terms of the speech's naturalness and similarity to the original speaker. Speaker encoding approaches are more appropriate for low-resource deployment since they require significantly less memory and have a faster cloning time than speaker adaption, which can offer slightly greater naturalness and similarity. The main goal is to create a vocal cloning system that produces audio output with a Nepali accent or that sounds like Nepali. For the further advancement of TTS, the idea of transfer learning was effectively used to address several issues that were encountered in the development of this system, including the poor audio quality and the lack of available data.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "7 pages, 10 figures"
    },
    {
        "paper id": "2408.10129",
        "abstract url": "https://arxiv.org/abs/2408.10129",
        "title": "UNINEXT-Cutie: The 1st Solution for LSVOS Challenge RVOS Track",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Referring video object segmentation (RVOS) relies on natural language expressions to segment target objects in video. In this year, LSVOS Challenge RVOS Track replaced the origin YouTube-RVOS benchmark with MeViS. MeViS focuses on referring the target object in a video through its motion descriptions instead of static attributes, posing a greater challenge to RVOS task. In this work, we integrate strengths of that leading RVOS and VOS models to build up a simple and effective pipeline for RVOS. Firstly, We finetune the state-of-the-art RVOS model to obtain mask sequences that are correlated with language descriptions. Secondly, based on a reliable and high-quality key frames, we leverage VOS model to enhance the quality and temporal consistency of the mask results. Finally, we further improve the performance of the RVOS model using semi-supervised learning. Our solution achieved 62.57 J&F on the MeViS test set and ranked 1st place for 6th LSVOS Challenge RVOS Track.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10130",
        "abstract url": "https://arxiv.org/abs/2408.10130",
        "title": "Rhyme-aware Chinese lyric generator based on GPT",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Neural language representation models such as GPT, pre-trained on large-scale corpora, can effectively capture rich semantic patterns from plain text and be fine-tuned to consistently improve natural language generation performance. However, existing pre-trained language models used to generate lyrics rarely consider rhyme information, which is crucial in lyrics. Using a pre-trained model directly results in poor performance. To enhance the rhyming quality of generated lyrics, we incorporate integrated rhyme information into our model, thereby improving lyric generation performance.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10141",
        "abstract url": "https://arxiv.org/abs/2408.10141",
        "title": "Instruction Finetuning for Leaderboard Generation from Empirical AI Research",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study demonstrates the application of instruction finetuning of pretrained Large Language Models (LLMs) to automate the generation of AI research leaderboards, extracting (Task, Dataset, Metric, Score) quadruples from articles. It aims to streamline the dissemination of advancements in AI research by transitioning from traditional, manual community curation, or otherwise taxonomy-constrained natural language inference (NLI) models, to an automated, generative LLM-based approach. Utilizing the FLAN-T5 model, this research enhances LLMs' adaptability and reliability in information extraction, offering a novel method for structured knowledge representation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2407.02409"
    },
    {
        "paper id": "2408.10147",
        "abstract url": "https://arxiv.org/abs/2408.10147",
        "title": "In-Context Learning with Representations: Contextual Generalization of Trained Transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In-context learning (ICL) refers to a remarkable capability of pretrained large language models, which can learn a new task given a few examples during inference. However, theoretical understanding of ICL is largely under-explored, particularly whether transformers can be trained to generalize to unseen examples in a prompt, which will require the model to acquire contextual knowledge of the prompt for generalization. This paper investigates the training dynamics of transformers by gradient descent through the lens of non-linear regression tasks. The contextual generalization here can be attained via learning the template function for each task in-context, where all template functions lie in a linear space with $m$ basis functions. We analyze the training dynamics of one-layer multi-head transformers to in-contextly predict unlabeled inputs given partially labeled prompts, where the labels contain Gaussian noise and the number of examples in each prompt are not sufficient to determine the template. Under mild assumptions, we show that the training loss for a one-layer multi-head transformer converges linearly to a global minimum. Moreover, the transformer effectively learns to perform ridge regression over the basis functions. To our knowledge, this study is the first provable demonstration that transformers can learn contextual (i.e., template) information to generalize to both unseen examples and tasks when prompts contain only a small number of query-answer pairs.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.IT",
            "math.OC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10151",
        "abstract url": "https://arxiv.org/abs/2408.10151",
        "title": "Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "While recent large language models (LLMs) demonstrate remarkable abilities in responding to queries in diverse languages, their ability to handle long multilingual contexts is unexplored. As such, a systematic evaluation of the long-context capabilities of LLMs in multilingual settings is crucial, specifically in the context of information retrieval. To address this gap, we introduce the MultiLingual Needle-in-a-Haystack (MLNeedle) test, designed to assess a model's ability to retrieve relevant information (the needle) from a collection of multilingual distractor texts (the haystack). This test serves as an extension of the multilingual question-answering task, encompassing both monolingual and cross-lingual retrieval. We evaluate four state-of-the-art LLMs on MLNeedle. Our findings reveal that model performance can vary significantly with language and needle position. Specifically, we observe that model performance is the lowest when the needle is (i) in a language outside the English language family and (ii) located in the middle of the input context. Furthermore, although some models claim a context size of $8k$ tokens or greater, none demonstrate satisfactory cross-lingual retrieval performance as the context length increases. Our analysis provides key insights into the long-context behavior of LLMs in multilingual settings to guide future evaluation protocols. To our knowledge, this is the first study to investigate the multilingual long-context behavior of LLMs.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10161",
        "abstract url": "https://arxiv.org/abs/2408.10161",
        "title": "NeuFlow v2: High-Efficiency Optical Flow Estimation on Edge Devices",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Real-time high-accuracy optical flow estimation is crucial for various real-world applications. While recent learning-based optical flow methods have achieved high accuracy, they often come with significant computational costs. In this paper, we propose a highly efficient optical flow method that balances high accuracy with reduced computational demands. Building upon NeuFlow v1, we introduce new components including a much more light-weight backbone and a fast refinement module. Both these modules help in keeping the computational demands light while providing close to state of the art accuracy. Compares to other state of the art methods, our model achieves a 10x-70x speedup while maintaining comparable performance on both synthetic and real-world data. It is capable of running at over 20 FPS on 512x384 resolution images on a Jetson Orin Nano. The full training and evaluation code is available at https://github.com/neufieldrobotics/NeuFlow_v2.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10330",
        "abstract url": "https://arxiv.org/abs/2408.10330",
        "title": "Meta-Learning in Audio and Speech Processing: An End to End Comprehensive Review",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This survey overviews various meta-learning approaches used in audio and speech processing scenarios. Meta-learning is used where model performance needs to be maximized with minimum annotated samples, making it suitable for low-sample audio processing. Although the field has made some significant contributions, audio meta-learning still lacks the presence of comprehensive survey papers. We present a systematic review of meta-learning methodologies in audio processing. This includes audio-specific discussions on data augmentation, feature extraction, preprocessing techniques, meta-learners, task selection strategies and also presents important datasets in audio, together with crucial real-world use cases. Through this extensive review, we aim to provide valuable insights and identify future research directions in the intersection of meta-learning and audio processing.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Survey Paper (15 pages, 1 figure)"
    },
    {
        "paper id": "2408.10349",
        "abstract url": "https://arxiv.org/abs/2408.10349",
        "title": "AIR: Analytic Imbalance Rectifier for Continual Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Continual learning enables AI models to learn new data sequentially without retraining in real-world scenarios. Most existing methods assume the training data are balanced, aiming to reduce the catastrophic forgetting problem that models tend to forget previously generated data. However, data imbalance and the mixture of new and old data in real-world scenarios lead the model to ignore categories with fewer training samples. To solve this problem, we propose an analytic imbalance rectifier algorithm (AIR), a novel online exemplar-free continual learning method with an analytic (i.e., closed-form) solution for data-imbalanced class-incremental learning (CIL) and generalized CIL scenarios in real-world continual learning. AIR introduces an analytic re-weighting module (ARM) that calculates a re-weighting factor for each class for the loss function to balance the contribution of each category to the overall loss and solve the problem of imbalanced training data. AIR uses the least squares technique to give a non-discriminatory optimal classifier and its iterative update method in continual learning. Experimental results on multiple datasets show that AIR significantly outperforms existing methods in long-tailed and generalized CIL scenarios. The source code is available at https://github.com/fang-d/AIR.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10353",
        "abstract url": "https://arxiv.org/abs/2408.10353",
        "title": "On the Identifiability of Sparse ICA without Assuming Non-Gaussianity",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Independent component analysis (ICA) is a fundamental statistical tool used to reveal hidden generative processes from observed data. However, traditional ICA approaches struggle with the rotational invariance inherent in Gaussian distributions, often necessitating the assumption of non-Gaussianity in the underlying sources. This may limit their applicability in broader contexts. To accommodate Gaussian sources, we develop an identifiability theory that relies on second-order statistics without imposing further preconditions on the distribution of sources, by introducing novel assumptions on the connective structure from sources to observed variables. Different from recent work that focuses on potentially restrictive connective structures, our proposed assumption of structural variability is both considerably less restrictive and provably necessary. Furthermore, we propose two estimation methods based on second-order statistics and sparsity constraint. Experimental results are provided to validate our identifiability theory and estimation methods.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "NeurIPS 2023"
    },
    {
        "paper id": "2408.10357",
        "abstract url": "https://arxiv.org/abs/2408.10357",
        "title": "Beyond Relevant Documents: A Knowledge-Intensive Approach for Query-Focused Summarization using Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Query-focused summarization (QFS) is a fundamental task in natural language processing with broad applications, including search engines and report generation. However, traditional approaches assume the availability of relevant documents, which may not always hold in practical scenarios, especially in highly specialized topics. To address this limitation, we propose a novel knowledge-intensive approach that reframes QFS as a knowledge-intensive task setup. This approach comprises two main components: a retrieval module and a summarization controller. The retrieval module efficiently retrieves potentially relevant documents from a large-scale knowledge corpus based on the given textual query, eliminating the dependence on pre-existing document sets. The summarization controller seamlessly integrates a powerful large language model (LLM)-based summarizer with a carefully tailored prompt, ensuring the generated summary is comprehensive and relevant to the query. To assess the effectiveness of our approach, we create a new dataset, along with human-annotated relevance labels, to facilitate comprehensive evaluation covering both retrieval and summarization performance. Extensive experiments demonstrate the superior performance of our approach, particularly its ability to generate accurate summaries without relying on the availability of relevant documents initially. This underscores our method's versatility and practical applicability across diverse query scenarios.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": "Accepted by the 27th International Conference on Pattern Recognition (ICPR 2024)"
    },
    {
        "paper id": "2408.10360",
        "abstract url": "https://arxiv.org/abs/2408.10360",
        "title": "HaSPeR: An Image Repository for Hand Shadow Puppet Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Hand shadow puppetry, also known as shadowgraphy or ombromanie, is a form of theatrical art and storytelling where hand shadows are projected onto flat surfaces to create illusions of living creatures. The skilled performers create these silhouettes by hand positioning, finger movements, and dexterous gestures to resemble shadows of animals and objects. Due to the lack of practitioners and a seismic shift in people's entertainment standards, this art form is on the verge of extinction. To facilitate its preservation and proliferate it to a wider audience, we introduce ${\\rm H{\\small A}SP{\\small E}R}$, a novel dataset consisting of 8,340 images of hand shadow puppets across 11 classes extracted from both professional and amateur hand shadow puppeteer clips. We provide a detailed statistical analysis of the dataset and employ a range of pretrained image classification models to establish baselines. Our findings show a substantial performance superiority of traditional convolutional models over attention-based transformer architectures. We also find that lightweight models, such as MobileNetV2, suited for mobile applications and embedded devices, perform comparatively well. We surmise that such low-latency architectures can be useful in developing ombromanie teaching tools, and we create a prototype application to explore this surmission. Keeping the best-performing model InceptionV3 under the limelight, we conduct comprehensive feature-spatial, explainability, and error analyses to gain insights into its decision-making process. To the best of our knowledge, this is the first documented dataset and research endeavor to preserve this dying art for future generations, with computer vision approaches. Our code and data are publicly available.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Submitted to IEEE Transactions on Artificial Intelligence (IEEE TAI), 11 pages, 78 figures, 2 tables"
    },
    {
        "paper id": "2408.10392",
        "abstract url": "https://arxiv.org/abs/2408.10392",
        "title": "Value Alignment from Unstructured Text",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Aligning large language models (LLMs) to value systems has emerged as a significant area of research within the fields of AI and NLP. Currently, this alignment process relies on the availability of high-quality supervised and preference data, which can be both time-consuming and expensive to curate or annotate. In this paper, we introduce a systematic end-to-end methodology for aligning LLMs to the implicit and explicit values represented in unstructured text data. Our proposed approach leverages the use of scalable synthetic data generation techniques to effectively align the model to the values present in the unstructured data. Through two distinct use-cases, we demonstrate the efficiency of our methodology on the Mistral-7B-Instruct model. Our approach credibly aligns LLMs to the values embedded within documents, and shows improved performance against other approaches, as quantified through the use of automatic metrics and win rates.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10414",
        "abstract url": "https://arxiv.org/abs/2408.10414",
        "title": "Towards Automation of Human Stage of Decay Identification: An Artificial Intelligence Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Determining the stage of decomposition (SOD) is crucial for estimating the postmortem interval and identifying human remains. Currently, labor-intensive manual scoring methods are used for this purpose, but they are subjective and do not scale for the emerging large-scale archival collections of human decomposition photos. This study explores the feasibility of automating two common human decomposition scoring methods proposed by Megyesi and Gelderman using artificial intelligence (AI). We evaluated two popular deep learning models, Inception V3 and Xception, by training them on a large dataset of human decomposition images to classify the SOD for different anatomical regions, including the head, torso, and limbs. Additionally, an interrater study was conducted to assess the reliability of the AI models compared to human forensic examiners for SOD identification. The Xception model achieved the best classification performance, with macro-averaged F1 scores of .878, .881, and .702 for the head, torso, and limbs when predicting Megyesi's SODs, and .872, .875, and .76 for the head, torso, and limbs when predicting Gelderman's SODs. The interrater study results supported AI's ability to determine the SOD at a reliability level comparable to a human expert. This work demonstrates the potential of AI models trained on a large dataset of human decomposition images to automate SOD identification.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2408.10441",
        "abstract url": "https://arxiv.org/abs/2408.10441",
        "title": "Goldfish: Monolingual Language Models for 350 Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "For many low-resource languages, the only available language models are large multilingual models trained on many languages simultaneously. However, using FLORES perplexity as a metric, we find that these models perform worse than bigrams for many languages (e.g. 24% of languages in XGLM 4.5B; 43% in BLOOM 7.1B). To facilitate research that focuses on low-resource languages, we pre-train and release Goldfish, a suite of monolingual autoregressive Transformer language models up to 125M parameters for 350 languages. The Goldfish reach lower FLORES perplexities than BLOOM, XGLM, and MaLA-500 on 98 of 204 FLORES languages, despite each Goldfish model being over 10x smaller. However, the Goldfish significantly underperform larger multilingual models on reasoning benchmarks, suggesting that for low-resource languages, multilinguality primarily improves general reasoning abilities rather than basic text generation. We release models trained on 5MB (350 languages), 10MB (288 languages), 100MB (166 languages), and 1GB (83 languages) of text data where available. The Goldfish models are available as baselines, fine-tuning sources, or augmentations to existing models in low-resource NLP research, and they are further useful for crosslinguistic studies requiring maximally comparable models across languages.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10442",
        "abstract url": "https://arxiv.org/abs/2408.10442",
        "title": "Feasibility of assessing cognitive impairment via distributed camera network and privacy-preserving edge computing",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "INTRODUCTION: Mild cognitive impairment (MCI) is characterized by a decline in cognitive functions beyond typical age and education-related expectations. Since, MCI has been linked to reduced social interactions and increased aimless movements, we aimed to automate the capture of these behaviors to enhance longitudinal monitoring. METHODS: Using a privacy-preserving distributed camera network, we collected movement and social interaction data from groups of individuals with MCI undergoing therapy within a 1700$m^2$ space. We developed movement and social interaction features, which were then used to train a series of machine learning algorithms to distinguish between higher and lower cognitive functioning MCI groups. RESULTS: A Wilcoxon rank-sum test revealed statistically significant differences between high and low-functioning cohorts in features such as linear path length, walking speed, change in direction while walking, entropy of velocity and direction change, and number of group formations in the indoor space. Despite lacking individual identifiers to associate with specific levels of MCI, a machine learning approach using the most significant features provided a 71% accuracy. DISCUSSION: We provide evidence to show that a privacy-preserving low-cost camera network using edge computing framework has the potential to distinguish between different levels of cognitive impairment from the movements and social interactions captured during group activities.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10443",
        "abstract url": "https://arxiv.org/abs/2408.10443",
        "title": "Federated Learning of Large ASR Models in the Real World",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Federated Learning"
            ],
            [
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Federated learning (FL) has shown promising results on training machine learning models with privacy preservation. However, for large models with over 100 million parameters, the training resource requirement becomes an obstacle for FL because common devices do not have enough memory and computation power to finish the FL tasks. Although efficient training methods have been proposed, it is still a challenge to train the large models like Conformer based ASR. This paper presents a systematic solution to train the full-size ASR models of 130M parameters with FL. To our knowledge, this is the first real-world FL application of the Conformer model, which is also the largest model ever trained with FL so far. And this is the first paper showing FL can improve the ASR model quality with a set of proposed methods to refine the quality of data and labels of clients. We demonstrate both the training efficiency and the model quality improvement in real-world experiments.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10467",
        "abstract url": "https://arxiv.org/abs/2408.10467",
        "title": "Learning Multimodal Latent Space with EBM Prior and MCMC Inference",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal generative models are crucial for various applications. We propose an approach that combines an expressive energy-based model (EBM) prior with Markov Chain Monte Carlo (MCMC) inference in the latent space for multimodal generation. The EBM prior acts as an informative guide, while MCMC inference, specifically through short-run Langevin dynamics, brings the posterior distribution closer to its true form. This method not only provides an expressive prior to better capture the complexity of multimodality but also improves the learning of shared latent variables for more coherent generation across modalities. Our proposed method is supported by empirical experiments, underscoring the effectiveness of our EBM prior with MCMC inference in enhancing cross-modal and joint generative tasks in multimodal contexts.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10468",
        "abstract url": "https://arxiv.org/abs/2408.10468",
        "title": "Tracing Privacy Leakage of Language Models to Training Data via Adjusted Influence Functions",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The responses generated by Large Language Models (LLMs) can include sensitive information from individuals and organizations, leading to potential privacy leakage. This work implements Influence Functions (IFs) to trace privacy leakage back to the training data, thereby mitigating privacy concerns of Language Models (LMs). However, we notice that current IFs struggle to accurately estimate the influence of tokens with large gradient norms, potentially overestimating their influence. When tracing the most influential samples, this leads to frequently tracing back to samples with large gradient norm tokens, overshadowing the actual most influential samples even if their influences are well estimated. To address this issue, we propose Heuristically Adjusted IF (HAIF), which reduces the weight of tokens with large gradient norms, thereby significantly improving the accuracy of tracing the most influential samples. To establish easily obtained groundtruth for tracing privacy leakage, we construct two datasets, PII-E and PII-CR, representing two distinct scenarios: one with identical text in the model outputs and pre-training data, and the other where models leverage their reasoning abilities to generate text divergent from pre-training data. HAIF significantly improves tracing accuracy, enhancing it by 20.96\\% to 73.71\\% on the PII-E dataset and 3.21\\% to 45.93\\% on the PII-CR dataset, compared to the best SOTA IFs against various GPT-2 and QWen-1.5 models. HAIF also outperforms SOTA IFs on real-world pretraining data CLUECorpus2020, demonstrating strong robustness regardless prompt and response lengths.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10469",
        "abstract url": "https://arxiv.org/abs/2408.10469",
        "title": "LSVOS Challenge 3rd Place Report: SAM2 and Cutie based VOS",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video Object Segmentation (VOS) presents several challenges, including object occlusion and fragmentation, the dis-appearance and re-appearance of objects, and tracking specific objects within crowded scenes. In this work, we combine the strengths of the state-of-the-art (SOTA) models SAM2 and Cutie to address these challenges. Additionally, we explore the impact of various hyperparameters on video instance segmentation performance. Our approach achieves a J\\&F score of 0.7952 in the testing phase of LSVOS challenge VOS track, ranking third overall.",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2406.03668"
    },
    {
        "paper id": "2408.10473",
        "abstract url": "https://arxiv.org/abs/2408.10473",
        "title": "Enhancing One-shot Pruned Pre-trained Language Models through Sparse-Dense-Sparse Mechanism",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Pre-trained language models (PLMs) are engineered to be robust in contextual understanding and exhibit outstanding performance in various natural language processing tasks. However, their considerable size incurs significant computational and storage costs. Modern pruning strategies employ one-shot techniques to compress PLMs without the need for retraining on task-specific or otherwise general data; however, these approaches often lead to an indispensable reduction in performance. In this paper, we propose SDS, a Sparse-Dense-Sparse pruning framework to enhance the performance of the pruned PLMs from a weight distribution optimization perspective. We outline the pruning process in three steps. Initially, we prune less critical connections in the model using conventional one-shot pruning methods. Next, we reconstruct a dense model featuring a pruning-friendly weight distribution by reactivating pruned connections with sparse regularization. Finally, we perform a second pruning round, yielding a superior pruned model compared to the initial pruning. Experimental results demonstrate that SDS outperforms the state-of-the-art pruning techniques SparseGPT and Wanda under an identical sparsity configuration. For instance, SDS reduces perplexity by 9.13 on Raw-Wikitext2 and improves accuracy by an average of 2.05% across multiple zero-shot benchmarks for OPT-125M with 2:4 sparsity.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10474",
        "abstract url": "https://arxiv.org/abs/2408.10474",
        "title": "LeCov: Multi-level Testing Criteria for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are widely used in many different domains, but because of their limited interpretability, there are questions about how trustworthy they are in various perspectives, e.g., truthfulness and toxicity. Recent research has started developing testing methods for LLMs, aiming to uncover untrustworthy issues, i.e., defects, before deployment. However, systematic and formalized testing criteria are lacking, which hinders a comprehensive assessment of the extent and adequacy of testing exploration. To mitigate this threat, we propose a set of multi-level testing criteria, LeCov, for LLMs. The criteria consider three crucial LLM internal components, i.e., the attention mechanism, feed-forward neurons, and uncertainty, and contain nine types of testing criteria in total. We apply the criteria in two scenarios: test prioritization and coverage-guided testing. The experiment evaluation, on three models and four datasets, demonstrates the usefulness and effectiveness of LeCov.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10490",
        "abstract url": "https://arxiv.org/abs/2408.10490",
        "title": "Analysis of Plan-based Retrieval for Grounded Text Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In text generation, hallucinations refer to the generation of seemingly coherent text that contradicts established knowledge. One compelling hypothesis is that hallucinations occur when a language model is given a generation task outside its parametric knowledge (due to rarity, recency, domain, etc.). A common strategy to address this limitation is to infuse the language models with retrieval mechanisms, providing the model with relevant knowledge for the task. In this paper, we leverage the planning capabilities of instruction-tuned LLMs and analyze how planning can be used to guide retrieval to further reduce the frequency of hallucinations. We empirically evaluate several variations of our proposed approach on long-form text generation tasks. By improving the coverage of relevant facts, plan-guided retrieval and generation can produce more informative responses while providing a higher rate of attribution to source documents.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10500",
        "abstract url": "https://arxiv.org/abs/2408.10500",
        "title": "SZTU-CMU at MER2024: Improving Emotion-LLaMA with Conv-Attention for Multimodal Emotion Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper presents our winning approach for the MER-NOISE and MER-OV tracks of the MER2024 Challenge on multimodal emotion recognition. Our system leverages the advanced emotional understanding capabilities of Emotion-LLaMA to generate high-quality annotations for unlabeled samples, addressing the challenge of limited labeled data. To enhance multimodal fusion while mitigating modality-specific noise, we introduce Conv-Attention, a lightweight and efficient hybrid framework. Extensive experimentation vali-dates the effectiveness of our approach. In the MER-NOISE track, our system achieves a state-of-the-art weighted average F-score of 85.30%, surpassing the second and third-place teams by 1.47% and 1.65%, respectively. For the MER-OV track, our utilization of Emotion-LLaMA for open-vocabulary annotation yields an 8.52% improvement in average accuracy and recall compared to GPT-4V, securing the highest score among all participating large multimodal models. The code and model for Emotion-LLaMA are available at https://github.com/ZebangCheng/Emotion-LLaMA.",
        "subjects": [
            "cs.MM",
            "cs.CV",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Ranked 1st in MER24@IJCAI and MRAC24@ACM MM (MER-NOISE & MER-OV (self-evaluated))"
    },
    {
        "paper id": "2408.10503",
        "abstract url": "https://arxiv.org/abs/2408.10503",
        "title": "Adaptive Knowledge Distillation for Classification of Hand Images using Explainable Vision Transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Assessing the forensic value of hand images involves the use of unique features and patterns present in an individual's hand. The human hand has distinct characteristics, such as the pattern of veins, fingerprints, and the geometry of the hand itself. This paper investigates the use of vision transformers (ViTs) for classification of hand images. We use explainability tools to explore the internal representations of ViTs and assess their impact on the model outputs. Utilizing the internal understanding of ViTs, we introduce distillation methods that allow a student model to adaptively extract knowledge from a teacher model while learning on data of a different domain to prevent catastrophic forgetting. Two publicly available hand image datasets are used to conduct a series of experiments to evaluate performance of the ViTs and our proposed adaptive distillation methods. The experimental results demonstrate that ViT models significantly outperform traditional machine learning methods and the internal states of ViTs are useful for explaining the model outputs in the classification task. By averting catastrophic forgetting, our distillation methods achieve excellent performance on data from both source and target domains, particularly when these two domains exhibit significant dissimilarity. The proposed approaches therefore can be developed and implemented effectively for real-world applications such as access control, identity verification, and authentication systems.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at the ECML PKDD 2024 (Research Track)"
    },
    {
        "paper id": "2408.10516",
        "abstract url": "https://arxiv.org/abs/2408.10516",
        "title": "Data Augmentation Integrating Dialogue Flow and Style to Adapt Spoken Dialogue Systems to Low-Resource User Groups",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study addresses the interaction challenges encountered by spoken dialogue systems (SDSs) when engaging with users who exhibit distinct conversational behaviors, particularly minors, in scenarios where data are scarce. We propose a novel data augmentation framework to enhance SDS performance for user groups with limited resources. Our approach leverages a large language model (LLM) to extract speaker styles and a pre-trained language model (PLM) to simulate dialogue act history. This method generates enriched and personalized dialogue data, facilitating improved interactions with unique user demographics. Extensive experiments validate the efficacy of our methodology, highlighting its potential to foster the development of more adaptive and inclusive dialogue systems.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted to SIGDIAL 2024"
    },
    {
        "paper id": "2408.10524",
        "abstract url": "https://arxiv.org/abs/2408.10524",
        "title": "XCB: an effective contextual biasing approach to bias cross-lingual phrases in speech recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Contextualized ASR models have been demonstrated to effectively improve the recognition accuracy of uncommon phrases when a predefined phrase list is available. However, these models often struggle with bilingual settings, which are prevalent in code-switching speech recognition. In this study, we make the initial attempt to address this challenge by introducing a Cross-lingual Contextual Biasing(XCB) module. Specifically, we augment a pre-trained ASR model for the dominant language by integrating an auxiliary language biasing module and a supplementary language-specific loss, aimed at enhancing the recognition of phrases in the secondary language. Experimental results conducted on our in-house code-switching dataset have validated the efficacy of our approach, demonstrating significant improvements in the recognition of biasing phrases in the secondary language, even without any additional inference overhead. Additionally, our proposed system exhibits both efficiency and generalization when is applied by the unseen ASRU-2019 test set.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "accepted to NCMMSC 2024"
    },
    {
        "paper id": "2408.10528",
        "abstract url": "https://arxiv.org/abs/2408.10528",
        "title": "NoMatterXAI: Generating \"No Matter What\" Alterfactual Examples for Explaining Black-Box Text Classification Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In Explainable AI (XAI), counterfactual explanations (CEs) are a well-studied method to communicate feature relevance through contrastive reasoning of \"what if\" to explain AI models' predictions. However, they only focus on important (i.e., relevant) features and largely disregard less important (i.e., irrelevant) ones. Such irrelevant features can be crucial in many applications, especially when users need to ensure that an AI model's decisions are not affected or biased against specific attributes such as gender, race, religion, or political affiliation. To address this gap, the concept of alterfactual explanations (AEs) has been proposed. AEs explore an alternative reality of \"no matter what\", where irrelevant features are substituted with alternative features (e.g., \"republicans\" -> \"democrats\") within the same attribute (e.g., \"politics\") while maintaining a similar prediction output. This serves to validate whether AI model predictions are influenced by the specified attributes. Despite the promise of AEs, there is a lack of computational approaches to systematically generate them, particularly in the text domain, where creating AEs for AI text classifiers presents unique challenges. This paper addresses this challenge by formulating AE generation as an optimization problem and introducing MoMatterXAI, a novel algorithm that generates AEs for text classification tasks. Our approach achieves high fidelity of up to 95% while preserving context similarity of over 90% across multiple models and datasets. A human study further validates the effectiveness of AEs in explaining AI text classifiers to end users. All codes will be publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10536",
        "abstract url": "https://arxiv.org/abs/2408.10536",
        "title": "Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Information retrieval across different languages is an increasingly important challenge in natural language processing. Recent approaches based on multilingual pre-trained language models have achieved remarkable success, yet they often optimize for either monolingual, cross-lingual, or multilingual retrieval performance at the expense of others. This paper proposes a novel hybrid batch training strategy to simultaneously improve zero-shot retrieval performance across monolingual, cross-lingual, and multilingual settings while mitigating language bias. The approach fine-tunes multilingual language models using a mix of monolingual and cross-lingual question-answer pair batches sampled based on dataset size. Experiments on XQuAD-R, MLQA-R, and MIRACL benchmark datasets show that the proposed method consistently achieves comparable or superior results in zero-shot retrieval across various languages and retrieval tasks compared to monolingual-only or cross-lingual-only training. Hybrid batch training also substantially reduces language bias in multilingual retrieval compared to monolingual training. These results demonstrate the effectiveness of the proposed approach for learning language-agnostic representations that enable strong zero-shot retrieval performance across diverse languages.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": "15 pages, 2 figures, 13 tables"
    },
    {
        "paper id": "2408.10539",
        "abstract url": "https://arxiv.org/abs/2408.10539",
        "title": "Training Matting Models without Alpha Labels",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The labelling difficulty has been a longstanding problem in deep image matting. To escape from fine labels, this work explores using rough annotations such as trimaps coarsely indicating the foreground/background as supervision. We present that the cooperation between learned semantics from indicated known regions and proper assumed matting rules can help infer alpha values at transition areas. Inspired by the nonlocal principle in traditional image matting, we build a directional distance consistency loss (DDC loss) at each pixel neighborhood to constrain the alpha values conditioned on the input image. DDC loss forces the distance of similar pairs on the alpha matte and on its corresponding image to be consistent. In this way, the alpha values can be propagated from learned known regions to unknown transition areas. With only images and trimaps, a matting model can be trained under the supervision of a known loss and the proposed DDC loss. Experiments on AM-2K and P3M-10K dataset show that our paradigm achieves comparable performance with the fine-label-supervised baseline, while sometimes offers even more satisfying results than human-labelled ground truth. Code is available at \\url{https://github.com/poppuppy/alpha-free-matting}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 12 figures"
    },
    {
        "paper id": "2408.10541",
        "abstract url": "https://arxiv.org/abs/2408.10541",
        "title": "The Instance-centric Transformer for the RVOS Track of LSVOS Challenge: 3rd Place Solution",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Referring Video Object Segmentation is an emerging multi-modal task that aims to segment objects in the video given a natural language expression. In this work, we build two instance-centric models and fuse predicted results from frame-level and instance-level. First, we introduce instance mask into the DETR-based model for query initialization to achieve temporal enhancement and employ SAM for spatial refinement. Secondly, we build an instance retrieval model conducting binary instance mask classification whether the instance is referred. Finally, we fuse predicted results and our method achieved a score of 52.67 J&F in the validation phase and 60.36 J&F in the test phase, securing the final ranking of 3rd place in the 6-th LSVOS Challenge RVOS Track.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2406.13939"
    },
    {
        "paper id": "2408.10841",
        "abstract url": "https://arxiv.org/abs/2408.10841",
        "title": "DELIA: Diversity-Enhanced Learning for Instruction Adaptation in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Although instruction tuning is widely used to adjust behavior in Large Language Models (LLMs), extensive empirical evidence and research indicates that it is primarily a process where the model fits to specific task formats, rather than acquiring new knowledge or capabilities. We propose that this limitation stems from biased features learned during instruction tuning, which differ from ideal task-specfic features, leading to learn less underlying semantics in downstream tasks. However, ideal features are unknown and incalculable, constraining past work to rely on prior knowledge to assist reasoning or training, which limits LLMs' capabilities to the developers' abilities, rather than data-driven scalable learning. In our paper, through our novel data synthesis method, DELIA (Diversity-Enhanced Learning for Instruction Adaptation), we leverage the buffering effect of extensive diverse data in LLMs training to transform biased features in instruction tuning into approximations of ideal features, without explicit prior ideal features. Experiments show DELIA's better performance compared to common instruction tuning and other baselines. It outperforms common instruction tuning by 17.07%-33.41% on Icelandic-English translation bleurt score (WMT-21 dataset, gemma-7b-it) and improves accuracy by 36.1% on formatted text generation (Llama2-7b-chat). Notably, among knowledge injection methods we've known, DELIA uniquely align the internal representations of new special tokens with their prior semantics.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2408.10845",
        "abstract url": "https://arxiv.org/abs/2408.10845",
        "title": "CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Autonomous Driving",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Autonomous driving, particularly navigating complex and unanticipated scenarios, demands sophisticated reasoning and planning capabilities. While Multi-modal Large Language Models (MLLMs) offer a promising avenue for this, their use has been largely confined to understanding complex environmental contexts or generating high-level driving commands, with few studies extending their application to end-to-end path planning. A major research bottleneck is the lack of large-scale annotated datasets encompassing vision, language, and action. To address this issue, we propose CoVLA (Comprehensive Vision-Language-Action) Dataset, an extensive dataset comprising real-world driving videos spanning more than 80 hours. This dataset leverages a novel, scalable approach based on automated data processing and a caption generation pipeline to generate accurate driving trajectories paired with detailed natural language descriptions of driving environments and maneuvers. This approach utilizes raw in-vehicle sensor data, allowing it to surpass existing datasets in scale and annotation richness. Using CoVLA, we investigate the driving capabilities of MLLMs that can handle vision, language, and action in a variety of driving scenarios. Our results illustrate the strong proficiency of our model in generating coherent language and action outputs, emphasizing the potential of Vision-Language-Action (VLA) models in the field of autonomous driving. This dataset establishes a framework for robust, interpretable, and data-driven autonomous driving systems by providing a comprehensive platform for training and evaluating VLA models, contributing to safer and more reliable self-driving vehicles. The dataset is released for academic purpose.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.11871",
        "abstract url": "https://arxiv.org/abs/2408.11871",
        "title": "MegaFake: A Theory-Driven Dataset of Fake News Generated by Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The advent of large language models (LLMs) has revolutionized online content creation, making it much easier to generate high-quality fake news. This misuse threatens the integrity of our digital environment and ethical standards. Therefore, understanding the motivations and mechanisms behind LLM-generated fake news is crucial. In this study, we analyze the creation of fake news from a social psychology perspective and develop a comprehensive LLM-based theoretical framework, LLM-Fake Theory. We introduce a novel pipeline that automates the generation of fake news using LLMs, thereby eliminating the need for manual annotation. Utilizing this pipeline, we create a theoretically informed Machine-generated Fake news dataset, MegaFake, derived from the GossipCop dataset. We conduct comprehensive analyses to evaluate our MegaFake dataset. We believe that our dataset and insights will provide valuable contributions to future research focused on the detection and governance of fake news in the era of LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.11873",
        "abstract url": "https://arxiv.org/abs/2408.11873",
        "title": "Parameter-Efficient Transfer Learning under Federated Learning for Automatic Speech Recognition",
        "rating": "1",
        "keywords": [
            [
                "Parameter-Efficient"
            ],
            [
                "Federated Learning"
            ],
            [
                "cs.LG",
                "eess.AS"
            ]
        ],
        "abstract": "This work explores the challenge of enhancing Automatic Speech Recognition (ASR) model performance across various user-specific domains while preserving user data privacy. We employ federated learning and parameter-efficient domain adaptation methods to solve the (1) massive data requirement of ASR models from user-specific scenarios and (2) the substantial communication cost between servers and clients during federated learning. We demonstrate that when equipped with proper adapters, ASR models under federated tuning can achieve similar performance compared with centralized tuning ones, thus providing a potential direction for future privacy-preserved ASR services. Besides, we investigate the efficiency of different adapters and adapter incorporation strategies under the federated learning setting.",
        "subjects": [
            "eess.AS",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09702",
        "abstract url": "https://arxiv.org/abs/2408.09702",
        "title": "Photorealistic Object Insertion with Diffusion-Guided Inverse Rendering",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion",
                "inpainting"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "The correct insertion of virtual objects in images of real-world scenes requires a deep understanding of the scene's lighting, geometry and materials, as well as the image formation process. While recent large-scale diffusion models have shown strong generative and inpainting capabilities, we find that current models do not sufficiently \"understand\" the scene shown in a single picture to generate consistent lighting effects (shadows, bright reflections, etc.) while preserving the identity and details of the composited object. We propose using a personalized large diffusion model as guidance to a physically based inverse rendering process. Our method recovers scene lighting and tone-mapping parameters, allowing the photorealistic composition of arbitrary virtual objects in single frames or videos of indoor or outdoor scenes. Our physically based pipeline further enables automatic materials and tone-mapping refinement.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "comment": "ECCV 2024, Project page: https://research.nvidia.com/labs/toronto-ai/DiPIR/"
    },
    {
        "paper id": "2408.09718",
        "abstract url": "https://arxiv.org/abs/2408.09718",
        "title": "Confirmation Bias in Gaussian Mixture Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Confirmation bias, the tendency to interpret information in a way that aligns with one's preconceptions, can profoundly impact scientific research, leading to conclusions that reflect the researcher's hypotheses even when the observational data do not support them. This issue is especially critical in scientific fields involving highly noisy observations, such as cryo-electron microscopy. This study investigates confirmation bias in Gaussian mixture models. We consider the following experiment: A team of scientists assumes they are analyzing data drawn from a Gaussian mixture model with known signals (hypotheses) as centroids. However, in reality, the observations consist entirely of noise without any informative structure. The researchers use a single iteration of the K-means or expectation-maximization algorithms, two popular algorithms to estimate the centroids. Despite the observations being pure noise, we show that these algorithms yield biased estimates that resemble the initial hypotheses, contradicting the unbiased expectation that averaging these noise observations would converge to zero. Namely, the algorithms generate estimates that mirror the postulated model, although the hypotheses (the presumed centroids of the Gaussian mixture) are not evident in the observations. Specifically, among other results, we prove a positive correlation between the estimates produced by the algorithms and the corresponding hypotheses. We also derive explicit closed-form expressions of the estimates for a finite and infinite number of hypotheses. This study underscores the risks of confirmation bias in low signal-to-noise environments, provides insights into potential pitfalls in scientific methodologies, and highlights the importance of prudent data interpretation.",
        "subjects": [
            "stat.ML",
            "cs.IT",
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09722",
        "abstract url": "https://arxiv.org/abs/2408.09722",
        "title": "Towards Few-Shot Learning in the Open World: A Review and Beyond",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Human intelligence is characterized by our ability to absorb and apply knowledge from the world around us, especially in rapidly acquiring new concepts from minimal examples, underpinned by prior knowledge. Few-shot learning (FSL) aims to mimic this capacity by enabling significant generalizations and transferability. However, traditional FSL frameworks often rely on assumptions of clean, complete, and static data, conditions that are seldom met in real-world environments. Such assumptions falter in the inherently uncertain, incomplete, and dynamic contexts of the open world. This paper presents a comprehensive review of recent advancements designed to adapt FSL for use in open-world settings. We categorize existing methods into three distinct types of open-world few-shot learning: those involving varying instances, varying classes, and varying distributions. Each category is discussed in terms of its specific challenges and methods, as well as its strengths and weaknesses. We standardize experimental settings and metric benchmarks across scenarios, and provide a comparative analysis of the performance of various methods. In conclusion, we outline potential future research directions for this evolving field. It is our hope that this review will catalyze further development of effective solutions to these complex challenges, thereby advancing the field of artificial intelligence.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09735",
        "abstract url": "https://arxiv.org/abs/2408.09735",
        "title": "Icing on the Cake: Automatic Code Summarization at Ericsson",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents our findings on the automatic summarization of Java methods within Ericsson, a global telecommunications company. We evaluate the performance of an approach called Automatic Semantic Augmentation of Prompts (ASAP), which uses a Large Language Model (LLM) to generate leading summary comments for Java methods. ASAP enhances the $LLM's$ prompt context by integrating static program analysis and information retrieval techniques to identify similar exemplar methods along with their developer-written Javadocs, and serves as the baseline in our study. In contrast, we explore and compare the performance of four simpler approaches that do not require static program analysis, information retrieval, or the presence of exemplars as in the ASAP method. Our methods rely solely on the Java method body as input, making them lightweight and more suitable for rapid deployment in commercial software development environments. We conducted experiments on an Ericsson software project and replicated the study using two widely-used open-source Java projects, Guava and Elasticsearch, to ensure the reliability of our results. Performance was measured across eight metrics that capture various aspects of similarity. Notably, one of our simpler approaches performed as well as or better than the ASAP method on both the Ericsson project and the open-source projects. Additionally, we performed an ablation study to examine the impact of method names on Javadoc summary generation across our four proposed approaches and the ASAP method. By masking the method names and observing the generated summaries, we found that our approaches were statistically significantly less influenced by the absence of method names compared to the baseline. This suggests that our methods are more robust to variations in method names and may derive summaries more comprehensively from the method body than the ASAP approach.",
        "subjects": [
            "cs.SE",
            "cs.LG"
        ],
        "comment": "16 pages, 6 tables, 4 figures. Accepted at the 2024 International Conference on Software Maintenance and Evolution (ICSME) 2024 - Industry Track"
    },
    {
        "paper id": "2408.09756",
        "abstract url": "https://arxiv.org/abs/2408.09756",
        "title": "Parallel-in-Time Solutions with Random Projection Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper considers one of the fundamental parallel-in-time methods for the solution of ordinary differential equations, Parareal, and extends it by adopting a neural network as a coarse propagator. We provide a theoretical analysis of the convergence properties of the proposed algorithm and show its effectiveness for several examples, including Lorenz and Burgers' equations. In our numerical simulations, we further specialize the underpinning neural architecture to Random Projection Neural Networks (RPNNs), a 2-layer neural network where the first layer weights are drawn at random rather than optimized. This restriction substantially increases the efficiency of fitting RPNN's weights in comparison to a standard feedforward network without negatively impacting the accuracy, as demonstrated in the SIR system example.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09760",
        "abstract url": "https://arxiv.org/abs/2408.09760",
        "title": "Regional and spatial dependence of poverty factors in Thailand, and its use into Bayesian hierarchical regression analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Poverty is a serious issue that harms humanity progression. The simplest solution is to use one-shirt-size policy to alleviate it. Nevertheless, each region has its unique issues, which require a unique solution to solve them. In the aspect of spatial analysis, neighbor regions can provide useful information to analyze issues of a given region. In this work, we proposed inferred boundaries of regions of Thailand that can explain better the poverty dynamics, instead of the usual government administrative regions. The proposed regions maximize a trade-off between poverty-related features and geographical coherence. We use a spatial analysis together with Moran's cluster algorithms and Bayesian hierarchical regression models, with the potential of assist the implementation of the right policy to alleviate the poverty phenomenon. We found that all variables considered show a positive spatial autocorrelation. The results of analysis illustrate that 1) Northern, Northeastern Thailand, and in less extend Northcentral Thailand are the regions that require more attention in the aspect of poverty issues, 2) Northcentral, Northeastern, Northern and Southern Thailand present dramatically low levels of education, income and amount of savings contrasted with large cities such as Bangkok-Pattaya and Central Thailand, and 3) Bangkok-Pattaya is the only region whose average years of education is above 12 years, which corresponds (approx.) with a complete senior high school.",
        "subjects": [
            "stat.ME",
            "cs.SI",
            "econ.GN",
            "stat.AP"
        ],
        "comment": "Codes to reproduce our results are available in https://github.com/IrvingGomez/SpatialPovertyFactors"
    },
    {
        "paper id": "2408.09765",
        "abstract url": "https://arxiv.org/abs/2408.09765",
        "title": "Baby Bear: Seeking a Just Right Rating Scale for Scalar Annotations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Our goal is a mechanism for efficiently assigning scalar ratings to each of a large set of elements. For example, \"what percent positive or negative is this product review?\" When sample sizes are small, prior work has advocated for methods such as Best Worst Scaling (BWS) as being more robust than direct ordinal annotation (\"Likert scales\"). Here we first introduce IBWS, which iteratively collects annotations through Best-Worst Scaling, resulting in robustly ranked crowd-sourced data. While effective, IBWS is too expensive for large-scale tasks. Using the results of IBWS as a best-desired outcome, we evaluate various direct assessment methods to determine what is both cost-efficient and best correlating to a large scale BWS annotation strategy. Finally, we illustrate in the domains of dialogue and sentiment how these annotations can support robust learning-to-rank models.",
        "subjects": [
            "cs.LG",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09768",
        "abstract url": "https://arxiv.org/abs/2408.09768",
        "title": "MalLight: Influence-Aware Coordinated Traffic Signal Control for Traffic Signal Malfunctions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Urban traffic is subject to disruptions that cause extended waiting time and safety issues at signalized intersections. While numerous studies have addressed the issue of intelligent traffic systems in the context of various disturbances, traffic signal malfunction, a common real-world occurrence with significant repercussions, has received comparatively limited attention. The primary objective of this research is to mitigate the adverse effects of traffic signal malfunction, such as traffic congestion and collision, by optimizing the control of neighboring functioning signals. To achieve this goal, this paper presents a novel traffic signal control framework (MalLight), which leverages an Influence-aware State Aggregation Module (ISAM) and an Influence-aware Reward Aggregation Module (IRAM) to achieve coordinated control of surrounding traffic signals. To the best of our knowledge, this study pioneers the application of a Reinforcement Learning(RL)-based approach to address the challenges posed by traffic signal malfunction. Empirical investigations conducted on real-world datasets substantiate the superior performance of our proposed methodology over conventional and deep learning-based alternatives in the presence of signal malfunction, with reduction of throughput alleviated by as much as 48.6$\\%$.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Paper accepted to CIKM24 Full Research track"
    },
    {
        "paper id": "2408.09791",
        "abstract url": "https://arxiv.org/abs/2408.09791",
        "title": "ALTBI: Constructing Improved Outlier Detection Models via Optimization of Inlier-Memorization Effect",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Outlier detection (OD) is the task of identifying unusual observations (or outliers) from a given or upcoming data by learning unique patterns of normal observations (or inliers). Recently, a study introduced a powerful unsupervised OD (UOD) solver based on a new observation of deep generative models, called inlier-memorization (IM) effect, which suggests that generative models memorize inliers before outliers in early learning stages. In this study, we aim to develop a theoretically principled method to address UOD tasks by maximally utilizing the IM effect. We begin by observing that the IM effect is observed more clearly when the given training data contain fewer outliers. This finding indicates a potential for enhancing the IM effect in UOD regimes if we can effectively exclude outliers from mini-batches when designing the loss function. To this end, we introduce two main techniques: 1) increasing the mini-batch size as the model training proceeds and 2) using an adaptive threshold to calculate the truncated loss function. We theoretically show that these two techniques effectively filter out outliers from the truncated loss function, allowing us to utilize the IM effect to the fullest. Coupled with an additional ensemble strategy, we propose our method and term it Adaptive Loss Truncation with Batch Increment (ALTBI). We provide extensive experimental results to demonstrate that ALTBI achieves state-of-the-art performance in identifying outliers compared to other recent methods, even with significantly lower computation costs. Additionally, we show that our method yields robust performances when combined with privacy-preserving algorithms.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "24 pages in total"
    },
    {
        "paper id": "2408.09798",
        "abstract url": "https://arxiv.org/abs/2408.09798",
        "title": "Enhance Modality Robustness in Text-Centric Multimodal Alignment with Adversarial Prompting",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Converting different modalities into generalized text, which then serves as input prompts for large language models (LLMs), is a common approach for aligning multimodal models, particularly when pairwise data is limited. Text-centric alignment method leverages the unique properties of text as a modality space, transforming diverse inputs into a unified textual representation, thereby enabling downstream models to effectively interpret various modal inputs. This study evaluates the quality and robustness of multimodal representations in the face of noise imperfections, dynamic input order permutations, and missing modalities, revealing that current text-centric alignment methods can compromise downstream robustness. To address this issue, we propose a new text-centric adversarial training approach that significantly enhances robustness compared to traditional robust training methods and pre-trained multimodal foundation models. Our findings underscore the potential of this approach to improve the robustness and adaptability of multimodal representations, offering a promising solution for dynamic and real-world applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2407.05036"
    },
    {
        "paper id": "2408.09807",
        "abstract url": "https://arxiv.org/abs/2408.09807",
        "title": "World Models Increase Autonomy in Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent's own autonomously acquired experience. However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments. To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision. We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance. MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states. It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision. Our findings suggest model-based methods hold significant promise for reducing human effort in RL. Website: https://sites.google.com/view/morefree",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09817",
        "abstract url": "https://arxiv.org/abs/2408.09817",
        "title": "Contextual Dual Learning Algorithm with Listwise Distillation for Unbiased Learning to Rank",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Unbiased Learning to Rank (ULTR) aims to leverage biased implicit user feedback (e.g., click) to optimize an unbiased ranking model. The effectiveness of the existing ULTR methods has primarily been validated on synthetic datasets. However, their performance on real-world click data remains unclear. Recently, Baidu released a large publicly available dataset of their web search logs. Subsequently, the NTCIR-17 ULTRE-2 task released a subset dataset extracted from it. We conduct experiments on commonly used or effective ULTR methods on this subset to determine whether they maintain their effectiveness. In this paper, we propose a Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD) to simultaneously address both position bias and contextual bias. We utilize a listwise-input ranking model to obtain reconstructed feature vectors incorporating local contextual information and employ the Dual Learning Algorithm (DLA) method to jointly train this ranking model and a propensity model to address position bias. As this ranking model learns the interaction information within the documents list of the training set, to enhance the ranking model's generalization ability, we additionally train a pointwise-input ranking model to learn the listwise-input ranking model's capability for relevance judgment in a listwise manner. Extensive experiments and analysis confirm the effectiveness of our approach.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "12 pages, 2 figures"
    },
    {
        "paper id": "2408.09821",
        "abstract url": "https://arxiv.org/abs/2408.09821",
        "title": "Symplectic Neural Networks Based on Dynamical Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present and analyze a framework for designing symplectic neural networks (SympNets) based on geometric integrators for Hamiltonian differential equations. The SympNets are universal approximators in the space of Hamiltonian diffeomorphisms, interpretable and have a non-vanishing gradient property. We also give a representation theory for linear systems, meaning the proposed P-SympNets can exactly parameterize any symplectic map corresponding to quadratic Hamiltonians. Extensive numerical tests demonstrate increased expressiveness and accuracy -- often several orders of magnitude better -- for lower training cost over existing architectures. Lastly, we show how to perform symbolic Hamiltonian regression with SympNets for polynomial systems using backward error analysis.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "math.NA",
            "physics.comp-ph"
        ],
        "comment": "33 pages including appendices but not references, 7 figures"
    },
    {
        "paper id": "2408.09825",
        "abstract url": "https://arxiv.org/abs/2408.09825",
        "title": "TDNetGen: Empowering Complex Network Resilience Prediction with Generative Augmentation of Topology and Dynamics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Predicting the resilience of complex networks, which represents the ability to retain fundamental functionality amidst external perturbations or internal failures, plays a critical role in understanding and improving real-world complex systems. Traditional theoretical approaches grounded in nonlinear dynamical systems rely on prior knowledge of network dynamics. On the other hand, data-driven approaches frequently encounter the challenge of insufficient labeled data, a predicament commonly observed in real-world scenarios. In this paper, we introduce a novel resilience prediction framework for complex networks, designed to tackle this issue through generative data augmentation of network topology and dynamics. The core idea is the strategic utilization of the inherent joint distribution present in unlabeled network data, facilitating the learning process of the resilience predictor by illuminating the relationship between network topology and dynamics. Experiment results on three network datasets demonstrate that our proposed framework TDNetGen can achieve high prediction accuracy up to 85%-95%. Furthermore, the framework still demonstrates a pronounced augmentation capability in extreme low-data regimes, thereby underscoring its utility and robustness in enhancing the prediction of network resilience. We have open-sourced our code in the following link, https://github.com/tsinghua-fib-lab/TDNetGen.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09834",
        "abstract url": "https://arxiv.org/abs/2408.09834",
        "title": "Minor DPO reject penalty to increase training robustness",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Learning from human preference is a paradigm used in large-scale language model (LLM) fine-tuning step to better align pretrained LLM to human preference for downstream task. In the past it uses reinforcement learning from human feedback (RLHF) algorithm to optimize the LLM policy to align with these preferences and not to draft too far from the original model. Recently, Direct Preference Optimization (DPO) has been proposed to solve the alignment problem with a simplified RL-free method. Using preference pairs of chosen and reject data, DPO models the relative log probability as implicit reward function and optimize LLM policy using a simple binary cross entropy objective directly. DPO is quite straight forward and easy to be understood. It perform efficiently and well in most cases. In this article, we analyze the working mechanism of $\u03b2$ in DPO, disclose its syntax difference between RL algorithm and DPO, and understand the potential shortage brought by the DPO simplification. With these insights, we propose MinorDPO, which is better aligned to the original RL algorithm, and increase the stability of preference optimization process.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "8 pages, 19 figures"
    },
    {
        "paper id": "2408.09838",
        "abstract url": "https://arxiv.org/abs/2408.09838",
        "title": "Mitigating the Stability-Plasticity Dilemma in Adaptive Train Scheduling with Curriculum-Driven Continual DQN Expansion",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A continual learning agent builds on previous experiences to develop increasingly complex behaviors by adapting to non-stationary and dynamic environments while preserving previously acquired knowledge. However, scaling these systems presents significant challenges, particularly in balancing the preservation of previous policies with the adaptation of new ones to current environments. This balance, known as the stability-plasticity dilemma, is especially pronounced in complex multi-agent domains such as the train scheduling problem, where environmental and agent behaviors are constantly changing, and the search space is vast. In this work, we propose addressing these challenges in the train scheduling problem using curriculum learning. We design a curriculum with adjacent skills that build on each other to improve generalization performance. Introducing a curriculum with distinct tasks introduces non-stationarity, which we address by proposing a new algorithm: Continual Deep Q-Network (DQN) Expansion (CDE). Our approach dynamically generates and adjusts Q-function subspaces to handle environmental changes and task requirements. CDE mitigates catastrophic forgetting through EWC while ensuring high plasticity using adaptive rational activation functions. Experimental results demonstrate significant improvements in learning efficiency and adaptability compared to RL baselines and other adapted methods for continual learning, highlighting the potential of our method in managing the stability-plasticity dilemma in the adaptive train scheduling setting.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "comment": "9 Pages, 2 Figures"
    },
    {
        "paper id": "2408.09841",
        "abstract url": "https://arxiv.org/abs/2408.09841",
        "title": "Demystifying Reinforcement Learning in Production Scheduling via Explainable AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep Reinforcement Learning (DRL) is a frequently employed technique to solve scheduling problems. Although DRL agents ace at delivering viable results in short computing times, their reasoning remains opaque. We conduct a case study where we systematically apply two explainable AI (xAI) frameworks, namely SHAP (DeepSHAP) and Captum (Input x Gradient), to describe the reasoning behind scheduling decisions of a specialized DRL agent in a flow production. We find that methods in the xAI literature lack falsifiability and consistent terminology, do not adequately consider domain-knowledge, the target audience or real-world scenarios, and typically provide simple input-output explanations rather than causal interpretations. To resolve this issue, we introduce a hypotheses-based workflow. This approach enables us to inspect whether explanations align with domain knowledge and match the reward hypotheses of the agent. We furthermore tackle the challenge of communicating these insights to third parties by tailoring hypotheses to the target audience, which can serve as interpretations of the agent's behavior after verification. Our proposed workflow emphasizes the repeated verification of explanations and may be applicable to various DRL-based scheduling use cases.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09882",
        "abstract url": "https://arxiv.org/abs/2408.09882",
        "title": "GINO-Q: Learning an Asymptotically Optimal Index Policy for Restless Multi-armed Bandits",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The restless multi-armed bandit (RMAB) framework is a popular model with applications across a wide variety of fields. However, its solution is hindered by the exponentially growing state space (with respect to the number of arms) and the combinatorial action space, making traditional reinforcement learning methods infeasible for large-scale instances. In this paper, we propose GINO-Q, a three-timescale stochastic approximation algorithm designed to learn an asymptotically optimal index policy for RMABs. GINO-Q mitigates the curse of dimensionality by decomposing the RMAB into a series of subproblems, each with the same dimension as a single arm, ensuring that complexity increases linearly with the number of arms. Unlike recently developed Whittle-index-based algorithms, GINO-Q does not require RMABs to be indexable, enhancing its flexibility and applicability. Our experimental results demonstrate that GINO-Q consistently learns near-optimal policies, even for non-indexable RMABs where Whittle-index-based algorithms perform poorly, and it converges significantly faster than existing baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages, 11 figures"
    },
    {
        "paper id": "2408.09891",
        "abstract url": "https://arxiv.org/abs/2408.09891",
        "title": "Differential Private Stochastic Optimization with Heavy-tailed Data: Towards Optimal Rates",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study convex optimization problems under differential privacy (DP). With heavy-tailed gradients, existing works achieve suboptimal rates. The main obstacle is that existing gradient estimators have suboptimal tail properties, resulting in a superfluous factor of $d$ in the union bound. In this paper, we explore algorithms achieving optimal rates of DP optimization with heavy-tailed gradients. Our first method is a simple clipping approach. Under bounded $p$-th order moments of gradients, with $n$ samples, it achieves $\\tilde{O}(\\sqrt{d/n}+\\sqrt{d}(\\sqrt{d}/n\u03b5)^{1-1/p})$ population risk with $\u03b5\\leq 1/\\sqrt{d}$. We then propose an iterative updating method, which is more complex but achieves this rate for all $\u03b5\\leq 1$. The results significantly improve over existing methods. Such improvement relies on a careful treatment of the tail behavior of gradient estimators. Our results match the minimax lower bound in \\cite{kamath2022improved}, indicating that the theoretical limit of stochastic convex optimization under DP is achievable.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09947",
        "abstract url": "https://arxiv.org/abs/2408.09947",
        "title": "Fiber Transmission Model with Parameterized Inputs based on GPT-PINN Neural Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this manuscript, a novelty principle driven fiber transmission model for short-distance transmission with parameterized inputs is put forward. By taking into the account of the previously proposed principle driven fiber model, the reduced basis expansion method and transforming the parameterized inputs into parameterized coefficients of the Nonlinear Schrodinger Equations, universal solutions with respect to inputs corresponding to different bit rates can all be obtained without the need of re-training the whole model. This model, once adopted, can have prominent advantages in both computation efficiency and physical background. Besides, this model can still be effectively trained without the needs of transmitted signals collected in advance. Tasks of on-off keying signals with bit rates ranging from 2Gbps to 50Gbps are adopted to demonstrate the fidelity of the model.",
        "subjects": [
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09957",
        "abstract url": "https://arxiv.org/abs/2408.09957",
        "title": "Contextual Importance and Utility in Python: New Functionality and Insights with the py-ciu Package",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The availability of easy-to-use and reliable software implementations is important for allowing researchers in academia and industry to test, assess and take into use eXplainable AI (XAI) methods. This paper describes the \\texttt{py-ciu} Python implementation of the Contextual Importance and Utility (CIU) model-agnostic, post-hoc explanation method and illustrates capabilities of CIU that go beyond the current state-of-the-art that could be useful for XAI practitioners in general.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "In Proceedings of XAI 2024 Workshop of 33rd International Joint Conference on Artificial Intelligence (IJCAI 2024), Jeju, South Corea"
    },
    {
        "paper id": "2408.09958",
        "abstract url": "https://arxiv.org/abs/2408.09958",
        "title": "AdaResNet: Enhancing Residual Networks with Dynamic Weight Adjustment for Improved Feature Integration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In very deep neural networks, gradients can become extremely small during backpropagation, making it challenging to train the early layers. ResNet (Residual Network) addresses this issue by enabling gradients to flow directly through the network via skip connections, facilitating the training of much deeper networks. However, in these skip connections, the input ipd is directly added to the transformed data tfd, treating ipd and tfd equally, without adapting to different scenarios. In this paper, we propose AdaResNet (Auto-Adapting Residual Network), which automatically adjusts the ratio between ipd and tfd based on the training data. We introduce a variable, weight}_{tfd}^{ipd, to represent this ratio. This variable is dynamically adjusted during backpropagation, allowing it to adapt to the training data rather than remaining fixed. Experimental results demonstrate that AdaResNet achieves a maximum accuracy improvement of over 50\\% compared to traditional ResNet.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09966",
        "abstract url": "https://arxiv.org/abs/2408.09966",
        "title": "Mask in the Mirror: Implicit Sparsification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sparsifying deep neural networks to reduce their inference cost is an NP-hard problem and difficult to optimize due to its mixed discrete and continuous nature. Yet, as we prove, continuous sparsification has already an implicit bias towards sparsity that would not require common projections of relaxed mask variables. While implicit rather than explicit regularization induces benefits, it usually does not provide enough flexibility in practice, as only a specific target sparsity is obtainable. To exploit its potential for continuous sparsification, we propose a way to control the strength of the implicit bias. Based on the mirror flow framework, we derive resulting convergence and optimality guarantees in the context of underdetermined linear regression and demonstrate the utility of our insights in more general neural network sparsification experiments, achieving significant performance gains, particularly in the high-sparsity regime. Our theoretical contribution might be of independent interest, as we highlight a way to enter the rich regime and show that implicit bias is controllable by a time-dependent Bregman potential.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "20 pages, 5 figures"
    },
    {
        "paper id": "2408.09967",
        "abstract url": "https://arxiv.org/abs/2408.09967",
        "title": "Unsupervised Machine Learning Hybrid Approach Integrating Linear Programming in Loss Function: A Robust Optimization Technique",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a novel hybrid approach that integrates linear programming (LP) within the loss function of an unsupervised machine learning model. By leveraging the strengths of both optimization techniques and machine learning, this method introduces a robust framework for solving complex optimization problems where traditional methods may fall short. The proposed approach encapsulates the constraints and objectives of a linear programming problem directly into the loss function, guiding the learning process to adhere to these constraints while optimizing the desired outcomes. This technique not only preserves the interpretability of linear programming but also benefits from the flexibility and adaptability of machine learning, making it particularly well-suited for unsupervised or semi-supervised learning scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09974",
        "abstract url": "https://arxiv.org/abs/2408.09974",
        "title": "The Exploration-Exploitation Dilemma Revisited: An Entropy Perspective",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The imbalance of exploration and exploitation has long been a significant challenge in reinforcement learning. In policy optimization, excessive reliance on exploration reduces learning efficiency, while over-dependence on exploitation might trap agents in local optima. This paper revisits the exploration-exploitation dilemma from the perspective of entropy by revealing the relationship between entropy and the dynamic adaptive process of exploration and exploitation. Based on this theoretical insight, we establish an end-to-end adaptive framework called AdaZero, which automatically determines whether to explore or to exploit as well as their balance of strength. Experiments show that AdaZero significantly outperforms baseline models across various Atari and MuJoCo environments with only a single setting. Especially in the challenging environment of Montezuma, AdaZero boosts the final returns by up to fifteen times. Moreover, we conduct a series of visualization analyses to reveal the dynamics of our self-adaptive mechanism, demonstrating how entropy reflects and changes with respect to the agent's performance and adaptive process.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09976",
        "abstract url": "https://arxiv.org/abs/2408.09976",
        "title": "Preference-Optimized Pareto Set Learning for Blackbox Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multi-Objective Optimization (MOO) is an important problem in real-world applications. However, for a non-trivial problem, no single solution exists that can optimize all the objectives simultaneously. In a typical MOO problem, the goal is to find a set of optimum solutions (Pareto set) that trades off the preferences among objectives. Scalarization in MOO is a well-established method for finding a finite set approximation of the whole Pareto set (PS). However, in real-world experimental design scenarios, it's beneficial to obtain the whole PS for flexible exploration of the design space. Recently Pareto set learning (PSL) has been introduced to approximate the whole PS. PSL involves creating a manifold representing the Pareto front of a multi-objective optimization problem. A naive approach includes finding discrete points on the Pareto front through randomly generated preference vectors and connecting them by regression. However, this approach is computationally expensive and leads to a poor PS approximation. We propose to optimize the preference points to be distributed evenly on the Pareto front. Our formulation leads to a bilevel optimization problem that can be solved by e.g. differentiable cross-entropy methods. We demonstrated the efficacy of our method for complex and difficult black-box MOO problems using both synthetic and real-world benchmark data.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09982",
        "abstract url": "https://arxiv.org/abs/2408.09982",
        "title": "Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This study delves into the application potential of the large language models (LLMs) ChatGLM in the automatic generation of structured questions for National Teacher Certification Exams (NTCE). Through meticulously designed prompt engineering, we guided ChatGLM to generate a series of simulated questions and conducted a comprehensive comparison with questions recollected from past examinees. To ensure the objectivity and professionalism of the evaluation, we invited experts in the field of education to assess these questions and their scoring criteria. The research results indicate that the questions generated by ChatGLM exhibit a high level of rationality, scientificity, and practicality similar to those of the real exam questions across most evaluation criteria, demonstrating the model's accuracy and reliability in question generation. Nevertheless, the study also reveals limitations in the model's consideration of various rating criteria when generating questions, suggesting the need for further optimization and adjustment. This research not only validates the application potential of ChatGLM in the field of educational assessment but also provides crucial empirical support for the development of more efficient and intelligent educational automated generation systems in the future.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09995",
        "abstract url": "https://arxiv.org/abs/2408.09995",
        "title": "Uniting contrastive and generative learning for event sequences models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "High-quality representation of transactional sequences is vital for modern banking applications, including risk management, churn prediction, and personalized customer offers. Different tasks require distinct representation properties: local tasks benefit from capturing the client's current state, while global tasks rely on general behavioral patterns. Previous research has demonstrated that various self-supervised approaches yield representations that better capture either global or local qualities. This study investigates the integration of two self-supervised learning techniques - instance-wise contrastive learning and a generative approach based on restoring masked events in latent space. The combined approach creates representations that balance local and global transactional data characteristics. Experiments conducted on several public datasets, focusing on sequence classification and next-event type prediction, show that the integrated method achieves superior performance compared to individual approaches and demonstrates synergistic effects. These findings suggest that the proposed approach offers a robust framework for advancing event sequences representation learning in the financial sector.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10002",
        "abstract url": "https://arxiv.org/abs/2408.10002",
        "title": "The Fairness-Quality Trade-off in Clustering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Fairness in clustering has been considered extensively in the past; however, the trade-off between the two objectives -- e.g., can we sacrifice just a little in the quality of the clustering to significantly increase fairness, or vice-versa? -- has rarely been addressed. We introduce novel algorithms for tracing the complete trade-off curve, or Pareto front, between quality and fairness in clustering problems; that is, computing all clusterings that are not dominated in both objectives by other clusterings. Unlike previous work that deals with specific objectives for quality and fairness, we deal with all objectives for fairness and quality in two general classes encompassing most of the special cases addressed in previous work. Our algorithm must take exponential time in the worst case as the Pareto front itself can be exponential. Even when the Pareto front is polynomial, our algorithm may take exponential time, and we prove that this is inevitable unless P = NP. However, we also present a new polynomial-time algorithm for computing the entire Pareto front when the cluster centers are fixed, and for perhaps the most natural fairness objective: minimizing the sum, over all clusters, of the imbalance between the two groups in each cluster.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10040",
        "abstract url": "https://arxiv.org/abs/2408.10040",
        "title": "The Practimum-Optimum Algorithm for Manufacturing Scheduling: A Paradigm Shift Leading to Breakthroughs in Scale and Performance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The Practimum-Optimum (P-O) algorithm represents a paradigm shift in developing automatic optimization products for complex real-life business problems such as large-scale manufacturing scheduling. It leverages deep business domain expertise to create a group of virtual human expert (VHE) agents with different \"schools of thought\" on how to create high-quality schedules. By computerizing them into algorithms, P-O generates many valid schedules at far higher speeds than human schedulers are capable of. Initially, these schedules can also be local optimum peaks far away from high-quality schedules. By submitting these schedules to a reinforced machine learning algorithm (RL), P-O learns the weaknesses and strengths of each VHE schedule, and accordingly derives reward and punishment changes in the Demand Set that will modify the relative priorities for time and resource allocation that jobs received in the prior iteration that led to the current state of the schedule. These cause the core logic of the VHE algorithms to explore, in the subsequent iteration, substantially different parts of the schedules universe and potentially find higher-quality schedules. Using the hill climbing analogy, this may be viewed as a big jump, shifting from a given local peak to a faraway promising start point equipped with knowledge embedded in the demand set for future iterations. This is a fundamental difference from most contemporary algorithms, which spend considerable time on local micro-steps restricted to the neighbourhoods of local peaks they visit. This difference enables a breakthrough in scale and performance for fully automatic manufacturing scheduling in complex organizations. The P-O algorithm is at the heart of Plataine Scheduler that, in one click, routinely schedules 30,000-50,000 tasks for real-life complex manufacturing operations.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10055",
        "abstract url": "https://arxiv.org/abs/2408.10055",
        "title": "Efficient Exploration in Deep Reinforcement Learning: A Novel Bayesian Actor-Critic Algorithm",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning (RL) and Deep Reinforcement Learning (DRL), in particular, have the potential to disrupt and are already changing the way we interact with the world. One of the key indicators of their applicability is their ability to scale and work in real-world scenarios, that is in large-scale problems. This scale can be achieved via a combination of factors, the algorithm's ability to make use of large amounts of data and computational resources and the efficient exploration of the environment for viable solutions (i.e. policies). In this work, we investigate and motivate some theoretical foundations for deep reinforcement learning. We start with exact dynamic programming and work our way up to stochastic approximations and stochastic approximations for a model-free scenario, which forms the theoretical basis of modern reinforcement learning. We present an overview of this highly varied and rapidly changing field from the perspective of Approximate Dynamic Programming. We then focus our study on the short-comings with respect to exploration of the cornerstone approaches (i.e. DQN, DDQN, A2C) in deep reinforcement learning. On the theory side, our main contribution is the proposal of a novel Bayesian actor-critic algorithm. On the empirical side, we evaluate Bayesian exploration as well as actor-critic algorithms on standard benchmarks as well as state-of-the-art evaluation suites and show the benefits of both of these approaches over current state-of-the-art deep RL methods. We release all the implementations and provide a full python library that is easy to install and hopefully will serve the reinforcement learning community in a meaningful way, and provide a strong foundation for future work.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "74 pages, MRes Thesis in Computer Science, UCL"
    },
    {
        "paper id": "2408.10074",
        "abstract url": "https://arxiv.org/abs/2408.10074",
        "title": "Synthesis of Reward Machines for Multi-Agent Equilibrium Design (Full Version)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Mechanism design is a well-established game-theoretic paradigm for designing games to achieve desired outcomes. This paper addresses a closely related but distinct concept, equilibrium design. Unlike mechanism design, the designer's authority in equilibrium design is more constrained; she can only modify the incentive structures in a given game to achieve certain outcomes without the ability to create the game from scratch. We study the problem of equilibrium design using dynamic incentive structures, known as reward machines. We use weighted concurrent game structures for the game model, with goals (for the players and the designer) defined as mean-payoff objectives. We show how reward machines can be used to represent dynamic incentives that allocate rewards in a manner that optimises the designer's goal. We also introduce the main decision problem within our framework, the payoff improvement problem. This problem essentially asks whether there exists a dynamic incentive (represented by some reward machine) that can improve the designer's payoff by more than a given threshold value. We present two variants of the problem: strong and weak. We demonstrate that both can be solved in polynomial time using a Turing machine equipped with an NP oracle. Furthermore, we also establish that these variants are either NP-hard or coNP-hard. Finally, we show how to synthesise the corresponding reward machine if it exists.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10077",
        "abstract url": "https://arxiv.org/abs/2408.10077",
        "title": "No Screening is More Efficient with Multiple Objects",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We study efficient mechanism design for allocating multiple heterogeneous objects. We aim to maximize the residual surplus, the total value generated from an allocation minus the costs for screening agents' values. We discover a robust trend indicating that no-screening mechanisms such as serial dictatorship with exogenous priority order tend to perform better as the variety of goods increases. We analyze the underlying reasons by characterizing efficient mechanisms in a stylized environment. We also apply an automated mechanism design approach to numerically derive efficient mechanisms and validate the trend in general environments. Building on this implication, we propose the register-invite-book system (RIB) as an efficient system for scheduling vaccination against pandemic diseases.",
        "subjects": [
            "econ.TH",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10085",
        "abstract url": "https://arxiv.org/abs/2408.10085",
        "title": "MASALA: Model-Agnostic Surrogate Explanations by Locality Adaptation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Existing local Explainable AI (XAI) methods, such as LIME, select a region of the input space in the vicinity of a given input instance, for which they approximate the behaviour of a model using a simpler and more interpretable surrogate model. The size of this region is often controlled by a user-defined locality hyperparameter. In this paper, we demonstrate the difficulties associated with defining a suitable locality size to capture impactful model behaviour, as well as the inadequacy of using a single locality size to explain all predictions. We propose a novel method, MASALA, for generating explanations, which automatically determines the appropriate local region of impactful model behaviour for each individual instance being explained. MASALA approximates the local behaviour used by a complex model to make a prediction by fitting a linear surrogate model to a set of points which experience similar model behaviour. These points are found by clustering the input space into regions of linear behavioural trends exhibited by the model. We compare the fidelity and consistency of explanations generated by our method with existing local XAI methods, namely LIME and CHILLI. Experiments on the PHM08 and MIDAS datasets show that our method produces more faithful and consistent explanations than existing methods, without the need to define any sensitive locality hyperparameters.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10086",
        "abstract url": "https://arxiv.org/abs/2408.10086",
        "title": "ARMADA: Attribute-Based Multimodal Data Augmentation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In Multimodal Language Models (MLMs), the cost of manually annotating high-quality image-text pair data for fine-tuning and alignment is extremely high. While existing multimodal data augmentation frameworks propose ways to augment image-text pairs, they either suffer from semantic inconsistency between texts and images, or generate unrealistic images, causing knowledge gap with real world examples. To address these issues, we propose Attribute-based Multimodal Data Augmentation (ARMADA), a novel multimodal data augmentation method via knowledge-guided manipulation of visual attributes of the mentioned entities. Specifically, we extract entities and their visual attributes from the original text data, then search for alternative values for the visual attributes under the guidance of knowledge bases (KBs) and large language models (LLMs). We then utilize an image-editing model to edit the images with the extracted attributes. ARMADA is a novel multimodal data generation framework that: (i) extracts knowledge-grounded attributes from symbolic KBs for semantically consistent yet distinctive image-text pair generation, (ii) generates visually similar images of disparate categories using neighboring entities in the KB hierarchy, and (iii) uses the commonsense knowledge of LLMs to modulate auxiliary visual attributes such as backgrounds for more robust representation of original entities. Our empirical results over four downstream tasks demonstrate the efficacy of our framework to produce high-quality data and enhance the model performance. This also highlights the need to leverage external knowledge proxies for enhanced interpretability and real-world grounding.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10107",
        "abstract url": "https://arxiv.org/abs/2408.10107",
        "title": "Perturb-and-Compare Approach for Detecting Out-of-Distribution Samples in Constrained Access Environments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Accessing machine learning models through remote APIs has been gaining prevalence following the recent trend of scaling up model parameters for increased performance. Even though these models exhibit remarkable ability, detecting out-of-distribution (OOD) samples remains a crucial safety concern for end users as these samples may induce unreliable outputs from the model. In this work, we propose an OOD detection framework, MixDiff, that is applicable even when the model's parameters or its activations are not accessible to the end user. To bypass the access restriction, MixDiff applies an identical input-level perturbation to a given target sample and a similar in-distribution (ID) sample, then compares the relative difference in the model outputs of these two samples. MixDiff is model-agnostic and compatible with existing output-based OOD detection methods. We provide theoretical analysis to illustrate MixDiff's effectiveness in discerning OOD samples that induce overconfident outputs from the model and empirically demonstrate that MixDiff consistently enhances the OOD detection performance on various datasets in vision and text domains.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "Accepted to European Conference on Artificial Intelligence (ECAI) 2024"
    },
    {
        "paper id": "2408.10111",
        "abstract url": "https://arxiv.org/abs/2408.10111",
        "title": "PLUTUS: A Well Pre-trained Large Unified Transformer can Unveil Financial Time Series Regularities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Financial time series modeling is crucial for understanding and predicting market behaviors but faces challenges such as non-linearity, non-stationarity, and high noise levels. Traditional models struggle to capture complex patterns due to these issues, compounded by limitations in computational resources and model capacity. Inspired by the success of large language models in NLP, we introduce $\\textbf{PLUTUS}$, a $\\textbf{P}$re-trained $\\textbf{L}$arge $\\textbf{U}$nified $\\textbf{T}$ransformer-based model that $\\textbf{U}$nveils regularities in financial time $\\textbf{S}$eries. PLUTUS uses an invertible embedding module with contrastive learning and autoencoder techniques to create an approximate one-to-one mapping between raw data and patch embeddings. TimeFormer, an attention based architecture, forms the core of PLUTUS, effectively modeling high-noise time series. We incorporate a novel attention mechanisms to capture features across both variable and temporal dimensions. PLUTUS is pre-trained on an unprecedented dataset of 100 billion observations, designed to thrive in noisy financial environments. To our knowledge, PLUTUS is the first open-source, large-scale, pre-trained financial time series model with over one billion parameters. It achieves state-of-the-art performance in various tasks, demonstrating strong transferability and establishing a robust foundational model for finance. Our research provides technical guidance for pre-training financial time series data, setting a new standard in the field.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10113",
        "abstract url": "https://arxiv.org/abs/2408.10113",
        "title": "Enhancing Reinforcement Learning Through Guided Search",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the aim of improving performance in Markov Decision Problem in an Off-Policy setting, we suggest taking inspiration from what is done in Offline Reinforcement Learning (RL). In Offline RL, it is a common practice during policy learning to maintain proximity to a reference policy to mitigate uncertainty, reduce potential policy errors, and help improve performance. We find ourselves in a different setting, yet it raises questions about whether a similar concept can be applied to enhance performance ie, whether it is possible to find a guiding policy capable of contributing to performance improvement, and how to incorporate it into our RL agent. Our attention is particularly focused on algorithms based on Monte Carlo Tree Search (MCTS) as a guide.MCTS renowned for its state-of-the-art capabilities across various domains, catches our interest due to its ability to converge to equilibrium in single-player and two-player contexts. By harnessing the power of MCTS as a guide for our RL agent, we observed a significant performance improvement, surpassing the outcomes achieved by utilizing each method in isolation. Our experiments were carried out on the Atari 100k benchmark.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted Paper at ECAI 2024; Extended Version"
    },
    {
        "paper id": "2408.10126",
        "abstract url": "https://arxiv.org/abs/2408.10126",
        "title": "Learning Brave Assumption-Based Argumentation Frameworks via ASP",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Assumption-based Argumentation (ABA) is advocated as a unifying formalism for various forms of non-monotonic reasoning, including logic programming. It allows capturing defeasible knowledge, subject to argumentative debate. While, in much existing work, ABA frameworks are given up-front, in this paper we focus on the problem of automating their learning from background knowledge and positive/negative examples. Unlike prior work, we newly frame the problem in terms of brave reasoning under stable extensions for ABA. We present a novel algorithm based on transformation rules (such as Rote Learning, Folding, Assumption Introduction and Fact Subsumption) and an implementation thereof that makes use of Answer Set Programming. Finally, we compare our technique to state-of-the-art ILP systems that learn defeasible knowledge.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.LO"
        ],
        "comment": "Extended version of the paper accepted at the 27th European Conference on Artificial Intelligence (ECAI 2024); Paper ID: M1488 (https://www.ecai2024.eu/)"
    },
    {
        "paper id": "2408.10174",
        "abstract url": "https://arxiv.org/abs/2408.10174",
        "title": "SMILE: Zero-Shot Sparse Mixture of Low-Rank Experts Construction From Pre-Trained Foundation Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep model training on extensive datasets is increasingly becoming cost-prohibitive, prompting the widespread adoption of deep model fusion techniques to leverage knowledge from pre-existing models. From simple weight averaging to more sophisticated methods like AdaMerging, model fusion effectively improves model performance and accelerates the development of new models. However, potential interference between parameters of individual models and the lack of interpretability in the fusion progress remain significant challenges. Existing methods often try to resolve the parameter interference issue by evaluating attributes of parameters, such as their magnitude or sign, or by parameter pruning. In this study, we begin by examining the fine-tuning of linear layers through the lens of subspace analysis and explicitly define parameter interference as an optimization problem to shed light on this subject. Subsequently, we introduce an innovative approach to model fusion called zero-shot Sparse MIxture of Low-rank Experts (SMILE) construction, which allows for the upscaling of source models into an MoE model without extra data or further training. Our approach relies on the observation that fine-tuning mostly keeps the important parts from the pre-training, but it uses less significant or unused areas to adapt to new tasks. Also, the issue of parameter interference, which is intrinsically intractable in the original parameter space, can be managed by expanding the dimensions. We conduct extensive experiments across diverse scenarios, such as image classification and text generalization tasks, using full fine-tuning and LoRA fine-tuning, and we apply our method to large language models (CLIP models, Flan-T5 models, and Mistral-7B models), highlighting the adaptability and scalability of SMILE. Code is available at https://github.com/tanganke/fusion_bench",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Code is available at https://github.com/tanganke/fusion_bench"
    },
    {
        "paper id": "2408.10189",
        "abstract url": "https://arxiv.org/abs/2408.10189",
        "title": "Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Transformer architectures have become a dominant paradigm for domains like language modeling but suffer in many inference settings due to their quadratic-time self-attention. Recently proposed subquadratic architectures, such as Mamba, have shown promise, but have been pretrained with substantially less computational resources than the strongest Transformer models. In this work, we present a method that is able to distill a pretrained Transformer architecture into alternative architectures such as state space models (SSMs). The key idea to our approach is that we can view both Transformers and SSMs as applying different forms of mixing matrices over the token sequences. We can thus progressively distill the Transformer architecture by matching different degrees of granularity in the SSM: first matching the mixing matrices themselves, then the hidden units at each block, and finally the end-to-end predictions. Our method, called MOHAWK, is able to distill a Mamba-2 variant based on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid version (Hybrid Phi-Mamba) using 5B tokens. Despite using less than 1% of the training data typically used to train models from scratch, Phi-Mamba boasts substantially stronger performance compared to all past open-source non-Transformer models. MOHAWK allows models like SSMs to leverage computational resources invested in training Transformer-based architectures, highlighting a new avenue for building such models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10193",
        "abstract url": "https://arxiv.org/abs/2408.10193",
        "title": "Area under the ROC Curve has the Most Consistent Evaluation for Binary Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Evaluation Metrics is an important question for model evaluation and model selection in binary classification tasks. This study investigates how consistent metrics are at evaluating different models under different data scenarios. Analyzing over 150 data scenarios and 18 model evaluation metrics using statistical simulation, I find that for binary classification tasks, evaluation metrics that are less influenced by prevalence offer more consistent ranking of a set of different models. In particular, Area Under the ROC Curve (AUC) has smallest variance in ranking of different models. Matthew's correlation coefficient as a more strict measure of model performance has the second smallest variance. These patterns holds across a rich set of data scenarios and five commonly used machine learning models as well as a naive random guess model. The results have significant implications for model evaluation and model selection in binary classification tasks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10197",
        "abstract url": "https://arxiv.org/abs/2408.10197",
        "title": "Demystifying the Communication Characteristics for Distributed Transformer Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep learning (DL) models based on the transformer architecture have revolutionized many DL applications such as large language models (LLMs), vision transformers, audio generation, and time series prediction. Much of this progress has been fueled by distributed training, yet distributed communication remains a substantial bottleneck to training progress. This paper examines the communication behavior of transformer models - that is, how different parallelism schemes used in multi-node/multi-GPU DL Training communicate data in the context of transformers. We use GPT-based language models as a case study of the transformer architecture due to their ubiquity. We validate the empirical results obtained from our communication logs using analytical models. At a high level, our analysis reveals a need to optimize small message point-to-point communication further, correlations between sequence length, per-GPU throughput, model size, and optimizations used, and where to potentially guide further optimizations in framework and HPC middleware design and optimization.",
        "subjects": [
            "cs.DC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10288",
        "abstract url": "https://arxiv.org/abs/2408.10288",
        "title": "Augmenting train maintenance technicians with automated incident diagnostic suggestions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Train operational incidents are so far diagnosed individually and manually by train maintenance technicians. In order to assist maintenance crews in their responsiveness and task prioritization, a learning machine is developed and deployed in production to suggest diagnostics to train technicians on their phones, tablets or laptops as soon as a train incident is declared. A feedback loop allows to take into account the actual diagnose by designated train maintenance experts to refine the learning machine. By formulating the problem as a discrete set classification task, feature engineering methods are proposed to extract physically plausible sets of events from traces generated on-board railway vehicles. The latter feed an original ensemble classifier to class incidents by their potential technical cause. Finally, the resulting model is trained and validated using real operational data and deployed on a cloud platform. Future work will explore how the extracted sets of events can be used to avoid incidents by assisting human experts in the creation predictive maintenance alerts.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10291",
        "abstract url": "https://arxiv.org/abs/2408.10291",
        "title": "Chatbots and Zero Sales Resistance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "It is argued that the pursuit of an ever increasing number of weights in large-scale machine learning applications, besides being energetically unsustainable, is also conducive to manipulative strategies whereby Science is easily served as a strawman for economic and financial power. If machine learning is meant to serve science ahead of vested business interests, a paradigm shift is needed: from more weights and little insight to more insight and less weights.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2408.10292",
        "abstract url": "https://arxiv.org/abs/2408.10292",
        "title": "Leveraging Superfluous Information in Contrastive Representation Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Contrastive representation learning, which aims to learnthe shared information between different views of unlabeled data by maximizing the mutual information between them, has shown its powerful competence in self-supervised learning for downstream tasks. However, recent works have demonstrated that more estimated mutual information does not guarantee better performance in different downstream tasks. Such works inspire us to conjecture that the learned representations not only maintain task-relevant information from unlabeled data but also carry task-irrelevant information which is superfluous for downstream tasks, thus leading to performance degeneration. In this paper we show that superfluous information does exist during the conventional contrastive learning framework, and further design a new objective, namely SuperInfo, to learn robust representations by a linear combination of both predictive and superfluous information. Besides, we notice that it is feasible to tune the coefficients of introduced losses to discard task-irrelevant information, while keeping partial non-shared task-relevant information according to our SuperInfo loss.We demonstrate that learning with our loss can often outperform the traditional contrastive learning approaches on image classification, object detection and instance segmentation tasks with significant improvements.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10332",
        "abstract url": "https://arxiv.org/abs/2408.10332",
        "title": "Spectral Guarantees for Adversarial Streaming PCA",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In streaming PCA, we see a stream of vectors $x_1, \\dotsc, x_n \\in \\mathbb{R}^d$ and want to estimate the top eigenvector of their covariance matrix. This is easier if the spectral ratio $R = \u03bb_1 / \u03bb_2$ is large. We ask: how large does $R$ need to be to solve streaming PCA in $\\widetilde{O}(d)$ space? Existing algorithms require $R = \\widetilde\u03a9(d)$. We show: (1) For all mergeable summaries, $R = \\widetilde\u03a9(\\sqrt{d})$ is necessary. (2) In the insertion-only model, a variant of Oja's algorithm gets $o(1)$ error for $R = O(\\log n \\log d)$. (3) No algorithm with $o(d^2)$ space gets $o(1)$ error for $R = O(1)$. Our analysis is the first application of Oja's algorithm to adversarial streams. It is also the first algorithm for adversarial streaming PCA that is designed for a spectral, rather than Frobenius, bound on the tail; and the bound it needs is exponentially better than is possible by adapting a Frobenius guarantee.",
        "subjects": [
            "cs.DS",
            "cs.LG"
        ],
        "comment": "FOCS 2024"
    },
    {
        "paper id": "2408.10340",
        "abstract url": "https://arxiv.org/abs/2408.10340",
        "title": "Can an unsupervised clustering algorithm reproduce a categorization system?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Peer analysis is a critical component of investment management, often relying on expert-provided categorization systems. These systems' consistency is questioned when they do not align with cohorts from unsupervised clustering algorithms optimized for various metrics. We investigate whether unsupervised clustering can reproduce ground truth classes in a labeled dataset, showing that success depends on feature selection and the chosen distance metric. Using toy datasets and fund categorization as real-world examples we demonstrate that accurately reproducing ground truth classes is challenging. We also highlight the limitations of standard clustering evaluation metrics in identifying the optimal number of clusters relative to the ground truth classes. We then show that if appropriate features are available in the dataset, and a proper distance metric is known (e.g., using a supervised Random Forest-based distance metric learning method), then an unsupervised clustering can indeed reproduce the ground truth classes as distinct clusters.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "q-fin.ST",
            "stat.AP"
        ],
        "comment": "9 pages, 4 tables 28 figures"
    },
    {
        "paper id": "2408.10343",
        "abstract url": "https://arxiv.org/abs/2408.10343",
        "title": "LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Retrieval-Augmented Generation (RAG) systems are showing promising potential, and are becoming increasingly relevant in AI-powered legal applications. Existing benchmarks, such as LegalBench, assess the generative capabilities of Large Language Models (LLMs) in the legal domain, but there is a critical gap in evaluating the retrieval component of RAG systems. To address this, we introduce LegalBench-RAG, the first benchmark specifically designed to evaluate the retrieval step of RAG pipelines within the legal space. LegalBench-RAG emphasizes precise retrieval by focusing on extracting minimal, highly relevant text segments from legal documents. These highly relevant snippets are preferred over retrieving document IDs, or large sequences of imprecise chunks, both of which can exceed context window limitations. Long context windows cost more to process, induce higher latency, and lead LLMs to forget or hallucinate information. Additionally, precise results allow LLMs to generate citations for the end user. The LegalBench-RAG benchmark is constructed by retracing the context used in LegalBench queries back to their original locations within the legal corpus, resulting in a dataset of 6,858 query-answer pairs over a corpus of over 79M characters, entirely human-annotated by legal experts. We also introduce LegalBench-RAG-mini, a lightweight version for rapid iteration and experimentation. By providing a dedicated benchmark for legal retrieval, LegalBench-RAG serves as a critical tool for companies and researchers focused on enhancing the accuracy and performance of RAG systems in the legal domain. The LegalBench-RAG dataset is publicly available at https://github.com/zeroentropy-cc/legalbenchrag.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10359",
        "abstract url": "https://arxiv.org/abs/2408.10359",
        "title": "How Small is Big Enough? Open Labeled Datasets and the Development of Deep Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "We investigate the emergence of Deep Learning as a technoscientific field, emphasizing the role of open labeled datasets. Through qualitative and quantitative analyses, we evaluate the role of datasets like CIFAR-10 in advancing computer vision and object recognition, which are central to the Deep Learning revolution. Our findings highlight CIFAR-10's crucial role and enduring influence on the field, as well as its importance in teaching ML techniques. Results also indicate that dataset characteristics such as size, number of instances, and number of categories, were key factors. Econometric analysis confirms that CIFAR-10, a small-but-sufficiently-large open dataset, played a significant and lasting role in technological advancements and had a major function in the development of the early scientific literature as shown by citation metrics.",
        "subjects": [
            "econ.GN",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10365",
        "abstract url": "https://arxiv.org/abs/2408.10365",
        "title": "AI-Driven Review Systems: Evaluating LLMs in Scalable and Bias-Aware Academic Reviews",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Automatic reviewing helps handle a large volume of papers, provides early feedback and quality control, reduces bias, and allows the analysis of trends. We evaluate the alignment of automatic paper reviews with human reviews using an arena of human preferences by pairwise comparisons. Gathering human preference may be time-consuming; therefore, we also use an LLM to automatically evaluate reviews to increase sample efficiency while reducing bias. In addition to evaluating human and LLM preferences among LLM reviews, we fine-tune an LLM to predict human preferences, predicting which reviews humans will prefer in a head-to-head battle between LLMs. We artificially introduce errors into papers and analyze the LLM's responses to identify limitations, use adaptive review questions, meta prompting, role-playing, integrate visual and textual analysis, use venue-specific reviewing materials, and predict human preferences, improving upon the limitations of the traditional review processes. We make the reviews of publicly available arXiv and open-access Nature journal papers available online, along with a free service which helps authors review and revise their research papers and improve their quality. This work develops proof-of-concept LLM reviewing systems that quickly deliver consistent, high-quality reviews and evaluate their quality. We mitigate the risks of misuse, inflated review scores, overconfident ratings, and skewed score distributions by augmenting the LLM with multiple documents, including the review form, reviewer guide, code of ethics and conduct, area chair guidelines, and previous year statistics, by finding which errors and shortcomings of the paper may be detected by automated reviews, and evaluating pairwise reviewer preferences. This work identifies and addresses the limitations of using LLMs as reviewers and evaluators and enhances the quality of the reviewing process.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "42 pages"
    },
    {
        "paper id": "2408.10368",
        "abstract url": "https://arxiv.org/abs/2408.10368",
        "title": "Deep-MacroFin: Informed Equilibrium Neural Network for Continuous Time Economic Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present Deep-MacroFin, a comprehensive framework designed to solve partial differential equations, with a particular focus on models in continuous time economics. This framework leverages deep learning methodologies, including conventional Multi-Layer Perceptrons and the newly developed Kolmogorov-Arnold Networks. It is optimized using economic information encapsulated by Hamilton-Jacobi-Bellman equations and coupled algebraic equations. The application of neural networks holds the promise of accurately resolving high-dimensional problems with fewer computational demands and limitations compared to standard numerical methods. This versatile framework can be readily adapted for elementary differential equations, and systems of differential equations, even in cases where the solutions may exhibit discontinuities. Importantly, it offers a more straightforward and user-friendly implementation than existing libraries.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "q-fin.CP"
        ],
        "comment": "25 pages, 8 figures"
    },
    {
        "paper id": "2408.10369",
        "abstract url": "https://arxiv.org/abs/2408.10369",
        "title": "Boolean Matrix Logic Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We describe a datalog query evaluation approach based on efficient and composable boolean matrix manipulation modules. We first define an overarching problem, Boolean Matrix Logic Programming (BMLP), which uses boolean matrices as an alternative computation to evaluate datalog programs. We develop two novel BMLP modules for bottom-up inferences on linear dyadic recursive datalog programs, and show how additional modules can extend this capability to compute both linear and non-linear recursive datalog programs of arity two. Our empirical results demonstrate that these modules outperform general-purpose and specialised systems by factors of 30x and 9x, respectively, when evaluating large programs with millions of facts. This boolean matrix approach significantly enhances the efficiency of datalog querying to support logic programming techniques.",
        "subjects": [
            "cs.SC",
            "cs.AI",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10395",
        "abstract url": "https://arxiv.org/abs/2408.10395",
        "title": "Evaluating Image-Based Face and Eye Tracking with Event Cameras",
        "rating": "0.5",
        "keywords": [
            [
                "Event Cameras"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Event Cameras, also known as Neuromorphic sensors, capture changes in local light intensity at the pixel level, producing asynchronously generated data termed ``events''. This distinct data format mitigates common issues observed in conventional cameras, like under-sampling when capturing fast-moving objects, thereby preserving critical information that might otherwise be lost. However, leveraging this data often necessitates the development of specialized, handcrafted event representations that can integrate seamlessly with conventional Convolutional Neural Networks (CNNs), considering the unique attributes of event data. In this study, We evaluate event-based Face and Eye tracking. The core objective of our study is to showcase the viability of integrating conventional algorithms with event-based data, transformed into a frame format while preserving the unique benefits of event cameras. To validate our approach, we constructed a frame-based event dataset by simulating events between RGB frames derived from the publicly accessible Helen Dataset. We assess its utility for face and eye detection tasks through the application of GR-YOLO -- a pioneering technique derived from YOLOv3. This evaluation includes a comparative analysis with results derived from training the dataset with YOLOv8. Subsequently, the trained models were tested on real event streams from various iterations of Prophesee's event cameras and further evaluated on the Faces in Event Stream (FES) benchmark dataset. The models trained on our dataset shows a good prediction performance across all the datasets obtained for validation with the best results of a mean Average precision score of 0.91. Additionally, The models trained demonstrated robust performance on real event camera data under varying light conditions.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "This paper has been accepted at The Workshop On Neuromorphic Vision: Advantages and Applications of Event Cameras at the European Conference on Computer Vision (ECCV), 2024"
    },
    {
        "paper id": "2408.10419",
        "abstract url": "https://arxiv.org/abs/2408.10419",
        "title": "Second-Order Forward-Mode Automatic Differentiation for Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces a second-order hyperplane search, a novel optimization step that generalizes a second-order line search from a line to a $k$-dimensional hyperplane. This, combined with the forward-mode stochastic gradient method, yields a second-order optimization algorithm that consists of forward passes only, completely avoiding the storage overhead of backpropagation. Unlike recent work that relies on directional derivatives (or Jacobian--Vector Products, JVPs), we use hyper-dual numbers to jointly evaluate both directional derivatives and their second-order quadratic terms. As a result, we introduce forward-mode weight perturbation with Hessian information (FoMoH). We then use FoMoH to develop a novel generalization of line search by extending it to a hyperplane search. We illustrate the utility of this extension and how it might be used to overcome some of the recent challenges of optimizing machine learning models without backpropagation. Our code is open-sourced at https://github.com/SRI-CSL/fomoh.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "14 pages, 8 figures"
    },
    {
        "paper id": "2408.10428",
        "abstract url": "https://arxiv.org/abs/2408.10428",
        "title": "Are LLMs Any Good for High-Level Synthesis?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The increasing complexity and demand for faster, energy-efficient hardware designs necessitate innovative High-Level Synthesis (HLS) methodologies. This paper explores the potential of Large Language Models (LLMs) to streamline or replace the HLS process, leveraging their ability to understand natural language specifications and refactor code. We survey the current research and conduct experiments comparing Verilog designs generated by a standard HLS tool (Vitis HLS) with those produced by LLMs translating C code or natural language specifications. Our evaluation focuses on quantifying the impact on performance, power, and resource utilization, providing an assessment of the efficiency of LLM-based approaches. This study aims to illuminate the role of LLMs in HLS, identifying promising directions for optimized hardware design in applications such as AI acceleration, embedded systems, and high-performance computing.",
        "subjects": [
            "cs.AR",
            "cs.AI"
        ],
        "comment": "ICCAD '24 Special Session on AI4HLS: New Frontiers in High-Level Synthesis Augmented with Artificial Intelligence"
    },
    {
        "paper id": "2408.10437",
        "abstract url": "https://arxiv.org/abs/2408.10437",
        "title": "Understanding Generative AI Content with Embedding Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The construction of high-quality numerical features is critical to any quantitative data analysis. Feature engineering has been historically addressed by carefully hand-crafting data representations based on domain expertise. This work views the internal representations of modern deep neural networks (DNNs), called embeddings, as an automated form of traditional feature engineering. For trained DNNs, we show that these embeddings can reveal interpretable, high-level concepts in unstructured sample data. We use these embeddings in natural language and computer vision tasks to uncover both inherent heterogeneity in the underlying data and human-understandable explanations for it. In particular, we find empirical evidence that there is inherent separability between real data and that generated from AI models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10455",
        "abstract url": "https://arxiv.org/abs/2408.10455",
        "title": "IDEA: Enhancing the rule learning ability of language agent through Induction, DEuction, and Abduction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "While large language models (LLMs) have been thoroughly evaluated for deductive and inductive reasoning, their proficiency in abductive reasoning and holistic rule learning in interactive environments remains less explored. This work introduces RULEARN, a novel benchmark specifically designed to assess the rule-learning ability of LLMs in interactive settings. In RULEARN, agents interact with the environment to gather observations and discern patterns, using these insights to solve problems. To further enhance the rule-learning capabilities of LLM agents within this benchmark, we propose IDEA agent, which integrates Induction, Deduction, and Abduction processes. IDEA agent refines this approach by leveraging a structured reasoning sequence: generating hypotheses through abduction, testing them via deduction, and refining them based on induction feedback. This sequence enables agents to dynamically establish and apply rules, mimicking human-like reasoning processes. Our evaluation of five representative LLMs indicates that while these models can generate plausible initial hypotheses, they often struggle with strategic interaction within the environment, effective incorporation of feedback, and adaptive refinement of their hypotheses. IDEA agent demonstrates significantly improved performance on the RULEARN benchmark, offering valuable insights for the development of agents capable of human-like rule-learning in real-world scenarios. We will release our code and data.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "9pages, 12 figs, 4 tables"
    },
    {
        "paper id": "2408.10458",
        "abstract url": "https://arxiv.org/abs/2408.10458",
        "title": "Transfer Operator Learning with Fusion Frame",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The challenge of applying learned knowledge from one domain to solve problems in another related but distinct domain, known as transfer learning, is fundamental in operator learning models that solve Partial Differential Equations (PDEs). These current models often struggle with generalization across different tasks and datasets, limiting their applicability in diverse scientific and engineering disciplines. This work presents a novel framework that enhances the transfer learning capabilities of operator learning models for solving Partial Differential Equations (PDEs) through the integration of fusion frame theory with the Proper Orthogonal Decomposition (POD)-enhanced Deep Operator Network (DeepONet). We introduce an innovative architecture that combines fusion frames with POD-DeepONet, demonstrating superior performance across various PDEs in our experimental analysis. Our framework addresses the critical challenge of transfer learning in operator learning models, paving the way for adaptable and efficient solutions across a wide range of scientific and engineering applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10491",
        "abstract url": "https://arxiv.org/abs/2408.10491",
        "title": "Achieving the Tightest Relaxation of Sigmoids for Formal Verification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the field of formal verification, Neural Networks (NNs) are typically reformulated into equivalent mathematical programs which are optimized over. To overcome the inherent non-convexity of these reformulations, convex relaxations of nonlinear activation functions are typically utilized. Common relaxations (i.e., static linear cuts) of \"S-shaped\" activation functions, however, can be overly loose, slowing down the overall verification process. In this paper, we derive tuneable hyperplanes which upper and lower bound the sigmoid activation function. When tuned in the dual space, these affine bounds smoothly rotate around the nonlinear manifold of the sigmoid activation function. This approach, termed $\u03b1$-sig, allows us to tractably incorporate the tightest possible, element-wise convex relaxation of the sigmoid activation function into a formal verification framework. We embed these relaxations inside of large verification tasks and compare their performance to LiRPA and $\u03b1$-CROWN, a state-of-the-art verification duo.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10495",
        "abstract url": "https://arxiv.org/abs/2408.10495",
        "title": "How Well Do Large Language Models Serve as End-to-End Secure Code Producers?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rapid advancement of large language models (LLMs) such as GPT-4 has revolutionized the landscape of software engineering, positioning these models at the core of modern development practices. As we anticipate these models to evolve into the primary and trustworthy tools used in software development, ensuring the security of the code they produce becomes paramount. How well can LLMs serve as end-to-end secure code producers? This paper presents a systematic investigation into LLMs' inherent potential to generate code with fewer vulnerabilities. Specifically, We studied GPT-3.5 and GPT-4's capability to identify and repair vulnerabilities in the code generated by four popular LLMs including themselves (GPT-3.5, GPT-4, Code Llama, and CodeGeeX2). By manually or automatically reviewing 4,900 pieces of code, our study reveals that: (1) large language models lack awareness of scenario-relevant security risks, which leads to the generation of over 75% vulnerable code on the SecurityEval benchmark; (2) LLMs such as GPT-3.5 and GPT-4 are unable to precisely identify vulnerabilities in the code they generated; (3) GPT-3.5 and GPT-4 can achieve 33.2%~59.6% success rates in repairing the insecure code produced by the 4 LLMs, but they both perform poorly when repairing self-produced code, indicating self-repair \"blind spots\". To address the limitation of a single round of repair, we developed a lightweight tool that prompts LLMs to construct safer source code through an iterative repair procedure based on the insights gained from our study. Experiments show that assisted by semantic analysis engines, our tool significantly improves the success rates of repair to 65.9%~85.5%.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10499",
        "abstract url": "https://arxiv.org/abs/2408.10499",
        "title": "ProgramAlly: Creating Custom Visual Access Programs via Multi-Modal End-User Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Existing visual assistive technologies are built for simple and common use cases, and have few avenues for blind people to customize their functionalities. Drawing from prior work on DIY assistive technology, this paper investigates end-user programming as a means for users to create and customize visual access programs to meet their unique needs. We introduce ProgramAlly, a system for creating custom filters for visual information, e.g., 'find NUMBER on BUS', leveraging three end-user programming approaches: block programming, natural language, and programming by example. To implement ProgramAlly, we designed a representation of visual filtering tasks based on scenarios encountered by blind people, and integrated a set of on-device and cloud models for generating and running these programs. In user studies with 12 blind adults, we found that participants preferred different programming modalities depending on the task, and envisioned using visual access programs to address unique accessibility challenges that are otherwise difficult with existing applications. Through ProgramAlly, we present an exploration of how blind end-users can create visual access programs to customize and control their experiences.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.PL"
        ],
        "comment": "UIST 2024"
    },
    {
        "paper id": "2408.10502",
        "abstract url": "https://arxiv.org/abs/2408.10502",
        "title": "Asymptotic Classification Error for Heavy-Tailed Renewal Processes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the widespread occurrence of classification problems and the increasing collection of point process data across many disciplines, study of error probability for point process classification only emerged very recently. Here, we consider classification of renewal processes. We obtain asymptotic expressions for the Bhattacharyya bound on misclassification error probabilities for heavy-tailed renewal processes.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": "11 pages, 2 figures"
    },
    {
        "paper id": "2408.10504",
        "abstract url": "https://arxiv.org/abs/2408.10504",
        "title": "QPO: Query-dependent Prompt Optimization via Multi-Loop Offline Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Prompt engineering has demonstrated remarkable success in enhancing the performance of large language models (LLMs) across diverse tasks. However, most existing prompt optimization methods only focus on the task-level performance, overlooking the importance of query-preferred prompts, which leads to suboptimal performances. Additionally, these methods rely heavily on frequent interactions with LLMs to obtain feedback for guiding the optimization process, incurring substantial redundant interaction costs. In this paper, we introduce Query-dependent Prompt Optimization (QPO), which leverages multi-loop offline reinforcement learning to iteratively fine-tune a small pretrained language model to generate optimal prompts tailored to the input queries, thus significantly improving the prompting effect on the large target LLM. We derive insights from offline prompting demonstration data, which already exists in large quantities as a by-product of benchmarking diverse prompts on open-sourced tasks, thereby circumventing the expenses of online interactions. Furthermore, we continuously augment the offline dataset with the generated prompts in each loop, as the prompts from the fine-tuned model are supposed to outperform the source prompts in the original dataset. These iterative loops bootstrap the model towards generating optimal prompts. Experiments on various LLM scales and diverse NLP and math tasks demonstrate the efficacy and cost-efficiency of our method in both zero-shot and few-shot scenarios.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10512",
        "abstract url": "https://arxiv.org/abs/2408.10512",
        "title": "Approximate Estimation of High-dimension Execution Skill for Dynamic Agents in Continuous Domains",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In many real-world continuous action domains, human agents must decide which actions to attempt and then execute those actions to the best of their ability. However, humans cannot execute actions without error. Human performance in these domains can potentially be improved by the use of AI to aid in decision-making. One requirement for an AI to correctly reason about what actions a human agent should attempt is a correct model of that human's execution error, or skill. Recent work has demonstrated successful techniques for estimating this execution error with various types of agents across different domains. However, this previous work made several assumptions that limit the application of these ideas to real-world settings. First, previous work assumed that the error distributions were symmetric normal, which meant that only a single parameter had to be estimated. In reality, agent error distributions might exhibit arbitrary shapes and should be modeled more flexibly. Second, it was assumed that the execution error of the agent remained constant across all observations. Especially for human agents, execution error changes over time, and this must be taken into account to obtain effective estimates. To overcome both of these shortcomings, we propose a novel particle-filter-based estimator for this problem. After describing the details of this approximate estimator, we experimentally explore various design decisions and compare performance with previous skill estimators in a variety of settings to showcase the improvements. The outcome is an estimator capable of generating more realistic, time-varying execution skill estimates of agents, which can then be used to assist agents in making better decisions and improve their overall performance.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09739",
        "abstract url": "https://arxiv.org/abs/2408.09739",
        "title": "TraDiffusion: Trajectory-Based Training-Free Image Generation",
        "rating": "0",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this work, we propose a training-free, trajectory-based controllable T2I approach, termed TraDiffusion. This novel method allows users to effortlessly guide image generation via mouse trajectories. To achieve precise control, we design a distance awareness energy function to effectively guide latent variables, ensuring that the focus of generation is within the areas defined by the trajectory. The energy function encompasses a control function to draw the generation closer to the specified trajectory and a movement function to diminish activity in areas distant from the trajectory. Through extensive experiments and qualitative assessments on the COCO dataset, the results reveal that TraDiffusion facilitates simpler, more natural image control. Moreover, it showcases the ability to manipulate salient regions, attributes, and relationships within the generated images, alongside visual input based on arbitrary or enhanced trajectories.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The code: https://github.com/och-mac/TraDiffusion"
    },
    {
        "paper id": "2408.09744",
        "abstract url": "https://arxiv.org/abs/2408.09744",
        "title": "RealCustom++: Representing Images as Real-Word for Real-Time Customization",
        "rating": "0",
        "keywords": [
            [
                "Text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image customization, which takes given texts and images depicting given subjects as inputs, aims to synthesize new images that align with both text semantics and subject appearance. This task provides precise control over details that text alone cannot capture and is fundamental for various real-world applications, garnering significant interest from academia and industry. Existing works follow the pseudo-word paradigm, which involves representing given subjects as pseudo-words and combining them with given texts to collectively guide the generation. However, the inherent conflict and entanglement between the pseudo-words and texts result in a dual-optimum paradox, where subject similarity and text controllability cannot be optimal simultaneously. We propose a novel real-words paradigm termed RealCustom++ that instead represents subjects as non-conflict real words, thereby disentangling subject similarity from text controllability and allowing both to be optimized simultaneously. Specifically, RealCustom++ introduces a novel \"train-inference\" decoupled framework: (1) During training, RealCustom++ learns the alignment between vision conditions and all real words in the text, ensuring high subject-similarity generation in open domains. This is achieved by the cross-layer cross-scale projector to robustly and finely extract subject features, and a curriculum training recipe that adapts the generated subject to diverse poses and sizes. (2) During inference, leveraging the learned general alignment, an adaptive mask guidance is proposed to only customize the generation of the specific target real word, keeping other subject-irrelevant regions uncontaminated to ensure high text-controllability in real-time.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2408.09752",
        "abstract url": "https://arxiv.org/abs/2408.09752",
        "title": "A Unified Framework for Iris Anti-Spoofing: Introducing IrisGeneral Dataset and Masked-MoE Method",
        "rating": "0",
        "keywords": [
            [
                "infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Iris recognition is widely used in high-security scenarios due to its stability and distinctiveness. However, the acquisition of iris images typically requires near-infrared illumination and near-infrared band filters, leading to significant and consistent differences in imaging across devices. This underscores the importance of developing cross-domain capabilities in iris anti-spoofing methods. Despite this need, there is no dataset available that comprehensively evaluates the generalization ability of the iris anti-spoofing task. To address this gap, we propose the IrisGeneral dataset, which includes 10 subsets, belonging to 7 databases, published by 4 institutions, collected with 6 types of devices. IrisGeneral is designed with three protocols, aimed at evaluating average performance, cross-racial generalization, and cross-device generalization of iris anti-spoofing models. To tackle the challenge of integrating multiple sub-datasets in IrisGeneral, we employ multiple parameter sets to learn from the various subsets. Specifically, we utilize the Mixture of Experts (MoE) to fit complex data distributions using multiple sub-neural networks. To further enhance the generalization capabilities, we introduce a novel method Masked-MoE (MMoE). It randomly masks a portion of tokens for some experts and requires their outputs to be similar to the unmasked experts, which improves the generalization ability and effectively mitigates the overfitting issue produced by MoE. We selected ResNet50, VIT-B/16, CLIP, and FLIP as representative models and benchmarked them on the IrisGeneral dataset. Experimental results demonstrate that our proposed MMoE with CLIP achieves the best performance on IrisGeneral.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09800",
        "abstract url": "https://arxiv.org/abs/2408.09800",
        "title": "Latent Diffusion for Guided Document Table Generation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Obtaining annotated table structure data for complex tables is a challenging task due to the inherent diversity and complexity of real-world document layouts. The scarcity of publicly available datasets with comprehensive annotations for intricate table structures hinders the development and evaluation of models designed for such scenarios. This research paper introduces a novel approach for generating annotated images for table structure by leveraging conditioned mask images of rows and columns through the application of latent diffusion models. The proposed method aims to enhance the quality of synthetic data used for training object detection models. Specifically, the study employs a conditioning mechanism to guide the generation of complex document table images, ensuring a realistic representation of table layouts. To evaluate the effectiveness of the generated data, we employ the popular YOLOv5 object detection model for training. The generated table images serve as valuable training samples, enriching the dataset with diverse table structures. The model is subsequently tested on the challenging pubtables-1m testset, a benchmark for table structure recognition in complex document layouts. Experimental results demonstrate that the introduced approach significantly improves the quality of synthetic data for training, leading to YOLOv5 models with enhanced performance. The mean Average Precision (mAP) values obtained on the pubtables-1m testset showcase results closely aligned with state-of-the-art methods. Furthermore, low FID results obtained on the synthetic data further validate the efficacy of the proposed methodology in generating annotated images for table structure.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in ICDAR 2024"
    },
    {
        "paper id": "2408.09859",
        "abstract url": "https://arxiv.org/abs/2408.09859",
        "title": "OccMamba: Semantic Occupancy Prediction with State Space Models",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Training deep learning models for semantic occupancy prediction is challenging due to factors such as a large number of occupancy cells, severe occlusion, limited visual cues, complicated driving scenarios, etc. Recent methods often adopt transformer-based architectures given their strong capability in learning input-conditioned weights and long-range relationships. However, transformer-based networks are notorious for their quadratic computation complexity, seriously undermining their efficacy and deployment in semantic occupancy prediction. Inspired by the global modeling and linear computation complexity of the Mamba architecture, we present the first Mamba-based network for semantic occupancy prediction, termed OccMamba. However, directly applying the Mamba architecture to the occupancy prediction task yields unsatisfactory performance due to the inherent domain gap between the linguistic and 3D domains. To relieve this problem, we present a simple yet effective 3D-to-1D reordering operation, i.e., height-prioritized 2D Hilbert expansion. It can maximally retain the spatial structure of point clouds as well as facilitate the processing of Mamba blocks. Our OccMamba achieves state-of-the-art performance on three prevalent occupancy prediction benchmarks, including OpenOccupancy, SemanticKITTI and SemanticPOSS. Notably, on OpenOccupancy, our OccMamba outperforms the previous state-of-the-art Co-Occ by 3.1% IoU and 3.2% mIoU, respectively. Codes will be released upon publication.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 4 figures"
    },
    {
        "paper id": "2408.09860",
        "abstract url": "https://arxiv.org/abs/2408.09860",
        "title": "3D-Aware Instance Segmentation and Tracking in Egocentric Videos",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Egocentric videos present unique challenges for 3D scene understanding due to rapid camera motion, frequent object occlusions, and limited object visibility. This paper introduces a novel approach to instance segmentation and tracking in first-person video that leverages 3D awareness to overcome these obstacles. Our method integrates scene geometry, 3D object centroid tracking, and instance segmentation to create a robust framework for analyzing dynamic egocentric scenes. By incorporating spatial and temporal cues, we achieve superior performance compared to state-of-the-art 2D approaches. Extensive evaluations on the challenging EPIC Fields dataset demonstrate significant improvements across a range of tracking and segmentation consistency metrics. Specifically, our method outperforms the next best performing approach by $7$ points in Association Accuracy (AssA) and $4.5$ points in IDF1 score, while reducing the number of ID switches by $73\\%$ to $80\\%$ across various object categories. Leveraging our tracked instance segmentations, we showcase downstream applications in 3D object reconstruction and amodal video object segmentation in these egocentric settings.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09928",
        "abstract url": "https://arxiv.org/abs/2408.09928",
        "title": "DiscoNeRF: Class-Agnostic Object Field for 3D Object Discovery",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Radiance Fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRFs) have become a powerful tool for modeling 3D scenes from multiple images. However, NeRFs remain difficult to segment into semantically meaningful regions. Previous approaches to 3D segmentation of NeRFs either require user interaction to isolate a single object, or they rely on 2D semantic masks with a limited number of classes for supervision. As a consequence, they generalize poorly to class-agnostic masks automatically generated in real scenes. This is attributable to the ambiguity arising from zero-shot segmentation, yielding inconsistent masks across views. In contrast, we propose a method that is robust to inconsistent segmentations and successfully decomposes the scene into a set of objects of any class. By introducing a limited number of competing object slots against which masks are matched, a meaningful object representation emerges that best explains the 2D supervision and minimizes an additional regularization term. Our experiments demonstrate the ability of our method to generate 3D panoptic segmentations on complex scenes, and extract high-quality 3D assets from NeRFs that can then be used in virtual 3D environments.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09940",
        "abstract url": "https://arxiv.org/abs/2408.09940",
        "title": "ML-CrAIST: Multi-scale Low-high Frequency Information-based Cross black Attention with Image Super-resolving Transformer",
        "rating": "0",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recently, transformers have captured significant interest in the area of single-image super-resolution tasks, demonstrating substantial gains in performance. Current models heavily depend on the network's extensive ability to extract high-level semantic details from images while overlooking the effective utilization of multi-scale image details and intermediate information within the network. Furthermore, it has been observed that high-frequency areas in images present significant complexity for super-resolution compared to low-frequency areas. This work proposes a transformer-based super-resolution architecture called ML-CrAIST that addresses this gap by utilizing low-high frequency information in multiple scales. Unlike most of the previous work (either spatial or channel), we operate spatial and channel self-attention, which concurrently model pixel interaction from both spatial and channel dimensions, exploiting the inherent correlations across spatial and channel axis. Further, we devise a cross-attention block for super-resolution, which explores the correlations between low and high-frequency information. Quantitative and qualitative assessments indicate that our proposed ML-CrAIST surpasses state-of-the-art super-resolution methods (e.g., 0.15 dB gain @Manga109 $\\times$4). Code is available on: https://github.com/Alik033/ML-CrAIST.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10024",
        "abstract url": "https://arxiv.org/abs/2408.10024",
        "title": "Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing",
        "rating": "0",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of Federated Learning (FL), particularly within the manufacturing sector, the strategy for selecting client weights for server aggregation is pivotal for model performance. This study investigates the comparative effectiveness of two weight selection strategies: Final Epoch Weight Selection (FEWS) and Optimal Epoch Weight Selection (OEWS). Designed for manufacturing contexts where collaboration typically involves a limited number of partners (two to four clients), our research focuses on federated image classification tasks. We employ various neural network architectures, including EfficientNet, ResNet, and VGG, to assess the impact of these weight selection strategies on model convergence and robustness. Our research aims to determine whether FEWS or OEWS enhances the global FL model's performance across communication rounds (CRs). Through empirical analysis and rigorous experimentation, we seek to provide valuable insights for optimizing FL implementations in manufacturing, ensuring that collaborative efforts yield the most effective and reliable models with a limited number of participating clients. The findings from this study are expected to refine FL practices significantly in manufacturing, thereby enhancing the efficiency and performance of collaborative machine learning endeavors in this vital sector.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to The 2nd IEEE International Conference on Federated Learning Technologies and Applications (FLTA24)"
    },
    {
        "paper id": "2408.10037",
        "abstract url": "https://arxiv.org/abs/2408.10037",
        "title": "SHARP: Segmentation of Hands and Arms by Range using Pseudo-Depth for Enhanced Egocentric 3D Hand Pose Estimation and Action Recognition",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Hand pose represents key information for action recognition in the egocentric perspective, where the user is interacting with objects. We propose to improve egocentric 3D hand pose estimation based on RGB frames only by using pseudo-depth images. Incorporating state-of-the-art single RGB image depth estimation techniques, we generate pseudo-depth representations of the frames and use distance knowledge to segment irrelevant parts of the scene. The resulting depth maps are then used as segmentation masks for the RGB frames. Experimental results on H2O Dataset confirm the high accuracy of the estimated pose with our method in an action recognition task. The 3D hand pose, together with information from object detection, is processed by a transformer-based action recognition network, resulting in an accuracy of 91.73%, outperforming all state-of-the-art methods. Estimations of 3D hand pose result in competitive performance with existing methods with a mean pose error of 28.66 mm. This method opens up new possibilities for employing distance information in egocentric 3D hand pose estimation without relying on depth sensors.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at 27th International Conference on Pattern Recognition (ICPR)"
    },
    {
        "paper id": "2408.10041",
        "abstract url": "https://arxiv.org/abs/2408.10041",
        "title": "Implicit Gaussian Splatting with Efficient Multi-Level Tri-Plane Representation",
        "rating": "0",
        "keywords": [
            [
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in photo-realistic novel view synthesis have been significantly driven by Gaussian Splatting (3DGS). Nevertheless, the explicit nature of 3DGS data entails considerable storage requirements, highlighting a pressing need for more efficient data representations. To address this, we present Implicit Gaussian Splatting (IGS), an innovative hybrid model that integrates explicit point clouds with implicit feature embeddings through a multi-level tri-plane architecture. This architecture features 2D feature grids at various resolutions across different levels, facilitating continuous spatial domain representation and enhancing spatial correlations among Gaussian primitives. Building upon this foundation, we introduce a level-based progressive training scheme, which incorporates explicit spatial regularization. This method capitalizes on spatial correlations to enhance both the rendering quality and the compactness of the IGS representation. Furthermore, we propose a novel compression pipeline tailored for both point clouds and 2D feature grids, considering the entropy variations across different levels. Extensive experimental evaluations demonstrate that our algorithm can deliver high-quality rendering using only a few MBs, effectively balancing storage efficiency and rendering fidelity, and yielding results that are competitive with the state-of-the-art.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10075",
        "abstract url": "https://arxiv.org/abs/2408.10075",
        "title": "Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning",
        "rating": "0",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for aligning foundation models to human values and preferences. However, current RLHF techniques cannot account for the naturally occurring differences in individual human preferences across a diverse population. When these differences arise, traditional RLHF frameworks simply average over them, leading to inaccurate rewards and poor performance for individual subgroups. To address the need for pluralistic alignment, we develop a class of multimodal RLHF methods. Our proposed techniques are based on a latent variable formulation - inferring a novel user-specific latent and learning reward models and policies conditioned on this latent without additional user-specific data. While conceptually simple, we show that in practice, this reward modeling requires careful algorithmic considerations around model architecture and reward scaling. To empirically validate our proposed technique, we first show that it can provide a way to combat underspecification in simulated control problems, inferring and optimizing user-specific reward functions. Next, we conduct experiments on pluralistic language datasets representing diverse user preferences and demonstrate improved reward function accuracy. We additionally show the benefits of this probabilistic framework in terms of measuring uncertainty, and actively learning user preferences. This work enables learning from diverse populations of users with divergent preferences, an important challenge that naturally occurs in problems from robot learning to foundation model alignment.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.RO"
        ],
        "comment": "weirdlabuw.github.io/vpl"
    },
    {
        "paper id": "2408.10115",
        "abstract url": "https://arxiv.org/abs/2408.10115",
        "title": "GLIMMER: Incorporating Graph and Lexical Features in Unsupervised Multi-Document Summarization",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Pre-trained language models are increasingly being used in multi-document summarization tasks. However, these models need large-scale corpora for pre-training and are domain-dependent. Other non-neural unsupervised summarization approaches mostly rely on key sentence extraction, which can lead to information loss. To address these challenges, we propose a lightweight yet effective unsupervised approach called GLIMMER: a Graph and LexIcal features based unsupervised Multi-docuMEnt summaRization approach. It first constructs a sentence graph from the source documents, then automatically identifies semantic clusters by mining low-level features from raw texts, thereby improving intra-cluster correlation and the fluency of generated sentences. Finally, it summarizes clusters into natural sentences. Experiments conducted on Multi-News, Multi-XScience and DUC-2004 demonstrate that our approach outperforms existing unsupervised approaches. Furthermore, it surpasses state-of-the-art pre-trained multi-document summarization models (e.g. PEGASUS and PRIMERA) under zero-shot settings in terms of ROUGE scores. Additionally, human evaluations indicate that summaries generated by GLIMMER achieve high readability and informativeness scores. Our code is available at https://github.com/Oswald1997/GLIMMER.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "19 pages, 7 figures. Accepted by ECAI 2024"
    },
    {
        "paper id": "2408.10119",
        "abstract url": "https://arxiv.org/abs/2408.10119",
        "title": "Factorized-Dreamer: Training A High-Quality Video Generator with Limited and Low-Quality Data",
        "rating": "0",
        "keywords": [
            [
                "Text-to-video"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-video (T2V) generation has gained significant attention due to its wide applications to video generation, editing, enhancement and translation, \\etc. However, high-quality (HQ) video synthesis is extremely challenging because of the diverse and complex motions existed in real world. Most existing works struggle to address this problem by collecting large-scale HQ videos, which are inaccessible to the community. In this work, we show that publicly available limited and low-quality (LQ) data are sufficient to train a HQ video generator without recaptioning or finetuning. We factorize the whole T2V generation process into two steps: generating an image conditioned on a highly descriptive caption, and synthesizing the video conditioned on the generated image and a concise caption of motion details. Specifically, we present \\emph{Factorized-Dreamer}, a factorized spatiotemporal framework with several critical designs for T2V generation, including an adapter to combine text and image embeddings, a pixel-aware cross attention module to capture pixel-level image information, a T5 text encoder to better understand motion description, and a PredictNet to supervise optical flows. We further present a noise schedule, which plays a key role in ensuring the quality and stability of video generation. Our model lowers the requirements in detailed captions and HQ videos, and can be directly trained on limited LQ datasets with noisy and brief captions such as WebVid-10M, largely alleviating the cost to collect large-scale HQ video-text pairs. Extensive experiments in a variety of T2V and image-to-video generation tasks demonstrate the effectiveness of our proposed Factorized-Dreamer. Our source codes are available at \\url{https://github.com/yangxy/Factorized-Dreamer/}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10178",
        "abstract url": "https://arxiv.org/abs/2408.10178",
        "title": "NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "SDF"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Signed Distance Function (SDF)-based volume rendering has demonstrated significant capabilities in surface reconstruction. Although promising, SDF-based methods often fail to capture detailed geometric structures, resulting in visible defects. By comparing SDF-based volume rendering to density-based volume rendering, we identify two main factors within the SDF-based approach that degrade surface quality: SDF-to-density representation and geometric regularization. These factors introduce challenges that hinder the optimization of the SDF field. To address these issues, we introduce NeuRodin, a novel two-stage neural surface reconstruction framework that not only achieves high-fidelity surface reconstruction but also retains the flexible optimization characteristics of density-based methods. NeuRodin incorporates innovative strategies that facilitate transformation of arbitrary topologies and reduce artifacts associated with density bias. Extensive evaluations on the Tanks and Temples and ScanNet++ datasets demonstrate the superiority of NeuRodin, showing strong reconstruction capabilities for both indoor and outdoor environments using solely posed RGB captures. Project website: https://open3dvlab.github.io/NeuRodin/",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10361",
        "abstract url": "https://arxiv.org/abs/2408.10361",
        "title": "ASASVIcomtech: The Vicomtech-UGR Speech Deepfake Detection and SASV Systems for the ASVspoof5 Challenge",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper presents the work carried out by the ASASVIcomtech team, made up of researchers from Vicomtech and University of Granada, for the ASVspoof5 Challenge. The team has participated in both Track 1 (speech deepfake detection) and Track 2 (spoofing-aware speaker verification). This work started with an analysis of the challenge available data, which was regarded as an essential step to avoid later potential biases of the trained models, and whose main conclusions are presented here. With respect to the proposed approaches, a closed-condition system employing a deep complex convolutional recurrent architecture was developed for Track 1, although, unfortunately, no noteworthy results were achieved. On the other hand, different possibilities of open-condition systems, based on leveraging self-supervised models, augmented training data from previous challenges, and novel vocoders, were explored for both tracks, finally achieving very competitive results with an ensemble system.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "This paper was accepted at ASVspoof Workshop 2024"
    },
    {
        "paper id": "2408.10388",
        "abstract url": "https://arxiv.org/abs/2408.10388",
        "title": "Narrowing the Gap between Vision and Action in Navigation",
        "rating": "0",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "The existing methods for Vision and Language Navigation in the Continuous Environment (VLN-CE) commonly incorporate a waypoint predictor to discretize the environment. This simplifies the navigation actions into a view selection task and improves navigation performance significantly compared to direct training using low-level actions. However, the VLN-CE agents are still far from the real robots since there are gaps between their visual perception and executed actions. First, VLN-CE agents that discretize the visual environment are primarily trained with high-level view selection, which causes them to ignore crucial spatial reasoning within the low-level action movements. Second, in these models, the existing waypoint predictors neglect object semantics and their attributes related to passibility, which can be informative in indicating the feasibility of actions. To address these two issues, we introduce a low-level action decoder jointly trained with high-level action prediction, enabling the current VLN agent to learn and ground the selected visual view to the low-level controls. Moreover, we enhance the current waypoint predictor by utilizing visual representations containing rich semantic information and explicitly masking obstacles based on humans' prior knowledge about the feasibility of actions. Empirically, our agent can improve navigation performance metrics compared to the strong baselines on both high-level and low-level actions.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10411",
        "abstract url": "https://arxiv.org/abs/2408.10411",
        "title": "Resolving Lexical Bias in Edit Scoping with Projector Editor Networks",
        "rating": "0",
        "keywords": [
            [
                "model editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Weight-preserving model editing techniques heavily rely on the scoping mechanism that decides when to apply an edit to the base model. These scoping mechanisms utilize distance functions in the representation space to ascertain the scope of the edit. In this work, we show that distance-based scoping functions grapple with lexical biases leading to issues such as misfires with irrelevant prompts that share similar lexical characteristics. To address this problem, we introduce, Projector Editor Networks for Model Editing (PENME),is a model editing approach that employs a compact adapter with a projection network trained via a contrastive learning objective. We demonstrate the efficacy of PENME in achieving superior results while being compute efficient and flexible to adapt across model architectures.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10417",
        "abstract url": "https://arxiv.org/abs/2408.10417",
        "title": "Development of an AI Anti-Bullying System Using Large Language Model Key Topic Detection",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents and evaluates work on the development of an artificial intelligence (AI) anti-bullying system. The system is designed to identify coordinated bullying attacks via social media and other mechanisms, characterize them and propose remediation and response activities to them. In particular, a large language model (LLM) is used to populate an enhanced expert system-based network model of a bullying attack. This facilitates analysis and remediation activity - such as generating report messages to social media companies - determination. The system is described and the efficacy of the LLM for populating the model is analyzed herein.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10453",
        "abstract url": "https://arxiv.org/abs/2408.10453",
        "title": "Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation",
        "rating": "0",
        "keywords": [
            [
                "VLM"
            ],
            [
                "3D"
            ],
            [
                "diffusion",
                "Text-to-video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-video generation has been dominated by end-to-end diffusion-based or autoregressive models. On one hand, those novel models provide plausible versatility, but they are criticized for physical correctness, shading and illumination, camera motion, and temporal consistency. On the other hand, film industry relies on manually-edited Computer-Generated Imagery (CGI) using 3D modeling software. Human-directed 3D synthetic videos and animations address the aforementioned shortcomings, but it is extremely tedious and requires tight collaboration between movie makers and 3D rendering experts. In this paper, we introduce an automatic synthetic video generation pipeline based on Vision Large Language Model (VLM) agent collaborations. Given a natural language description of a video, multiple VLM agents auto-direct various processes of the generation pipeline. They cooperate to create Blender scripts which render a video that best aligns with the given description. Based on film making inspiration and augmented with Blender-based movie making knowledge, the Director agent decomposes the input text-based video description into sub-processes. For each sub-process, the Programmer agent produces Python-based Blender scripts based on customized function composing and API calling. Then, the Reviewer agent, augmented with knowledge of video reviewing, character motion coordinates, and intermediate screenshots uses its compositional reasoning ability to provide feedback to the Programmer agent. The Programmer agent iteratively improves the scripts to yield the best overall video outcome. Our generated videos show better quality than commercial video generation models in 5 metrics on video quality and instruction-following performance. Moreover, our framework outperforms other approaches in a comprehensive user study on quality, consistency, and rationality.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10487",
        "abstract url": "https://arxiv.org/abs/2408.10487",
        "title": "MambaEVT: Event Stream based Visual Object Tracking using State Space Model",
        "rating": "0",
        "keywords": [
            [
                "Event camera"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Event camera-based visual tracking has drawn more and more attention in recent years due to the unique imaging principle and advantages of low energy consumption, high dynamic range, and dense temporal resolution. Current event-based tracking algorithms are gradually hitting their performance bottlenecks, due to the utilization of vision Transformer and the static template for target object localization. In this paper, we propose a novel Mamba-based visual tracking framework that adopts the state space model with linear complexity as a backbone network. The search regions and target template are fed into the vision Mamba network for simultaneous feature extraction and interaction. The output tokens of search regions will be fed into the tracking head for target localization. More importantly, we consider introducing a dynamic template update strategy into the tracking framework using the Memory Mamba network. By considering the diversity of samples in the target template library and making appropriate adjustments to the template memory module, a more effective dynamic template can be integrated. The effective combination of dynamic and static templates allows our Mamba-based tracking algorithm to achieve a good balance between accuracy and computational cost on multiple large-scale datasets, including EventVOT, VisEvent, and FE240hz. The source code will be released on https://github.com/Event-AHU/MambaEVT",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "In Peer Review"
    },
    {
        "paper id": "2408.10496",
        "abstract url": "https://arxiv.org/abs/2408.10496",
        "title": "GPT-based Textile Pilling Classification Using 3D Point Cloud Data",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Textile pilling assessment is critical for textile quality control. We collect thousands of 3D point cloud images in the actual test environment of textiles and organize and label them as TextileNet8 dataset. To the best of our knowledge, it is the first publicly available eight-categories 3D point cloud dataset in the field of textile pilling assessment. Based on PointGPT, the GPT-like big model of point cloud analysis, we incorporate the global features of the input point cloud extracted from the non-parametric network into it, thus proposing the PointGPT+NN model. Using TextileNet8 as a benchmark, the experimental results show that the proposed PointGPT+NN model achieves an overall accuracy (OA) of 91.8% and a mean per-class accuracy (mAcc) of 92.2%. Test results on other publicly available datasets also validate the competitive performance of the proposed PointGPT+NN model. The proposed TextileNet8 dataset will be publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 2 figures"
    },
    {
        "paper id": "2408.10527",
        "abstract url": "https://arxiv.org/abs/2408.10527",
        "title": "EdgeNAT: Transformer for Efficient Edge Detection",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Transformers, renowned for their powerful feature extraction capabilities, have played an increasingly prominent role in various vision tasks. Especially, recent advancements present transformer with hierarchical structures such as Dilated Neighborhood Attention Transformer (DiNAT), demonstrating outstanding ability to efficiently capture both global and local features. However, transformers' application in edge detection has not been fully exploited. In this paper, we propose EdgeNAT, a one-stage transformer-based edge detector with DiNAT as the encoder, capable of extracting object boundaries and meaningful edges both accurately and efficiently. On the one hand, EdgeNAT captures global contextual information and detailed local cues with DiNAT, on the other hand, it enhances feature representation with a novel SCAF-MLA decoder by utilizing both inter-spatial and inter-channel relationships of feature maps. Extensive experiments on multiple datasets show that our method achieves state-of-the-art performance on both RGB and depth images. Notably, on the widely used BSDS500 dataset, our L model achieves impressive performances, with ODS F-measure and OIS F-measure of 86.0%, 87.6% for multi-scale input,and 84.9%, and 86.3% for single-scale input, surpassing the current state-of-the-art EDTER by 1.2%, 1.1%, 1.7%, and 1.6%, respectively. Moreover, as for throughput, our approach runs at 20.87 FPS on RTX 4090 GPU with single-scale input. The code for our method will be released soon.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10533",
        "abstract url": "https://arxiv.org/abs/2408.10533",
        "title": "FAGStyle: Feature Augmentation on Geodesic Surface for Zero-shot Text-guided Diffusion Image Style Transfer",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The goal of image style transfer is to render an image guided by a style reference while maintaining the original content. Existing image-guided methods rely on specific style reference images, restricting their wider application and potentially compromising result quality. As a flexible alternative, text-guided methods allow users to describe the desired style using text prompts. Despite their versatility, these methods often struggle with maintaining style consistency, reflecting the described style accurately, and preserving the content of the target image. To address these challenges, we introduce FAGStyle, a zero-shot text-guided diffusion image style transfer method. Our approach enhances inter-patch information interaction by incorporating the Sliding Window Crop technique and Feature Augmentation on Geodesic Surface into our style control loss. Furthermore, we integrate a Pre-Shape self-correlation consistency loss to ensure content consistency. FAGStyle demonstrates superior performance over existing methods, consistently achieving stylization that retains the semantic content of the source image. Experimental results confirms the efficacy of FAGStyle across a diverse range of source contents and styles, both imagined and common.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10537",
        "abstract url": "https://arxiv.org/abs/2408.10537",
        "title": "Subspace Prototype Guidance for Mitigating Class Imbalance in Point Cloud Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Point cloud semantic segmentation can significantly enhance the perception of an intelligent agent. Nevertheless, the discriminative capability of the segmentation network is influenced by the quantity of samples available for different categories. To mitigate the cognitive bias induced by class imbalance, this paper introduces a novel method, namely subspace prototype guidance (\\textbf{SPG}), to guide the training of segmentation network. Specifically, the point cloud is initially separated into independent point sets by category to provide initial conditions for the generation of feature subspaces. The auxiliary branch which consists of an encoder and a projection head maps these point sets into separate feature subspaces. Subsequently, the feature prototypes which are extracted from the current separate subspaces and then combined with prototypes of historical subspaces guide the feature space of main branch to enhance the discriminability of features of minority categories. The prototypes derived from the feature space of main branch are also employed to guide the training of the auxiliary branch, forming a supervisory loop to maintain consistent convergence of the entire network. The experiments conducted on the large public benchmarks (i.e. S3DIS, ScanNet v2, ScanNet200, Toronto-3D) and collected real-world data illustrate that the proposed method significantly improves the segmentation performance and surpasses the state-of-the-art method. The code is available at \\url{https://github.com/Javion11/PointLiBR.git}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10846",
        "abstract url": "https://arxiv.org/abs/2408.10846",
        "title": "Harmonizing Attention: Training-free Texture-aware Geometry Transfer",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Extracting geometry features from photographic images independently of surface texture and transferring them onto different materials remains a complex challenge. In this study, we introduce Harmonizing Attention, a novel training-free approach that leverages diffusion models for texture-aware geometry transfer. Our method employs a simple yet effective modification of self-attention layers, allowing the model to query information from multiple reference images within these layers. This mechanism is seamlessly integrated into the inversion process as Texture-aligning Attention and into the generation process as Geometry-aligning Attention. This dual-attention approach ensures the effective capture and transfer of material-independent geometry features while maintaining material-specific textural continuity, all without the need for model fine-tuning.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "10 pages, 6 figures"
    },
    {
        "paper id": "2408.09762",
        "abstract url": "https://arxiv.org/abs/2408.09762",
        "title": "Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In a real federated learning (FL) system, communication overhead for passing model parameters between the clients and the parameter server (PS) is often a bottleneck. Hierarchical federated learning (HFL) that poses multiple edge servers (ESs) between clients and the PS can partially alleviate communication pressure but still needs the aggregation of model parameters from multiple ESs at the PS. To further reduce communication overhead, we bring sequential FL (SFL) into HFL for the first time, which removes the central PS and enables the model training to be completed only through passing the global model between two adjacent ESs for each iteration, and propose a novel algorithm adaptive to such a combinational framework, referred to as Fed-CHS. Convergence results are derived for strongly convex and non-convex loss functions under various data heterogeneity setups, which show comparable convergence performance with the algorithms for HFL or SFL solely. Experimental results provide evidence of the superiority of our proposed Fed-CHS on both communication overhead saving and test accuracy over baseline methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09767",
        "abstract url": "https://arxiv.org/abs/2408.09767",
        "title": "Propagating the prior from shallow to deep with a pre-trained velocity-model Generative Transformer network",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Building subsurface velocity models is essential to our goals in utilizing seismic data for Earth discovery and exploration, as well as monitoring. With the dawn of machine learning, these velocity models (or, more precisely, their distribution) can be stored accurately and efficiently in a generative model. These stored velocity model distributions can be utilized to regularize or quantify uncertainties in inverse problems, like full waveform inversion. However, most generators, like normalizing flows or diffusion models, treat the image (velocity model) uniformly, disregarding spatial dependencies and resolution changes with respect to the observation locations. To address this weakness, we introduce VelocityGPT, a novel implementation that utilizes Transformer decoders trained autoregressively to generate a velocity model from shallow subsurface to deep. Owing to the fact that seismic data are often recorded on the Earth's surface, a top-down generator can utilize the inverted information in the shallow as guidance (prior) to generating the deep. To facilitate the implementation, we use an additional network to compress the velocity model. We also inject prior information, like well or structure (represented by a migration image) to generate the velocity model. Using synthetic data, we demonstrate the effectiveness of VelocityGPT as a promising approach in generative model applications for seismic velocity model building.",
        "subjects": [
            "physics.geo-ph",
            "cs.AI",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09781",
        "abstract url": "https://arxiv.org/abs/2408.09781",
        "title": "Neural Horizon Model Predictive Control -- Increasing Computational Efficiency with Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The expansion in automation of increasingly fast applications and low-power edge devices poses a particular challenge for optimization based control algorithms, like model predictive control. Our proposed machine-learning supported approach addresses this by utilizing a feed-forward neural network to reduce the computation load of the online-optimization. We propose approximating part of the problem horizon, while maintaining safety guarantees -- constraint satisfaction -- via the remaining optimization part of the controller. The approach is validated in simulation, demonstrating an improvement in computational efficiency, while maintaining guarantees and near-optimal performance. The proposed MPC scheme can be applied to a wide range of applications, including those requiring a rapid control response, such as robotics and embedded applications with limited computational resources.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "6 pages, 4 figures, 4 tables, American Control Conference (ACC) 2024"
    },
    {
        "paper id": "2408.09790",
        "abstract url": "https://arxiv.org/abs/2408.09790",
        "title": "Structure-enhanced Contrastive Learning for Graph Clustering",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph clustering is a crucial task in network analysis with widespread applications, focusing on partitioning nodes into distinct groups with stronger intra-group connections than inter-group ones. Recently, contrastive learning has achieved significant progress in graph clustering. However, most methods suffer from the following issues: 1) an over-reliance on meticulously designed data augmentation strategies, which can undermine the potential of contrastive learning. 2) overlooking cluster-oriented structural information, particularly the higher-order cluster(community) structure information, which could unveil the mesoscopic cluster structure information of the network. In this study, Structure-enhanced Contrastive Learning (SECL) is introduced to addresses these issues by leveraging inherent network structures. SECL utilizes a cross-view contrastive learning mechanism to enhance node embeddings without elaborate data augmentations, a structural contrastive learning module for ensuring structural consistency, and a modularity maximization strategy for harnessing clustering-oriented information. This comprehensive approach results in robust node representations that greatly enhance clustering performance. Extensive experiments on six datasets confirm SECL's superiority over current state-of-the-art methods, indicating a substantial improvement in the domain of graph clustering.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09815",
        "abstract url": "https://arxiv.org/abs/2408.09815",
        "title": "A Population-to-individual Tuning Framework for Adapting Pretrained LM to On-device User Intent Prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mobile devices, especially smartphones, can support rich functions and have developed into indispensable tools in daily life. With the rise of generative AI services, smartphones can potentially transform into personalized assistants, anticipating user needs and scheduling services accordingly. Predicting user intents on smartphones, and reflecting anticipated activities based on past interactions and context, remains a pivotal step towards this vision. Existing research predominantly focuses on specific domains, neglecting the challenge of modeling diverse event sequences across dynamic contexts. Leveraging pre-trained language models (PLMs) offers a promising avenue, yet adapting PLMs to on-device user intent prediction presents significant challenges. To address these challenges, we propose PITuning, a Population-to-Individual Tuning framework. PITuning enhances common pattern extraction through dynamic event-to-intent transition modeling and addresses long-tailed preferences via adaptive unlearning strategies. Experimental results on real-world datasets demonstrate PITuning's superior intent prediction performance, highlighting its ability to capture long-tailed preferences and its practicality for on-device prediction scenarios.",
        "subjects": [
            "cs.LG",
            "cs.HC"
        ],
        "comment": "accepted by KDD 2024"
    },
    {
        "paper id": "2408.09858",
        "abstract url": "https://arxiv.org/abs/2408.09858",
        "title": "ShortCircuit: AlphaZero-Driven Circuit Design",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Chip design relies heavily on generating Boolean circuits, such as AND-Inverter Graphs (AIGs), from functional descriptions like truth tables. While recent advances in deep learning have aimed to accelerate circuit design, these efforts have mostly focused on tasks other than synthesis, and traditional heuristic methods have plateaued. In this paper, we introduce ShortCircuit, a novel transformer-based architecture that leverages the structural properties of AIGs and performs efficient space exploration. Contrary to prior approaches attempting end-to-end generation of logic circuits using deep networks, ShortCircuit employs a two-phase process combining supervised with reinforcement learning to enhance generalization to unseen truth tables. We also propose an AlphaZero variant to handle the double exponentially large state space and the sparsity of the rewards, enabling the discovery of near-optimal designs. To evaluate the generative performance of our trained model , we extract 500 truth tables from a benchmark set of 20 real-world circuits. ShortCircuit successfully generates AIGs for 84.6% of the 8-input test truth tables, and outperforms the state-of-the-art logic synthesis tool, ABC, by 14.61% in terms of circuits size.",
        "subjects": [
            "cs.LG",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09908",
        "abstract url": "https://arxiv.org/abs/2408.09908",
        "title": "$p$SVM: Soft-margin SVMs with $p$-norm Hinge Loss",
        "rating": "-0.5",
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Support Vector Machines (SVMs) based on hinge loss have been extensively discussed and applied to various binary classification tasks. These SVMs achieve a balance between margin maximization and the minimization of slack due to outliers. Although many efforts have been dedicated to enhancing the performance of SVMs with hinge loss, studies on $p$SVMs, soft-margin SVMs with $p$-norm hinge loss, remain relatively scarce. In this paper, we explore the properties, performance, and training algorithms of $p$SVMs. We first derive the generalization bound of $p$SVMs, then formulate the dual optimization problem, comparing it with the traditional approach. Furthermore, we discuss a generalized version of the Sequential Minimal Optimization (SMO) algorithm, $p$SMO, to train our $p$SVM model. Comparative experiments on various datasets, including binary and multi-class classification tasks, demonstrate the effectiveness and advantages of our $p$SVM model and the $p$SMO method. Code is available at https://github.com/CoderBak/pSVM.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09918",
        "abstract url": "https://arxiv.org/abs/2408.09918",
        "title": "Expressive Power of Temporal Message Passing",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph neural networks (GNNs) have recently been adapted to temporal settings, often employing temporal versions of the message-passing mechanism known from GNNs. We divide temporal message passing mechanisms from literature into two main types: global and local, and establish Weisfeiler-Leman characterisations for both. This allows us to formally analyse expressive power of temporal message-passing models. We show that global and local temporal message-passing mechanisms have incomparable expressive power when applied to arbitrary temporal graphs. However, the local mechanism is strictly more expressive than the global mechanism when applied to colour-persistent temporal graphs, whose node colours are initially the same in all time points. Our theoretical findings are supported by experimental evidence, underlining practical implications of our analysis.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2408.09937",
        "abstract url": "https://arxiv.org/abs/2408.09937",
        "title": "The curse of random quantum data",
        "rating": "-0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantum machine learning, which involves running machine learning algorithms on quantum devices, may be one of the most significant flagship applications for these devices. Unlike its classical counterparts, the role of data in quantum machine learning has not been fully understood. In this work, we quantify the performances of quantum machine learning in the landscape of quantum data. Provided that the encoding of quantum data is sufficiently random, the performance, we find that the training efficiency and generalization capabilities in quantum machine learning will be exponentially suppressed with the increase in the number of qubits, which we call \"the curse of random quantum data\". Our findings apply to both the quantum kernel method and the large-width limit of quantum neural networks. Conversely, we highlight that through meticulous design of quantum datasets, it is possible to avoid these curses, thereby achieving efficient convergence and robust generalization. Our conclusions are corroborated by extensive numerical simulations.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "40 pages, 8 figures"
    },
    {
        "paper id": "2408.09972",
        "abstract url": "https://arxiv.org/abs/2408.09972",
        "title": "Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Integrating large language models (LLMs) into autonomous driving enhances personalization and adaptability in open-world scenarios. However, traditional edge computing models still face significant challenges in processing complex driving data, particularly regarding real-time performance and system efficiency. To address these challenges, this study introduces EC-Drive, a novel edge-cloud collaborative autonomous driving system with data drift detection capabilities. EC-Drive utilizes drift detection algorithms to selectively upload critical data, including new obstacles and traffic pattern changes, to the cloud for processing by GPT-4, while routine data is efficiently managed by smaller LLMs on edge devices. This approach not only reduces inference latency but also improves system efficiency by optimizing communication resource use. Experimental validation confirms the system's robust processing capabilities and practical applicability in real-world driving conditions, demonstrating the effectiveness of this edge-cloud collaboration framework. Our data and system demonstration will be released at https://sites.google.com/view/ec-drive.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10003",
        "abstract url": "https://arxiv.org/abs/2408.10003",
        "title": "Towards a Knowledge Graph for Models and Algorithms in Applied Mathematics",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Mathematical models and algorithms are an essential part of mathematical research data, as they are epistemically grounding numerical data. In order to represent models and algorithms as well as their relationship semantically to make this research data FAIR, two previously distinct ontologies were merged and extended, becoming a living knowledge graph. The link between the two ontologies is established by introducing computational tasks, as they occur in modeling, corresponding to algorithmic tasks. Moreover, controlled vocabularies are incorporated and a new class, distinguishing base quantities from specific use case quantities, was introduced. Also, both models and algorithms can now be enriched with metadata. Subject-specific metadata is particularly relevant here, such as the symmetry of a matrix or the linearity of a mathematical model. This is the only way to express specific workflows with concrete models and algorithms, as the feasible solution algorithm can only be determined if the mathematical properties of a model are known. We demonstrate this using two examples from different application areas of applied mathematics. In addition, we have already integrated over 250 research assets from applied mathematics into our knowledge graph.",
        "subjects": [
            "cs.AI",
            "cs.DL"
        ],
        "comment": "Preprint submitted to the 18th International Conference on Metadata and Semantics Research 2024"
    },
    {
        "paper id": "2408.10015",
        "abstract url": "https://arxiv.org/abs/2408.10015",
        "title": "Deterministic Policy Gradient Primal-Dual Methods for Continuous-Space Constrained MDPs",
        "rating": "-0.5",
        "keywords": [
            [
                "robot",
                "navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We study the problem of computing deterministic optimal policies for constrained Markov decision processes (MDPs) with continuous state and action spaces, which are widely encountered in constrained dynamical systems. Designing deterministic policy gradient methods in continuous state and action spaces is particularly challenging due to the lack of enumerable state-action pairs and the adoption of deterministic policies, hindering the application of existing policy gradient methods for constrained MDPs. To this end, we develop a deterministic policy gradient primal-dual method to find an optimal deterministic policy with non-asymptotic convergence. Specifically, we leverage regularization of the Lagrangian of the constrained MDP to propose a deterministic policy gradient primal-dual (D-PGPD) algorithm that updates the deterministic policy via a quadratic-regularized gradient ascent step and the dual variable via a quadratic-regularized gradient descent step. We prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair. We instantiate D-PGPD with function approximation and prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair, up to a function approximation error. Furthermore, we demonstrate the effectiveness of our method in two continuous control problems: robot navigation and fluid control. To the best of our knowledge, this appears to be the first work that proposes a deterministic policy search method for continuous-space constrained MDPs.",
        "subjects": [
            "cs.AI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10018",
        "abstract url": "https://arxiv.org/abs/2408.10018",
        "title": "\"EBK\" : Leveraging Crowd-Sourced Social Media Data to Quantify How Hyperlocal Gang Affiliations Shape Personal Networks and Violence in Chicago's Contemporary Southside",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Recent ethnographic research reveals that gang dynamics in Chicago's Southside have evolved with decentralized micro-gang \"set\" factions and cross-gang interpersonal networks marking the contemporary landscape. However, standard police datasets lack the depth to analyze gang violence with such granularity. To address this, we employed a natural language processing strategy to analyze text from a Chicago gangs message board. By identifying proper nouns, probabilistically linking them to gang sets, and assuming social connections among names mentioned together, we created a social network dataset of 271 individuals across 11 gang sets. Using Louvain community detection, we found that these individuals often connect with gang-affiliated peers from various gang sets that are physically proximal. Hierarchical logistic regression revealed that individuals with ties to homicide victims and central positions in the overall gang network were at increased risk of victimization, regardless of gang affiliation. This research demonstrates that utilizing crowd-sourced information online can enable the study of otherwise inaccessible topics and populations.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "24 pages, 5 figures"
    },
    {
        "paper id": "2408.10031",
        "abstract url": "https://arxiv.org/abs/2408.10031",
        "title": "Dynamic Label Injection for Imbalanced Industrial Defect Segmentation",
        "rating": "-0.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "In this work, we propose a simple yet effective method to tackle the problem of imbalanced multi-class semantic segmentation in deep learning systems. One of the key properties for a good training set is the balancing among the classes. When the input distribution is heavily imbalanced in the number of instances, the learning process could be hindered or difficult to carry on. To this end, we propose a Dynamic Label Injection (DLI) algorithm to impose a uniform distribution in the input batch. Our algorithm computes the current batch defect distribution and re-balances it by transferring defects using a combination of Poisson-based seamless image cloning and cut-paste techniques. A thorough experimental section on the Magnetic Tiles dataset shows better results of DLI compared to other balancing loss approaches also in the challenging weakly-supervised setup. The code is available at https://github.com/covisionlab/dynamic-label-injection.git",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024 VISION Workshop"
    },
    {
        "paper id": "2408.10073",
        "abstract url": "https://arxiv.org/abs/2408.10073",
        "title": "Modelling the Distribution of Human Motion for Sign Language Assessment",
        "rating": "-0.5",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Sign Language Assessment (SLA) tools are useful to aid in language learning and are underdeveloped. Previous work has focused on isolated signs or comparison against a single reference video to assess Sign Languages (SL). This paper introduces a novel SLA tool designed to evaluate the comprehensibility of SL by modelling the natural distribution of human motion. We train our pipeline on data from native signers and evaluate it using SL learners. We compare our results to ratings from a human raters study and find strong correlation between human ratings and our tool. We visually demonstrate our tools ability to detect anomalous results spatio-temporally, providing actionable feedback to aid in SL learning and assessment.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to Twelfth International Workshop on Assistive Computer Vision and Robotics at ECCV 2024"
    },
    {
        "paper id": "2408.10084",
        "abstract url": "https://arxiv.org/abs/2408.10084",
        "title": "TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking and Graph-Cut Optimization",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Density-based clustering methods by mode-seeking usually achieve clustering by using local density estimation to mine structural information, such as local dependencies from lower density points to higher neighbors. However, they often rely too heavily on \\emph{local} structures and neglect \\emph{global} characteristics, which can lead to significant errors in peak selection and dependency establishment. Although introducing more hyperparameters that revise dependencies can help mitigate this issue, tuning them is challenging and even impossible on real-world datasets. In this paper, we propose a new algorithm (TANGO) to establish local dependencies by exploiting a global-view \\emph{typicality} of points, which is obtained by mining further the density distributions and initial dependencies. TANGO then obtains sub-clusters with the help of the adjusted dependencies, and characterizes the similarity between sub-clusters by incorporating path-based connectivity. It achieves final clustering by employing graph-cut on sub-clusters, thus avoiding the challenging selection of cluster centers. Moreover, this paper provides theoretical analysis and an efficient method for the calculation of typicality. Experimental results on several synthetic and $16$ real-world datasets demonstrate the effectiveness and superiority of TANGO.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10088",
        "abstract url": "https://arxiv.org/abs/2408.10088",
        "title": "Recent Surge in Public Interest in Transportation: Sentiment Analysis of Baidu Apollo Go Using Weibo Data",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Urban mobility and transportation systems have been profoundly transformed by the advancement of autonomous vehicle technologies. Baidu Apollo Go, a pioneer robotaxi service from the Chinese tech giant Baidu, has recently been widely deployed in major cities like Beijing and Wuhan, sparking increased conversation and offering a glimpse into the future of urban mobility. This study investigates public attitudes towards Apollo Go across China using Sentiment Analysis with a hybrid BERT model on 36,096 Weibo posts from January to July 2024. The analysis shows that 89.56\\% of posts related to Apollo Go are clustered in July. From January to July, public sentiment was mostly positive, but negative comments began to rise after it became a hot topic on July 21. Spatial analysis indicates a strong correlation between provinces with high discussion intensity and those where Apollo Go operates. Initially, Hubei and Guangdong dominated online posting volume, but by July, Guangdong, Beijing, and international regions had overtaken Hubei. Attitudes varied significantly among provinces, with Xinjiang and Qinghai showing optimism and Tibet and Gansu expressing concerns about the impact on traditional taxi services. Sentiment analysis revealed that positive comments focused on technology applications and personal experiences, while negative comments centered on job displacement and safety concerns. In summary, this study highlights the divergence in public perceptions of autonomous ride-hailing services, providing valuable insights for planners, policymakers, and service providers. The model is published on Hugging Face at https://huggingface.co/wsqstar/bert-finetuned-weibo-luobokuaipao and the repository on GitHub at https://github.com/GIStudio/trb2024.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10090",
        "abstract url": "https://arxiv.org/abs/2408.10090",
        "title": "Federated Frank-Wolfe Algorithm",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) has gained a lot of attention in recent years for building privacy-preserving collaborative learning systems. However, FL algorithms for constrained machine learning problems are still limited, particularly when the projection step is costly. To this end, we propose a Federated Frank-Wolfe Algorithm (FedFW). FedFW features data privacy, low per-iteration cost, and communication of sparse signals. In the deterministic setting, FedFW achieves an $\\varepsilon$-suboptimal solution within $O(\\varepsilon^{-2})$ iterations for smooth and convex objectives, and $O(\\varepsilon^{-3})$ iterations for smooth but non-convex objectives. Furthermore, we present a stochastic variant of FedFW and show that it finds a solution within $O(\\varepsilon^{-3})$ iterations in the convex setting. We demonstrate the empirical performance of FedFW on several machine learning tasks.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases"
    },
    {
        "paper id": "2408.10136",
        "abstract url": "https://arxiv.org/abs/2408.10136",
        "title": "Robust spectral clustering with rank statistics",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper analyzes the statistical performance of a robust spectral clustering method for latent structure recovery in noisy data matrices. We consider eigenvector-based clustering applied to a matrix of nonparametric rank statistics that is derived entrywise from the raw, original data matrix. This approach is robust in the sense that, unlike traditional spectral clustering procedures, it can provably recover population-level latent block structure even when the observed data matrix includes heavy-tailed entries and has a heterogeneous variance profile. Our main theoretical contributions are threefold and hold under flexible data generating conditions. First, we establish that robust spectral clustering with rank statistics can consistently recover latent block structure, viewed as communities of nodes in a graph, in the sense that unobserved community memberships for all but a vanishing fraction of nodes are correctly recovered with high probability when the data matrix is large. Second, we refine the former result and further establish that, under certain conditions, the community membership of any individual, specified node of interest can be asymptotically exactly recovered with probability tending to one in the large-data limit. Third, we establish asymptotic normality results associated with the truncated eigenstructure of matrices whose entries are rank statistics, made possible by synthesizing contemporary entrywise matrix perturbation analysis with the classical nonparametric theory of so-called simple linear rank statistics. Collectively, these results demonstrate the statistical utility of rank-based data transformations when paired with spectral techniques for dimensionality reduction. Additionally, for a dataset of human connectomes, our approach yields parsimonious dimensionality reduction and improved recovery of ground-truth neuroanatomical cluster structure.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.ME"
        ],
        "comment": "82 pages, 8 figures, 1 table"
    },
    {
        "paper id": "2408.10175",
        "abstract url": "https://arxiv.org/abs/2408.10175",
        "title": "Fairness Under Cover: Evaluating the Impact of Occlusions on Demographic Bias in Facial Recognition",
        "rating": "-0.5",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This study investigates the effects of occlusions on the fairness of face recognition systems, particularly focusing on demographic biases. Using the Racial Faces in the Wild (RFW) dataset and synthetically added realistic occlusions, we evaluate their effect on the performance of face recognition models trained on the BUPT-Balanced and BUPT-GlobalFace datasets. We note increases in the dispersion of FMR, FNMR, and accuracy alongside decreases in fairness according to Equilized Odds, Demographic Parity, STD of Accuracy, and Fairness Discrepancy Rate. Additionally, we utilize a pixel attribution method to understand the importance of occlusions in model predictions, proposing a new metric, Face Occlusion Impact Ratio (FOIR), that quantifies the extent to which occlusions affect model performance across different demographic groups. Our results indicate that occlusions exacerbate existing demographic biases, with models placing higher importance on occlusions in an unequal fashion, particularly affecting African individuals more severely.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted at ECCV Workshop FAILED"
    },
    {
        "paper id": "2408.10195",
        "abstract url": "https://arxiv.org/abs/2408.10195",
        "title": "SpaRP: Fast 3D Object Reconstruction and Pose Estimation from Sparse Views",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Open-world 3D generation has recently attracted considerable attention. While many single-image-to-3D methods have yielded visually appealing outcomes, they often lack sufficient controllability and tend to produce hallucinated regions that may not align with users' expectations. In this paper, we explore an important scenario in which the input consists of one or a few unposed 2D images of a single object, with little or no overlap. We propose a novel method, SpaRP, to reconstruct a 3D textured mesh and estimate the relative camera poses for these sparse-view images. SpaRP distills knowledge from 2D diffusion models and finetunes them to implicitly deduce the 3D spatial relationships between the sparse views. The diffusion model is trained to jointly predict surrogate representations for camera poses and multi-view images of the object under known poses, integrating all information from the input sparse views. These predictions are then leveraged to accomplish 3D reconstruction and pose estimation, and the reconstructed 3D model can be used to further refine the camera poses of input views. Through extensive experiments on three datasets, we demonstrate that our method not only significantly outperforms baseline methods in terms of 3D reconstruction quality and pose prediction accuracy but also exhibits strong efficiency. It requires only about 20 seconds to produce a textured mesh and camera poses for the input views. Project page: https://chaoxu.xyz/sparp.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2408.10205",
        "abstract url": "https://arxiv.org/abs/2408.10205",
        "title": "KAN 2.0: Kolmogorov-Arnold Networks Meet Science",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "A major challenge of AI + Science lies in their inherent incompatibility: today's AI is primarily based on connectionism, while science depends on symbolism. To bridge the two worlds, we propose a framework to seamlessly synergize Kolmogorov-Arnold Networks (KANs) and science. The framework highlights KANs' usage for three aspects of scientific discovery: identifying relevant features, revealing modular structures, and discovering symbolic formulas. The synergy is bidirectional: science to KAN (incorporating scientific knowledge into KANs), and KAN to science (extracting scientific insights from KANs). We highlight major new functionalities in the pykan package: (1) MultKAN: KANs with multiplication nodes. (2) kanpiler: a KAN compiler that compiles symbolic formulas into KANs. (3) tree converter: convert KANs (or any neural networks) to tree graphs. Based on these tools, we demonstrate KANs' capability to discover various types of physical laws, including conserved quantities, Lagrangians, symmetries, and constitutive laws.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.comp-ph",
            "physics.data-an"
        ],
        "comment": "27 pages, 14 figures"
    },
    {
        "paper id": "2408.10334",
        "abstract url": "https://arxiv.org/abs/2408.10334",
        "title": "A Disguised Wolf Is More Harmful Than a Toothless Tiger: Adaptive Malicious Code Injection Backdoor Attack Leveraging User Behavior as Triggers",
        "rating": "-0.5",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In recent years, large language models (LLMs) have made significant progress in the field of code generation. However, as more and more users rely on these models for software development, the security risks associated with code generation models have become increasingly significant. Studies have shown that traditional deep learning robustness issues also negatively impact the field of code generation. In this paper, we first present the game-theoretic model that focuses on security issues in code generation scenarios. This framework outlines possible scenarios and patterns where attackers could spread malicious code models to create security threats. We also pointed out for the first time that the attackers can use backdoor attacks to dynamically adjust the timing of malicious code injection, which will release varying degrees of malicious code depending on the skill level of the user. Through extensive experiments on leading code generation models, we validate our proposed game-theoretic model and highlight the significant threats that these new attack scenarios pose to the safe use of code models.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10381",
        "abstract url": "https://arxiv.org/abs/2408.10381",
        "title": "Efficient Reinforcement Learning in Probabilistic Reward Machines",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we study reinforcement learning in Markov Decision Processes with Probabilistic Reward Machines (PRMs), a form of non-Markovian reward commonly found in robotics tasks. We design an algorithm for PRMs that achieves a regret bound of $\\widetilde{O}(\\sqrt{HOAT} + H^2O^2A^{3/2} + H\\sqrt{T})$, where $H$ is the time horizon, $O$ is the number of observations, $A$ is the number of actions, and $T$ is the number of time-steps. This result improves over the best-known bound, $\\widetilde{O}(H\\sqrt{OAT})$ of \\citet{pmlr-v206-bourel23a} for MDPs with Deterministic Reward Machines (DRMs), a special case of PRMs. When $T \\geq H^3O^3A^2$ and $OA \\geq H$, our regret bound leads to a regret of $\\widetilde{O}(\\sqrt{HOAT})$, which matches the established lower bound of $\u03a9(\\sqrt{HOAT})$ for MDPs with DRMs up to a logarithmic factor. To the best of our knowledge, this is the first efficient algorithm for PRMs. Additionally, we present a new simulation lemma for non-Markovian rewards, which enables reward-free exploration for any non-Markovian reward given access to an approximate planner. Complementing our theoretical findings, we show through extensive experiment evaluations that our algorithm indeed outperforms prior methods in various PRM environments.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "33 pages, 4 figures"
    },
    {
        "paper id": "2408.10436",
        "abstract url": "https://arxiv.org/abs/2408.10436",
        "title": "Learning Regularization for Graph Inverse Problems",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, Graph Neural Networks (GNNs) have been utilized for various applications ranging from drug discovery to network design and social networks. In many applications, it is impossible to observe some properties of the graph directly; instead, noisy and indirect measurements of these properties are available. These scenarios are coined as Graph Inverse Problems (GRIP). In this work, we introduce a framework leveraging GNNs to solve GRIPs. The framework is based on a combination of likelihood and prior terms, which are used to find a solution that fits the data while adhering to learned prior information. Specifically, we propose to combine recent deep learning techniques that were developed for inverse problems, together with GNN architectures, to formulate and solve GRIP. We study our approach on a number of representative problems that demonstrate the effectiveness of the framework.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10456",
        "abstract url": "https://arxiv.org/abs/2408.10456",
        "title": "Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Differentially private stochastic gradient descent (DP-SGD) has been instrumental in privately training deep learning models by providing a framework to control and track the privacy loss incurred during training. At the core of this computation lies a subsampling method that uses a privacy amplification lemma to enhance the privacy guarantees provided by the additive noise. Fixed size subsampling is appealing for its constant memory usage, unlike the variable sized minibatches in Poisson subsampling. It is also of interest in addressing class imbalance and federated learning. However, the current computable guarantees for fixed-size subsampling are not tight and do not consider both add/remove and replace-one adjacency relationships. We present a new and holistic R{\u00e9}nyi differential privacy (RDP) accountant for DP-SGD with fixed-size subsampling without replacement (FSwoR) and with replacement (FSwR). For FSwoR we consider both add/remove and replace-one adjacency. Our FSwoR results improves on the best current computable bound by a factor of $4$. We also show for the first time that the widely-used Poisson subsampling and FSwoR with replace-one adjacency have the same privacy to leading order in the sampling probability. Accordingly, our work suggests that FSwoR is often preferable to Poisson subsampling due to constant memory usage. Our FSwR accountant includes explicit non-asymptotic upper and lower bounds and, to the authors' knowledge, is the first such analysis of fixed-size RDP with replacement for DP-SGD. We analytically and empirically compare fixed size and Poisson subsampling, and show that DP-SGD gradients in a fixed-size subsampling regime exhibit lower variance in practice in addition to memory usage benefits.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "39 pages, 10 figures"
    },
    {
        "paper id": "2408.10463",
        "abstract url": "https://arxiv.org/abs/2408.10463",
        "title": "Adversarial training of Keyword Spotting to Minimize TTS Data Overfitting",
        "rating": "-0.5",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "The keyword spotting (KWS) problem requires large amounts of real speech training data to achieve high accuracy across diverse populations. Utilizing large amounts of text-to-speech (TTS) synthesized data can reduce the cost and time associated with KWS development. However, TTS data may contain artifacts not present in real speech, which the KWS model can exploit (overfit), leading to degraded accuracy on real speech. To address this issue, we propose applying an adversarial training method to prevent the KWS model from learning TTS-specific features when trained on large amounts of TTS data. Experimental results demonstrate that KWS model accuracy on real speech data can be improved by up to 12% when adversarial loss is used in addition to the original KWS loss. Surprisingly, we also observed that the adversarial setup improves accuracy by up to 8%, even when trained solely on TTS and real negative speech data, without any real positive examples.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "to be published in a Workshop at Interspeech 2024, Synthetic Data's Transformative Role in Foundational Speech Models"
    },
    {
        "paper id": "2408.10464",
        "abstract url": "https://arxiv.org/abs/2408.10464",
        "title": "Improved Community Detection using Stochastic Block Models",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Community detection approaches resolve complex networks into smaller groups (communities) that are expected to be relatively edge-dense and well-connected. The stochastic block model (SBM) is one of several approaches used to uncover community structure in graphs. In this study, we demonstrate that SBM software applied to various real-world and synthetic networks produces poorly-connected to disconnected clusters. We present simple modifications to improve the connectivity of SBM clusters, and show that the modifications improve accuracy using simulated networks.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10492",
        "abstract url": "https://arxiv.org/abs/2408.10492",
        "title": "Is the Lecture Engaging for Learning? Lecture Voice Sentiment Analysis for Knowledge Graph-Supported Intelligent Lecturing Assistant (ILA) System",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces an intelligent lecturing assistant (ILA) system that utilizes a knowledge graph to represent course content and optimal pedagogical strategies. The system is designed to support instructors in enhancing student learning through real-time analysis of voice, content, and teaching methods. As an initial investigation, we present a case study on lecture voice sentiment analysis, in which we developed a training set comprising over 3,000 one-minute lecture voice clips. Each clip was manually labeled as either engaging or non-engaging. Utilizing this dataset, we constructed and evaluated several classification models based on a variety of features extracted from the voice clips. The results demonstrate promising performance, achieving an F1-score of 90% for boring lectures on an independent set of over 800 test voice clips. This case study lays the groundwork for the development of a more sophisticated model that will integrate content analysis and pedagogical practices. Our ultimate goal is to aid instructors in teaching more engagingly and effectively by leveraging modern artificial intelligence techniques.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10493",
        "abstract url": "https://arxiv.org/abs/2408.10493",
        "title": "Clustering by Mining Density Distributions and Splitting Manifold Structure",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spectral clustering requires the time-consuming decomposition of the Laplacian matrix of the similarity graph, thus limiting its applicability to large datasets. To improve the efficiency of spectral clustering, a top-down approach was recently proposed, which first divides the data into several micro-clusters (granular-balls), then splits these micro-clusters when they are not \"compact'', and finally uses these micro-clusters as nodes to construct a similarity graph for more efficient spectral clustering. However, this top-down approach is challenging to adapt to unevenly distributed or structurally complex data. This is because constructing micro-clusters as a rough ball struggles to capture the shape and structure of data in a local range, and the simplistic splitting rule that solely targets ``compactness'' is susceptible to noise and variations in data density and leads to micro-clusters with varying shapes, making it challenging to accurately measure the similarity between them. To resolve these issues, this paper first proposes to start from local structures to obtain micro-clusters, such that the complex structural information inside local neighborhoods is well captured by them. Moreover, by noting that Euclidean distance is more suitable for convex sets, this paper further proposes a data splitting rule that couples local density and data manifold structures, so that the similarities of the obtained micro-clusters can be easily characterized. A novel similarity measure between micro-clusters is then proposed for the final spectral clustering. A series of experiments based on synthetic and real-world datasets demonstrate that the proposed method has better adaptability to structurally complex data than granular-ball based methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10517",
        "abstract url": "https://arxiv.org/abs/2408.10517",
        "title": "Integrating Multi-Modal Input Token Mixer Into Mamba-Based Decision Models: Decision MetaMamba",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Return-Conditioned Transformer Decision Models (RCTDM) have demonstrated the potential to enhance transformer performance in offline reinforcement learning by replacing rewards in the input sequence with returns-to-go. However, to achieve the goal of learning an optimal policy from offline datasets composed of limited suboptimal trajectories, RCTDM required alternative methods. One prominent approach, trajectory stitching, was designed to enable the network to combine multiple trajectories to find the optimal path. To implement this using only transformers without auxiliary networks, it was necessary to shorten the input sequence length to better capture the Markov property in reinforcement learnings. This, however, introduced a trade-off, as it reduced the accuracy of action inference. Our study introduces a model named Decision MetaMamba to resolve these challenges. DMM employs an input token mixer to extract patterns from short sequences and uses a State Space Model (SSM) to selectively combine information from relatively distant sequences. Inspired by Metaformer, this structure was developed by transforming Mamba's input layer into various multi-modal layers. Fortunately, with the advent of Mamba, implemented using parallel selective scanning, we achieved a high-performance sequence model capable of replacing transformers. Based on these innovations, DMM demonstrated excellent performance across various datasets in offline RL, confirming that models using SSM can improve performance by domain-specific alterations of the input layer. Additionally, it maintained its performance even in lightweight models with fewer parameters. These results suggest that decision models based on SSM can pave the way for improved outcomes in future developments.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09715",
        "abstract url": "https://arxiv.org/abs/2408.09715",
        "title": "HYDEN: Hyperbolic Density Representations for Medical Images and Reports",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In light of the inherent entailment relations between images and text, hyperbolic point vector embeddings, leveraging the hierarchical modeling advantages of hyperbolic space, have been utilized for visual semantic representation learning. However, point vector embedding approaches fail to address the issue of semantic uncertainty, where an image may have multiple interpretations, and text may refer to different images, a phenomenon particularly prevalent in the medical domain. Therefor, we propose \\textbf{HYDEN}, a novel hyperbolic density embedding based image-text representation learning approach tailored for specific medical domain data. This method integrates text-aware local features alongside global features from images, mapping image-text features to density features in hyperbolic space via using hyperbolic pseudo-Gaussian distributions. An encapsulation loss function is employed to model the partial order relations between image-text density distributions. Experimental results demonstrate the interpretability of our approach and its superior performance compared to the baseline methods across various zero-shot tasks and different datasets.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09719",
        "abstract url": "https://arxiv.org/abs/2408.09719",
        "title": "Work-Efficient Parallel Counting via Sampling",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "We study the problem of estimating the partition function $Z(\u03b2) = \\sum_{x \\in \u03a9} \\exp[-\u03b2\\cdot H(x)]$ of a Gibbs distribution defined by a Hamiltonian $H(\\cdot)$. It is well known that the partition function $Z(\u03b2)$ can be well approximated by the simulated annealing method, assuming a sampling oracle that can generate samples according to the Gibbs distribution of any given inverse temperature $\u03b2$. This method yields the most efficient reductions from counting to sampling, including: $\\bullet$ classic non-adaptive (parallel) algorithms with sub-optimal cost [DFK89; Bez+08]; $\\bullet$ adaptive (sequential) algorithms with near-optimal cost [SVV09; Hub15; Kol18; HK23]. In this paper, we give an algorithm that achieves efficiency in both parallelism and total work. Specifically, it provides a reduction from counting to sampling using near-optimal total work and logarithmic depth of computation. Consequently, it gives work-efficient parallel counting algorithms for several important models, including the hardcore and Ising models in the uniqueness regime.",
        "subjects": [
            "cs.DS",
            "cs.CC",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09743",
        "abstract url": "https://arxiv.org/abs/2408.09743",
        "title": "R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "X-ray"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Inspired by the tremendous success of Large Language Models (LLMs), existing X-ray medical report generation methods attempt to leverage large models to achieve better performance. They usually adopt a Transformer to extract the visual features of a given X-ray image, and then, feed them into the LLM for text generation. How to extract more effective information for the LLMs to help them improve final results is an urgent problem that needs to be solved. Additionally, the use of visual Transformer models also brings high computational complexity. To address these issues, this paper proposes a novel context-guided efficient X-ray medical report generation framework. Specifically, we introduce the Mamba as the vision backbone with linear complexity, and the performance obtained is comparable to that of the strong Transformer model. More importantly, we perform context retrieval from the training set for samples within each mini-batch during the training phase, utilizing both positively and negatively related samples to enhance feature representation and discriminative learning. Subsequently, we feed the vision tokens, context information, and prompt statements to invoke the LLM for generating high-quality medical reports. Extensive experiments on three X-ray report generation datasets (i.e., IU-Xray, MIMIC-CXR, CheXpert Plus) fully validated the effectiveness of our proposed model. The source code of this work will be released on \\url{https://github.com/Event-AHU/Medical_Image_Analysis}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "In Peer Review"
    },
    {
        "paper id": "2408.09746",
        "abstract url": "https://arxiv.org/abs/2408.09746",
        "title": "Enhanced Cascade Prostate Cancer Classifier in mp-MRI Utilizing Recall Feedback Adaptive Loss and Prior Knowledge-Based Feature Extraction",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "MRI",
                "Cancer",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Prostate cancer is the second most common cancer in males worldwide, and mpMRI is commonly used for diagnosis. However, interpreting mpMRI is challenging and requires expertise from radiologists. This highlights the urgent need for automated grading in mpMRI. Existing studies lack integration of clinical prior information and suffer from uneven training sample distribution due to prevalence. Therefore, we propose a solution that incorporates prior knowledge, addresses the issue of uneven medical sample distribution, and maintains high interpretability in mpMRI. Firstly, we introduce Prior Knowledge-Based Feature Extraction, which mathematically models the PI-RADS criteria for prostate cancer as diagnostic information into model training. Secondly, we propose Adaptive Recall Feedback Loss to address the extremely imbalanced data problem. This method adjusts the training dynamically based on accuracy and recall in the validation set, resulting in high accuracy and recall simultaneously in the testing set.Thirdly, we design an Enhanced Cascade Prostate Cancer Classifier that classifies prostate cancer into different levels in an interpretable way, which refines the classification results and helps with clinical intervention. Our method is validated through experiments on the PI-CAI dataset and outperforms other methods with a more balanced result in both accuracy and recall rate.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09757",
        "abstract url": "https://arxiv.org/abs/2408.09757",
        "title": "Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning",
        "rating": "-1",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Recent studies highlight the effectiveness of using in-context learning (ICL) to steer large language models (LLMs) in processing tabular data, a challenging task given the structured nature of such data. Despite advancements in performance, the fairness implications of these methods are less understood. This study investigates how varying demonstrations within ICL prompts influence the fairness outcomes of LLMs. Our findings reveal that deliberately including minority group samples in prompts significantly boosts fairness without sacrificing predictive accuracy. Further experiments demonstrate that the proportion of minority to majority samples in demonstrations affects the trade-off between fairness and prediction accuracy. Based on these insights, we introduce a mitigation technique that employs clustering and evolutionary strategies to curate a diverse and representative sample set from the training data. This approach aims to enhance both predictive performance and fairness in ICL applications. Experimental results validate that our proposed method dramatically improves fairness across various metrics, showing its efficacy in real-world scenarios.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09769",
        "abstract url": "https://arxiv.org/abs/2408.09769",
        "title": "Integrating Naturalistic Insights in Objective Multi-Vehicle Safety Framework",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "As autonomous vehicle technology advances, the precise assessment of safety in complex traffic scenarios becomes crucial, especially in mixed-vehicle environments where human perception of safety must be taken into account. This paper presents a framework designed for assessing traffic safety in multi-vehicle situations, facilitating the simultaneous utilization of diverse objective safety metrics. Additionally, it allows the integration of subjective perception of safety by adjusting model parameters. The framework was applied to evaluate various model configurations in car-following scenarios on a highway, utilizing naturalistic driving datasets. The evaluation of the model showed an outstanding performance, particularly when integrating multiple objective safety measures. Furthermore, the performance was significantly enhanced when considering all surrounding vehicles.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09788",
        "abstract url": "https://arxiv.org/abs/2408.09788",
        "title": "Simplicial complexes in network intrusion profiling",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "For studying intrusion detection data we consider data points referring to individual IP addresses and their connections: We build networks associated with those data points, such that vertices in a graph are associated via the respective IP addresses, with the key property that attacked data points are part of the structure of the network. More precisely, we propose a novel approach using simplicial complexes to model the desired network and the respective intrusions in terms of simplicial attributes thus generalizing previous graph-based approaches. Adapted network centrality measures related to simplicial complexes yield so-called patterns associated to vertices, which themselves contain a set of features. These are then used to describe the attacked or the attacker vertices, respectively. Comparing this new strategy with classical concepts demonstrates the advantages of the presented approach using simplicial features for detecting and characterizing intrusions.",
        "subjects": [
            "math.AC",
            "cs.CR"
        ],
        "comment": "20 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2408.09833",
        "abstract url": "https://arxiv.org/abs/2408.09833",
        "title": "Automated Vehicle Driver Monitoring Dataset from Real-World Scenarios",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving",
                "Vehicle"
            ]
        ],
        "abstract": "From SAE Level 3 of automation onwards, drivers are allowed to engage in activities that are not directly related to driving during their travel. However, in level 3, a misunderstanding of the capabilities of the system might lead drivers to engage in secondary tasks, which could impair their ability to react to challenging traffic situations. Anticipating driver activity allows for early detection of risky behaviors, to prevent accidents. To be able to predict the driver activity, a Deep Learning network needs to be trained on a dataset. However, the use of datasets based on simulation for training and the migration to real-world data for prediction has proven to be suboptimal. Hence, this paper presents a real-world driver activity dataset, openly accessible on IEEE Dataport, which encompasses various activities that occur in autonomous driving scenarios under various illumination and weather conditions. Results from the training process showed that the dataset provides an excellent benchmark for implementing models for driver activity recognition.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2408.09839",
        "abstract url": "https://arxiv.org/abs/2408.09839",
        "title": "Segment-Anything Models Achieve Zero-shot Robustness in Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Semantic segmentation is a significant perception task in autonomous driving. It suffers from the risks of adversarial examples. In the past few years, deep learning has gradually transitioned from convolutional neural network (CNN) models with a relatively small number of parameters to foundation models with a huge number of parameters. The segment-anything model (SAM) is a generalized image segmentation framework that is capable of handling various types of images and is able to recognize and segment arbitrary objects in an image without the need to train on a specific object. It is a unified model that can handle diverse downstream tasks, including semantic segmentation, object detection, and tracking. In the task of semantic segmentation for autonomous driving, it is significant to study the zero-shot adversarial robustness of SAM. Therefore, we deliver a systematic empirical study on the robustness of SAM without additional training. Based on the experimental results, the zero-shot adversarial robustness of the SAM under the black-box corruptions and white-box adversarial attacks is acceptable, even without the need for additional training. The finding of this study is insightful in that the gigantic model parameters and huge amounts of training data lead to the phenomenon of emergence, which builds a guarantee of adversarial robustness. SAM is a vision foundation model that can be regarded as an early prototype of an artificial general intelligence (AGI) pipeline. In such a pipeline, a unified model can handle diverse tasks. Therefore, this research not only inspects the impact of vision foundation models on safe autonomous driving but also provides a perspective on developing trustworthy AGI. The code is available at: https://github.com/momo1986/robust_sam_iv.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted to IAVVC 2024"
    },
    {
        "paper id": "2408.09844",
        "abstract url": "https://arxiv.org/abs/2408.09844",
        "title": "Joint Beamforming and Power Control for D2D-Assisted Integrated Sensing and Communication Networks",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Integrated sensing and communication (ISAC) is an emerging technology in next-generation communication networks. However, the communication performance of the ISAC system may be severely affected by interference from the radar system if the sensing task has demanding performance requirements. In this paper, we exploit device-to-device communication (D2D) to improve system communication capacity. The ISAC system in a single cell D2D assisted-network is investigated, where the base station (BS) performs target sensing and communication with multiple celluar user equipments (CUEs) as well as D2D user equipments (DUEs) simultaneously communicating with other DUEs by multiplexing the same frequency resource. To achieve the optimal communication performance in the D2D-assisted ISAC system, a joint beamforming and power control problem is formulated with the goal to maximize the sum rate of the system while guaranteeing the performance requirements of radar sensing. Due to the non-convexity of the problem, we propose the algorithm to transform the origin problem into a relaxation form and obtain the solution. We also proposed the zero-forcing (ZF) beamforming scheme to acquire the solution that can eliminate the interference of the BS on DUEs. Extensive numerical simulations demonstrated that with the assistance of the D2D communications, our proposed algorithm significantly outperforms the baseline schemes in the system sum rate.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09851",
        "abstract url": "https://arxiv.org/abs/2408.09851",
        "title": "ISAC-Fi: Enabling Full-fledged Monostatic Sensing over Wi-Fi Communication",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Whereas Wi-Fi communications have been exploited for sensing purpose for over a decade, the bistatic or multistatic nature of Wi-Fi still poses multiple challenges, hampering real-life deployment of integrated sensing and communication (ISAC) within Wi-Fi framework. In this paper, we aim to re-design WiFi so that monostatic sensing (mimicking radar) can be achieved over the multistatic communication infrastructure. Specifically, we propose, design, and implement ISAC-Fi as an ISAC-ready Wi-Fi prototype. We first present a novel self-interference cancellation scheme, in order to extract reflected (radio frequency) signals for sensing purpose in the face of transmissions. We then subtly revise existing Wi-Fi framework so as to seamlessly operate monostatic sensing under Wi-Fi communication standard. Finally, we offer two ISAC-Fi designs: while a USRP-based one emulates a totally re-designed ISAC-Fi device, another plug-andplay design allows for backward compatibility by attaching an extra module to an arbitrary Wi-Fi device. We perform extensive experiments to validate the efficacy of ISAC-Fi and also to demonstrate its superiority over existing Wi-Fi sensing proposals.",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": "14 pages, 22 figures"
    },
    {
        "paper id": "2408.09878",
        "abstract url": "https://arxiv.org/abs/2408.09878",
        "title": "Transferring Backdoors between Large Language Models by Knowledge Distillation",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Backdoor Attacks have been a serious vulnerability against Large Language Models (LLMs). However, previous methods only reveal such risk in specific models, or present tasks transferability after attacking the pre-trained phase. So, how risky is the model transferability of a backdoor attack? In this paper, we focus on whether existing mini-LLMs may be unconsciously instructed in backdoor knowledge by poisoned teacher LLMs through knowledge distillation (KD). Specifically, we propose ATBA, an adaptive transferable backdoor attack, which can effectively distill the backdoor of teacher LLMs into small models when only executing clean-tuning. We first propose the Target Trigger Generation (TTG) module that filters out a set of indicative trigger candidates from the token list based on cosine similarity distribution. Then, we exploit a shadow model to imitate the distilling process and introduce an Adaptive Trigger Optimization (ATO) module to realize a gradient-based greedy feedback to search optimal triggers. Extensive experiments show that ATBA generates not only positive guidance for student models but also implicitly transfers backdoor knowledge. Our attack is robust and stealthy, with over 80% backdoor transferability, and hopes the attention of security.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "13 pages, 16 figures, 5 tables"
    },
    {
        "paper id": "2408.09883",
        "abstract url": "https://arxiv.org/abs/2408.09883",
        "title": "Sensing in NLOS: a Stroboscopic Approach",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Sensing in non-line-of-sight (NLOS) is a well-known issue that limits the effective range of radar-like sensors. Existing approaches for NLOS sensing consider the usage of either metallic mirrors, that only work under specular reflection, or dynamically-reconfigurable metasurfaces that steer the signal to cover a desired area in NLOS, with the drawback of cost and control signaling. This paper proposes a novel sensing system, that allows a source to image a desired region of interest (ROI) in NLOS, using the combination of a proper beam sweeping (by the source) as well as a passive reflection plane configured as a periodic angular deflecting function (that allows illuminating the ROI). \\textit{Stroboscopic sensing} is obtained by sweeping over a sufficiently large portion of the reflection plane, the source covers the ROI \\textit{and} enhance the spatial resolution of the image, thanks to multiple diverse observation angles of ROI. Remarkably, the proposed system achieves a near-field imaging with a sequence of far-field acquisitions, thus limiting the implementation complexity. We detail the system design criteria and trade-offs, demonstrating the remarkable benefits of such a stroboscopic sensing system, where a possibly moving source can observe a ROI through multiple points of view as if it were static.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2408.09886",
        "abstract url": "https://arxiv.org/abs/2408.09886",
        "title": "SAM-UNet:Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Segment Anything Model (SAM) has demonstrated impressive performance on a wide range of natural image segmentation tasks. However, its performance significantly deteriorates when directly applied to medical domain, due to the remarkable differences between natural images and medical images. Some researchers have attempted to train SAM on large scale medical datasets. However, poor zero-shot performance is observed from the experimental results. In this context, inspired by the superior performance of U-Net-like models in medical image segmentation, we propose SAMUNet, a new foundation model which incorporates U-Net to the original SAM, to fully leverage the powerful contextual modeling ability of convolutions. To be specific, we parallel a convolutional branch in the image encoder, which is trained independently with the vision Transformer branch frozen. Additionally, we employ multi-scale fusion in the mask decoder, to facilitate accurate segmentation of objects with different scales. We train SAM-UNet on SA-Med2D-16M, the largest 2-dimensional medical image segmentation dataset to date, yielding a universal pretrained model for medical images. Extensive experiments are conducted to evaluate the performance of the model, and state-of-the-art result is achieved, with a dice similarity coefficient score of 0.883 on SA-Med2D-16M dataset. Specifically, in zero-shot segmentation experiments, our model not only significantly outperforms previous large medical SAM models across all modalities, but also substantially mitigates the performance degradation seen on unseen modalities. It should be highlighted that SAM-UNet is an efficient and extensible foundation model, which can be further fine-tuned for other downstream tasks in medical community. The code is available at https://github.com/Hhankyangg/sam-unet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09894",
        "abstract url": "https://arxiv.org/abs/2408.09894",
        "title": "Preoperative Rotator Cuff Tear Prediction from Shoulder Radiographs using a Convolutional Block Attention Module-Integrated Neural Network",
        "rating": "-1",
        "keywords": [
            [
                "MRI"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Research question: We test whether a plane shoulder radiograph can be used together with deep learning methods to identify patients with rotator cuff tears as opposed to using an MRI in standard of care. Findings: By integrating convolutional block attention modules into a deep neural network, our model demonstrates high accuracy in detecting patients with rotator cuff tears, achieving an average AUC of 0.889 and an accuracy of 0.831. Meaning: This study validates the efficacy of our deep learning model to accurately detect rotation cuff tears from radiographs, offering a viable pre-assessment or alternative to more expensive imaging techniques such as MRI.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09899",
        "abstract url": "https://arxiv.org/abs/2408.09899",
        "title": "LCE: A Framework for Explainability of DNNs for Ultrasound Image Based on Concept Discovery",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Lesion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Explaining the decisions of Deep Neural Networks (DNNs) for medical images has become increasingly important. Existing attribution methods have difficulty explaining the meaning of pixels while existing concept-based methods are limited by additional annotations or specific model structures that are difficult to apply to ultrasound images. In this paper, we propose the Lesion Concept Explainer (LCE) framework, which combines attribution methods with concept-based methods. We introduce the Segment Anything Model (SAM), fine-tuned on a large number of medical images, for concept discovery to enable a meaningful explanation of ultrasound image DNNs. The proposed framework is evaluated in terms of both faithfulness and understandability. We point out deficiencies in the popular faithfulness evaluation metrics and propose a new evaluation metric. Our evaluation of public and private breast ultrasound datasets (BUSI and FG-US-B) shows that LCE performs well compared to commonly-used explainability methods. Finally, we also validate that LCE can consistently provide reliable explanations for more meaningful fine-grained diagnostic tasks in breast ultrasound.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09904",
        "abstract url": "https://arxiv.org/abs/2408.09904",
        "title": "Multi-layer diffusion model of photovoltaic installations",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "Nowadays, harmful effects of climate change are becoming increasingly apparent. A vital issue that must be addressed is the generation of energy from non-renewable and often polluted sources. For this reason, the development of renewable energy sources is of great importance. Unfortunately, too rapid spread of renewables can disrupt stability of the power system and lead to energy blackouts. One should not simply support it, without ensuring sustainability and understanding of the diffusion process. In this research, we propose a new agent-based model of diffusion of photovoltaic panels. It is an extension of the $q$-voter model that utilizes multi-layer network structure. The model is analyzed by Monte Carlo simulations and mean-field approximation. The impact of parameters and specifications on the basic properties of the model is discussed.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09920",
        "abstract url": "https://arxiv.org/abs/2408.09920",
        "title": "Sliced Maximal Information Coefficient: A Training-Free Approach for Image Quality Assessment Enhancement",
        "rating": "-1",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Full-reference image quality assessment (FR-IQA) models generally operate by measuring the visual differences between a degraded image and its reference. However, existing FR-IQA models including both the classical ones (eg, PSNR and SSIM) and deep-learning based measures (eg, LPIPS and DISTS) still exhibit limitations in capturing the full perception characteristics of the human visual system (HVS). In this paper, instead of designing a new FR-IQA measure, we aim to explore a generalized human visual attention estimation strategy to mimic the process of human quality rating and enhance existing IQA models. In particular, we model human attention generation by measuring the statistical dependency between the degraded image and the reference image. The dependency is captured in a training-free manner by our proposed sliced maximal information coefficient and exhibits surprising generalization in different IQA measures. Experimental results verify the performance of existing IQA models can be consistently improved when our attention module is incorporated. The source code is available at https://github.com/KANGX99/SMIC.",
        "subjects": [
            "cs.CV",
            "cs.MM",
            "eess.IV"
        ],
        "comment": "6 pages, 5 figures, accepted by ICME2024"
    },
    {
        "paper id": "2408.09949",
        "abstract url": "https://arxiv.org/abs/2408.09949",
        "title": "C${^2}$RL: Content and Context Representation Learning for Gloss-free Sign Language Translation and Retrieval",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Sign Language Representation Learning (SLRL) is crucial for a range of sign language-related downstream tasks such as Sign Language Translation (SLT) and Sign Language Retrieval (SLRet). Recently, many gloss-based and gloss-free SLRL methods have been proposed, showing promising performance. Among them, the gloss-free approach shows promise for strong scalability without relying on gloss annotations. However, it currently faces suboptimal solutions due to challenges in encoding the intricate, context-sensitive characteristics of sign language videos, mainly struggling to discern essential sign features using a non-monotonic video-text alignment strategy. Therefore, we introduce an innovative pretraining paradigm for gloss-free SLRL, called C${^2}$RL, in this paper. Specifically, rather than merely incorporating a non-monotonic semantic alignment of video and text to learn language-oriented sign features, we emphasize two pivotal aspects of SLRL: Implicit Content Learning (ICL) and Explicit Context Learning (ECL). ICL delves into the content of communication, capturing the nuances, emphasis, timing, and rhythm of the signs. In contrast, ECL focuses on understanding the contextual meaning of signs and converting them into equivalent sentences. Despite its simplicity, extensive experiments confirm that the joint optimization of ICL and ECL results in robust sign language representation and significant performance gains in gloss-free SLT and SLRet tasks. Notably, C${^2}$RL improves the BLEU-4 score by +5.3 on P14T, +10.6 on CSL-daily, +6.2 on OpenASL, and +1.3 on How2Sign. It also boosts the R@1 score by +8.3 on P14T, +14.4 on CSL-daily, and +5.9 on How2Sign. Additionally, we set a new baseline for the OpenASL dataset in the SLRet task.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09952",
        "abstract url": "https://arxiv.org/abs/2408.09952",
        "title": "Weakly Supervised Pretraining and Multi-Annotator Supervised Finetuning for Facial Wrinkle Detection",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "1. Research question: With the growing interest in skin diseases and skin aesthetics, the ability to predict facial wrinkles is becoming increasingly important. This study aims to evaluate whether a computational model, convolutional neural networks (CNN), can be trained for automated facial wrinkle segmentation. 2. Findings: Our study presents an effective technique for integrating data from multiple annotators and illustrates that transfer learning can enhance performance, resulting in dependable segmentation of facial wrinkles. 3. Meaning: This approach automates intricate and time-consuming tasks of wrinkle analysis with a deep learning framework. It could be used to facilitate skin treatments and diagnostics.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09997",
        "abstract url": "https://arxiv.org/abs/2408.09997",
        "title": "Forbidden paths and cycles in the undirected underlying graph of a 2-quasi best match graph",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The undirected underlying graph of a 2-quasi best match graph (2-qBMG) is proven not to contain any induced graph isomorphic to $P_6$ or $C_6$. This new feature allows for the investigation of 2-BMGs further by exploiting the numerous known results on $P_6$ and $C_6$ free graphs together with the available polynomial algorithms developed for their studies. In this direction, there are also some new contributions about dominating bicliques and certain vertex decompositions of the undirected underlying graph of a 2-qBMG.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "Accepted in Proceedings of the 24th International Conference on Information Technologies - Applications and Theory (ITAT 2024), Workshop on Computational Aspects of Large-Scale Problems in Discrete Mathematics (CADM)"
    },
    {
        "paper id": "2408.09999",
        "abstract url": "https://arxiv.org/abs/2408.09999",
        "title": "Gathering Semi-Synchronously Scheduled Two-State Robots",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "We study the problem \\emph{Gathering} for $n$ autonomous mobile robots in synchronous settings with a persistent memory called \\emph{light}. It is well known that Gathering is impossible in the basic model ($OBLOT$) where robots have no lights, even if the system is semi-synchronous (called SSYNCH). Gathering becomes possible, however, if each robot has a light of some type that can be set to a constant number of colors. In the $FCOM$ model, the robots can only see the lights of other robots. In the $FSTA$ model, each robot can only observe its own light. In the $LUMI$ model, all robots can see all lights. This paper focuses on $FSTA$ robots with 2-colored lights in synchronous settings. We show that 2-color $FSTA$ and $FCOM$ robots cannot solve Gathering in SSYNCH without additional conditions, even with rigid movement and agreement of chirality and the minimum moving distance. We also improve the condition of the previous gathering algorithm for $FSTA$ robots with 2-color working in SSYNCH.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "16 pages, 3 figures. arXiv admin note: text overlap with arXiv:1811.12068"
    },
    {
        "paper id": "2408.10005",
        "abstract url": "https://arxiv.org/abs/2408.10005",
        "title": "Optimal Few-GHW Linear Codes and Their Subcode Support Weight Distributions",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Few-weight codes have been constructed and studied for many years, since their fascinating relations to finite geometries, strongly regular graphs and Boolean functions. Simplex codes are one-weight Griesmer $[\\frac{q^k-1}{q-1},k ,q^{k-1}]_q$-linear codes and they meet all Griesmer bounds of the generalized Hamming weights of linear codes. All the subcodes with dimension $r$ of a $[\\frac{q^k-1}{q-1},k ,q^{k-1}]_q$-simplex code have the same subcode support weight $\\frac{q^{k-r}(q^r-1)}{q-1}$ for $1\\leq r\\leq k$. In this paper, we construct linear codes meeting the Griesmer bound of the $r$-generalized Hamming weight, such codes do not meet the Griesmer bound of the $j$-generalized Hamming weight for $1\\leq j<r$. Moreover these codes have only few subcode support weights. The weight distribution and the subcode support weight distributions of these distance-optimal codes are determined. Linear codes constructed in this paper are natural generalizations of distance-optimal few-weight codes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10014",
        "abstract url": "https://arxiv.org/abs/2408.10014",
        "title": "Improved Distance (Sensitivity) Oracles with Subquadratic Space",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A distance oracle (DO) with stretch $(\u03b1, \u03b2)$ for a graph $G$ is a data structure that, when queried with vertices $s$ and $t$, returns a value $\\widehat{d}(s,t)$ such that $d(s,t) \\le \\widehat{d}(s,t) \\le \u03b1\\cdot d(s,t) + \u03b2$. An $f$-edge fault-tolerant distance sensitivity oracle ($f$-DSO) additionally receives a set $F$ of up to $f$ edges and estimates the $s$-$t$-distance in $G{-}F$. Our first contribution is a new distance oracle with subquadratic space for undirected graphs. Introducing a small additive stretch $\u03b2> 0$ allows us to make the multiplicative stretch $\u03b1$ arbitrarily small. This sidesteps a known lower bound of $\u03b1\\ge 3$ (for $\u03b2= 0$ and subquadratic space) [Thorup & Zwick, JACM 2005]. We present a DO for graphs with edge weights in $[0,W]$ that, for any positive integer $t$ and any $c \\in (0, \\ell/2]$, has stretch $(1{+}\\frac{1}{\\ell}, 2W)$, space $\\widetilde{O}(n^{2-\\frac{c}{t}})$, and query time $O(n^c)$. These are the first subquadratic-space DOs with $(1+\u03b5, O(1))$-stretch generalizing Agarwal and Godfrey's results for sparse graphs [SODA 2013] to general undirected graphs. Our second contribution is a framework that turns a $(\u03b1,\u03b2)$-stretch DO for unweighted graphs into an $(\u03b1(1{+}\\varepsilon),\u03b2)$-stretch $f$-DSO with sensitivity $f = o(\\log(n)/\\log\\log n)$ and retains subquadratic space. This generalizes a result by Bil\u00f2, Chechik, Choudhary, Cohen, Friedrich, Krogmann, and Schirneck [STOC 2023, TheoretiCS 2024] for the special case of stretch $(3,0)$ and $f = O(1)$. By combining the framework with our new distance oracle, we obtain an $f$-DSO that, for any $\u03b3\\in (0, (\\ell{+}1)/2]$, has stretch $((1{+}\\frac{1}{\\ell}) (1{+}\\varepsilon), 2)$, space $n^{ 2- \\frac\u03b3{(\\ell+1)(f+1)} + o(1)}/\\varepsilon^{f+2}$, and query time $\\widetilde{O}(n^\u03b3 /{\\varepsilon}^2)$.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "An extended abstract of this work appeared at FOCS 2024"
    },
    {
        "paper id": "2408.10021",
        "abstract url": "https://arxiv.org/abs/2408.10021",
        "title": "Detecting Adversarial Attacks in Semantic Segmentation via Uncertainty Estimation: A Deep Analysis",
        "rating": "-1",
        "keywords": [
            [
                "automated driving"
            ],
            [
                "Attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural networks have demonstrated remarkable effectiveness across a wide range of tasks such as semantic segmentation. Nevertheless, these networks are vulnerable to adversarial attacks that add imperceptible perturbations to the input image, leading to false predictions. This vulnerability is particularly dangerous in safety-critical applications like automated driving. While adversarial examples and defense strategies are well-researched in the context of image classification, there is comparatively less research focused on semantic segmentation. Recently, we have proposed an uncertainty-based method for detecting adversarial attacks on neural networks for semantic segmentation. We observed that uncertainty, as measured by the entropy of the output distribution, behaves differently on clean versus adversely perturbed images, and we utilize this property to differentiate between the two. In this extended version of our work, we conduct a detailed analysis of uncertainty-based detection of adversarial attacks including a diverse set of adversarial attacks and various state-of-the-art neural networks. Our numerical experiments show the effectiveness of the proposed uncertainty-based detection method, which is lightweight and operates as a post-processing step, i.e., no model modifications or knowledge of the adversarial example generation process are required.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10043",
        "abstract url": "https://arxiv.org/abs/2408.10043",
        "title": "Stacked Intelligent Metasurfaces for Integrated Sensing and Communications",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Stacked intelligent metasurfaces (SIM) have recently emerged as a promising technology, which can realize transmit precoding in the wave domain. In this paper, we investigate a SIM-aided integrated sensing and communications system, in which SIM is capable of generating a desired beam pattern for simultaneously communicating with multiple downlink users and detecting a radar target. Specifically, we formulate an optimization problem of maximizing the spectrum efficiency, while satisfying the power constraint of the desired direction. This requires jointly designing the phase shifts of the SIM and the power allocation at the base station. By incorporating the sensing power constraint into the objective functions as a penalty term, we further simplify the optimization problem and solve it by customizing an efficient gradient ascent algorithm. Finally, extensive numerical results demonstrate the effectiveness of the proposed wave-domain precoder for automatically mitigating the inter-user interference and generating a desired beampattern for the sensing task, as multiple separate data streams transmit through the SIM.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "15 pages, 5 figures, accepted by IEEE WCL"
    },
    {
        "paper id": "2408.10060",
        "abstract url": "https://arxiv.org/abs/2408.10060",
        "title": "Facial Wrinkle Segmentation for Cosmetic Dermatology: Pretraining with Texture Map-Based Weak Supervision",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Facial wrinkle detection plays a crucial role in cosmetic dermatology. Precise manual segmentation of facial wrinkles is challenging and time-consuming, with inherent subjectivity leading to inconsistent results among graders. To address this issue, we propose two solutions. First, we build and release the first public facial wrinkle dataset, `FFHQ-Wrinkle', an extension of the NVIDIA FFHQ dataset. This dataset includes 1,000 images with human labels and 50,000 images with automatically generated weak labels. This dataset can foster the research community to develop advanced wrinkle detection algorithms. Second, we introduce a training strategy for U-Net-like encoder-decoder models to detect wrinkles across the face automatically. Our method employs a two-stage training strategy: texture map pretraining and finetuning on human-labeled data. Initially, we pretrain models on a large dataset with weak labels (N=50k) or masked texture maps generated through computer vision techniques, without human intervention. Subsequently, we finetune the models using human-labeled data (N=1k), which consists of manually labeled wrinkle masks. During finetuning, the network inputs a combination of RGB and masked texture maps, comprising four channels. We effectively combine labels from multiple annotators to minimize subjectivity in manual labeling. Our strategies demonstrate improved segmentation performance in facial wrinkle segmentation both quantitatively and visually compared to existing pretraining methods.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10064",
        "abstract url": "https://arxiv.org/abs/2408.10064",
        "title": "Understanding cyclists' perception of driverless vehicles through eye-tracking and interviews",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "As automated vehicles (AVs) become increasingly popular, the question arises as to how cyclists will interact with such vehicles. This study investigated (1) whether cyclists spontaneously notice if a vehicle is driverless, (2) how well they perform a driver-detection task when explicitly instructed, and (3) how they carry out such tasks. Using a Wizard-of-Oz method, 37 participants cycled a designated route and encountered an AV multiple times in two experimental sessions. In Session 1, participants cycled the route uninstructed, while in Session 2, they were instructed to verbally report whether they detected the presence or absence of a driver. Additionally, we recorded the participants' gaze behaviour with eye-tracking and their responses in post-session interviews. The interviews revealed that 30% of the cyclists spontaneously mentioned the absence of a driver (Session 1), and when instructed (Session 2), they detected the absence and presence of the driver with 93% accuracy. The eye-tracking data showed that cyclists looked more frequently and longer at the vehicle in Session 2 compared to Session 1. Furthermore, participants exhibited intermittent sampling of the vehicle, and they looked in front of the vehicle when it was far away and towards the windshield region when it was closer. The post-session interviews also indicated that participants were curious, felt safe, and reported a need to receive information about the AV's driving state. In conclusion, cyclists can detect the absence of a driver in the AV, and this detection may influence their perceptions of safety. Further research is needed to explore these findings in real-world traffic conditions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10123",
        "abstract url": "https://arxiv.org/abs/2408.10123",
        "title": "Learning Precise Affordances from Egocentric Videos for Robotic Manipulation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "robot",
                "Robotic Manipulation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Affordance, defined as the potential actions that an object offers, is crucial for robotic manipulation tasks. A deep understanding of affordance can lead to more intelligent AI systems. For example, such knowledge directs an agent to grasp a knife by the handle for cutting and by the blade when passing it to someone. In this paper, we present a streamlined affordance learning system that encompasses data collection, effective model training, and robot deployment. First, we collect training data from egocentric videos in an automatic manner. Different from previous methods that focus only on the object graspable affordance and represent it as coarse heatmaps, we cover both graspable (e.g., object handles) and functional affordances (e.g., knife blades, hammer heads) and extract data with precise segmentation masks. We then propose an effective model, termed Geometry-guided Affordance Transformer (GKT), to train on the collected data. GKT integrates an innovative Depth Feature Injector (DFI) to incorporate 3D shape and geometric priors, enhancing the model's understanding of affordances. To enable affordance-oriented manipulation, we further introduce Aff-Grasp, a framework that combines GKT with a grasp generation model. For comprehensive evaluation, we create an affordance evaluation dataset with pixel-wise annotations, and design real-world tasks for robot experiments. The results show that GKT surpasses the state-of-the-art by 15.9% in mIoU, and Aff-Grasp achieves high success rates of 95.5% in affordance prediction and 77.1% in successful grasping among 179 trials, including evaluations with seen, unseen objects, and cluttered scenes.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Project page: https://reagan1311.github.io/affgrasp"
    },
    {
        "paper id": "2408.10152",
        "abstract url": "https://arxiv.org/abs/2408.10152",
        "title": "Source-Seeking Problem with Robot Swarms",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "We present an algorithm to solve the problem of locating the source, or maxima, of a scalar field using a robot swarm. We demonstrate how the robot swarm determines its direction of movement to approach the source using only field intensity measurements taken by each robot. In contrast with the current literature, our algorithm accommodates a generic (non-degenerate) geometry for the swarm's formation. Additionally, we rigorously show the effectiveness of the algorithm even when the dynamics of the robots are complex, such as a unicycle with constant speed. Not requiring a strict geometry for the swarm significantly enhances its resilience. For example, this allows the swarm to change its size and formation in the presence of obstacles or other real-world factors, including the loss or addition of individuals to the swarm on the fly. For clarity, the article begins by presenting the algorithm for robots with free dynamics. In the second part, we demonstrate the algorithm's effectiveness even considering non-holonomic dynamics for the robots, using the vector field guidance paradigm. Finally, we verify and validate our algorithm with various numerical simulations.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10187",
        "abstract url": "https://arxiv.org/abs/2408.10187",
        "title": "Assessment of Spectral based Solutions for the Detection of Floating Marine Debris",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Typically, the detection of marine debris relies on in-situ campaigns that are characterized by huge human effort and limited spatial coverage. Following the need of a rapid solution for the detection of floating plastic, methods based on remote sensing data have been proposed recently. Their main limitation is represented by the lack of a general reference for evaluating performance. Recently, the Marine Debris Archive (MARIDA) has been released as a standard dataset to develop and evaluate Machine Learning (ML) algorithms for detection of Marine Plastic Debris. The MARIDA dataset has been created for simplifying the comparison between detection solutions with the aim of stimulating the research in the field of marine environment preservation. In this work, an assessment of spectral based solutions is proposed by evaluating performance on MARIDA dataset. The outcome highlights the need of precise reference for fair evaluation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 3 figures, submitted and accepted for 2024 Second International Conference on Networks, Multimedia and Information Technology (NMITCON)"
    },
    {
        "paper id": "2408.10198",
        "abstract url": "https://arxiv.org/abs/2408.10198",
        "title": "MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "SDF"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Open-world 3D reconstruction models have recently garnered significant attention. However, without sufficient 3D inductive bias, existing methods typically entail expensive training costs and struggle to extract high-quality 3D meshes. In this work, we introduce MeshFormer, a sparse-view reconstruction model that explicitly leverages 3D native structure, input guidance, and training supervision. Specifically, instead of using a triplane representation, we store features in 3D sparse voxels and combine transformers with 3D convolutions to leverage an explicit 3D structure and projective bias. In addition to sparse-view RGB input, we require the network to take input and generate corresponding normal maps. The input normal maps can be predicted by 2D diffusion models, significantly aiding in the guidance and refinement of the geometry's learning. Moreover, by combining Signed Distance Function (SDF) supervision with surface rendering, we directly learn to generate high-quality meshes without the need for complex multi-stage training processes. By incorporating these explicit 3D biases, MeshFormer can be trained efficiently and deliver high-quality textured meshes with fine-grained geometric details. It can also be integrated with 2D diffusion models to enable fast single-image-to-3D and text-to-3D tasks. Project page: https://meshformer3d.github.io",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "20 pages, 9 figures"
    },
    {
        "paper id": "2408.10338",
        "abstract url": "https://arxiv.org/abs/2408.10338",
        "title": "Revisiting Tree Canonization using polynomials",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Graph Isomorphism (GI) is a fundamental algorithmic problem. Amongst graph classes for which the computational complexity of GI has been resolved, trees are arguably the most fundamental. Tree Isomorphism is complete for deterministic logspace, a tiny subclass of polynomial time, by Lindell's result. Over three decades ago, he devised a deterministic logspace algorithm that computes a string which is a canon for the input tree -- two trees are isomorphic precisely when their canons are identical. Inspired by Miller-Reif's reduction of Tree Isomorphism to Polynomial Identity Testing, we present a new logspace algorithm for tree canonization fundamentally different from Lindell's algorithm. Our algorithm computes a univariate polynomial as canon for an input tree, based on the classical Eisenstein's criterion for the irreducibility of univariate polynomials. This can be implemented in logspace by invoking the well known Buss et al. algorithm for arithmetic formula evaluation. This algorithm is conceptually very simple, avoiding the delicate case analysis and complex recursion that constitute the core of Lindell's algorithm. We illustrate the adaptability of our algorithm by extending it to a couple of other classes of graphs.",
        "subjects": [
            "cs.CC",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10346",
        "abstract url": "https://arxiv.org/abs/2408.10346",
        "title": "Toward Fair and Strategyproof Tournament Rules for Tournaments with Partially Transferable Utilities",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A tournament on $n$ agents is a complete oriented graph with the agents as vertices and edges that describe the win-loss outcomes of the $\\binom{n}{2}$ matches played between each pair of agents. The winner of a tournament is determined by a tournament rule that maps tournaments to probability distributions over the agents. We want these rules to be fair (choose a high-quality agent) and robust to strategic manipulation. Prior work has shown that under minimally fair rules, manipulations between two agents can be prevented when utility is nontransferable but not when utility is completely transferable. We introduce a partially transferable utility model that interpolates between these two extremes using a selfishness parameter $\u03bb$. Our model is that an agent may be willing to lose on purpose, sacrificing some of her own chance of winning, but only if the colluding pair's joint gain is more than $\u03bb$ times the individual's sacrifice. We show that no fair tournament rule can prevent manipulations when $\u03bb< 1$. We computationally solve for fair and manipulation-resistant tournament rules for $\u03bb= 1$ for up to 6 agents. We conjecture and leave as a major open problem that such a tournament rule exists for all $n$. We analyze the trade-offs between ``relative'' and ``absolute'' approximate strategyproofness for previously studied rules and derive as a corollary that all of these rules require $\u03bb\\geq \u03a9(n)$ to be robust to manipulation. We show that for stronger notions of fairness, non-manipulable tournament rules are closely related to tournament rules that witness decreasing gains from manipulation as the number of agents increases.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10356",
        "abstract url": "https://arxiv.org/abs/2408.10356",
        "title": "Diversity and stylization of the contemporary user-generated visual arts in the complexity-entropy plane",
        "rating": "-1",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The advent of computational and numerical methods in recent times has provided new avenues for analyzing art historiographical narratives and tracing the evolution of art styles therein. Here, we investigate an evolutionary process underpinning the emergence and stylization of contemporary user-generated visual art styles using the complexity-entropy (C-H) plane, which quantifies local structures in paintings. Informatizing 149,780 images curated in DeviantArt and Behance platforms from 2010 to 2020, we analyze the relationship between local information of the C-H space and multi-level image features generated by a deep neural network and a feature extraction algorithm. The results reveal significant statistical relationships between the C-H information of visual artistic styles and the dissimilarities of the multi-level image features over time within groups of artworks. By disclosing a particular C-H region where the diversity of image representations is noticeably manifested, our analyses reveal an empirical condition of emerging styles that are both novel in the C-H plane and characterized by greater stylistic diversity. Our research shows that visual art analyses combined with physics-inspired methodologies and machine learning, can provide macroscopic insights into quantitatively mapping relevant characteristics of an evolutionary process underpinning the creative stylization of uncharted visual arts of given groups and time.",
        "subjects": [
            "cs.CV",
            "physics.data-an",
            "physics.soc-ph"
        ],
        "comment": "18 pages, 3 figures, 1 table, SI(4 figures, 3 tables)"
    },
    {
        "paper id": "2408.10431",
        "abstract url": "https://arxiv.org/abs/2408.10431",
        "title": "System-Level Design Space Exploration for High-Level Synthesis under End-to-End Latency Constraints",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving"
            ]
        ],
        "abstract": "Many modern embedded systems have end-to-end (EtoE) latency constraints that necessitate precise timing to ensure high reliability and functional correctness. The combination of High-Level Synthesis (HLS) and Design Space Exploration (DSE) enables the rapid generation of embedded systems using various constraints/directives to find Pareto-optimal configurations. Current HLS DSE approaches often address latency by focusing on individual components, without considering the EtoE latency during the system-level optimization process. However, to truly optimize the system under EtoE latency, we need a holistic approach that analyzes individual system components' timing constraints in the context of how the different components interact and impact the overall design. This paper presents a novel system-level HLS DSE approach, called EtoE-DSE, that accommodates EtoE latency and variable timing constraints for complex multi-component application-specific embedded systems. EtoE-DSE employs a latency estimation model and a pathfinding algorithm to identify and estimate the EtoE latency for paths between any endpoints. It also uses a frequency-based segmentation process to segment and prune the design space, alongside a latency-constrained optimization algorithm for efficiently and accurately exploring the system-level design space. We evaluate our approach using a real-world use case of an autonomous driving subsystem compared to the state-of-the-art in HLS DSE. We show that our approach yields substantially better optimization results than prior DSE approaches, improving the quality of results by up to 89.26%, while efficiently identifying Pareto-optimal configurations in terms of energy and area.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10488",
        "abstract url": "https://arxiv.org/abs/2408.10488",
        "title": "Event Stream based Sign Language Translation: A High-Definition Benchmark Dataset and A New Algorithm",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Sign Language Translation (SLT) is a core task in the field of AI-assisted disability. Unlike traditional SLT based on visible light videos, which is easily affected by factors such as lighting, rapid hand movements, and privacy breaches, this paper proposes the use of high-definition Event streams for SLT, effectively mitigating the aforementioned issues. This is primarily because Event streams have a high dynamic range and dense temporal signals, which can withstand low illumination and motion blur well. Additionally, due to their sparsity in space, they effectively protect the privacy of the target person. More specifically, we propose a new high-resolution Event stream sign language dataset, termed Event-CSL, which effectively fills the data gap in this area of research. It contains 14,827 videos, 14,821 glosses, and 2,544 Chinese words in the text vocabulary. These samples are collected in a variety of indoor and outdoor scenes, encompassing multiple angles, light intensities, and camera movements. We have benchmarked existing mainstream SLT works to enable fair comparison for future efforts. Based on this dataset and several other large-scale datasets, we propose a novel baseline method that fully leverages the Mamba model's ability to integrate temporal information of CNN features, resulting in improved sign language translation outcomes. Both the benchmark dataset and source code will be released on https://github.com/Event-AHU/OpenESL",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.NE"
        ],
        "comment": "First Large-scale and High-Definition Benchmark Dataset for Event-based Sign Language Translation"
    },
    {
        "paper id": "2408.10497",
        "abstract url": "https://arxiv.org/abs/2408.10497",
        "title": "QUITO-X: An Information Bottleneck-based Compression Algorithm with Cross-Attention",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Generative LLM have achieved significant success in various industrial tasks and can effectively adapt to vertical domains and downstream tasks through ICL. However, with tasks becoming increasingly complex, the context length required by ICL is also getting longer, and two significant issues arise: (i) The excessively long context leads to high costs and inference delays. (ii) A substantial amount of task-irrelevant information introduced by long contexts exacerbates the \"lost in the middle\" problem. Recently, compressing prompts by removing tokens according to some metric obtained from some causal language models, such as llama-7b, has emerged as an effective approach to mitigate these issues. However, the metric used by prior method such as self-information or PPL do not fully align with the objective of distinuishing the most important tokens when conditioning on query. In this work, we introduce information bottleneck theory to carefully examine the properties required by the metric. Inspired by this, we use cross-attention in encoder-decoder architecture as a new metric. Our simple method leads to significantly better performance in smaller models with lower latency. We evaluate our method on four datasets: DROP, CoQA, SQuAD, and Quoref. The experimental results show that, while maintaining the same performance, our compression rate can improve by nearly 25% over previous SOTA. Remarkably, in experiments where 25% of the tokens are removed, our model's EM score for answers sometimes even exceeds that of the control group using uncompressed text as context.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10498",
        "abstract url": "https://arxiv.org/abs/2408.10498",
        "title": "Cervical Cancer Detection Using Multi-Branch Deep Learning Model",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "diagnosis",
                "Cancer",
                "disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Cervical cancer is a crucial global health concern for women, and the persistent infection of High-risk HPV mainly triggers this remains a global health challenge, with young women diagnosis rates soaring from 10\\% to 40\\% over three decades. While Pap smear screening is a prevalent diagnostic method, visual image analysis can be lengthy and often leads to mistakes. Early detection of the disease can contribute significantly to improving patient outcomes. In recent decades, many researchers have employed machine learning techniques that achieved promise in cervical cancer detection processes based on medical images. In recent years, many researchers have employed various deep-learning techniques to achieve high-performance accuracy in detecting cervical cancer but are still facing various challenges. This research proposes an innovative and novel approach to automate cervical cancer image classification using Multi-Head Self-Attention (MHSA) and convolutional neural networks (CNNs). The proposed method leverages the strengths of both MHSA mechanisms and CNN to effectively capture both local and global features within cervical images in two streams. MHSA facilitates the model's ability to focus on relevant regions of interest, while CNN extracts hierarchical features that contribute to accurate classification. Finally, we combined the two stream features and fed them into the classification module to refine the feature and the classification. To evaluate the performance of the proposed approach, we used the SIPaKMeD dataset, which classifies cervical cells into five categories. Our model achieved a remarkable accuracy of 98.522\\%. This performance has high recognition accuracy of medical image classification and holds promise for its applicability in other medical image recognition tasks.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10501",
        "abstract url": "https://arxiv.org/abs/2408.10501",
        "title": "Generative Diffusion Models for High Dimensional Channel Estimation",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ]
        ],
        "abstract": "Along with the prosperity of generative artificial intelligence (AI), its potential for solving conventional challenges in wireless communications has also surfaced. Inspired by this trend, we investigate the application of the advanced diffusion models (DMs), a representative class of generative AI models, to high dimensional wireless channel estimation. By capturing the structure of multiple-input multiple-output (MIMO) wireless channels via a deep generative prior encoded by DMs, we develop a novel posterior inference method for channel reconstruction. We further adapt the proposed method to recover channel information from low-resolution quantized measurements. Additionally, to enhance the over-the-air viability, we integrate the DM with the unsupervised Stein's unbiased risk estimator to enable learning from noisy observations and circumvent the requirements for ground truth channel data that is hardly available in practice. Results reveal that the proposed estimator achieves high-fidelity channel recovery while reducing estimation latency by a factor of 10 compared to state-of-the-art schemes, facilitating real-time implementation. Moreover, our method outperforms existing estimators while reducing the pilot overhead by half, showcasing its scalability to ultra-massive antenna arrays.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2408.10518",
        "abstract url": "https://arxiv.org/abs/2408.10518",
        "title": "BAUST Lipi: A BdSL Dataset with Deep Learning Based Bangla Sign Language Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "People commonly communicate in English, Arabic, and Bengali spoken languages through various mediums. However, deaf and hard-of-hearing individuals primarily use body language and sign language to express their needs and achieve independence. Sign language research is burgeoning to enhance communication with the deaf community. While many researchers have made strides in recognizing sign languages such as French, British, Arabic, Turkish, and American, there has been limited research on Bangla sign language (BdSL) with less-than-satisfactory results. One significant barrier has been the lack of a comprehensive Bangla sign language dataset. In our work, we introduced a new BdSL dataset comprising alphabets totaling 18,000 images, with each image being 224x224 pixels in size. Our dataset encompasses 36 Bengali symbols, of which 30 are consonants and the remaining six are vowels. Despite our dataset contribution, many existing systems continue to grapple with achieving high-performance accuracy for BdSL. To address this, we devised a hybrid Convolutional Neural Network (CNN) model, integrating multiple convolutional layers, activation functions, dropout techniques, and LSTM layers. Upon evaluating our hybrid-CNN model with the newly created BdSL dataset, we achieved an accuracy rate of 97.92\\%. We are confident that both our BdSL dataset and hybrid CNN model will be recognized as significant milestones in BdSL research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10529",
        "abstract url": "https://arxiv.org/abs/2408.10529",
        "title": "Automated Detection of Algorithm Debt in Deep Learning Frameworks: An Empirical Study",
        "rating": "-1",
        "keywords": [
            [
                "Support Vector Machine"
            ]
        ],
        "abstract": "Context: Previous studies demonstrate that Machine or Deep Learning (ML/DL) models can detect Technical Debt from source code comments called Self-Admitted Technical Debt (SATD). Despite the importance of ML/DL in software development, limited studies focus on automated detection for new SATD types: Algorithm Debt (AD). AD detection is important because it helps to identify TD early, facilitating research, learning, and preventing the accumulation of issues related to model degradation and lack of scalability. Aim: Our goal is to improve AD detection performance of various ML/DL models. Method: We will perform empirical studies using approaches: TF-IDF, Count Vectorizer, Hash Vectorizer, and TD-indicative words to identify features that improve AD detection, using ML/DL classifiers with different data featurisations. We will use an existing dataset curated from seven DL frameworks where comments were manually classified as AD, Compatibility, Defect, Design, Documentation, Requirement, and Test Debt. We will explore various word embedding methods to further enrich features for ML models. These embeddings will be from models founded in DL such as ROBERTA, ALBERTv2, and large language models (LLMs): INSTRUCTOR and VOYAGE AI. We will enrich the dataset by incorporating AD-related terms, then train various ML/DL classifiers, Support Vector Machine, Logistic Regression, Random Forest, ROBERTA, and ALBERTv2.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted as Continuity Acceptance (CA) for a Stage 1 registration of the Registered Report Track at 40th IEEE International Conference on Software Maintenance and Evolution (ICSME 2024), Flagstaff, USA, October 6-11, 2024"
    },
    {
        "paper id": "2408.10532",
        "abstract url": "https://arxiv.org/abs/2408.10532",
        "title": "NutrifyAI: An AI-Powered System for Real-Time Food Detection, Nutritional Analysis, and Personalized Meal Recommendations",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "With diet and nutrition apps reaching 1.4 billion users in 2022 [1], it's no surprise that health apps like MyFitnessPal, Noom, and Calorie Counter, are surging in popularity. However, one major setback [2] of nearly all nutrition applications is that users must enter food data manually, which is time-consuming and tedious. Thus, there has been an increasing demand for applications that can accurately identify food items, analyze their nutritional content, and offer dietary recommendations in real-time. This paper introduces a comprehensive system that combines advanced computer vision techniques with nutrition analysis, implemented in a versatile mobile and web application. The system is divided into three key components: 1) food detection using the YOLOv8 model, 2) nutrient analysis via the Edamam Nutrition Analysis API, and 3) personalized meal recommendations using the Edamam Meal Planning and Recipe Search APIs. Designed for both mobile and web platforms, the application ensures fast processing times with an intuitive user interface, with features such as data visualizations using Chart.js, a login system, and personalized settings for dietary preferences, allergies, and cuisine choices. Preliminary results showcase the system's effectiveness, making it a valuable tool for users to make informed dietary decisions.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "7 pages, 12 figures"
    },
    {
        "paper id": "2408.10538",
        "abstract url": "https://arxiv.org/abs/2408.10538",
        "title": "Surgical Workflow Recognition and Blocking Effectiveness Detection in Laparoscopic Liver Resections with Pringle Maneuver",
        "rating": "-1",
        "keywords": [
            [
                "Surgical",
                "surgery",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Pringle maneuver (PM) in laparoscopic liver resection aims to reduce blood loss and provide a clear surgical view by intermittently blocking blood inflow of the liver, whereas prolonged PM may cause ischemic injury. To comprehensively monitor this surgical procedure and provide timely warnings of ineffective and prolonged blocking, we suggest two complementary AI-assisted surgical monitoring tasks: workflow recognition and blocking effectiveness detection in liver resections. The former presents challenges in real-time capturing of short-term PM, while the latter involves the intraoperative discrimination of long-term liver ischemia states. To address these challenges, we meticulously collect a novel dataset, called PmLR50, consisting of 25,037 video frames covering various surgical phases from 50 laparoscopic liver resection procedures. Additionally, we develop an online baseline for PmLR50, termed PmNet. This model embraces Masked Temporal Encoding (MTE) and Compressed Sequence Modeling (CSM) for efficient short-term and long-term temporal information modeling, and embeds Contrastive Prototype Separation (CPS) to enhance action discrimination between similar intraoperative operations. Experimental results demonstrate that PmNet outperforms existing state-of-the-art surgical workflow recognition methods on the PmLR50 benchmark. Our research offers potential clinical applications for the laparoscopic liver surgery community. Source code and data will be publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10543",
        "abstract url": "https://arxiv.org/abs/2408.10543",
        "title": "Diff-PCC: Diffusion-based Neural Compression for 3D Point Clouds",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Stable diffusion networks have emerged as a groundbreaking development for their ability to produce realistic and detailed visual content. This characteristic renders them ideal decoders, capable of producing high-quality and aesthetically pleasing reconstructions. In this paper, we introduce the first diffusion-based point cloud compression method, dubbed Diff-PCC, to leverage the expressive power of the diffusion model for generative and aesthetically superior decoding. Different from the conventional autoencoder fashion, a dual-space latent representation is devised in this paper, in which a compressor composed of two independent encoding backbones is considered to extract expressive shape latents from distinct latent spaces. At the decoding side, a diffusion-based generator is devised to produce high-quality reconstructions by considering the shape latents as guidance to stochastically denoise the noisy point clouds. Experiments demonstrate that the proposed Diff-PCC achieves state-of-the-art compression performance (e.g., 7.711 dB BD-PSNR gains against the latest G-PCC standard at ultra-low bitrate) while attaining superior subjective quality. Source code will be made publicly available.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10843",
        "abstract url": "https://arxiv.org/abs/2408.10843",
        "title": "Detecting Wildfires on UAVs with Real-time Segmentation Trained by Larger Teacher Models",
        "rating": "-1",
        "keywords": [
            [
                "UAV"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Early detection of wildfires is essential to prevent large-scale fires resulting in extensive environmental, structural, and societal damage. Uncrewed aerial vehicles (UAVs) can cover large remote areas effectively with quick deployment requiring minimal infrastructure and equipping them with small cameras and computers enables autonomous real-time detection. In remote areas, however, the UAVs are limited to on-board computing for detection due to the lack of high-bandwidth mobile networks. This limits the detection to methods which are light enough for the on-board computer alone. For accurate camera-based localisation, segmentation of the detected smoke is essential but training data for deep learning-based wildfire smoke segmentation is limited. This study shows how small specialised segmentation models can be trained using only bounding box labels, leveraging zero-shot foundation model supervision. The method offers the advantages of needing only fairly easily obtainable bounding box labels and requiring training solely for the smaller student network. The proposed method achieved 63.3% mIoU on a manually annotated and diverse wildfire dataset. The used model can perform in real-time at ~11 fps with a UAV-carried NVIDIA Jetson Orin NX computer while reliably recognising smoke, demonstrated at real-world forest burning events. Code is available at https://gitlab.com/fgi_nls/public/wildfire-real-time-segmentation",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.11077",
        "abstract url": "https://arxiv.org/abs/2408.11077",
        "title": "Solving Oscillator ODEs via Soft-constrained Physics-informed Neural Network with Small Data",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper compared physics-informed neural network (PINN), conventional neural network (NN) and numerical discretization methods on solving differential equations through literature research. We formalized the mathematical framework and computational flow of the soft-constrained PINN method for solving differential equations (e.g., ODEs/PDEs). Its working mechanism and its accuracy and efficiency were experimentally verified by solving typical linear and non-linear oscillator ODEs. The implementation of the PINN method based on DeepXDE is not only light code and efficient in training, but also flexible across platforms. PINN greatly reduces the need for labeled data: when the nonlinearity of the ODE is weak, a very small amount of supervised training data plus a small amount of collocation points are sufficient to predict the solution; in the minimalist case, only one or two training points (with initial values) are needed for first- or second-order ODEs, respectively. Strongly nonlinear ODE also require only an appropriate increase in the number of training and collocation points, which still has significant advantages over conventional NN. With the aid of collocation points and the use of physical information, PINN has the ability to extrapolate data outside the time domain covered by the training set, and is robust to noisy data, thus with enhanced generalization capabilities. Training is accelerated when the gains obtained along with the reduction in the amount of data outweigh the delay caused by the increase in the loss function terms. The soft-constrained PINN method can easily impose a physical law (e.g., energy conservation) constraint by adding a regularization term to the total loss function, thus improving the solution performance of ODEs that obey this physical law.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "stat.ML"
        ],
        "comment": "17 pages, 7 figures, 2 tables, etc"
    },
    {
        "paper id": "2408.09703",
        "abstract url": "https://arxiv.org/abs/2408.09703",
        "title": "Partial-Multivariate Model for Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "When solving forecasting problems including multiple time-series features, existing approaches often fall into two extreme categories, depending on whether to utilize inter-feature information: univariate and complete-multivariate models. Unlike univariate cases which ignore the information, complete-multivariate models compute relationships among a complete set of features. However, despite the potential advantage of leveraging the additional information, complete-multivariate models sometimes underperform univariate ones. Therefore, our research aims to explore a middle ground between these two by introducing what we term Partial-Multivariate models where a neural network captures only partial relationships, that is, dependencies within subsets of all features. To this end, we propose PMformer, a Transformer-based partial-multivariate model, with its training algorithm. We demonstrate that PMformer outperforms various univariate and complete-multivariate models, providing a theoretical rationale and empirical analysis for its superiority. Additionally, by proposing an inference technique for PMformer, the forecasting accuracy is further enhanced. Finally, we highlight other advantages of PMformer: efficiency and robustness under missing features.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2408.09705",
        "abstract url": "https://arxiv.org/abs/2408.09705",
        "title": "Community-Centric Graph Unlearning",
        "rating": "-1.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph unlearning technology has become increasingly important since the advent of the `right to be forgotten' and the growing concerns about the privacy and security of artificial intelligence. Graph unlearning aims to quickly eliminate the effects of specific data on graph neural networks (GNNs). However, most existing deterministic graph unlearning frameworks follow a balanced partition-submodel training-aggregation paradigm, resulting in a lack of structural information between subgraph neighborhoods and redundant unlearning parameter calculations. To address this issue, we propose a novel Graph Structure Mapping Unlearning paradigm (GSMU) and a novel method based on it named Community-centric Graph Eraser (CGE). CGE maps community subgraphs to nodes, thereby enabling the reconstruction of a node-level unlearning operation within a reduced mapped graph. CGE makes the exponential reduction of both the amount of training data and the number of unlearning parameters. Extensive experiments conducted on five real-world datasets and three widely used GNN backbones have verified the high performance and efficiency of our CGE method, highlighting its potential in the field of graph unlearning.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09723",
        "abstract url": "https://arxiv.org/abs/2408.09723",
        "title": "sTransformer: A Modular Approach for Extracting Inter-Sequential and Temporal Information for Time-Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, numerous Transformer-based models have been applied to long-term time-series forecasting (LTSF) tasks. However, recent studies with linear models have questioned their effectiveness, demonstrating that simple linear layers can outperform sophisticated Transformer-based models. In this work, we review and categorize existing Transformer-based models into two main types: (1) modifications to the model structure and (2) modifications to the input data. The former offers scalability but falls short in capturing inter-sequential information, while the latter preprocesses time-series data but is challenging to use as a scalable module. We propose $\\textbf{sTransformer}$, which introduces the Sequence and Temporal Convolutional Network (STCN) to fully capture both sequential and temporal information. Additionally, we introduce a Sequence-guided Mask Attention mechanism to capture global feature information. Our approach ensures the capture of inter-sequential information while maintaining module scalability. We compare our model with linear models and existing forecasting models on long-term time-series forecasting, achieving new state-of-the-art results. We also conducted experiments on other time-series tasks, achieving strong performance. These demonstrate that Transformer-based structures remain effective and our model can serve as a viable baseline for time-series tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09725",
        "abstract url": "https://arxiv.org/abs/2408.09725",
        "title": "State surveillance in the digital age: Factors associated with citizens' attitudes towards trust registers",
        "rating": "-1.5",
        "keywords": [
            [
                "crime"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper investigates factors related to the acceptance of trust registers (e.g., the Chinese Social Credit System - SCS) in Western settings. To avoid a negative connotation, we first define the concept of trust register which encompasses surveillance systems in other settings beyond China, such as FICO in the US. Then, we explore which factors are associated with people's attitude towards trust registers leaning on the technology acceptance and privacy concern theories. A cross-sectional survey among Slovenian Facebook and Instagram users (N=147) was conducted. Covariance-based structural equation modeling (CB-SEM) was used to test the hypothesized associations between the studied constructs. Results indicate that attitude towards trust register is directly associated with perceived general usefulness of the trust register. Additionally, perceived general usefulness is associated with perceived usefulness of the trust register for ensuring national security and fighting crime, its ease of use, and privacy concern regarding data collection. As one of the first studies investigating attitude towards trust registers in a Western country, it provides pioneering insights into factors that may be relevant in case such registers would be implemented in a Western context, and provides some practical implications regarding messaging for would-be implementers of such systems.",
        "subjects": [
            "cs.CY",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09748",
        "abstract url": "https://arxiv.org/abs/2408.09748",
        "title": "Revisiting Reciprocal Recommender Systems: Metrics, Formulation, and Method",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Reciprocal recommender systems~(RRS), conducting bilateral recommendations between two involved parties, have gained increasing attention for enhancing matching efficiency. However, the majority of existing methods in the literature still reuse conventional ranking metrics to separately assess the performance on each side of the recommendation process. These methods overlook the fact that the ranking outcomes of both sides collectively influence the effectiveness of the RRS, neglecting the necessity of a more holistic evaluation and a capable systemic solution. In this paper, we systemically revisit the task of reciprocal recommendation, by introducing the new metrics, formulation, and method. Firstly, we propose five new evaluation metrics that comprehensively and accurately assess the performance of RRS from three distinct perspectives: overall coverage, bilateral stability, and balanced ranking. These metrics provide a more holistic understanding of the system's effectiveness and enable a comprehensive evaluation. Furthermore, we formulate the RRS from a causal perspective, formulating recommendations as bilateral interventions, which can better model the decoupled effects of potential influencing factors. By utilizing the potential outcome framework, we further develop a model-agnostic causal reciprocal recommendation method that considers the causal effects of recommendations. Additionally, we introduce a reranking strategy to maximize matching outcomes, as measured by the proposed metrics. Extensive experiments on two real-world datasets from recruitment and dating scenarios demonstrate the effectiveness of our proposed metrics and approach. The code and dataset are available at: https://github.com/RUCAIBox/CRRS.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "KDD 2024"
    },
    {
        "paper id": "2408.09881",
        "abstract url": "https://arxiv.org/abs/2408.09881",
        "title": "Uncertainty Quantification of Pre-Trained and Fine-Tuned Surrogate Models using Conformal Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Data-driven surrogate models have shown immense potential as quick, inexpensive approximations to complex numerical and experimental modelling tasks. However, most surrogate models characterising physical systems do not quantify their uncertainty, rendering their predictions unreliable, and needing further validation. Though Bayesian approximations offer some solace in estimating the error associated with these models, they cannot provide they cannot provide guarantees, and the quality of their inferences depends on the availability of prior information and good approximations to posteriors for complex problems. This is particularly pertinent to multi-variable or spatio-temporal problems. Our work constructs and formalises a conformal prediction framework that satisfies marginal coverage for spatio-temporal predictions in a model-agnostic manner, requiring near-zero computational costs. The paper provides an extensive empirical study of the application of the framework to ascertain valid error bars that provide guaranteed coverage across the surrogate model's domain of operation. The application scope of our work extends across a large range of spatio-temporal models, ranging from solving partial differential equations to weather forecasting. Through the applications, the paper looks at providing statistically valid error bars for deterministic models, as well as crafting guarantees to the error bars of probabilistic models. The paper concludes with a viable conformal prediction formalisation that provides guaranteed coverage of the surrogate model, regardless of model architecture, and its training regime and is unbothered by the curse of dimensionality.",
        "subjects": [
            "cs.AI",
            "physics.ao-ph",
            "physics.plasm-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09936",
        "abstract url": "https://arxiv.org/abs/2408.09936",
        "title": "Electron-nucleus cross sections from transfer learning",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transfer learning (TL) allows a deep neural network (DNN) trained on one type of data to be adapted for new problems with limited information. We propose to use the TL technique in physics. The DNN learns the physics of one process, and after fine-tuning, it makes predictions for related processes. We consider the DNNs, trained on inclusive electron-carbon scattering data, and show that after fine-tuning, they accurately predict cross sections for electron interactions with nuclear targets ranging from lithium to iron. The method works even when the DNN is fine-tuned on a small dataset.",
        "subjects": [
            "hep-ph",
            "cs.LG",
            "hep-ex",
            "nucl-ex",
            "nucl-th"
        ],
        "comment": "4 pages, 2 figures"
    },
    {
        "paper id": "2408.09951",
        "abstract url": "https://arxiv.org/abs/2408.09951",
        "title": "Principle Driven Parameterized Fiber Model based on GPT-PINN Neural Network",
        "rating": "-1.5",
        "keywords": [
            [
                "5G"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In cater the need of Beyond 5G communications, large numbers of data driven artificial intelligence based fiber models has been put forward as to utilize artificial intelligence's regression ability to predict pulse evolution in fiber transmission at a much faster speed compared with the traditional split step Fourier method. In order to increase the physical interpretabiliy, principle driven fiber models have been proposed which inserts the Nonlinear Schodinger Equation into their loss functions. However, regardless of either principle driven or data driven models, they need to be re-trained the whole model under different transmission conditions. Unfortunately, this situation can be unavoidable when conducting the fiber communication optimization work. If the scale of different transmission conditions is large, then the whole model needs to be retrained large numbers of time with relatively large scale of parameters which may consume higher time costs. Computing efficiency will be dragged down as well. In order to address this problem, we propose the principle driven parameterized fiber model in this manuscript. This model breaks down the predicted NLSE solution with respect to one set of transmission condition into the linear combination of several eigen solutions which were outputted by each pre-trained principle driven fiber model via the reduced basis method. Therefore, the model can greatly alleviate the heavy burden of re-training since only the linear combination coefficients need to be found when changing the transmission condition. Not only strong physical interpretability can the model posses, but also higher computing efficiency can be obtained. Under the demonstration, the model's computational complexity is 0.0113% of split step Fourier method and 1% of the previously proposed principle driven fiber model.",
        "subjects": [
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09981",
        "abstract url": "https://arxiv.org/abs/2408.09981",
        "title": "Parseval Convolution Operators and Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "biomedical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We first establish a kernel theorem that characterizes all linear shift-invariant (LSI) operators acting on discrete multicomponent signals. This result naturally leads to the identification of the Parseval convolution operators as the class of energy-preserving filterbanks. We then present a constructive approach for the design/specification of such filterbanks via the chaining of elementary Parseval modules, each of which being parameterized by an orthogonal matrix or a 1-tight frame. Our analysis is complemented with explicit formulas for the Lipschitz constant of all the components of a convolutional neural network (CNN), which gives us a handle on their stability. Finally, we demonstrate the usage of those tools with the design of a CNN-based algorithm for the iterative reconstruction of biomedical images. Our algorithm falls within the plug-and-play framework for the resolution of inverse problems. It yields better-quality results than the sparsity-based methods used in compressed sensing, while offering essentially the same convergence and robustness guarantees.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "math.FA",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10006",
        "abstract url": "https://arxiv.org/abs/2408.10006",
        "title": "Unlocking the Power of LSTM for Long Term Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional recurrent neural network architectures, such as long short-term memory neural networks (LSTM), have historically held a prominent role in time series forecasting (TSF) tasks. While the recently introduced sLSTM for Natural Language Processing (NLP) introduces exponential gating and memory mixing that are beneficial for long term sequential learning, its potential short memory issue is a barrier to applying sLSTM directly in TSF. To address this, we propose a simple yet efficient algorithm named P-sLSTM, which is built upon sLSTM by incorporating patching and channel independence. These modifications substantially enhance sLSTM's performance in TSF, achieving state-of-the-art results. Furthermore, we provide theoretical justifications for our design, and conduct extensive comparative and analytical experiments to fully validate the efficiency and superior performance of our model.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10011",
        "abstract url": "https://arxiv.org/abs/2408.10011",
        "title": "PinnDE: Physics-Informed Neural Networks for Solving Differential Equations",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years the study of deep learning for solving differential equations has grown substantially. The use of physics-informed neural networks (PINNs) and deep operator networks (DeepONets) have emerged as two of the most useful approaches in approximating differential equation solutions using machine learning. Here, we propose PinnDE, an open-source python library for solving differential equations with both PINNs and DeepONets. We give a brief review of both PINNs and DeepONets, introduce PinnDE along with the structure and usage of the package, and present worked examples to show PinnDE's effectiveness in approximating solutions with both PINNs and DeepONets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10026",
        "abstract url": "https://arxiv.org/abs/2408.10026",
        "title": "Defense Priorities in the Open-Source AI Debate: A Preliminary Assessment",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "A spirited debate is taking place over the regulation of open foundation models: artificial intelligence models whose underlying architectures and parameters are made public and can be inspected, modified, and run by end users. Proposed limits on releasing open foundation models may have significant defense industrial impacts. If model training is a form of defense production, these impacts deserve further scrutiny. Preliminary evidence suggests that an open foundation model ecosystem could benefit the U.S. Department of Defense's supplier diversity, sustainment, cybersecurity, and innovation priorities. Follow-on analyses should quantify impacts on acquisition cost and supply chain security.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "20 pages, 3 figures"
    },
    {
        "paper id": "2408.10039",
        "abstract url": "https://arxiv.org/abs/2408.10039",
        "title": "MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "Clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Clinical diagnosis is critical in medical practice, typically requiring a continuous and evolving process that includes primary diagnosis, differential diagnosis, and final diagnosis. However, most existing clinical diagnostic tasks are single-step processes, which does not align with the complex multi-step diagnostic procedures found in real-world clinical settings. In this paper, we propose a multi-step diagnostic task and annotate a clinical diagnostic dataset (MSDiagnosis). This dataset includes primary diagnosis, differential diagnosis, and final diagnosis questions. Additionally, we propose a novel and effective framework. This framework combines forward inference, backward inference, reflection, and refinement, enabling the LLM to self-evaluate and adjust its diagnostic results. To assess the effectiveness of our proposed method, we design and conduct extensive experiments. The experimental results demonstrate the effectiveness of the proposed method. We also provide a comprehensive experimental analysis and suggest future research directions for this task.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10108",
        "abstract url": "https://arxiv.org/abs/2408.10108",
        "title": "Envisioning Possibilities and Challenges of AI for Personalized Cancer Care",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "Cancer"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The use of Artificial Intelligence (AI) in healthcare, including in caring for cancer survivors, has gained significant interest. However, gaps remain in our understanding of how such AI systems can provide care, especially for ethnic and racial minority groups who continue to face care disparities. Through interviews with six cancer survivors, we identify critical gaps in current healthcare systems such as a lack of personalized care and insufficient cultural and linguistic accommodation. AI, when applied to care, was seen as a way to address these issues by enabling real-time, culturally aligned, and linguistically appropriate interactions. We also uncovered concerns about the implications of AI-driven personalization, such as data privacy, loss of human touch in caregiving, and the risk of echo chambers that limit exposure to diverse information. We conclude by discussing the trade-offs between AI-enhanced personalization and the need for structural changes in healthcare that go beyond technological solutions, leading us to argue that we should begin by asking, ``Why personalization?''",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "7 pages, 1 table, short paper at CSCW 2024"
    },
    {
        "paper id": "2408.10120",
        "abstract url": "https://arxiv.org/abs/2408.10120",
        "title": "Geometry Informed Tokenization of Molecules for Language Model Generation",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "graphs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We consider molecule generation in 3D space using language models (LMs), which requires discrete tokenization of 3D molecular geometries. Although tokenization of molecular graphs exists, that for 3D geometries is largely unexplored. Here, we attempt to bridge this gap by proposing the Geo2Seq, which converts molecular geometries into $SE(3)$-invariant 1D discrete sequences. Geo2Seq consists of canonical labeling and invariant spherical representation steps, which together maintain geometric and atomic fidelity in a format conducive to LMs. Our experiments show that, when coupled with Geo2Seq, various LMs excel in molecular geometry generation, especially in controlled generation tasks.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10159",
        "abstract url": "https://arxiv.org/abs/2408.10159",
        "title": "Customizing Language Models with Instance-wise LoRA for Sequential Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Sequential recommendation systems predict a user's next item of interest by analyzing past interactions, aligning recommendations with individual preferences. Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches have applied LLMs to sequential recommendation through language generation paradigms. These methods convert user behavior sequences into prompts for LLM fine-tuning, utilizing Low-Rank Adaptation (LoRA) modules to refine recommendations. However, the uniform application of LoRA across diverse user behaviors sometimes fails to capture individual variability, leading to suboptimal performance and negative transfer between disparate sequences. To address these challenges, we propose Instance-wise LoRA (iLoRA), integrating LoRA with the Mixture of Experts (MoE) framework. iLoRA creates a diverse array of experts, each capturing specific aspects of user preferences, and introduces a sequence representation guided gate function. This gate function processes historical interaction sequences to generate enriched representations, guiding the gating network to output customized expert participation weights. This tailored approach mitigates negative transfer and dynamically adjusts to diverse behavior patterns. Extensive experiments on three benchmark datasets demonstrate the effectiveness of iLoRA, highlighting its superior performance compared to existing methods in capturing user-specific preferences and improving recommendation accuracy.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10285",
        "abstract url": "https://arxiv.org/abs/2408.10285",
        "title": "BatGPT-Chem: A Foundation Large Model For Retrosynthesis Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "chemistry",
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Retrosynthesis analysis is pivotal yet challenging in drug discovery and organic chemistry. Despite the proliferation of computational tools over the past decade, AI-based systems often fall short in generalizing across diverse reaction types and exploring alternative synthetic pathways. This paper presents BatGPT-Chem, a large language model with 15 billion parameters, tailored for enhanced retrosynthesis prediction. Integrating chemical tasks via a unified framework of natural language and SMILES notation, this approach synthesizes extensive instructional data from an expansive chemical database. Employing both autoregressive and bidirectional training techniques across over one hundred million instances, BatGPT-Chem captures a broad spectrum of chemical knowledge, enabling precise prediction of reaction conditions and exhibiting strong zero-shot capabilities. Superior to existing AI methods, our model demonstrates significant advancements in generating effective strategies for complex molecules, as validated by stringent benchmark tests. BatGPT-Chem not only boosts the efficiency and creativity of retrosynthetic analysis but also establishes a new standard for computational tools in synthetic design. This development empowers chemists to adeptly address the synthesis of novel compounds, potentially expediting the innovation cycle in drug manufacturing and materials science. We release our trial platform at \\url{https://www.batgpt.net/dapp/chem}.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10286",
        "abstract url": "https://arxiv.org/abs/2408.10286",
        "title": "GPT-Augmented Reinforcement Learning with Intelligent Control for Vehicle Dispatching",
        "rating": "-1.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "As urban residents demand higher travel quality, vehicle dispatch has become a critical component of online ride-hailing services. However, current vehicle dispatch systems struggle to navigate the complexities of urban traffic dynamics, including unpredictable traffic conditions, diverse driver behaviors, and fluctuating supply and demand patterns. These challenges have resulted in travel difficulties for passengers in certain areas, while many drivers in other areas are unable to secure orders, leading to a decline in the overall quality of urban transportation services. To address these issues, this paper introduces GARLIC: a framework of GPT-Augmented Reinforcement Learning with Intelligent Control for vehicle dispatching. GARLIC utilizes multiview graphs to capture hierarchical traffic states, and learns a dynamic reward function that accounts for individual driving behaviors. The framework further integrates a GPT model trained with a custom loss function to enable high-precision predictions and optimize dispatching policies in real-world scenarios. Experiments conducted on two real-world datasets demonstrate that GARLIC effectively aligns with driver behaviors while reducing the empty load rate of vehicles.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10328",
        "abstract url": "https://arxiv.org/abs/2408.10328",
        "title": "Decoding Human Emotions: Analyzing Multi-Channel EEG Data using LSTM Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Emotion recognition from electroencephalogram (EEG) signals is a thriving field, particularly in neuroscience and Human-Computer Interaction (HCI). This study aims to understand and improve the predictive accuracy of emotional state classification through metrics such as valence, arousal, dominance, and likeness by applying a Long Short-Term Memory (LSTM) network to analyze EEG signals. Using a popular dataset of multi-channel EEG recordings known as DEAP, we look towards leveraging LSTM networks' properties to handle temporal dependencies within EEG signal data. This allows for a more comprehensive understanding and classification of emotional parameter states. We obtain accuracies of 89.89%, 90.33%, 90.70%, and 90.54% for arousal, valence, dominance, and likeness, respectively, demonstrating significant improvements in emotion recognition model capabilities. This paper elucidates the methodology and architectural specifics of our LSTM model and provides a benchmark analysis with existing papers.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "13 pages, 3 figures; accepted at ICDSA '24 Conference, Jaipur, India"
    },
    {
        "paper id": "2408.10351",
        "abstract url": "https://arxiv.org/abs/2408.10351",
        "title": "The Psychological Impacts of Algorithmic and AI-Driven Social Media on Teenagers: A Call to Action",
        "rating": "-1.5",
        "keywords": [
            [
                "Psychological"
            ],
            [
                "cs.AI",
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "This study investigates the meta-issues surrounding social media, which, while theoretically designed to enhance social interactions and improve our social lives by facilitating the sharing of personal experiences and life events, often results in adverse psychological impacts. Our investigation reveals a paradoxical outcome: rather than fostering closer relationships and improving social lives, the algorithms and structures that underlie social media platforms inadvertently contribute to a profound psychological impact on individuals, influencing them in unforeseen ways. This phenomenon is particularly pronounced among teenagers, who are disproportionately affected by curated online personas, peer pressure to present a perfect digital image, and the constant bombardment of notifications and updates that characterize their social media experience. As such, we issue a call to action for policymakers, platform developers, and educators to prioritize the well-being of teenagers in the digital age and work towards creating secure and safe social media platforms that protect the young from harm, online harassment, and exploitation.",
        "subjects": [
            "cs.SI",
            "cs.AI",
            "cs.CY",
            "cs.HC"
        ],
        "comment": "7 pages, 0 figures, 2 tables, 2024 IEEE Conference on Digital Platforms and Societal Harms"
    },
    {
        "paper id": "2408.10394",
        "abstract url": "https://arxiv.org/abs/2408.10394",
        "title": "Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Search and recommendation systems are essential in many services, and they are often developed separately, leading to complex maintenance and technical debt. In this paper, we present a unified deep learning model that efficiently handles key aspects of both tasks.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "3 pages, 1 figure"
    },
    {
        "paper id": "2408.10457",
        "abstract url": "https://arxiv.org/abs/2408.10457",
        "title": "Parkinson's Disease Classification via EEG: All You Need is a Single Convolutional Layer",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "EEG",
                "Disease",
                "pathological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we introduce LightCNN, a minimalist Convolutional Neural Network (CNN) architecture designed for Parkinson's disease (PD) classification using EEG data. LightCNN's strength lies in its simplicity, utilizing just a single convolutional layer. Embracing Leonardo da Vinci's principle that \"simplicity is the ultimate sophistication,\" LightCNN demonstrates that complexity is not required to achieve outstanding results. We benchmarked LightCNN against several state-of-the-art deep learning models known for their effectiveness in EEG-based PD classification. Remarkably, LightCNN outperformed all these complex architectures, with a 2.3% improvement in recall, a 4.6% increase in precision, a 0.1% edge in AUC, a 4% boost in F1-score, and a 3.3% higher accuracy compared to the closest competitor. Furthermore, LightCNN identifies known pathological brain rhythms associated with PD and effectively captures clinically relevant neurophysiological changes in EEG. Its simplicity and interpretability make it ideal for deployment in resource-constrained environments, such as mobile or embedded systems for EEG analysis. In conclusion, LightCNN represents a significant step forward in efficient EEG-based PD classification, demonstrating that a well-designed, lightweight model can achieve superior performance over more complex architectures. This work underscores the potential for minimalist models to meet the needs of modern healthcare applications, particularly where resources are limited.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": "10 pages, 5 figures"
    },
    {
        "paper id": "2408.10479",
        "abstract url": "https://arxiv.org/abs/2408.10479",
        "title": "An End-to-End Reinforcement Learning Based Approach for Micro-View Order-Dispatching in Ride-Hailing",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Assigning orders to drivers under localized spatiotemporal context (micro-view order-dispatching) is a major task in Didi, as it influences ride-hailing service experience. Existing industrial solutions mainly follow a two-stage pattern that incorporate heuristic or learning-based algorithms with naive combinatorial methods, tackling the uncertainty of both sides' behaviors, including emerging timings, spatial relationships, and travel duration, etc. In this paper, we propose a one-stage end-to-end reinforcement learning based order-dispatching approach that solves behavior prediction and combinatorial optimization uniformly in a sequential decision-making manner. Specifically, we employ a two-layer Markov Decision Process framework to model this problem, and present \\underline{D}eep \\underline{D}ouble \\underline{S}calable \\underline{N}etwork (D2SN), an encoder-decoder structure network to generate order-driver assignments directly and stop assignments accordingly. Besides, by leveraging contextual dynamics, our approach can adapt to the behavioral patterns for better performance. Extensive experiments on Didi's real-world benchmarks justify that the proposed approach significantly outperforms competitive baselines in optimizing matching efficiency and user experience tasks. In addition, we evaluate the deployment outline and discuss the gains and experiences obtained during the deployment tests from the view of large-scale engineering implementation.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2408.10482",
        "abstract url": "https://arxiv.org/abs/2408.10482",
        "title": "Evaluation Framework for AI-driven Molecular Design of Multi-target Drugs: Brain Diseases as a Case Study",
        "rating": "-1.5",
        "keywords": [
            [
                "bioassay"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The widespread application of Artificial Intelligence (AI) techniques has significantly influenced the development of new therapeutic agents. These computational methods can be used to design and predict the properties of generated molecules. Multi-target Drug Discovery (MTDD) is an emerging paradigm for discovering drugs against complex disorders that do not respond well to more traditional target-specific treatments, such as central nervous system, immune system, and cardiovascular diseases. Still, there is yet to be an established benchmark suite for assessing the effectiveness of AI tools for designing multi-target compounds. Standardized benchmarks allow for comparing existing techniques and promote rapid research progress. Hence, this work proposes an evaluation framework for molecule generation techniques in MTDD scenarios, considering brain diseases as a case study. Our methodology involves using large language models to select the appropriate molecular targets, gathering and preprocessing the bioassay datasets, training quantitative structure-activity relationship models to predict target modulation, and assessing other essential drug-likeness properties for implementing the benchmarks. Additionally, this work will assess the performance of four deep generative models and evolutionary algorithms over our benchmark suite. In our findings, both evolutionary algorithms and generative models can achieve competitive results across the proposed benchmarks.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": "8 pages, 1 figure, published in 2024 IEEE Congress on Evolutionary Computation (CEC)"
    },
    {
        "paper id": "2408.10483",
        "abstract url": "https://arxiv.org/abs/2408.10483",
        "title": "PRformer: Pyramidal Recurrent Transformer for Multivariate Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The self-attention mechanism in Transformer architecture, invariant to sequence order, necessitates positional embeddings to encode temporal order in time series prediction. We argue that this reliance on positional embeddings restricts the Transformer's ability to effectively represent temporal sequences, particularly when employing longer lookback windows. To address this, we introduce an innovative approach that combines Pyramid RNN embeddings(PRE) for univariate time series with the Transformer's capability to model multivariate dependencies. PRE, utilizing pyramidal one-dimensional convolutional layers, constructs multiscale convolutional features that preserve temporal order. Additionally, RNNs, layered atop these features, learn multiscale time series representations sensitive to sequence order. This integration into Transformer models with attention mechanisms results in significant performance enhancements. We present the PRformer, a model integrating PRE with a standard Transformer encoder, demonstrating state-of-the-art performance on various real-world datasets. This performance highlights the effectiveness of our approach in leveraging longer lookback windows and underscores the critical role of robust temporal representations in maximizing Transformer's potential for prediction tasks. Code is available at this repository: \\url{https://github.com/usualheart/PRformer}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.12389",
        "abstract url": "https://arxiv.org/abs/2408.12389",
        "title": "Fredholm Integral Equations Neural Operator (FIE-NO) for Data-Driven Boundary Value Problems",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present a novel Fredholm Integral Equation Neural Operator (FIE-NO) method, an integration of Random Fourier Features and Fredholm Integral Equations (FIE) into the deep learning framework, tailored for solving data-driven Boundary Value Problems (BVPs) with irregular boundaries. Unlike traditional computational approaches that struggle with the computational intensity and complexity of such problems, our method offers a robust, efficient, and accurate solution mechanism, using a physics inspired design of the learning structure. We demonstrate that the proposed physics-guided operator learning method (FIE-NO) achieves superior performance in addressing BVPs. Notably, our approach can generalize across multiple scenarios, including those with unknown equation forms and intricate boundary shapes, after being trained only on one boundary condition. Experimental validation demonstrates that the FIE-NO method performs well in simulated examples, including Darcy flow equation and typical partial differential equations such as the Laplace and Helmholtz equations. The proposed method exhibits robust performance across different boundary conditions. Experimental results indicate that FIE-NO achieves higher accuracy and stability compared to other methods when addressing complex boundary value problems with varying numbers of interior points.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09716",
        "abstract url": "https://arxiv.org/abs/2408.09716",
        "title": "RENAS: Prioritizing Co-Renaming Opportunities of Identifiers",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Renaming identifiers in source code is a common refactoring task in software development. When renaming an identifier, other identifiers containing words with the same naming intention related to the renaming should be renamed simultaneously. However, identifying these related identifiers can be challenging. This study introduces a technique called RENAS, which identifies and recommends related identifiers that should be renamed simultaneously in Java applications. RENAS determines priority scores for renaming candidates based on the relationships and similarities among identifiers. Since identifiers that have a relationship and/or have similar vocabulary in the source code are often renamed together, their priority scores are determined based on these factors. Identifiers with higher priority are recommended to be renamed together. Through an evaluation involving real renaming instances extracted from change histories and validated manually, RENAS demonstrated an improvement in the F1-measure by more than 0.11 compared with existing renaming recommendation approaches.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "ICSME 2024. (C) 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2408.09717",
        "abstract url": "https://arxiv.org/abs/2408.09717",
        "title": "SEMDR: A Semantic-Aware Dual Encoder Model for Legal Judgment Prediction with Legal Clue Tracing",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "crimes"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Legal Judgment Prediction (LJP) aims to form legal judgments based on the criminal fact description. However, researchers struggle to classify confusing criminal cases, such as robbery and theft, which requires LJP models to distinguish the nuances between similar crimes. Existing methods usually design handcrafted features to pick up necessary semantic legal clues to make more accurate legal judgment predictions. In this paper, we propose a Semantic-Aware Dual Encoder Model (SEMDR), which designs a novel legal clue tracing mechanism to conduct fine-grained semantic reasoning between criminal facts and instruments. Our legal clue tracing mechanism is built from three reasoning levels: 1) Lexicon-Tracing, which aims to extract criminal facts from criminal descriptions; 2) Sentence Representation Learning, which contrastively trains language models to better represent confusing criminal facts; 3) Multi-Fact Reasoning, which builds a reasons graph to propagate semantic clues among fact nodes to capture the subtle difference among criminal facts. Our legal clue tracing mechanism helps SEMDR achieve state-of-the-art on the CAIL2018 dataset and shows its advance in few-shot scenarios. Our experiments show that SEMDR has a strong ability to learn more uniform and distinguished representations for criminal facts, which helps to make more accurate predictions on confusing criminal cases and reduces the model uncertainty during making judgments. All codes will be released via GitHub.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09727",
        "abstract url": "https://arxiv.org/abs/2408.09727",
        "title": "Quantitative 3D Map Accuracy Evaluation Hardware and Algorithm for LiDAR(-Inertial) SLAM",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving",
                "LiDAR",
                "SLAM"
            ]
        ],
        "abstract": "Accuracy evaluation of a 3D pointcloud map is crucial for the development of autonomous driving systems. In this work, we propose a user-independent software/hardware system that can quantitatively evaluate the accuracy of a 3D pointcloud map acquired from LiDAR(-Inertial) SLAM. We introduce a LiDAR target that functions robustly in the outdoor environment, while remaining observable by LiDAR. We also propose a software algorithm that automatically extracts representative points and calculates the accuracy of the 3D pointcloud map by leveraging GPS position data. This methodology overcomes the limitations of the manual selection method, that its result varies between users. Furthermore, two different error metrics, relative and absolute errors, are introduced to analyze the accuracy from different perspectives. Our implementations are available at: https://github.com/SangwooJung98/3D_Map_Evaluation",
        "subjects": [
            "cs.RO"
        ],
        "comment": "ICCAS 2024 accepted, 5 pages, 6 figures, 2 Tables"
    },
    {
        "paper id": "2408.09729",
        "abstract url": "https://arxiv.org/abs/2408.09729",
        "title": "Targeted Drug Delivery: Algorithmic Methods for Collecting a Swarm of Particles with Uniform External Forces",
        "rating": "-2",
        "keywords": [
            [
                "tumor"
            ]
        ],
        "abstract": "We investigate algorithmic approaches for targeted drug delivery in a complex, maze-like environment, such as a vascular system. The basic scenario is given by a large swarm of micro-scale particles (''agents'') and a particular target region (''tumor'') within a system of passageways. Agents are too small to contain on-board power or computation and are instead controlled by a global external force that acts uniformly on all particles, such as an applied fluidic flow or electromagnetic field. The challenge is to deliver all agents to the target region with a minimum number of actuation steps. We provide a number of results for this challenge. We show that the underlying problem is NP-complete, which explains why previous work did not provide provably efficient algorithms. We also develop several algorithmic approaches that greatly improve the worst-case guarantees for the number of required actuation steps. We evaluate our algorithmic approaches by numerous simulations, both for deterministic algorithms and searches supported by deep learning, which show that the performance is practically promising.",
        "subjects": [
            "cs.CG"
        ],
        "comment": "21 pages, 11 figures; full version of an extended abstract that appeared in the proceedings of the 37th IEEE International Conference on Robotics and Automation (ICRA 2020)"
    },
    {
        "paper id": "2408.09764",
        "abstract url": "https://arxiv.org/abs/2408.09764",
        "title": "Event Stream based Human Action Recognition: A High-Definition Benchmark Dataset and Algorithms",
        "rating": "-2",
        "keywords": [
            [
                "voxel",
                "event cameras"
            ],
            [
                "bio-inspired"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Human Action Recognition (HAR) stands as a pivotal research domain in both computer vision and artificial intelligence, with RGB cameras dominating as the preferred tool for investigation and innovation in this field. However, in real-world applications, RGB cameras encounter numerous challenges, including light conditions, fast motion, and privacy concerns. Consequently, bio-inspired event cameras have garnered increasing attention due to their advantages of low energy consumption, high dynamic range, etc. Nevertheless, most existing event-based HAR datasets are low resolution ($346 \\times 260$). In this paper, we propose a large-scale, high-definition ($1280 \\times 800$) human action recognition dataset based on the CeleX-V event camera, termed CeleX-HAR. It encompasses 150 commonly occurring action categories, comprising a total of 124,625 video sequences. Various factors such as multi-view, illumination, action speed, and occlusion are considered when recording these data. To build a more comprehensive benchmark dataset, we report over 20 mainstream HAR models for future works to compare. In addition, we also propose a novel Mamba vision backbone network for event stream based HAR, termed EVMamba, which equips the spatial plane multi-directional scanning and novel voxel temporal scanning mechanism. By encoding and mining the spatio-temporal information of event streams, our EVMamba has achieved favorable results across multiple datasets. Both the dataset and source code will be released on \\url{https://github.com/Event-AHU/CeleX-HAR}",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.NE"
        ],
        "comment": "In Peer Review"
    },
    {
        "paper id": "2408.09792",
        "abstract url": "https://arxiv.org/abs/2408.09792",
        "title": "Unsupervised Composable Representations for Audio",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Current generative models are able to generate high-quality artefacts but have been shown to struggle with compositional reasoning, which can be defined as the ability to generate complex structures from simpler elements. In this paper, we focus on the problem of compositional representation learning for music data, specifically targeting the fully-unsupervised setting. We propose a simple and extensible framework that leverages an explicit compositional inductive bias, defined by a flexible auto-encoding objective that can leverage any of the current state-of-art generative models. We demonstrate that our framework, used with diffusion models, naturally addresses the task of unsupervised audio source separation, showing that our model is able to perform high-quality separation. Our findings reveal that our proposal achieves comparable or superior performance with respect to other blind source separation methods and, furthermore, it even surpasses current state-of-art supervised baselines on signal-to-interference ratio metrics. Additionally, by learning an a-posteriori masking diffusion model in the space of composable representations, we achieve a system capable of seamlessly performing unsupervised source separation, unconditional generation, and variation generation. Finally, as our proposal works in the latent space of pre-trained neural audio codecs, it also provides a lower computational cost with respect to other neural baselines.",
        "subjects": [
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "ISMIR 2024"
    },
    {
        "paper id": "2408.09822",
        "abstract url": "https://arxiv.org/abs/2408.09822",
        "title": "SurgicaL-CD: Generating Surgical Images via Unpaired Image Translation with Latent Consistency Diffusion Models",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "SurgicaL",
                "surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Computer-assisted surgery (CAS) systems are designed to assist surgeons during procedures, thereby reducing complications and enhancing patient care. Training machine learning models for these systems requires a large corpus of annotated datasets, which is challenging to obtain in the surgical domain due to patient privacy concerns and the significant labeling effort required from doctors. Previous methods have explored unpaired image translation using generative models to create realistic surgical images from simulations. However, these approaches have struggled to produce high-quality, diverse surgical images. In this work, we introduce \\emph{SurgicaL-CD}, a consistency-distilled diffusion method to generate realistic surgical images with only a few sampling steps without paired data. We evaluate our approach on three datasets, assessing the generated images in terms of quality and utility as downstream training datasets. Our results demonstrate that our method outperforms GANs and diffusion-based approaches. Our code is available at \\url{https://gitlab.com/nct_tso_public/gan2diffusion}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09831",
        "abstract url": "https://arxiv.org/abs/2408.09831",
        "title": "Ranking Generated Answers: On the Agreement of Retrieval Models with Humans on Consumer Health Questions",
        "rating": "-2",
        "keywords": [
            [
                "Health"
            ]
        ],
        "abstract": "Evaluating the output of generative large language models (LLMs) is challenging and difficult to scale. Most evaluations of LLMs focus on tasks such as single-choice question-answering or text classification. These tasks are not suitable for assessing open-ended question-answering capabilities, which are critical in domains where expertise is required, such as health, and where misleading or incorrect answers can have a significant impact on a user's health. Using human experts to evaluate the quality of LLM answers is generally considered the gold standard, but expert annotation is costly and slow. We present a method for evaluating LLM answers that uses ranking signals as a substitute for explicit relevance judgements. Our scoring method correlates with the preferences of human experts. We validate it by investigating the well-known fact that the quality of generated answers improves with the size of the model as well as with more sophisticated prompting strategies.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09909",
        "abstract url": "https://arxiv.org/abs/2408.09909",
        "title": "Early Validation of High-level System Requirements with Event Calculus and Answer Set Programming",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "This paper proposes a new methodology for early validation of high-level requirements on cyber-physical systems with the aim of improving their quality and, thus, lowering chances of specification errors propagating into later stages of development where it is much more expensive to fix them. The paper presents a transformation of a real-world requirements specification of a medical device$-$a PCA pump$-$into an Event Calculus model that is then evaluated using answer set programming and the s(CASP) system. The evaluation under s(CASP) allowed deductive as well as abductive reasoning about the specified functionality of the PCA pump on the conceptual level with minimal implementation or design dependent influences, and led to fully-automatically detected nuanced violations of critical safety properties. Further, the paper discusses scalability and non-termination challenges that had to be faced in the evaluation and techniques proposed to (partially) solve them. Finally, ideas for improving s(CASP) to overcome its evaluation limitations that still persist as well as to increase its expressiveness are presented.",
        "subjects": [
            "cs.LO",
            "cs.SE"
        ],
        "comment": "Accepted for ICLP 2024"
    },
    {
        "paper id": "2408.09912",
        "abstract url": "https://arxiv.org/abs/2408.09912",
        "title": "Harnessing Multi-resolution and Multi-scale Attention for Underwater Image Restoration",
        "rating": "-2",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "Image Restoration",
                "image enhancement"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Underwater imagery is often compromised by factors such as color distortion and low contrast, posing challenges for high-level vision tasks. Recent underwater image restoration (UIR) methods either analyze the input image at full resolution, resulting in spatial richness but contextual weakness, or progressively from high to low resolution, yielding reliable semantic information but reduced spatial accuracy. Here, we propose a lightweight multi-stage network called Lit-Net that focuses on multi-resolution and multi-scale image analysis for restoring underwater images while retaining original resolution during the first stage, refining features in the second, and focusing on reconstruction in the final stage. Our novel encoder block utilizes parallel $1\\times1$ convolution layers to capture local information and speed up operations. Further, we incorporate a modified weighted color channel-specific $l_1$ loss ($cl_1$) function to recover color and detail information. Extensive experimentations on publicly available datasets suggest our model's superiority over recent state-of-the-art methods, with significant improvement in qualitative and quantitative measures, such as $29.477$ dB PSNR ($1.92\\%$ improvement) and $0.851$ SSIM ($2.87\\%$ improvement) on the EUVP dataset. The contributions of Lit-Net offer a more robust approach to underwater image enhancement and super-resolution, which is of considerable importance for underwater autonomous vehicles and surveillance. The code is available at: https://github.com/Alik033/Lit-Net.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09935",
        "abstract url": "https://arxiv.org/abs/2408.09935",
        "title": "Privacy Technologies for Financial Intelligence",
        "rating": "-2",
        "keywords": [
            [
                "crimes"
            ]
        ],
        "abstract": "Financial crimes like terrorism financing and money laundering can have real impacts on society, including the abuse and mismanagement of public funds, increase in societal problems such as drug trafficking and illicit gambling with attendant economic costs, and loss of innocent lives in the case of terrorism activities. Complex financial crimes can be hard to detect primarily because data related to different pieces of the overall puzzle is usually distributed across a network of financial institutions, regulators, and law-enforcement agencies and they cannot be easily shared due to privacy constraints. Recent advances in Privacy-Preserving Data Matching and Machine Learning provide an opportunity for regulators and the financial industry to come together to solve the risk-discovery problem with technology. This paper provides a survey of the financial intelligence landscape and where opportunities lie for privacy technologies to improve the state-of-the-art in financial-crime detection.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09992",
        "abstract url": "https://arxiv.org/abs/2408.09992",
        "title": "Efficient Inference of Sub-Item Id-based Sequential Recommendation Models with Millions of Items",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Transformer-based recommender systems, such as BERT4Rec or SASRec, achieve state-of-the-art results in sequential recommendation. However, it is challenging to use these models in production environments with catalogues of millions of items: scaling Transformers beyond a few thousand items is problematic for several reasons, including high model memory consumption and slow inference. In this respect, RecJPQ is a state-of-the-art method of reducing the models' memory consumption; RecJPQ compresses item catalogues by decomposing item IDs into a small number of shared sub-item IDs. Despite reporting the reduction of memory consumption by a factor of up to 50x, the original RecJPQ paper did not report inference efficiency improvements over the baseline Transformer-based models. Upon analysing RecJPQ's scoring algorithm, we find that its efficiency is limited by its use of score accumulators for each item, which prevents parallelisation. In contrast, LightRec (a non-sequential method that uses a similar idea of sub-ids) reported large inference efficiency improvements using an algorithm we call PQTopK. We show that it is also possible to improve RecJPQ-based models' inference efficiency using the PQTopK algorithm. In particular, we speed up RecJPQ-enhanced SASRec by a factor of 4.5 x compared to the original SASRec's inference method and by a factor of 1.56 x compared to the method implemented in RecJPQ code on a large-scale Gowalla dataset with more than a million items. Further, using simulated data, we show that PQTopK remains efficient with catalogues of up to tens of millions of items, removing one of the last obstacles to using Transformer-based models in production environments with large catalogues.",
        "subjects": [
            "cs.IR",
            "cs.DS"
        ],
        "comment": "Accepted by RecSys 2024"
    },
    {
        "paper id": "2408.10001",
        "abstract url": "https://arxiv.org/abs/2408.10001",
        "title": "Coprime Bivariate Bicycle Codes and their Properties",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "This work (1) proposes a novel numerical algorithm to accelerate the search process for good Bivariate Bicycle (BB) codes and (2) defines a new variant of BB codes suitable for quantum error correction. The proposed acceleration search algorithm reduces the search space by excluding some equivalent codes from the search space, as well as setting thresholds to drop bad codes at an early stage. A number of new BB codes found by this algorithm are reported. The proposed variant of BB codes employs coprimes to construct groups via polynomials as the basis for the BB code, rather than using the standard BB codes with unconstrained constructors. In contrast to vanilla BB codes, where parameters remain unknown prior to code discovery, the rate of the proposed code can be determined beforehand by specifying a factor polynomial as an input to the numerical search algorithm. Using this coprime BB construction, we found a number of surprisingly short to medium-length codes that were previously unknown.",
        "subjects": [
            "quant-ph",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10053",
        "abstract url": "https://arxiv.org/abs/2408.10053",
        "title": "Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Health"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Privacy research has attracted wide attention as individuals worry that their private data can be easily leaked during interactions with smart devices, social platforms, and AI applications. Computer science researchers, on the other hand, commonly study privacy issues through privacy attacks and defenses on segmented fields. Privacy research is conducted on various sub-fields, including Computer Vision (CV), Natural Language Processing (NLP), and Computer Networks. Within each field, privacy has its own formulation. Though pioneering works on attacks and defenses reveal sensitive privacy issues, they are narrowly trapped and cannot fully cover people's actual privacy concerns. Consequently, the research on general and human-centric privacy research remains rather unexplored. In this paper, we formulate the privacy issue as a reasoning problem rather than simple pattern matching. We ground on the Contextual Integrity (CI) theory which posits that people's perceptions of privacy are highly correlated with the corresponding social context. Based on such an assumption, we develop the first comprehensive checklist that covers social identities, private attributes, and existing privacy regulations. Unlike prior works on CI that either cover limited expert annotated norms or model incomplete social context, our proposed privacy checklist uses the whole Health Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to show that we can resort to large language models (LLMs) to completely cover the HIPAA's regulations. Additionally, our checklist also gathers expert annotations across multiple ontologies to determine private information including but not limited to personally identifiable information (PII). We use our preliminary results on the HIPAA to shed light on future context-centric privacy research to cover more privacy regulations, social norms and standards.",
        "subjects": [
            "cs.CL",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10054",
        "abstract url": "https://arxiv.org/abs/2408.10054",
        "title": "Quantum Register Machine: Efficient Implementation of Quantum Recursive Programs",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum recursive programming has been recently introduced for describing sophisticated and complicated quantum algorithms in a compact and elegant way. However, implementation of quantum recursion involves intricate interplay between quantum control flows and recursive procedure calls. In this paper, we aim at resolving this fundamental challenge and develop a series of techniques to efficiently implement quantum recursive programs. Our main contributions include: 1. We propose a notion of quantum register machine, the first purely quantum architecture (including an instruction set) that supports quantum control flows and recursive procedure calls at the same time. 2. Based on quantum register machine, we describe the first comprehensive implementation process of quantum recursive programs, including the compilation, the partial evaluation of quantum control flows, and the execution on the quantum register machine. 3. As a bonus, our efficient implementation of quantum recursive programs also offers automatic parallelisation of quantum algorithms. For implementing certain quantum algorithmic subroutine, like the widely used quantum multiplexor, we can even obtain exponential parallel speed-up (over the straightforward implementation) from this automatic parallelisation. This demonstrates that quantum recursive programming can be win-win for both modularity of programs and efficiency of their implementation.",
        "subjects": [
            "quant-ph",
            "cs.AR",
            "cs.PL"
        ],
        "comment": "71 pages, 26 figures"
    },
    {
        "paper id": "2408.10067",
        "abstract url": "https://arxiv.org/abs/2408.10067",
        "title": "Towards a Benchmark for Colorectal Cancer Segmentation in Endorectal Ultrasound Videos: Dataset and Model Development",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "diagnosing",
                "Cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Endorectal ultrasound (ERUS) is an important imaging modality that provides high reliability for diagnosing the depth and boundary of invasion in colorectal cancer. However, the lack of a large-scale ERUS dataset with high-quality annotations hinders the development of automatic ultrasound diagnostics. In this paper, we collected and annotated the first benchmark dataset that covers diverse ERUS scenarios, i.e. colorectal cancer segmentation, detection, and infiltration depth staging. Our ERUS-10K dataset comprises 77 videos and 10,000 high-resolution annotated frames. Based on this dataset, we further introduce a benchmark model for colorectal cancer segmentation, named the Adaptive Sparse-context TRansformer (ASTR). ASTR is designed based on three considerations: scanning mode discrepancy, temporal information, and low computational complexity. For generalizing to different scanning modes, the adaptive scanning-mode augmentation is proposed to convert between raw sector images and linear scan ones. For mining temporal information, the sparse-context transformer is incorporated to integrate inter-frame local and global features. For reducing computational complexity, the sparse-context block is introduced to extract contextual features from auxiliary frames. Finally, on the benchmark dataset, the proposed ASTR model achieves a 77.6% Dice score in rectal cancer segmentation, largely outperforming previous state-of-the-art methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10069",
        "abstract url": "https://arxiv.org/abs/2408.10069",
        "title": "LNQ 2023 challenge: Benchmark of weakly-supervised techniques for mediastinal lymph node quantification",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "CT",
                "cancer"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate assessment of lymph node size in 3D CT scans is crucial for cancer staging, therapeutic management, and monitoring treatment response. Existing state-of-the-art segmentation frameworks in medical imaging often rely on fully annotated datasets. However, for lymph node segmentation, these datasets are typically small due to the extensive time and expertise required to annotate the numerous lymph nodes in 3D CT scans. Weakly-supervised learning, which leverages incomplete or noisy annotations, has recently gained interest in the medical imaging community as a potential solution. Despite the variety of weakly-supervised techniques proposed, most have been validated only on private datasets or small publicly available datasets. To address this limitation, the Mediastinal Lymph Node Quantification (LNQ) challenge was organized in conjunction with the 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023). This challenge aimed to advance weakly-supervised segmentation methods by providing a new, partially annotated dataset and a robust evaluation framework. A total of 16 teams from 5 countries submitted predictions to the validation leaderboard, and 6 teams from 3 countries participated in the evaluation phase. The results highlighted both the potential and the current limitations of weakly-supervised approaches. On one hand, weakly-supervised approaches obtained relatively good performance with a median Dice score of $61.0\\%$. On the other hand, top-ranked teams, with a median Dice score exceeding $70\\%$, boosted their performance by leveraging smaller but fully annotated datasets to combine weak supervision and full supervision. This highlights both the promise of weakly-supervised methods and the ongoing need for high-quality, fully annotated data to achieve higher segmentation performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to MELBA"
    },
    {
        "paper id": "2408.10072",
        "abstract url": "https://arxiv.org/abs/2408.10072",
        "title": "FFAA: Multimodal Large Language Model based Explainable Open-World Face Forgery Analysis Assistant",
        "rating": "-2",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement of deepfake technologies has sparked widespread public concern, particularly as face forgery poses a serious threat to public information security. However, the unknown and diverse forgery techniques, varied facial features and complex environmental factors pose significant challenges for face forgery analysis. Existing datasets lack descriptions of these aspects, making it difficult for models to distinguish between real and forged faces using only visual information amid various confounding factors. In addition, existing methods do not yield user-friendly and explainable results, complicating the understanding of the model's decision-making process. To address these challenges, we introduce a novel Open-World Face Forgery Analysis VQA (OW-FFA-VQA) task and the corresponding benchmark. To tackle this task, we first establish a dataset featuring a diverse collection of real and forged face images with essential descriptions and reliable forgery reasoning. Base on this dataset, we introduce FFAA: Face Forgery Analysis Assistant, consisting of a fine-tuned Multimodal Large Language Model (MLLM) and Multi-answer Intelligent Decision System (MIDS). By integrating hypothetical prompts with MIDS, the impact of fuzzy classification boundaries is effectively mitigated, enhancing the model's robustness. Extensive experiments demonstrate that our method not only provides user-friendly explainable results but also significantly boosts accuracy and robustness compared to previous methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "17 pages, 18 figures; project page: https://ffaa-vl.github.io"
    },
    {
        "paper id": "2408.10099",
        "abstract url": "https://arxiv.org/abs/2408.10099",
        "title": "Neural Representation of Shape-Dependent Laplacian Eigenfunctions",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "The eigenfunctions of the Laplace operator are essential in mathematical physics, engineering, and geometry processing. Typically, these are computed by discretizing the domain and performing eigendecomposition, tying the results to a specific mesh. However, this method is unsuitable for continuously-parameterized shapes. We propose a novel representation for eigenfunctions in continuously-parameterized shape spaces, where eigenfunctions are spatial fields with continuous dependence on shape parameters, defined by minimal Dirichlet energy, unit norm, and mutual orthogonality. We implement this with multilayer perceptrons trained as neural fields, mapping shape parameters and domain positions to eigenfunction values. A unique challenge is enforcing mutual orthogonality with respect to causality, where the causal ordering varies across the shape space. Our training method therefore requires three interwoven concepts: (1) learning $n$ eigenfunctions concurrently by minimizing Dirichlet energy with unit norm constraints; (2) filtering gradients during backpropagation to enforce causal orthogonality, preventing earlier eigenfunctions from being influenced by later ones; (3) dynamically sorting the causal ordering based on eigenvalues to track eigenvalue curve crossovers. We demonstrate our method on problems such as shape family analysis, predicting eigenfunctions for incomplete shapes, interactive shape manipulation, and computing higher-dimensional eigenfunctions, on all of which traditional methods fall short.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10110",
        "abstract url": "https://arxiv.org/abs/2408.10110",
        "title": "Electrically Reconfigurable Non-Volatile On-Chip Bragg Filter with Multilevel Operation",
        "rating": "-2",
        "keywords": [
            [
                "thermal"
            ]
        ],
        "abstract": "Photonic integrated circuits (PICs) demand tailored spectral responses for various applications. On-chip Bragg filters offer a promising solution, yet their static nature hampers scalability. Current tunable filters rely on volatile switching mechanisms plagued by high static power consumption and thermal crosstalk. Here, we introduce, for the first time, a non-volatile, electrically programmable on-chip Bragg filter. This device incorporates a nanoscale layer of wide-bandgap phase change material (Sb2S3) atop a periodically structured silicon waveguide. The reversible phase transitions and drastic refractive index modulation of Sb2S3 enable dynamic spectral tuning via foundry-compatible microheaters. Our design surpasses traditional passive Bragg gratings and active volatile filters by offering electrically controlled, reconfigurable spectral responses in a non-volatile manner. The proposed filter achieves a peak reflectivity exceeding 99% and a high tuning range ($\u0394\u03bb$=20 nm) when transitioning between the amorphous and crystalline states of Sb2S3. Additionally, we demonstrate quasi-continuous spectral control of the filter stopband by modulating the amorphous/crystalline distribution within Sb2S3. Our approach offers substantial benefits for low-power, programmable PICs, thereby laying the groundwork for prospective applications in optical communications, optical interconnects, microwave photonics, optical signal processing, and adaptive multi-parameter sensing.",
        "subjects": [
            "physics.optics",
            "eess.SP",
            "physics.app-ph"
        ],
        "comment": "20 pages, 4 figures,"
    },
    {
        "paper id": "2408.10134",
        "abstract url": "https://arxiv.org/abs/2408.10134",
        "title": "Perceptual Depth Quality Assessment of Stereoscopic Omnidirectional Images",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "Quality Assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Depth perception plays an essential role in the viewer experience for immersive virtual reality (VR) visual environments. However, previous research investigations in the depth quality of 3D/stereoscopic images are rather limited, and in particular, are largely lacking for 3D viewing of 360-degree omnidirectional content. In this work, we make one of the first attempts to develop an objective quality assessment model named depth quality index (DQI) for efficient no-reference (NR) depth quality assessment of stereoscopic omnidirectional images. Motivated by the perceptual characteristics of the human visual system (HVS), the proposed DQI is built upon multi-color-channel, adaptive viewport selection, and interocular discrepancy features. Experimental results demonstrate that the proposed method outperforms state-of-the-art image quality assessment (IQA) and depth quality assessment (DQA) approaches in predicting the perceptual depth quality when tested using both single-viewport and omnidirectional stereoscopic image databases. Furthermore, we demonstrate that combining the proposed depth quality model with existing IQA methods significantly boosts the performance in predicting the overall quality of 3D omnidirectional images.",
        "subjects": [
            "cs.CV",
            "cs.MM",
            "eess.IV"
        ],
        "comment": "Accepted by IEEE TCSVT"
    },
    {
        "paper id": "2408.10135",
        "abstract url": "https://arxiv.org/abs/2408.10135",
        "title": "$R^2$-Mesh: Reinforcement Learning Powered Mesh Reconstruction via Geometry and Appearance Refinement",
        "rating": "-2",
        "keywords": [
            [
                "NeRF",
                "Radiance Fields",
                "Signed Distance Field",
                "SDF"
            ],
            [
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Mesh reconstruction based on Neural Radiance Fields (NeRF) is popular in a variety of applications such as computer graphics, virtual reality, and medical imaging due to its efficiency in handling complex geometric structures and facilitating real-time rendering. However, existing works often fail to capture fine geometric details accurately and struggle with optimizing rendering quality. To address these challenges, we propose a novel algorithm that progressively generates and optimizes meshes from multi-view images. Our approach initiates with the training of a NeRF model to establish an initial Signed Distance Field (SDF) and a view-dependent appearance field. Subsequently, we iteratively refine the SDF through a differentiable mesh extraction method, continuously updating both the vertex positions and their connectivity based on the loss from mesh differentiable rasterization, while also optimizing the appearance representation. To further leverage high-fidelity and detail-rich representations from NeRF, we propose an online-learning strategy based on Upper Confidence Bound (UCB) to enhance viewpoints by adaptively incorporating images rendered by the initial NeRF model into the training dataset. Through extensive experiments, we demonstrate that our method delivers highly competitive and robust performance in both mesh rendering quality and geometric quality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10145",
        "abstract url": "https://arxiv.org/abs/2408.10145",
        "title": "Multi-Scale Representation Learning for Image Restoration with State-Space Model",
        "rating": "-2",
        "keywords": [
            [
                "deraining"
            ],
            [
                "Image Restoration",
                "dehazing",
                "low-light enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image restoration endeavors to reconstruct a high-quality, detail-rich image from a degraded counterpart, which is a pivotal process in photography and various computer vision systems. In real-world scenarios, different types of degradation can cause the loss of image details at various scales and degrade image contrast. Existing methods predominantly rely on CNN and Transformer to capture multi-scale representations. However, these methods are often limited by the high computational complexity of Transformers and the constrained receptive field of CNN, which hinder them from achieving superior performance and efficiency in image restoration. To address these challenges, we propose a novel Multi-Scale State-Space Model-based (MS-Mamba) for efficient image restoration that enhances the capacity for multi-scale representation learning through our proposed global and regional SSM modules. Additionally, an Adaptive Gradient Block (AGB) and a Residual Fourier Block (RFB) are proposed to improve the network's detail extraction capabilities by capturing gradients in various directions and facilitating learning details in the frequency domain. Extensive experiments on nine public benchmarks across four classic image restoration tasks, image deraining, dehazing, denoising, and low-light enhancement, demonstrate that our proposed method achieves new state-of-the-art performance while maintaining low computational complexity. The source code will be publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10153",
        "abstract url": "https://arxiv.org/abs/2408.10153",
        "title": "Structure-preserving Image Translation for Depth Estimation in Colonoscopy Video",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Monocular depth estimation in colonoscopy video aims to overcome the unusual lighting properties of the colonoscopic environment. One of the major challenges in this area is the domain gap between annotated but unrealistic synthetic data and unannotated but realistic clinical data. Previous attempts to bridge this domain gap directly target the depth estimation task itself. We propose a general pipeline of structure-preserving synthetic-to-real (sim2real) image translation (producing a modified version of the input image) to retain depth geometry through the translation process. This allows us to generate large quantities of realistic-looking synthetic images for supervised depth estimation with improved generalization to the clinical domain. We also propose a dataset of hand-picked sequences from clinical colonoscopies to improve the image translation process. We demonstrate the simultaneous realism of the translated images and preservation of depth maps via the performance of downstream depth estimation on various datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 7 figures, accepted at MICCAI 2024"
    },
    {
        "paper id": "2408.10154",
        "abstract url": "https://arxiv.org/abs/2408.10154",
        "title": "LoopSplat: Loop Closure by Registering 3D Gaussian Splats",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "point cloud",
                "RGB-D"
            ],
            [
                "SLAM"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Simultaneous Localization and Mapping (SLAM) based on 3D Gaussian Splats (3DGS) has recently shown promise towards more accurate, dense 3D scene maps. However, existing 3DGS-based methods fail to address the global consistency of the scene via loop closure and/or global bundle adjustment. To this end, we propose LoopSplat, which takes RGB-D images as input and performs dense mapping with 3DGS submaps and frame-to-model tracking. LoopSplat triggers loop closure online and computes relative loop edge constraints between submaps directly via 3DGS registration, leading to improvements in efficiency and accuracy over traditional global-to-local point cloud registration. It uses a robust pose graph optimization formulation and rigidly aligns the submaps to achieve global consistency. Evaluation on the synthetic Replica and real-world TUM-RGBD, ScanNet, and ScanNet++ datasets demonstrates competitive or superior tracking, mapping, and rendering compared to existing methods for dense RGB-D SLAM. Code is available at loopsplat.github.io.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Project page: https://loopsplat.github.io/"
    },
    {
        "paper id": "2408.10181",
        "abstract url": "https://arxiv.org/abs/2408.10181",
        "title": "Imbalance-Aware Culvert-Sewer Defect Segmentation Using an Enhanced Feature Pyramid Network",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "drone"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Imbalanced datasets are a significant challenge in real-world scenarios. They lead to models that underperform on underrepresented classes, which is a critical issue in infrastructure inspection. This paper introduces the Enhanced Feature Pyramid Network (E-FPN), a deep learning model for the semantic segmentation of culverts and sewer pipes within imbalanced datasets. The E-FPN incorporates architectural innovations like sparsely connected blocks and depth-wise separable convolutions to improve feature extraction and handle object variations. To address dataset imbalance, the model employs strategies like class decomposition and data augmentation. Experimental results on the culvert-sewer defects dataset and a benchmark aerial semantic segmentation drone dataset show that the E-FPN outperforms state-of-the-art methods, achieving an average Intersection over Union (IoU) improvement of 13.8% and 27.2%, respectively. Additionally, class decomposition and data augmentation together boost the model's performance by approximately 6.9% IoU. The proposed E-FPN presents a promising solution for enhancing object segmentation in challenging, multi-class real-world datasets, with potential applications extending beyond culvert-sewer defect detection.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10192",
        "abstract url": "https://arxiv.org/abs/2408.10192",
        "title": "A Biologically Inspired Design Principle for Building Robust Robotic Systems",
        "rating": "-2",
        "keywords": [
            [
                "Biologically"
            ]
        ],
        "abstract": "Robustness, the ability of a system to maintain performance under significant and unanticipated environmental changes, is a critical property for robotic systems. While biological systems naturally exhibit robustness, there is no comprehensive understanding of how to achieve similar robustness in robotic systems. In this work, we draw inspirations from biological systems and propose a design principle that advocates active interconnections among system components to enhance robustness to environmental variations. We evaluate this design principle in a challenging long-horizon manipulation task: solving lockboxes. Our extensive simulated and real-world experiments demonstrate that we could enhance robustness against environmental changes by establishing active interconnections among system components without substantial changes in individual components. Our findings suggest that a systematic investigation of design principles in system building is necessary. It also advocates for interdisciplinary collaborations to explore and evaluate additional principles of biological robustness to advance the development of intelligent and adaptable robotic systems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10287",
        "abstract url": "https://arxiv.org/abs/2408.10287",
        "title": "Recognizing Beam Profiles from Silicon Photonics Gratings using Transformer Model",
        "rating": "-2",
        "keywords": [
            [
                "infrared"
            ],
            [
                "quantum"
            ],
            [
                "cs.AI",
                "eess.IV"
            ]
        ],
        "abstract": "Over the past decade, there has been extensive work in developing integrated silicon photonics (SiPh) gratings for the optical addressing of trapped ion qubits in the ion trap quantum computing community. However, when viewing beam profiles from infrared (IR) cameras, it is often difficult to determine the corresponding heights where the beam profiles are located. In this work, we developed transformer models to recognize the corresponding height categories of beam profiles of light from SiPh gratings. The model is trained using two techniques: (1) input patches, and (2) input sequence. For model trained with input patches, the model achieved recognition accuracy of 0.938. Meanwhile, model trained with input sequence shows lower accuracy of 0.895. However, when repeating the model-training 150 cycles, model trained with input patches shows inconsistent accuracy ranges between 0.445 to 0.959, while model trained with input sequence exhibit higher accuracy values between 0.789 to 0.936. The obtained outcomes can be expanded to various applications, including auto-focusing of light beam and auto-adjustment of z-axis stage to acquire desired beam profiles.",
        "subjects": [
            "physics.optics",
            "cs.AI",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10323",
        "abstract url": "https://arxiv.org/abs/2408.10323",
        "title": "SDP bounds on quantum codes",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "This paper provides a semidefinite programming hierarchy based on state polynomial optimization to determine the existence of quantum codes with given parameters. The hierarchy is complete, in the sense that if a $(\\!(n,K,\u03b4)\\!)_2$ code does not exist then a level of the hierarchy is infeasible. It is not limited to stabilizer codes and thus applicable generally. While it is formally dimension-free, we restrict it to qubit codes through quasi-Clifford algebras. We derive the quantum analog of a range of classical results: first, from an intermediate level a Lov\u00e1sz bound for self-dual quantum codes is recovered. Second, a symmetrization of a minor variation of this Lov\u00e1sz bound recovers the quantum Delsarte bound. Third, a symmetry reduction using the Terwilliger algebra leads to semidefinite programming bounds of size $O(n^4)$. With this we give an alternative proof that there is no $(\\!(7,1,4)\\!)_2$ quantum code, and show that $(\\!(8,9,3)\\!)_2$ and $(\\!(10,5,4)\\!)_2$ codes do not exist.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "math.OC"
        ],
        "comment": "51 pages"
    },
    {
        "paper id": "2408.10374",
        "abstract url": "https://arxiv.org/abs/2408.10374",
        "title": "Security Risks Due to Data Persistence in Cloud FPGA Platforms",
        "rating": "-2",
        "keywords": [
            [
                "FPGA"
            ]
        ],
        "abstract": "The integration of Field Programmable Gate Arrays (FPGAs) into cloud computing systems has become commonplace. As the operating systems used to manage these systems evolve, special consideration must be given to DRAM devices accessible by FPGAs. These devices may hold sensitive data that can become inadvertently exposed to adversaries following user logout. Although addressed in some cloud FPGA environments, automatic DRAM clearing after process termination is not automatically included in popular FPGA runtime environments nor in most proposed cloud FPGA hypervisors. In this paper, we examine DRAM data persistence in AMD/Xilinx Alveo U280 nodes that are part of the Open Cloud Testbed (OCT). Our results indicate that DDR4 DRAM is not automatically cleared following user logout from an allocated node and subsequent node users can easily obtain recognizable data from the DRAM following node reallocation over 17 minutes later. This issue is particularly relevant for systems which support FPGA multi-tenancy.",
        "subjects": [
            "cs.CR",
            "cs.AR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10376",
        "abstract url": "https://arxiv.org/abs/2408.10376",
        "title": "Self-Play Ensemble Q-learning enabled Resource Allocation for Network Slicing",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "In 5G networks, network slicing has emerged as a pivotal paradigm to address diverse user demands and service requirements. To meet the requirements, reinforcement learning (RL) algorithms have been utilized widely, but this method has the problem of overestimation and exploration-exploitation trade-offs. To tackle these problems, this paper explores the application of self-play ensemble Q-learning, an extended version of the RL-based technique. Self-play ensemble Q-learning utilizes multiple Q-tables with various exploration-exploitation rates leading to different observations for choosing the most suitable action for each state. Moreover, through self-play, each model endeavors to enhance its performance compared to its previous iterations, boosting system efficiency, and decreasing the effect of overestimation. For performance evaluation, we consider three RL-based algorithms; self-play ensemble Q-learning, double Q-learning, and Q-learning, and compare their performance under different network traffic. Through simulations, we demonstrate the effectiveness of self-play ensemble Q-learning in meeting the diverse demands within 21.92% in latency, 24.22% in throughput, and 23.63\\% in packet drop rate in comparison with the baseline methods. Furthermore, we evaluate the robustness of self-play ensemble Q-learning and double Q-learning in situations where one of the Q-tables is affected by a malicious user. Our results depicted that the self-play ensemble Q-learning method is more robust against adversarial users and prevents a noticeable drop in system performance, mitigating the impact of users manipulating policies.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10390",
        "abstract url": "https://arxiv.org/abs/2408.10390",
        "title": "Self-Refined Generative Foundation Models for Wireless Traffic Prediction",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "With a broad range of emerging applications in 6G networks, wireless traffic prediction has become a critical component of network management. However, the dynamically shifting distribution of wireless traffic in non-stationary 6G networks presents significant challenges to achieving accurate and stable predictions. Motivated by recent advancements in Generative AI (GAI)-enabled 6G networks, this paper proposes a novel self-refined Large Language Model (LLM) for wireless traffic prediction, namely TrafficLLM, through in-context learning without parameter fine-tuning or model training. The proposed TrafficLLM harnesses the powerful few-shot learning abilities of LLMs to enhance the scalability of traffic prediction in dynamically changing wireless environments. Specifically, our proposed TrafficLLM embraces an LLM to iteratively refine its predictions through a three-step process: traffic prediction, feedback generation, and prediction refinement. Initially, the proposed TrafficLLM conducts traffic predictions using task-specific demonstration prompts. Recognizing that LLMs may generate incorrect predictions on the first attempt, we subsequently incorporate feedback demonstration prompts designed to provide multifaceted and valuable feedback related to these initial predictions. Following this comprehensive feedback, our proposed TrafficLLM introduces refinement demonstration prompts, enabling the same LLM to further refine its predictions and thereby enhance prediction performance. The evaluations on two realistic datasets demonstrate that the proposed TrafficLLM outperforms state-of-the-art methods with performance improvements of 23.17% and 17.09%, respectively.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10397",
        "abstract url": "https://arxiv.org/abs/2408.10397",
        "title": "Webcam-based Pupil Diameter Prediction Benefits from Upscaling",
        "rating": "-2",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "psychological",
                "physiological"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Capturing pupil diameter is essential for assessing psychological and physiological states such as stress levels and cognitive load. However, the low resolution of images in eye datasets often hampers precise measurement. This study evaluates the impact of various upscaling methods, ranging from bicubic interpolation to advanced super-resolution, on pupil diameter predictions. We compare several pre-trained methods, including CodeFormer, GFPGAN, Real-ESRGAN, HAT, and SRResNet. Our findings suggest that pupil diameter prediction models trained on upscaled datasets are highly sensitive to the selected upscaling method and scale. Our results demonstrate that upscaling methods consistently enhance the accuracy of pupil diameter prediction models, highlighting the importance of upscaling in pupilometry. Overall, our work provides valuable insights for selecting upscaling techniques, paving the way for more accurate assessments in psychological and physiological research.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10462",
        "abstract url": "https://arxiv.org/abs/2408.10462",
        "title": "High-Sensitivity and Compact Time-domain Soil Moisture Sensor Using Dispersive Phase Shifter for Complex Permittivity Measurement",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "This paper presents a Time-Domain Transmissometry Soil Moisture Sensor (TDT-SMS) using a Dispersive Phase Shifter (DPS), consisting of an interdigital capacitor that is loaded with a stacked 4-turn Complementary Spiral Resonator (S4-CSR). Soil moisture measurement technique of the proposed sensor is based on the complex permittivity sensing property of a DPS in time domain. Soil relative permittivity which varies with its moisture content is measured by burying the DPS under a soil mass and changing its phase difference while excited with a 114 MHz sine wave (single tone). DPS output phase and magnitude are compared with the reference signal and measured with a phase/loss detector. The proposed sensor exhibits accuracy better than +-1.2 percent at the highest Volumetric Water Content (VWC=30 percent) for sandy-type soil. Precise design guide is developed and simulations are performed to achieve a highly sensitive sensor. The measurement results validate the accuracy of theoretical analysis and design procedure. Owning the advantages of low profile, low power consumption, and high sensitivity makes the proposed TDT-SMS a good candidate for precision farming and IoT systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10484",
        "abstract url": "https://arxiv.org/abs/2408.10484",
        "title": "Dependable Classical-Quantum Computer Systems Engineering",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum Computing (QC) offers the potential to enhance traditional High-Performance Computing (HPC) workloads by leveraging the unique properties of quantum computers, leading to the emergence of a new paradigm: HPC-QC. While this integration presents new opportunities, it also brings novel challenges, particularly in ensuring the dependability of such hybrid systems. This paper aims to identify integration challenges, anticipate failures, and foster a diverse co-design for HPC-QC systems by bringing together QC, cloud computing, HPC, and network security. The focus of this emerging inter-disciplinary effort is to develop engineering principles that ensure the dependability of hybrid systems, aiming for a more prescriptive co-design cycle. Our framework will help to prevent design pitfalls and accelerate the maturation of the QC technology ecosystem. Key aspects include building resilient HPC-QC systems, analyzing the applicability of conventional techniques to the quantum domain, and exploring the complexity of scaling in such hybrid systems. This underscores the need for performance-reliability metrics specific to this new computational paradigm.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10531",
        "abstract url": "https://arxiv.org/abs/2408.10531",
        "title": "Leveraging Temporal Contexts to Enhance Vehicle-Infrastructure Cooperative Perception",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving",
                "Vehicle"
            ]
        ],
        "abstract": "Infrastructure sensors installed at elevated positions offer a broader perception range and encounter fewer occlusions. Integrating both infrastructure and ego-vehicle data through V2X communication, known as vehicle-infrastructure cooperation, has shown considerable advantages in enhancing perception capabilities and addressing corner cases encountered in single-vehicle autonomous driving. However, cooperative perception still faces numerous challenges, including limited communication bandwidth and practical communication interruptions. In this paper, we propose CTCE, a novel framework for cooperative 3D object detection. This framework transmits queries with temporal contexts enhancement, effectively balancing transmission efficiency and performance to accommodate real-world communication conditions. Additionally, we propose a temporal-guided fusion module to further improve performance. The roadside temporal enhancement and vehicle-side spatial-temporal fusion together constitute a multi-level temporal contexts integration mechanism, fully leveraging temporal information to enhance performance. Furthermore, a motion-aware reconstruction module is introduced to recover lost roadside queries due to communication interruptions. Experimental results on V2X-Seq and V2X-Sim datasets demonstrate that CTCE outperforms the baseline QUEST, achieving improvements of 3.8% and 1.3% in mAP, respectively. Experiments under communication interruption conditions validate CTCE's robustness to communication interruptions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted by IEEE ITSC 2024"
    },
    {
        "paper id": "2408.09802",
        "abstract url": "https://arxiv.org/abs/2408.09802",
        "title": "Hear Your Face: Face-based voice conversion with F0 estimation",
        "rating": "-2.5",
        "keywords": [
            [
                "facial"
            ],
            [
                "voice conversion"
            ],
            [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "This paper delves into the emerging field of face-based voice conversion, leveraging the unique relationship between an individual's facial features and their vocal characteristics. We present a novel face-based voice conversion framework that particularly utilizes the average fundamental frequency of the target speaker, derived solely from their facial images. Through extensive analysis, our framework demonstrates superior speech generation quality and the ability to align facial features with voice characteristics, including tracking of the target speaker's fundamental frequency.",
        "subjects": [
            "cs.SD",
            "cs.CV",
            "eess.AS"
        ],
        "comment": "Interspeech 2024"
    },
    {
        "paper id": "2408.10124",
        "abstract url": "https://arxiv.org/abs/2408.10124",
        "title": "Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Molecular property prediction is a crucial foundation for drug discovery. In recent years, pre-trained deep learning models have been widely applied to this task. Some approaches that incorporate prior biological domain knowledge into the pre-training framework have achieved impressive results. However, these methods heavily rely on biochemical experts, and retrieving and summarizing vast amounts of domain knowledge literature is both time-consuming and expensive. Large Language Models (LLMs) have demonstrated remarkable performance in understanding and efficiently providing general knowledge. Nevertheless, they occasionally exhibit hallucinations and lack precision in generating domain-specific knowledge. Conversely, Domain-specific Small Models (DSMs) possess rich domain knowledge and can accurately calculate molecular domain-related metrics. However, due to their limited model size and singular functionality, they lack the breadth of knowledge necessary for comprehensive representation learning. To leverage the advantages of both approaches in molecular property prediction, we propose a novel Molecular Graph representation learning framework that integrates Large language models and Domain-specific small models (MolGraph-LarDo). Technically, we design a two-stage prompt strategy where DSMs are introduced to calibrate the knowledge provided by LLMs, enhancing the accuracy of domain-specific information and thus enabling LLMs to generate more precise textual descriptions for molecular samples. Subsequently, we employ a multi-modal alignment method to coordinate various modalities, including molecular graphs and their corresponding descriptive texts, to guide the pre-training of molecular representations. Extensive experiments demonstrate the effectiveness of the proposed method.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IR",
            "physics.chem-ph",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10162",
        "abstract url": "https://arxiv.org/abs/2408.10162",
        "title": "Physics-Aware Combinatorial Assembly Planning using Deep Reinforcement Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Combinatorial assembly uses standardized unit primitives to build objects that satisfy user specifications. Lego is a widely used platform for combinatorial assembly, in which people use unit primitives (ie Lego bricks) to build highly customizable 3D objects. This paper studies sequence planning for physical combinatorial assembly using Lego. Given the shape of the desired object, we want to find a sequence of actions for placing Lego bricks to build the target object. In particular, we aim to ensure the planned assembly sequence is physically executable. However, assembly sequence planning (ASP) for combinatorial assembly is particularly challenging due to its combinatorial nature, ie the vast number of possible combinations and complex constraints. To address the challenges, we employ deep reinforcement learning to learn a construction policy for placing unit primitives sequentially to build the desired object. Specifically, we design an online physics-aware action mask that efficiently filters out invalid actions and guides policy learning. In the end, we demonstrate that the proposed method successfully plans physically valid assembly sequences for constructing different Lego structures. The generated construction plan can be executed in real.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10362",
        "abstract url": "https://arxiv.org/abs/2408.10362",
        "title": "Query languages for neural networks",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "SQL"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We lay the foundations for a database-inspired approach to interpreting and understanding neural network models by querying them using declarative languages. Towards this end we study different query languages, based on first-order logic, that mainly differ in their access to the neural network model. First-order logic over the reals naturally yields a language which views the network as a black box; only the input--output function defined by the network can be queried. This is essentially the approach of constraint query languages. On the other hand, a white-box language can be obtained by viewing the network as a weighted graph, and extending first-order logic with summation over weight terms. The latter approach is essentially an abstraction of SQL. In general, the two approaches are incomparable in expressive power, as we will show. Under natural circumstances, however, the white-box approach can subsume the black-box approach; this is our main result. We prove the result concretely for linear constraint queries over real functions definable by feedforward neural networks with a fixed number of hidden layers and piecewise linear activation functions.",
        "subjects": [
            "cs.AI",
            "cs.DB",
            "cs.LO"
        ],
        "comment": "To appear at ICDT 2025"
    },
    {
        "paper id": "2408.10450",
        "abstract url": "https://arxiv.org/abs/2408.10450",
        "title": "RUMI: Rummaging Using Mutual Information",
        "rating": "-2.5",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "trajectory"
            ],
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents Rummaging Using Mutual Information (RUMI), a method for online generation of robot action sequences to gather information about the pose of a known movable object in visually-occluded environments. Focusing on contact-rich rummaging, our approach leverages mutual information between the object pose distribution and robot trajectory for action planning. From an observed partial point cloud, RUMI deduces the compatible object pose distribution and approximates the mutual information of it with workspace occupancy in real time. Based on this, we develop an information gain cost function and a reachability cost function to keep the object within the robot's reach. These are integrated into a model predictive control (MPC) framework with a stochastic dynamics model, updating the pose distribution in a closed loop. Key contributions include a new belief framework for object pose estimation, an efficient information gain computation strategy, and a robust MPC-based control scheme. RUMI demonstrates superior performance in both simulated and real tasks compared to baseline methods.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "19 pages, 17 figures, submitted to IEEE Transactions on Robotics (T-RO)"
    },
    {
        "paper id": "2408.10511",
        "abstract url": "https://arxiv.org/abs/2408.10511",
        "title": "Single-cell Curriculum Learning-based Deep Graph Embedding Clustering",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "biological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The swift advancement of single-cell RNA sequencing (scRNA-seq) technologies enables the investigation of cellular-level tissue heterogeneity. Cell annotation significantly contributes to the extensive downstream analysis of scRNA-seq data. However, The analysis of scRNA-seq for biological inference presents challenges owing to its intricate and indeterminate data distribution, characterized by a substantial volume and a high frequency of dropout events. Furthermore, the quality of training samples varies greatly, and the performance of the popular scRNA-seq data clustering solution GNN could be harmed by two types of low-quality training nodes: 1) nodes on the boundary; 2) nodes that contribute little additional information to the graph. To address these problems, we propose a single-cell curriculum learning-based deep graph embedding clustering (scCLG). We first propose a Chebyshev graph convolutional autoencoder with multi-decoder (ChebAE) that combines three optimization objectives corresponding to three decoders, including topology reconstruction loss of cell graphs, zero-inflated negative binomial (ZINB) loss, and clustering loss, to learn cell-cell topology representation. Meanwhile, we employ a selective training strategy to train GNN based on the features and entropy of nodes and prune the difficult nodes based on the difficulty scores to keep the high-quality graph. Empirical results on a variety of gene expression datasets show that our model outperforms state-of-the-art methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09731",
        "abstract url": "https://arxiv.org/abs/2408.09731",
        "title": "Reconstruct Spine CT from Biplanar X-Rays via Diffusion Learning",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "surgical",
                "CT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Intraoperative CT imaging serves as a crucial resource for surgical guidance; however, it may not always be readily accessible or practical to implement. In scenarios where CT imaging is not an option, reconstructing CT scans from X-rays can offer a viable alternative. In this paper, we introduce an innovative method for 3D CT reconstruction utilizing biplanar X-rays. Distinct from previous research that relies on conventional image generation techniques, our approach leverages a conditional diffusion process to tackle the task of reconstruction. More precisely, we employ a diffusion-based probabilistic model trained to produce 3D CT images based on orthogonal biplanar X-rays. To improve the structural integrity of the reconstructed images, we incorporate a novel projection loss function. Experimental results validate that our proposed method surpasses existing state-of-the-art benchmarks in both visual image quality and multiple evaluative metrics. Specifically, our technique achieves a higher Structural Similarity Index (SSIM) of 0.83, a relative increase of 10\\%, and a lower Fr\u00e9chet Inception Distance (FID) of 83.43, which represents a relative decrease of 25\\%.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09736",
        "abstract url": "https://arxiv.org/abs/2408.09736",
        "title": "Coarse-Fine View Attention Alignment-Based GAN for CT Reconstruction from Biplanar X-Rays",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "GAN"
            ],
            [
                "surgical",
                "CT",
                "X-ray"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "For surgical planning and intra-operation imaging, CT reconstruction using X-ray images can potentially be an important alternative when CT imaging is not available or not feasible. In this paper, we aim to use biplanar X-rays to reconstruct a 3D CT image, because biplanar X-rays convey richer information than single-view X-rays and are more commonly used by surgeons. Different from previous studies in which the two X-ray views were treated indifferently when fusing the cross-view data, we propose a novel attention-informed coarse-to-fine cross-view fusion method to combine the features extracted from the orthogonal biplanar views. This method consists of a view attention alignment sub-module and a fine-distillation sub-module that are designed to work together to highlight the unique or complementary information from each of the views. Experiments have demonstrated the superiority of our proposed method over the SOTA methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09753",
        "abstract url": "https://arxiv.org/abs/2408.09753",
        "title": "Harnessing the Potential of Omnidirectional Multi-Rotor Aerial Vehicles in Cooperative Jamming Against Eavesdropping",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Recent research in communications-aware robotics has been propelled by advancements in 5G and emerging 6G technologies. This field now includes the integration of Multi-Rotor Aerial Vehicles (MRAVs) into cellular networks, with a specific focus on under-actuated MRAVs. These vehicles face challenges in independently controlling position and orientation due to their limited control inputs, which adversely affects communication metrics such as Signal-to-Noise Ratio. In response, a newer class of omnidirectional MRAVs has been developed, which can control both position and orientation simultaneously by tilting their propellers. However, exploiting this capability fully requires sophisticated motion planning techniques. This paper presents a novel application of omnidirectional MRAVs designed to enhance communication security and thwart eavesdropping. It proposes a strategy where one MRAV functions as an aerial Base Station, while another acts as a friendly jammer to secure communications. This study is the first to apply such a strategy to MRAVs in scenarios involving eavesdroppers.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages, 4 figures, Accepted for presentation to the 2024 IEEE Global Communications Conference (IEEE GLOBECOM), Cape Town, South Africa. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2408.09865",
        "abstract url": "https://arxiv.org/abs/2408.09865",
        "title": "MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation",
        "rating": "-3",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "grammatical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Explainable Recommendation task is designed to receive a pair of user and item and output explanations to justify why an item is recommended to a user. Many models treat review-generation as a proxy of explainable recommendation. Although they are able to generate fluent and grammatical sentences, they suffer from generality and hallucination issues. We propose a personalized, aspect-controlled model called Multi-Aspect Prompt LEarner (MAPLE), in which it integrates aspect category as another input dimension to facilitate the memorization of fine-grained aspect terms. Experiments on two real-world review datasets in restaurant domain show that MAPLE outperforms the baseline review-generation models in terms of text and feature diversity while maintaining excellent coherence and factual relevance. We further treat MAPLE as a retriever component in the retriever-reader framework and employ a Large-Language Model (LLM) as the reader, showing that MAPLE's explanation along with the LLM's comprehension ability leads to enriched and personalized explanation as a result. We will release the code and data in this http upon acceptance.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.IR"
        ],
        "comment": "8 main pages, 10 pages for appendix. Under review"
    },
    {
        "paper id": "2408.09873",
        "abstract url": "https://arxiv.org/abs/2408.09873",
        "title": "New spectral imaging biomarkers for sepsis and mortality in intensive care",
        "rating": "-3",
        "keywords": [
            [
                "biomarkers",
                "diagnosis",
                "clinical"
            ],
            [
                "hyperspectral imaging"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "With sepsis remaining a leading cause of mortality, early identification of septic patients and those at high risk of death is a challenge of high socioeconomic importance. The driving hypothesis of this study was that hyperspectral imaging (HSI) could provide novel biomarkers for sepsis diagnosis and treatment management due to its potential to monitor microcirculatory alterations. We conducted a comprehensive study involving HSI data of the palm and fingers from more than 480 patients on the day of their intensive care unit (ICU) admission. The findings demonstrate that HSI measurements can predict sepsis with an area under the receiver operating characteristic curve (AUROC) of 0.80 (95 % confidence interval (CI) [0.76; 0.84]) and mortality with an AUROC of 0.72 (95 % CI [0.65; 0.79]). The predictive performance improves substantially when additional clinical data is incorporated, leading to an AUROC of up to 0.94 (95 % CI [0.92; 0.96]) for sepsis and 0.84 (95 % CI [0.78; 0.89]) for mortality. We conclude that HSI presents novel imaging biomarkers for the rapid, non-invasive prediction of sepsis and mortality, suggesting its potential as an important modality for guiding diagnosis and treatment.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "eess.IV"
        ],
        "comment": "Markus A. Weigand, Lena Maier-Hein and Maximilian Dietrich contributed equally"
    },
    {
        "paper id": "2408.09931",
        "abstract url": "https://arxiv.org/abs/2408.09931",
        "title": "Pose-GuideNet: Automatic Scanning Guidance for Fetal Head Ultrasound from Pose Estimation",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "navigation"
            ],
            [
                "biometry",
                "healthcare",
                "clinical",
                "radiology"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "3D pose estimation from a 2D cross-sectional view enables healthcare professionals to navigate through the 3D space, and such techniques initiate automatic guidance in many image-guided radiology applications. In this work, we investigate how estimating 3D fetal pose from freehand 2D ultrasound scanning can guide a sonographer to locate a head standard plane. Fetal head pose is estimated by the proposed Pose-GuideNet, a novel 2D/3D registration approach to align freehand 2D ultrasound to a 3D anatomical atlas without the acquisition of 3D ultrasound. To facilitate the 2D to 3D cross-dimensional projection, we exploit the prior knowledge in the atlas to align the standard plane frame in a freehand scan. A semantic-aware contrastive-based approach is further proposed to align the frames that are off standard planes based on their anatomical similarity. In the experiment, we enhance the existing assessment of freehand image localization by comparing the transformation of its estimated pose towards standard plane with the corresponding probe motion, which reflects the actual view change in 3D anatomy. Extensive results on two clinical head biometry tasks show that Pose-GuideNet not only accurately predicts pose but also successfully predicts the direction of the fetal head. Evaluations with probe motions further demonstrate the feasibility of adopting Pose-GuideNet for freehand ultrasound-assisted navigation in a sensor-free environment.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted by MICCAI2024"
    },
    {
        "paper id": "2408.10114",
        "abstract url": "https://arxiv.org/abs/2408.10114",
        "title": "Topics in Algebra of Synchronous Games, Algebraic Graph Identities and Quantum NP-hardness Reductions",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "We review the correspondence between a synchronous game and its associated game algebra. We slightly develop the work of Helton et al.[HMPS17] by proposing results on algebraic and locally commuting graph identities. Based on the theoretical works on noncommutative Nullstellens\u00e4tze [BWHK23], we build computational tools involving Gr\u00f6bner basis method and semidefinite programming to check the existence of perfect strategies with specific models. We prove the equivalence between the hereditary and $C^*$ models proposed in [HMPS17]. We also extend Ji's reduction $\\texttt{3-Coloring}^* \\leq_p \\texttt{3-SAT}^*$ [Ji13] and exhibit another instance of quantum-version NP-hardness reduction $\\texttt{Clique}^* \\leq_p \\texttt{3-SAT}^*$.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "math.OA"
        ],
        "comment": "There is a problem of authorship among people involved in the research project, and we have yet reached an agreement. Meanwhile, we hope to further check the validity of the proving system"
    },
    {
        "paper id": "2408.10163",
        "abstract url": "https://arxiv.org/abs/2408.10163",
        "title": "Towards UAV-USV Collaboration in Harsh Maritime Conditions Including Large Waves",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "This paper introduces a system designed for tight collaboration between Unmanned Aerial Vehicles (UAVs) and Unmanned Surface Vehicles (USVs) in harsh maritime conditions characterized by large waves. This onboard UAV system aims to enhance collaboration with USVs for following and landing tasks under such challenging conditions. The main contribution of our system is the novel mathematical USV model, describing the movement of the USV in 6 degrees of freedom on a wavy water surface, which is used to estimate and predict USV states. The estimator fuses data from multiple global and onboard sensors, ensuring accurate USV state estimation. The predictor computes future USV states using the novel mathematical USV model and the last estimated states. The estimated and predicted USV states are forwarded into a trajectory planner that generates a UAV trajectory for following the USV or landing on its deck, even in harsh environmental conditions. The proposed approach was verified in numerous simulations and deployed to the real world, where the UAV was able to follow the USV and land on its deck repeatedly.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10172",
        "abstract url": "https://arxiv.org/abs/2408.10172",
        "title": "Eulerian Graph Sparsification by Effective Resistance Decomposition",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Song"
            ]
        ],
        "abstract": "We provide an algorithm that, given an $n$-vertex $m$-edge Eulerian graph with polynomially bounded weights, computes an $\\breve{O}(n\\log^{2} n \\cdot \\varepsilon^{-2})$-edge $\\varepsilon$-approximate Eulerian sparsifier with high probability in $\\breve{O}(m\\log^3 n)$ time (where $\\breve{O}(\\cdot)$ hides $\\text{polyloglog}(n)$ factors). Due to a reduction from [Peng-Song, STOC '22], this yields an $\\breve{O}(m\\log^3 n + n\\log^6 n)$-time algorithm for solving $n$-vertex $m$-edge Eulerian Laplacian systems with polynomially-bounded weights with high probability, improving upon the previous state-of-the-art runtime of $\u03a9(m\\log^8 n + n\\log^{23} n)$. We also give a polynomial-time algorithm that computes $O(\\min(n\\log n \\cdot \\varepsilon^{-2} + n\\log^{5/3} n \\cdot \\varepsilon^{-4/3}, n\\log^{3/2} n \\cdot \\varepsilon^{-2}))$-edge sparsifiers, improving the best such sparsity bound of $O(n\\log^2 n \\cdot \\varepsilon^{-2} + n\\log^{8/3} n \\cdot \\varepsilon^{-4/3})$ [Sachdeva-Thudi-Zhao, ICALP '24]. Finally, we show that our techniques extend to yield the first $O(m\\cdot\\text{polylog}(n))$ time algorithm for computing $O(n\\varepsilon^{-1}\\cdot\\text{polylog}(n))$-edge graphical spectral sketches, as well as a natural Eulerian generalization we introduce. In contrast to prior Eulerian graph sparsification algorithms which used either short cycle or expander decompositions, our algorithms use a simple efficient effective resistance decomposition scheme we introduce. Our algorithms apply a natural sampling scheme and electrical routing (to achieve degree balance) to such decompositions. Our analysis leverages new asymmetric variance bounds specialized to Eulerian Laplacians and tools from discrepancy theory.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10177",
        "abstract url": "https://arxiv.org/abs/2408.10177",
        "title": "Perfectly Undetectable Reflection and Scaling False Data Injection Attacks via Affine Transformation on Mobile Robot Trajectory Tracking Control",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "Robot"
            ],
            [
                "Attacks"
            ]
        ],
        "abstract": "With the increasing integration of cyber-physical systems (CPS) into critical applications, ensuring their resilience against cyberattacks is paramount. A particularly concerning threat is the vulnerability of CPS to deceptive attacks that degrade system performance while remaining undetected. This paper investigates perfectly undetectable false data injection attacks (FDIAs) targeting the trajectory tracking control of a non-holonomic mobile robot. The proposed attack method utilizes affine transformations of intercepted signals, exploiting weaknesses inherent in the partially linear dynamic properties and symmetry of the nonlinear plant. The feasibility and potential impact of these attacks are validated through experiments using a Turtlebot 3 platform, highlighting the urgent need for sophisticated detection mechanisms and resilient control strategies to safeguard CPS against such threats. Furthermore, a novel approach for detection of these attacks called the state monitoring signature function (SMSF) is introduced. An example SMSF, a carefully designed function resilient to FDIA, is shown to be able to detect the presence of a FDIA through signatures based on systems states.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "15 pages, 17 figures. Manuscript under review for publication"
    },
    {
        "paper id": "2408.10404",
        "abstract url": "https://arxiv.org/abs/2408.10404",
        "title": "Parallel Processing of Point Cloud Ground Segmentation for Mechanical and Solid-State LiDARs",
        "rating": "-3",
        "keywords": [
            [
                "voxel",
                "Point Cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "FPGA"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this study, we introduce a novel parallel processing framework for real-time point cloud ground segmentation on FPGA platforms, aimed at adapting LiDAR algorithms to the evolving landscape from mechanical to solid-state LiDAR (SSL) technologies. Focusing on the ground segmentation task, we explore parallel processing techniques on existing approaches and adapt them to real-world SSL data handling. We validated frame-segmentation based parallel processing methods using point-based, voxel-based, and range-image-based ground segmentation approaches on the SemanticKITTI dataset based on mechanical LiDAR. The results revealed the superior performance and robustness of the range-image method, especially in its resilience to slicing. Further, utilizing a custom dataset from our self-built Camera-SSLSS equipment, we examined regular SSL data frames and validated the effectiveness of our parallel approach for SSL sensor. Additionally, our pioneering implementation of range-image ground segmentation on FPGA for SSL sensors demonstrated significant processing speed improvements and resource efficiency, achieving processing rates up to 50.3 times faster than conventional CPU setups. These findings underscore the potential of parallel processing strategies to significantly enhance LiDAR technologies for advanced perception tasks in autonomous systems. Post-publication, both the data and the code will be made available on GitHub.",
        "subjects": [
            "cs.CV",
            "eess.IV",
            "eess.SP"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2408.10446",
        "abstract url": "https://arxiv.org/abs/2408.10446",
        "title": "The Brittleness of AI-Generated Image Watermarking Techniques: Examining Their Robustness Against Visual Paraphrasing Attacks",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "Attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement of text-to-image generation systems, exemplified by models like Stable Diffusion, Midjourney, Imagen, and DALL-E, has heightened concerns about their potential misuse. In response, companies like Meta and Google have intensified their efforts to implement watermarking techniques on AI-generated images to curb the circulation of potentially misleading visuals. However, in this paper, we argue that current image watermarking methods are fragile and susceptible to being circumvented through visual paraphrase attacks. The proposed visual paraphraser operates in two steps. First, it generates a caption for the given image using KOSMOS-2, one of the latest state-of-the-art image captioning systems. Second, it passes both the original image and the generated caption to an image-to-image diffusion system. During the denoising step of the diffusion pipeline, the system generates a visually similar image that is guided by the text caption. The resulting image is a visual paraphrase and is free of any watermarks. Our empirical findings demonstrate that visual paraphrase attacks can effectively remove watermarks from images. This paper provides a critical assessment, empirically revealing the vulnerability of existing watermarking techniques to visual paraphrase attacks. While we do not propose solutions to this issue, this paper serves as a call to action for the scientific community to prioritize the development of more robust watermarking techniques. Our first-of-its-kind visual paraphrase dataset and accompanying code are publicly available.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "23 pages and 10 figures"
    },
    {
        "paper id": "2408.09818",
        "abstract url": "https://arxiv.org/abs/2408.09818",
        "title": "Liquid Fourier Latent Dynamics Networks for fast GPU-based numerical simulations in computational cardiology",
        "rating": "-3.5",
        "keywords": [
            [
                "cardiac"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Scientific Machine Learning (ML) is gaining momentum as a cost-effective alternative to physics-based numerical solvers in many engineering applications. In fact, scientific ML is currently being used to build accurate and efficient surrogate models starting from high-fidelity numerical simulations, effectively encoding the parameterized temporal dynamics underlying Ordinary Differential Equations (ODEs), or even the spatio-temporal behavior underlying Partial Differential Equations (PDEs), in appropriately designed neural networks. We propose an extension of Latent Dynamics Networks (LDNets), namely Liquid Fourier LDNets (LFLDNets), to create parameterized space-time surrogate models for multiscale and multiphysics sets of highly nonlinear differential equations on complex geometries. LFLDNets employ a neurologically-inspired, sparse, liquid neural network for temporal dynamics, relaxing the requirement of a numerical solver for time advancement and leading to superior performance in terms of tunable parameters, accuracy, efficiency and learned trajectories with respect to neural ODEs based on feedforward fully-connected neural networks. Furthermore, in our implementation of LFLDNets, we use a Fourier embedding with a tunable kernel in the reconstruction network to learn high-frequency functions better and faster than using space coordinates directly as input. We challenge LFLDNets in the framework of computational cardiology and evaluate their capabilities on two 3-dimensional test cases arising from multiscale cardiac electrophysiology and cardiovascular hemodynamics. This paper illustrates the capability to run Artificial Intelligence-based numerical simulations on single or multiple GPUs in a matter of minutes and represents a significant step forward in the development of physics-informed digital twins.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09896",
        "abstract url": "https://arxiv.org/abs/2408.09896",
        "title": "Instruction-Based Molecular Graph Generation with Unified Text-Graph Diffusion Model",
        "rating": "-3.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Graph"
            ],
            [
                "chemistry"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in computational chemistry have increasingly focused on synthesizing molecules based on textual instructions. Integrating graph generation with these instructions is complex, leading most current methods to use molecular sequences with pre-trained large language models. In response to this challenge, we propose a novel framework, named $\\textbf{UTGDiff (Unified Text-Graph Diffusion Model)}$, which utilizes language models for discrete graph diffusion to generate molecular graphs from instructions. UTGDiff features a unified text-graph transformer as the denoising network, derived from pre-trained language models and minimally modified to process graph data through attention bias. Our experimental results demonstrate that UTGDiff consistently outperforms sequence-based baselines in tasks involving instruction-based molecule generation and editing, achieving superior performance with fewer parameters given an equivalent level of pretraining corpus. Our code is availble at https://github.com/ran1812/UTGDiff.",
        "subjects": [
            "cs.LG",
            "physics.chem-ph",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09785",
        "abstract url": "https://arxiv.org/abs/2408.09785",
        "title": "GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making",
        "rating": "-4",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "industrial"
            ],
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Traditional methods for making software deployment decisions in the automotive industry typically rely on manual analysis of tabular software test data. These methods often lead to higher costs and delays in the software release cycle due to their labor-intensive nature. Large Language Models (LLMs) present a promising solution to these challenges. However, their application generally demands multiple rounds of human-driven prompt engineering, which limits their practical deployment, particularly for industrial end-users who need reliable and efficient results. In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive software deployment while meeting both functional requirements and practical industrial constraints. Unlike previous systems, GoNoGo is specifically tailored to address domain-specific and risk-sensitive systems. We evaluate GoNoGo's performance across different task difficulties using zero-shot and few-shot examples taken from industrial practice. Our results show that GoNoGo achieves a 100% success rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains high performance even for more complex tasks. We find that GoNoGo effectively automates decision-making for simpler tasks, significantly reducing the need for manual intervention. In summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently employed in our industrial partner's company to assist with software release decision-making, supporting more informed and timely decisions in the release process for risk-sensitive vehicle systems.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09888",
        "abstract url": "https://arxiv.org/abs/2408.09888",
        "title": "Forecasting Attacker Actions using Alert-driven Attack Graphs",
        "rating": "-4",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "Attack"
            ],
            [
                "Forecasting"
            ]
        ],
        "abstract": "While intrusion detection systems form the first line-of-defense against cyberattacks, they often generate an overwhelming volume of alerts, leading to alert fatigue among security operations center (SOC) analysts. Alert-driven attack graphs (AGs) have been developed to reduce alert fatigue by automatically discovering attack paths in intrusion alerts. However, they only work in offline settings and cannot prioritize critical attack paths. This paper builds an action forecasting capability on top of the existing alert-driven AG framework for predicting the next likely attacker action given a sequence of observed actions, thus enabling analysts to prioritize non-trivial attack paths. We also modify the framework to build AGs in real time, as new alerts are triggered. This way, we convert alert-driven AGs into an early warning system that enables analysts to circumvent ongoing attacks and break the cyber killchain. We propose an expectation maximization approach to forecast future actions in a reversed suffix-based probabilistic deterministic finite automaton (rSPDFA). By utilizing three real-world intrusion and endpoint alert datasets, we empirically demonstrate that the best performing rSPDFA achieves an average top-3 accuracy of 67.27%, which reflects a 57.17% improvement over three baselines, on average. We also invite six SOC analysts to use the evolving AGs in two scenarios. Their responses suggest that the action forecasts help them prioritize critical incidents, while the evolving AGs enable them to choose countermeasures in real-time.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09954",
        "abstract url": "https://arxiv.org/abs/2408.09954",
        "title": "Experiment-based Models for Air Time and Current Consumption of LoRaWAN LR-FHSS",
        "rating": "-4",
        "keywords": [
            [
                "IoT"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "Long Range - Frequency Hopping Spread Spectrum (LR-FHSS) is an emerging and promising technology recently introduced into the LoRaWAN protocol specification for both terrestrial and non-terrestrial networks, notably satellites. The higher capacity, long-range and robustness to Doppler effect make LR-FHSS a primary candidate for direct-to-satellite (DtS) connectivity for enabling Internet-of-things (IoT) in remote areas. The LR-FHSS devices envisioned for DtS IoT will be primarily battery-powered. Therefore, it is crucial to investigate the current consumption characteristics and Time-on-Air (ToA) of LR-FHSS technology. However, to our knowledge, no prior research has presented the accurate ToA and current consumption models for this newly introduced scheme. This paper addresses this shortcoming through extensive field measurements and the development of analytical models. Specifically, we have measured the current consumption and ToA for variable transmit power, message payload, and two new LR-FHSS-based Data Rates (DR8 and DR9). We also develop current consumption and ToA analytical models demonstrating a strong correlation with the measurement results exhibiting a relative error of less than 0.3%. Thus, it confirms the validity of our models. Conversely, the existing analytical models exhibit a higher relative error rate of -9.2 to 3.4% compared to our measurement results. The presented in this paper results can be further used for simulators or in analytical studies to accurately model the on-air time and energy consumption of LR-FHSS devices.",
        "subjects": [
            "cs.ET",
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE Internet of Things Journal for possible publication. Copyright to IEEE may be transferred without notice"
    },
    {
        "paper id": "2408.10470",
        "abstract url": "https://arxiv.org/abs/2408.10470",
        "title": "Inverse Design of Snap-Actuated Jumping Robots Powered by Mechanics-Aided Machine Learning",
        "rating": "-4",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Exploring the design and control strategies of soft robots through simulation is highly attractive due to its cost-effectiveness. Although many existing models (e.g., finite element analysis) are effective for simulating soft robotic dynamics, there remains a need for a general and efficient numerical simulation approach in the soft robotics community. In this paper, we develop a discrete differential geometry-based numerical framework to achieve the model-based inverse design of a novel snap-actuated jumping robot. It is found that the dynamic process of a snapping beam can be either symmetric or asymmetric, such that the trajectory of the jumping robot can be tunable (e.g., horizontal or vertical). By employing this novel mechanism of the bistable beam as the robotic actuator, we next propose a physics-data hybrid inverse design strategy for the snap-jump robot with a broad spectrum of jumping capabilities. We first use the physical engine to study the influences of the robot's design parameters on the jumping capabilities, then generate extensive simulation data to formulate a data-driven inverse design solution. The inverse design solution can rapidly explore the combination of design parameters for achieving a target jump, which provides valuable guidance for the fabrication and control of the jumping robot. The proposed methodology paves the way for exploring the design and control insights of soft robots with the help of simulations.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2408.10520",
        "abstract url": "https://arxiv.org/abs/2408.10520",
        "title": "Efficient and Deployable Knowledge Infusion for Open-World Recommendations via Large Language Models",
        "rating": "-4",
        "keywords": [
            [
                "industrial",
                "recommendation"
            ],
            [
                "music"
            ]
        ],
        "abstract": "Recommender systems (RSs) play a pervasive role in today's online services, yet their closed-loop nature constrains their access to open-world knowledge. Recently, large language models (LLMs) have shown promise in bridging this gap. However, previous attempts to directly implement LLMs as recommenders fall short in meeting the requirements of industrial RSs, particularly in terms of online inference latency and offline resource efficiency. Thus, we propose REKI to acquire two types of external knowledge about users and items from LLMs. Specifically, we introduce factorization prompting to elicit accurate knowledge reasoning on user preferences and items. We develop individual knowledge extraction and collective knowledge extraction tailored for different scales of scenarios, effectively reducing offline resource consumption. Subsequently, generated knowledge undergoes efficient transformation and condensation into augmented vectors through a hybridized expert-integrated network, ensuring compatibility. The obtained vectors can then be used to enhance any conventional recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from LLMs. Experiments demonstrate that REKI outperforms state-of-the-art baselines and is compatible with lots of recommendation algorithms and tasks. Now, REKI has been deployed to Huawei's news and music recommendation platforms and gained a 7% and 1.99% improvement during the online A/B test.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2306.10933"
    },
    {
        "paper id": "2408.09845",
        "abstract url": "https://arxiv.org/abs/2408.09845",
        "title": "Predicting Long-term Dynamics of Complex Networks via Identifying Skeleton in Hyperbolic Space",
        "rating": "-4.5",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "super-resolution"
            ],
            [
                "graph"
            ],
            [
                "physics"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Learning complex network dynamics is fundamental for understanding, modeling, and controlling real-world complex systems. Though great efforts have been made to predict the future states of nodes on networks, the capability of capturing long-term dynamics remains largely limited. This is because they overlook the fact that long-term dynamics in complex network are predominantly governed by their inherent low-dimensional manifolds, i.e., skeletons. Therefore, we propose the Dynamics-Invariant Skeleton Neural Net}work (DiskNet), which identifies skeletons of complex networks based on the renormalization group structure in hyperbolic space to preserve both topological and dynamics properties. Specifically, we first condense complex networks with various dynamics into simple skeletons through physics-informed hyperbolic embeddings. Further, we design graph neural ordinary differential equations to capture the condensed dynamics on the skeletons. Finally, we recover the skeleton networks and dynamics to the original ones using a degree-based super-resolution module. Extensive experiments across three representative dynamics as well as five real-world and two synthetic networks demonstrate the superior performances of the proposed DiskNet, which outperforms the state-of-the-art baselines by an average of 10.18\\% in terms of long-term prediction accuracy. Code for reproduction is available at: https://github.com/tsinghua-fib-lab/DiskNet.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09840",
        "abstract url": "https://arxiv.org/abs/2408.09840",
        "title": "Machine Learning with Physics Knowledge for Prediction: A Survey",
        "rating": "-5.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "forecast"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "physics.comp-ph"
        ],
        "comment": "56 pages, 8 figures, 2 tables"
    },
    {
        "paper id": "2408.09835",
        "abstract url": "https://arxiv.org/abs/2408.09835",
        "title": "Experimental Characterization of Hydrodynamic Gating-Based Molecular Communication Transmitter",
        "rating": "-6",
        "keywords": [
            [
                "bio-inspired",
                "medical"
            ],
            [
                "chemical"
            ],
            [
                "agricultural"
            ]
        ],
        "abstract": "Molecular communication (MC) is a bio-inspired method of transmitting information using biochemical signals, promising for novel medical, agricultural, and environmental applications at the intersection of bio-, nano-, and communication technologies. Developing reliable MC systems for high-rate information transfer remains challenging due to the complex and dynamic nature of application environments and the physical and resource limitations of micro/nanoscale transmitters and receivers. Microfluidics can help overcome many such practical challenges by enabling testbeds that can replicate the application media with precise control over flow conditions. However, existing microfluidic MC testbeds face significant limitations in chemical signal generation with programmable signal waveforms, e.g., in terms of pulse width. To tackle this, we previously proposed a practical microfluidic MC transmitter architecture based on the hydrodynamic gating technique, a prevalent chemical waveform generation method. This paper reports the experimental validation and characterization of this method, examining its precision in terms of spatiotemporal control on the generated molecular concentration pulses. We detail the fabrication of the transmitter, its working mechanism and discuss its potential limitations based on empirical data. We show that the microfluidic transmitter is capable of providing precise, programmable, and reproducible molecular concentration pulses, which would facilitate the experimental research in MC.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10191",
        "abstract url": "https://arxiv.org/abs/2408.10191",
        "title": "A Graph-based Approach to Human Activity Recognition",
        "rating": "-6",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "Graph"
            ],
            [
                "health"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Advanced wearable sensor devices have enabled the recording of vast amounts of movement data from individuals regarding their physical activities. This data offers valuable insights that enhance our understanding of how physical activities contribute to improved physical health and overall quality of life. Consequently, there is a growing need for efficient methods to extract significant insights from these rapidly expanding real-time datasets. This paper presents a methodology to efficiently extract substantial insights from these expanding datasets, focusing on professional sports but applicable to various human activities. By utilizing data from Inertial Measurement Units (IMU) and Global Navigation Satellite Systems (GNSS) receivers, athletic performance can be analyzed using directed graphs to encode knowledge of complex movements. Our approach is demonstrated on biathlon data and detects specific points of interest and complex movement sequences, facilitating the comparison and analysis of human physical performance.",
        "subjects": [
            "cs.SE",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10410",
        "abstract url": "https://arxiv.org/abs/2408.10410",
        "title": "Stream-Based Ground Segmentation for Real-Time LiDAR Point Cloud Processing on FPGA",
        "rating": "-6",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "FPGA"
            ],
            [
                "bird's-eye view",
                "BEV"
            ]
        ],
        "abstract": "This paper presents a novel and fast approach for ground plane segmentation in a LiDAR point cloud, specifically optimized for processing speed and hardware efficiency on FPGA hardware platforms. Our approach leverages a channel-based segmentation method with an advanced angular data repair technique and a cross-eight-way flood-fill algorithm. This innovative approach significantly reduces the number of iterations while ensuring the high accuracy of the segmented ground plane, which makes the stream-based hardware implementation possible. To validate the proposed approach, we conducted extensive experiments on the SemanticKITTI dataset. We introduced a bird's-eye view (BEV) evaluation metric tailored for the area representation of LiDAR segmentation tasks. Our method demonstrated superior performance in terms of BEV areas when compared to the existing approaches. Moreover, we presented an optimized hardware architecture targeted on a Zynq-7000 FPGA, compatible with LiDARs of various channel densities, i.e., 32, 64, and 128 channels. Our FPGA implementation operating at 160 MHz significantly outperforms the traditional computing platforms, which is 12 to 25 times faster than the CPU-based solutions and up to 6 times faster than the GPU-based solution, in addition to the benefit of low power consumption.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09711",
        "abstract url": "https://arxiv.org/abs/2408.09711",
        "title": "Avoshifts",
        "rating": "-10",
        "keywords": [],
        "abstract": "An avoshift is a subshift where for each set $C$ from a suitable family of subsets of the shift group, the set of all possible valid extensions of a globally valid pattern on $C$ to the identity element is determined by a bounded subpattern. This property is shared (for various families of sets $C$) by for example cellwise quasigroup shifts, TEP subshifts, and subshifts of finite type with a safe symbol. In this paper we concentrate on avoshifts on polycyclic groups, when the sets $C$ are what we call ``inductive intervals''. We show that then avoshifts are a recursively enumerable subset of subshifts of finite type. Furthermore, we can effectively compute lower-dimensional projective subdynamics and certain factors (avofactors), and we can decide equality and inclusion for subshifts in this class. These results were previously known for group shifts, but our class also covers many non-algebraic examples as well as many SFTs without dense periodic points. The theory also yields new proofs of decidability of inclusion for SFTs on free groups, and SFTness of subshifts with the topological strong spatial mixing property.",
        "subjects": [
            "math.DS",
            "cs.CC",
            "math.GR"
        ],
        "comment": "34 pages, 1 figure"
    },
    {
        "paper id": "2408.09713",
        "abstract url": "https://arxiv.org/abs/2408.09713",
        "title": "Carbon Footprint Accounting Driven by Large Language Models and Retrieval-augmented Generation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Carbon footprint accounting is crucial for quantifying greenhouse gas emissions and achieving carbon neutrality.The dynamic nature of processes, accounting rules, carbon-related policies, and energy supply structures necessitates real-time updates of CFA. Traditional life cycle assessment methods rely heavily on human expertise, making near-real-time updates challenging. This paper introduces a novel approach integrating large language models (LLMs) with retrieval-augmented generation technology to enhance the real-time, professional, and economical aspects of carbon footprint information retrieval and analysis. By leveraging LLMs' logical and language understanding abilities and RAG's efficient retrieval capabilities, the proposed method LLMs-RAG-CFA can retrieve more relevant professional information to assist LLMs, enhancing the model's generative abilities. This method offers broad professional coverage, efficient real-time carbon footprint information acquisition and accounting, and cost-effective automation without frequent LLMs' parameter updates. Experimental results across five industries(primary aluminum, lithium battery, photovoltaic, new energy vehicles, and transformers)demonstrate that the LLMs-RAG-CFA method outperforms traditional methods and other LLMs, achieving higher information retrieval rates and significantly lower information deviations and carbon footprint accounting deviations. The economically viable design utilizes RAG technology to balance real-time updates with cost-effectiveness, providing an efficient, reliable, and cost-saving solution for real-time carbon emission management, thereby enhancing environmental sustainability practices.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09761",
        "abstract url": "https://arxiv.org/abs/2408.09761",
        "title": "Mutation Strength Adaptation of the $(\u03bc/\u03bc_I, \u03bb)$-ES for Large Population Sizes on the Sphere Function",
        "rating": "-10",
        "keywords": [],
        "abstract": "The mutation strength adaptation properties of a multi-recombinative $(\u03bc/\u03bc_I, \u03bb)$-ES are studied for isotropic mutations. To this end, standard implementations of cumulative step-size adaptation (CSA) and mutative self-adaptation ($\u03c3$SA) are investigated experimentally and theoretically by assuming large population sizes ($\u03bc$) in relation to the search space dimensionality ($N$). The adaptation is characterized in terms of the scale-invariant mutation strength on the sphere in relation to its maximum achievable value for positive progress. %The results show how the different $\u03c3$-adaptation variants behave as $\u03bc$ and $N$ are varied. Standard CSA-variants show notably different adaptation properties and progress rates on the sphere, becoming slower or faster as $\u03bc$ or $N$ are varied. This is shown by investigating common choices for the cumulation and damping parameters. Standard $\u03c3$SA-variants (with default learning parameter settings) can achieve faster adaptation and larger progress rates compared to the CSA. However, it is shown how self-adaptation affects the progress rate levels negatively. Furthermore, differences regarding the adaptation and stability of $\u03c3$SA with log-normal and normal mutation sampling are elaborated.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "Technical Report"
    },
    {
        "paper id": "2408.09766",
        "abstract url": "https://arxiv.org/abs/2408.09766",
        "title": "From a Natural to a Formal Language with DSL Assistant",
        "rating": "-10",
        "keywords": [],
        "abstract": "The development of domain-specific languages (DSLs) is a laborious and iterative process that seems to naturally lean to the use of generative artificial intelligence. We design and prototype DSL Assistant, a tool that integrates generative language models to support the development of DSLs. DSL Assistant uses OpenAI's assistant API with GPT-4o to generate DSL grammars and example instances. To reflect real-world use, DSL Assistant supports several different interaction modes for evolving a DSL design, and includes automatic error repair. Our experiments show that DSL Assistant helps users to create and modify DSLs. However, the quality of the generated DSLs depends on the specific domain and the followed interaction patterns.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": "Published in MDE Intelligence Workshop 2024"
    },
    {
        "paper id": "2408.09829",
        "abstract url": "https://arxiv.org/abs/2408.09829",
        "title": "Dynamic Shaping of Multi-Touch Stimuli by Programmable Acoustic Metamaterial",
        "rating": "-10",
        "keywords": [],
        "abstract": "Acoustic metamaterials are artificial structures, often lattice of resonators, with unusual properties. They can be engineered to stop wave propagation in specific frequency bands. Once manufactured, their dispersive qualities remain invariant in time and space, limiting their practical use. Actively tuned arrangements have received growing interest to address this issue. Here, we introduce a new class of active metamaterial made from dual-state unit cells, either vibration sources when powered or passive resonators when left disconnected. They possess self-tuning capabilities, enabling deep subwavelength band gaps to automatically match the carrier signal of powered cells, typically around 200Hz. Swift electronic commutations between both states establish the basis for real-time reconfiguration of waveguides and shaping of vibration patterns. A series of experiments highlight how these tailored acceleration fields can spatially encode information relevant to human touch. This novel metamaterial can readily be made using off-the-shelf smartphone vibration motors, paving the way for a widespread adoption of multi-touch tactile displays.",
        "subjects": [
            "physics.app-ph",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09836",
        "abstract url": "https://arxiv.org/abs/2408.09836",
        "title": "Effects of the Plan V\u00e9lo I and II on vehicular flow in Paris -- An Empirical Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, Paris, France, transformed its transportation infrastructure, marked by a notable reallocation of space away from cars to active modes of transportation. Key initiatives driving this transformation included Plan V\u00e9lo I and II, during which the city created over 1,000 kilometres of new bike paths to encourage cycling. For this, substantial road capacity has been removed from the system. This transformation provides a unique opportunity to investigate the impact of the large-scale network re-configuration on the network-wide traffic flow. Using the Network Fundamental Diagram (NFD) and a re-sampling methodology for its estimation, we investigate with empirical loop detector data from 2010 and 2023 the impact on the network's capacity, critical density, and free-flow speed resulting from these policy interventions. We find that in the urban core with the most policy interventions, per lane capacity decreased by over 50%, accompanied by a 60% drop in free-flow speed. Similarly, in the zone with fewer interventions, capacity declined by 34%, with a 40% reduction in free-flow speed. While these changes seem substantial, the NFDs show that overall congestion did not increase, indicating a modal shift to other modes of transport and hence presumably more sustainable urban mobility.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09842",
        "abstract url": "https://arxiv.org/abs/2408.09842",
        "title": "Can we measure the impact of a database?",
        "rating": "-10",
        "keywords": [],
        "abstract": "In disseminating scientific and statistical data, on-line databases have almost completely replaced traditional paper-based media such as journals and reference works. Given this, can we measure the impact of a database in the same way that we measure an author's or journal's impact? To do this, we need somehow to represent a database as a set of publications, and databases typically allow a large number of possible decompositions into parts, any of which could be treated as a publication. We show that the definition of the h-index naturally extends to hierarchies, so that if a database admits some kind of hierarchical interpretation we can use this as one measure of the importance of a database; moreover, this can be computed as efficiently as one can compute the normal h-index. This also gives us a decomposition of the database that might be used for other purposes such as giving credit to the curators or contributors to the database. We illustrate the process by analyzing three widely used databases.",
        "subjects": [
            "cs.DB",
            "cs.DL"
        ],
        "comment": "10 pages, 4 figures, accepted with minor in the Communications of the ACM"
    },
    {
        "paper id": "2408.09847",
        "abstract url": "https://arxiv.org/abs/2408.09847",
        "title": "Fashion Image-to-Image Translation for Complementary Item Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "The increasing demand for online fashion retail has boosted research in fashion compatibility modeling and item retrieval, focusing on matching user queries (textual descriptions or reference images) with compatible fashion items. A key challenge is top-bottom retrieval, where precise compatibility modeling is essential. Traditional methods, often based on Bayesian Personalized Ranking (BPR), have shown limited performance. Recent efforts have explored using generative models in compatibility modeling and item retrieval, where generated images serve as additional inputs. However, these approaches often overlook the quality of generated images, which could be crucial for model performance. Additionally, generative models typically require large datasets, posing challenges when such data is scarce. To address these issues, we introduce the Generative Compatibility Model (GeCo), a two-stage approach that improves fashion image retrieval through paired image-to-image translation. First, the Complementary Item Generation Model (CIGM), built on Conditional Generative Adversarial Networks (GANs), generates target item images (e.g., bottoms) from seed items (e.g., tops), offering conditioning signals for retrieval. These generated samples are then integrated into GeCo, enhancing compatibility modeling and retrieval accuracy. Evaluations on three datasets show that GeCo outperforms state-of-the-art baselines. Key contributions include: (i) the GeCo model utilizing paired image-to-image translation within the Composed Image Retrieval framework, (ii) comprehensive evaluations on benchmark datasets, and (iii) the release of a new Fashion Taobao dataset designed for top-bottom retrieval, promoting further research.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09848",
        "abstract url": "https://arxiv.org/abs/2408.09848",
        "title": "Abstract Environment Trimming",
        "rating": "-10",
        "keywords": [],
        "abstract": "Variable sharing is a fundamental property in the static analysis of logic programs, since it is instrumental for ensuring correctness and increasing precision while inferring many useful program properties. Such properties include modes, determinacy, non-failure, cost, etc. This has motivated significant work on developing abstract domains to improve the precision and performance of sharing analyses. Much of this work has centered around the family of set-sharing domains, because of the high precision they offer. However, this comes at a price: their scalability to a wide set of realistic programs remains challenging and this hinders their wider adoption. In this work, rather than defining new sharing abstract domains, we focus instead on developing techniques which can be incorporated in the analyzers to address aspects that are known to affect the efficiency of these domains, such as the number of variables, without affecting precision. These techniques are inspired in others used in the context of compiler optimizations, such as expression reassociation and variable trimming. We present several such techniques and provide an extensive experimental evaluation of over 1100 program modules taken from both production code and classical benchmarks. This includes the Spectector cache analyzer, the s(CASP) system, the libraries of the Ciao system, the LPdoc documenter, the PLAI analyzer itself, etc. The experimental results are quite encouraging: we have obtained significant speed-ups, and, more importantly, the number of modules that require a timeout was cut in half. As a result, many more programs can be analyzed precisely in reasonable times.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "61 pages, 10 figures, 7 tables, submitted to ICLP 2024"
    },
    {
        "paper id": "2408.09854",
        "abstract url": "https://arxiv.org/abs/2408.09854",
        "title": "Qualitative properties and stability analysis of the mathematical model for a DC-DC electric circuit",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper describes a simplified model of an electric circuit with a DC-DC converter and a PID-regulator as a system of integral differential equations with an identically singular matrix multiplying the higher derivative of the desired vector-function. We use theoretical results on integral and differential equations and their systems to prove solvability of such a model and analyze its stability.",
        "subjects": [
            "eess.SY",
            "math.NA"
        ],
        "comment": "submitted to COIA-2024. arXiv admin note: text overlap with arXiv:2408.06045"
    },
    {
        "paper id": "2408.09871",
        "abstract url": "https://arxiv.org/abs/2408.09871",
        "title": "Exploring Complexity: An Extended Study of Formal Properties for Process Model Complexity Measures",
        "rating": "-10",
        "keywords": [],
        "abstract": "A good process model is expected not only to reflect the behavior of the process, but also to be as easy to read and understand as possible. Because preferences vary across different applications, numerous measures provide ways to reflect the complexity of a model with a numeric score. However, this abundance of different complexity measures makes it difficult to select one for analysis. Furthermore, most complexity measures are defined for BPMN or EPC, but not for workflow nets. This paper is an extended analysis of complexity measures and their formal properties. It adapts existing complexity measures to the world of workflow nets. It then compares these measures with a set of properties originally defined for software complexity, as well as new extensions to it. We discuss the importance of the properties in theory by evaluating whether matured complexity measures should fulfill them or whether they are optional. We find that not all inspected properties are mandatory, but also demonstrate that the behavior of evolutionary process discovery algorithms is influenced by some of these properties. Our findings help analysts to choose the right complexity measure for their use-case.",
        "subjects": [
            "cs.FL"
        ],
        "comment": "73 pages, 68 figures"
    },
    {
        "paper id": "2408.09874",
        "abstract url": "https://arxiv.org/abs/2408.09874",
        "title": "Unsourced Multiple Access: A Coding Paradigm for Massive Random Access",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper is a tutorial introduction to the field of unsourced multiple access (UMAC) protocols. We first provide a historical survey of the evolution of random access protocols, focusing specifically on the case in which uncoordinated users share a wireless broadcasting medium. Next, we highlight the change of perspective originated by the UMAC model, in which the physical and medium access layer's protocols cooperate, thus reframing random access as a novel coding-theoretic problem. By now, a large variety of UMAC protocols (codes) emerged, necessitating a certain classification that we indeed propose here. Although some random access schemes require a radical change of the physical layer, others can be implemented with minimal changes to existing industry standards. As an example, we discuss a simple modification to the 5GNR Release 16 random access channel that builds on the UMAC theory and that dramatically improves energy efficiency for systems with even moderate number of simultaneous users (e.g., $5-10$ dB gain for $10-50$ users), and also enables handling of high number of users, something completely out of reach of the state-of-the-art.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Proceedings of the IEEE, accepted for publication"
    },
    {
        "paper id": "2408.09885",
        "abstract url": "https://arxiv.org/abs/2408.09885",
        "title": "Joint Auction in the Online Advertising Market",
        "rating": "-10",
        "keywords": [],
        "abstract": "Online advertising is a primary source of income for e-commerce platforms. In the current advertising pattern, the oriented targets are the online store owners who are willing to pay extra fees to enhance the position of their stores. On the other hand, brand suppliers are also desirable to advertise their products in stores to boost brand sales. However, the currently used advertising mode cannot satisfy the demand of both stores and brand suppliers simultaneously. To address this, we innovatively propose a joint advertising model termed Joint Auction, allowing brand suppliers and stores to collaboratively bid for advertising slots, catering to both their needs. However, conventional advertising auction mechanisms are not suitable for this novel scenario. In this paper, we propose JRegNet, a neural network architecture for the optimal joint auction design, to generate mechanisms that can achieve the optimal revenue and guarantee near dominant strategy incentive compatibility and individual rationality. Finally, multiple experiments are conducted on synthetic and real data to demonstrate that our proposed joint auction significantly improves platform revenue compared to the known baselines.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09887",
        "abstract url": "https://arxiv.org/abs/2408.09887",
        "title": "Beyond Diagonal RIS: Passive Maximum Ratio Transmission and Interference Nulling Enabler",
        "rating": "-10",
        "keywords": [],
        "abstract": "Beyond diagonal reconfigurable intelligent surfaces (BD-RIS) generalizes and goes beyond conventional diagonal reconfigurable intelligent surfaces (D-RIS) by interconnecting elements to generate beyond diagonal scattering matrices, which significantly strengthen the wireless channels. In this work, we use BD-RIS for passive multiuser beamforming in multiuser multiple-input-single-output (MU-MISO) systems. Specifically, we design the scattering matrix of BD-RIS to either maximize the sum received signal power at the users following maximum ratio transmission (MRT), or to nullify the interference at the users following zero forcing (ZF). Furthermore, we investigate uniform/optimized power allocation and ZF precoding at the base station (BS). Numerical results show that BD-RIS improves the interference nulling capability and sum rate with fewer reflecting elements (REs) compared to D-RIS. In addition, at moderate to high signal to noise ratios (SNRs), passive interference nulling reduces the complexity at the BS by relaxing the need for precoding or water-filling power allocation design. Furthermore, the passive MRT with ZF precoding achieves a tight sum rate performance to the joint design considering MU-MISO scenarios with many REs while maintaining low computational complexity and simplifying the channel estimation.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09889",
        "abstract url": "https://arxiv.org/abs/2408.09889",
        "title": "Towards a Field Based Bayesian Evidence Inference from Nested Sampling Data",
        "rating": "-10",
        "keywords": [],
        "abstract": "Nested sampling (NS) is a stochastic method for computing the log-evidence of a Bayesian problem. It relies on stochastic estimates of prior volumes enclosed by likelihood contours, which limits the accuracy of the log-evidence calculation. We propose to transform the prior volume estimation into a Bayesian inference problem, which allows us to incorporate a smoothness assumption for likelihood-prior volume relations. As a result, we aim to increase the accuracy of the volume estimates and thus improve the overall log-evidence calculation using NS. The method presented works as a post-processing step for NS and provides posterior samples of the likelihood-prior-volume relation, from which the log-evidence can be calculated. We demonstrate an implementation of the algorithm and compare its results with plain NS on two synthetic datasets for which the underlying evidence is known. We find a significant improvement in accuracy for runs with less than one hundred active samples in NS, but are prone to numerical problems beyond this point.",
        "subjects": [
            "physics.comp-ph",
            "cs.IT",
            "physics.data-an"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09902",
        "abstract url": "https://arxiv.org/abs/2408.09902",
        "title": "Implementing OpenMP for Zig to enable its use in HPC context",
        "rating": "-10",
        "keywords": [],
        "abstract": "This extended abstract explores supporting OpenMP in the Zig programming language. Whilst, C and Fortran are currently the main languages used to implement HPC applications, Zig provides a similar level of performance complimented with several modern language features, such as enforcing memory safety. However, Zig lacks support for OpenMP which is the de facto threaded programming technology. Leveraging Zig's LLVM compiler tooling, we have added partial support for OpenMP to the Zig compiler and demonstrated that the performance attained by using Zig with OpenMP is comparable to, and in come cases exceeds, that of conventional HPC languages. Consequently we demonstrate that Zig is a viable and important programming technology to use for HPC, and this work paves the way for more HPC features to be added to Zig, ultimately providing HPC developers with the option of using a safer, more modern language for creating high performance applications.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Author accepted version of extended abstract in ICPP workshop proceedings"
    },
    {
        "paper id": "2408.09926",
        "abstract url": "https://arxiv.org/abs/2408.09926",
        "title": "WoW -- A System for Self-Service Collaborative Design Workshops",
        "rating": "-10",
        "keywords": [],
        "abstract": "In many working environments, users have to solve complex problems relying on large and multi-source data. Such problems require several experts to collaborate on solving them, or a single analyst to reconcile multiple complementary standpoints. Previous research has shown that wall-sized displays supports different collaboration styles, based most often on abstract tasks as proxies of real work. We present the design and implementation of WoW, short for ``Workspace on Wall'', a multi-user Web-based portal for collaborative meetings and workshops in multi-surface environments. We report on a two-year effort spanning context inquiry studies, system design iterations, development, and real testing rounds targeting design engineers in the tire industry. The pneumatic tires found on the market result from a highly collaborative and iterative development process that reconciles conflicting constraints through a series of product design workshops. WoW was found to be a flexible solution to build multi-view set-ups in a self-service manner and an effective means to access more content at once. Our users also felt more engaged in their collaborative problem-solving work using WoW than in conventional meeting rooms.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09934",
        "abstract url": "https://arxiv.org/abs/2408.09934",
        "title": "Human Mimetic Forearm Design with Radioulnar Joint using Miniature Bone-Muscle Modules and Its Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "The human forearm is composed of two long, thin bones called the radius and the ulna, and rotates using two axle joints. We aimed to develop a forearm based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body in order to bring out its benefits. For this, we need to miniaturize the muscle modules. To approach this task, we arranged two muscle motors inside one muscle module, and used the space effectively by utilizing common parts. In addition, we enabled the muscle module to also be used as the bone structure. Moreover, we used miniature motors and developed a way to dissipate the motor heat to the bone structure. Through these approaches, we succeeded in developing a forearm with a radioulnar joint based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body, while keeping maintainability and reliability. Also, we performed some motions such as soldering, opening a book, turning a screw, and badminton swinging using the benefits of the radioulnar structure, which have not been discussed before, and verified that Kengoro can realize skillful motions using the radioulnar joint like a human.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at IROS2017"
    },
    {
        "paper id": "2408.09938",
        "abstract url": "https://arxiv.org/abs/2408.09938",
        "title": "Minimal Sensor Placement for Generic State and Unknown Input Observability",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper addresses the problem of selecting the minimum number of dedicated sensors to achieve observability in the presence of unknown inputs, namely, the state and input observability, for linear time-invariant systems. We assume that the only available information is the zero-nonzero structure of system matrices, and approach this problem within a structured system model. We revisit the concept of state and input observability for structured systems, providing refined necessary and sufficient conditions for placing dedicated sensors via the Dulmage-Mendelsohn decomposition. Based on these conditions, we prove that determining the minimum number of dedicated sensors to achieve generic state and input observability is NP-hard, which contrasts sharply with the polynomial-time complexity of the corresponding problem with known inputs. We also demonstrate that this problem is hard to approximate within a factor of $(1-o(1)){\\rm{log}}(n)$, where $n$ is the state dimension. Notwithstanding, we propose nontrivial upper and lower bounds that can be computed in polynomial time, which confine the optimal value of this problem to an interval with length being the number of inputs. We further present a special case for which the exact optimal value can be determined in polynomial time. Additionally, we propose a two-stage algorithm to solve this problem approximately. Each stage of the algorithm is either optimal or suboptimal and can be completed in polynomial time.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2408.09943",
        "abstract url": "https://arxiv.org/abs/2408.09943",
        "title": "Calibrating Noise for Group Privacy in Subsampled Mechanisms",
        "rating": "-10",
        "keywords": [],
        "abstract": "Given a group size m and a sensitive dataset D, group privacy (GP) releases information about D with the guarantee that the adversary cannot infer with high confidence whether the underlying data is D or a neighboring dataset D' that differs from D by m records. GP generalizes the well-established notion of differential privacy (DP) for protecting individuals' privacy; in particular, when m=1, GP reduces to DP. Compared to DP, GP is capable of protecting the sensitive aggregate information of a group of up to m individuals, e.g., the average annual income among members of a yacht club. Despite its longstanding presence in the research literature and its promising applications, GP is often treated as an afterthought, with most approaches first developing a DP mechanism and then using a generic conversion to adapt it for GP, treating the DP solution as a black box. As we point out in the paper, this methodology is suboptimal when the underlying DP solution involves subsampling, e.g., in the classic DP-SGD method for training deep learning models. In this case, the DP-to-GP conversion is overly pessimistic in its analysis, leading to low utility in the published results under GP. Motivated by this, we propose a novel analysis framework that provides tight privacy accounting for subsampled GP mechanisms. Instead of converting a black-box DP mechanism to GP, our solution carefully analyzes and utilizes the inherent randomness in subsampled mechanisms, leading to a substantially improved bound on the privacy loss with respect to GP. The proposed solution applies to a wide variety of foundational mechanisms with subsampling. Extensive experiments with real datasets demonstrate that compared to the baseline convert-from-blackbox-DP approach, our GP mechanisms achieve noise reductions of over an order of magnitude in several practical settings, including deep neural network training.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "accepted for publication in Proceedings of VLDB Endowment (PVLDB) 2025"
    },
    {
        "paper id": "2408.09953",
        "abstract url": "https://arxiv.org/abs/2408.09953",
        "title": "Control by Adding Players to Change or Maintain the Shapley-Shubik or the Penrose-Banzhaf Power Index in Weighted Voting Games Is Complete for NP^PP",
        "rating": "-10",
        "keywords": [],
        "abstract": "Weighted voting games are a well-known and useful class of succinctly representable simple games that have many real-world applications, e.g., to model collective decision-making in legislative bodies or shareholder voting. Among the structural control types being analyzing, one is control by adding players to weighted voting games, so as to either change or to maintain a player's power in the sense of the (probabilistic) Penrose-Banzhaf power index or the Shapley-Shubik power index. For the problems related to this control, the best known lower bound is PP-hardness, where PP is \"probabilistic polynomial time,\" and the best known upper bound is the class NP^PP, i.e., the class NP with a PP oracle. We optimally raise this lower bound by showing NP^PP-hardness of all these problems for the Penrose-Banzhaf and the Shapley-Shubik indices, thus establishing completeness for them in that class. Our proof technique may turn out to be useful for solving other open problems related to weighted voting games with such a complexity gap as well.",
        "subjects": [
            "cs.GT",
            "cs.CC"
        ],
        "comment": "To appear in Proceedings of ECAI 2024"
    },
    {
        "paper id": "2408.09955",
        "abstract url": "https://arxiv.org/abs/2408.09955",
        "title": "MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the emergence of large language models (LLMs), LLM-powered multi-agent systems (LLM-MA systems) have been proposed to tackle real-world tasks. However, their agents mostly follow predefined Standard Operating Procedures (SOPs) that remain unchanged across the whole interaction, lacking autonomy and scalability. Additionally, current solutions often overlook the necessity for effective agent cooperation. To address the above limitations, we propose MegaAgent, a practical framework designed for autonomous cooperation in large-scale LLM Agent systems. MegaAgent leverages the autonomy of agents to dynamically generate agents based on task requirements, incorporating features such as automatically dividing tasks, systematic planning and monitoring of agent activities, and managing concurrent operations. In addition, MegaAgent is designed with a hierarchical structure and employs system-level parallelism to enhance performance and boost communication. We demonstrate the effectiveness of MegaAgent through Gobang game development, showing that it outperforms popular LLM-MA systems; and national policy simulation, demonstrating its high autonomy and potential to rapidly scale up to 590 agents while ensuring effective cooperation among them. Our results indicate that MegaAgent is the first autonomous large-scale LLM-MA system with no pre-defined SOPs, high effectiveness and scalability, paving the way for further research in this field. Our code is at https://anonymous.4open.science/r/MegaAgent-81F3.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09962",
        "abstract url": "https://arxiv.org/abs/2408.09962",
        "title": "Validation of the Results of Cross-chain Smart Contract Based on Confirmation Method",
        "rating": "-10",
        "keywords": [],
        "abstract": "Smart contracts are widely utilized in cross-chain interactions, where their results are transmitted from one blockchain (the producer blockchain) to another (the consumer blockchain). Unfortunately, the consumer blockchain often accepts these results without executing the smart contracts for validation, posing potential security risks. To address this, we propose a method for validating cross-chain smart contract results. Our approach emphasizes consumer blockchain execution of cross-chain smart contracts of producer blockchain, allowing comparison of results with the transmitted ones to detect potential discrepancies and ensure data integrity during cross-chain data dissemination. Additionally, we introduce the confirmation with proof method, which involves incorporating the chain of blocks and relevant cross-chain smart contract data from the producer blockchain into the consumer blockchain as evidence (or proof), establishing a unified and secure perspective of cross-chain smart contract results. Our verification results highlight the feasibility of cross-chain validation at the smart contract level.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.09989",
        "abstract url": "https://arxiv.org/abs/2408.09989",
        "title": "Adaptive BESS and Grid Setpoints Optimization: A Model-Free Framework for Efficient Battery Management under Dynamic Tariff Pricing",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces an enhanced framework for managing Battery Energy Storage Systems (BESS) in residential communities. The non-convex BESS control problem is first addressed using a gradient-based optimizer, providing a benchmark solution. Subsequently, the problem is tackled using multiple Deep Reinforcement Learning (DRL) agents, with a specific emphasis on the off-policy Soft Actor-Critic (SAC) algorithm. This version of SAC incorporates reward refinement based on this non-convex problem, applying logarithmic scaling to enhance convergence rates. Additionally, a safety mechanism selects only feasible actions from the action space, aimed at improving the learning curve, accelerating convergence, and reducing computation times. Moreover, the state representation of this DRL approach now includes uncertainties quantified in the entropy term, enhancing the model's adaptability across various entropy types. This developed system adheres to strict limits on the battery's State of Charge (SOC), thus preventing breaches of SOC boundaries and extending the battery lifespan. The robustness of the model is validated across several Australian states' districts, each characterized by unique uncertainty distributions. By implementing the refined SAC, the SOC consistently surpasses 50 percent by the end of each day, enabling the BESS control to start smoothly for the next day with some reserve. Finally, this proposed DRL method achieves a mean reduction in optimization time by 50 percent and an average cost saving of 40 percent compared to the gradient-based optimization benchmark.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10000",
        "abstract url": "https://arxiv.org/abs/2408.10000",
        "title": "Working in Extended Reality in the Wild: Worker and Bystander Experiences of XR Virtual Displays in Real-World Settings",
        "rating": "-10",
        "keywords": [],
        "abstract": "Although access to sufficient screen space is crucial to knowledge work, workers often find themselves with limited access to display infrastructure in remote or public settings. While virtual displays can be used to extend the available screen space through extended reality (XR) head-worn displays (HWD), we must better understand the implications of working with them in public settings from both users' and bystanders' viewpoints. To this end, we conducted two user studies. We first explored the usage of a hybrid AR display across real-world settings and tasks. We focused on how users take advantage of virtual displays and what social and environmental factors impact their usage of the system. A second study investigated the differences between working with a laptop, an AR system, or a VR system in public. We focused on a single location and participants performed a predefined task to enable direct comparisons between the conditions while also gathering data from bystanders. The combined results suggest a positive acceptance of XR technology in public settings and show that virtual displays can be used to accompany existing devices. We highlighted some environmental and social factors. We saw that previous XR experience and personality can influence how people perceive the use of XR in public. In addition, we confirmed that using XR in public still makes users stand out and that bystanders are curious about the devices, yet have no clear understanding of how they can be used.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2310.09786"
    },
    {
        "paper id": "2408.10017",
        "abstract url": "https://arxiv.org/abs/2408.10017",
        "title": "General Impedance Modeling for Modular Multilevel Converter with Grid-forming and Grid-following Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "Modular multilevel converter (MMC) has complex topology, control architecture and broadband harmonic spectrum. For this, linear-time-periodic (LTP) theory, covering multi-harmonic coupling relations, has been adopted for MMC impedance modeling recently. However, the existing MMC impedance models usually lack explicit expressions and general modeling procedure for different control strategies. To this end, this paper proposes a general impedance modeling procedure applicable to various power converters with grid-forming and grid-following control strategies. The modeling is based on a unified representation of MMC circuit as the input and output relation between the voltage or current on the AC side and the exerted modulation index, while the control part vice versa, thereby interconnected as closed-loop feedback. With each part expressed as transfer functions, the final impedance model keeps the explicit form of harmonic transfer function matrix, making it convenient to directly observe and analyze the influence of each part individually. Thereby the submodule capacitance is found as the main cause of difference between MMC impedance compared to two-level converter, which will get closer as the capacitance increases. Effectiveness and generality of the impedance modeling method is demonstrated through comprehensive comparison with impedance scanning using electromagnetic transient simulation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10027",
        "abstract url": "https://arxiv.org/abs/2408.10027",
        "title": "The Expressive Power of Uniform Population Protocols with Logarithmic Space",
        "rating": "-10",
        "keywords": [],
        "abstract": "Population protocols are a model of computation in which indistinguishable mobile agents interact in pairs to decide a property of their initial configuration. Originally introduced by Angluin et. al. in 2004 with a constant number of states, research nowadays focuses on protocols where the space usage depends on the number of agents. The expressive power of population protocols has so far however only been determined for protocols using $o(\\log n)$ states, which compute only semilinear predicates, and for $\u03a9(n)$ states. This leaves a significant gap, particularly concerning protocols with $\u0398(\\log n)$ or $\u0398(\\operatorname{polylog} n)$ states, which are the most common constructions in the literature. In this paper we close the gap and prove that for any $\\varepsilon>0$ and $f\\in\u03a9(\\log n)\\cap\\mathcal{O}(n^{1-\\varepsilon})$, both uniform and non-uniform population protocols with $\u0398(f(n))$ states can decide exactly $\\mathsf{NSPACE}(f(n) \\log n)$.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10029",
        "abstract url": "https://arxiv.org/abs/2408.10029",
        "title": "On the Optimal Radius and Subcarrier Mapping for Binary Modulation on Conjugate-Reciprocal Zeros",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we investigate the radius maximizing reliability for binary modulation on conjugate-reciprocal zeros (BMOCZ) implemented with both maximum likelihood (ML) and direct zero-testing (DiZeT) decoders. We first show that the optimal radius for BMOCZ is a function of the employed decoder and that the radius maximizing the minimum distance between polynomial zeros does not maximize the minimum distance of the final code. While maximizing zero separation offers an almost optimal solution with the DiZeT decoder, simulations show that the ML decoder outperforms the DiZeT decoder in both additive white Gaussian noise (AWGN) and fading channels when the radius is chosen to maximize codeword separation. Finally, we analyze different sequence-to-subcarrier mappings for BMOCZ-based orthogonal frequency division multiplexing (OFDM). We highlight a flexible time-frequency OFDM waveform that avoids distortion introduced by a frequency-selective channel at the expense of a higher peak-to-average power ratio (PAPR).",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This work has been accepted for presentation at IEEE MILCOM 2024"
    },
    {
        "paper id": "2408.10066",
        "abstract url": "https://arxiv.org/abs/2408.10066",
        "title": "Near-Optimal Mechanisms for Resource Allocation Without Monetary Transfers",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem in which a central planner sequentially allocates a single resource to multiple strategic agents using their utility reports at each round, but without using any monetary transfers. We consider general agent utility distributions and two standard settings: a finite horizon $T$ and an infinite horizon with $\u03b3$ discounts. We provide general tools to characterize the convergence rate between the optimal mechanism for the central planner and the first-best allocation if true agent utilities were available. This heavily depends on the utility distributions, yielding rates anywhere between $1/\\sqrt T$ and $1/T$ for the finite-horizon setting, and rates faster than $\\sqrt{1-\u03b3}$, including exponential rates for the infinite-horizon setting as agents are more patient $\u03b3\\to 1$. On the algorithmic side, we design mechanisms based on the promised-utility framework to achieve these rates and leverage structure on the utility distributions. Intuitively, the more flexibility the central planner has to reward or penalize any agent while incurring little social welfare cost, the faster the convergence rate. In particular, discrete utility distributions typically yield the slower rates $1/\\sqrt T$ and $\\sqrt{1-\u03b3}$, while smooth distributions with density typically yield faster rates $1/T$ (up to logarithmic factors) and $1-\u03b3$.",
        "subjects": [
            "cs.GT",
            "econ.TH",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10082",
        "abstract url": "https://arxiv.org/abs/2408.10082",
        "title": "Tywaves: A Typed Waveform Viewer for Chisel",
        "rating": "-10",
        "keywords": [],
        "abstract": "Chisel (Constructing Hardware In a Scala Embedded Language) is a broadly adopted HDL that brings object-oriented and functional programming, type-safety, and parameterization to hardware design. However, while these language features significantly improve the process of writing code, debugging Chisel designs with open source tools loses many of the advantages of the source language, as type information and data structure hierarchies are lost in the translation, simulator output, and waveform viewer. This work, Tywaves, presents a new type-centered debugging format that brings the same level of abstraction found in contemporary hardware languages to waveform viewers. Contributions to the Chisel library and CIRCT MLIR compiler as well as the Surfer waveform viewer result in a waveform viewer that better supports the Chisel HDL. Project url: https://github.com/rameloni/tywaves-chisel-demo",
        "subjects": [
            "cs.AR",
            "cs.PL"
        ],
        "comment": "6 pages, 2 tables, 3 figures"
    },
    {
        "paper id": "2408.10092",
        "abstract url": "https://arxiv.org/abs/2408.10092",
        "title": "Selecting Relay Nodes Based on Evaluation Results to Enhance P2P Broadcasting Efficiency",
        "rating": "-10",
        "keywords": [],
        "abstract": "The existence of node failures is inevitable in distributed systems, thus many P2P broadcasting networks adopt highly robust Flooding-based broadcast algorithms. High redundancy inevitably leads to high network resource consumption, and it may constrain the data transmission rate of the network. To address excessive network resource consumption, many studies have explored broadcasting mechanisms in structured P2P overlay networks. However, existing DHT-based algorithms cannot assess the quality of neighbors, which is crucial for broadcast efficiency. In this paper, we introduce the Neighbor Evaluation mechanism to select relay nodes based on their evaluated contributions. According to experimental results, the Neighbor Evaluation mechanism has a significant effect on both broadcast latency and coverage rate.",
        "subjects": [
            "cs.NI",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10116",
        "abstract url": "https://arxiv.org/abs/2408.10116",
        "title": "Vulseye: Detect Smart Contract Vulnerabilities via Stateful Directed Graybox Fuzzing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Smart contracts, the cornerstone of decentralized applications, have become increasingly prominent in revolutionizing the digital landscape. However, vulnerabilities in smart contracts pose great risks to user assets and undermine overall trust in decentralized systems. But current smart contract fuzzers fall short of expectations in testing efficiency for two primary reasons. Firstly, smart contracts are stateful programs, and existing approaches, primarily coverage-guided, lack effective feedback from the contract state. Consequently, they struggle to effectively explore the contract state space. Secondly, coverage-guided fuzzers, aiming for comprehensive program coverage, may lead to a wastage of testing resources on benign code areas. This wastage worsens in smart contract testing, as the mix of code and state spaces further complicates comprehensive testing. To address these challenges, we propose Vulseye, a stateful directed graybox fuzzer for smart contracts guided by vulnerabilities. Different from prior works, Vulseye achieves stateful directed fuzzing by prioritizing testing resources to code areas and contract states that are more prone to vulnerabilities. We introduce Code Targets and State Targets into fuzzing loops as the testing targets of Vulseye. We use static analysis and pattern matching to pinpoint Code Targets, and propose a scalable backward analysis algorithm to specify State Targets. We design a novel fitness metric that leverages feedback from both the contract code space and state space, directing fuzzing toward these targets. With the guidance of code and state targets, Vulseye alleviates the wastage of testing resources on benign code areas and achieves effective stateful fuzzing. In comparison with state-of-the-art fuzzers, Vulseye demonstrated superior effectiveness and efficiency.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Submitted to TIFS"
    },
    {
        "paper id": "2408.10117",
        "abstract url": "https://arxiv.org/abs/2408.10117",
        "title": "Branching Bisimilarity for Processes with Time-outs",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper provides an adaptation of branching bisimilarity to reactive systems with time-outs. Multiple equivalent definitions are procured, along with a modal characterisation and a proof of its congruence property for a standard process algebra with recursion. The last section presents a complete axiomatisation for guarded processes without infinite sequences of unobservable actions.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "An extended abstract of this paper appears in Proc. CONCUR'24, see https://doi.org/10.4230/LIPIcs.CONCUR.2024.36"
    },
    {
        "paper id": "2408.10143",
        "abstract url": "https://arxiv.org/abs/2408.10143",
        "title": "Data-Driven Analysis to Understand GPU Hardware Resource Usage of Optimizations",
        "rating": "-10",
        "keywords": [],
        "abstract": "With heterogeneous systems, the number of GPUs per chip increases to provide computational capabilities for solving science at a nanoscopic scale. However, low utilization for single GPUs defies the need to invest more money for expensive ccelerators. While related work develops optimizations for improving application performance, none studies how these optimizations impact hardware resource usage or the average GPU utilization. This paper takes a data-driven analysis approach in addressing this gap by (1) characterizing how hardware resource usage affects device utilization, execution time, or both, (2) presenting a multi-objective metric to identify important application-device interactions that can be optimized to improve device utilization and application performance jointly, (3) studying hardware resource usage behaviors of several optimizations for a benchmark application, and finally (4) identifying optimization opportunities for several scientific proxy applications based on their hardware resource usage behaviors. Furthermore, we demonstrate the applicability of our methodology by applying the identified optimizations to a proxy application, which improves the execution time, device utilization and power consumption by up to 29.6%, 5.3% and 26.5% respectively.",
        "subjects": [
            "cs.DC",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10148",
        "abstract url": "https://arxiv.org/abs/2408.10148",
        "title": "Auctioning Escape Permits for Multiple Correlated Pollutants Using CMRA",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the context of increasingly complex environmental challenges, effective pollution control mechanisms are crucial. By extending the state of the art auction mechanisms, we aim to develop an efficient approach for allocating pollution abatement resources in a multi-pollutant setting with pollutants affecting each other's reduction costs. We modify the Combinatorial Multi-Round Ascending Auction for the auction of escape permits of pollutants with co-dependent reduction processes, specifically, greenhouse gas emissions and nutrient runoff in Finnish agriculture. We show the significant advantages of this mechanism in pollution control through experiments on the bid prices and amount of escape permits sold in multiple auction simulations.",
        "subjects": [
            "cs.GT",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10167",
        "abstract url": "https://arxiv.org/abs/2408.10167",
        "title": "Don't Get Stuck: A Deadlock Recovery Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "When multiple agents share space, interactions can lead to deadlocks, where no agent can advance towards its goal. This paper addresses this challenge with a deadlock recovery strategy. In particular, the proposed algorithm integrates hybrid-A$^\\star$, STL, and MPPI frameworks. Specifically, hybrid-A$^\\star$ generates a reference path, STL defines a goal (deadlock avoidance) and associated constraints (w.r.t. traffic rules), and MPPI refines the path and speed accordingly. This STL-MPPI framework ensures system compliance to specifications and dynamics while ensuring the safety of the resulting maneuvers, indicating a strong potential for application to complex traffic scenarios (and rules) in practice. Validation studies are conducted in simulations and on scaled cars, respectively, to demonstrate the effectiveness of the proposed algorithm.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Presented at the 27th IEEE International Conference on Intelligent Transportation Systems (ITSC) 2024, Edmonton, Alberta, Canada"
    },
    {
        "paper id": "2408.10171",
        "abstract url": "https://arxiv.org/abs/2408.10171",
        "title": "LCDN: Providing Network Determinism with Low-Cost Switches",
        "rating": "-10",
        "keywords": [],
        "abstract": "The demands on networks are increasing on a fast pace. In particular, real-time applications have very strict network requirements. However, building a network capable of hosting real-time applications is a cost-intensive endeavor, especially for experimental systems such as testbeds. Systems that provide guaranteed real-time networking capabilities usually work with expensive software-defined switches. In contrast, real-time networking systems based on cheaper hardware face the limitation of lower link speeds. Therefore, this paper fills this gap and presents Low-Cost Deterministic Networking (LCDN), a system that is designed to work with cheap common off-the-shelf switches and devices. LCDN works at Gigabit speed and enables powerful testbeds that can host real-time applications with hard delay guarantees. This paper also provides the evaluation of the determinism of the used switch as well as a Raspberry Pi used as an end device.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10200",
        "abstract url": "https://arxiv.org/abs/2408.10200",
        "title": "SoK: Runtime Integrity",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper provides a systematic exploration of runtime integrity mechanisms, such as Control Flow Integrity (CFI) and Control Flow Attestation (CFA). It examines their differences and relationships while addressing crucial questions about the goals, assumptions, features, and design spaces. It includes examining a potential coexistence of CFI and CFA on the same platform. Through a comprehensive review of existing defenses, this paper positions CFI and CFA within the broader landscape of runtime defenses, critically evaluating their strengths, limitations, and trade-offs. The findings emphasize the importance of further research to bridge the gaps between CFI and CFA, advancing the field of runtime defenses.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10201",
        "abstract url": "https://arxiv.org/abs/2408.10201",
        "title": "LEAD: Towards Learning-Based Equity-Aware Decarbonization in Ridesharing Platforms",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ridesharing platforms such as Uber, Lyft, and DiDi have grown in popularity due to their on-demand availability, ease of use, and commute cost reductions, among other benefits. However, not all ridesharing promises have panned out. Recent studies demonstrate that the expected drop in traffic congestion and reduction in greenhouse gas (GHG) emissions have not materialized. This is primarily due to the substantial distances traveled by the ridesharing vehicles without passengers between rides, known as deadhead miles. Recent work has focused on reducing the impact of deadhead miles while considering additional metrics such as rider waiting time, GHG emissions from deadhead miles, or driver earnings. Unfortunately, prior studies consider these environmental and equity-based metrics individually despite them being interrelated. In this paper, we propose a Learning-based Equity-Aware Decarabonization approach, LEAD, for ridesharing platforms. LEAD targets minimizing emissions while ensuring that the driver's utility, defined as the difference between the trip distance and the deadhead miles, is fairly distributed. LEAD uses reinforcement learning to match riders to drivers based on the expected future utility of drivers and the expected carbon emissions of the platform without increasing the rider waiting times. Extensive experiments based on a real-world ride-sharing dataset show that LEAD improves fairness by 2$\\times$ when compared to emission-aware ride-assignment and reduces emissions by 70% while ensuring fairness within 66% of the fair baseline. It also reduces the rider wait time, by at least 40%, compared to various baselines. Additionally, LEAD corrects the imbalance in previous emission-aware ride assignment algorithms that overassigned rides to low-emission vehicles.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10327",
        "abstract url": "https://arxiv.org/abs/2408.10327",
        "title": "An Empirical Study on Package-Level Deprecation in Python Ecosystem",
        "rating": "-10",
        "keywords": [],
        "abstract": "Open-source software (OSS) plays a crucial role in modern software development. Utilizing OSS code can greatly accelerate software development, reduce redundancy, and enhance reliability. Python, a widely adopted programming language, is renowned for its extensive and diverse third-party package ecosystem. However, a significant number of OSS packages within the Python ecosystem are in poor maintenance, leading to potential risks in functionality and security. Consequently, it is essential to establish a deprecation mechanism to assist package developers and users in managing packages effectively. To facilitate the establishment of the package-level deprecation mechanism, this paper presents a mixed-method empirical study, including data analysis and surveys. We investigate the current practices of announcing, receiving, and handling package-level deprecation in the Python ecosystem. We also assess the benefits of having deprecation announcements for inactively maintained packages. Furthermore, we investigate the challenges faced by package developers and users and their expectations for future deprecation practices. Our findings reveal that 75.4% of inactive package developers have no intention of releasing deprecation declarations for various reasons, while 89.5% of users express a desire to be notified about the deprecation, highlighting a gap between developers and users; in many cases, no alternative solutions are available when deprecation occurs, emphasizing the need to explore practical approaches that enable seamless package handover and require less maintenance effort. Our work aims to enhance the understanding of existing package-level deprecation patterns within the Python OSS realm and facilitate the development of deprecation practices for the Python community in the future.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE'25)"
    },
    {
        "paper id": "2408.10333",
        "abstract url": "https://arxiv.org/abs/2408.10333",
        "title": "An LMI-based Robust Fuzzy Controller for Blood Glucose Regulation in Type 1 Diabetes",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a control algorithm for creating an artificial pancreas for type 1 diabetes, factoring in input saturation for a practical application. By utilizing the parallel distributed compensation and Takagi-Sugeno Fuzzy model, we design an optimal robust fuzzy controller. Stability conditions derived from the Lyapunov method are expressed as linear matrix inequalities, allowing for optimal controller gain selection that minimizes disturbance effects. We employ the minimal Bergman and Tolic models to represent type 1 diabetes glucose-insulin dynamics, converting them into corresponding Takagi-Sugeno fuzzy models using the sector nonlinearity approach. Simulation results demonstrate the proposed controller's effectiveness.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10378",
        "abstract url": "https://arxiv.org/abs/2408.10378",
        "title": "Finite-time input-to-state stability for infinite-dimensional systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we extend the notion of finite-time input-to-state stability (FTISS) for finite-dimensional systems to infinite-dimensional systems. More specifically, we first prove an FTISS Lyapunov theorem for a class of infinite-dimensional systems, namely, the existence of an FTISS Lyapunov functional (FTISS-LF) implies the FTISS of the system, and then, provide a sufficient condition for ensuring the existence of an FTISS-LF for a class of abstract infinite-dimensional systems under the framework of compact semigroup theory and Hilbert spaces. As an application of the FTISS Lyapunov theorem, we verify the FTISS for a class of parabolic PDEs involving sublinear terms and distributed in-domain disturbances. Since the nonlinear terms of the corresponding abstract system are not Lipschitz continuous, the well-posedness is proved based on the application of compact semigroup theory and the FTISS is assessed by using the Lyapunov method with the aid of an interpolation inequality. Numerical simulations are conducted to confirm the theoretical results.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10391",
        "abstract url": "https://arxiv.org/abs/2408.10391",
        "title": "Tax Credits and Household Behavior: The Roles of Myopic Decision-Making and Liquidity in a Simulated Economy",
        "rating": "-10",
        "keywords": [],
        "abstract": "There has been a growing interest in multi-agent simulators in the domain of economic modeling. However, contemporary research often involves developing reinforcement learning (RL) based models that focus solely on a single type of agents, such as households, firms, or the government. Such an approach overlooks the adaptation of interacting agents thereby failing to capture the complexity of real-world economic systems. In this work, we consider a multi-agent simulator comprised of RL agents of numerous types, including heterogeneous households, firm, central bank and government. In particular, we focus on the crucial role of the government in distributing tax credits to households. We conduct two broad categories of comprehensive experiments dealing with the impact of tax credits on 1) households with varied degrees of myopia (short-sightedness in spending and saving decisions), and 2) households with diverse liquidity profiles. The first category of experiments examines the impact of the frequency of tax credits (e.g. annual vs quarterly) on consumption patterns of myopic households. The second category of experiments focuses on the impact of varying tax credit distribution strategies on households with differing liquidities. We validate our simulation model by reproducing trends observed in real households upon receipt of unforeseen, uniform tax credits, as documented in a JPMorgan Chase report. Based on the results of the latter, we propose an innovative tax credit distribution strategy for the government to reduce inequality among households. We demonstrate the efficacy of this strategy in improving social welfare in our simulation results.",
        "subjects": [
            "cs.MA",
            "econ.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10405",
        "abstract url": "https://arxiv.org/abs/2408.10405",
        "title": "ROOT: Requirements Organization and Optimization Tool",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software engineering practices such as constructing requirements and establishing traceability help ensure systems are safe, reliable, and maintainable. However, they can be resource-intensive and are frequently underutilized. To alleviate the burden of these essential processes, we developed the Requirements Organization and Optimization Tool (ROOT). ROOT centralizes project information and offers project visualizations and AI-based tools designed to streamline engineering processes. With ROOT's assistance, engineers benefit from improved oversight and early error detection, leading to the successful development of software systems. Link to screen cast: https://youtu.be/3rtMYRnsu24",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10409",
        "abstract url": "https://arxiv.org/abs/2408.10409",
        "title": "Real-Time Digital Twin Platform: A Case Study on Core Network Selection in Aeronautical Ad-Hoc Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The development of Digital Twins (DTs) is hindered by a lack of specialized, open-source solutions that can meet the demands of dynamic applications. This has caused state-of-the-art DT applications to be validated using offline data. However, this approach falls short of integrating real-time data, which is one of the most important characteristics of DTs. This can limit the validating effectiveness of DT applications in cases such as aeronautical ad-hoc networks (AANETs). Considering this, we develop a Real-Time Digital Twin Platform and implement core network selection in AANETs as a case study. In this, we implement microservice-based architecture and design a robust data pipeline. Additionally, we develop an interactive user interface using open-source tools. Using this, the platform supports real-time decision-making in the presence of data retrieval failures.",
        "subjects": [
            "cs.NI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10429",
        "abstract url": "https://arxiv.org/abs/2408.10429",
        "title": "Price Competition Under A Consider-Then-Choose Model With Lexicographic Choice",
        "rating": "-10",
        "keywords": [],
        "abstract": "The sorting and filtering capabilities offered by modern e-commerce platforms significantly impact customers' purchase decisions, as well as the resulting prices set by competing sellers on these platforms. Motivated by this practical reality, we study price competition under a flexible choice model: Consider-then-Choose with Lexicographic Choice (CLC). In this model, a customer first forms a consideration set of sellers based on (i) her willingness-to-pay and (ii) an arbitrary set of criteria on items' non-price attributes; she then chooses the highest-ranked item according to a lexicographic ranking in which items with better performance on more important attributes are ranked higher. We provide a structural characterization of equilibria in the resulting game of price competition, and derive an economically interpretable condition, which we call gradient dominance, under which equilibria can be computed efficiently. For this subclass of CLC models, we prove that distributed gradient-based pricing dynamics converge to the set of equilibria. Extensive numerical experiments show robustness of our theoretical findings when gradient dominance does not hold.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10434",
        "abstract url": "https://arxiv.org/abs/2408.10434",
        "title": "Insights on Microservice Architecture Through the Eyes of Industry Practitioners",
        "rating": "-10",
        "keywords": [],
        "abstract": "The adoption of microservice architecture has seen a considerable upswing in recent years, mainly driven by the need to modernize legacy systems and address their limitations. Legacy systems, typically designed as monolithic applications, often struggle with maintenance, scalability, and deployment inefficiencies. This study investigates the motivations, activities, and challenges associated with migrating from monolithic legacy systems to microservices, aiming to shed light on common practices and challenges from a practitioner's point of view. We conducted a comprehensive study with 53 software practitioners who use microservices, expanding upon previous research by incorporating diverse international perspectives. Our mixed-methods approach includes quantitative and qualitative analyses, focusing on four main aspects: (i) the driving forces behind migration, (ii) the activities to conduct the migration, (iii) strategies for managing data consistency, and (iv) the prevalent challenges. Thus, our results reveal diverse practices and challenges practitioners face when migrating to microservices. Companies are interested in technical benefits, enhancing maintenance, scalability, and deployment processes. Testing in microservice environments remains complex, and extensive monitoring is crucial to managing the dynamic nature of microservices. Database management remains challenging. While most participants prefer decentralized databases for autonomy and scalability, challenges persist in ensuring data consistency. Additionally, many companies leverage modern cloud technologies to mitigate network overhead, showcasing the importance of cloud infrastructure in facilitating efficient microservice communication.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10435",
        "abstract url": "https://arxiv.org/abs/2408.10435",
        "title": "Enhanced document retrieval with topic embeddings",
        "rating": "-10",
        "keywords": [],
        "abstract": "Document retrieval systems have experienced a revitalized interest with the advent of retrieval-augmented generation (RAG). RAG architecture offers a lower hallucination rate than LLM-only applications. However, the accuracy of the retrieval mechanism is known to be a bottleneck in the efficiency of these applications. A particular case of subpar retrieval performance is observed in situations where multiple documents from several different but related topics are in the corpus. We have devised a new vectorization method that takes into account the topic information of the document. The paper introduces this new method for text vectorization and evaluates it in the context of RAG. Furthermore, we discuss the challenge of evaluating RAG systems, which pertains to the case at hand.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted to AICT 2024"
    },
    {
        "paper id": "2408.10438",
        "abstract url": "https://arxiv.org/abs/2408.10438",
        "title": "Private Means and the Curious Incident of the Free Lunch",
        "rating": "-10",
        "keywords": [],
        "abstract": "We show that the most well-known and fundamental building blocks of DP implementations -- sum, mean, count (and many other linear queries) -- can be released with substantially reduced noise for the same privacy guarantee. We achieve this by projecting individual data with worst-case sensitivity $R$ onto a simplex where all data now has a constant norm $R$. In this simplex, additional ``free'' queries can be run that are already covered by the privacy-loss of the original budgeted query, and which algebraically give additional estimates of counts or sums, and can be combined for lower final noise.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "TPDP24"
    },
    {
        "paper id": "2408.10439",
        "abstract url": "https://arxiv.org/abs/2408.10439",
        "title": "Visual Storytelling: A Methodological Approach to Designing and Implementing a Visualisation Poster",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a design study of developing a visualisation poster. Posters can be difficult to create, and the story on a poster is not always clear. Using a case-study approach we propose three important aspects: the poster should have a clear focus (especially a hero visualisation), envisioning its use helps to drive the important aspects, and third the essence (its fundamental concept and guiding idea) must be clear. We will use case studies that have focused on the use of the Five Design-Sheet method (FdS) as a way to sketch and plan a visualisation, before successfully implementing and creating the visual poster. The case studies serve as a practical illustration of the workflow, offering a means to explain the three key processes involved: (1) comprehending the data, (2) employing a design study with the FdS (Five Design-Sheet), (3) crafting, evaluating and refining the visualisation.",
        "subjects": [
            "cs.HC",
            "cs.GR"
        ],
        "comment": "5 pages, 1 figure, accepted for publication to the EG UK Computer Graphics & Visual Computing (CGVC) 2024"
    },
    {
        "paper id": "2408.10454",
        "abstract url": "https://arxiv.org/abs/2408.10454",
        "title": "Likelihood Scouting Via Map Inversion For A Posterior-Sampled Particle Filter",
        "rating": "-10",
        "keywords": [],
        "abstract": "An exploit of the Sequential Importance Sampling (SIS) algorithm using Differential Algebra (DA) techniques is derived to develop an efficient particle filter. The filter creates an original kind of particles, called scout particles, that bring information from the measurement noise onto the state prior probability density function. Thanks to the creation of high-order polynomial maps and their inversions, the scouting of the measurements helps the SIS algorithm identify the region of the prior more affected by the likelihood distribution. The result of the technique is two different versions of the proposed Scout Particle Filter (SPF), which identifies and delimits the region where the true posterior probability has high density in the SIS algorithm. Four different numerical applications show the benefits of the methodology both in terms of accuracy and efficiency, where the SPF is compared to other particle filters, with a particular focus on target tracking and orbit determination problems.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "17 Pages, 12 Figures"
    },
    {
        "paper id": "2408.10461",
        "abstract url": "https://arxiv.org/abs/2408.10461",
        "title": "Low Profile Metamaterial Band-Pass Filter Loaded with 4-Turn Complementary Spiral Resonator for WPT Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a very compact and low insertion loss metamaterial band-pass filter (MBPF) at the center frequency of f0=730 MHz is proposed, based on the rectangular-shape 4 turn complementary spiral resonators (4 CSR). The proposed MBPF consists of an interdigital capacitor as a series capacitance in the top layer, leading to improve the stopband performance in the pass band range of 700 to 760 MHz, which makes it suitable for wireless power transfer (WPT) systems by rejecting unwanted signals. In order to validate the performance of the proposed technique, the MBPF is fabricated on the RO-4003 substrate and great agreement is achieved between simulated and measured results. The stop band attenuations of greater than 52 dB and 20 dB are obtained around the 0.8xfcl (lower cutoff frequency) and 1.2xfcu (upper cutoff frequency), respectively.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10486",
        "abstract url": "https://arxiv.org/abs/2408.10486",
        "title": "Revisiting Evolutionary Program Repair via Code Language Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software defects are an inherent part of software development and maintenance. To address these defects, Automated Program Repair (APR) has been developed to fix bugs automatically. With the advent of Large Language Models, Code Language Models (CLMs) trained on code corpora excels in code generation, making them suitable for APR applications. Despite this progress, a significant limitation remains: many bugs necessitate multi-point edits for repair, yet current CLM-based APRs are restricted to single-point bug fixes, which severely narrows the scope of repairable bugs. Moreover, these tools typically only consider the direct context of the buggy line when building prompts for the CLM, leading to suboptimal repair outcomes due to the limited information provided. This paper introduces a novel approach, ARJA-CLM, which integrates the multiobjective evolutionary algorithm with CLM to fix multilocation bugs in Java projects. We also propose a context-aware prompt construction stratege, which enriches the prompt with additional information about accessible fields and methods for the CLM generating candidate statements. Our experiments on the Defects4J and APR-2024 competition benchmark demonstrate that ARJA-CLM surpasses many state-of-the-art repair systems, and performs well on multi-point bugs. The results also reveal that CLMs effectively utilize the provided field and method information within context-aware prompts to produce candidate statements.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10519",
        "abstract url": "https://arxiv.org/abs/2408.10519",
        "title": "Almost Optimal Algorithms for Token Collision in Anonymous Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "In distributed systems, situations often arise where some nodes each holds a collection of tokens, and all nodes collectively need to determine whether all tokens are distinct. For example, if each token represents a logged-in user, the problem corresponds to checking whether there are duplicate logins. Similarly, if each token represents a data object or a timestamp, the problem corresponds to checking whether there are conflicting operations in distributed databases. In distributed computing theory, unique identifiers generation is also related to this problem: each node generates one token, which is its identifier, then a verification phase is needed to ensure all identifiers are unique. In this paper, we formalize and initiate the study of token collision. In this problem, a collection of $k$ tokens, each represented by some length-$L$ bit string, are distributed to $n$ nodes of an anonymous CONGEST network in an arbitrary manner. The nodes need to determine whether there are tokens with an identical value. We present near optimal deterministic algorithms for the token collision problem with $\\tilde{O}(D+k\\cdot L/\\log{n})$ round complexity, where $D$ denotes the network diameter. Besides high efficiency, the prior knowledge required by our algorithms is also limited. For completeness, we further present a near optimal randomized algorithm for token collision.",
        "subjects": [
            "cs.DC",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.10522",
        "abstract url": "https://arxiv.org/abs/2408.10522",
        "title": "On the Security of Directional Modulation via Time Modulated Arrays Using OFDM Waveforms",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate how secure the TMA OFDM system is, by looking at the transmitted signal from an the viewpoint of eavesdropper. First, we propose a novel, low-complexity scheme via which the eavesdropper could defy the scrambling in the received signal and recover the transmitted symbols. We show that the symbols which the eavesdropper sees along the OFDM subcarriers are linear mixtures of the source symbols, where the mixing coefficients are unknown to the eavesdropper. Independent component analysis (ICA) could be used to obtain the mixing matrix but there would be permutation and scaling ambiguities. We show that these ambiguities can be resolved by leveraging the structure of the mixing matrix and the characteristics of the TMA OFDM system. In particular, we construct a k-nearest neighbors (KNN)-based algorithm that exploits jointly the Toeplitz structure of the mixing matrix, knowledge of data constellation, and the rules for designing the TMA ON-OFF pattern to resolve the ambiguities. In general, resolving the ambiguities and recovering the symbols requires long data. Specifically for the case of the constant modulus symbols, we propose a modified ICA approach, namely the constant-modulus ICA (CMICA), that provides a good estimate of the mixing matrix using a small number of received samples. We also propose measures which the TMA could undertake in order to defend the scrambling. Simulation results are presented to demonstrate the effectiveness, efficiency and robustness of our scrambling defying and defending schemes. Complete abstract please see in the paper.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to IEEE TWC for peer reviewing"
    },
    {
        "paper id": "2408.10525",
        "abstract url": "https://arxiv.org/abs/2408.10525",
        "title": "MPGNet: Learning Move-Push-Grasping Synergy for Target-Oriented Grasping in Occluded Scenes",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper focuses on target-oriented grasping in occluded scenes, where the target object is specified by a binary mask and the goal is to grasp the target object with as few robotic manipulations as possible. Most existing methods rely on a push-grasping synergy to complete this task. To deliver a more powerful target-oriented grasping pipeline, we present MPGNet, a three-branch network for learning a synergy between moving, pushing, and grasping actions. We also propose a multi-stage training strategy to train the MPGNet which contains three policy networks corresponding to the three actions. The effectiveness of our method is demonstrated via both simulated and real-world experiments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IROS 2024"
    },
    {
        "paper id": "2408.11080",
        "abstract url": "https://arxiv.org/abs/2408.11080",
        "title": "ARAP: Demystifying Anti Runtime Analysis Code in Android Apps",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the continuous growth in the usage of Android apps, ensuring their security has become critically important. An increasing number of malicious apps adopt anti-analysis techniques to evade security measures. Although some research has started to consider anti-runtime analysis (ARA), it is unfortunate that they have not systematically examined ARA techniques. Furthermore, the rapid evolution of ARA technology exacerbates the issue, leading to increasingly inaccurate analysis results. To effectively analyze Android apps, understanding their adopted ARA techniques is necessary. However, no systematic investigation has been conducted thus far. In this paper, we conduct the first systematic study of the ARA implementations in a wide range of 117,171 Android apps (including both malicious and benign ones) collected between 2016 and 2023. Additionally, we propose a specific investigation tool named ARAP to assist this study by leveraging both static and dynamic analysis. According to the evaluation results, ARAP not only effectively identifies the ARA implementations in Android apps but also reveals many important findings. For instance, almost all apps have implemented at least one category of ARA technology (99.6% for benign apps and 97.0% for malicious apps).",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": null
    }
]