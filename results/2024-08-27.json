[
    {
        "paper id": "2408.15305",
        "abstract url": "https://arxiv.org/abs/2408.15305",
        "title": "Parameter-Efficient Quantized Mixture-of-Experts Meets Vision-Language Instruction Tuning for Semiconductor Electron Micrograph Analysis",
        "rating": "3.5",
        "keywords": [
            [
                "Parameter-Efficient"
            ],
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Semiconductors, crucial to modern electronics, are generally under-researched in foundational models. It highlights the need for research to enhance the semiconductor device technology portfolio and aid in high-end device fabrication. In this paper, we introduce sLAVA, a small-scale vision-language assistant tailored for semiconductor manufacturing, with a focus on electron microscopy image analysis. It addresses challenges of data scarcity and acquiring high-quality, expert-annotated data. We employ a teacher-student paradigm, using a foundational vision language model like GPT-4 as a teacher to create instruction-following multimodal data for customizing the student model, sLAVA, for electron microscopic image analysis tasks on consumer hardware with limited budgets. Our approach allows enterprises to further fine-tune the proposed framework with their proprietary data securely within their own infrastructure, protecting intellectual property. Rigorous experiments validate that our framework surpasses traditional methods, handles data shifts, and enables high-throughput screening.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Paper published at ICML 2024 Workshop on Foundation Models in the Wild"
    },
    {
        "paper id": "2408.14868",
        "abstract url": "https://arxiv.org/abs/2408.14868",
        "title": "ZeroMamba: Exploring Visual State Space Model for Zero-Shot Learning",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Zero-shot learning (ZSL) aims to recognize unseen classes by transferring semantic knowledge from seen classes to unseen ones, guided by semantic information. To this end, existing works have demonstrated remarkable performance by utilizing global visual features from Convolutional Neural Networks (CNNs) or Vision Transformers (ViTs) for visual-semantic interactions. Due to the limited receptive fields of CNNs and the quadratic complexity of ViTs, however, these visual backbones achieve suboptimal visual-semantic interactions. In this paper, motivated by the visual state space model (i.e., Vision Mamba), which is capable of capturing long-range dependencies and modeling complex visual dynamics, we propose a parameter-efficient ZSL framework called ZeroMamba to advance ZSL. Our ZeroMamba comprises three key components: Semantic-aware Local Projection (SLP), Global Representation Learning (GRL), and Semantic Fusion (SeF). Specifically, SLP integrates semantic embeddings to map visual features to local semantic-related representations, while GRL encourages the model to learn global semantic representations. SeF combines these two semantic representations to enhance the discriminability of semantic features. We incorporate these designs into Vision Mamba, forming an end-to-end ZSL framework. As a result, the learned semantic representations are better suited for classification. Through extensive experiments on four prominent ZSL benchmarks, ZeroMamba demonstrates superior performance, significantly outperforming the state-of-the-art (i.e., CNN-based and ViT-based) methods under both conventional ZSL (CZSL) and generalized ZSL (GZSL) settings. Code is available at: https://anonymous.4open.science/r/ZeroMamba.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14961",
        "abstract url": "https://arxiv.org/abs/2408.14961",
        "title": "CVPT: Cross-Attention help Visual Prompt Tuning adapt visual task",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the rapid expansion of model sizes has led to large-scale pre-trained models demonstrating remarkable capabilities. Consequently, there has been a trend towards increasing the scale of models. However, this trend introduces significant challenges, including substantial computational costs of training and transfer to downstream tasks. To address these issues, Parameter-Efficient Fine-Tuning (PEFT) methods have been introduced. These methods optimize large-scale pre-trained models for specific tasks by fine-tuning a select group of parameters. Among these PEFT methods, adapter-based and prompt-based methods are the primary techniques. Specifically, in the field of visual fine-tuning, adapters gain prominence over prompts because of the latter's relatively weaker performance and efficiency. Under the circumstances, we refine the widely-used Visual Prompt Tuning (VPT) method, proposing Cross Visual Prompt Tuning (CVPT). CVPT calculates cross-attention between the prompt tokens and the embedded tokens, which allows us to compute the semantic relationship between them and conduct the fine-tuning of models exactly to adapt visual tasks better. Furthermore, we introduce the weight-sharing mechanism to initialize the parameters of cross-attention, which avoids massive learnable parameters from cross-attention and enhances the representative capability of cross-attention. We conduct comprehensive testing across 25 datasets and the result indicates that CVPT significantly improves VPT's performance and efficiency in visual tasks. For example, on the VTAB-1K benchmark, CVPT outperforms VPT over 4% in average accuracy, rivaling the advanced adapter-based methods in performance and efficiency. Our experiments confirm that prompt-based methods can achieve exceptional results in visual fine-tuning.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15518",
        "abstract url": "https://arxiv.org/abs/2408.15518",
        "title": "Dolphin: Long Context as a New Modality for Energy-Efficient On-Device Language Models",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents Dolphin, a novel decoder-decoder architecture for energy-efficient processing of long contexts in language models. Our approach addresses the significant energy consumption and latency challenges inherent in on-device models. Dolphin employs a compact 0.5B parameter decoder to distill extensive contextual information into a memory embedding, substantially reducing the input length for the primary 7B parameter decoder model. Inspired by vision-language models, we repurpose the image embedding projector to encode long textual contexts, effectively treating extended context as a distinct modality. This innovative method enables processing of substantially longer contexts without the typical computational overhead associated with extended input sequences. Empirical evaluations demonstrate a 10-fold improvement in energy efficiency and a 5-fold reduction in latency compared to conventional full-length context processing methods without losing quality of the response. Our work contributes to the development of more sustainable and scalable language models for on-device applications, addressing the critical need for energy-efficient and responsive AI technologies in resource-constrained environments while maintaining the accuracy to understand long contexts. This research has implications for the broader field of natural language processing, particularly in the domain of efficient model design for resource-limited settings. By enabling more sophisticated AI capabilities on edge devices, Dolphin paves the way for advanced language processing in a wide range of applications where computational resources are at a premium. The Dolphin model is publicly available at https://huggingface.co/NexaAIDev/Dolphin.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15521",
        "abstract url": "https://arxiv.org/abs/2408.15521",
        "title": "A Simple Baseline with Single-encoder for Referring Image Segmentation",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Referring image segmentation (RIS) requires dense vision-language interactions between visual pixels and textual words to segment objects based on a given description. However, commonly adapted dual-encoders in RIS, e.g., Swin transformer and BERT (uni-modal encoders) or CLIP (a multi-modal dual-encoder), lack dense multi-modal interactions during pre-training, leading to a gap with a pixel-level RIS task. To bridge this gap, existing RIS methods often rely on multi-modal fusion modules that interact two encoders, but this approach leads to high computational costs. In this paper, we present a novel RIS method with a single-encoder, i.e., BEiT-3, maximizing the potential of shared self-attention across all framework components. This enables seamless interactions of two modalities from input to final prediction, producing granularly aligned multi-modal features. Furthermore, we propose lightweight yet effective decoder modules, a Shared FPN and a Shared Mask Decoder, which contribute to the high efficiency of our model. Our simple baseline with a single encoder achieves outstanding performances on the RIS benchmark datasets while maintaining computational efficiency, compared to the most recent SoTA methods based on dual-encoders.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "ArXiv pre-print"
    },
    {
        "paper id": "2408.14802",
        "abstract url": "https://arxiv.org/abs/2408.14802",
        "title": "RAW-Adapter: Adapting Pre-trained Visual Model to Camera RAW Images",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "sRGB images are now the predominant choice for pre-training visual models in computer vision research, owing to their ease of acquisition and efficient storage. Meanwhile, the advantage of RAW images lies in their rich physical information under variable real-world challenging lighting conditions. For computer vision tasks directly based on camera RAW data, most existing studies adopt methods of integrating image signal processor (ISP) with backend networks, yet often overlook the interaction capabilities between the ISP stages and subsequent networks. Drawing inspiration from ongoing adapter research in NLP and CV areas, we introduce RAW-Adapter, a novel approach aimed at adapting sRGB pre-trained models to camera RAW data. RAW-Adapter comprises input-level adapters that employ learnable ISP stages to adjust RAW inputs, as well as model-level adapters to build connections between ISP stages and subsequent high-level networks. Additionally, RAW-Adapter is a general framework that could be used in various computer vision frameworks. Abundant experiments under different lighting conditions have shown our algorithm's state-of-the-art (SOTA) performance, demonstrating its effectiveness and efficiency across a range of real-world and synthetic datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024, code link: https://github.com/cuiziteng/ECCV_RAW_Adapter"
    },
    {
        "paper id": "2408.14805",
        "abstract url": "https://arxiv.org/abs/2408.14805",
        "title": "Platypus: A Generalized Specialist Model for Reading Text in Various Forms",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Reading text from images (either natural scenes or documents) has been a long-standing research topic for decades, due to the high technical challenge and wide application range. Previously, individual specialist models are developed to tackle the sub-tasks of text reading (e.g., scene text recognition, handwritten text recognition and mathematical expression recognition). However, such specialist models usually cannot effectively generalize across different sub-tasks. Recently, generalist models (such as GPT-4V), trained on tremendous data in a unified way, have shown enormous potential in reading text in various scenarios, but with the drawbacks of limited accuracy and low efficiency. In this work, we propose Platypus, a generalized specialist model for text reading. Specifically, Platypus combines the best of both worlds: being able to recognize text of various forms with a single unified architecture, while achieving excellent accuracy and high efficiency. To better exploit the advantage of Platypus, we also construct a text reading dataset (called Worms), the images of which are curated from previous datasets and partially re-labeled. Experiments on standard benchmarks demonstrate the effectiveness and superiority of the proposed Platypus model. Model and data will be made publicly available at https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/Platypus.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV2024"
    },
    {
        "paper id": "2408.14892",
        "abstract url": "https://arxiv.org/abs/2408.14892",
        "title": "A Functional Trade-off between Prosodic and Semantic Cues in Conveying Sarcasm",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "This study investigates the acoustic features of sarcasm and disentangles the interplay between the propensity of an utterance being used sarcastically and the presence of prosodic cues signaling sarcasm. Using a dataset of sarcastic utterances compiled from television shows, we analyze the prosodic features within utterances and key phrases belonging to three distinct sarcasm categories (embedded, propositional, and illocutionary), which vary in the degree of semantic cues present, and compare them to neutral expressions. Results show that in phrases where the sarcastic meaning is salient from the semantics, the prosodic cues are less relevant than when the sarcastic meaning is not evident from the semantics, suggesting a trade-off between prosodic and semantic cues of sarcasm at the phrase level. These findings highlight a lessened reliance on prosodic modulation in semantically dense sarcastic expressions and a nuanced interaction that shapes the communication of sarcastic intent.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "accepted at Interspeech 2024"
    },
    {
        "paper id": "2408.15201",
        "abstract url": "https://arxiv.org/abs/2408.15201",
        "title": "An Investigation on The Position Encoding in Vision-Based Dynamics Prediction",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Despite the success of vision-based dynamics prediction models, which predict object states by utilizing RGB images and simple object descriptions, they were challenged by environment misalignments. Although the literature has demonstrated that unifying visual domains with both environment context and object abstract, such as semantic segmentation and bounding boxes, can effectively mitigate the visual domain misalignment challenge, discussions were focused on the abstract of environment context, and the insight of using bounding box as the object abstract is under-explored. Furthermore, we notice that, as empirical results shown in the literature, even when the visual appearance of objects is removed, object bounding boxes alone, instead of being directly fed into the network, can indirectly provide sufficient position information via the Region of Interest Pooling operation for dynamics prediction. However, previous literature overlooked discussions regarding how such position information is implicitly encoded in the dynamics prediction model. Thus, in this paper, we provide detailed studies to investigate the process and necessary conditions for encoding position information via using the bounding box as the object abstract into output features. Furthermore, we study the limitation of solely using object abstracts, such that the dynamics prediction performance will be jeopardized when the environment context varies.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 4 tables, and 3 figures. Accepted to ECCV2024 eXCV workshop"
    },
    {
        "paper id": "2408.15296",
        "abstract url": "https://arxiv.org/abs/2408.15296",
        "title": "Feature Representations for Automatic Meerkat Vocalization Classification",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Understanding evolution of vocal communication in social animals is an important research problem. In that context, beyond humans, there is an interest in analyzing vocalizations of other social animals such as, meerkats, marmosets, apes. While existing approaches address vocalizations of certain species, a reliable method tailored for meerkat calls is lacking. To that extent, this paper investigates feature representations for automatic meerkat vocalization analysis. Both traditional signal processing-based representations and data-driven representations facilitated by advances in deep learning are explored. Call type classification studies conducted on two data sets reveal that feature extraction methods developed for human speech processing can be effectively employed for automatic meerkat call analysis.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "Accepted at Interspeech 2024 satellite event (VIHAR 2024)"
    },
    {
        "paper id": "2408.15297",
        "abstract url": "https://arxiv.org/abs/2408.15297",
        "title": "YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Dysfluent speech detection is the bottleneck for disordered speech analysis and spoken language learning. Current state-of-the-art models are governed by rule-based systems which lack efficiency and robustness, and are sensitive to template design. In this paper, we propose YOLO-Stutter: a first end-to-end method that detects dysfluencies in a time-accurate manner. YOLO-Stutter takes imperfect speech-text alignment as input, followed by a spatial feature aggregator, and a temporal dependency extractor to perform region-wise boundary and class predictions. We also introduce two dysfluency corpus, VCTK-Stutter and VCTK-TTS, that simulate natural spoken dysfluencies including repetition, block, missing, replacement, and prolongation. Our end-to-end method achieves state-of-the-art performance with a minimum number of trainable parameters for on both simulated data and real aphasia speech. Code and datasets are open-sourced at https://github.com/rorizzz/YOLO-Stutter",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Interspeech 2024"
    },
    {
        "paper id": "2408.15300",
        "abstract url": "https://arxiv.org/abs/2408.15300",
        "title": "GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs",
        "rating": "1.5",
        "keywords": [
            [
                "Parameter Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have gained popularity and democratized the usage of Large Language Models (LLMs). Recent studies have shown that a small subset of weights significantly impacts performance. Based on this observation, we introduce a novel PEFT method, called Gaussian noise Injected Fine Tuning of Salient Weights (GIFT-SW). Our method updates only salient columns, while injecting Gaussian noise into non-salient ones. To identify these columns, we developeda generalized sensitivity metric that extends and unifies metrics from previous studies. Experiments with LLaMA models demonstrate that GIFT-SW outperforms full fine-tuning and modern PEFT methods under the same computational budget. Moreover, GIFT-SW offers practical advantages to recover performance of models subjected to mixed-precision quantization with keeping salient weights in full precision.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14777",
        "abstract url": "https://arxiv.org/abs/2408.14777",
        "title": "Quartered Chirp Spectral Envelope for Whispered vs Normal Speech Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "eess.AS"
            ]
        ],
        "abstract": "Whispered speech as an acceptable form of human-computer interaction is gaining traction. Systems that address multiple modes of speech require a robust front-end speech classifier. Performance of whispered vs normal speech classification drops in the presence of additive white Gaussian noise, since normal speech takes on some of the characteristics of whispered speech. In this work, we propose a new feature named the quartered chirp spectral envelope, a combination of the chirp spectrum and the quartered spectral envelope, to classify whispered and normal speech. The chirp spectrum can be fine-tuned to obtain customized features for a given task, and the quartered spectral envelope has been proven to work especially well for the current task. The feature is trained on a one dimensional convolutional neural network, that captures the trends in the spectral envelope. The proposed system performs better than the state of the art, in the presence of white noise.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "eess.SP"
        ],
        "comment": "submitted to TENCON 2024"
    },
    {
        "paper id": "2408.14812",
        "abstract url": "https://arxiv.org/abs/2408.14812",
        "title": "HPT++: Hierarchically Prompting Vision-Language Models with Multi-Granularity Knowledge Generation and Improved Structure Modeling",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Prompt learning has become a prevalent strategy for adapting vision-language foundation models (VLMs) such as CLIP to downstream tasks. With the emergence of large language models (LLMs), recent studies have explored the potential of using category-related descriptions to enhance prompt effectiveness. However, conventional descriptions lack explicit structured information necessary to represent the interconnections among key elements like entities or attributes with relation to a particular category. Since existing prompt tuning methods give little consideration to managing structured knowledge, this paper advocates leveraging LLMs to construct a graph for each description to prioritize such structured knowledge. Consequently, we propose a novel approach called Hierarchical Prompt Tuning (HPT), enabling simultaneous modeling of both structured and conventional linguistic knowledge. Specifically, we introduce a relationship-guided attention module to capture pair-wise associations among entities and attributes for low-level prompt learning. In addition, by incorporating high-level and global-level prompts modeling overall semantics, the proposed hierarchical structure forges cross-level interlinks and empowers the model to handle more complex and long-term relationships. Finally, by enhancing multi-granularity knowledge generation, redesigning the relationship-driven attention re-weighting module, and incorporating consistent constraints on the hierarchical text encoder, we propose HPT++, which further improves the performance of HPT. Our experiments are conducted across a wide range of evaluation settings, including base-to-new generalization, cross-dataset evaluation, and domain generalization. Extensive results and ablation studies demonstrate the effectiveness of our methods, which consistently outperform existing SOTA methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "19 pages, 7 figures, 7 tables. arXiv admin note: substantial text overlap with arXiv:2312.06323"
    },
    {
        "paper id": "2408.14830",
        "abstract url": "https://arxiv.org/abs/2408.14830",
        "title": "PolicyLR: A Logic Representation For Privacy Policies",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Privacy policies are crucial in the online ecosystem, defining how services handle user data and adhere to regulations such as GDPR and CCPA. However, their complexity and frequent updates often make them difficult for stakeholders to understand and analyze. Current automated analysis methods, which utilize natural language processing, have limitations. They typically focus on individual tasks and fail to capture the full context of the policies. We propose PolicyLR, a new paradigm that offers a comprehensive machine-readable representation of privacy policies, serving as an all-in-one solution for multiple downstream tasks. PolicyLR converts privacy policies into a machine-readable format using valuations of atomic formulae, allowing for formal definitions of tasks like compliance and consistency. We have developed a compiler that transforms unstructured policy text into this format using off-the-shelf Large Language Models (LLMs). This compiler breaks down the transformation task into a two-stage translation and entailment procedure. This procedure considers the full context of the privacy policy to infer a complex formula, where each formula consists of simpler atomic formulae. The advantage of this model is that PolicyLR is interpretable by design and grounded in segments of the privacy policy. We evaluated the compiler using ToS;DR, a community-annotated privacy policy entailment dataset. Utilizing open-source LLMs, our compiler achieves precision and recall values of 0.91 and 0.88, respectively. Finally, we demonstrate the utility of PolicyLR in three privacy tasks: Policy Compliance, Inconsistency Detection, and Privacy Comparison Shopping.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14836",
        "abstract url": "https://arxiv.org/abs/2408.14836",
        "title": "Similarity Metrics For Late Reverberation",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Automatic tuning of reverberation algorithms relies on the optimization of a cost function. While general audio similarity metrics are useful, they are not optimized for the specific statistical properties of reverberation in rooms. This paper presents two novel metrics for assessing the similarity of late reverberation in room impulse responses. These metrics are differentiable and can be utilized within a machine-learning framework. We compare the performance of these metrics to two popular audio metrics using a large dataset of room impulse responses encompassing various room configurations and microphone positions. The results indicate that the proposed functions based on averaged power and frequency-band energy decay outperform the baselines with the former exhibiting the most suitable profile towards the minimum. The proposed work holds promise as an improvement to the design and evaluation of reverberation similarity metrics.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14845",
        "abstract url": "https://arxiv.org/abs/2408.14845",
        "title": "AAVENUE: Detecting LLM Biases on NLU Tasks in AAVE via a Novel Benchmark",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Detecting biases in natural language understanding (NLU) for African American Vernacular English (AAVE) is crucial to developing inclusive natural language processing (NLP) systems. To address dialect-induced performance discrepancies, we introduce AAVENUE ({AAVE} {N}atural Language {U}nderstanding {E}valuation), a benchmark for evaluating large language model (LLM) performance on NLU tasks in AAVE and Standard American English (SAE). AAVENUE builds upon and extends existing benchmarks like VALUE, replacing deterministic syntactic and morphological transformations with a more flexible methodology leveraging LLM-based translation with few-shot prompting, improving performance across our evaluation metrics when translating key tasks from the GLUE and SuperGLUE benchmarks. We compare AAVENUE and VALUE translations using five popular LLMs and a comprehensive set of metrics including fluency, BARTScore, quality, coherence, and understandability. Additionally, we recruit fluent AAVE speakers to validate our translations for authenticity. Our evaluations reveal that LLMs consistently perform better on SAE tasks than AAVE-translated versions, underscoring inherent biases and highlighting the need for more inclusive NLP models. We have open-sourced our source code on GitHub and created a website to showcase our work at https://aavenue.live.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14849",
        "abstract url": "https://arxiv.org/abs/2408.14849",
        "title": "Project SHADOW: Symbolic Higher-order Associative Deductive reasoning On Wikidata using LM probing",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce SHADOW, a fine-tuned language model trained on an intermediate task using associative deductive reasoning, and measure its performance on a knowledge base construction task using Wikidata triple completion. We evaluate SHADOW on the LM-KBC 2024 challenge and show that it outperforms the baseline solution by 20% with a F1 score of 68.72%.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "6 pages, 1 figure"
    },
    {
        "paper id": "2408.14862",
        "abstract url": "https://arxiv.org/abs/2408.14862",
        "title": "Leveraging Self-supervised Audio Representations for Data-Efficient Acoustic Scene Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Acoustic scene classification (ASC) predominantly relies on supervised approaches. However, acquiring labeled data for training ASC models is often costly and time-consuming. Recently, self-supervised learning (SSL) has emerged as a powerful method for extracting features from unlabeled audio data, benefiting many downstream audio tasks. This paper proposes a data-efficient and low-complexity ASC system by leveraging self-supervised audio representations extracted from general-purpose audio datasets. We introduce BEATs, an audio SSL pre-trained model, to extract the general representations from AudioSet. Through extensive experiments, it has been demonstrated that the self-supervised audio representations can help to achieve high ASC accuracy with limited labeled fine-tuning data. Furthermore, we find that ensembling the SSL models fine-tuned with different strategies contributes to a further performance improvement. To meet low-complexity requirements, we use knowledge distillation to transfer the self-supervised knowledge from large teacher models to an efficient student model. The experimental results suggest that the self-supervised teachers effectively improve the classification accuracy of the student model. Our best-performing system obtains an average accuracy of 56.7%.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by DCASE Workshop 2024"
    },
    {
        "paper id": "2408.14866",
        "abstract url": "https://arxiv.org/abs/2408.14866",
        "title": "Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy Coordinate Gradient (GCG). However, GCG struggles with computational inefficiency, limiting further investigations regarding suffix transferability and scalability across models and data. In this work, we bridge the connection between search efficiency and suffix transferability. We propose a two-stage transfer learning framework, DeGCG, which decouples the search process into behavior-agnostic pre-searching and behavior-relevant post-searching. Specifically, we employ direct first target token optimization in pre-searching to facilitate the search process. We apply our approach to cross-model, cross-data, and self-transfer scenarios. Furthermore, we introduce an interleaved variant of our approach, i-DeGCG, which iteratively leverages self-transferability to accelerate the search process. Experiments on HarmBench demonstrate the efficiency of our approach across various models and domains. Notably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of $43.9$ ($+22.2$) and $39.0$ ($+19.5$) on valid and test sets, respectively. Further analysis on cross-model transfer indicates the pivotal role of first target token optimization in leveraging suffix transferability for efficient searching.",
        "subjects": [
            "cs.CL",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2408.14874",
        "abstract url": "https://arxiv.org/abs/2408.14874",
        "title": "Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has proven effective in aligning large language models with human intentions, yet it often relies on complex methodologies like Proximal Policy Optimization (PPO) that require extensive hyper-parameter tuning and present challenges in sample efficiency and stability. In this paper, we introduce Inverse-Q*, an innovative framework that transcends traditional RL methods by optimizing token-level reinforcement learning without the need for additional reward or value models. Inverse-Q* leverages direct preference optimization techniques but extends them by estimating the conditionally optimal policy directly from the model's responses, facilitating more granular and flexible policy shaping. Our approach reduces reliance on human annotation and external supervision, making it especially suitable for low-resource settings. We present extensive experimental results demonstrating that Inverse-Q* not only matches but potentially exceeds the effectiveness of PPO in terms of convergence speed and the alignment of model responses with human preferences. Our findings suggest that Inverse-Q* offers a practical and robust alternative to conventional RLHF approaches, paving the way for more efficient and adaptable model training approaches.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14886",
        "abstract url": "https://arxiv.org/abs/2408.14886",
        "title": "The VoxCeleb Speaker Recognition Challenge: A Retrospective",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The VoxCeleb Speaker Recognition Challenges (VoxSRC) were a series of challenges and workshops that ran annually from 2019 to 2023. The challenges primarily evaluated the tasks of speaker recognition and diarisation under various settings including: closed and open training data; as well as supervised, self-supervised, and semi-supervised training for domain adaptation. The challenges also provided publicly available training and evaluation datasets for each task and setting, with new test sets released each year. In this paper, we provide a review of these challenges that covers: what they explored; the methods developed by the challenge participants and how these evolved; and also the current state of the field for speaker verification and diarisation. We chart the progress in performance over the five installments of the challenge on a common evaluation dataset and provide a detailed analysis of how each year's special focus affected participants' performance. This paper is aimed both at researchers who want an overview of the speaker recognition and diarisation field, and also at challenge organisers who want to benefit from the successes and avoid the mistakes of the VoxSRC challenges. We end with a discussion of the current strengths of the field and open challenges. Project page : https://mm.kaist.ac.kr/datasets/voxceleb/voxsrc/workshop.html",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "TASLP 2024"
    },
    {
        "paper id": "2408.14887",
        "abstract url": "https://arxiv.org/abs/2408.14887",
        "title": "Literary and Colloquial Dialect Identification for Tamil using Acoustic Features",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "eess.AS"
            ]
        ],
        "abstract": "The evolution and diversity of a language is evident from it's various dialects. If the various dialects are not addressed in technological advancements like automatic speech recognition and speech synthesis, there is a chance that these dialects may disappear. Speech technology plays a role in preserving various dialects of a language from going extinct. In order to build a full fledged automatic speech recognition system that addresses various dialects, an Automatic Dialect Identification (ADI) system acting as the front end is required. This is similar to how language identification systems act as front ends to automatic speech recognition systems that handle multiple languages. The current work proposes a way to identify two popular and broadly classified Tamil dialects, namely literary and colloquial Tamil. Acoustical characteristics rather than phonetics and phonotactics are used, alleviating the requirement of language-dependant linguistic tools. Hence one major advantage of the proposed method is that it does not require an annotated corpus, hence it can be easily adapted to other languages. Gaussian Mixture Models (GMM) using Mel Frequency Cepstral Coefficient (MFCC) features are used to perform the classification task. The experiments yielded an error rate of 12%. Vowel nasalization, as being the reason for this good performance, is discussed. The number of mixture models for the GMM is varied and the performance is analysed.",
        "subjects": [
            "eess.AS",
            "cs.LG"
        ],
        "comment": "submitted to TENCON 2019"
    },
    {
        "paper id": "2408.14895",
        "abstract url": "https://arxiv.org/abs/2408.14895",
        "title": "VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities",
        "rating": "1",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data (e.g., images and videos) into symbols, have attracted attention as resources enabling knowledge processing and machine learning across modalities. However, the construction of MMKGs for videos consisting of multiple events, such as daily activities, is still in the early stages. In this paper, we construct an MMKG based on synchronized multi-view simulated videos of daily activities. Besides representing the content of daily life videos as event-centric knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as bounding boxes within video frames. In addition, we provide support tools for querying our MMKG. As an application example, we demonstrate that our MMKG facilitates benchmarking vision-language models by providing the necessary vision-language datasets for a tailored task.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "5 pages, 4 figures, accepted by CIKM2024 Resource Track"
    },
    {
        "paper id": "2408.14906",
        "abstract url": "https://arxiv.org/abs/2408.14906",
        "title": "Writing in the Margins: Better Inference Pattern for Long Context Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we introduce Writing in the Margins (WiM), a new inference pattern for Large Language Models designed to optimize the handling of long input sequences in retrieval-oriented tasks. This approach leverages the chunked prefill of the key-value cache to perform segment-wise inference, which enables efficient processing of extensive contexts along with the generation and classification of intermediate information (\"margins\") that guide the model towards specific tasks. This method increases computational overhead marginally while significantly enhancing the performance of off-the-shelf models without the need for fine-tuning. Specifically, we observe that WiM provides an average enhancement of 7.5% in accuracy for reasoning skills (HotpotQA, MultiHop-RAG) and more than a 30.0% increase in the F1-score for aggregation tasks (CWE). Additionally, we show how the proposed pattern fits into an interactive retrieval design that provides end-users with ongoing updates about the progress of context processing, and pinpoints the integration of relevant information into the final response. We release our implementation of WiM using Hugging Face Transformers library at https://github.com/writer/writing-in-the-margins.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14909",
        "abstract url": "https://arxiv.org/abs/2408.14909",
        "title": "SpikingSSMs: Learning Long Sequences with Sparse and Parallel Spiking State Space Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Known as low energy consumption networks, spiking neural networks (SNNs) have gained a lot of attention within the past decades. While SNNs are increasing competitive with artificial neural networks (ANNs) for vision tasks, they are rarely used for long sequence tasks, despite their intrinsic temporal dynamics. In this work, we develop spiking state space models (SpikingSSMs) for long sequence learning by leveraging on the sequence learning abilities of state space models (SSMs). Inspired by dendritic neuron structure, we hierarchically integrate neuronal dynamics with the original SSM block, meanwhile realizing sparse synaptic computation. Furthermore, to solve the conflict of event-driven neuronal dynamics with parallel computing, we propose a light-weight surrogate dynamic network which accurately predicts the after-reset membrane potential and compatible to learnable thresholds, enabling orders of acceleration in training speed compared with conventional iterative methods. On the long range arena benchmark task, SpikingSSM achieves competitive performance to state-of-the-art SSMs meanwhile realizing on average 90\\% of network sparsity. On language modeling, our network significantly surpasses existing spiking large language models (spikingLLMs) on the WikiText-103 dataset with only a third of the model size, demonstrating its potential as backbone architecture for low computation cost LLMs.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14910",
        "abstract url": "https://arxiv.org/abs/2408.14910",
        "title": "Deep learning classification system for coconut maturity levels based on acoustic signals",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The advancement of computer image processing, pattern recognition, signal processing, and other technologies has gradually replaced the manual methods of classifying fruit with computer and mechanical methods. In the field of agriculture, the intelligent classification of post-harvested fruit has enabled the use of smart devices that creates a direct impact on farmers, especially on export products. For coconut classification, it remains to be traditional in process. This study presents a classification of the coconut dataset based on acoustic signals. To address the imbalanced dataset, a data augmentation technique was conducted through audiomentation and procedural audio generation methods. Audio signals under premature, mature, and overmature now have 4,050, 4,050, and 5,850 audio signals, respectively. To address the updation of the classification system and the classification accuracy performance, deep learning models were utilized for classifying the generated audio signals from data generation. Specifically, RNN and LSTM models were trained and tested, and their performances were compared with each other and the machine learning methods used by Caladcad et al. (2020). The two DL models showed impressive performance with both having an accuracy of 97.42% and neither of them outperformed the other since there are no significant differences in their classification performance.",
        "subjects": [
            "cs.SD",
            "eess.AS",
            "eess.SP"
        ],
        "comment": "7 pages, 4 figures, accepted in the 2024 IEEE 12th Region 10 Humanitarian Technology Conference (R10-HTC)"
    },
    {
        "paper id": "2408.14939",
        "abstract url": "https://arxiv.org/abs/2408.14939",
        "title": "Integrating Continuous and Binary Relevances in Audio-Text Relevance Learning",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Audio-text relevance learning refers to learning the shared semantic properties of audio samples and textual descriptions. The standard approach uses binary relevances derived from pairs of audio samples and their human-provided captions, categorizing each pair as either positive or negative. This may result in suboptimal systems due to varying levels of relevance between audio samples and captions. In contrast, a recent study used human-assigned relevance ratings, i.e., continuous relevances, for these pairs but did not obtain performance gains in audio-text relevance learning. This work introduces a relevance learning method that utilizes both human-assigned continuous relevance ratings and binary relevances using a combination of a listwise ranking objective and a contrastive learning objective. Experimental results demonstrate the effectiveness of the proposed method, showing improvements in language-based audio retrieval, a downstream task in audio-text relevance learning. In addition, we analyze how properties of the captions or audio clips contribute to the continuous audio-text relevances provided by humans or learned by the machine.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Accepted at DCASE 2024 Workshop"
    },
    {
        "paper id": "2408.14957",
        "abstract url": "https://arxiv.org/abs/2408.14957",
        "title": "Applying ViT in Generalized Few-shot Semantic Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper explores the capability of ViT-based models under the generalized few-shot semantic segmentation (GFSS) framework. We conduct experiments with various combinations of backbone models, including ResNets and pretrained Vision Transformer (ViT)-based models, along with decoders featuring a linear classifier, UPerNet, and Mask Transformer. The structure made of DINOv2 and linear classifier takes the lead on popular few-shot segmentation bench mark PASCAL-$5^i$, substantially outperforming the best of ResNet structure by 116% in one-shot scenario. We demonstrate the great potential of large pretrained ViT-based model on GFSS task, and expect further improvement on testing benchmarks. However, a potential caveat is that when applying pure ViT-based model and large scale ViT decoder, the model is easy to overfit.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages, 4 figures"
    },
    {
        "paper id": "2408.14960",
        "abstract url": "https://arxiv.org/abs/2408.14960",
        "title": "Multilingual Arbitrage: Optimizing Data Pools to Accelerate Multilingual Progress",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The use of synthetic data has played a critical role in recent state-of-art breakthroughs. However, overly relying on a single oracle teacher model to generate data has been shown to lead to model collapse and invite propagation of biases. These limitations are particularly evident in multilingual settings, where the absence of a universally effective teacher model that excels across all languages presents significant challenges. In this work, we address these extreme difference by introducing \"multilingual arbitrage\", which capitalizes on performance variations between multiple models for a given language. To do so, we strategically route samples through a diverse pool of models, each with unique strengths in different languages. Across exhaustive experiments on state-of-art models, our work suggests that arbitrage techniques allow for spectacular gains in performance that far outperform relying on a single teacher. In particular, compared to the best single teacher, we observe gains of up to 56.5% improvement in win rates averaged across all languages when switching to multilingual arbitrage. We observe the most significant gains for the least resourced languages in our pool.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14962",
        "abstract url": "https://arxiv.org/abs/2408.14962",
        "title": "Deep Learning-based Average Shear Wave Velocity Prediction using Accelerometer Records",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Assessing seismic hazards and thereby designing earthquake-resilient structures or evaluating structural damage that has been incurred after an earthquake are important objectives in earthquake engineering. Both tasks require critical evaluation of strong ground motion records, and the knowledge of site conditions at the earthquake stations plays a major role in achieving the aforementioned objectives. Site conditions are generally represented by the time-averaged shear wave velocity in the upper 30 meters of the geological materials (Vs30). Several strong motion stations lack Vs30 measurements resulting in potentially inaccurate assessment of seismic hazards and evaluation of ground motion records. In this study, we present a deep learning-based approach for predicting Vs30 at strong motion station locations using three-channel earthquake records. For this purpose, Convolutional Neural Networks (CNNs) with dilated and causal convolutional layers are used to extract deep features from accelerometer records collected from over 700 stations located in Turkey. In order to overcome the limited availability of labeled data, we propose a two-phase training approach. In the first phase, a CNN is trained to estimate the epicenters, for which ground truth is available for all records. After the CNN is trained, the pre-trained encoder is fine-tuned based on the Vs30 ground truth. The performance of the proposed method is compared with machine learning models that utilize hand-crafted features. The results demonstrate that the deep convolutional encoder based Vs30 prediction model outperforms the machine learning models that rely on hand-crafted features.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 14 figures, Accepted by 18th World Conference on Earthquake Engineering WCEE2024"
    },
    {
        "paper id": "2408.14968",
        "abstract url": "https://arxiv.org/abs/2408.14968",
        "title": "MRSE: An Efficient Multi-modality Retrieval System for Large Scale E-commerce",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Providing high-quality item recall for text queries is crucial in large-scale e-commerce search systems. Current Embedding-based Retrieval Systems (ERS) embed queries and items into a shared low-dimensional space, but uni-modality ERS rely too heavily on textual features, making them unreliable in complex contexts. While multi-modality ERS incorporate various data sources, they often overlook individual preferences for different modalities, leading to suboptimal results. To address these issues, we propose MRSE, a Multi-modality Retrieval System that integrates text, item images, and user preferences through lightweight mixture-of-expert (LMoE) modules to better align features across and within modalities. MRSE also builds user profiles at a multi-modality level and introduces a novel hybrid loss function that enhances consistency and robustness using hard negative sampling. Experiments on a large-scale dataset from Shopee and online A/B testing show that MRSE achieves an 18.9% improvement in offline relevance and a 3.7% gain in online core metrics compared to Shopee's state-of-the-art uni-modality system.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14972",
        "abstract url": "https://arxiv.org/abs/2408.14972",
        "title": "AgentMonitor: A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The rapid advancement of large language models (LLMs) has led to the rise of LLM-based agents. Recent research shows that multi-agent systems (MAS), where each agent plays a specific role, can outperform individual LLMs. However, configuring an MAS for a task remains challenging, with performance only observable post-execution. Inspired by scaling laws in LLM development, we investigate whether MAS performance can be predicted beforehand. We introduce AgentMonitor, a framework that integrates at the agent level to capture inputs and outputs, transforming them into statistics for training a regression model to predict task performance. Additionally, it can further apply real-time corrections to address security risks posed by malicious agents, mitigating negative impacts and enhancing MAS security. Experiments demonstrate that an XGBoost model achieves a Spearman correlation of 0.89 in-domain and 0.58 in more challenging scenarios. Furthermore, using AgentMonitor reduces harmful content by 6.2% and increases helpful content by 1.8% on average, enhancing safety and reliability. Code is available at \\url{https://github.com/chanchimin/AgentMonitor}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14976",
        "abstract url": "https://arxiv.org/abs/2408.14976",
        "title": "Prior-free Balanced Replay: Uncertainty-guided Reservoir Sampling for Long-Tailed Continual Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Even in the era of large models, one of the well-known issues in continual learning (CL) is catastrophic forgetting, which is significantly challenging when the continual data stream exhibits a long-tailed distribution, termed as Long-Tailed Continual Learning (LTCL). Existing LTCL solutions generally require the label distribution of the data stream to achieve re-balance training. However, obtaining such prior information is often infeasible in real scenarios since the model should learn without pre-identifying the majority and minority classes. To this end, we propose a novel Prior-free Balanced Replay (PBR) framework to learn from long-tailed data stream with less forgetting. Concretely, motivated by our experimental finding that the minority classes are more likely to be forgotten due to the higher uncertainty, we newly design an uncertainty-guided reservoir sampling strategy to prioritize rehearsing minority data without using any prior information, which is based on the mutual dependence between the model and samples. Additionally, we incorporate two prior-free components to further reduce the forgetting issue: (1) Boundary constraint is to preserve uncertain boundary supporting samples for continually re-estimating task boundaries. (2) Prototype constraint is to maintain the consistency of learned class prototypes along with training. Our approach is evaluated on three standard long-tailed benchmarks, demonstrating superior performance to existing CL methods and previous SOTA LTCL approach in both task- and class-incremental learning settings, as well as ordered- and shuffled-LTCL settings.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14991",
        "abstract url": "https://arxiv.org/abs/2408.14991",
        "title": "Speech Recognition Transformers: Topological-lingualism Perspective",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Transformers have evolved with great success in various artificial intelligence tasks. Thanks to our recent prevalence of self-attention mechanisms, which capture long-term dependency, phenomenal outcomes in speech processing and recognition tasks have been produced. The paper presents a comprehensive survey of transformer techniques oriented in speech modality. The main contents of this survey include (1) background of traditional ASR, end-to-end transformer ecosystem, and speech transformers (2) foundational models in a speech via lingualism paradigm, i.e., monolingual, bilingual, multilingual, and cross-lingual (3) dataset and languages, acoustic features, architecture, decoding, and evaluation metric from a specific topological lingualism perspective (4) popular speech transformer toolkit for building end-to-end ASR systems. Finally, highlight the discussion of open challenges and potential research directions for the community to conduct further research in this domain.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14998",
        "abstract url": "https://arxiv.org/abs/2408.14998",
        "title": "FastTextSpotter: A High-Efficiency Transformer for Multilingual Scene Text Spotting",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The proliferation of scene text in both structured and unstructured environments presents significant challenges in optical character recognition (OCR), necessitating more efficient and robust text spotting solutions. This paper presents FastTextSpotter, a framework that integrates a Swin Transformer visual backbone with a Transformer Encoder-Decoder architecture, enhanced by a novel, faster self-attention unit, SAC2, to improve processing speeds while maintaining accuracy. FastTextSpotter has been validated across multiple datasets, including ICDAR2015 for regular texts and CTW1500 and TotalText for arbitrary-shaped texts, benchmarking against current state-of-the-art models. Our results indicate that FastTextSpotter not only achieves superior accuracy in detecting and recognizing multilingual scene text (English and Vietnamese) but also improves model efficiency, thereby setting new benchmarks in the field. This study underscores the potential of advanced transformer architectures in improving the adaptability and speed of text spotting applications in diverse real-world settings. The dataset, code, and pre-trained models have been released in our Github.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in ICPR 2024"
    },
    {
        "paper id": "2408.15015",
        "abstract url": "https://arxiv.org/abs/2408.15015",
        "title": "Alternating Minimization Schemes for Computing Rate-Distortion-Perception Functions with $f$-Divergence Perception Constraints",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We study the computation of the rate-distortion-perception function (RDPF) for discrete memoryless sources subject to a single-letter average distortion constraint and a perception constraint that belongs to the family of $f$-divergences. In this setting, the RDPF forms a convex programming problem for which we characterize the optimal parametric solutions. We employ the developed solutions in an alternating minimization scheme, namely Optimal Alternating Minimization (OAM), for which we provide convergence guarantees. Nevertheless, the OAM scheme does not lead to a direct implementation of a generalized Blahut-Arimoto (BA) type of algorithm due to the presence of implicit equations in the structure of the iteration. To overcome this difficulty, we propose two alternative minimization approaches whose applicability depends on the smoothness of the used perception metric: a Newton-based Alternating Minimization (NAM) scheme, relying on Newton's root-finding method for the approximation of the optimal iteration solution, and a Relaxed Alternating Minimization (RAM) scheme, based on a relaxation of the OAM iterates. Both schemes are shown, via the derivation of necessary and sufficient conditions, to guarantee convergence to a globally optimal solution. We also provide sufficient conditions on the distortion and the perception constraints which guarantee that the proposed algorithms converge exponentially fast in the number of iteration steps. We corroborate our theoretical results with numerical simulations and draw connections with existing results.",
        "subjects": [
            "cs.IT",
            "cs.CV",
            "eess.SP"
        ],
        "comment": "This work has been submitted for possible publication"
    },
    {
        "paper id": "2408.15037",
        "abstract url": "https://arxiv.org/abs/2408.15037",
        "title": "Evidence-Enhanced Triplet Generation Framework for Hallucination Alleviation in Generative Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "To address the hallucination in generative question answering (GQA) where the answer can not be derived from the document, we propose a novel evidence-enhanced triplet generation framework, EATQA, encouraging the model to predict all the combinations of (Question, Evidence, Answer) triplet by flipping the source pair and the target label to understand their logical relationships, i.e., predict Answer(A), Question(Q), and Evidence(E) given a QE, EA, and QA pairs, respectively. Furthermore, we bridge the distribution gap to distill the knowledge from evidence in inference stage. Our framework ensures the model to learn the logical relation between query, evidence and answer, which simultaneously improves the evidence generation and query answering. In this paper, we apply EATQA to LLama and it outperforms other LLMs-based methods and hallucination mitigation approaches on two challenging GQA benchmarks. Further analysis shows that our method not only keeps prior knowledge within LLM, but also mitigates hallucination and generates faithful answers.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15040",
        "abstract url": "https://arxiv.org/abs/2408.15040",
        "title": "A Survey of Large Language Models for European Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have gained significant attention due to their high performance on a wide range of natural language tasks since the release of ChatGPT. The LLMs learn to understand and generate language by training billions of model parameters on vast volumes of text data. Despite being a relatively new field, LLM research is rapidly advancing in various directions. In this paper, we present an overview of LLM families, including LLaMA, PaLM, GPT, and MoE, and the methods developed to create and enhance LLMs for official European Union (EU) languages. We provide a comprehensive summary of common monolingual and multilingual datasets used for pretraining large language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15045",
        "abstract url": "https://arxiv.org/abs/2408.15045",
        "title": "DocLayLLM: An Efficient and Effective Multi-modal Extension of Large Language Models for Text-rich Document Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-rich document understanding (TDU) refers to analyzing and comprehending documents containing substantial textual content. With the rapid evolution of large language models (LLMs), they have been widely leveraged for TDU due to their remarkable versatility and generalization. In this paper, we introduce DocLayLLM, an efficient and effective multi-modal extension of LLMs specifically designed for TDU. By integrating visual patch tokens and 2D positional tokens into LLMs and encoding the document content using the LLMs themselves, we fully take advantage of the document comprehension capability of LLMs and enhance their perception of OCR information. We have also deeply considered the role of the chain-of-thought (CoT) and innovatively proposed the techniques of CoT Pre-training and CoT Annealing. Our DocLayLLM can achieve remarkable performances with lightweight training settings, showcasing its efficiency and effectiveness. Experimental results demonstrate that our DocLayLLM surpasses existing OCR-dependent methods and also outperforms OCR-free competitors.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15050",
        "abstract url": "https://arxiv.org/abs/2408.15050",
        "title": "Self-supervised Topic Taxonomy Discovery in the Box Embedding Space",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Topic taxonomy discovery aims at uncovering topics of different abstraction levels and constructing hierarchical relations between them. Unfortunately, most of prior work can hardly model semantic scopes of words and topics by holding the Euclidean embedding space assumption. What's worse, they infer asymmetric hierarchical relations by symmetric distances between topic embeddings. As a result, existing methods suffer from problems of low-quality topics at high abstraction levels and inaccurate hierarchical relations. To alleviate these problems, this paper develops a Box embedding-based Topic Model (BoxTM) that maps words and topics into the box embedding space, where the asymmetric metric is defined to properly infer hierarchical relations among topics. Additionally, our BoxTM explicitly infers upper-level topics based on correlation between specific topics through recursive clustering on topic boxes. Finally, extensive experiments validate high-quality of the topic taxonomy learned by BoxTM.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "to be published in TACL"
    },
    {
        "paper id": "2408.15079",
        "abstract url": "https://arxiv.org/abs/2408.15079",
        "title": "BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The general capabilities of Large Language Models (LLM) highly rely on the composition and selection on extensive pretraining datasets, treated as commercial secrets by several institutions. To mitigate this issue, we open-source the details of a universally applicable data processing pipeline and validate its effectiveness and potential by introducing a competitive LLM baseline. Specifically, the data processing pipeline consists of broad collection to scale up and reweighting to improve quality. We then pretrain a 7B model BaichuanSEED with 3T tokens processed by our pipeline without any deliberate downstream task-related optimization, followed by an easy but effective supervised fine-tuning stage. BaichuanSEED demonstrates consistency and predictability throughout training and achieves comparable performance on comprehensive benchmarks with several commercial advanced large language models, such as Qwen1.5 and Llama3. We also conduct several heuristic experiments to discuss the potential for further optimization of downstream tasks, such as mathematics and coding.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "19 pages, 6 figures"
    },
    {
        "paper id": "2408.15101",
        "abstract url": "https://arxiv.org/abs/2408.15101",
        "title": "MTMamba++: Enhancing Multi-Task Dense Scene Understanding via Mamba-Based Decoders",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Multi-task dense scene understanding, which trains a model for multiple dense prediction tasks, has a wide range of application scenarios. Capturing long-range dependency and enhancing cross-task interactions are crucial to multi-task dense prediction. In this paper, we propose MTMamba++, a novel architecture for multi-task scene understanding featuring with a Mamba-based decoder. It contains two types of core blocks: self-task Mamba (STM) block and cross-task Mamba (CTM) block. STM handles long-range dependency by leveraging state-space models, while CTM explicitly models task interactions to facilitate information exchange across tasks. We design two types of CTM block, namely F-CTM and S-CTM, to enhance cross-task interaction from feature and semantic perspectives, respectively. Experiments on NYUDv2, PASCAL-Context, and Cityscapes datasets demonstrate the superior performance of MTMamba++ over CNN-based and Transformer-based methods. The code is available at https://github.com/EnVision-Research/MTMamba.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2407.02228"
    },
    {
        "paper id": "2408.15119",
        "abstract url": "https://arxiv.org/abs/2408.15119",
        "title": "Urdu Digital Text Word Optical Character Recognition Using Permuted Auto Regressive Sequence Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This research paper presents a novel word-level Optical Character Recognition (OCR) model developed specifically for digital Urdu text. The model utilizes transformer-based architectures and attention mechanisms to address the unique challenges of recognizing Urdu script, which includes handling a diverse range of text styles, fonts, and variations. Trained on a comprehensive dataset of approximately 160,000 Urdu text images, the model incorporates a permuted autoregressive sequence (PARSeq) architecture. This design enables context-aware inference and iterative refinement by leveraging bidirectional context information, significantly enhancing its ability to accurately recognize Urdu characters. The model achieves a character error rate (CER) of 0.178, highlighting its effectiveness and precision in real-world applications. However, the model has some limitations, such as difficulties with blurred images, non-horizontal orientations, and the presence of trailing punctuation marks, which can introduce noise into the recognition process. Addressing these challenges will be a key focus of future work. Future research will aim to further refine the model through advanced data augmentation techniques, optimization of hyperparameters, and the integration of context-aware language models, ultimately enhancing the model's performance and robustness in Urdu text recognition.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15138",
        "abstract url": "https://arxiv.org/abs/2408.15138",
        "title": "How transformers learn structured data: insights from hierarchical filtering",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce a hierarchical filtering procedure for generative models of sequences on trees, enabling control over the range of positional correlations in the data. Leveraging this controlled setting, we provide evidence that vanilla encoder-only transformer architectures can implement the optimal Belief Propagation algorithm on both root classification and masked language modeling tasks. Correlations at larger distances corresponding to increasing layers of the hierarchy are sequentially included as the network is trained. We analyze how the transformer layers succeed by focusing on attention maps from models trained with varying degrees of filtering. These attention maps show clear evidence for iterative hierarchical reconstruction of correlations, and we can relate these observations to a plausible implementation of the exact inference algorithm for the network sizes considered.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cond-mat.stat-mech",
            "cs.CL"
        ],
        "comment": "18 pages, 9 figures"
    },
    {
        "paper id": "2408.15171",
        "abstract url": "https://arxiv.org/abs/2408.15171",
        "title": "Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The use of large language models (LLMs) has significantly increased since the introduction of ChatGPT in 2022, demonstrating their value across various applications. However, a major challenge for enterprise and commercial adoption of LLMs is their tendency to generate inaccurate information, a phenomenon known as \"hallucination.\" This project proposes a method for estimating the factuality of a summary generated by LLMs when compared to a source text. Our approach utilizes Naive Bayes classification to assess the accuracy of the content produced.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2408.15178",
        "abstract url": "https://arxiv.org/abs/2408.15178",
        "title": "A Review of Transformer-Based Models for Computer Vision Tasks: Capturing Global Context and Spatial Relationships",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Transformer-based models have transformed the landscape of natural language processing (NLP) and are increasingly applied to computer vision tasks with remarkable success. These models, renowned for their ability to capture long-range dependencies and contextual information, offer a promising alternative to traditional convolutional neural networks (CNNs) in computer vision. In this review paper, we provide an extensive overview of various transformer architectures adapted for computer vision tasks. We delve into how these models capture global context and spatial relationships in images, empowering them to excel in tasks such as image classification, object detection, and segmentation. Analyzing the key components, training methodologies, and performance metrics of transformer-based models, we highlight their strengths, limitations, and recent advancements. Additionally, we discuss potential research directions and applications of transformer-based models in computer vision, offering insights into their implications for future advancements in the field.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15198",
        "abstract url": "https://arxiv.org/abs/2408.15198",
        "title": "Automatic 8-tissue Segmentation for 6-month Infant Brains",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Numerous studies have highlighted that atypical brain development, particularly during infancy and toddlerhood, is linked to an increased likelihood of being diagnosed with a neurodevelopmental condition, such as autism. Accurate brain tissue segmentations for morphological analysis are essential in numerous infant studies. However, due to ongoing white matter (WM) myelination changing tissue contrast in T1- and T2-weighted images, automatic tissue segmentation in 6-month infants is particularly difficult. On the other hand, manual labelling by experts is time-consuming and labor-intensive. In this study, we propose the first 8-tissue segmentation pipeline for six-month-old infant brains. This pipeline utilizes domain adaptation (DA) techniques to leverage our longitudinal data, including neonatal images segmented with the neonatal Developing Human Connectome Project structural pipeline. Our pipeline takes raw 6-month images as inputs and generates the 8-tissue segmentation as outputs, forming an end-to-end segmentation pipeline. The segmented tissues include WM, gray matter (GM), cerebrospinal fluid (CSF), ventricles, cerebellum, basal ganglia, brainstem, and hippocampus/amygdala. Cycle-Consistent Generative Adversarial Network (CycleGAN) and Attention U-Net were employed to achieve the image contrast transformation between neonatal and 6-month images and perform tissue segmentation on the synthesized 6-month images (neonatal images with 6-month intensity contrast), respectively. Moreover, we incorporated the segmentation outputs from Infant Brain Extraction and Analysis Toolbox (iBEAT) and another Attention U-Net to further enhance the performance and construct the end-to-end segmentation pipeline. Our evaluation with real 6-month images achieved a DICE score of 0.92, an HD95 of 1.6, and an ASSD of 0.42.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "11 pages, 4 figures, to be published in MICCAI PIPPI workshop"
    },
    {
        "paper id": "2408.15204",
        "abstract url": "https://arxiv.org/abs/2408.15204",
        "title": "Can Unconfident LLM Annotations Be Used for Confident Conclusions?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown high agreement with human raters across a variety of tasks, demonstrating potential to ease the challenges of human data collection. In computational social science (CSS), researchers are increasingly leveraging LLM annotations to complement slow and expensive human annotations. Still, guidelines for collecting and using LLM annotations, without compromising the validity of downstream conclusions, remain limited. We introduce Confidence-Driven Inference: a method that combines LLM annotations and LLM confidence indicators to strategically select which human annotations should be collected, with the goal of producing accurate statistical estimates and provably valid confidence intervals while reducing the number of human annotations needed. Our approach comes with safeguards against LLM annotations of poor quality, guaranteeing that the conclusions will be both valid and no less accurate than if we only relied on human annotations. We demonstrate the effectiveness of Confidence-Driven Inference over baselines in statistical estimation tasks across three CSS settings--text politeness, stance, and bias--reducing the needed number of human annotations by over 25% in each. Although we use CSS settings for demonstration, Confidence-Driven Inference can be used to estimate most standard quantities across a broad range of NLP problems.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15205",
        "abstract url": "https://arxiv.org/abs/2408.15205",
        "title": "Leveraging Hallucinations to Reduce Manual Prompt Dependency in Promptable Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Promptable segmentation typically requires instance-specific manual prompts to guide the segmentation of each desired object. To minimize such a need, task-generic promptable segmentation has been introduced, which employs a single task-generic prompt to segment various images of different objects in the same task. Current methods use Multimodal Large Language Models (MLLMs) to reason detailed instance-specific prompts from a task-generic prompt for improving segmentation accuracy. The effectiveness of this segmentation heavily depends on the precision of these derived prompts. However, MLLMs often suffer hallucinations during reasoning, resulting in inaccurate prompting. While existing methods focus on eliminating hallucinations to improve a model, we argue that MLLM hallucinations can reveal valuable contextual insights when leveraged correctly, as they represent pre-trained large-scale knowledge beyond individual images. In this paper, we utilize hallucinations to mine task-related information from images and verify its accuracy for enhancing precision of the generated prompts. Specifically, we introduce an iterative Prompt-Mask Cycle generation framework (ProMaC) with a prompt generator and a mask generator.The prompt generator uses a multi-scale chain of thought prompting, initially exploring hallucinations for extracting extended contextual knowledge on a test image.These hallucinations are then reduced to formulate precise instance-specific prompts, directing the mask generator to produce masks that are consistent with task semantics by mask semantic alignment. The generated masks iteratively induce the prompt generator to focus more on task-relevant image areas and reduce irrelevant hallucinations, resulting jointly in better prompts and masks. Experiments on 5 benchmarks demonstrate the effectiveness of ProMaC. Code given in https://lwpyh.github.io/ProMaC/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "We propose using hallucinations as prior knowledge to extract and validate task-related information, which helps generate instance-specific prompts for reducing reliance on manual prompts in promptable segmentation"
    },
    {
        "paper id": "2408.15209",
        "abstract url": "https://arxiv.org/abs/2408.15209",
        "title": "Sec2Sec Co-attention for Video-Based Apparent Affective Prediction",
        "rating": "1",
        "keywords": [
            [
                "audio-visual"
            ]
        ],
        "abstract": "Video-based apparent affect detection plays a crucial role in video understanding, as it encompasses various elements such as vision, audio, audio-visual interactions, and spatiotemporal information, which are essential for accurate video predictions. However, existing approaches often focus on extracting only a subset of these elements, resulting in the limited predictive capacity of their models. To address this limitation, we propose a novel LSTM-based network augmented with a Transformer co-attention mechanism for predicting apparent affect in videos. We demonstrate that our proposed Sec2Sec Co-attention Transformer surpasses multiple state-of-the-art methods in predicting apparent affect on two widely used datasets: LIRIS-ACCEDE and First Impressions. Notably, our model offers interpretability, allowing us to examine the contributions of different time points to the overall prediction. The implementation is available at: https://github.com/nestor-sun/sec2sec.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "5 pages, 3 figures"
    },
    {
        "paper id": "2408.15213",
        "abstract url": "https://arxiv.org/abs/2408.15213",
        "title": "Classifying populist language in American presidential and governor speeches using automatic text analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Populism is a concept that is often used but notoriously difficult to measure. Common qualitative measurements like holistic grading or content analysis require great amounts of time and labour, making it difficult to quickly scope out which politicians should be classified as populist and which should not, while quantitative methods show mixed results when it comes to classifying populist rhetoric. In this paper, we develop a pipeline to train and validate an automated classification model to estimate the use of populist language. We train models based on sentences that were identified as populist and pluralist in 300 US governors' speeches from 2010 to 2018 and in 45 speeches of presidential candidates in 2016. We find that these models classify most speeches correctly, including 84% of governor speeches and 89% of presidential speeches. These results extend to different time periods (with 92% accuracy on more recent American governors), different amounts of data (with as few as 70 training sentences per category achieving similar results), and when classifying politicians instead of individual speeches. This pipeline is thus an effective tool that can optimise the systematic and swift classification of the use of populist language in politicians' speeches.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15231",
        "abstract url": "https://arxiv.org/abs/2408.15231",
        "title": "DCT-CryptoNets: Scaling Private Inference in the Frequency Domain",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The convergence of fully homomorphic encryption (FHE) and machine learning offers unprecedented opportunities for private inference of sensitive data. FHE enables computation directly on encrypted data, safeguarding the entire machine learning pipeline, including data and model confidentiality. However, existing FHE-based implementations for deep neural networks face significant challenges in computational cost, latency, and scalability, limiting their practical deployment. This paper introduces DCT-CryptoNets, a novel approach that leverages frequency-domain learning to tackle these issues. Our method operates directly in the frequency domain, utilizing the discrete cosine transform (DCT) commonly employed in JPEG compression. This approach is inherently compatible with remote computing services, where images are usually transmitted and stored in compressed formats. DCT-CryptoNets reduces the computational burden of homomorphic operations by focusing on perceptually relevant low-frequency components. This is demonstrated by substantial latency reduction of up to 5.3$\\times$ compared to prior work on image classification tasks, including a novel demonstration of ImageNet inference within 2.5 hours, down from 12.5 hours compared to prior work on equivalent compute resources. Moreover, DCT-CryptoNets improves the reliability of encrypted accuracy by reducing variability (e.g., from $\\pm$2.5\\% to $\\pm$1.0\\% on ImageNet). This study demonstrates a promising avenue for achieving efficient and practical privacy-preserving deep learning on high resolution images seen in real-world applications.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Under Review; 10 pages content, 3 pages appendix, 4 figures, 8 tables; Code TBD"
    },
    {
        "paper id": "2408.15232",
        "abstract url": "https://arxiv.org/abs/2408.15232",
        "title": "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "While language model (LM)-powered chatbots and generative search engines excel at answering concrete queries, discovering information in the terrain of unknown unknowns remains challenging for users. To emulate the common educational scenario where children/students learn by listening to and participating in conversations of their parents/teachers, we create Collaborative STORM (Co-STORM). Unlike QA systems that require users to ask all the questions, Co-STORM lets users observe and occasionally steer the discourse among several LM agents. The agents ask questions on the user's behalf, allowing the user to discover unknown unknowns serendipitously. To facilitate user interaction, Co-STORM assists users in tracking the discourse by organizing the uncovered information into a dynamic mind map, ultimately generating a comprehensive report as takeaways. For automatic evaluation, we construct the WildSeek dataset by collecting real information-seeking records with user goals. Co-STORM outperforms baseline methods on both discourse trace and report quality. In a further human evaluation, 70% of participants prefer Co-STORM over a search engine, and 78% favor it over a RAG chatbot.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15313",
        "abstract url": "https://arxiv.org/abs/2408.15313",
        "title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Fine-tuning large language models (LLMs) on human preferences, typically through reinforcement learning from human feedback (RLHF), has proven successful in enhancing their capabilities. However, ensuring the safety of LLMs during the fine-tuning remains a critical concern, and mitigating the potential conflicts in safety and helpfulness is costly in RLHF. To address this issue, we propose a supervised learning framework called Bi-Factorial Preference Optimization (BFPO), which re-parameterizes a joint RLHF objective of both safety and helpfulness into a single supervised learning objective. In the supervised optimization, a labeling function is used to capture global preferences ranking to balance both safety and helpfulness. To evaluate BFPO, we develop a benchmark including comprehensive discriminative and generative tasks for helpfulness and harmlessness. The results indicate that our method significantly outperforms existing approaches in both safety and helpfulness. Moreover, BFPO eliminates the need for human prompting and annotation in LLM fine-tuning while achieving the same level of safety as methods that heavily rely on human labor, with less than 10% of the computational resources. The training recipes and models will be released.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15339",
        "abstract url": "https://arxiv.org/abs/2408.15339",
        "title": "UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "An LLM is pretrained on trillions of tokens, but the pretrained LLM may still generate undesired responses. To solve this problem, alignment techniques such as RLHF, DPO and KTO are proposed. However, these alignment techniques have limitations. For example, RLHF requires training the reward model and policy separately, which is complex, time-consuming, memory intensive and unstable during training processes. DPO proposes a mapping between an optimal policy and a reward, greatly simplifying the training process of RLHF. However, it can not take full advantages of a reward model and it is limited to pairwise preference data. In this paper, we propose \\textbf{UN}ified \\textbf{A}lignment (UNA) which unifies RLHF/PPO, DPO and KTO. Firstly, we mathematically prove that given the classical RLHF objective, the optimal policy is induced by a generalize implicit reward function. With this novel mapping between a reward model and an optimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised learning of minimizing the difference between an implicit reward and an explicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and reduce memory burden of RL fine-tuning process; 3. accommodate different feedback types including pairwise, binary and scalar feedback. Downstream experiments show UNA outperforms DPO, KTO and RLHF.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15374",
        "abstract url": "https://arxiv.org/abs/2408.15374",
        "title": "CycleGAN with Better Cycles",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "CycleGAN provides a framework to train image-to-image translation with unpaired datasets using cycle consistency loss [4]. While results are great in many applications, the pixel level cycle consistency can potentially be problematic and causes unrealistic images in certain cases. In this project, we propose three simple modifications to cycle consistency, and show that such an approach achieves better results with fewer artifacts.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Technical Report 2018"
    },
    {
        "paper id": "2408.15379",
        "abstract url": "https://arxiv.org/abs/2408.15379",
        "title": "DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model Transformer for Multimodal Aspect-based Sentiment Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal aspect-based sentiment analysis (MABSA) enhances sentiment detection by combining text with other data types like images. However, despite setting significant benchmarks, attention mechanisms exhibit limitations in efficiently modelling long-range dependencies between aspect and opinion targets within the text. They also face challenges in capturing global-context dependencies for visual representations. To this end, we propose Kolmogorov-Arnold Networks (KANs) and Selective State Space model (Mamba) transformer (DualKanbaFormer), a novel architecture to address the above issues. We leverage the power of Mamba to capture global context dependencies, Multi-head Attention (MHA) to capture local context dependencies, and KANs to capture non-linear modelling patterns for both textual representations (textual KanbaFormer) and visual representations (visual KanbaFormer). Furthermore, we fuse the textual KanbaFormer and visual KanbaFomer with a gated fusion layer to capture the inter-modality dynamics. According to extensive experimental results, our model outperforms some state-of-the-art (SOTA) studies on two public datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, 2 figures, and 3 tables"
    },
    {
        "paper id": "2408.15399",
        "abstract url": "https://arxiv.org/abs/2408.15399",
        "title": "A Statistical Framework for Data-dependent Retrieval-Augmented Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Modern ML systems increasingly augment input instances with additional relevant information to enhance final prediction. Despite growing interest in such retrieval-augmented models, their fundamental properties and training are not well understood. We propose a statistical framework to study such models with two components: 1) a {\\em retriever} to identify the relevant information out of a large corpus via a data-dependent metric; and 2) a {\\em predictor} that consumes the input instances along with the retrieved information to make the final predictions. We present a principled method for end-to-end training of both components and draw connections with various training approaches in the literature. Furthermore, we establish excess risk bounds for retrieval-augmented models while delineating the contributions of both retriever and predictor towards the model performance. We validate the utility of our proposed training methods along with the key takeaways from our statistical analysis on open domain question answering task where retrieval augmentation is important.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15409",
        "abstract url": "https://arxiv.org/abs/2408.15409",
        "title": "Awes, Laws, and Flaws From Today's LLM Research",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We perform a critical examination of the scientific methodology behind contemporary large language model (LLM) research. For this we assess over 2,000 research works based on criteria typical of what is considered good research (e.g. presence of statistical tests and reproducibility) and cross-validate it with arguments that are at the centre of controversy (e.g., claims of emergent behaviour, the use of LLMs as evaluators). We find multiple trends, such as declines in claims of emergent behaviour and ethics disclaimers; the rise of LLMs as evaluators in spite of a lack of consensus from the community about their useability; and an increase of claims of LLM reasoning abilities, typically without leveraging human evaluation. This paper underscores the need for more scrutiny and rigour by and from this field to live up to the fundamentals of a responsible scientific method that is ethical, reproducible, systematic, and open to criticism.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under review -- v1 was an old draft with an unrevised abstract (oops)"
    },
    {
        "paper id": "2408.15417",
        "abstract url": "https://arxiv.org/abs/2408.15417",
        "title": "Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns to Model Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Next-token prediction (NTP) over large text corpora has become the go-to paradigm to train large language models. Yet, it remains unclear how NTP influences the mapping of linguistic patterns to geometric properties of the resulting model representations. We frame training of large language models as soft-label classification over sparse probabilistic label vectors, coupled with an analytical approximation that allows unrestricted generation of context embeddings. This approach links NTP training to rank-constrained, nuclear-norm regularized optimization in the logit domain, offering a framework for analyzing the geometry of word and context embeddings. In large embedding spaces, we find that NTP implicitly favors learning logits with a sparse plus low-rank structure. While the sparse component captures the co-occurrence frequency of context-word pairs, the orthogonal low-rank component, which becomes dominant as training progresses, depends solely on the sparsity pattern of the co-occurrence matrix. Consequently, when projected onto an appropriate subspace, representations of contexts that are followed by the same set of next-tokens collapse, a phenomenon we term subspace-collapse. We validate our findings on synthetic and small-scale real language datasets. Finally, we outline potential research directions aimed at deepening the understanding of NTP's influence on the learning of linguistic patterns and regularities.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted at COLM 2024"
    },
    {
        "paper id": "2408.15447",
        "abstract url": "https://arxiv.org/abs/2408.15447",
        "title": "Fine-grained length controllable video captioning with ordinal embeddings",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper proposes a method for video captioning that controls the length of generated captions. Previous work on length control often had few levels for expressing length. In this study, we propose two methods of length embedding for fine-grained length control. A traditional embedding method is linear, using a one-hot vector and an embedding matrix. In this study, we propose methods that represent length in multi-hot vectors. One is bit embedding that expresses length in bit representation, and the other is ordinal embedding that uses the binary representation often used in ordinal regression. These length representations of multi-hot vectors are converted into length embedding by a nonlinear MLP. This method allows for not only the length control of caption sentences but also the control of the time when reading the caption. Experiments using ActivityNet Captions and Spoken Moments in Time show that the proposed method effectively controls the length of the generated captions. Analysis of the embedding vectors with ICA shows that length and semantics were learned separately, demonstrating the effectiveness of the proposed embedding methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15465",
        "abstract url": "https://arxiv.org/abs/2408.15465",
        "title": "Dynamic Reconstruction from Neuromorphic Data",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unlike traditional cameras which synchronously register pixel intensity, neuromorphic sensors only register `changes' at pixels where a change is occurring asynchronously. This enables neuromorphic sensors to sample at a micro-second level and efficiently capture the dynamics. Since, only sequences of asynchronous event changes are recorded rather than brightness intensities over time, many traditional image processing techniques cannot be directly applied. Furthermore, existing approaches, including the ones recently introduced by the authors, use traditional images combined with neuromorphic event data to carry out reconstructions. The aim of this work is introduce an optimization based approach to reconstruct images and dynamics only from the neuromoprhic event data without any additional knowledge of the events. Each pixel is modeled temporally. The experimental results on real data highlight the efficacy of the presented approach, paving the way for efficient and accurate processing of neuromorphic sensor data in real-world applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15488",
        "abstract url": "https://arxiv.org/abs/2408.15488",
        "title": "Legilimens: Practical and Unified Content Moderation for Large Language Model Services",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers. Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources. In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation. We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency. Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking. Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methods. We have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries. A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens. Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ACM Conference on Computer and Communications Security (CCS) 2024"
    },
    {
        "paper id": "2408.15491",
        "abstract url": "https://arxiv.org/abs/2408.15491",
        "title": "Enhancing and Accelerating Large Language Models via Instruction-Aware Contextual Compression",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have garnered widespread attention due to their remarkable performance across various tasks. However, to mitigate the issue of hallucinations, LLMs often incorporate retrieval-augmented pipeline to provide them with rich external knowledge and context. Nevertheless, challenges stem from inaccurate and coarse-grained context retrieved from the retriever. Supplying irrelevant context to the LLMs can result in poorer responses, increased inference latency, and higher costs. This paper introduces a method called Instruction-Aware Contextual Compression, which filters out less informative content, thereby accelerating and enhancing the use of LLMs. The experimental results demonstrate that Instruction-Aware Contextual Compression notably reduces memory consumption and minimizes generation latency while maintaining performance levels comparable to those achieved with the use of the full context. Specifically, we achieved a 50% reduction in context-related costs, resulting in a 5% reduction in inference memory usage and a 2.2-fold increase in inference speed, with only a minor drop of 0.047 in Rouge-1. These findings suggest that our method strikes an effective balance between efficiency and performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2408.15496",
        "abstract url": "https://arxiv.org/abs/2408.15496",
        "title": "ReMamba: Equip Mamba with Effective Long-Sequence Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "While the Mamba architecture demonstrates superior inference efficiency and competitive performance on short-context natural language processing (NLP) tasks, empirical evidence suggests its capacity to comprehend long contexts is limited compared to transformer-based models. In this study, we investigate the long-context efficiency issues of the Mamba models and propose ReMamba, which enhances Mamba's ability to comprehend long contexts. ReMamba incorporates selective compression and adaptation techniques within a two-stage re-forward process, incurring minimal additional inference costs overhead. Experimental results on the LongBench and L-Eval benchmarks demonstrate ReMamba's efficacy, improving over the baselines by 3.2 and 1.6 points, respectively, and attaining performance almost on par with same-size transformer models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15510",
        "abstract url": "https://arxiv.org/abs/2408.15510",
        "title": "Measuring the Reliability of Causal Probing Methods: Tradeoffs, Limitations, and the Plight of Nullifying Interventions",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Causal probing is an approach to interpreting foundation models, such as large language models, by training probes to recognize latent properties of interest from embeddings, intervening on probes to modify this representation, and analyzing the resulting changes in the model's behavior. While some recent works have cast doubt on the theoretical basis of several leading causal probing intervention methods, it has been unclear how to systematically and empirically evaluate their effectiveness in practice. To address this problem, we propose a general empirical analysis framework to evaluate the reliability of causal probing interventions, formally defining and quantifying two key causal probing desiderata: completeness (fully transforming the representation of the target property) and selectivity (minimally impacting other properties). Our formalism allows us to make the first direct comparisons between different families of causal probing methods (e.g., linear vs. nonlinear or counterfactual vs. nullifying interventions). We conduct extensive experiments across several leading methods, finding that (1) there is an inherent tradeoff between these criteria, and no method is able to consistently satisfy both at once; and (2) across the board, nullifying interventions are always far less complete than counterfactual interventions, indicating that nullifying methods may not be an effective approach to causal probing.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15512",
        "abstract url": "https://arxiv.org/abs/2408.15512",
        "title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The advent of Large Language Models (LLMs) has created new opportunities for the automation of scientific research, spanning both experimental processes and computational simulations. This study explores the feasibility of constructing an autonomous simulation agent (ASA) powered by LLM, through sophisticated API integration, to automate the entire research process, from experimental design, remote upload and simulation execution, data analysis, to report compilation. Using a simulation problem of polymer chain conformations as a case study, we assessed the performance of ASAs powered by different LLMs including GPT-4-Turbo. Our findings revealed that ASA-GPT-4o achieved near-flawless execution on designated research missions, underscoring the potential of LLMs to manage complete scientific investigations autonomously. The outlined automation can be iteratively performed up to twenty cycles without human intervention, illustrating the potential of LLMs for large-scale autonomous research endeavors. Additionally, we discussed the intrinsic traits of ASAs in managing extensive tasks, focusing on self-validation mechanisms and the balance between local attention and global oversight.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "physics.chem-ph"
        ],
        "comment": "For additional code and data, please visit our GitHub repository: https://github.com/zokaraa/autonomous_simulation_agent"
    },
    {
        "paper id": "2408.15513",
        "abstract url": "https://arxiv.org/abs/2408.15513",
        "title": "Continual-learning-based framework for structural damage recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Multi-damage is common in reinforced concrete structures and leads to the requirement of large number of neural networks, parameters and data storage, if convolutional neural network (CNN) is used for damage recognition. In addition, conventional CNN experiences catastrophic forgetting and training inefficiency as the number of tasks increases during continual learning, leading to large accuracy decrease of previous learned tasks. To address these problems, this study proposes a continuallearning-based damage recognition model (CLDRM) which integrates the learning without forgetting continual learning method into the ResNet-34 architecture for the recognition of damages in RC structures as well as relevant structural components. Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework. In this way, it reduces both the prediction time and data storage by about 75% in four tasks of continuous learning. Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework. By gradual feature fusion, CLDRM outperformed other methods by managed to achieve high accuracy in the damage recognition and classification. As the number of recognition tasks increased, CLDRM also experienced smaller decrease of the previous learned tasks. Results indicate that the CLDRM framework successfully performs damage recognition and classification with reasonable accuracy and effectiveness.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "18 pages, 12 figures"
    },
    {
        "paper id": "2408.15533",
        "abstract url": "https://arxiv.org/abs/2408.15533",
        "title": "LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-Augmented Generation (RAG) has become a primary technique for mitigating hallucinations in large language models (LLMs). However, incomplete knowledge extraction and insufficient understanding can still mislead LLMs to produce irrelevant or even contradictory responses, which means hallucinations persist in RAG. In this paper, we propose LRP4RAG, a method based on the Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations in RAG. Specifically, we first utilize LRP to compute the relevance between the input and output of the RAG generator. We then apply further extraction and resampling to the relevance matrix. The processed relevance data are input into multiple classifiers to determine whether the output contains hallucinations. To the best of our knowledge, this is the first time that LRP has been used for detecting RAG hallucinations, and extensive experiments demonstrate that LRP4RAG outperforms existing baselines.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14778",
        "abstract url": "https://arxiv.org/abs/2408.14778",
        "title": "GPU-Accelerated Counterfactual Regret Minimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Counterfactual regret minimization (CFR) is a family of algorithms of no-regret learning dynamics capable of solving large-scale imperfect information games. There has been a notable lack of work on making CFR more computationally efficient. We propose implementing this algorithm as a series of dense and sparse matrix and vector operations, thereby making it highly parallelizable for a graphical processing unit. Our experiments show that our implementation performs up to about 352.5 times faster than OpenSpiel's Python implementation and up to about 22.2 times faster than OpenSpiel's C++ implementation and the speedup becomes more pronounced as the size of the game being solved grows.",
        "subjects": [
            "cs.GT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14785",
        "abstract url": "https://arxiv.org/abs/2408.14785",
        "title": "Unsupervised-to-Online Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Offline-to-online reinforcement learning (RL), a framework that trains a policy with offline RL and then further fine-tunes it with online RL, has been considered a promising recipe for data-driven decision-making. While sensible, this framework has drawbacks: it requires domain-specific offline RL pre-training for each task, and is often brittle in practice. In this work, we propose unsupervised-to-online RL (U2O RL), which replaces domain-specific supervised offline RL with unsupervised offline RL, as a better alternative to offline-to-online RL. U2O RL not only enables reusing a single pre-trained model for multiple downstream tasks, but also learns better representations, which often result in even better performance and stability than supervised offline-to-online RL. To instantiate U2O RL in practice, we propose a general recipe for U2O RL to bridge task-agnostic unsupervised offline skill-based policy pre-training and supervised online fine-tuning. Throughout our experiments in nine state-based and pixel-based environments, we empirically demonstrate that U2O RL achieves strong performance that matches or even outperforms previous offline-to-online RL approaches, while being able to reuse a single pre-trained model for a number of different downstream tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14791",
        "abstract url": "https://arxiv.org/abs/2408.14791",
        "title": "Optimizing Structured Data Processing through Robotic Process Automation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Robotic Process Automation (RPA) has emerged as a game-changing technology in data extraction, revolutionizing the way organizations process and analyze large volumes of documents such as invoices, purchase orders, and payment advices. This study investigates the use of RPA for structured data extraction and evaluates its advantages over manual processes. By comparing human-performed tasks with those executed by RPA software bots, we assess efficiency and accuracy in data extraction from invoices, focusing on the effectiveness of the RPA system. Through four distinct scenarios involving varying numbers of invoices, we measure efficiency in terms of time and effort required for task completion, as well as accuracy by comparing error rates between manual and RPA processes. Our findings highlight the significant efficiency gains achieved by RPA, with bots completing tasks in significantly less time compared to manual efforts across all cases. Moreover, the RPA system consistently achieves perfect accuracy, mitigating the risk of errors and enhancing process reliability. These results underscore the transformative potential of RPA in optimizing operational efficiency, reducing human labor costs, and improving overall business performance.",
        "subjects": [
            "cs.AI",
            "cs.RO"
        ],
        "comment": "This manuscript has been accepted for publication in the journal Revue d'Intelligence Artificielle"
    },
    {
        "paper id": "2408.14792",
        "abstract url": "https://arxiv.org/abs/2408.14792",
        "title": "Measuring Human Contribution in AI-Assisted Content Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "With the growing prevalence of generative artificial intelligence (AI), an increasing amount of content is no longer exclusively generated by humans but by generative AI models with human guidance. This shift presents notable challenges for the delineation of originality due to the varying degrees of human contribution in AI-assisted works. This study raises the research question of measuring human contribution in AI-assisted content generation and introduces a framework to address this question that is grounded in information theory. By calculating mutual information between human input and AI-assisted output relative to self-information of AI-assisted output, we quantify the proportional information contribution of humans in content generation. Our experimental results demonstrate that the proposed measure effectively discriminates between varying degrees of human contribution across multiple creative domains. We hope that this work lays a foundation for measuring human contributions in AI-assisted content generation in the era of generative AI.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14806",
        "abstract url": "https://arxiv.org/abs/2408.14806",
        "title": "Poly2Vec: Polymorphic Encoding of Geospatial Objects for Spatial Reasoning with Deep Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Encoding geospatial data is crucial for enabling machine learning (ML) models to perform tasks that require spatial reasoning, such as identifying the topological relationships between two different geospatial objects. However, existing encoding methods are limited as they are typically customized to handle only specific types of spatial data, which impedes their applicability across different downstream tasks where multiple data types coexist. To address this, we introduce Poly2Vec, an encoding framework that unifies the modeling of different geospatial objects, including 2D points, polylines, and polygons, irrespective of the downstream task. We leverage the power of the 2D Fourier transform to encode useful spatial properties, such as shape and location, from geospatial objects into fixed-length vectors. These vectors are then inputted into neural network models for spatial reasoning tasks.This unified approach eliminates the need to develop and train separate models for each distinct spatial type. We evaluate Poly2Vec on both synthetic and real datasets of mixed geometry types and verify its consistent performance across several downstream spatial reasoning tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14811",
        "abstract url": "https://arxiv.org/abs/2408.14811",
        "title": "Brain-inspired Artificial Intelligence: A Comprehensive Review",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Current artificial intelligence (AI) models often focus on enhancing performance through meticulous parameter tuning and optimization techniques. However, the fundamental design principles behind these models receive comparatively less attention, which can limit our understanding of their potential and constraints. This comprehensive review explores the diverse design inspirations that have shaped modern AI models, i.e., brain-inspired artificial intelligence (BIAI). We present a classification framework that categorizes BIAI approaches into physical structure-inspired and human behavior-inspired models. We also examine the real-world applications where different BIAI models excel, highlighting their practical benefits and deployment challenges. By delving into these areas, we provide new insights and propose future research directions to drive innovation and address current gaps in the field. This review offers researchers and practitioners a comprehensive overview of the BIAI landscape, helping them harness its potential and expedite advancements in AI development.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "35 pages, 4 figures"
    },
    {
        "paper id": "2408.14821",
        "abstract url": "https://arxiv.org/abs/2408.14821",
        "title": "Data-driven Effective Modeling of Multiscale Stochastic Dynamical Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a numerical method for learning the dynamics of slow components of unknown multiscale stochastic dynamical systems. While the governing equations of the systems are unknown, bursts of observation data of the slow variables are available. By utilizing the observation data, our proposed method is capable of constructing a generative stochastic model that can accurately capture the effective dynamics of the slow variables in distribution. We present a comprehensive set of numerical examples to demonstrate the performance of the proposed method.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "stat.ML"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2406.15747"
    },
    {
        "paper id": "2408.14826",
        "abstract url": "https://arxiv.org/abs/2408.14826",
        "title": "Alfie: Democratising RGBA Image Generation With No $$$",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Designs and artworks are ubiquitous across various creative fields, requiring graphic design skills and dedicated software to create compositions that include many graphical elements, such as logos, icons, symbols, and art scenes, which are integral to visual storytelling. Automating the generation of such visual elements improves graphic designers' productivity, democratizes and innovates the creative industry, and helps generate more realistic synthetic data for related tasks. These illustration elements are mostly RGBA images with irregular shapes and cutouts, facilitating blending and scene composition. However, most image generation models are incapable of generating such images and achieving this capability requires expensive computational resources, specific training recipes, or post-processing solutions. In this work, we propose a fully-automated approach for obtaining RGBA illustrations by modifying the inference-time behavior of a pre-trained Diffusion Transformer model, exploiting the prompt-guided controllability and visual quality offered by such models with no additional computational cost. We force the generation of entire subjects without sharp croppings, whose background is easily removed for seamless integration into design projects or artistic scenes. We show with a user study that, in most cases, users prefer our solution over generating and then matting an image, and we show that our generated illustrations yield good results when used as inputs for composite scene generation pipelines. We release the code at https://github.com/aimagelab/Alfie.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted at ECCV AI for Visual Arts Workshop and Challenges"
    },
    {
        "paper id": "2408.14834",
        "abstract url": "https://arxiv.org/abs/2408.14834",
        "title": "Strategic Optimization and Challenges of Large Language Models in Object-Oriented Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the area of code generation research, the emphasis has transitioned from crafting individual functions to developing class-level method code that integrates contextual information. This shift has brought several benchmarks such as ClassEval and CoderEval, which consider class-level contexts. Nevertheless, the influence of specific contextual factors at the method level remains less explored. This research focused on method-level code generation within the Object-Oriented Programming (OOP) framework. Based on CoderEval, we devised experiments that varied the extent of contextual information in the prompts, ranging from method-specific to project-wide details. We introduced the innovative metric of \"Prompt-Token Cost-Effectiveness\" to evaluate the economic viability of incorporating additional contextual layers. Our findings indicate that prompts enriched with method invocation details yield the highest cost-effectiveness. Additionally, our study revealed disparities among Large Language Models (LLMs) regarding error type distributions and the level of assistance they provide to developers. Notably, larger LLMs do not invariably perform better. We also observed that tasks with higher degrees of coupling present more substantial challenges, suggesting that the choice of LLM should be tailored to the task's coupling degree. For example, GPT-4 exhibited improved performance in low-coupling scenarios, whereas GPT-3.5 seemed better suited for tasks with high coupling. By meticulously curating prompt content and selecting the appropriate LLM, developers can optimize code quality while maximizing cost-efficiency during the development process.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2408.14855",
        "abstract url": "https://arxiv.org/abs/2408.14855",
        "title": "Enhancing Analogical Reasoning in the Abstraction and Reasoning Corpus via Model-Based RL",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper demonstrates that model-based reinforcement learning (model-based RL) is a suitable approach for the task of analogical reasoning. We hypothesize that model-based RL can solve analogical reasoning tasks more efficiently through the creation of internal models. To test this, we compared DreamerV3, a model-based RL method, with Proximal Policy Optimization, a model-free RL method, on the Abstraction and Reasoning Corpus (ARC) tasks. Our results indicate that model-based RL not only outperforms model-free RL in learning and generalizing from single tasks but also shows significant advantages in reasoning across similar tasks.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": "Accepted to IJCAI 2024 IARML Workshop"
    },
    {
        "paper id": "2408.14864",
        "abstract url": "https://arxiv.org/abs/2408.14864",
        "title": "Dynamic operator management in meta-heuristics using reinforcement learning: an application to permutation flowshop scheduling problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study develops a framework based on reinforcement learning to dynamically manage a large portfolio of search operators within meta-heuristics. Using the idea of tabu search, the framework allows for continuous adaptation by temporarily excluding less efficient operators and updating the portfolio composition during the search. A Q-learning-based adaptive operator selection mechanism is used to select the most suitable operator from the dynamically updated portfolio at each stage. Unlike traditional approaches, the proposed framework requires no input from the experts regarding the search operators, allowing domain-specific non-experts to effectively use the framework. The performance of the proposed framework is analyzed through an application to the permutation flowshop scheduling problem. The results demonstrate the superior performance of the proposed framework against state-of-the-art algorithms in terms of optimality gap and convergence speed.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14871",
        "abstract url": "https://arxiv.org/abs/2408.14871",
        "title": "Learning Robust Reward Machines from Noisy Labels",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents PROB-IRM, an approach that learns robust reward machines (RMs) for reinforcement learning (RL) agents from noisy execution traces. The key aspect of RM-driven RL is the exploitation of a finite-state machine that decomposes the agent's task into different subtasks. PROB-IRM uses a state-of-the-art inductive logic programming framework robust to noisy examples to learn RMs from noisy traces using the Bayesian posterior degree of beliefs, thus ensuring robustness against inconsistencies. Pivotal for the results is the interleaving between RM learning and policy learning: a new RM is learned whenever the RL agent generates a trace that is believed not to be accepted by the current RM. To speed up the training of the RL agent, PROB-IRM employs a probabilistic formulation of reward shaping that uses the posterior Bayesian beliefs derived from the traces. Our experimental analysis shows that PROB-IRM can learn (potentially imperfect) RMs from noisy traces and exploit them to train an RL agent to solve its tasks successfully. Despite the complexity of learning the RM from noisy traces, agents trained with PROB-IRM perform comparably to agents provided with handcrafted RMs.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Preprint accepted for publication to the 21st International Conference on Principles of Knowledge Representation and Reasoning (KR 2024)"
    },
    {
        "paper id": "2408.14930",
        "abstract url": "https://arxiv.org/abs/2408.14930",
        "title": "CMTA: Cross-Modal Temporal Alignment for Event-guided Video Deblurring",
        "rating": "0.5",
        "keywords": [
            [
                "event camera"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Video deblurring aims to enhance the quality of restored results in motion-blurred videos by effectively gathering information from adjacent video frames to compensate for the insufficient data in a single blurred frame. However, when faced with consecutively severe motion blur situations, frame-based video deblurring methods often fail to find accurate temporal correspondence among neighboring video frames, leading to diminished performance. To address this limitation, we aim to solve the video deblurring task by leveraging an event camera with micro-second temporal resolution. To fully exploit the dense temporal resolution of the event camera, we propose two modules: 1) Intra-frame feature enhancement operates within the exposure time of a single blurred frame, iteratively enhancing cross-modality features in a recurrent manner to better utilize the rich temporal information of events, 2) Inter-frame temporal feature alignment gathers valuable long-range temporal information to target frames, aggregating sharp features leveraging the advantages of the events. In addition, we present a novel dataset composed of real-world blurred RGB videos, corresponding sharp videos, and event data. This dataset serves as a valuable resource for evaluating event-guided deblurring methods. We demonstrate that our proposed methods outperform state-of-the-art frame-based and event-based motion deblurring methods through extensive experiments conducted on both synthetic and real-world deblurring datasets. The code and dataset are available at https://github.com/intelpro/CMTA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in ECCV2024"
    },
    {
        "paper id": "2408.14935",
        "abstract url": "https://arxiv.org/abs/2408.14935",
        "title": "Quotient Normalized Maximum Likelihood Criterion for Learning Bayesian Network Structures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We introduce an information theoretic criterion for Bayesian network structure learning which we call quotient normalized maximum likelihood (qNML). In contrast to the closely related factorized normalized maximum likelihood criterion, qNML satisfies the property of score equivalence. It is also decomposable and completely free of adjustable hyperparameters. For practical computations, we identify a remarkably accurate approximation proposed earlier by Szpankowski and Weinberger. Experiments on both simulated and real data demonstrate that the new criterion leads to parsimonious models with good predictive accuracy.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to AISTATS 2018"
    },
    {
        "paper id": "2408.15004",
        "abstract url": "https://arxiv.org/abs/2408.15004",
        "title": "Measuring publication relatedness using controlled vocabularies",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Measuring the relatedness between scientific publications has important applications in many areas of bibliometrics and science policy. Controlled vocabularies provide a promising basis for measuring relatedness because they address issues that arise when using citation or textual similarity to measure relatedness. While several controlled-vocabulary-based relatedness measures have been developed, there exists no comprehensive and direct test of their accuracy and suitability for different types of research questions. This paper reviews existing measures, develops a new measure, and benchmarks the measures using TREC Genomics data as a ground truth of topics. The benchmark test show that the new measure and the measure proposed by Ahlgren et al. (2020) have differing strengths and weaknesses. These results inform a discussion of which method to choose when studying interdisciplinarity, information retrieval, clustering of science, and researcher topic switching.",
        "subjects": [
            "cs.IR",
            "cs.IT",
            "cs.SI"
        ],
        "comment": "Accepted for presentation at the 28th International Conference on Science, Technology and Innovation Indicators, 2024"
    },
    {
        "paper id": "2408.15055",
        "abstract url": "https://arxiv.org/abs/2408.15055",
        "title": "Causal Rule Forest: Toward Interpretable and Precise Treatment Effect Estimation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Understanding and inferencing Heterogeneous Treatment Effects (HTE) and Conditional Average Treatment Effects (CATE) are vital for developing personalized treatment recommendations. Many state-of-the-art approaches achieve inspiring performance in estimating HTE on benchmark datasets or simulation studies. However, the indirect predicting manner and complex model architecture reduce the interpretability of these approaches. To mitigate the gap between predictive performance and heterogeneity interpretability, we introduce the Causal Rule Forest (CRF), a novel approach to learning hidden patterns from data and transforming the patterns into interpretable multi-level Boolean rules. By training the other interpretable causal inference models with data representation learned by CRF, we can reduce the predictive errors of these models in estimating HTE and CATE, while keeping their interpretability for identifying subgroups that a treatment is more effective. Our experiments underscore the potential of CRF to advance personalized interventions and policies, paving the way for future research to enhance its scalability and application across complex causal inference challenges.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "The 25th IEEE International Conference on Information Reuse and Integration for Data Science (IRI 2024)"
    },
    {
        "paper id": "2408.15065",
        "abstract url": "https://arxiv.org/abs/2408.15065",
        "title": "The Benefits of Balance: From Information Projections to Variance Reduction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data balancing across multiple modalities/sources appears in various forms in several foundation models (e.g., CLIP and DINO) achieving universal representation learning. We show that this iterative algorithm, usually used to avoid representation collapse, enjoys an unsuspected benefit: reducing the variance of estimators that are functionals of the empirical distribution over these sources. We provide non-asymptotic bounds quantifying this variance reduction effect and relate them to the eigendecays of appropriately defined Markov operators. We explain how various forms of data balancing in contrastive multimodal learning and self-supervised clustering can be interpreted as instances of this variance reduction scheme.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15066",
        "abstract url": "https://arxiv.org/abs/2408.15066",
        "title": "Constraining Participation: Affordances of Feedback Features in Interfaces to Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Large language models (LLMs) are now accessible to anyone with a computer, a web browser, and an internet connection via browser-based interfaces, shifting the dynamics of participation in AI development. This paper examines the affordances of interactive feedback features in ChatGPT's interface, analysing how they shape user input and participation in LLM iteration. Drawing on a survey of ChatGPT users and applying the mechanisms and conditions framework of affordances, we demonstrate that these features encourage simple, frequent, and performance-focused feedback while discouraging collective input and discussions among users. We argue that this feedback format significantly constrains user participation, reinforcing power imbalances between users, the public, and companies developing LLMs. Our analysis contributes to the growing body of literature on participatory AI by critically examining the limitations of existing feedback processes and proposing directions for their redesign. To enable more meaningful public participation in AI development, we advocate for a shift away from processes focused on aligning model outputs with specific user preferences. Instead, we emphasise the need for processes that facilitate dialogue between companies and diverse 'publics' about the purpose and applications of LLMs. This approach requires attention to the ongoing work of infrastructuring - creating and sustaining the social, technical, and institutional structures necessary to address matters of concern to groups impacted by AI development and deployment.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15073",
        "abstract url": "https://arxiv.org/abs/2408.15073",
        "title": "Interactive dense pixel visualizations for time series and model attribution explanations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The field of Explainable Artificial Intelligence (XAI) for Deep Neural Network models has developed significantly, offering numerous techniques to extract explanations from models. However, evaluating explanations is often not trivial, and differences in applied metrics can be subtle, especially with non-intelligible data. Thus, there is a need for visualizations tailored to explore explanations for domains with such data, e.g., time series. We propose DAVOTS, an interactive visual analytics approach to explore raw time series data, activations of neural networks, and attributions in a dense-pixel visualization to gain insights into the data, models' decisions, and explanations. To further support users in exploring large datasets, we apply clustering approaches to the visualized data domains to highlight groups and present ordering strategies for individual and combined data exploration to facilitate finding patterns. We visualize a CNN trained on the FordA dataset to demonstrate the approach.",
        "subjects": [
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "5 pages, 2 figures, accepted at MLVIS 2023"
    },
    {
        "paper id": "2408.15096",
        "abstract url": "https://arxiv.org/abs/2408.15096",
        "title": "Post-processing fairness with minimal changes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we introduce a novel post-processing algorithm that is both model-agnostic and does not require the sensitive attribute at test time. In addition, our algorithm is explicitly designed to enforce minimal changes between biased and debiased predictions; a property that, while highly desirable, is rarely prioritized as an explicit objective in fairness literature. Our approach leverages a multiplicative factor applied to the logit value of probability scores produced by a black-box classifier. We demonstrate the efficacy of our method through empirical evaluations, comparing its performance against other four debiasing algorithms on two widely used datasets in fairness research.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15114",
        "abstract url": "https://arxiv.org/abs/2408.15114",
        "title": "Few-Shot Unsupervised Implicit Neural Shape Representation Learning with Spatial Adversaries",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "SDF"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities, encompassing a wide range from 3D shapes to images and audio. Within the realm of 3D shape representation, Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry. However, learning SDFs from sparse 3D point clouds in the absence of ground truth supervision remains a very challenging task. While recent methods rely on smoothness priors to regularize the learning, our method introduces a regularization term that leverages adversarial samples around the shape to improve the learned SDFs. Through extensive experiments and evaluations, we illustrate the efficacy of our proposed method, highlighting its capacity to improve SDF learning with respect to baselines and the state-of-the-art using synthetic and real data.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.LG"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2408.15116",
        "abstract url": "https://arxiv.org/abs/2408.15116",
        "title": "Evaluating Stability of Unreflective Alignment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Many theoretical obstacles to AI alignment are consequences of reflective stability - the problem of designing alignment mechanisms that the AI would not disable if given the option. However, problems stemming from reflective stability are not obviously present in current LLMs, leading to disagreement over whether they will need to be solved to enable safe delegation of cognitive labor. In this paper, we propose Counterfactual Priority Change (CPC) destabilization as a mechanism by which reflective stability problems may arise in future LLMs. We describe two risk factors for CPC-destabilization: 1) CPC-based stepping back and 2) preference instability. We develop preliminary evaluations for each of these risk factors, and apply them to frontier LLMs. Our findings indicate that in current LLMs, increased scale and capability are associated with increases in both CPC-based stepping back and preference instability, suggesting that CPC-destabilization may cause reflective stability problems in future LLMs.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15128",
        "abstract url": "https://arxiv.org/abs/2408.15128",
        "title": "Evaluating the Energy Consumption of Machine Learning: Systematic Literature Review and Experiments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Monitoring, understanding, and optimizing the energy consumption of Machine Learning (ML) are various reasons why it is necessary to evaluate the energy usage of ML. However, there exists no universal tool that can answer this question for all use cases, and there may even be disagreement on how to evaluate energy consumption for a specific use case. Tools and methods are based on different approaches, each with their own advantages and drawbacks, and they need to be mapped out and explained in order to select the most suitable one for a given situation. We address this challenge through two approaches. First, we conduct a systematic literature review of all tools and methods that permit to evaluate the energy consumption of ML (both at training and at inference), irrespective of whether they were originally designed for machine learning or general software. Second, we develop and use an experimental protocol to compare a selection of these tools and methods. The comparison is both qualitative and quantitative on a range of ML tasks of different nature (vision, language) and computational complexity. The systematic literature review serves as a comprehensive guide for understanding the array of tools and methods used in evaluating energy consumption of ML, for various use cases going from basic energy monitoring to consumption optimization. Two open-source repositories are provided for further exploration. The first one contains tools that can be used to replicate this work or extend the current review. The second repository houses the experimental protocol, allowing users to augment the protocol with new ML computing tasks and additional energy evaluation tools.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "52 pages,"
    },
    {
        "paper id": "2408.15136",
        "abstract url": "https://arxiv.org/abs/2408.15136",
        "title": "Low-Budget Simulation-Based Inference with Bayesian Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Simulation-based inference methods have been shown to be inaccurate in the data-poor regime, when training simulations are limited or expensive. Under these circumstances, the inference network is particularly prone to overfitting, and using it without accounting for the computational uncertainty arising from the lack of identifiability of the network weights can lead to unreliable results. To address this issue, we propose using Bayesian neural networks in low-budget simulation-based inference, thereby explicitly accounting for the computational uncertainty of the posterior approximation. We design a family of Bayesian neural network priors that are tailored for inference and show that they lead to well-calibrated posteriors on tested benchmarks, even when as few as $O(10)$ simulations are available. This opens up the possibility of performing reliable simulation-based inference using very expensive simulators, as we demonstrate on a problem from the field of cosmology where single simulations are computationally expensive. We show that Bayesian neural networks produce informative and well-calibrated posterior estimates with only a few hundred simulations.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15158",
        "abstract url": "https://arxiv.org/abs/2408.15158",
        "title": "Delay as Payoff in MAB",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we investigate a variant of the classical stochastic Multi-armed Bandit (MAB) problem, where the payoff received by an agent (either cost or reward) is both delayed, and directly corresponds to the magnitude of the delay. This setting models faithfully many real world scenarios such as the time it takes for a data packet to traverse a network given a choice of route (where delay serves as the agent's cost); or a user's time spent on a web page given a choice of content (where delay serves as the agent's reward). Our main contributions are tight upper and lower bounds for both the cost and reward settings. For the case that delays serve as costs, which we are the first to consider, we prove optimal regret that scales as $\\sum_{i:\u0394_i > 0}\\frac{\\log T}{\u0394_i} + d^*$, where $T$ is the maximal number of steps, $\u0394_i$ are the sub-optimality gaps and $d^*$ is the minimal expected delay amongst arms. For the case that delays serves as rewards, we show optimal regret of $\\sum_{i:\u0394_i > 0}\\frac{\\log T}{\u0394_i} + \\bar{d}$, where $\\bar d$ is the second maximal expected delay. These improve over the regret in the general delay-dependent payoff setting, which scales as $\\sum_{i:\u0394_i > 0}\\frac{\\log T}{\u0394_i} + D$, where $D$ is the maximum possible delay. Our regret bounds highlight the difference between the cost and reward scenarios, showing that the improvement in the cost scenario is more significant than for the reward. Finally, we accompany our theoretical results with an empirical evaluation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15162",
        "abstract url": "https://arxiv.org/abs/2408.15162",
        "title": "The networks of ingredient combination in cuisines around the world",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Investigating how different ingredients are combined in popular dishes is crucial to reveal the fundamental principles behind the formation of food preferences. Here, we use data from food repositories and network analysis to characterize worldwide cuisines. In our framework, each cuisine is represented as a network, where nodes correspond to ingredient types and weighted links describe how frequently pairs of ingredient types appear together in recipes. The networks of ingredient combinations reveal cuisine-specific patterns, highlighting similarities and differences in gastronomic preferences across different world regions. We find that popular ingredients, recurrent combinations, and the way they are organized within the backbone of the network provide a unique fingerprint for each cuisine. Hence, we demonstrate that networks of ingredient combinations are able to cluster global cuisines into meaningful geo-cultural groups, and can also be used to train models to uniquely identify a cuisine from a subset of its recipes. Our study advances our understanding of food combinations and helps uncover the geography of taste, paving the way for the creation of new and innovative recipes.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15165",
        "abstract url": "https://arxiv.org/abs/2408.15165",
        "title": "Latent Ewald summation for machine learning of long-range interactions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning interatomic potentials (MLIPs) often neglect long-range interactions, such as electrostatic and dispersion forces. In this work, we introduce a straightforward and efficient method to account for long-range interactions by learning a latent variable from local atomic descriptors and applying an Ewald summation to this variable. We demonstrate that in systems including charged, polar, or apolar molecular dimers, bulk water, and water-vapor interface, standard short-ranged MLIPs can lead to unphysical predictions even when employing message passing. The long-range models effectively eliminate these artifacts, with only about twice the computational cost of short-range MLIPs.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci",
            "physics.chem-ph",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15173",
        "abstract url": "https://arxiv.org/abs/2408.15173",
        "title": "Exploiting Approximate Symmetry for Efficient Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mean-field games (MFG) have become significant tools for solving large-scale multi-agent reinforcement learning problems under symmetry. However, the assumption of exact symmetry limits the applicability of MFGs, as real-world scenarios often feature inherent heterogeneity. Furthermore, most works on MFG assume access to a known MFG model, which might not be readily available for real-world finite-agent games. In this work, we broaden the applicability of MFGs by providing a methodology to extend any finite-player, possibly asymmetric, game to an \"induced MFG\". First, we prove that $N$-player dynamic games can be symmetrized and smoothly extended to the infinite-player continuum via explicit Kirszbraun extensions. Next, we propose the notion of $\u03b1,\u03b2$-symmetric games, a new class of dynamic population games that incorporate approximate permutation invariance. For $\u03b1,\u03b2$-symmetric games, we establish explicit approximation bounds, demonstrating that a Nash policy of the induced MFG is an approximate Nash of the $N$-player dynamic game. We show that TD learning converges up to a small bias using trajectories of the $N$-player game with finite-sample guarantees, permitting symmetrized learning without building an explicit MFG model. Finally, for certain games satisfying monotonicity, we prove a sample complexity of $\\widetilde{\\mathcal{O}}(\\varepsilon^{-6})$ for the $N$-agent game to learn an $\\varepsilon$-Nash up to symmetrization bias. Our theory is supported by evaluations on MARL benchmarks with thousands of agents.",
        "subjects": [
            "cs.GT",
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "comment": "5 figures"
    },
    {
        "paper id": "2408.15186",
        "abstract url": "https://arxiv.org/abs/2408.15186",
        "title": "Easy-access online social media metrics can effectively identify misinformation sharing users",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Misinformation poses a significant challenge studied extensively by researchers, yet acquiring data to identify primary sharers is costly and challenging. To address this, we propose a low-barrier approach to differentiate social media users who are more likely to share misinformation from those who are less likely. Leveraging insights from previous studies, we demonstrate that easy-access online social network metrics -- average daily tweet count, and account age -- can be leveraged to help identify potential low factuality content spreaders on X (previously known as Twitter). We find that higher tweet frequency is positively associated with low factuality in shared content, while account age is negatively associated with it. We also find that some of the effects, namely the effect of the number of accounts followed and the number of tweets produced, differ depending on the number of followers a user has. Our findings show that relying on these easy-access social network metrics could serve as a low-barrier approach for initial identification of users who are more likely to spread misinformation, and therefore contribute to combating misinformation effectively on social media platforms.",
        "subjects": [
            "cs.SI",
            "cs.CY",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15237",
        "abstract url": "https://arxiv.org/abs/2408.15237",
        "title": "The Mamba in the Llama: Distilling and Accelerating Hybrid Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Linear RNN architectures, like Mamba, can be competitive with Transformer models in language modeling while having advantageous deployment characteristics. Given the focus on training large-scale Transformer models, we consider the challenge of converting these pretrained models for deployment. We demonstrate that it is feasible to distill large Transformers into linear RNNs by reusing the linear projection weights from attention layers with academic GPU resources. The resulting hybrid model, which incorporates a quarter of the attention layers, achieves performance comparable to the original Transformer in chat benchmarks and outperforms open-source hybrid Mamba models trained from scratch with trillions of tokens in both chat benchmarks and general benchmarks. Moreover, we introduce a hardware-aware speculative decoding algorithm that accelerates the inference speed of Mamba and hybrid models. Overall we show how, with limited computation resources, we can remove many of the original attention layers and generate from the resulting model more efficiently. Our top-performing model, distilled from Llama3-8B-Instruct, achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and 7.35 on MT-Bench, surpassing the best instruction-tuned linear RNN model.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Code is open-sourced at https://github.com/jxiw/MambaInLlama"
    },
    {
        "paper id": "2408.15240",
        "abstract url": "https://arxiv.org/abs/2408.15240",
        "title": "Generative Verifiers: Reward Modeling as Next-Token Prediction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Verifiers or reward models are often used to enhance the reasoning performance of large language models (LLMs). A common approach is the Best-of-N method, where N candidate solutions generated by the LLM are ranked by a verifier, and the best one is selected. While LLM-based verifiers are typically trained as discriminative classifiers to score solutions, they do not utilize the text generation capabilities of pretrained LLMs. To overcome this limitation, we instead propose training verifiers using the ubiquitous next-token prediction objective, jointly on verification and solution generation. Compared to standard verifiers, such generative verifiers (GenRM) can benefit from several advantages of LLMs: they integrate seamlessly with instruction tuning, enable chain-of-thought reasoning, and can utilize additional inference-time compute via majority voting for better verification. We demonstrate that when using Gemma-based verifiers on algorithmic and grade-school math reasoning tasks, GenRM outperforms discriminative verifiers and LLM-as-a-Judge, showing a 16-64% improvement in the percentage of problems solved with Best-of-N. Furthermore, we show that GenRM scales favorably across dataset size, model capacity, and inference-time compute.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15299",
        "abstract url": "https://arxiv.org/abs/2408.15299",
        "title": "TourSynbio: A Multi-Modal Large Model and Agent Framework to Bridge Text and Protein Sequences for Protein Engineering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The structural similarities between protein sequences and natural languages have led to parallel advancements in deep learning across both domains. While large language models (LLMs) have achieved much progress in the domain of natural language processing, their potential in protein engineering remains largely unexplored. Previous approaches have equipped LLMs with protein understanding capabilities by incorporating external protein encoders, but this fails to fully leverage the inherent similarities between protein sequences and natural languages, resulting in sub-optimal performance and increased model complexity. To address this gap, we present TourSynbio-7B, the first multi-modal large model specifically designed for protein engineering tasks without external protein encoders. TourSynbio-7B demonstrates that LLMs can inherently learn to understand proteins as language. The model is post-trained and instruction fine-tuned on InternLM2-7B using ProteinLMDataset, a dataset comprising 17.46 billion tokens of text and protein sequence for self-supervised pretraining and 893K instructions for supervised fine-tuning. TourSynbio-7B outperforms GPT-4 on the ProteinLMBench, a benchmark of 944 manually verified multiple-choice questions, with 62.18% accuracy. Leveraging TourSynbio-7B's enhanced protein sequence understanding capability, we introduce TourSynbio-Agent, an innovative framework capable of performing various protein engineering tasks, including mutation analysis, inverse folding, protein folding, and visualization. TourSynbio-Agent integrates previously disconnected deep learning models in the protein engineering domain, offering a unified conversational user interface for improved usability. Finally, we demonstrate the efficacy of TourSynbio-7B and TourSynbio-Agent through two wet lab case studies on vanilla key enzyme modification and steroid compound catalysis.",
        "subjects": [
            "q-bio.BM",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15301",
        "abstract url": "https://arxiv.org/abs/2408.15301",
        "title": "The Uniqueness of LLaMA3-70B with Per-Channel Quantization: An Empirical Study",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We have observed a distinctive quantization-related behavior in the LLaMA3/3.1-70B models that is absent in both the LLaMA2-70B and LLaMA3/3.1-8B/405B models. Quantization is a crucial technique for deploying large language models (LLMs) efficiently. Among various bit widths and representations for weights and activations, the 8-bit integer weight and 8-bit integer activation (W8A8) configuration is particularly popular due to its widespread hardware support. However, the impact of W8A8 post-training quantization on model accuracy remains contentious. While several studies have suggested calibrating either weights or activations to mitigate accuracy degradation, a comprehensive solution has yet to be identified. In this paper, we empirically investigate multiple LLMs featured on an open LLM leaderboard, discovering that the LLaMA3-70B model series have a unique accuracy degradation behavior with W8A8 per-channel post-training quantization. In contrast, other model series such as LLaMA2, LLaMA3-8B, Qwen, Mixtral, Mistral, Phi-3, and Falcon demonstrate robust performance with W8A8, sometimes surpassing their FP16 counterparts. Contrary to previous assertions attributing degradation to the large dynamic range of activations, our findings indicate that the weight distribution of the LLaMA3-70B is the primary factor behind the vulnerability. By meticulously analyzing the distinct characteristics of weight distributions across Transformer blocks, we propose a mixed strategy with less than 3% of the layers enabling finer W8A8 quantization granularity, while the remaining 97% of layers retain the per-channel configuration. As a result, the average accuracy of LLaMA3-70B-W8A8 is increased from 45.5% to 73.4% (just 0.7% shy of LLaMA3-70B-FP16) across eight reasoning tasks. Notably, our method requires neither calibration nor fine-tuning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15308",
        "abstract url": "https://arxiv.org/abs/2408.15308",
        "title": "Antivax and off-label medication communities on brazilian Telegram: between esotericism as a gateway and the monetization of false miraculous cures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Conspiracy theories, particularly those focused on anti-vaccine narratives and the promotion of off-label medications such as MMS and CDS, have proliferated on Telegram, including in Brazil, finding fertile ground among communities that share esoteric beliefs and distrust towards scientific institutions. In this context, this study seeks to answer how Brazilian conspiracy theory communities on Telegram are characterized and articulated concerning anti-vaccine themes and off-label medications? It is important to highlight that this study is part of a series of seven studies aimed at understanding and characterizing Brazilian conspiracy theory communities on Telegram. This series of seven studies is openly and originally available on the arXiv of Cornell University, applying a mirrored method across all studies, changing only the thematic object of analysis and providing replicable research, including proprietary and original codes developed, contributing to the culture of free and open-source software. Regarding the main findings of this study, it was observed: Themes such as the New World Order and Apocalypse and Survivalism act as significant gateways to anti-vaccine narratives, connecting them to theories of global control; Globalism and New World Order stand out as the main communities receiving invitations from anti-vaccine communities; Occultism and Esotericism emerge as the largest sources of invitations to off-label medication communities, creating a strong connection between esoteric beliefs and the promotion of non-scientific treatments; Anti-vaccine narratives experienced a 290% increase during the COVID-19 pandemic, evidencing a growing interconnectedness with other conspiracy theories; The overlap of themes between anti-vaccine and other conspiracy theories creates an interdependent disinformation network, where different narratives mutually reinforce each other.",
        "subjects": [
            "cs.CY",
            "cs.SI"
        ],
        "comment": "57 pages, 15 figures, #DataConspiraProject"
    },
    {
        "paper id": "2408.15311",
        "abstract url": "https://arxiv.org/abs/2408.15311",
        "title": "Climate change denial and anti-science communities on brazilian Telegram: climate disinformation as a gateway to broader conspiracy networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Conspiracy theories related to climate change denial and anti-science have found fertile ground on Telegram, particularly among Brazilian communities that distrust scientific institutions and oppose global environmental policies. This study seeks to answer the research question: how are Brazilian conspiracy theory communities on climate change and anti-science themes characterized and articulated on Telegram? It is worth noting that this study is part of a series of seven studies aimed at understanding and characterizing Brazilian conspiracy theory communities on Telegram. This series of studies is openly and originally available on arXiv from Cornell University, applying a mirrored method across all seven studies, changing only the thematic focus of analysis, and providing replicable investigation methods, including custom-developed and proprietary codes, contributing to the culture of open-source software. Regarding the main findings of this study, the following observations were made: Climate change denial and anti-science communities interact synergistically, creating a complex network that mutually reinforces disinformation narratives; Apocalyptic themes, such as Apocalypse and Survivalism, act as gateways to climate denial, with 5,057 links directed to these communities; Anti-science communities function as gatekeepers, distributing links evenly to theories such as the New World Order and Globalism, among others; During the COVID-19 pandemic, anti-science discussions experienced a significant peak, driven by vaccine disinformation; The intersection between anti-science narratives and esoteric beliefs reinforces the idea of a supposed alternative truth that challenges science; Since 2022, discussions on climate change have evolved to align with global domination theories; Additionally, the UN's 2030 Agenda is portrayed as part of a global conspiracy.",
        "subjects": [
            "cs.CY",
            "cs.SI"
        ],
        "comment": "55 pages, 15 figures, #DataConspiraProject"
    },
    {
        "paper id": "2408.15332",
        "abstract url": "https://arxiv.org/abs/2408.15332",
        "title": "What makes math problems hard for reinforcement learning: a case study",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Using a long-standing conjecture from combinatorial group theory, we explore, from multiple angles, the challenges of finding rare instances carrying disproportionately high rewards. Based on lessons learned in the mathematical context defined by the Andrews-Curtis conjecture, we propose algorithmic improvements that can be relevant in other domains with ultra-sparse reward problems. Although our case study can be formulated as a game, its shortest winning sequences are potentially $10^6$ or $10^9$ times longer than those encountered in chess. In the process of our study, we demonstrate that one of the potential counterexamples due to Akbulut and Kirby, whose status escaped direct mathematical methods for 39 years, is stably AC-trivial.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.CO",
            "math.GR",
            "math.GT"
        ],
        "comment": "39 pages, 18 figures, 1 table"
    },
    {
        "paper id": "2408.15344",
        "abstract url": "https://arxiv.org/abs/2408.15344",
        "title": "Conformal Disentanglement: A Neural Framework for Perspective Synthesis and Differentiation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "For multiple scientific endeavors it is common to measure a phenomenon of interest in more than one ways. We make observations of objects from several different perspectives in space, at different points in time; we may also measure different properties of a mixture using different types of instruments. After collecting this heterogeneous information, it is necessary to be able to synthesize a complete picture of what is `common' across its sources: the subject we ultimately want to study. However, isolated (`clean') observations of a system are not always possible: observations often contain information about other systems in its environment, or about the measuring instruments themselves. In that sense, each observation may contain information that `does not matter' to the original object of study; this `uncommon' information between sensors observing the same object may still be important, and decoupling it from the main signal(s) useful. We introduce a neural network autoencoder framework capable of both tasks: it is structured to identify `common' variables, and, making use of orthogonality constraints to define geometric independence, to also identify disentangled `uncommon' information originating from the heterogeneous sensors. We demonstrate applications in several computational examples.",
        "subjects": [
            "cs.LG",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15356",
        "abstract url": "https://arxiv.org/abs/2408.15356",
        "title": "Optimal level set estimation for non-parametric tournament and crowdsourcing problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Motivated by crowdsourcing, we consider a problem where we partially observe the correctness of the answers of $n$ experts on $d$ questions. In this paper, we assume that both the experts and the questions can be ordered, namely that the matrix $M$ containing the probability that expert $i$ answers correctly to question $j$ is bi-isotonic up to a permutation of it rows and columns. When $n=d$, this also encompasses the strongly stochastic transitive (SST) model from the tournament literature. Here, we focus on the relevant problem of deciphering small entries of $M$ from large entries of $M$, which is key in crowdsourcing for efficient allocation of workers to questions. More precisely, we aim at recovering a (or several) level set $p$ of the matrix up to a precision $h$, namely recovering resp. the sets of positions $(i,j)$ in $M$ such that $M_{ij}>p+h$ and $M_{i,j}<p-h$. We consider, as a loss measure, the number of misclassified entries. As our main result, we construct an efficient polynomial-time algorithm that turns out to be minimax optimal for this classification problem. This heavily contrasts with existing literature in the SST model where, for the stronger reconstruction loss, statistical-computational gaps have been conjectured. More generally, this shades light on the nature of statistical-computational gaps for permutations models.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15368",
        "abstract url": "https://arxiv.org/abs/2408.15368",
        "title": "Optimization Solution Functions as Deterministic Policies for Offline Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Offline reinforcement learning (RL) is a promising approach for many control applications but faces challenges such as limited data coverage and value function overestimation. In this paper, we propose an implicit actor-critic (iAC) framework that employs optimization solution functions as a deterministic policy (actor) and a monotone function over the optimal value of optimization as a critic. By encoding optimality in the actor policy, we show that the learned policies are robust to the suboptimality of the learned actor parameters via the exponentially decaying sensitivity (EDS) property. We obtain performance guarantees for the proposed iAC framework and show its benefits over general function approximation schemes. Finally, we validate the proposed framework on two real-world applications and show a significant improvement over state-of-the-art (SOTA) offline RL methods.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": "American Control Conference 2024"
    },
    {
        "paper id": "2408.15381",
        "abstract url": "https://arxiv.org/abs/2408.15381",
        "title": "On Stateful Value Factorization in Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Value factorization is a popular paradigm for designing scalable multi-agent reinforcement learning algorithms. However, current factorization methods make choices without full justification that may limit their performance. For example, the theory in prior work uses stateless (i.e., history) functions, while the practical implementations use state information -- making the motivating theory a mismatch for the implementation. Also, methods have built off of previous approaches, inheriting their architectures without exploring other, potentially better ones. To address these concerns, we formally analyze the theory of using the state instead of the history in current methods -- reconnecting theory and practice. We then introduce DuelMIX, a factorization algorithm that learns distinct per-agent utility estimators to improve performance and achieve full expressiveness. Experiments on StarCraft II micromanagement and Box Pushing tasks demonstrate the benefits of our intuitions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "22 pages, 9 figures, 4 tables"
    },
    {
        "paper id": "2408.15383",
        "abstract url": "https://arxiv.org/abs/2408.15383",
        "title": "An evidence-based and critical analysis of the Fediverse decentralization promises",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper examines the potential of the Fediverse, a federated network of social media and content platforms, to counter the centralization and dominance of commercial platforms on the social Web. We gather evidence from the technology powering the Fediverse (especially the ActivityPub protocol), current statistical data regarding Fediverse user distribution over instances, and the status of two older, similar, decentralized technologies: e-mail and the Web. Our findings suggest that Fediverse will face significant challenges in fulfilling its decentralization promises, potentially hindering its ability to positively impact the social Web on a large scale.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "5 pages, 1 figure, 1 table. Accepted at the 30th Brazilian Symposium on Multimedia and the Web"
    },
    {
        "paper id": "2408.15400",
        "abstract url": "https://arxiv.org/abs/2408.15400",
        "title": "Exploring the origins of switching dynamics in a multifunctional reservoir computer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The concept of multifunctionality has enabled reservoir computers (RCs), a type of dynamical system that is typically realised as an artificial neural network, to reconstruct multiple attractors simultaneously using the same set of trained weights. However there are many additional phenomena that arise when training a RC to reconstruct more than one attractor. Previous studies have found that, in certain cases, if the RC fails to reconstruct a coexistence of attractors then it exhibits a form of metastability whereby, without any external input, the state of the RC switches between different modes of behaviour that resemble properties of the attractors it failed to reconstruct. In this paper we explore the origins of these switching dynamics in a paradigmatic setting via the `seeing double' problem.",
        "subjects": [
            "math.DS",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "Preprint submitted to Frontiers in Network Physiology"
    },
    {
        "paper id": "2408.15421",
        "abstract url": "https://arxiv.org/abs/2408.15421",
        "title": "Simultaneous Training of First- and Second-Order Optimizers in Population-Based Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The tuning of hyperparameters in reinforcement learning (RL) is critical, as these parameters significantly impact an agent's performance and learning efficiency. Dynamic adjustment of hyperparameters during the training process can significantly enhance both the performance and stability of learning. Population-based training (PBT) provides a method to achieve this by continuously tuning hyperparameters throughout the training. This ongoing adjustment enables models to adapt to different learning stages, resulting in faster convergence and overall improved performance. In this paper, we propose an enhancement to PBT by simultaneously utilizing both first- and second-order optimizers within a single population. We conducted a series of experiments using the TD3 algorithm across various MuJoCo environments. Our results, for the first time, empirically demonstrate the potential of incorporating second-order optimizers within PBT-based RL. Specifically, the combination of the K-FAC optimizer with Adam led to up to a 10% improvement in overall performance compared to PBT using only Adam. Additionally, in environments where Adam occasionally fails, such as the Swimmer environment, the mixed population with K-FAC exhibited more reliable learning outcomes, offering a significant advantage in training stability without a substantial increase in computational time.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2408.15436",
        "abstract url": "https://arxiv.org/abs/2408.15436",
        "title": "Online Event-Triggered Switching for Frequency Control in Power Grids with Variable Inertia",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The increasing integration of renewable energy resources into power grids has led to time-varying system inertia and consequent degradation in frequency dynamics. A promising solution to alleviate performance degradation is using power electronics interfaced energy resources, such as renewable generators and battery energy storage for primary frequency control, by adjusting their power output set-points in response to frequency deviations. However, designing a frequency controller under time-varying inertia is challenging. Specifically, the stability or optimality of controllers designed for time-invariant systems can be compromised once applied to a time-varying system. We model the frequency dynamics under time-varying inertia as a nonlinear switching system, where the frequency dynamics under each mode are described by the nonlinear swing equations and different modes represent different inertia levels. We identify a key controller structure, named Neural Proportional-Integral (Neural-PI) controller, that guarantees exponential input-to-state stability for each mode. To further improve performance, we present an online event-triggered switching algorithm to select the most suitable controller from a set of Neural-PI controllers, each optimized for specific inertia levels. Simulations on the IEEE 39-bus system validate the effectiveness of the proposed online switching control method with stability guarantees and optimized performance for frequency control under time-varying inertia.",
        "subjects": [
            "eess.SY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15443",
        "abstract url": "https://arxiv.org/abs/2408.15443",
        "title": "Pathfinding with Lazy Successor Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We study a pathfinding problem where only locations (i.e., vertices) are given, and edges are implicitly defined by an oracle answering the connectivity of two locations. Despite its simple structure, this problem becomes non-trivial with a massive number of locations, due to posing a huge branching factor for search algorithms. Limiting the number of successors, such as with nearest neighbors, can reduce search efforts but compromises completeness. Instead, we propose a novel LaCAS* algorithm, which does not generate successors all at once but gradually generates successors as the search progresses. This scheme is implemented with k-nearest neighbors search on a k-d tree. LaCAS* is a complete and anytime algorithm that eventually converges to the optima. Extensive evaluations demonstrate the efficacy of LaCAS*, e.g., solving complex pathfinding instances quickly, where conventional methods falter.",
        "subjects": [
            "cs.AI",
            "cs.RO"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2408.15495",
        "abstract url": "https://arxiv.org/abs/2408.15495",
        "title": "Remove Symmetries to Control Model Expressivity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "When symmetry is present in the loss function, the model is likely to be trapped in a low-capacity state that is sometimes known as a \"collapse.\" Being trapped in these low-capacity states can be a major obstacle to training across many scenarios where deep learning technology is applied. We first prove two concrete mechanisms through which symmetries lead to reduced capacities and ignored features during training. We then propose a simple and theoretically justified algorithm, syre, to remove almost all symmetry-induced low-capacity states in neural networks. The proposed method is shown to improve the training of neural networks in scenarios when this type of entrapment is especially a concern. A remarkable merit of the proposed method is that it is model-agnostic and does not require any knowledge of the symmetry.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "preprint"
    },
    {
        "paper id": "2408.15507",
        "abstract url": "https://arxiv.org/abs/2408.15507",
        "title": "What Machine Learning Tells Us About the Mathematical Structure of Concepts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper examines the connections among various approaches to understanding concepts in philosophy, cognitive science, and machine learning, with a particular focus on their mathematical nature. By categorizing these approaches into Abstractionism, the Similarity Approach, the Functional Approach, and the Invariance Approach, the study highlights how each framework provides a distinct mathematical perspective for modeling concepts. The synthesis of these approaches bridges philosophical theories and contemporary machine learning models, providing a comprehensive framework for future research. This work emphasizes the importance of interdisciplinary dialogue, aiming to enrich our understanding of the complex relationship between human cognition and artificial intelligence.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "25 pages, 3 figures"
    },
    {
        "paper id": "2408.15524",
        "abstract url": "https://arxiv.org/abs/2408.15524",
        "title": "Ray-Distance Volume Rendering for Neural Scene Reconstruction",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "SDF"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Existing methods in neural scene reconstruction utilize the Signed Distance Function (SDF) to model the density function. However, in indoor scenes, the density computed from the SDF for a sampled point may not consistently reflect its real importance in volume rendering, often due to the influence of neighboring objects. To tackle this issue, our work proposes a novel approach for indoor scene reconstruction, which instead parameterizes the density function with the Signed Ray Distance Function (SRDF). Firstly, the SRDF is predicted by the network and transformed to a ray-conditioned density function for volume rendering. We argue that the ray-specific SRDF only considers the surface along the camera ray, from which the derived density function is more consistent to the real occupancy than that from the SDF. Secondly, although SRDF and SDF represent different aspects of scene geometries, their values should share the same sign indicating the underlying spatial occupancy. Therefore, this work introduces a SRDF-SDF consistency loss to constrain the signs of the SRDF and SDF outputs. Thirdly, this work proposes a self-supervised visibility task, introducing the physical visibility geometry to the reconstruction task. The visibility task combines prior from predicted SRDF and SDF as pseudo labels, and contributes to generating more accurate 3D geometry. Our method implemented with different representations has been validated on indoor datasets, achieving improved performance in both reconstruction and view synthesis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV2024"
    },
    {
        "paper id": "2408.16027",
        "abstract url": "https://arxiv.org/abs/2408.16027",
        "title": "Toward Time-Continuous Data Inference in Sparse Urban CrowdSensing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Mobile Crowd Sensing (MCS) is a promising paradigm that leverages mobile users and their smart portable devices to perform various real-world tasks. However, due to budget constraints and the inaccessibility of certain areas, Sparse MCS has emerged as a more practical alternative, collecting data from a limited number of target subareas and utilizing inference algorithms to complete the full sensing map. While existing approaches typically assume a time-discrete setting with data remaining constant within each sensing cycle, this simplification can introduce significant errors, especially when dealing with long cycles, as real-world sensing data often changes continuously. In this paper, we go from fine-grained completion, i.e., the subdivision of sensing cycles into minimal time units, towards a more accurate, time-continuous completion. We first introduce Deep Matrix Factorization (DMF) as a neural network-enabled framework and enhance it with a Recurrent Neural Network (RNN-DMF) to capture temporal correlations in these finer time slices. To further deal with the continuous data, we propose TIME-DMF, which captures temporal information across unequal intervals, enabling time-continuous completion. Additionally, we present the Query-Generate (Q-G) strategy within TIME-DMF to model the infinite states of continuous data. Extensive experiments across five types of sensing tasks demonstrate the effectiveness of our models and the advantages of time-continuous completion.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NI"
        ],
        "comment": "11 pages, 11 figures"
    },
    {
        "paper id": "2408.16029",
        "abstract url": "https://arxiv.org/abs/2408.16029",
        "title": "Meta-Learn Unimodal Signals with Weak Supervision for Multimodal Sentiment Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Multimodal sentiment analysis aims to effectively integrate information from various sources to infer sentiment, where in many cases there are no annotations for unimodal labels. Therefore, most works rely on multimodal labels for training. However, there exists the noisy label problem for the learning of unimodal signals as multimodal annotations are not always the ideal substitutes for the unimodal ones, failing to achieve finer optimization for individual modalities. In this paper, we explore the learning of unimodal labels under the weak supervision from the annotated multimodal labels. Specifically, we propose a novel meta uni-label generation (MUG) framework to address the above problem, which leverages the available multimodal labels to learn the corresponding unimodal labels by the meta uni-label correction network (MUCN). We first design a contrastive-based projection module to bridge the gap between unimodal and multimodal representations, so as to use multimodal annotations to guide the learning of MUCN. Afterwards, we propose unimodal and multimodal denoising tasks to train MUCN with explicit supervision via a bi-level optimization strategy. We then jointly train unimodal and multimodal learning tasks to extract discriminative unimodal features for multimodal inference. Experimental results suggest that MUG outperforms competitive baselines and can learn accurate unimodal labels.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.16088",
        "abstract url": "https://arxiv.org/abs/2408.16088",
        "title": "Ensuring Equitable Financial Decisions: Leveraging Counterfactual Fairness and Deep Learning for Bias",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Concerns regarding fairness and bias have been raised in recent years due to the growing use of machine learning models in crucial decision-making processes, especially when it comes to delicate characteristics like gender. In order to address biases in machine learning models, this research paper investigates advanced bias mitigation techniques, with a particular focus on counterfactual fairness in conjunction with data augmentation. The study looks into how these integrated approaches can lessen gender bias in the financial industry, specifically in loan approval procedures. We show that these approaches are effective in achieving more equitable results through thorough testing and assessment on a skewed financial dataset. The findings emphasize how crucial it is to use fairness-aware techniques when creating machine learning models in order to guarantee morally righteous and impartial decision-making.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "8 pages, 7 figures"
    },
    {
        "paper id": "2408.14809",
        "abstract url": "https://arxiv.org/abs/2408.14809",
        "title": "GSIFN: A Graph-Structured and Interlaced-Masked Multimodal Transformer Based Fusion Network for Multimodal Sentiment Analysis",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal Sentiment Analysis (MSA) leverages multiple modals to analyze sentiments. Typically, advanced fusion methods and representation learning-based methods are designed to tackle it. Our proposed GSIFN solves two key problems to be solved in MSA: (i) In multimodal fusion, the decoupling of modal combinations and tremendous parameter redundancy in existing fusion methods, which lead to poor fusion performance and efficiency. (ii) The trade-off between representation capability and computation overhead of the unimodal feature extractors and enhancers. GSIFN incorporates two main components to solve these problems: (i) Graph-Structured and Interlaced-Masked Multimodal Transformer. It adopts the Interlaced Mask mechanism to construct robust multimodal graph embedding, achieve all-modal-in-one Transformer-based fusion, and greatly reduce the computation overhead. (ii) A self-supervised learning framework with low computation overhead and high performance, which utilizes a parallelized LSTM with matrix memory to enhance non-verbal modal feature for unimodal label generation. Evaluated on the MSA datasets CMU-MOSI, CMU-MOSEI, and CH-SIMS, GSIFN demonstrates superior performance with significantly lower computation overhead compared with state-of-the-art methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14823",
        "abstract url": "https://arxiv.org/abs/2408.14823",
        "title": "LapisGS: Layered Progressive 3D Gaussian Splatting for Adaptive Streaming",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rise of Extended Reality (XR) requires efficient streaming of 3D online worlds, challenging current 3DGS representations to adapt to bandwidth-constrained environments. This paper proposes LapisGS, a layered 3DGS that supports adaptive streaming and progressive rendering. Our method constructs a layered structure for cumulative representation, incorporates dynamic opacity optimization to maintain visual fidelity, and utilizes occupancy maps to efficiently manage Gaussian splats. This proposed model offers a progressive representation supporting a continuous rendering quality adapted for bandwidth-aware streaming. Extensive experiments validate the effectiveness of our approach in balancing visual fidelity with the compactness of the model, with up to 50.71% improvement in SSIM, 286.53% improvement in LPIPS, and 318.41% reduction in model size, and shows its potential for bandwidth-adapted 3D streaming and rendering applications.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14837",
        "abstract url": "https://arxiv.org/abs/2408.14837",
        "title": "Diffusion Models Are Real-Time Game Engines",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present GameNGen, the first game engine powered entirely by a neural model that enables real-time interaction with a complex environment over long trajectories at high quality. GameNGen can interactively simulate the classic game DOOM at over 20 frames per second on a single TPU. Next frame prediction achieves a PSNR of 29.4, comparable to lossy JPEG compression. Human raters are only slightly better than random chance at distinguishing short clips of the game from clips of the simulation. GameNGen is trained in two phases: (1) an RL-agent learns to play the game and the training sessions are recorded, and (2) a diffusion model is trained to produce the next frame, conditioned on the sequence of past frames and actions. Conditioning augmentations enable stable auto-regressive generation over long trajectories.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Project page: https://gamengen.github.io/"
    },
    {
        "paper id": "2408.14840",
        "abstract url": "https://arxiv.org/abs/2408.14840",
        "title": "CL4KGE: A Curriculum Learning Method for Knowledge Graph Embedding",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge graph embedding (KGE) constitutes a foundational task, directed towards learning representations for entities and relations within knowledge graphs (KGs), with the objective of crafting representations comprehensive enough to approximate the logical and symbolic interconnections among entities. In this paper, we define a metric Z-counts to measure the difficulty of training each triple ($<$head entity, relation, tail entity$>$) in KGs with theoretical analysis. Based on this metric, we propose \\textbf{CL4KGE}, an efficient \\textbf{C}urriculum \\textbf{L}earning based training strategy for \\textbf{KGE}. This method includes a difficulty measurer and a training scheduler that aids in the training of KGE models. Our approach possesses the flexibility to act as a plugin within a wide range of KGE models, with the added advantage of adaptability to the majority of KGs in existence. The proposed method has been evaluated on popular KGE models, and the results demonstrate that it enhances the state-of-the-art methods. The use of Z-counts as a metric has enabled the identification of challenging triples in KGs, which helps in devising effective training strategies.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "16 pages, 3 figures"
    },
    {
        "paper id": "2408.14841",
        "abstract url": "https://arxiv.org/abs/2408.14841",
        "title": "Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Out-of-distribution (OOD) detection, which determines whether a given sample is part of the in-distribution (ID), has recently shown promising results through training with synthetic OOD datasets. Nonetheless, existing methods often produce outliers that are considerably distant from the ID, showing limited efficacy for capturing subtle distinctions between ID and OOD. To address these issues, we propose a novel framework, Semantic Outlier generation via Nuisance Awareness (SONA), which notably produces challenging outliers by directly leveraging pixel-space ID samples through diffusion models. Our approach incorporates SONA guidance, providing separate control over semantic and nuisance regions of ID samples. Thereby, the generated outliers achieve two crucial properties: (i) they present explicit semantic-discrepant information, while (ii) maintaining various levels of nuisance resemblance with ID. Furthermore, the improved OOD detector training with SONA outliers facilitates learning with a focus on semantic distinctions. Extensive experiments demonstrate the effectiveness of our framework, achieving an impressive AUROC of 88% on near-OOD datasets, which surpasses the performance of baseline methods by a significant margin of approximately 6%.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14853",
        "abstract url": "https://arxiv.org/abs/2408.14853",
        "title": "Detecting AI Flaws: Target-Driven Attacks on Internal Faults in Language Models",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have become a focal point in the rapidly evolving field of artificial intelligence. However, a critical concern is the presence of toxic content within the pre-training corpus of these models, which can lead to the generation of inappropriate outputs. Investigating methods for detecting internal faults in LLMs can help us understand their limitations and improve their security. Existing methods primarily focus on jailbreaking attacks, which involve manually or automatically constructing adversarial content to prompt the target LLM to generate unexpected responses. These methods rely heavily on prompt engineering, which is time-consuming and usually requires specially designed questions. To address these challenges, this paper proposes a target-driven attack paradigm that focuses on directly eliciting the target response instead of optimizing the prompts. We introduce the use of another LLM as the detector for toxic content, referred to as ToxDet. Given a target toxic response, ToxDet can generate a possible question and a preliminary answer to provoke the target model into producing desired toxic responses with meanings equivalent to the provided one. ToxDet is trained by interacting with the target LLM and receiving reward signals from it, utilizing reinforcement learning for the optimization process. While the primary focus of the target models is on open-source LLMs, the fine-tuned ToxDet can also be transferred to attack black-box models such as GPT-4o, achieving notable results. Experimental results on AdvBench and HH-Harmless datasets demonstrate the effectiveness of our methods in detecting the tendencies of target LLMs to generate harmful responses. This algorithm not only exposes vulnerabilities but also provides a valuable resource for researchers to strengthen their models against such attacks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14908",
        "abstract url": "https://arxiv.org/abs/2408.14908",
        "title": "Tripl\u00e8toile: Extraction of Knowledge from Microblogging Text",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Numerous methods and pipelines have recently emerged for the automatic extraction of knowledge graphs from documents such as scientific publications and patents. However, adapting these methods to incorporate alternative text sources like micro-blogging posts and news has proven challenging as they struggle to model open-domain entities and relations, typically found in these sources. In this paper, we propose an enhanced information extraction pipeline tailored to the extraction of a knowledge graph comprising open-domain entities from micro-blogging posts on social media platforms. Our pipeline leverages dependency parsing and classifies entity relations in an unsupervised manner through hierarchical clustering over word embeddings. We provide a use case on extracting semantic triples from a corpus of 100 thousand tweets about digital transformation and publicly release the generated knowledge graph. On the same dataset, we conduct two experimental evaluations, showing that the system produces triples with precision over 95% and outperforms similar pipelines of around 5% in terms of precision, while generating a comparatively higher number of triples.",
        "subjects": [
            "cs.IR",
            "cs.CE",
            "cs.CL"
        ],
        "comment": "42 pages, 6 figures"
    },
    {
        "paper id": "2408.14975",
        "abstract url": "https://arxiv.org/abs/2408.14975",
        "title": "MegActor-$\u03a3$: Unlocking Flexible Mixed-Modal Control in Portrait Animation with Diffusion Transformer",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have demonstrated superior performance in the field of portrait animation. However, current approaches relied on either visual or audio modality to control character movements, failing to exploit the potential of mixed-modal control. This challenge arises from the difficulty in balancing the weak control strength of audio modality and the strong control strength of visual modality. To address this issue, we introduce MegActor-$\u03a3$: a mixed-modal conditional diffusion transformer (DiT), which can flexibly inject audio and visual modality control signals into portrait animation. Specifically, we make substantial advancements over its predecessor, MegActor, by leveraging the promising model structure of DiT and integrating audio and visual conditions through advanced modules within the DiT framework. To further achieve flexible combinations of mixed-modal control signals, we propose a ``Modality Decoupling Control\" training strategy to balance the control strength between visual and audio modalities, along with the ``Amplitude Adjustment\" inference strategy to freely regulate the motion amplitude of each modality. Finally, to facilitate extensive studies in this field, we design several dataset evaluation metrics to filter out public datasets and solely use this filtered dataset to train MegActor-$\u03a3$. Extensive experiments demonstrate the superiority of our approach in generating vivid portrait animations, outperforming previous methods trained on private dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15011",
        "abstract url": "https://arxiv.org/abs/2408.15011",
        "title": "Pre-training Everywhere: Parameter-Efficient Fine-Tuning for Medical Image Analysis via Target Parameter Pre-training",
        "rating": "0",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Parameter-efficient fine-tuning (PEFT) techniques have emerged to address issues of overfitting and high computational costs associated with fully fine-tuning in the paradigm of self-supervised learning. Mainstream methods based on PEFT involve adding a few trainable parameters while keeping the pre-trained parameters of the backbone fixed. These methods achieve comparative, and often superior, performance to fully fine-tuning, demonstrating the powerful representation ability of the pre-trained backbone. Despite its success, these methods typically ignore the initialization of the new parameters, often relying solely on random initialization. We argue that if pre-training is significantly beneficial, it should be applied to all parameters requiring representational capacity. Motivated by this insight, we propose a simple yet effective fine-tuning framework based on Target Parameter Pre-training (TPP). The target parameters refer to the new parameters introduced during fine-tuning. TPP includes an additional stage before PEFT to pre-train these target parameters. During this stage, the pre-trained backbone parameters are frozen, and only the target parameters are trainable. A defined pre-text task is used to encourage the target parameters to learn specific representations of downstream data. When PEFT is subsequently employed, the pre-trained target parameters are loaded to enhance fine-tuning efficiency. The proposed TPP framework is versatile, allowing for the integration of various pretext tasks for pre-training and supporting different PEFT methods as backbones. We evaluated the fine-tining performance of our method using five public datasets, including three modalities and two task types. The results demonstrate that the proposed TPP can be easily integrated into existing PEFT methods, significantly improving performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15020",
        "abstract url": "https://arxiv.org/abs/2408.15020",
        "title": "Hierarchical Graph Interaction Transformer with Dynamic Token Clustering for Camouflaged Object Detection",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Camouflaged object detection (COD) aims to identify the objects that seamlessly blend into the surrounding backgrounds. Due to the intrinsic similarity between the camouflaged objects and the background region, it is extremely challenging to precisely distinguish the camouflaged objects by existing approaches. In this paper, we propose a hierarchical graph interaction network termed HGINet for camouflaged object detection, which is capable of discovering imperceptible objects via effective graph interaction among the hierarchical tokenized features. Specifically, we first design a region-aware token focusing attention (RTFA) with dynamic token clustering to excavate the potentially distinguishable tokens in the local region. Afterwards, a hierarchical graph interaction transformer (HGIT) is proposed to construct bi-directional aligned communication between hierarchical features in the latent interaction space for visual semantics enhancement. Furthermore, we propose a decoder network with confidence aggregated feature fusion (CAFF) modules, which progressively fuses the hierarchical interacted features to refine the local detail in ambiguous regions. Extensive experiments conducted on the prevalent datasets, i.e. COD10K, CAMO, NC4K and CHAMELEON demonstrate the superior performance of HGINet compared to existing state-of-the-art methods. Our code is available at https://github.com/Garyson1204/HGINet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Submitted to IEEE Transactions on Image Processing"
    },
    {
        "paper id": "2408.15038",
        "abstract url": "https://arxiv.org/abs/2408.15038",
        "title": "Interactive Occlusion Boundary Estimation through Exploitation of Synthetic Data",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Occlusion boundaries (OBs) geometrically localize the occlusion events in a 2D image, and contain useful information for addressing various scene understanding problems. To advance their study, we have led the investigation in the following three aspects. Firstly, we have studied interactive estimation of OBs, which is the first in the literature, and proposed an efficient deep-network-based method using multiple-scribble intervention, named DNMMSI, which significantly improves the performance over the state-of-the-art fully-automatic methods. Secondly, we propose to exploit the synthetic benchmark for the training process, thanks to the particularity that OBs are determined geometrically and unambiguously from the 3D scene. To this end, we have developed an efficient tool, named Mesh2OB, for the automatic generation of 2D images together with their ground-truth OBs, using which we have constructed a synthetic benchmark, named OB-FUTURE. Abundant experimental results demonstrate that leveraging such a synthetic benchmark for training achieves promising performance, even without the use of domain adaptation techniques. Finally, to achieve a more compelling and robust evaluation in OB-related research, we have created a real benchmark, named OB-LabName, consisting of 120 high-resolution images together with their ground-truth OBs, with precision surpassing that of previous benchmarks. We will release DNMMSI with pre-trained parameters, Mesh2OB, OB-FUTURE, and OB-LabName to support further research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15077",
        "abstract url": "https://arxiv.org/abs/2408.15077",
        "title": "MMASD+: A Novel Dataset for Privacy-Preserving Behavior Analysis of Children with Autism Spectrum Disorder",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Skeleton"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Autism spectrum disorder (ASD) is characterized by significant challenges in social interaction and comprehending communication signals. Recently, therapeutic interventions for ASD have increasingly utilized Deep learning powered-computer vision techniques to monitor individual progress over time. These models are trained on private, non-public datasets from the autism community, creating challenges in comparing results across different models due to privacy-preserving data-sharing issues. This work introduces MMASD+, an enhanced version of the novel open-source dataset called Multimodal ASD (MMASD). MMASD+ consists of diverse data modalities, including 3D-Skeleton, 3D Body Mesh, and Optical Flow data. It integrates the capabilities of Yolov8 and Deep SORT algorithms to distinguish between the therapist and children, addressing a significant barrier in the original dataset. Additionally, a Multimodal Transformer framework is proposed to predict 11 action types and the presence of ASD. This framework achieves an accuracy of 95.03% for predicting action types and 96.42% for predicting ASD presence, demonstrating over a 10% improvement compared to models trained on single data modalities. These findings highlight the advantages of integrating multiple data modalities within the Multimodal Transformer framework.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15091",
        "abstract url": "https://arxiv.org/abs/2408.15091",
        "title": "Relation Also Knows: Rethinking the Recall and Editing of Factual Associations in Auto-Regressive Transformer Language Models",
        "rating": "0",
        "keywords": [
            [
                "knowledge editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The storage and recall of factual associations in auto-regressive transformer language models (LMs) have drawn a great deal of attention, inspiring knowledge editing by directly modifying the located model weights. Most editing works achieve knowledge editing under the guidance of existing interpretations of knowledge recall that mainly focus on subject knowledge. However, these interpretations are seriously flawed, neglecting relation information and leading to the over-generalizing problem for editing. In this work, we discover a novel relation-focused perspective to interpret the knowledge recall of transformer LMs during inference and apply it on knowledge editing to avoid over-generalizing. Experimental results on the dataset supplemented with a new R-Specificity criterion demonstrate that our editing approach significantly alleviates over-generalizing while remaining competitive on other criteria, breaking the domination of subject-focused editing for future research.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15094",
        "abstract url": "https://arxiv.org/abs/2408.15094",
        "title": "Constrained Diffusion Models via Dual Training",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have attained prominence for their ability to synthesize a probability distribution for a given dataset via a diffusion process, enabling the generation of new data points with high fidelity. However, diffusion processes are prone to generating biased data based on the training dataset. To address this issue, we develop constrained diffusion models by imposing diffusion constraints based on desired distributions that are informed by requirements. Specifically, we cast the training of diffusion models under requirements as a constrained distribution optimization problem that aims to reduce the distribution difference between original and generated data while obeying constraints on the distribution of generated data. We show that our constrained diffusion models generate new data from a mixture data distribution that achieves the optimal trade-off among objective and constraints. To train constrained diffusion models, we develop a dual training algorithm and characterize the optimality of the trained constrained diffusion model. We empirically demonstrate the effectiveness of our constrained models in two constrained generation tasks: (i) we consider a dataset with one or more underrepresented classes where we train the model with constraints to ensure fairly sampling from all classes during inference; (ii) we fine-tune a pre-trained diffusion model to sample from a new dataset while avoiding overfitting.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "math.OC"
        ],
        "comment": "41 pages, 4 figures, 2 tables"
    },
    {
        "paper id": "2408.15098",
        "abstract url": "https://arxiv.org/abs/2408.15098",
        "title": "CLIP-AGIQA: Boosting the Performance of AI-Generated Image Quality Assessment with CLIP",
        "rating": "0",
        "keywords": [
            [
                "visual language"
            ],
            [
                "Quality Assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the rapid development of generative technologies, AI-Generated Images (AIGIs) have been widely applied in various aspects of daily life. However, due to the immaturity of the technology, the quality of the generated images varies, so it is important to develop quality assessment techniques for the generated images. Although some models have been proposed to assess the quality of generated images, they are inadequate when faced with the ever-increasing and diverse categories of generated images. Consequently, the development of more advanced and effective models for evaluating the quality of generated images is urgently needed. Recent research has explored the significant potential of the visual language model CLIP in image quality assessment, finding that it performs well in evaluating the quality of natural images. However, its application to generated images has not been thoroughly investigated. In this paper, we build on this idea and further explore the potential of CLIP in evaluating the quality of generated images. We design CLIP-AGIQA, a CLIP-based regression model for quality assessment of generated images, leveraging rich visual and textual knowledge encapsulated in CLIP. Particularly, we implement multi-category learnable prompts to fully utilize the textual knowledge in CLIP for quality assessment. Extensive experiments on several generated image quality assessment benchmarks, including AGIQA-3K and AIGCIQA2023, demonstrate that CLIP-AGIQA outperforms existing IQA models, achieving excellent results in evaluating the quality of generated images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted by ICPR2024"
    },
    {
        "paper id": "2408.15103",
        "abstract url": "https://arxiv.org/abs/2408.15103",
        "title": "Enhancing License Plate Super-Resolution: A Layout-Aware and Character-Driven Approach",
        "rating": "0",
        "keywords": [
            [
                "GAN",
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite significant advancements in License Plate Recognition (LPR) through deep learning, most improvements rely on high-resolution images with clear characters. This scenario does not reflect real-world conditions where traffic surveillance often captures low-resolution and blurry images. Under these conditions, characters tend to blend with the background or neighboring characters, making accurate LPR challenging. To address this issue, we introduce a novel loss function, Layout and Character Oriented Focal Loss (LCOFL), which considers factors such as resolution, texture, and structural details, as well as the performance of the LPR task itself. We enhance character feature learning using deformable convolutions and shared weights in an attention module and employ a GAN-based training approach with an Optical Character Recognition (OCR) model as the discriminator to guide the super-resolution process. Our experimental results show significant improvements in character reconstruction quality, outperforming two state-of-the-art methods in both quantitative and qualitative measures. Our code is publicly available at https://github.com/valfride/lpsr-lacd",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for presentation at the Conference on Graphics, Patterns and Images (SIBGRAPI) 2024"
    },
    {
        "paper id": "2408.15122",
        "abstract url": "https://arxiv.org/abs/2408.15122",
        "title": "Machine Learning for Methane Detection and Quantification from Space - A survey",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Methane ($CH_4$) is a potent anthropogenic greenhouse gas, contributing 86 times more to global warming than Carbon Dioxide ($CO_2$) over 20 years, and it also acts as an air pollutant. Given its high radiative forcing potential and relatively short atmospheric lifetime (9$\\pm$1 years), methane has important implications for climate change, therefore, cutting methane emissions is crucial for effective climate change mitigation. This work expands existing information on operational methane point source detection sensors in the Short-Wave Infrared (SWIR) bands. It reviews the state-of-the-art for traditional as well as Machine Learning (ML) approaches. The architecture and data used in such ML models will be discussed separately for methane plume segmentation and emission rate estimation. Traditionally, experts rely on labor-intensive manually adjusted methods for methane detection. However, ML approaches offer greater scalability. Our analysis reveals that ML models outperform traditional methods, particularly those based on convolutional neural networks (CNN), which are based on the U-net and transformer architectures. These ML models extract valuable information from methane-sensitive spectral data, enabling a more accurate detection. Challenges arise when comparing these methods due to variations in data, sensor specifications, and evaluation metrics. To address this, we discuss existing datasets and metrics, providing an overview of available resources and identifying open research problems. Finally, we explore potential future advances in ML, emphasizing approaches for model comparability, large dataset creation, and the European Union's forthcoming methane strategy.",
        "subjects": [
            "cs.CV",
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15185",
        "abstract url": "https://arxiv.org/abs/2408.15185",
        "title": "PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Video Anomaly Detection (VAD) presents a significant challenge in computer vision, particularly due to the unpredictable and infrequent nature of anomalous events, coupled with the diverse and dynamic environments in which they occur. Human-centric VAD, a specialized area within this domain, faces additional complexities, including variations in human behavior, potential biases in data, and substantial privacy concerns related to human subjects. These issues complicate the development of models that are both robust and generalizable. To address these challenges, recent advancements have focused on pose-based VAD, which leverages human pose as a high-level feature to mitigate privacy concerns, reduce appearance biases, and minimize background interference. In this paper, we introduce PoseWatch, a novel transformer-based architecture designed specifically for human-centric pose-based VAD. PoseWatch features an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP) tokenization method that enhances the representation of human motion over time, which is also beneficial for broader human behavior analysis tasks. The architecture's core, a Unified Encoder Twin Decoders (UETD) transformer, significantly improves the detection of anomalous behaviors in video data. Extensive evaluations across multiple benchmark datasets demonstrate that PoseWatch consistently outperforms existing methods, establishing a new state-of-the-art in pose-based VAD. This work not only demonstrates the efficacy of PoseWatch but also highlights the potential of integrating Natural Language Processing techniques with computer vision to advance human behavior analysis.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15239",
        "abstract url": "https://arxiv.org/abs/2408.15239",
        "title": "Generative Inbetweening: Adapting Image-to-Video Models for Keyframe Interpolation",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present a method for generating video sequences with coherent motion between a pair of input key frames. We adapt a pretrained large-scale image-to-video diffusion model (originally trained to generate videos moving forward in time from a single input image) for key frame interpolation, i.e., to produce a video in between two input frames. We accomplish this adaptation through a lightweight fine-tuning technique that produces a version of the model that instead predicts videos moving backwards in time from a single input image. This model (along with the original forward-moving model) is subsequently used in a dual-directional diffusion sampling process that combines the overlapping model estimates starting from each of the two keyframes. Our experiments show that our method outperforms both existing diffusion-based methods and traditional frame interpolation techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "project page: https://svd-keyframe-interpolation.github.io/"
    },
    {
        "paper id": "2408.15241",
        "abstract url": "https://arxiv.org/abs/2408.15241",
        "title": "GenRec: Unifying Video Generation and Recognition with Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video diffusion models are able to generate high-quality videos by learning strong spatial-temporal priors on large-scale datasets. In this paper, we aim to investigate whether such priors derived from a generative process are suitable for video recognition, and eventually joint optimization of generation and recognition. Building upon Stable Video Diffusion, we introduce GenRec, the first unified framework trained with a random-frame conditioning process so as to learn generalized spatial-temporal representations. The resulting framework can naturally supports generation and recognition, and more importantly is robust even when visual inputs contain limited information. Extensive experiments demonstrate the efficacy of GenRec for both recognition and generation. In particular, GenRec achieves competitive recognition performance, offering 75.8% and 87.2% accuracy on SSV2 and K400, respectively. GenRec also performs the best class-conditioned image-to-video generation results, achieving 46.5 and 49.3 FVD scores on SSV2 and EK-100 datasets. Furthermore, GenRec demonstrates extraordinary robustness in scenarios that only limited frames can be observed.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "17 pages, 6 figures, 7 tables"
    },
    {
        "paper id": "2408.15293",
        "abstract url": "https://arxiv.org/abs/2408.15293",
        "title": "Learning Granularity Representation for Temporal Knowledge Graph Completion",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Temporal Knowledge Graphs (TKGs) incorporate temporal information to reflect the dynamic structural knowledge and evolutionary patterns of real-world facts. Nevertheless, TKGs are still limited in downstream applications due to the problem of incompleteness. Consequently, TKG completion (also known as link prediction) has been widely studied, with recent research focusing on incorporating independent embeddings of time or combining them with entities and relations to form temporal representations. However, most existing methods overlook the impact of history from a multi-granularity aspect. The inherent semantics of human-defined temporal granularities, such as ordinal dates, reveal general patterns to which facts typically adhere. To counter this limitation, this paper proposes \\textbf{L}earning \\textbf{G}ranularity \\textbf{Re}presentation (termed $\\mathsf{LGRe}$) for TKG completion. It comprises two main components: Granularity Representation Learning (GRL) and Adaptive Granularity Balancing (AGB). Specifically, GRL employs time-specific multi-layer convolutional neural networks to capture interactions between entities and relations at different granularities. After that, AGB generates adaptive weights for these embeddings according to temporal semantics, resulting in expressive representations of predictions. Moreover, to reflect similar semantics of adjacent timestamps, a temporal loss function is introduced. Extensive experimental results on four event benchmarks demonstrate the effectiveness of $\\mathsf{LGRe}$ in learning time-related representations. To ensure reproducibility, our code is available at https://github.com/KcAcoZhang/LGRe.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "15 pages. Accepted at ICONIP 2024"
    },
    {
        "paper id": "2408.15388",
        "abstract url": "https://arxiv.org/abs/2408.15388",
        "title": "Panoptic Perception for Autonomous Driving: A Survey",
        "rating": "0",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Panoptic perception represents a forefront advancement in autonomous driving technology, unifying multiple perception tasks into a singular, cohesive framework to facilitate a thorough understanding of the vehicle's surroundings. This survey reviews typical panoptic perception models for their unique inputs and architectures and compares them to performance, responsiveness, and resource utilization. It also delves into the prevailing challenges faced in panoptic perception and explores potential trajectories for future research. Our goal is to furnish researchers in autonomous driving with a detailed synopsis of panoptic perception, positioning this survey as a pivotal reference in the ever-evolving landscape of autonomous driving technologies.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15450",
        "abstract url": "https://arxiv.org/abs/2408.15450",
        "title": "Avoiding Generative Model Writer's Block With Embedding Nudging",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Generative image models, since introduction, have become a global phenomenon. From new arts becoming possible to new vectors of abuse, many new capabilities have become available. One of the challenging issues with generative models is controlling the generation process specially to prevent specific generations classes or instances . There are several reasons why one may want to control the output of generative models, ranging from privacy and safety concerns to application limitations or user preferences To address memorization and privacy challenges, there has been considerable research dedicated to filtering prompts or filtering the outputs of these models. What all these solutions have in common is that at the end of the day they stop the model from producing anything, hence limiting the usability of the model. In this paper, we propose a method for addressing this usability issue by making it possible to steer away from unwanted concepts (when detected in model's output) and still generating outputs. In particular we focus on the latent diffusion image generative models and how one can prevent them to generate particular images while generating similar images with limited overhead. We focus on mitigating issues like image memorization, demonstrating our technique's effectiveness through qualitative and quantitative evaluations. Our method successfully prevents the generation of memorized training images while maintaining comparable image quality and relevance to the unmodified model.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15451",
        "abstract url": "https://arxiv.org/abs/2408.15451",
        "title": "Certified Causal Defense with Generalizable Robustness",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "While machine learning models have proven effective across various scenarios, it is widely acknowledged that many models are vulnerable to adversarial attacks. Recently, there have emerged numerous efforts in adversarial defense. Among them, certified defense is well known for its theoretical guarantees against arbitrary adversarial perturbations on input within a certain range (e.g., $l_2$ ball). However, most existing works in this line struggle to generalize their certified robustness in other data domains with distribution shifts. This issue is rooted in the difficulty of eliminating the negative impact of spurious correlations on robustness in different domains. To address this problem, in this work, we propose a novel certified defense framework GLEAN, which incorporates a causal perspective into the generalization problem in certified defense. More specifically, our framework integrates a certifiable causal factor learning component to disentangle the causal relations and spurious correlations between input and label, and thereby exclude the negative effect of spurious correlations on defense. On top of that, we design a causally certified defense strategy to handle adversarial attacks on latent causal factors. In this way, our framework is not only robust against malicious noises on data in the training distribution but also can generalize its robustness across domains with distribution shifts. Extensive experiments on benchmark datasets validate the superiority of our framework in certified robustness generalization in different data domains. Code is available in the supplementary materials.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "stat.ME"
        ],
        "comment": "Submitted to AAAI"
    },
    {
        "paper id": "2408.15461",
        "abstract url": "https://arxiv.org/abs/2408.15461",
        "title": "Hand1000: Generating Realistic Hands from Text with Only 1,000 Images",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image generation models have achieved remarkable advancements in recent years, aiming to produce realistic images from textual descriptions. However, these models often struggle with generating anatomically accurate representations of human hands. The resulting images frequently exhibit issues such as incorrect numbers of fingers, unnatural twisting or interlacing of fingers, or blurred and indistinct hands. These issues stem from the inherent complexity of hand structures and the difficulty in aligning textual descriptions with precise visual depictions of hands. To address these challenges, we propose a novel approach named Hand1000 that enables the generation of realistic hand images with target gesture using only 1,000 training samples. The training of Hand1000 is divided into three stages with the first stage aiming to enhance the model's understanding of hand anatomy by using a pre-trained hand gesture recognition model to extract gesture representation. The second stage further optimizes text embedding by incorporating the extracted hand gesture representation, to improve alignment between the textual descriptions and the generated hand images. The third stage utilizes the optimized embedding to fine-tune the Stable Diffusion model to generate realistic hand images. In addition, we construct the first publicly available dataset specifically designed for text-to-hand image generation. Based on the existing hand gesture recognition dataset, we adopt advanced image captioning models and LLaMA3 to generate high-quality textual descriptions enriched with detailed gesture information. Extensive experiments demonstrate that Hand1000 significantly outperforms existing models in producing anatomically correct hand images while faithfully representing other details in the text, such as faces, clothing, and colors.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Project page https://haozhuo-zhang.github.io/Hand1000-project-page/"
    },
    {
        "paper id": "2408.15484",
        "abstract url": "https://arxiv.org/abs/2408.15484",
        "title": "NAS-BNN: Neural Architecture Search for Binary Neural Networks",
        "rating": "0",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Binary Neural Networks (BNNs) have gained extensive attention for their superior inferencing efficiency and compression ratio compared to traditional full-precision networks. However, due to the unique characteristics of BNNs, designing a powerful binary architecture is challenging and often requires significant manpower. A promising solution is to utilize Neural Architecture Search (NAS) to assist in designing BNNs, but current NAS methods for BNNs are relatively straightforward and leave a performance gap between the searched models and manually designed ones. To address this gap, we propose a novel neural architecture search scheme for binary neural networks, named NAS-BNN. We first carefully design a search space based on the unique characteristics of BNNs. Then, we present three training strategies, which significantly enhance the training of supernet and boost the performance of all subnets. Our discovered binary model family outperforms previous BNNs for a wide range of operations (OPs) from 20M to 200M. For instance, we achieve 68.20% top-1 accuracy on ImageNet with only 57M OPs. In addition, we validate the transferability of these searched BNNs on the object detection task, and our binary detectors with the searched BNNs achieve a novel state-of-the-art result, e.g., 31.6% mAP with 370M OPs, on MS COCO dataset. The source code and models will be released at https://github.com/VDIGPKU/NAS-BNN.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2408.14788",
        "abstract url": "https://arxiv.org/abs/2408.14788",
        "title": "Learning from Complementary Features",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "While precise data observation is essential for the learning processes of predictive models, it can be challenging owing to factors such as insufficient observation accuracy, high collection costs, and privacy constraints. In this paper, we examines cases where some qualitative features are unavailable as precise information indicating \"what it is,\" but rather as complementary information indicating \"what it is not.\" We refer to features defined by precise information as ordinary features (OFs) and those defined by complementary information as complementary features (CFs). We then formulate a new learning scenario termed Complementary Feature Learning (CFL), where predictive models are constructed using instances consisting of OFs and CFs. The simplest formalization of CFL applies conventional supervised learning directly using the observed values of CFs. However, this approach does not resolve the ambiguity associated with CFs, making learning challenging and complicating the interpretation of the predictive model's specific predictions. Therefore, we derive an objective function from an information-theoretic perspective to estimate the OF values corresponding to CFs and to predict output labels based on these estimations. Based on this objective function, we propose a theoretically guaranteed graph-based estimation method along with its practical approximation, for estimating OF values corresponding to CFs. The results of numerical experiments conducted with real-world data demonstrate that our proposed method effectively estimates OF values corresponding to CFs and predicts output labels.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, 7 figures"
    },
    {
        "paper id": "2408.14831",
        "abstract url": "https://arxiv.org/abs/2408.14831",
        "title": "DRL-Based Federated Self-Supervised Learning for Task Offloading and Resource Allocation in ISAC-Enabled Vehicle Edge Computing",
        "rating": "-0.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Intelligent Transportation Systems (ITS) leverage Integrated Sensing and Communications (ISAC) to enhance data exchange between vehicles and infrastructure in the Internet of Vehicles (IoV). This integration inevitably increases computing demands, risking real-time system stability. Vehicle Edge Computing (VEC) addresses this by offloading tasks to Road Side Unit (RSU), ensuring timely services. Our previous work FLSimCo algorithm, which uses local resources for Federated Self-Supervised Learning (SSL), though vehicles often can't complete all iterations task. Our improved algorithm offloads partial task to RSU and optimizes energy consumption by adjusting transmission power, CPU frequency, and task assignment ratios, balancing local and RSU-based training. Meanwhile, setting an offloading threshold further prevents inefficiencies. Simulation results show that the enhanced algorithm reduces energy consumption, improves offloading efficiency and the accuracy of Federated SSL.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.NI"
        ],
        "comment": "This paper has been submitted to Digital Communications and Networks. The source code has been released at: https://github.com/qiongwu86/Federated-SSL-task-offloading-and-resource-allocation"
    },
    {
        "paper id": "2408.14843",
        "abstract url": "https://arxiv.org/abs/2408.14843",
        "title": "Correntropy-Based Improper Likelihood Model for Robust Electrophysiological Source Imaging",
        "rating": "-0.5",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian learning provides a unified skeleton to solve the electrophysiological source imaging task. From this perspective, existing source imaging algorithms utilize the Gaussian assumption for the observation noise to build the likelihood function for Bayesian inference. However, the electromagnetic measurements of brain activity are usually affected by miscellaneous artifacts, leading to a potentially non-Gaussian distribution for the observation noise. Hence the conventional Gaussian likelihood model is a suboptimal choice for the real-world source imaging task. In this study, we aim to solve this problem by proposing a new likelihood model which is robust with respect to non-Gaussian noises. Motivated by the robust maximum correntropy criterion, we propose a new improper distribution model concerning the noise assumption. This new noise distribution is leveraged to structure a robust likelihood function and integrated with hierarchical prior distributions to estimate source activities by variational inference. In particular, the score matching is adopted to determine the hyperparameters for the improper likelihood model. A comprehensive performance evaluation is performed to compare the proposed noise assumption to the conventional Gaussian model. Simulation results show that, the proposed method can realize more precise source reconstruction by designing known ground-truth. The real-world dataset also demonstrates the superiority of our new method with the visual perception task. This study provides a new backbone for Bayesian source imaging, which would facilitate its application using real-world noisy brain signal.",
        "subjects": [
            "cs.LG",
            "cs.NE",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14860",
        "abstract url": "https://arxiv.org/abs/2408.14860",
        "title": "DiffSurf: A Transformer-based Diffusion Model for Generating and Reconstructing 3D Surfaces in Pose",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This paper presents DiffSurf, a transformer-based denoising diffusion model for generating and reconstructing 3D surfaces. Specifically, we design a diffusion transformer architecture that predicts noise from noisy 3D surface vertices and normals. With this architecture, DiffSurf is able to generate 3D surfaces in various poses and shapes, such as human bodies, hands, animals and man-made objects. Further, DiffSurf is versatile in that it can address various 3D downstream tasks including morphing, body shape variation and 3D human mesh fitting to 2D keypoints. Experimental results on 3D human model benchmarks demonstrate that DiffSurf can generate shapes with greater diversity and higher quality than previous generative models. Furthermore, when applied to the task of single-image 3D human mesh recovery, DiffSurf achieves accuracy comparable to prior techniques at a near real-time rate.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ECCV2024"
    },
    {
        "paper id": "2408.14925",
        "abstract url": "https://arxiv.org/abs/2408.14925",
        "title": "Distance-Forward Learning: Enhancing the Forward-Forward Algorithm Towards High-Performance On-Chip Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "memory-efficient"
            ],
            [
                "biological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The Forward-Forward (FF) algorithm was recently proposed as a local learning method to address the limitations of backpropagation (BP), offering biological plausibility along with memory-efficient and highly parallelized computational benefits. However, it suffers from suboptimal performance and poor generalization, largely due to inadequate theoretical support and a lack of effective learning strategies. In this work, we reformulate FF using distance metric learning and propose a distance-forward algorithm (DF) to improve FF performance in supervised vision tasks while preserving its local computational properties, making it competitive for efficient on-chip learning. To achieve this, we reinterpret FF through the lens of centroid-based metric learning and develop a goodness-based N-pair margin loss to facilitate the learning of discriminative features. Furthermore, we integrate layer-collaboration local update strategies to reduce information loss caused by greedy local parameter updates. Our method surpasses existing FF models and other advanced local learning approaches, with accuracies of 99.7\\% on MNIST, 88.2\\% on CIFAR-10, 59\\% on CIFAR-100, 95.9\\% on SVHN, and 82.5\\% on ImageNette, respectively. Moreover, it achieves comparable performance with less than 40\\% memory cost compared to BP training, while exhibiting stronger robustness to multiple types of hardware-related noise, demonstrating its potential for online learning and energy-efficient computation on neuromorphic chips.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15003",
        "abstract url": "https://arxiv.org/abs/2408.15003",
        "title": "Gradient flow-based modularity maximization for community detection in multiplex networks",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "We propose two methods for the unsupervised detection of communities in undirected multiplex networks. These networks consist of multiple layers that record different relationships between the same entities or incorporate data from different sources. Both methods are formulated as gradient flows of suitable energy functionals: the first (MPBTV) builds on the minimization of a balanced total variation functional, which we show to be equivalent to multiplex modularity maximization, while the second (DGFM3) directly maximizes multiplex modularity. The resulting non-linear matrix-valued ordinary differential equations (ODEs) are solved efficiently by a graph Merriman--Bence--Osher (MBO) scheme. Key to the efficiency is the approximate integration of the discrete linear differential operators by truncated eigendecompositions in the matrix exponential function. Numerical experiments on several real-world multiplex networks show that our methods are competitive with the state of the art with respect to various metrics. Their major benefit is a significant reduction of computational complexity leading to runtimes that are orders of magnitude faster for large multiplex networks.",
        "subjects": [
            "math.NA",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15097",
        "abstract url": "https://arxiv.org/abs/2408.15097",
        "title": "Data-Driven Nonlinear Deformation Design of 3D-Printable Shells",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Designing and fabricating structures with specific mechanical properties requires understanding the intricate relationship between design parameters and performance. Understanding the design-performance relationship becomes increasingly complicated for nonlinear deformations. Though successful at modeling elastic deformations, simulation-based techniques struggle to model large elastoplastic deformations exhibiting plasticity and densification. We propose a neural network trained on experimental data to learn the design-performance relationship between 3D-printable shells and their compressive force-displacement behavior. Trained on thousands of physical experiments, our network aids in both forward and inverse design to generate shells exhibiting desired elastoplastic and hyperelastic deformations. We validate a subset of generated designs through fabrication and testing. Furthermore, we demonstrate the network's inverse design efficacy in generating custom shells for several applications.",
        "subjects": [
            "cs.GR",
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": "Submitted to 3D Printing and Additive Manufacturing"
    },
    {
        "paper id": "2408.15099",
        "abstract url": "https://arxiv.org/abs/2408.15099",
        "title": "No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "What data or environments to use for training to improve downstream performance is a longstanding and very topical question in reinforcement learning. In particular, Unsupervised Environment Design (UED) methods have gained recent attention as their adaptive curricula enable agents to be robust to in- and out-of-distribution tasks. We ask to what extent these methods are themselves robust when applied to a novel setting, closely inspired by a real-world robotics problem. Surprisingly, we find that the state-of-the-art UED methods either do not improve upon the na\u00efve baseline of Domain Randomisation (DR), or require substantial hyperparameter tuning to do so. Our analysis shows that this is due to their underlying scoring functions failing to predict intuitive measures of ``learnability'', i.e., in finding the settings that the agent sometimes solves, but not always. Based on this, we instead directly train on levels with high learnability and find that this simple and intuitive approach outperforms UED methods and DR in several binary-outcome environments, including on our domain and the standard UED domain of Minigrid. We further introduce a new adversarial evaluation procedure for directly measuring robustness, closely mirroring the conditional value at risk (CVaR). We open-source all our code and present visualisations of final policies here: https://github.com/amacrutherford/sampling-for-learnability.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15176",
        "abstract url": "https://arxiv.org/abs/2408.15176",
        "title": "Unlocking Potential in Pre-Trained Music Language Models for Versatile Multi-Track Music Arrangement",
        "rating": "-0.5",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Large language models have shown significant capabilities across various domains, including symbolic music generation. However, leveraging these pre-trained models for controllable music arrangement tasks, each requiring different forms of musical information as control, remains a novel challenge. In this paper, we propose a unified sequence-to-sequence framework that enables the fine-tuning of a symbolic music language model for multiple multi-track arrangement tasks, including band arrangement, piano reduction, drum arrangement, and voice separation. Our experiments demonstrate that the proposed approach consistently achieves higher musical quality compared to task-specific baselines across all four tasks. Furthermore, through additional experiments on probing analysis, we show the pre-training phase equips the model with essential knowledge to understand musical conditions, which is hard to acquired solely through task-specific fine-tuning.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "Submitted to AAAI 2025"
    },
    {
        "paper id": "2408.15183",
        "abstract url": "https://arxiv.org/abs/2408.15183",
        "title": "On latent dynamics learning in nonlinear reduced order modeling",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we present the novel mathematical framework of latent dynamics models (LDMs) for reduced order modeling of parameterized nonlinear time-dependent PDEs. Our framework casts this latter task as a nonlinear dimensionality reduction problem, while constraining the latent state to evolve accordingly to an (unknown) dynamical system. A time-continuous setting is employed to derive error and stability estimates for the LDM approximation of the full order model (FOM) solution. We analyze the impact of using an explicit Runge-Kutta scheme in the time-discrete setting, resulting in the $\u0394\\text{LDM}$ formulation, and further explore the learnable setting, $\u0394\\text{LDM}_\u03b8$, where deep neural networks approximate the discrete LDM components, while providing a bounded approximation error with respect to the FOM. Moreover, we extend the concept of parameterized Neural ODE - recently proposed as a possible way to build data-driven dynamical systems with varying input parameters - to be a convolutional architecture, where the input parameters information is injected by means of an affine modulation mechanism, while designing a convolutional autoencoder neural network able to retain spatial-coherence, thus enhancing interpretability at the latent level. Numerical experiments, including the Burgers' and the advection-reaction-diffusion equations, demonstrate the framework's ability to obtain, in a multi-query context, a time-continuous approximation of the FOM solution, thus being able to query the LDM approximation at any given time instance while retaining a prescribed level of accuracy. Our findings highlight the remarkable potential of the proposed LDMs, representing a mathematically rigorous framework to enhance the accuracy and approximation capabilities of reduced order modeling for time-dependent parameterized PDEs.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": "43 pages"
    },
    {
        "paper id": "2408.15310",
        "abstract url": "https://arxiv.org/abs/2408.15310",
        "title": "RGDA-DDI: Residual graph attention network and dual-attention based framework for drug-drug interaction prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent studies suggest that drug-drug interaction (DDI) prediction via computational approaches has significant importance for understanding the functions and co-prescriptions of multiple drugs. However, the existing silico DDI prediction methods either ignore the potential interactions among drug-drug pairs (DDPs), or fail to explicitly model and fuse the multi-scale drug feature representations for better prediction. In this study, we propose RGDA-DDI, a residual graph attention network (residual-GAT) and dual-attention based framework for drug-drug interaction prediction. A residual-GAT module is introduced to simultaneously learn multi-scale feature representations from drugs and DDPs. In addition, a dual-attention based feature fusion block is constructed to learn local joint interaction representations. A series of evaluation metrics demonstrate that the RGDA-DDI significantly improved DDI prediction performance on two public benchmark datasets, which provides a new insight into drug development.",
        "subjects": [
            "q-bio.MN",
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15395",
        "abstract url": "https://arxiv.org/abs/2408.15395",
        "title": "SCAN-Edge: Finding MobileNet-speed Hybrid Networks for Diverse Edge Devices via Hardware-Aware Evolutionary Search",
        "rating": "-0.5",
        "keywords": [
            [
                "architecture search",
                "NAS"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Designing low-latency and high-efficiency hybrid networks for a variety of low-cost commodity edge devices is both costly and tedious, leading to the adoption of hardware-aware neural architecture search (NAS) for finding optimal architectures. However, unifying NAS for a wide range of edge devices presents challenges due to the variety of hardware designs, supported operations, and compilation optimizations. Existing methods often fix the search space of architecture choices (e.g., activation, convolution, or self-attention) and estimate latency using hardware-agnostic proxies (e.g., FLOPs), which fail to achieve proclaimed latency across various edge devices. To address this issue, we propose SCAN-Edge, a unified NAS framework that jointly searches for self-attention, convolution, and activation to accommodate the wide variety of edge devices, including CPU-, GPU-, and hardware accelerator-based systems. To handle the large search space, SCAN-Edge relies on with a hardware-aware evolutionary algorithm that improves the quality of the search space to accelerate the sampling process. Experiments on large-scale datasets demonstrate that our hybrid networks match the actual MobileNetV2 latency for 224x224 input resolution on various commodity edge devices.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15404",
        "abstract url": "https://arxiv.org/abs/2408.15404",
        "title": "Evaluating Credit VIX (CDS IV) Prediction Methods with Incremental Batch Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents the experimental process and results of SVM, Gradient Boosting, and an Attention-GRU Hybrid model in predicting the Implied Volatility of rolled-over five-year spread contracts of credit default swaps (CDS) on European corporate debt during the quarter following mid-May '24, as represented by the iTraxx/Cboe Europe Main 1-Month Volatility Index (BP Volatility). The analysis employs a feature matrix inspired by Merton's determinants of default probability. Our comparative assessment aims to identify strengths in SOTA and classical machine learning methods for financial risk prediction",
        "subjects": [
            "q-fin.CP",
            "cs.LG",
            "q-fin.RM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15418",
        "abstract url": "https://arxiv.org/abs/2408.15418",
        "title": "Understanding GNNs for Boolean Satisfiability through Approximation Algorithms",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The paper deals with the interpretability of Graph Neural Networks in the context of Boolean Satisfiability. The goal is to demystify the internal workings of these models and provide insightful perspectives into their decision-making processes. This is done by uncovering connections to two approximation algorithms studied in the domain of Boolean Satisfiability: Belief Propagation and Semidefinite Programming Relaxations. Revealing these connections has empowered us to introduce a suite of impactful enhancements. The first significant enhancement is a curriculum training procedure, which incrementally increases the problem complexity in the training set, together with increasing the number of message passing iterations of the Graph Neural Network. We show that the curriculum, together with several other optimizations, reduces the training time by more than an order of magnitude compared to the baseline without the curriculum. Furthermore, we apply decimation and sampling of initial embeddings, which significantly increase the percentage of solved problems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "CIKM 2024"
    },
    {
        "paper id": "2408.15425",
        "abstract url": "https://arxiv.org/abs/2408.15425",
        "title": "Fast and Modular Autonomy Software for Autonomous Racing Vehicles",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Autonomous motorsports aim to replicate the human racecar driver with software and sensors. As in traditional motorsports, Autonomous Racing Vehicles (ARVs) are pushed to their handling limits in multi-agent scenarios at extremely high ($\\geq 150mph$) speeds. This Operational Design Domain (ODD) presents unique challenges across the autonomy stack. The Indy Autonomous Challenge (IAC) is an international competition aiming to advance autonomous vehicle development through ARV competitions. While far from challenging what a human racecar driver can do, the IAC is pushing the state of the art by facilitating full-sized ARV competitions. This paper details the MIT-Pitt-RW Team's approach to autonomous racing in the IAC. In this work, we present our modular and fast approach to agent detection, motion planning and controls to create an autonomy stack. We also provide analysis of the performance of the software stack in single and multi-agent scenarios for rapid deployment in a fast-paced competition environment. We also cover what did and did not work when deployed on a physical system the Dallara AV-21 platform and potential improvements to address these shortcomings. Finally, we convey lessons learned and discuss limitations and future directions for improvement.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.SE"
        ],
        "comment": "Published in Journal of Field Robotics"
    },
    {
        "paper id": "2408.15449",
        "abstract url": "https://arxiv.org/abs/2408.15449",
        "title": "Graph Attention Inference of Network Topology in Multi-Agent Systems",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurately identifying the underlying graph structures of multi-agent systems remains a difficult challenge. Our work introduces a novel machine learning-based solution that leverages the attention mechanism to predict future states of multi-agent systems by learning node representations. The graph structure is then inferred from the strength of the attention values. This approach is applied to both linear consensus dynamics and the non-linear dynamics of Kuramoto oscillators, resulting in implicit learning the graph by learning good agent representations. Our results demonstrate that the presented data-driven graph attention machine learning model can identify the network topology in multi-agent systems, even when the underlying dynamic model is not known, as evidenced by the F1 scores achieved in the link prediction.",
        "subjects": [
            "cs.MA",
            "cs.LG"
        ],
        "comment": "Accepted for publication at Modeling and Estimation Control Conference 2024; 6 pages, 5 figures"
    },
    {
        "paper id": "2408.15501",
        "abstract url": "https://arxiv.org/abs/2408.15501",
        "title": "MODULI: Unlocking Preference Generalization via Diffusion Models for Offline Multi-Objective Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Multi-objective Reinforcement Learning (MORL) seeks to develop policies that simultaneously optimize multiple conflicting objectives, but it requires extensive online interactions. Offline MORL provides a promising solution by training on pre-collected datasets to generalize to any preference upon deployment. However, real-world offline datasets are often conservatively and narrowly distributed, failing to comprehensively cover preferences, leading to the emergence of out-of-distribution (OOD) preference areas. Existing offline MORL algorithms exhibit poor generalization to OOD preferences, resulting in policies that do not align with preferences. Leveraging the excellent expressive and generalization capabilities of diffusion models, we propose MODULI (Multi-objective Diffusion Planner with Sliding Guidance), which employs a preference-conditioned diffusion model as a planner to generate trajectories that align with various preferences and derive action for decision-making. To achieve accurate generation, MODULI introduces two return normalization methods under diverse preferences for refining guidance. To further enhance generalization to OOD preferences, MODULI proposes a novel sliding guidance mechanism, which involves training an additional slider adapter to capture the direction of preference changes. Incorporating the slider, it transitions from in-distribution (ID) preferences to generating OOD preferences, patching, and extending the incomplete Pareto front. Extensive experiments on the D4MORL benchmark demonstrate that our algorithm outperforms state-of-the-art Offline MORL baselines, exhibiting excellent generalization to OOD preferences.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "23 pages, 7 figures"
    },
    {
        "paper id": "2408.16028",
        "abstract url": "https://arxiv.org/abs/2408.16028",
        "title": "ANVIL: Anomaly-based Vulnerability Identification without Labelled Training Data",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Supervised learning-based software vulnerability detectors often fall short due to the inadequate availability of labelled training data. In contrast, Large Language Models (LLMs) such as GPT-4, are not trained on labelled data, but when prompted to detect vulnerabilities, LLM prediction accuracy is only marginally better than random guessing. In this paper, we explore a different approach by reframing vulnerability detection as one of anomaly detection. Since the vast majority of code does not contain vulnerabilities and LLMs are trained on massive amounts of such code, vulnerable code can be viewed as an anomaly from the LLM's predicted code distribution, freeing the model from the need for labelled data to provide a learnable representation of vulnerable code. Leveraging this perspective, we demonstrate that LLMs trained for code generation exhibit a significant gap in prediction accuracy when prompted to reconstruct vulnerable versus non-vulnerable code. Using this insight, we implement ANVIL, a detector that identifies software vulnerabilities at line-level granularity. Our experiments explore the discriminating power of different anomaly scoring methods, as well as the sensitivity of ANVIL to context size. We also study the effectiveness of ANVIL on various LLM families, and conduct leakage experiments on vulnerabilities that were discovered after the knowledge cutoff of our evaluated LLMs. On a collection of vulnerabilities from the Magma benchmark, ANVIL outperforms state-of-the-art line-level vulnerability detectors, LineVul and LineVD, which have been trained with labelled data, despite ANVIL having never been trained with labelled vulnerabilities. Specifically, our approach achieves $1.62\\times$ to $2.18\\times$ better Top-5 accuracies and $1.02\\times$ to $1.29\\times$ times better ROC scores on line-level vulnerability detection tasks.",
        "subjects": [
            "cs.CR",
            "cs.LG",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14797",
        "abstract url": "https://arxiv.org/abs/2408.14797",
        "title": "MaskCycleGAN-based Whisper to Normal Speech Conversion",
        "rating": "-1",
        "keywords": [
            [
                "voice conversion"
            ],
            [
                "cs.LG",
                "eess.AS"
            ]
        ],
        "abstract": "Whisper to normal speech conversion is an active area of research. Various architectures based on generative adversarial networks have been proposed in the recent past. Especially, recent study shows that MaskCycleGAN, which is a mask guided, and cyclic consistency keeping, generative adversarial network, performs really well for voice conversion from spectrogram representations. In the current work we present a MaskCycleGAN approach for the conversion of whispered speech to normal speech. We find that tuning the mask parameters, and pre-processing the signal with a voice activity detector provides superior performance when compared to the existing approach. The wTIMIT dataset is used for evaluation. Objective metrics such as PESQ and G-Loss are used to evaluate the converted speech, along with subjective evaluation using mean opinion score. The results show that the proposed approach offers considerable benefits.",
        "subjects": [
            "eess.AS",
            "cs.LG"
        ],
        "comment": "submitted to TENCON 2024"
    },
    {
        "paper id": "2408.14810",
        "abstract url": "https://arxiv.org/abs/2408.14810",
        "title": "Generalist Segmentation Algorithm for Photoreceptors Analysis in Adaptive Optics Imaging",
        "rating": "-1",
        "keywords": [
            [
                "retina"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Analyzing the cone photoreceptor pattern in images obtained from the living human retina using quantitative methods can be crucial for the early detection and management of various eye conditions. Confocal adaptive optics scanning light ophthalmoscope (AOSLO) imaging enables visualization of the cones from reflections of waveguiding cone photoreceptors. While there have been significant improvements in automated algorithms for segmenting cones in confocal AOSLO images, the process of labelling data remains labor-intensive and manual. This paper introduces a method based on deep learning (DL) for detecting and segmenting cones in AOSLO images. The models were trained on a semi-automatically labelled dataset of 20 AOSLO batches of images of 18 participants for 0$^{\\circ}$, 1$^{\\circ}$, and 2$^{\\circ}$ from the foveal center. F1 scores were 0.968, 0.958, and 0.954 for 0$^{\\circ}$, 1$^{\\circ}$, and 2$^{\\circ}$, respectively, which is better than previously reported DL approaches. Our method minimizes the need for labelled data by only necessitating a fraction of labelled cones, which is especially beneficial in the field of ophthalmology, where labelled data can often be limited.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14814",
        "abstract url": "https://arxiv.org/abs/2408.14814",
        "title": "Partition Detection in Byzantine Networks",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Detecting and handling network partitions is a fundamental requirement of distributed systems. Although existing partition detection methods in arbitrary graphs tolerate unreliable networks, they either assume that all nodes are correct or that a limited number of nodes might crash. In particular, Byzantine behaviors are out of the scope of these algorithms despite Byzantine fault tolerance being an active research topic for important problems such as consensus. Moreover, Byzantinetolerant protocols, such as broadcast or consensus, always rely on the assumption of connected networks. This paper addresses the problem of detecting partition in Byzantine networks (without connectivity assumption). We present a novel algorithm, which we call NECTAR, that safely detects partitioned and possibly partitionable networks and prove its correctness. NECTAR allows all correct nodes to detect whether a network could suffer from Byzantine nodes. We evaluate NECTAR's performance and compare it to two existing baselines using up to 100 nodes running real code, on various realistic topologies. Our results confirm that NECTAR maintains a 100% accuracy while the accuracy of the various existing baselines decreases by at least 40% as soon as one participant is Byzantine. Although NECTAR's network cost increases with the number of nodes and decreases with the network's diameter, it does not go above around 500KB in the worst cases.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14819",
        "abstract url": "https://arxiv.org/abs/2408.14819",
        "title": "Build-A-Scene: Interactive 3D Layout Control for Diffusion-Based Image Generation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose a diffusion-based approach for Text-to-Image (T2I) generation with interactive 3D layout control. Layout control has been widely studied to alleviate the shortcomings of T2I diffusion models in understanding objects' placement and relationships from text descriptions. Nevertheless, existing approaches for layout control are limited to 2D layouts, require the user to provide a static layout beforehand, and fail to preserve generated images under layout changes. This makes these approaches unsuitable for applications that require 3D object-wise control and iterative refinements, e.g., interior design and complex scene generation. To this end, we leverage the recent advancements in depth-conditioned T2I models and propose a novel approach for interactive 3D layout control. We replace the traditional 2D boxes used in layout control with 3D boxes. Furthermore, we revamp the T2I task as a multi-stage generation process, where at each stage, the user can insert, change, and move an object in 3D while preserving objects from earlier stages. We achieve this through our proposed Dynamic Self-Attention (DSA) module and the consistent 3D object translation strategy. Experiments show that our approach can generate complicated scenes based on 3D layouts, boosting the object generation success rate over the standard depth-conditioned T2I methods by 2x. Moreover, it outperforms other methods in comparison in preserving objects under layout changes. Project Page: \\url{https://abdo-eldesokey.github.io/build-a-scene/}",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://abdo-eldesokey.github.io/build-a-scene/"
    },
    {
        "paper id": "2408.14825",
        "abstract url": "https://arxiv.org/abs/2408.14825",
        "title": "From Rule-Based Models to Deep Learning Transformers Architectures for Natural Language Processing and Sign Language Translation Systems: Survey, Taxonomy and Performance Evaluation",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "With the growing Deaf and Hard of Hearing population worldwide and the persistent shortage of certified sign language interpreters, there is a pressing need for an efficient, signs-driven, integrated end-to-end translation system, from sign to gloss to text and vice-versa. There has been a wealth of research on machine translations and related reviews. However, there are few works on sign language machine translation considering the particularity of the language being continuous and dynamic. This paper aims to address this void, providing a retrospective analysis of the temporal evolution of sign language machine translation algorithms and a taxonomy of the Transformers architectures, the most used approach in language translation. We also present the requirements of a real-time Quality-of-Service sign language ma-chine translation system underpinned by accurate deep learning algorithms. We propose future research directions for sign language translation systems.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14842",
        "abstract url": "https://arxiv.org/abs/2408.14842",
        "title": "From Bias to Balance: Detecting Facial Expression Recognition Biases in Large Multimodal Foundation Models",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This study addresses the racial biases in facial expression recognition (FER) systems within Large Multimodal Foundation Models (LMFMs). Despite advances in deep learning and the availability of diverse datasets, FER systems often exhibit higher error rates for individuals with darker skin tones. Existing research predominantly focuses on traditional FER models (CNNs, RNNs, ViTs), leaving a gap in understanding racial biases in LMFMs. We benchmark four leading LMFMs: GPT-4o, PaliGemma, Gemini, and CLIP to assess their performance in facial emotion detection across different racial demographics. A linear classifier trained on CLIP embeddings obtains accuracies of 95.9\\% for RADIATE, 90.3\\% for Tarr, and 99.5\\% for Chicago Face. Furthermore, we identify that Anger is misclassified as Disgust 2.1 times more often in Black Females than White Females. This study highlights the need for fairer FER systems and establishes a foundation for developing unbiased, accurate FER technologies. Visit https://kvjvhub.github.io/FERRacialBias/ for further information regarding the biases within facial expression recognition.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14846",
        "abstract url": "https://arxiv.org/abs/2408.14846",
        "title": "Diffusion-Occ: 3D Point Cloud Completion via Occupancy Diffusion",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Voxel",
                "Point Cloud"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Point clouds are crucial for capturing three-dimensional data but often suffer from incompleteness due to limitations such as resolution and occlusion. Traditional methods typically rely on point-based approaches within discriminative frameworks for point cloud completion. In this paper, we introduce \\textbf{Diffusion-Occ}, a novel framework for Diffusion Point Cloud Completion. Diffusion-Occ utilizes a two-stage coarse-to-fine approach. In the first stage, the Coarse Density Voxel Prediction Network (CDNet) processes partial points to predict coarse density voxels, streamlining global feature extraction through voxel classification, as opposed to previous regression-based methods. In the second stage, we introduce the Occupancy Generation Network (OccGen), a conditional occupancy diffusion model based on a transformer architecture and enhanced by our Point-Voxel Fuse (PVF) block. This block integrates coarse density voxels with partial points to leverage both global and local features for comprehensive completion. By thresholding the occupancy field, we convert it into a complete point cloud. Additionally, our method employs diverse training mixtures and efficient diffusion parameterization to enable effective one-step sampling during both training and inference. Experimental results demonstrate that Diffusion-Occ outperforms existing discriminative and generative methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14847",
        "abstract url": "https://arxiv.org/abs/2408.14847",
        "title": "Intraoperative Glioma Segmentation with YOLO + SAM for Improved Accuracy in Tumor Resection",
        "rating": "-1",
        "keywords": [
            [
                "surgical",
                "surgery",
                "MRI",
                "Tumor"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Gliomas, a common type of malignant brain tumor, present significant surgical challenges due to their similarity to healthy tissue. Preoperative Magnetic Resonance Imaging (MRI) images are often ineffective during surgery due to factors such as brain shift, which alters the position of brain structures and tumors. This makes real-time intraoperative MRI (ioMRI) crucial, as it provides updated imaging that accounts for these shifts, ensuring more accurate tumor localization and safer resections. This paper presents a deep learning pipeline combining You Only Look Once Version 8 (YOLOv8) and Segment Anything Model Vision Transformer-base (SAM ViT-b) to enhance glioma detection and segmentation during ioMRI. Our model was trained using the Brain Tumor Segmentation 2021 (BraTS 2021) dataset, which includes standard magnetic resonance imaging (MRI) images, and noise-augmented MRI images that simulate ioMRI images. Noised MRI images are harder for a deep learning pipeline to segment, but they are more representative of surgical conditions. Achieving a Dice Similarity Coefficient (DICE) score of 0.79, our model performs comparably to state-of-the-art segmentation models tested on noiseless data. This performance demonstrates the model's potential to assist surgeons in maximizing tumor resection and improving surgical outcomes.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14870",
        "abstract url": "https://arxiv.org/abs/2408.14870",
        "title": "Towards Safe Autonomous Intersection Management: Temporal Logic-based Safety Filters for Vehicle Coordination",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "In this paper, we introduce a temporal logic-based safety filter for Autonomous Intersection Management (AIM), an emerging infrastructure technology for connected vehicles to coordinate traffic flow through intersections. Despite substantial work on AIM systems, the balance between intersection safety and efficiency persists as a significant challenge. Building on recent developments in formal methods that now have become computationally feasible for AIM applications, we introduce an approach that starts with a temporal logic specification for the intersection and then uses reachability analysis to compute safe time-state corridors for the connected vehicles that pass through the intersection. By analyzing these corridors, in contrast to single trajectories, we can make explicit design decisions regarding safety-efficiency trade-offs while taking each vehicle's decision uncertainty into account. Additionally, we compute safe driving limits to ensure that vehicles remain within their designated safe corridors. Combining these elements, we develop a service that provides safety filters for AIM coordination of connected vehicles. We evaluate the practical feasibility of our safety framework using a simulated 4-way intersection, showing that our approach performs in real-time for multiple scenarios.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "To be published in 27th IEEE International Conference on Intelligent Transportation Systems"
    },
    {
        "paper id": "2408.14890",
        "abstract url": "https://arxiv.org/abs/2408.14890",
        "title": "Development of Large Annotated Music Datasets using HMM-based Forced Viterbi Alignment",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Datasets are essential for any machine learning task. Automatic Music Transcription (AMT) is one such task, where considerable amount of data is required depending on the way the solution is achieved. Considering the fact that a music dataset, complete with audio and its time-aligned transcriptions would require the effort of people with musical experience, it could be stated that the task becomes even more challenging. Musical experience is required in playing the musical instrument(s), and in annotating and verifying the transcriptions. We propose a method that would help in streamlining this process, making the task of obtaining a dataset from a particular instrument easy and efficient. We use predefined guitar exercises and hidden Markov model(HMM) based forced viterbi alignment to accomplish this. The guitar exercises are designed to be simple. Since the note sequence are already defined, HMM based forced viterbi alignment provides time-aligned transcriptions of these audio files. The onsets of the transcriptions are manually verified and the labels are accurate up to 10ms, averaging at 5ms. The contributions of the proposed work is two fold, i) a well streamlined and efficient method for generating datasets for any instrument, especially monophonic and, ii) an acoustic plectrum guitar dataset containing wave files and transcriptions in the form of label files. This method will aid as a preliminary step towards building concrete datasets for building AMT systems for different instruments.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "submitted to TENCON 2019"
    },
    {
        "paper id": "2408.14899",
        "abstract url": "https://arxiv.org/abs/2408.14899",
        "title": "MeshUp: Multi-Target Mesh Deformation via Blended Score Distillation",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose MeshUp, a technique that deforms a 3D mesh towards multiple target concepts, and intuitively controls the region where each concept is expressed. Conveniently, the concepts can be defined as either text queries, e.g., \"a dog\" and \"a turtle,\" or inspirational images, and the local regions can be selected as any number of vertices on the mesh. We can effectively control the influence of the concepts and mix them together using a novel score distillation approach, referred to as the Blended Score Distillation (BSD). BSD operates on each attention layer of the denoising U-Net of a diffusion model as it extracts and injects the per-objective activations into a unified denoising pipeline from which the deformation gradients are calculated. To localize the expression of these activations, we create a probabilistic Region of Interest (ROI) map on the surface of the mesh, and turn it into 3D-consistent masks that we use to control the expression of these activations. We demonstrate the effectiveness of BSD empirically and show that it can deform various meshes towards multiple objectives.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14927",
        "abstract url": "https://arxiv.org/abs/2408.14927",
        "title": "Automatic Detection of COVID-19 from Chest X-ray Images Using Deep Learning Model",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "diagnosis",
                "X-ray",
                "disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The infectious disease caused by novel corona virus (2019-nCoV) has been widely spreading since last year and has shaken the entire world. It has caused an unprecedented effect on daily life, global economy and public health. Hence this disease detection has life-saving importance for both patients as well as doctors. Due to limited test kits, it is also a daunting task to test every patient with severe respiratory problems using conventional techniques (RT-PCR). Thus implementing an automatic diagnosis system is urgently required to overcome the scarcity problem of Covid-19 test kits at hospital, health care systems. The diagnostic approach is mainly classified into two categories-laboratory based and Chest radiography approach. In this paper, a novel approach for computerized corona virus (2019-nCoV) detection from lung x-ray images is presented. Here, we propose models using deep learning to show the effectiveness of diagnostic systems. In the experimental result, we evaluate proposed models on publicly available data-set which exhibit satisfactory performance and promising results compared with other previous existing methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted in AIP Conference Proceedings (Vol. 2424, No. 1)"
    },
    {
        "paper id": "2408.14950",
        "abstract url": "https://arxiv.org/abs/2408.14950",
        "title": "NeuralOOD: Improving Out-of-Distribution Generalization Performance with Brain-machine Fusion Learning Framework",
        "rating": "-1",
        "keywords": [
            [
                "fMRI"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Deep Neural Networks (DNNs) have demonstrated exceptional recognition capabilities in traditional computer vision (CV) tasks. However, existing CV models often suffer a significant decrease in accuracy when confronted with out-of-distribution (OOD) data. In contrast to these DNN models, human can maintain a consistently low error rate when facing OOD scenes, partly attributed to the rich prior cognitive knowledge stored in the human brain. Previous OOD generalization researches only focus on the single modal, overlooking the advantages of multimodal learning method. In this paper, we utilize the multimodal learning method to improve the OOD generalization and propose a novel Brain-machine Fusion Learning (BMFL) framework. We adopt the cross-attention mechanism to fuse the visual knowledge from CV model and prior cognitive knowledge from the human brain. Specially, we employ a pre-trained visual neural encoding model to predict the functional Magnetic Resonance Imaging (fMRI) from visual features which eliminates the need for the fMRI data collection and pre-processing, effectively reduces the workload associated with conventional BMFL methods. Furthermore, we construct a brain transformer to facilitate the extraction of knowledge inside the fMRI data. Moreover, we introduce the Pearson correlation coefficient maximization regularization method into the training process, which improves the fusion capability with better constrains. Our model outperforms the DINOv2 and baseline models on the ImageNet-1k validation dataset as well as six curated OOD datasets, showcasing its superior performance in diverse scenarios.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14953",
        "abstract url": "https://arxiv.org/abs/2408.14953",
        "title": "Morphogenesis of sound creates acoustic rainbows",
        "rating": "-1",
        "keywords": [
            [
                "bionics"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Sound is an essential sensing element for many organisms in nature, and multiple species have evolved organic structures that create complex acoustic scattering and dispersion phenomena to emit and perceive sound unambiguously. To date, it has not proven possible to design artificial scattering structures that rival the performance of those found in organic structures. Contrarily, most sound manipulation relies on active transduction in fluid media rather than relying on passive scattering principles, as are often found in nature. In this work, we utilize computational morphogenesis to synthesize complex energy-efficient wavelength-sized single-material scattering structures that passively decompose radiated sound into its spatio-spectral components. Specifically, we tailor an acoustic rainbow structure with \"above unity\" efficiency and an acoustic wavelength-splitter. Our work paves the way for a new frontier in sound-field engineering, with potential applications in transduction, bionics, energy harvesting, communications and sensing.",
        "subjects": [
            "cs.SD",
            "eess.AS",
            "math.OC",
            "physics.app-ph"
        ],
        "comment": "8 Pages, 4 Figures, Supplementary information including text and four movies"
    },
    {
        "paper id": "2408.14997",
        "abstract url": "https://arxiv.org/abs/2408.14997",
        "title": "Depth Restoration of Hand-Held Transparent Objects for Human-to-Robot Handover",
        "rating": "-1",
        "keywords": [
            [
                "RGB-D",
                "Depth"
            ],
            [
                "Robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Transparent objects are common in daily life, while their unique optical properties pose challenges for RGB-D cameras, which struggle to capture accurate depth information. For assistant robots, accurately perceiving transparent objects held by humans is essential for effective human-robot interaction. This paper presents a Hand-Aware Depth Restoration (HADR) method for hand-held transparent objects based on creating an implicit neural representation function from a single RGB-D image. The proposed method introduces the hand posture as an important guidance to leverage semantic and geometric information. To train and evaluate the proposed method, we create a high-fidelity synthetic dataset called TransHand-14K with a real-to-sim data generation scheme. Experiments show that our method has a better performance and generalization ability compared with existing methods. We further develop a real-world human-to-robot handover system based on the proposed depth restoration method, demonstrating its application value in human-robot interaction.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "7 pages, 7 figures, conference"
    },
    {
        "paper id": "2408.14999",
        "abstract url": "https://arxiv.org/abs/2408.14999",
        "title": "The equational theory of the Weihrauch lattice with (iterated) composition",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "We study the equational theory of the Weihrauch lattice with composition and iterations, meaning the collection of equations between terms built from variables, the lattice operations $\\sqcup$, $\\sqcap$, the composition operator $\\star$ and its iteration $(-)^\\diamond$ , which are true however we substitute (slightly extended) Weihrauch degrees for the variables. We characterize them using B\u00fcchi games on finite graphs and give a complete axiomatization that derives them. The term signature and the axiomatization are reminiscent of Kleene algebras, except that we additionally have meets and the lattice operations do not fully distributes over composition. The game characterization also implies that it is decidable whether an equation is universally valid. We give some complexity bounds; in particular, the problem is Pspace-hard in general and we conjecture that it is solvable in Pspace.",
        "subjects": [
            "cs.LO",
            "math.LO"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2408.15001",
        "abstract url": "https://arxiv.org/abs/2408.15001",
        "title": "PaceMaker: A Practical Tool for Pacing Video Games",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Designing pacing for video games presents a unique set of challenges. Due to their interactivity, non-linearity, and narrative nature, many aspects must be coordinated and considered simultaneously. In addition, games are often developed in an iterative workflow, making revisions to previous designs difficult and time-consuming. In this paper, we present PaceMaker, a toolkit designed to enable common design workflows for pacing while addressing the challenges above. We conducted initial research on pacing and then implemented our findings in a platform-independent application that allows the user to define simple state diagrams to deal with the possibility space of games. The user can select paths on the directed graph to visualize a node's data in diagrams dedicated to intensity and gameplay category. After implementation, we created a demonstration of the tool and conducted qualitative interviews. While the interviews raised some concerns about the efficiency of PaceMaker, the results https://info.arxiv.org/help/prep#commentsdemonstrate the expressiveness of the toolkit and support the need for such a tool.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "To be published in \"IEEE Conferences on Games 2024 Proceedings\", 8 pages, 5 figures"
    },
    {
        "paper id": "2408.15002",
        "abstract url": "https://arxiv.org/abs/2408.15002",
        "title": "Knowledge Discovery in Optical Music Recognition: Enhancing Information Retrieval with Instance Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.CV",
                "cs.SD"
            ]
        ],
        "abstract": "Optical Music Recognition (OMR) automates the transcription of musical notation from images into machine-readable formats like MusicXML, MEI, or MIDI, significantly reducing the costs and time of manual transcription. This study explores knowledge discovery in OMR by applying instance segmentation using Mask R-CNN to enhance the detection and delineation of musical symbols in sheet music. Unlike Optical Character Recognition (OCR), OMR must handle the intricate semantics of Common Western Music Notation (CWMN), where symbol meanings depend on shape, position, and context. Our approach leverages instance segmentation to manage the density and overlap of musical symbols, facilitating more precise information retrieval from music scores. Evaluations on the DoReMi and MUSCIMA++ datasets demonstrate substantial improvements, with our method achieving a mean Average Precision (mAP) of up to 59.70\\% in dense symbol environments, achieving comparable results to object detection. Furthermore, using traditional computer vision techniques, we add a parallel step for staff detection to infer the pitch for the recognised symbols. This study emphasises the role of pixel-wise segmentation in advancing accurate music symbol recognition, contributing to knowledge discovery in OMR. Our findings indicate that instance segmentation provides more precise representations of musical symbols, particularly in densely populated scores, advancing OMR technology. We make our implementation, pre-processing scripts, trained models, and evaluation results publicly available to support further research and development.",
        "subjects": [
            "cs.IR",
            "cs.CV",
            "cs.SD"
        ],
        "comment": "8 pages content and one references, accepted version at the International Conference on Knowledge Discovery and Information Retrieval 2024, Porto, Portugal"
    },
    {
        "paper id": "2408.15019",
        "abstract url": "https://arxiv.org/abs/2408.15019",
        "title": "Fixed-time Disturbance Observer-Based MPC Robust Trajectory Tracking Control of Quadrotor",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "In this paper, a fixed-time disturbance observerbased model predictive control algorithm is proposed for trajectory tracking of quadrotor in the presence of disturbances. First, a novel multivariable fixed-time disturbance observer is proposed to estimate the lumped disturbances. The bi-limit homogeneity and Lyapunov techniques are employed to ensure the convergence of estimation error within a fixed convergence time, independent of the initial estimation error. Then, an observerbased model predictive control strategy is formulated to achieve robust trajectory tracking of quadrotor, attenuating the lumped disturbances and model uncertainties. Finally, simulations and real-world experiments are provided to illustrate the effectiveness of the proposed method.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15032",
        "abstract url": "https://arxiv.org/abs/2408.15032",
        "title": "Mamba2MIL: State Space Duality Based Multiple Instance Learning for Computational Pathology",
        "rating": "-1",
        "keywords": [
            [
                "whole slide",
                "clinical",
                "tumor"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Computational pathology (CPath) has significantly advanced the clinical practice of pathology. Despite the progress made, Multiple Instance Learning (MIL), a promising paradigm within CPath, continues to face challenges, particularly related to incomplete information utilization. Existing frameworks, such as those based on Convolutional Neural Networks (CNNs), attention, and selective scan space state sequential model (SSM), lack sufficient flexibility and scalability in fusing diverse features, and cannot effectively fuse diverse features. Additionally, current approaches do not adequately exploit order-related and order-independent features, resulting in suboptimal utilization of sequence information. To address these limitations, we propose a novel MIL framework called Mamba2MIL. Our framework utilizes the state space duality model (SSD) to model long sequences of patches of whole slide images (WSIs), which, combined with weighted feature selection, supports the fusion processing of more branching features and can be extended according to specific application needs. Moreover, we introduce a sequence transformation method tailored to varying WSI sizes, which enhances sequence-independent features while preserving local sequence information, thereby improving sequence information utilization. Extensive experiments demonstrate that Mamba2MIL surpasses state-of-the-art MIL methods. We conducted extensive experiments across multiple datasets, achieving improvements in nearly all performance metrics. Specifically, on the NSCLC dataset, Mamba2MIL achieves a binary tumor classification AUC of 0.9533 and an accuracy of 0.8794. On the BRACS dataset, it achieves a multiclass classification AUC of 0.7986 and an accuracy of 0.4981. The code is available at https://github.com/YuqiZhang-Buaa/Mamba2MIL.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15044",
        "abstract url": "https://arxiv.org/abs/2408.15044",
        "title": "Enabling Efficient and Scalable DRAM Read Disturbance Mitigation via New Experimental Insights into Modern DRAM Chips",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Increasing storage density exacerbates DRAM read disturbance, a circuit-level vulnerability exploited by system-level attacks. Unfortunately, existing defenses are either ineffective or prohibitively expensive. Efficient mitigation is critical to ensure robust (reliable, secure, and safe) execution in future DRAM-based systems. This dissertation tackles two problems: 1) protecting DRAM-based systems becomes more expensive as technology scaling increases read disturbance vulnerability, and 2) many existing solutions depend on proprietary knowledge of DRAM internals. First, we build a detailed understanding of DRAM read disturbance by rigorously characterizing off-the-shelf modern DRAM chips under varying 1) temperatures, 2) memory access patterns, 3) in-chip locations, and 4) voltage. Our novel observations demystify the implications of large DRAM read disturbance variation on future DRAM read disturbance attacks and solutions. Second, we propose new mechanisms that mitigate read disturbance bitflips efficiently and scalably by leveraging insights into DRAM chip design: 1) subarray-level parallelism and 2) variation in read disturbance across DRAM rows in off-the-shelf DRAM chips. Third, we propose a novel solution that mitigates DRAM read disturbance by selectively throttling unsafe memory accesses that might otherwise cause read disturbance bitflips without proprietary knowledge of DRAM chip internals. We demonstrate that it is possible to mitigate DRAM read disturbance efficiently and scalably with worsening DRAM read disturbance by 1) building a detailed understanding of DRAM read disturbance, 2) leveraging insights into DRAM chips, and 3) devising novel solutions that do not require proprietary knowledge of DRAM chip internals. Our experimental insights and solutions enable future works targeting robust memory systems.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "comment": "Doctoral thesis"
    },
    {
        "paper id": "2408.15046",
        "abstract url": "https://arxiv.org/abs/2408.15046",
        "title": "Distributed Planning for Rigid Robot Formations with Probabilistic Collision Avoidance",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "This paper presents a distributed method for robots moving in rigid formations while ensuring probabilistic collision avoidance between the robots. The formation is parametrised through the transformation of a base configuration. The robots map their desired velocities into a corresponding desired change in the formation parameters and apply a consensus step to reach agreement on the desired formation and a constraint satisfaction step to ensure collision avoidance within the formation. The constraint set is found such that the probability of collision remains below an upper bound. The method was demonstrated in a manual teleoperation scenario both in simulation and a real-world experiment.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15107",
        "abstract url": "https://arxiv.org/abs/2408.15107",
        "title": "The Illusion of Randomness: An Empirical Analysis of Address Space Layout Randomization Implementations",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "Address Space Layout Randomization (ASLR) is a crucial defense mechanism employed by modern operating systems to mitigate exploitation by randomizing processes' memory layouts. However, the stark reality is that real-world implementations of ASLR are imperfect and subject to weaknesses that attackers can exploit. This work evaluates the effectiveness of ASLR on major desktop platforms, including Linux, MacOS, and Windows, by examining the variability in the placement of memory objects across various processes, threads, and system restarts. In particular, we collect samples of memory object locations, conduct statistical analyses to measure the randomness of these placements and examine the memory layout to find any patterns among objects that could decrease this randomness. The results show that while some systems, like Linux distributions, provide robust randomization, others, like Windows and MacOS, often fail to adequately randomize key areas like executable code and libraries. Moreover, we find a significant entropy reduction in the entropy of libraries after the Linux 5.18 version and identify correlation paths that an attacker could leverage to reduce exploitation complexity significantly. Ultimately, we rank the identified weaknesses based on severity and validate our entropy estimates with a proof-of-concept attack. In brief, this paper provides the first comprehensive evaluation of ASLR effectiveness across different operating systems and highlights opportunities for Operating System (OS) vendors to strengthen ASLR implementations.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Extended version of the accepted paper at ACM CCS 2024"
    },
    {
        "paper id": "2408.15172",
        "abstract url": "https://arxiv.org/abs/2408.15172",
        "title": "X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation",
        "rating": "-1",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been shown to enhance the effectiveness of enriching item descriptions, thereby improving the accuracy of recommendation systems. However, most existing approaches either rely on text-only prompting or employ basic multimodal strategies that do not fully exploit the complementary information available from both textual and visual modalities. This paper introduces a novel framework, Cross-Reflection Prompting, termed X-Reflect, designed to address these limitations by prompting LMMs to explicitly identify and reconcile supportive and conflicting information between text and images. By capturing nuanced insights from both modalities, this approach generates more comprehensive and contextually richer item representations. Extensive experiments conducted on two widely used benchmarks demonstrate that our method outperforms existing prompting baselines in downstream recommendation accuracy. Additionally, we evaluate the generalizability of our framework across different LMM backbones and the robustness of the prompting strategies, offering insights for optimization. This work underscores the importance of integrating multimodal information and presents a novel solution for improving item understanding in multimodal recommendation systems.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15181",
        "abstract url": "https://arxiv.org/abs/2408.15181",
        "title": "On the parameterized complexity of computing good edge-labelings",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A good edge-labeling (gel for short) of a graph $G$ is a function $\u03bb: E(G) \\to \\mathbb{R}$ such that, for any ordered pair of vertices $(x, y)$ of $G$, there do not exist two distinct increasing paths from $x$ to $y$, where ``increasing'' means that the sequence of labels is non-decreasing. This notion was introduced by Bermond et al. [Theor. Comput. Sci. 2013] motivated by practical applications arising from routing and wavelength assignment problems in optical networks. Prompted by the lack of algorithmic results about the problem of deciding whether an input graph admits a gel, called GEL, we initiate its study from the viewpoint of parameterized complexity. We first introduce the natural version of GEL where one wants to use at most $c$ distinct labels, which we call $c$-GEL, and we prove that it is NP-complete for every $c \\geq 2$ on very restricted instances. We then provide several positive results, starting with simple polynomial kernels for GEL and $c$-\\GEL parameterized by neighborhood diversity or vertex cover. As one of our main technical contributions, we present an FPT algorithm for GEL parameterized by the size of a modulator to a forest of stars, based on a novel approach via a 2-SAT formulation which we believe to be of independent interest. We also present FPT algorithms based on dynamic programming for $c$-GEL parameterized by treewidth and $c$, and for GEL parameterized by treewidth and the maximum degree. Finally, we answer positively a question of Bermond et al. [Theor. Comput. Sci. 2013] by proving the NP-completeness of a problem strongly related to GEL, namely that of deciding whether an input graph admits a so-called UPP-orientation.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "comment": "46 pages, 16 figures"
    },
    {
        "paper id": "2408.15184",
        "abstract url": "https://arxiv.org/abs/2408.15184",
        "title": "Pushing Tree Decompositions Forward Along Graph Homomorphisms",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "It is folklore that tree-width is monotone under taking subgraphs (i.e. injective graph homomorphisms) and contractions (certain kinds of surjective graph homomorphisms). However, although tree-width is obviously not monotone under any surjective graph homomorphism, it is not clear whether contractions are canonically the only class of surjections with respect to which it is monotone. We prove that this is indeed the case: we show that - up to isomorphism - contractions are the only surjective graph homomorphisms that preserve tree decompositions and the shape of the decomposition tree. Furthermore, our results provide a framework for answering questions of this sort for many other kinds of combinatorial data structures (such as directed multigraphs, hypergraphs, Petri nets, circular port graphs, half-edge graphs, databases, simplicial complexes etc.) for which natural analogues of tree decompositions can be defined.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "math.CT"
        ],
        "comment": "28 pages excluding appendix"
    },
    {
        "paper id": "2408.15188",
        "abstract url": "https://arxiv.org/abs/2408.15188",
        "title": "Infusing Acoustic Pause Context into Text-Based Dementia Assessment",
        "rating": "-1",
        "keywords": [
            [
                "biomarker",
                "clinical"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech pauses, alongside content and structure, offer a valuable and non-invasive biomarker for detecting dementia. This work investigates the use of pause-enriched transcripts in transformer-based language models to differentiate the cognitive states of subjects with no cognitive impairment, mild cognitive impairment, and Alzheimer's dementia based on their speech from a clinical assessment. We address three binary classification tasks: Onset, monitoring, and dementia exclusion. The performance is evaluated through experiments on a German Verbal Fluency Test and a Picture Description Test, comparing the model's effectiveness across different speech production contexts. Starting from a textual baseline, we investigate the effect of incorporation of pause information and acoustic context. We show the test should be chosen depending on the task, and similarly, lexical pause information and acoustic cross-attention contribute differently.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.SD"
        ],
        "comment": "Accepted at INTERSPEECH 2024"
    },
    {
        "paper id": "2408.15199",
        "abstract url": "https://arxiv.org/abs/2408.15199",
        "title": "Crossing Rays: Evaluation of Bimanual Mid-air Selection Techniques in an Immersive Environment",
        "rating": "-1",
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "Mid-air navigation offers a method of aerial travel that mitigates the constraints associated with continuous navigation. A mid-air selection technique is essential to enable such navigation. In this paper, we consider four variations of intersection-based bimanual mid-air selection techniques with visual aids and supporting features: Simple-Ray, Simple-Stripe, Precision-Stripe, and Cursor-Sync. We evaluate their performance and user experience compared to an unimanual mid-air selection technique using two tasks that require selecting a mid-air position with or without a reference object. Our findings indicate that the bimanual techniques generally demonstrate faster selection times compared to the unimanual technique. With a supporting feature, the bimanual techniques can provide a more accurate selection than the unimanual technique. Based on our results, we discuss the effect of selection technique's visual aids and supporting features on performance and user experience for mid-air selection.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "This paper is accepted as a conference paper on ISMAR 2024"
    },
    {
        "paper id": "2408.15200",
        "abstract url": "https://arxiv.org/abs/2408.15200",
        "title": "SpecGuard: Specification Aware Recovery for Robotic Autonomous Vehicles from Physical Attacks",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Robotic Autonomous Vehicles (RAVs) rely on their sensors for perception, and follow strict mission specifications (e.g., altitude, speed, and geofence constraints) for safe and timely operations. Physical attacks can corrupt the RAVs' sensors, resulting in mission failures. Recovering RAVs from such attacks demands robust control techniques that maintain compliance with mission specifications even under attacks to ensure the RAV's safety and timely operations. We propose SpecGuard, a technique that complies with mission specifications and performs safe recovery of RAVs. There are two innovations in SpecGuard. First, it introduces an approach to incorporate mission specifications and learn a recovery control policy using Deep Reinforcement Learning (Deep-RL). We design a compliance-based reward structure that reflects the RAV's complex dynamics and enables SpecGuard to satisfy multiple mission specifications simultaneously. Second, SpecGuard incorporates state reconstruction, a technique that minimizes attack induced sensor perturbations. This reconstruction enables effective adversarial training, and optimizing the recovery control policy for robustness under attacks. We evaluate SpecGuard in both virtual and real RAVs, and find that it achieves 92% recovery success rate under attacks on different sensors, without any crashes or stalls. SpecGuard achieves 2X higher recovery success than prior work, and incurs about 15% performance overhead on real RAVs.",
        "subjects": [
            "cs.RO",
            "cs.CR",
            "eess.SY"
        ],
        "comment": "CCS'24 (a shorter version of this paper will appear in the conference proceeding)"
    },
    {
        "paper id": "2408.15207",
        "abstract url": "https://arxiv.org/abs/2408.15207",
        "title": "Investigating Coverage Criteria in Large Language Models: An In-Depth Study Through Jailbreak Attacks",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "The swift advancement of large language models (LLMs) has profoundly shaped the landscape of artificial intelligence; however, their deployment in sensitive domains raises grave concerns, particularly due to their susceptibility to malicious exploitation. This situation underscores the insufficiencies in pre-deployment testing, highlighting the urgent need for more rigorous and comprehensive evaluation methods. This study presents a comprehensive empirical analysis assessing the efficacy of conventional coverage criteria in identifying these vulnerabilities, with a particular emphasis on the pressing issue of jailbreak attacks. Our investigation begins with a clustering analysis of the hidden states in LLMs, demonstrating that intrinsic characteristics of these states can distinctly differentiate between various types of queries. Subsequently, we assess the performance of these criteria across three critical dimensions: criterion level, layer level, and token level. Our findings uncover significant disparities in neuron activation patterns between the processing of normal and jailbreak queries, thereby corroborating the clustering results. Leveraging these findings, we propose an innovative approach for the real-time detection of jailbreak attacks by utilizing neural activation features. Our classifier demonstrates remarkable accuracy, averaging 96.33% in identifying jailbreak queries, including those that could lead to adversarial attacks. The importance of our research lies in its comprehensive approach to addressing the intricate challenges of LLM security. By enabling instantaneous detection from the model's first token output, our method holds promise for future systems integrating LLMs, offering robust real-time detection capabilities. This study advances our understanding of LLM security testing, and lays a critical foundation for the development of more resilient AI systems.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15342",
        "abstract url": "https://arxiv.org/abs/2408.15342",
        "title": "Multi-domain Network Slice Partitioning: A Graph Neural Network Algorithm",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "In the context of multi-domain network slices, multiple domains need to work together to provide a service. The problem of determining which part of the service fits within which domain is referred to as slice partitioning. The partitioning of multi-domain network slices poses a challenging problem, particularly when striving to strike the right balance between inter-domain and intra-domain costs, as well as ensuring optimal load distribution within each domain. To approach the optimal partition solution while maintaining load balance between domains, a framework has been proposed. This framework not only generates partition plans with various characteristics but also employs a Graph Neural Network solver, which significantly reduces the plan generation time. The proposed approach is promising in generating partition plans for multi-domain network slices and is expected to improve the overall performance of the network.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15348",
        "abstract url": "https://arxiv.org/abs/2408.15348",
        "title": "A parallel particle cluster algorithm using nearest neighbour graphs and passive target communication",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "We present a parallel cluster algorithm for $N$-body simulations which uses a nearest neighbour search algorithm and one-sided messaging passing interface (MPI) communication. The nearest neighbour is defined by the Euclidean distance in three-dimensional space. The resulting directed nearest neighbour graphs that are used to define the clusters are split up in an iterative procedure with MPI remote memory access (RMA) communication. The method has been implemented as part of the elliptical parcel-in-cell (EPIC) method targeting geophysical fluid flows. The parallel scalability of the algorithm is discussed by means of an artificial and a standard fluid dynamics test case. The cluster algorithm shows good weak and strong scalability up to 16,384 cores with a parallel weak scaling efficiency of about 80% for balanced workloads. In poorly balanced problems, MPI synchronisation dominates execution of the cluster algorithm and thus drastically worsens its parallel scalability.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "19 pages, 14 figures, 7 tables"
    },
    {
        "paper id": "2408.15354",
        "abstract url": "https://arxiv.org/abs/2408.15354",
        "title": "What Is Required for Empathic AI? It Depends, and Why That Matters for AI Developers and Users",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CY"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Interest is growing in artificial empathy, but so is confusion about what artificial empathy is or needs to be. This confusion makes it challenging to navigate the technical and ethical issues that accompany empathic AI development. Here, we outline a framework for thinking about empathic AI based on the premise that different constellations of capabilities associated with empathy are important for different empathic AI applications. We describe distinctions of capabilities that we argue belong under the empathy umbrella, and show how three medical empathic AI use cases require different sets of these capabilities. We conclude by discussing why appreciation of the diverse capabilities under the empathy umbrella is important for both AI creators and users.",
        "subjects": [
            "cs.AI",
            "cs.CY",
            "cs.HC"
        ],
        "comment": "To appear at the 7th AAAI/ACM Conference on AI, Ethics, and Society, 2024"
    },
    {
        "paper id": "2408.15355",
        "abstract url": "https://arxiv.org/abs/2408.15355",
        "title": "Optimizing Lung Cancer Detection in CT Imaging: A Wavelet Multi-Layer Perceptron (WMLP) Approach Enhanced by Dragonfly Algorithm (DA)",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "CT",
                "Cancer",
                "disease"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Lung cancer stands as the preeminent cause of cancer-related mortality globally. Prompt and precise diagnosis, coupled with effective treatment, is imperative to reduce the fatality rates associated with this formidable disease. This study introduces a cutting-edge deep learning framework for the classification of lung cancer from CT scan imagery. The research encompasses a suite of image pre-processing strategies, notably Canny edge detection, and wavelet transformations, which precede the extraction of salient features and subsequent classification via a Multi-Layer Perceptron (MLP). The optimization process is further refined using the Dragonfly Algorithm (DA). The methodology put forth has attained an impressive training and testing accuracy of 99.82\\%, underscoring its efficacy and reliability in the accurate diagnosis of lung cancer.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15366",
        "abstract url": "https://arxiv.org/abs/2408.15366",
        "title": "Pitfalls and Outlooks in Using COMET",
        "rating": "-1",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Since its introduction, the COMET metric has blazed a trail in the machine translation community, given its strong correlation with human judgements of translation quality. Its success stems from being a modified pre-trained multilingual model finetuned for quality assessment. However, it being a machine learning model also gives rise to a new set of pitfalls that may not be widely known. We investigate these unexpected behaviours from three aspects: 1) technical: obsolete software versions and compute precision; 2) data: empty content, language mismatch, and translationese at test time as well as distribution and domain biases in training; 3) usage and reporting: multi-reference support and model referencing in the literature. All of these problems imply that COMET scores is not comparable between papers or even technical setups and we put forward our perspective on fixing each issue. Furthermore, we release the SacreCOMET package that can generate a signature for the software and model configuration as well as an appropriate citation. The goal of this work is to help the community make more sound use of the COMET metric.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15367",
        "abstract url": "https://arxiv.org/abs/2408.15367",
        "title": "How Much is too Much: Exploring the Effect of Verbal Route Description Length on Indoor Navigation",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "Navigation"
            ]
        ],
        "abstract": "Navigating through a new indoor environment can be stressful. Recently, many places have deployed robots to assist visitors. One of the features of such robots is escorting the visitors to their desired destination within the environment, but this is neither scalable nor necessary for every visitor. Instead, a robot assistant could be deployed at a strategic location to provide wayfinding instructions. This not only increases the user experience but can be helpful in many time-critical scenarios e.g., escorting someone to their boarding gate at an airport. However, delivering route descriptions verbally poses a challenge. If the description is too verbose, people may struggle to recall all the information, while overly brief descriptions may be simply unhelpful. This article focuses on studying the optimal length of verbal route descriptions that are effective for reaching the destination and easy for people to recall. This work proposes a theoretical framework that links route segments to chunks in working memory. Based on this framework, an experiment is designed and conducted to examine the effects of route descriptions of different lengths on navigational performance. The results revealed intriguing patterns suggesting an ideal length of four route segments. This study lays a foundation for future research exploring the relationship between route description lengths, working memory capacity, and navigational performance in indoor environments.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "Accepted in IEEE ROMAN 2024"
    },
    {
        "paper id": "2408.15375",
        "abstract url": "https://arxiv.org/abs/2408.15375",
        "title": "Signals as submanifolds, and configurations of points",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "For the purposes of abstract theory of signal propagation, a signal is a submanifold of a Riemannian manifold. We obtain energy inequalities, or upper bounds, lower bounds on energy in a number of specific cases, including parameter spaces of Gaussians and spaces of configurations of points. We discuss the role of time as well as graph embeddings.",
        "subjects": [
            "cs.IT",
            "math.DG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15391",
        "abstract url": "https://arxiv.org/abs/2408.15391",
        "title": "Examining the Interplay Between Privacy and Fairness for Speech Processing: A Review and Perspective",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech technology has been increasingly deployed in various areas of daily life including sensitive domains such as healthcare and law enforcement. For these technologies to be effective, they must work reliably for all users while preserving individual privacy. Although tradeoffs between privacy and utility, as well as fairness and utility, have been extensively researched, the specific interplay between privacy and fairness in speech processing remains underexplored. This review and position paper offers an overview of emerging privacy-fairness tradeoffs throughout the entire machine learning lifecycle for speech processing. By drawing on well-established frameworks on fairness and privacy, we examine existing biases and sources of privacy harm that coexist during the development of speech processing models. We then highlight how corresponding privacy-enhancing technologies have the potential to inadvertently increase these biases and how bias mitigation strategies may conversely reduce privacy. By raising open questions, we advocate for a comprehensive evaluation of privacy-fairness tradeoffs for speech technology and the development of privacy-enhancing and fairness-aware algorithms in this domain.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15398",
        "abstract url": "https://arxiv.org/abs/2408.15398",
        "title": "Evaluating Pre-Training Bias on Severe Acute Respiratory Syndrome Dataset",
        "rating": "-1",
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Machine learning (ML) is a growing field of computer science that has found many practical applications in several domains, including Health. However, as data grows in size and availability, and the number of models that aim to aid or replace human decisions, it raises the concern that these models can be susceptible to bias, which can lead to harm to specific individuals by basing its decisions on protected attributes such as gender, religion, sexual orientation, ethnicity, and others. Visualization techniques might generate insights and help summarize large datasets, enabling data scientists to understand the data better before training a model by evaluating pre-training metrics applied to the datasets before training, which might contribute to identifying potential harm before any effort is put into training and deploying the models. This work uses the severe acute respiratory syndrome dataset from OpenDataSUS to visualize three pre-training bias metrics and their distribution across different regions in Brazil. A random forest model is trained in each region and applied to the others. The aim is to compare the bias for the different regions, focusing on their protected attributes and comparing the model's performance with the metric values.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "short paper for eurovis, 5 pages"
    },
    {
        "paper id": "2408.15406",
        "abstract url": "https://arxiv.org/abs/2408.15406",
        "title": "Intertwined Biases Across Social Media Spheres: Unpacking Correlations in Media Bias Dimensions",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "Media bias significantly shapes public perception by reinforcing stereotypes and exacerbating societal divisions. Prior research has often focused on isolated media bias dimensions such as \\textit{political bias} or \\textit{racial bias}, neglecting the complex interrelationships among various bias dimensions across different topic domains. Moreover, we observe that models trained on existing media bias benchmarks fail to generalize effectively on recent social media posts, particularly in certain bias identification tasks. This shortfall primarily arises because these benchmarks do not adequately reflect the rapidly evolving nature of social media content, which is characterized by shifting user behaviors and emerging trends. In response to these limitations, our research introduces a novel dataset collected from YouTube and Reddit over the past five years. Our dataset includes automated annotations for YouTube content across a broad spectrum of bias dimensions, such as gender, racial, and political biases, as well as hate speech, among others. It spans diverse domains including politics, sports, healthcare, education, and entertainment, reflecting the complex interplay of biases across different societal sectors. Through comprehensive statistical analysis, we identify significant differences in bias expression patterns and intra-domain bias correlations across these domains. By utilizing our understanding of the correlations among various bias dimensions, we lay the groundwork for creating advanced systems capable of detecting multiple biases simultaneously. Overall, our dataset advances the field of media bias identification, contributing to the development of tools that promote fairer media consumption. The comprehensive awareness of existing media bias fosters more ethical journalism, promotes cultural sensitivity, and supports a more informed and equitable public discourse.",
        "subjects": [
            "cs.SI",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Accepted to ASONAM 2024"
    },
    {
        "paper id": "2408.15420",
        "abstract url": "https://arxiv.org/abs/2408.15420",
        "title": "Showing the Receipts: Understanding the Modern Ransomware Ecosystem",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Ransomware attacks continue to wreak havoc across the globe, with public reports of total ransomware payments topping billions of dollars annually. While the use of cryptocurrency presents an avenue to understand the tactics of ransomware actors, to date published research has been constrained by relatively limited public datasets of ransomware payments. We present novel techniques to identify ransomware payments with low false positives, classifying nearly \\$700 million in previously-unreported ransomware payments. We publish the largest public dataset of over \\$900 million in ransomware payments -- several times larger than any existing public dataset. We then leverage this expanded dataset to present an analysis focused on understanding the activities of ransomware groups over time. This provides unique insights into ransomware behavior and a corpus for future study of ransomware cybercriminal activity.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "To be published in 2024 APWG Symposium on Electronic Crime Research (eCrime)"
    },
    {
        "paper id": "2408.15434",
        "abstract url": "https://arxiv.org/abs/2408.15434",
        "title": "Weighted Matching in the Random-Order Streaming and Robust Communication Models",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We study the maximum weight matching problem in the random-order semi-streaming model and in the robust communication model. Unlike many other sublinear models, in these two frameworks, there is a large gap between the guarantees of the best known algorithms for the unweighted and weighted versions of the problem. In the random-order semi-streaming setting, the edges of an $n$-vertex graph arrive in a stream in a random order. The goal is to compute an approximate maximum weight matching with a single pass over the stream using $O(n\\text{ polylog } n)$ space. Our main result is a $(2/3-\u03b5)$-approximation algorithm for maximum weight matching in random-order streams, using space $O(n \\log n \\log R)$, where $R$ is the ratio between the heaviest and the lightest edge in the graph. Our result nearly matches the best known unweighted $(2/3+\u03b5_0)$-approximation (where $\u03b5_0 \\sim 10^{-14}$ is a small constant) achieved by Assadi and Behnezhad [ICALP 2021], and significantly improves upon previous weighted results. Our techniques also extend to the related robust communication model, in which the edges of a graph are partitioned randomly between Alice and Bob. Alice sends a single message of size $O(n\\text{ polylog }n)$ to Bob, who must compute an approximate maximum weight matching. We achieve a $(5/6-\u03b5)$-approximation using $O(n \\log n \\log R)$ words of communication, matching the results of Azarmehr and Behnezhad [ICALP 2023] for unweighted graphs.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15474",
        "abstract url": "https://arxiv.org/abs/2408.15474",
        "title": "Drop the beat! Freestyler for Accompaniment Conditioned Rapping Voice Generation",
        "rating": "-1",
        "keywords": [
            [
                "song"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Rap, a prominent genre of vocal performance, remains underexplored in vocal generation. General vocal synthesis depends on precise note and duration inputs, requiring users to have related musical knowledge, which limits flexibility. In contrast, rap typically features simpler melodies, with a core focus on a strong rhythmic sense that harmonizes with accompanying beats. In this paper, we propose Freestyler, the first system that generates rapping vocals directly from lyrics and accompaniment inputs. Freestyler utilizes language model-based token generation, followed by a conditional flow matching model to produce spectrograms and a neural vocoder to restore audio. It allows a 3-second prompt to enable zero-shot timbre control. Due to the scarcity of publicly available rap datasets, we also present RapBank, a rap song dataset collected from the internet, alongside a meticulously designed processing pipeline. Experimental results show that Freestyler produces high-quality rapping voice generation with enhanced naturalness and strong alignment with accompanying beats, both stylistically and rhythmically.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15490",
        "abstract url": "https://arxiv.org/abs/2408.15490",
        "title": "Symbiotic Sensing and Communication: Framework and Beamforming Design",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "In this paper, we propose a novel symbiotic sensing and communication (SSAC) framework, comprising a base station (BS) and a passive sensing node. In particular, the BS transmits communication waveform to serve vehicle users (VUEs), while the sensing node is employed to execute sensing tasks based on the echoes in a bistatic manner, thereby avoiding the issue of self-interference. Besides the weak target of interest, the sensing node tracks VUEs and shares sensing results with BS to facilitate sensing-assisted beamforming. By considering both fully digital arrays and hybrid analog-digital (HAD) arrays, we investigate the beamforming design in the SSAC system. We first derive the Cramer-Rao lower bound (CRLB) of the two-dimensional angles of arrival estimation as the sensing metric. Next, we formulate an achievable sum rate maximization problem under the CRLB constraint, where the channel state information is reconstructed based on the sensing results. Then, we propose two penalty dual decomposition (PDD)-based alternating algorithms for fully digital and HAD arrays, respectively. Simulation results demonstrate that the proposed algorithms can achieve an outstanding data rate with effective localization capability for both VUEs and the weak target. In particular, the HAD beamforming design exhibits remarkable performance gain compared to conventional schemes, especially with fewer radio frequency chains.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "16 pages, 11 figures, submitted to IEEE journals for possible publication"
    },
    {
        "paper id": "2408.15497",
        "abstract url": "https://arxiv.org/abs/2408.15497",
        "title": "On the Existence of Linear Observed Systems on Manifolds with Connection",
        "rating": "-1",
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "Linear observed systems on manifolds are a special class of nonlinear systems whose state spaces are smooth manifolds but possess properties similar to linear systems. Such properties can be characterized by the ability to conduct preintegration and exact linearization with Jacobians independent of the linearization point. IMU dynamics in navigation can be constructed into linear observed settings, leading to invariant filters with guaranteed behaviors such as local convergence and consistency. In this letter, we establish linear observed property for dynamics evolving on an arbitrary smooth manifold through the connection structure endowed upon this space. Our key findings are the existence of linear observed systems on manifolds poses strong constraints on the state space itself, apart from requiring the dynamics to be in some specific forms. The existence of such systems is equivalent to the flatness of the state space, forcing the manifold to admit a group structure under mild topological assumptions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages, 2 figures"
    },
    {
        "paper id": "2408.15503",
        "abstract url": "https://arxiv.org/abs/2408.15503",
        "title": "RoboSense: Large-scale Dataset and Benchmark for Multi-sensor Low-speed Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving",
                "LiDAR",
                "Vehicle"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Robust object detection and tracking under arbitrary sight of view is challenging yet essential for the development of Autonomous Vehicle technology. With the growing demand of unmanned function vehicles, near-field scene understanding becomes an important research topic in the areas of low-speed autonomous driving. Due to the complexity of driving conditions and diversity of near obstacles such as blind spots and high occlusion, the perception capability of near-field environment is still inferior than its farther counterpart. To further enhance the intelligent ability of unmanned vehicles, in this paper, we construct a multimodal data collection platform based on 3 main types of sensors (Camera, LiDAR and Fisheye), which supports flexible sensor configurations to enable dynamic sight of view for ego vehicle, either global view or local view. Meanwhile, a large-scale multi-sensor dataset is built, named RoboSense, to facilitate near-field scene understanding. RoboSense contains more than 133K synchronized data with 1.4M 3D bounding box and IDs annotated in the full $360^{\\circ}$ view, forming 216K trajectories across 7.6K temporal sequences. It has $270\\times$ and $18\\times$ as many annotations of near-field obstacles within 5$m$ as the previous single-vehicle datasets such as KITTI and nuScenes. Moreover, we define a novel matching criterion for near-field 3D perception and prediction metrics. Based on RoboSense, we formulate 6 popular tasks to facilitate the future development of related research, where the detailed data analysis as well as benchmarks are also provided accordingly.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.16530",
        "abstract url": "https://arxiv.org/abs/2408.16530",
        "title": "A Comprehensive Review of 3D Object Detection in Autonomous Driving: Technological Advances and Future Directions",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, 3D object perception has become a crucial component in the development of autonomous driving systems, providing essential environmental awareness. However, as perception tasks in autonomous driving evolve, their variants have increased, leading to diverse insights from industry and academia. Currently, there is a lack of comprehensive surveys that collect and summarize these perception tasks and their developments from a broader perspective. This review extensively summarizes traditional 3D object detection methods, focusing on camera-based, LiDAR-based, and fusion detection techniques. We provide a comprehensive analysis of the strengths and limitations of each approach, highlighting advancements in accuracy and robustness. Furthermore, we discuss future directions, including methods to improve accuracy such as temporal perception, occupancy grids, and end-to-end learning frameworks. We also explore cooperative perception methods that extend the perception range through collaborative communication. By providing a holistic view of the current state and future developments in 3D object perception, we aim to offer a more comprehensive understanding of perception tasks for autonomous driving. Additionally, we have established an active repository to provide continuous updates on the latest advancements in this field, accessible at: https://github.com/Fishsoup0/Autonomous-Driving-Perception.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14780",
        "abstract url": "https://arxiv.org/abs/2408.14780",
        "title": "GINN-KAN: Interpretability pipelining with applications in Physics Informed Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Neural networks are powerful function approximators, yet their ``black-box\" nature often renders them opaque and difficult to interpret. While many post-hoc explanation methods exist, they typically fail to capture the underlying reasoning processes of the networks. A truly interpretable neural network would be trained similarly to conventional models using techniques such as backpropagation, but additionally provide insights into the learned input-output relationships. In this work, we introduce the concept of interpretability pipelineing, to incorporate multiple interpretability techniques to outperform each individual technique. To this end, we first evaluate several architectures that promise such interpretability, with a particular focus on two recent models selected for their potential to incorporate interpretability into standard neural network architectures while still leveraging backpropagation: the Growing Interpretable Neural Network (GINN) and Kolmogorov Arnold Networks (KAN). We analyze the limitations and strengths of each and introduce a novel interpretable neural network GINN-KAN that synthesizes the advantages of both models. When tested on the Feynman symbolic regression benchmark datasets, GINN-KAN outperforms both GINN and KAN. To highlight the capabilities and the generalizability of this approach, we position GINN-KAN as an alternative to conventional black-box networks in Physics-Informed Neural Networks (PINNs). We expect this to have far-reaching implications in the application of deep learning pipelines in the natural sciences. Our experiments with this interpretable PINN on 15 different partial differential equations demonstrate that GINN-KAN augmented PINNs outperform PINNs with black-box networks in solving differential equations and surpass the capabilities of both GINN and KAN.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14865",
        "abstract url": "https://arxiv.org/abs/2408.14865",
        "title": "Data downlink prioritization using image classification on-board a 6U CubeSat",
        "rating": "-1.5",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Nanosatellites are proliferating as low-cost dedicated sensing systems with lean development cycles. Kyushu Institute of Technology and collaborators have launched a joint venture for a nanosatellite mission, VERTECS. The primary mission is to elucidate the formation history of stars by observing the optical-wavelength cosmic background radiation. The VERTECS satellite will be equipped with a small-aperture telescope and a high-precision attitude control system to capture the cosmic data for analysis on the ground. However, nanosatellites are limited by their onboard memory resources and downlink speed capabilities. Additionally, due to a limited number of ground stations, the satellite mission will face issues meeting the required data budget for mission success. To alleviate this issue, we propose an on-orbit system to autonomously classify and then compress desirable image data for data downlink prioritization and optimization. The system comprises a prototype Camera Controller Board (CCB) which carries a Raspberry Pi Compute Module 4 which is used for classification and compression. The system uses a lightweight Convolutional Neural Network (CNN) model to classify and determine the desirability of captured image data. The model is designed to be lean and robust to reduce the computational and memory load on the satellite. The model is trained and tested on a novel star field dataset consisting of data captured by the Sloan Digital Sky Survey (SDSS). The dataset is meant to simulate the expected data produced by the 6U satellite. The compression step implements GZip, RICE or HCOMPRESS compression, which are standards for astronomical data. Preliminary testing on the proposed CNN model results in a classification accuracy of about 100\\% on the star field dataset, with compression ratios of 3.99, 5.16 and 5.43 for GZip, RICE and HCOMPRESS that were achieved on tested FITS image data.",
        "subjects": [
            "astro-ph.IM",
            "cs.LG"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2408.14889",
        "abstract url": "https://arxiv.org/abs/2408.14889",
        "title": "Towards turbine-location-aware multi-decadal wind power predictions with CMIP6",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the increasing amount of renewable energy in the grid, long-term wind power forecasting for multiple decades becomes more critical. In these long-term forecasts, climate data is essential as it allows us to account for climate change. Yet the resolution of climate models is often very coarse. In this paper, we show that by including turbine locations when downscaling with Gaussian Processes, we can generate valuable aggregate wind power predictions despite the low resolution of the CMIP6 climate models. This work is a first step towards multi-decadal turbine-location-aware wind power forecasting using global climate model output.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": "4 pages, pre-print"
    },
    {
        "paper id": "2408.14915",
        "abstract url": "https://arxiv.org/abs/2408.14915",
        "title": "Can Transformers Do Enumerative Geometry?",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "How can Transformers model and learn enumerative geometry? What is a robust procedure for using Transformers in abductive knowledge discovery within a mathematician-machine collaboration? In this work, we introduce a new paradigm in computational enumerative geometry in analyzing the $\u03c8$-class intersection numbers on the moduli space of curves. By formulating the enumerative problem as a continuous optimization task, we develop a Transformer-based model for computing $\u03c8$-class intersection numbers based on the underlying quantum Airy structure. For a finite range of genera, our model is capable of regressing intersection numbers that span an extremely wide range of values, from $10^{-45}$ to $10^{45}$. To provide a proper inductive bias for capturing the recursive behavior of intersection numbers, we propose a new activation function, Dynamic Range Activator (DRA). Moreover, given the severe heteroscedasticity of $\u03c8$-class intersections and the required precision, we quantify the uncertainty of the predictions using Conformal Prediction with a dynamic sliding window that is aware of the number of marked points. Next, we go beyond merely computing intersection numbers and explore the enumerative \"world-model\" of the Transformers. Through a series of causal inference and correlational interpretability analyses, we demonstrate that Transformers are actually modeling Virasoro constraints in a purely data-driven manner. Additionally, we provide evidence for the comprehension of several values appearing in the large genus asymptotic of $\u03c8$-class intersection numbers through abductive hypothesis testing.",
        "subjects": [
            "cs.LG",
            "math.AG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14916",
        "abstract url": "https://arxiv.org/abs/2408.14916",
        "title": "Towards Real-world Event-guided Low-light Video Enhancement and Deblurring",
        "rating": "-1.5",
        "keywords": [
            [
                "Event cameras"
            ],
            [
                "Video Enhancement"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "In low-light conditions, capturing videos with frame-based cameras often requires long exposure times, resulting in motion blur and reduced visibility. While frame-based motion deblurring and low-light enhancement have been studied, they still pose significant challenges. Event cameras have emerged as a promising solution for improving image quality in low-light environments and addressing motion blur. They provide two key advantages: capturing scene details well even in low light due to their high dynamic range, and effectively capturing motion information during long exposures due to their high temporal resolution. Despite efforts to tackle low-light enhancement and motion deblurring using event cameras separately, previous work has not addressed both simultaneously. To explore the joint task, we first establish real-world datasets for event-guided low-light enhancement and deblurring using a hybrid camera system based on beam splitters. Subsequently, we introduce an end-to-end framework to effectively handle these tasks. Our framework incorporates a module to efficiently leverage temporal information from events and frames. Furthermore, we propose a module to utilize cross-modal feature information to employ a low-pass filter for noise suppression while enhancing the main structural information. Our proposed method significantly outperforms existing approaches in addressing the joint task. Our project pages are available at https://github.com/intelpro/ELEDNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in ECCV2024"
    },
    {
        "paper id": "2408.15057",
        "abstract url": "https://arxiv.org/abs/2408.15057",
        "title": "Subgroup Analysis via Model-based Rule Forest",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning models are often criticized for their black-box nature, raising concerns about their applicability in critical decision-making scenarios. Consequently, there is a growing demand for interpretable models in such contexts. In this study, we introduce Model-based Deep Rule Forests (mobDRF), an interpretable representation learning algorithm designed to extract transparent models from data. By leveraging IF-THEN rules with multi-level logic expressions, mobDRF enhances the interpretability of existing models without compromising accuracy. We apply mobDRF to identify key risk factors for cognitive decline in an elderly population, demonstrating its effectiveness in subgroup analysis and local model optimization. Our method offers a promising solution for developing trustworthy and interpretable machine learning models, particularly valuable in fields like healthcare, where understanding differential effects across patient subgroups can lead to more personalized and effective treatments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15076",
        "abstract url": "https://arxiv.org/abs/2408.15076",
        "title": "MiWaves Reinforcement Learning Algorithm",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The escalating prevalence of cannabis use poses a significant public health challenge globally. In the U.S., cannabis use is more prevalent among emerging adults (EAs) (ages 18-25) than any other age group, with legalization in the multiple states contributing to a public perception that cannabis is less risky than in prior decades. To address this growing concern, we developed MiWaves, a reinforcement learning (RL) algorithm designed to optimize the delivery of personalized intervention prompts to reduce cannabis use among EAs. MiWaves leverages domain expertise and prior data to tailor the likelihood of delivery of intervention messages. This paper presents a comprehensive overview of the algorithm's design, including key decisions and experimental outcomes. The finalized MiWaves RL algorithm was deployed in a clinical trial from March to May 2024.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2402.17739"
    },
    {
        "paper id": "2408.15113",
        "abstract url": "https://arxiv.org/abs/2408.15113",
        "title": "AnomalousPatchCore: Exploring the Use of Anomalous Samples in Industrial Anomaly Detection",
        "rating": "-1.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Visual inspection, or industrial anomaly detection, is one of the most common quality control types in manufacturing. The task is to identify the presence of an anomaly given an image, e.g., a missing component on an image of a circuit board, for subsequent manual inspection. While industrial anomaly detection has seen a surge in recent years, most anomaly detection methods still utilize knowledge only from normal samples, failing to leverage the information from the frequently available anomalous samples. Additionally, they heavily rely on very general feature extractors pre-trained on common image classification datasets. In this paper, we address these shortcomings and propose the new anomaly detection system AnomalousPatchCore~(APC) based on a feature extractor fine-tuned with normal and anomalous in-domain samples and a subsequent memory bank for identifying unusual features. To fine-tune the feature extractor in APC, we propose three auxiliary tasks that address the different aspects of anomaly detection~(classification vs. localization) and mitigate the effect of the imbalance between normal and anomalous samples. Our extensive evaluation on the MVTec dataset shows that APC outperforms state-of-the-art systems in detecting anomalies, which is especially important in industrial anomaly detection given the subsequent manual inspection. In detailed ablation studies, we further investigate the properties of our APC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at the 2nd workshop on Vision-based InduStrial InspectiON (VISION) @ ECCV"
    },
    {
        "paper id": "2408.15121",
        "abstract url": "https://arxiv.org/abs/2408.15121",
        "title": "Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "Biomedical",
                "medical",
                "healthcare",
                "disease"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Significant investment and development have gone into integrating Artificial Intelligence (AI) in medical and healthcare applications, leading to advanced control systems in medical technology. However, the opacity of AI systems raises concerns about essential characteristics needed in such sensitive applications, like transparency and trustworthiness. Our study addresses these concerns by investigating a process for selecting the most adequate Explainable AI (XAI) methods to comply with the explanation requirements of key EU regulations in the context of smart bioelectronics for medical devices. The adopted methodology starts with categorising smart devices by their control mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving into their technology. Then, we analyse these regulations to define their explainability requirements for the various devices and related goals. Simultaneously, we classify XAI methods by their explanatory objectives. This allows for matching legal explainability requirements with XAI explanatory goals and determining the suitable XAI algorithms for achieving them. Our findings provide a nuanced understanding of which XAI algorithms align better with EU regulations for different types of medical devices. We demonstrate this through practical case studies on different neural implants, from chronic disease management to advanced prosthetics. This study fills a crucial gap in aligning XAI applications in bioelectronics with stringent provisions of EU regulations. It provides a practical framework for developers and researchers, ensuring their AI innovations advance healthcare technology and adhere to legal and ethical standards.",
        "subjects": [
            "cs.AI",
            "cs.CY"
        ],
        "comment": "Accepted for publication at ECAI 2024, main-track"
    },
    {
        "paper id": "2408.15126",
        "abstract url": "https://arxiv.org/abs/2408.15126",
        "title": "Force-Guided Bridge Matching for Full-Atom Time-Coarsened Dynamics of Peptides",
        "rating": "-1.5",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Molecular Dynamics (MD) simulations are irreplaceable and ubiquitous in fields of materials science, chemistry, pharmacology just to name a few. Conventional MD simulations are plagued by numerical stability as well as long equilibration time issues, which limits broader applications of MD simulations. Recently, a surge of deep learning approaches have been devised for time-coarsened dynamics, which learns the state transition mechanism over much larger time scales to overcome these limitations. However, only a few methods target the underlying Boltzmann distribution by resampling techniques, where proposals are rarely accepted as new states with low efficiency. In this work, we propose a force-guided bridge matching model, FBM, a novel framework that first incorporates physical priors into bridge matching for full-atom time-coarsened dynamics. With the guidance of our well-designed intermediate force field, FBM is feasible to target the Boltzmann-like distribution by direct inference without extra steps. Experiments on small peptides verify our superiority in terms of comprehensive metrics and demonstrate transferability to unseen peptide systems.",
        "subjects": [
            "physics.chem-ph",
            "cs.LG",
            "physics.comp-ph",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15133",
        "abstract url": "https://arxiv.org/abs/2408.15133",
        "title": "Using LLMs for Explaining Sets of Counterfactual Examples to Final Users",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causality is vital for understanding true cause-and-effect relationships between variables within predictive models, rather than relying on mere correlations, making it highly relevant in the field of Explainable AI. In an automated decision-making scenario, causal inference methods can analyze the underlying data-generation process, enabling explanations of a model's decision by manipulating features and creating counterfactual examples. These counterfactuals explore hypothetical scenarios where a minimal number of factors are altered, providing end-users with valuable information on how to change their situation. However, interpreting a set of multiple counterfactuals can be challenging for end-users who are not used to analyzing raw data records. In our work, we propose a novel multi-step pipeline that uses counterfactuals to generate natural language explanations of actions that will lead to a change in outcome in classifiers of tabular data using LLMs. This pipeline is designed to guide the LLM through smaller tasks that mimic human reasoning when explaining a decision based on counterfactual cases. We conducted various experiments using a public dataset and proposed a method of closed-loop evaluation to assess the coherence of the final explanation with the counterfactuals, as well as the quality of the content. Results are promising, although further experiments with other datasets and human evaluations should be carried out.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Presented as a poster in the 2nd Workshop on Causal Inference and Machine Learning in Practice at KDD 2024"
    },
    {
        "paper id": "2408.15357",
        "abstract url": "https://arxiv.org/abs/2408.15357",
        "title": "On the effectiveness of smartphone IMU sensors and Deep Learning in the detection of cardiorespiratory conditions",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "disease",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This research introduces an innovative method for the early screening of cardiorespiratory diseases based on an acquisition protocol, which leverages commodity smartphone's Inertial Measurement Units (IMUs) and deep learning techniques. We collected, in a clinical setting, a dataset featuring recordings of breathing kinematics obtained by accelerometer and gyroscope readings from five distinct body regions. We propose an end-to-end deep learning pipeline for early cardiorespiratory disease screening, incorporating a preprocessing step segmenting the data into individual breathing cycles, and a recurrent bidirectional module capturing features from diverse body regions. We employed Leave-one-out-cross-validation with Bayesian optimization for hyperparameter tuning and model selection. The experimental results consistently demonstrated the superior performance of a bidirectional Long-Short Term Memory (Bi-LSTM) as a feature encoder architecture, yielding an average sensitivity of $0.81 \\pm 0.02$, specificity of $0.82 \\pm 0.05$, F1 score of $0.81 \\pm 0.02$, and accuracy of $80.2\\% \\pm 3.9$ across diverse seed variations. We also assessed generalization capabilities on a skewed distribution, comprising exclusively healthy patients not used in training, revealing a true negative rate of $74.8 \\% \\pm 4.5$. The sustained accuracy of predictions over time during breathing cycles within a single patient underscores the efficacy of the preprocessing strategy, highlighting the model's ability to discern significant patterns throughout distinct phases of the respiratory cycle. This investigation underscores the potential usefulness of widely available smartphones as devices for timely cardiorespiratory disease screening in the general population, in at-home settings, offering crucial assistance to public health efforts (especially during a pandemic outbreaks, such as the recent COVID-19).",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15393",
        "abstract url": "https://arxiv.org/abs/2408.15393",
        "title": "Stability Analysis of Physics-Informed Neural Networks for Stiff Linear Differential Equations",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a stability analysis of Physics-Informed Neural Networks (PINNs) coupled with random projections, for the numerical solution of (stiff) linear differential equations. For our analysis, we consider systems of linear ODEs, and linear parabolic PDEs. We prove that properly designed PINNs offer consistent and asymptotically stable numerical schemes, thus convergent schemes. In particular, we prove that multi-collocation random projection PINNs guarantee asymptotic stability for very high stiffness and that single-collocation PINNs are $A$-stable. To assess the performance of the PINNs in terms of both numerical approximation accuracy and computational cost, we compare it with other implicit schemes and in particular backward Euler, the midpoint, trapezoidal (Crank-Nikolson), the 2-stage Gauss scheme and the 2 and 3 stages Radau schemes. We show that the proposed PINNs outperform the above traditional schemes, in both numerical approximation accuracy and importantly computational cost, for a wide range of step sizes.",
        "subjects": [
            "math.NA",
            "cs.LG",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15408",
        "abstract url": "https://arxiv.org/abs/2408.15408",
        "title": "Divergence-free neural operators for stress field modeling in polycrystalline materials",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The purpose of the current work is the development and comparison of Fourier neural operators (FNOs) for surrogate modeling of the quasi-static mechanical response of polycrystalline materials. Three types of such FNOs are considered here: a physics-guided FNO (PgFNO), a physics-informed FNO (PiFNO), and a physics-encoded FNO (PeFNO). These are trained and compared with the help of stress field data from a reference model for heterogeneous elastic materials with a periodic grain microstructure. Whereas PgFNO training is based solely on these data, that of the PiFNO and PeFNO is in addition constrained by the requirement that stress fields satisfy mechanical equilibrium, i.e., be divergence-free. The difference between the PiFNO and PeFNO lies in how this constraint is taken into account; in the PiFNO, it is included in the loss function, whereas in the PeFNO, it is \"encoded\" in the operator architecture. In the current work, this encoding is based on a stress potential and Fourier transforms. As a result, only the training of the PiFNO is constrained by mechanical equilibrium; in contrast, mechanical equilibrium constrains both the training and output of the PeFNO. Due in particular to this, stress fields calculated by the trained PeFNO are significantly more accurate than those calculated by the trained PiFNO in the example cases considered.",
        "subjects": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "cs.LG",
            "math.AP"
        ],
        "comment": "17 pages, 11 figures"
    },
    {
        "paper id": "2408.15462",
        "abstract url": "https://arxiv.org/abs/2408.15462",
        "title": "CTRQNets & LQNets: Continuous Time Recurrent and Liquid Quantum Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Neural networks have continued to gain prevalence in the modern era for their ability to model complex data through pattern recognition and behavior remodeling. However, the static construction of traditional neural networks inhibits dynamic intelligence. This makes them inflexible to temporal changes in data and unfit to capture complex dependencies. With the advent of quantum technology, there has been significant progress in creating quantum algorithms. In recent years, researchers have developed quantum neural networks that leverage the capabilities of qubits to outperform classical networks. However, their current formulation exhibits a static construction limiting the system's dynamic intelligence. To address these weaknesses, we develop a Liquid Quantum Neural Network (LQNet) and a Continuous Time Recurrent Quantum Neural Network (CTRQNet). Both models demonstrate a significant improvement in accuracy compared to existing quantum neural networks (QNNs), achieving accuracy increases as high as 40\\% on CIFAR 10 through binary classification. We propose LQNets and CTRQNets might shine a light on quantum machine learning's black box.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15498",
        "abstract url": "https://arxiv.org/abs/2408.15498",
        "title": "Deep Learning to Predict Late-Onset Breast Cancer Metastasis: the Single Hyperparameter Grid Search (SHGS) Strategy for Meta Tuning Concerning Deep Feed-forward Neural Network",
        "rating": "-1.5",
        "keywords": [
            [
                "Cancer",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "While machine learning has advanced in medicine, its widespread use in clinical applications, especially in predicting breast cancer metastasis, is still limited. We have been dedicated to constructing a DFNN model to predict breast cancer metastasis n years in advance. However, the challenge lies in efficiently identifying optimal hyperparameter values through grid search, given the constraints of time and resources. Issues such as the infinite possibilities for continuous hyperparameters like l1 and l2, as well as the time-consuming and costly process, further complicate the task. To address these challenges, we developed Single Hyperparameter Grid Search (SHGS) strategy, serving as a preselection method before grid search. Our experiments with SHGS applied to DFNN models for breast cancer metastasis prediction focus on analyzing eight target hyperparameters: epochs, batch size, dropout, L1, L2, learning rate, decay, and momentum. We created three figures, each depicting the experiment results obtained from three LSM-I-10-Plus-year datasets. These figures illustrate the relationship between model performance and the target hyperparameter values. For each hyperparameter, we analyzed whether changes in this hyperparameter would affect model performance, examined if there were specific patterns, and explored how to choose values for the particular hyperparameter. Our experimental findings reveal that the optimal value of a hyperparameter is not only dependent on the dataset but is also significantly influenced by the settings of other hyperparameters. Additionally, our experiments suggested some reduced range of values for a target hyperparameter, which may be helpful for low-budget grid search. This approach serves as a prior experience and foundation for subsequent use of grid search to enhance model performance.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15508",
        "abstract url": "https://arxiv.org/abs/2408.15508",
        "title": "EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "Voice Conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Deep speech classification tasks, mainly including keyword spotting and speaker verification, play a crucial role in speech-based human-computer interaction. Recently, the security of these technologies has been demonstrated to be vulnerable to backdoor attacks. Specifically speaking, speech samples are attacked by noisy disruption and component modification in present triggers. We suggest that speech backdoor attacks can strategically focus on emotion, a higher-level subjective perceptual attribute inherent in speech. Furthermore, we proposed that emotional voice conversion technology can serve as the speech backdoor attack trigger, and the method is called EmoAttack. Based on this, we conducted attack experiments on two speech classification tasks, showcasing that EmoAttack method owns impactful trigger effectiveness and its remarkable attack success rate and accuracy variance. Additionally, the ablation experiments found that speech with intensive emotion is more suitable to be targeted for attacks.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2408.15511",
        "abstract url": "https://arxiv.org/abs/2408.15511",
        "title": "AeroVerse: UAV-Agent Benchmark Suite for Simulating, Pre-training, Finetuning, and Evaluating Aerospace Embodied World Models",
        "rating": "-1.5",
        "keywords": [
            [
                "visual language"
            ],
            [
                "3D"
            ],
            [
                "UAV"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Aerospace embodied intelligence aims to empower unmanned aerial vehicles (UAVs) and other aerospace platforms to achieve autonomous perception, cognition, and action, as well as egocentric active interaction with humans and the environment. The aerospace embodied world model serves as an effective means to realize the autonomous intelligence of UAVs and represents a necessary pathway toward aerospace embodied intelligence. However, existing embodied world models primarily focus on ground-level intelligent agents in indoor scenarios, while research on UAV intelligent agents remains unexplored. To address this gap, we construct the first large-scale real-world image-text pre-training dataset, AerialAgent-Ego10k, featuring urban drones from a first-person perspective. We also create a virtual image-text-pose alignment dataset, CyberAgent Ego500k, to facilitate the pre-training of the aerospace embodied world model. For the first time, we clearly define 5 downstream tasks, i.e., aerospace embodied scene awareness, spatial reasoning, navigational exploration, task planning, and motion decision, and construct corresponding instruction datasets, i.e., SkyAgent-Scene3k, SkyAgent-Reason3k, SkyAgent-Nav3k and SkyAgent-Plan3k, and SkyAgent-Act3k, for fine-tuning the aerospace embodiment world model. Simultaneously, we develop SkyAgentEval, the downstream task evaluation metrics based on GPT-4, to comprehensively, flexibly, and objectively assess the results, revealing the potential and limitations of 2D/3D visual language models in UAV-agent tasks. Furthermore, we integrate over 10 2D/3D visual-language models, 2 pre-training datasets, 5 finetuning datasets, more than 10 evaluation metrics, and a simulator into the benchmark suite, i.e., AeroVerse, which will be released to the community to promote exploration and development of aerospace embodied intelligence.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.16022",
        "abstract url": "https://arxiv.org/abs/2408.16022",
        "title": "Characterizing Physician Referral Networks with Ricci Curvature",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Identifying (a) systemic barriers to quality healthcare access and (b) key indicators of care efficacy in the United States remains a significant challenge. To improve our understanding of regional disparities in care delivery, we introduce a novel application of curvature, a geometrical-topological property of networks, to Physician Referral Networks. Our initial findings reveal that Forman-Ricci and Ollivier-Ricci curvature measures, which are known for their expressive power in characterizing network structure, offer promising indicators for detecting variations in healthcare efficacy while capturing a range of significant regional demographic features. We also present APPARENT, an open-source tool that leverages Ricci curvature and other network features to examine correlations between regional Physician Referral Networks structure, local census data, healthcare effectiveness, and patient outcomes.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.16025",
        "abstract url": "https://arxiv.org/abs/2408.16025",
        "title": "Improving Adversarial Robustness in Android Malware Detection by Reducing the Impact of Spurious Correlations",
        "rating": "-1.5",
        "keywords": [
            [
                "SVM"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) has demonstrated significant advancements in Android malware detection (AMD); however, the resilience of ML against realistic evasion attacks remains a major obstacle for AMD. One of the primary factors contributing to this challenge is the scarcity of reliable generalizations. Malware classifiers with limited generalizability tend to overfit spurious correlations derived from biased features. Consequently, adversarial examples (AEs), generated by evasion attacks, can modify these features to evade detection. In this study, we propose a domain adaptation technique to improve the generalizability of AMD by aligning the distribution of malware samples and AEs. Specifically, we utilize meaningful feature dependencies, reflecting domain constraints in the feature space, to establish a robust feature space. Training on the proposed robust feature space enables malware classifiers to learn from predefined patterns associated with app functionality rather than from individual features. This approach helps mitigate spurious correlations inherent in the initial feature space. Our experiments conducted on DREBIN, a renowned Android malware detector, demonstrate that our approach surpasses the state-of-the-art defense, Sec-SVM, when facing realistic evasion attacks. In particular, our defense can improve adversarial robustness by up to 55% against realistic evasion attacks compared to Sec-SVM.",
        "subjects": [
            "cs.CR",
            "cs.LG",
            "cs.SE"
        ],
        "comment": "The paper is accepted at the ESORICS 2024 Workshop on Security and Artificial Intelligence (SECAI 2024)"
    },
    {
        "paper id": "2408.14789",
        "abstract url": "https://arxiv.org/abs/2408.14789",
        "title": "Revisiting Surgical Instrument Segmentation Without Human Intervention: A Graph Partitioning View",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Surgical",
                "surgery",
                "clinical",
                "endoscopic"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Surgical instrument segmentation (SIS) on endoscopic images stands as a long-standing and essential task in the context of computer-assisted interventions for boosting minimally invasive surgery. Given the recent surge of deep learning methodologies and their data-hungry nature, training a neural predictive model based on massive expert-curated annotations has been dominating and served as an off-the-shelf approach in the field, which could, however, impose prohibitive burden to clinicians for preparing fine-grained pixel-wise labels corresponding to the collected surgical video frames. In this work, we propose an unsupervised method by reframing the video frame segmentation as a graph partitioning problem and regarding image pixels as graph nodes, which is significantly different from the previous efforts. A self-supervised pre-trained model is firstly leveraged as a feature extractor to capture high-level semantic features. Then, Laplacian matrixs are computed from the features and are eigendecomposed for graph partitioning. On the \"deep\" eigenvectors, a surgical video frame is meaningfully segmented into different modules such as tools and tissues, providing distinguishable semantic information like locations, classes, and relations. The segmentation problem can then be naturally tackled by applying clustering or threshold on the eigenvectors. Extensive experiments are conducted on various datasets (e.g., EndoVis2017, EndoVis2018, UCL, etc.) for different clinical endpoints. Across all the challenging scenarios, our method demonstrates outstanding performance and robustness higher than unsupervised state-of-the-art (SOTA) methods. The code is released at https://github.com/MingyuShengSMY/GraphClusteringSIS.git.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14827",
        "abstract url": "https://arxiv.org/abs/2408.14827",
        "title": "Generative-AI for AI/ML Model Adaptive Retraining in Beyond 5G Networks",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Beyond fifth-generation (B5G) networks aim to support high data rates, low-latency applications, and massive machine communications. Artificial Intelligence/Machine Learning (AI/ML) can help to improve B5G network performance and efficiency. However, dynamic service demands of B5G use cases cause AI/ML model performance degradation, resulting in Service Level Agreements (SLA) violations, over- or under-provisioning of resources, etc. Retraining is essential to address the performance degradation of the AI/ML models. Existing threshold and periodic retraining approaches have potential disadvantages, such as SLA violations and inefficient resource utilization for setting a threshold parameter in a dynamic environment. This paper proposes a novel approach that predicts when to retrain AI/ML models using Generative Artificial Intelligence. The proposed predictive approach is evaluated for a Quality of Service Prediction use case on the Open Radio Access Network (O-RAN) Software Community platform and compared to the predictive approach based on the classifier and a threshold approach. Also, a realtime dataset from the Colosseum testbed is considered to evaluate Network Slicing (NS) use case with the proposed predictive approach. The results show that the proposed predictive approach outperforms both the classifier-based predictive and threshold approaches.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14829",
        "abstract url": "https://arxiv.org/abs/2408.14829",
        "title": "Time-Aware Face Anti-Spoofing with Rotation Invariant Local Binary Patterns and Deep Learning",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial recognition systems have become an integral part of the modern world. These methods accomplish the task of human identification in an automatic, fast, and non-interfering way. Past research has uncovered high vulnerability to simple imitation attacks that could lead to erroneous identification and subsequent authentication of attackers. Similar to face recognition, imitation attacks can also be detected with Machine Learning. Attack detection systems use a variety of facial features and advanced machine learning models for uncovering the presence of attacks. In this work, we assess existing work on liveness detection and propose a novel approach that promises high classification accuracy by combining previously unused features with time-aware deep learning strategies.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14884",
        "abstract url": "https://arxiv.org/abs/2408.14884",
        "title": "User-level Social Multimedia Traffic Anomaly Detection with Meta-Learning",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "Accuracy anomaly detection in user-level social multimedia traffic is crucial for privacy security. Compared with existing models that passively detect specific anomaly classes with large labeled training samples, user-level social multimedia traffic contains sizeable new anomaly classes with few labeled samples and has an imbalance, self-similar, and data-hungry nature. Recent advances, such as Generative Adversarial Networks (GAN), solve it by learning a sample generator only from seen class samples to synthesize new samples. However, if we detect many new classes, the number of synthesizing samples would be unfeasibly estimated, and this operation will drastically increase computational complexity and energy consumption. Motivation on these limitations, in this paper, we propose \\textit{Meta-UAD}, a Meta-learning scheme for User-level social multimedia traffic Anomaly Detection. This scheme relies on the episodic training paradigm and learns from the collection of K-way-M-shot classification tasks, which can use the pre-trained model to adapt any new class with few samples by going through few iteration steps. Since user-level social multimedia traffic emerges from a complex interaction process of users and social applications, we further develop a feature extractor to improve scheme performance. It extracts statistical features using cumulative importance ranking and time-series features using an LSTM-based AutoEncoder. We evaluate our scheme on two public datasets and the results further demonstrate the superiority of Meta-UAD.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "To Be Submitting"
    },
    {
        "paper id": "2408.14917",
        "abstract url": "https://arxiv.org/abs/2408.14917",
        "title": "PMSN: A Parallel Multi-compartment Spiking Neuron for Multi-scale Temporal Processing",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Spiking Neural Networks (SNNs) hold great potential to realize brain-inspired, energy-efficient computational systems. However, current SNNs still fall short in terms of multi-scale temporal processing compared to their biological counterparts. This limitation has resulted in poor performance in many pattern recognition tasks with information that varies across different timescales. To address this issue, we put forward a novel spiking neuron model called Parallel Multi-compartment Spiking Neuron (PMSN). The PMSN emulates biological neurons by incorporating multiple interacting substructures and allows for flexible adjustment of the substructure counts to effectively represent temporal information across diverse timescales. Additionally, to address the computational burden associated with the increased complexity of the proposed model, we introduce two parallelization techniques that decouple the temporal dependencies of neuronal updates, enabling parallelized training across different time steps. Our experimental results on a wide range of pattern recognition tasks demonstrate the superiority of PMSN. It outperforms other state-of-the-art spiking neuron models in terms of its temporal processing capacity, training speed, and computation cost. Specifically, compared with the commonly used Leaky Integrate-and-Fire neuron, PMSN offers a simulation acceleration of over 10 $\\times$ and a 30 % improvement in accuracy on Sequential CIFAR10 dataset, while maintaining comparable computational cost.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14944",
        "abstract url": "https://arxiv.org/abs/2408.14944",
        "title": "Dynamic Spectrum Management for 6G Network-in-Network Concepts",
        "rating": "-2",
        "keywords": [
            [
                "6G",
                "industrial"
            ]
        ],
        "abstract": "Flexible, self-organizing communication networks will be a key feature in the next mobile communication standard. Network-in-Network (NiN) is one important concept in 6G research, introducing sub-networks tailored to specific application requirements. These sub-networks may be dynamic, i.e., they may appear, disappear, or even move throughout the network. Moreover, sub-networks may operate within a shared frequency spectrum, thereby requiring coordination among them. We demonstrate the concept of Dynamic Spectrum Management (DSM) for future 6G networks that dynamically (re-)allocates spectrum according to active sub-networks in the shared spectrum domain. Resilient control plane connectivity between sub-networks and the DSM is provided by the self-organizing routing protocol KIRA, enabling the aforementioned coordination. This demonstration presents an integrated solution of the DSM concept, providing increased flexibility to support diverse industrial applications and their individual performance requirements simultaneously within the context of a cyber-physical production system (CPPS). For the sub-networks, we use specifically designed hardware for wireless real-time communication and couple them with a network emulation. By switching sub-networks on and off, one can see that the DSM dynamically manages the spectrum allocations for them and that KIRA provides the required connectivity.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "5 pages, 3 figures"
    },
    {
        "paper id": "2408.14947",
        "abstract url": "https://arxiv.org/abs/2408.14947",
        "title": "ERX: A Fast Real-Time Anomaly Detection Algorithm for Hyperspectral Line-Scanning",
        "rating": "-2",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "satellite",
                "drone"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Detecting unexpected objects (anomalies) in real-time has great potential for monitoring, managing, and protecting the environment. Hyperspectral line-scan cameras are a low-cost solution that enhance confidence in anomaly detection over RGB and multispectral imagery. However, real-time algorithms for these cameras must be fast when using small computers (e.g., those onboard a drone or small satellite), scalable to high dimensions, adaptable to changing scenery, and robust against geometric and radiometric distortions. This paper introduces the Exponentially moving RX algorithm (ERX) and compares it to existing RX-based anomaly detection methods for real-time line-scanning. ERX was tested using a Jetson Xavier NX compute module, achieving the best combination of speed and detection across three novel datasets compared to the other algorithms. This research paves the way for future studies in grouping and locating anomalous objects, adaptive and automatic threshold selection, and real-time field tests. The Python code for the algorithms and experiments is available at https://github.com/WiseGamgee/HyperAD.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "10 pages, 9 figures, 3 tables, code and datasets accessible at https://github.com/WiseGamgee/HyperAD"
    },
    {
        "paper id": "2408.14954",
        "abstract url": "https://arxiv.org/abs/2408.14954",
        "title": "Stochastic Geometry Based Modelling and Analysis of Uplink Cooperative Satellite-Aerial-Terrestrial Networks for Nomadic Communications with Weak Satellite Coverage",
        "rating": "-2",
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "Cooperative satellite-aerial-terrestrial networks (CSATNs), where unmanned aerial vehicles (UAVs) are utilized as nomadic aerial relays (A), are highly valuable for many important applications, such as post-disaster urban reconstruction. In this scenario, direct communication between terrestrial terminals (T) and satellites (S) is often unavailable due to poor propagation conditions for satellite signals, and users tend to congregate in regions of finite size. There is a current dearth in the open literature regarding the uplink performance analysis of CSATN operating under the above constraints, and the few contributions on the uplink model terrestrial terminals by a Poisson point process (PPP) relying on the unrealistic assumption of an infinite area. This paper aims to fill the above research gap. First, we propose a stochastic geometry based innovative model to characterize the impact of the finite-size distribution region of terrestrial terminals in the CSATN by jointly using a binomial point process (BPP) and a type-II Mat{\u00e9}rn hard-core point process (MHCPP). Then, we analyze the relationship between the spatial distribution of the coverage areas of aerial nodes and the finite-size distribution region of terrestrial terminals, thereby deriving the distance distribution of the T-A links. Furthermore, we consider the stochastic nature of the spatial distributions of terrestrial terminals and UAVs, and conduct a thorough analysis of the coverage probability and average ergodic rate of the T-A links under Nakagami fading and the A-S links under shadowed-Rician fading. Finally, the accuracy of our theoretical derivations are confirmed by Monte Carlo simulations. Our research offers fundamental insights into the system-level performance optimization for the realistic CSATNs involving nomadic aerial relays and terrestrial terminals confined in a finite-size region.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": "17 pages, 16 pages, 2 tables, accepted to appear on IEEE Journal on Selected Areas in Communications, Aug. 2024"
    },
    {
        "paper id": "2408.14964",
        "abstract url": "https://arxiv.org/abs/2408.14964",
        "title": "Cross-Modal Learning for Chemistry Property Prediction: Large Language Models Meet Graph Machine Learning",
        "rating": "-2",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "Chemistry"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In the field of chemistry, the objective is to create novel molecules with desired properties, facilitating accurate property predictions for applications such as material design and drug screening. However, existing graph deep learning methods face limitations that curb their expressive power. To address this, we explore the integration of vast molecular domain knowledge from Large Language Models (LLMs) with the complementary strengths of Graph Neural Networks (GNNs) to enhance performance in property prediction tasks. We introduce a Multi-Modal Fusion (MMF) framework that synergistically harnesses the analytical prowess of GNNs and the linguistic generative and predictive abilities of LLMs, thereby improving accuracy and robustness in predicting molecular properties. Our framework combines the effectiveness of GNNs in modeling graph-structured data with the zero-shot and few-shot learning capabilities of LLMs, enabling improved predictions while reducing the risk of overfitting. Furthermore, our approach effectively addresses distributional shifts, a common challenge in real-world applications, and showcases the efficacy of learning cross-modal representations, surpassing state-of-the-art baselines on benchmark datasets for property prediction tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Paper Accepted at Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023"
    },
    {
        "paper id": "2408.15027",
        "abstract url": "https://arxiv.org/abs/2408.15027",
        "title": "European Quantum Ecosystems -- Preparing the Industry for the Quantum Security and Communications Revolution",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "There is mounting evidence that a second quantum revolution based on the technological capabilities to detect and manipulate single quantum particles (e.g., electrons, photons, ions, etc), a feat not achieved during the first quantum revolution, is progressing fast. It is expected that in less than 10 years, this second quantum revolution shall have a significant impact over numerous industries, including finance, medicine, energy, transportation, etc. Quantum computers threaten the status quo of cybersecurity, due to known quantum algorithms that can break asymmetric encryption, which is what gives us the ability to communicate securely using a public channel. Considering the world's dependence on digital communication through data exchange and processing, retaining the ability to communicate securely even once quantum computers come into play, cannot be stressed enough. Two solutions are available: Quantum Key Distribution (QKD) and Post-Quantum Cryptography (PQC); which, we emphasise, are not mutually exclusive. The EuroQCI initiative, of which EQUO is a part of, focuses on QKD and aims to build a network whereby EU countries can communicate securely through QKD. To this aim, the DEP (Digital Europe Programme) project aims to bring technological matureness to QKD by deploying a QKD test network and, through this exercise, understand what is lacking from an operator's point of view when the time to integrate QKD in their network comes.",
        "subjects": [
            "quant-ph",
            "cs.ET",
            "cs.NI"
        ],
        "comment": "IEEE 2024 International Conference on Quantum Communications, Networking, and Computing (QCNC)"
    },
    {
        "paper id": "2408.15063",
        "abstract url": "https://arxiv.org/abs/2408.15063",
        "title": "Adapting Segment Anything Model to Multi-modal Salient Object Detection with Semantic Feature Fusion Guidance",
        "rating": "-2",
        "keywords": [
            [
                "RGB-D",
                "depth"
            ],
            [
                "thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Although most existing multi-modal salient object detection (SOD) methods demonstrate effectiveness through training models from scratch, the limited multi-modal data hinders these methods from reaching optimality. In this paper, we propose a novel framework to explore and exploit the powerful feature representation and zero-shot generalization ability of the pre-trained Segment Anything Model (SAM) for multi-modal SOD. Despite serving as a recent vision fundamental model, driving the class-agnostic SAM to comprehend and detect salient objects accurately is non-trivial, especially in challenging scenes. To this end, we develop \\underline{SAM} with se\\underline{m}antic f\\underline{e}ature fu\\underline{s}ion guidanc\\underline{e} (Sammese), which incorporates multi-modal saliency-specific knowledge into SAM to adapt SAM to multi-modal SOD tasks. However, it is difficult for SAM trained on single-modal data to directly mine the complementary benefits of multi-modal inputs and comprehensively utilize them to achieve accurate saliency prediction.To address these issues, we first design a multi-modal complementary fusion module to extract robust multi-modal semantic features by integrating information from visible and thermal or depth image pairs. Then, we feed the extracted multi-modal semantic features into both the SAM image encoder and mask decoder for fine-tuning and prompting, respectively. Specifically, in the image encoder, a multi-modal adapter is proposed to adapt the single-modal SAM to multi-modal information. In the mask decoder, a semantic-geometric prompt generation strategy is proposed to produce corresponding embeddings with various saliency cues. Extensive experiments on both RGB-D and RGB-T SOD benchmarks show the effectiveness of the proposed framework.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 9 figures"
    },
    {
        "paper id": "2408.15069",
        "abstract url": "https://arxiv.org/abs/2408.15069",
        "title": "Geometric Artifact Correction for Symmetric Multi-Linear Trajectory CT: Theory, Method, and Generalization",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "CT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "For extending CT field-of-view to perform non-destructive testing, the Symmetric Multi-Linear trajectory Computed Tomography (SMLCT) has been developed as a successful example of non-standard CT scanning modes. However, inevitable geometric errors can cause severe artifacts in the reconstructed images. The existing calibration method for SMLCT is both crude and inefficient. It involves reconstructing hundreds of images by exhaustively substituting each potential error, and then manually identifying the images with the fewest geometric artifacts to estimate the final geometric errors for calibration. In this paper, we comprehensively and efficiently address the challenging geometric artifacts in SMLCT, , and the corresponding works mainly involve theory, method, and generalization. In particular, after identifying sensitive parameters and conducting some theory analysis of geometric artifacts, we summarize several key properties between sensitive geometric parameters and artifact characteristics. Then, we further construct mathematical relationships that relate sensitive geometric errors to the pixel offsets of reconstruction images with artifact characteristics. To accurately extract pixel bias, we innovatively adapt the Generalized Cross-Correlation with Phase Transform (GCC-PHAT) algorithm, commonly used in sound processing, for our image registration task for each paired symmetric LCT. This adaptation leads to the design of a highly efficient rigid translation registration method. Simulation and physical experiments have validated the excellent performance of this work. Additionally, our results demonstrate significant generalization to common rotated CT and a variant of SMLCT.",
        "subjects": [
            "cs.CV",
            "eess.IV",
            "physics.ins-det"
        ],
        "comment": "15 pages, 10 figures"
    },
    {
        "paper id": "2408.15083",
        "abstract url": "https://arxiv.org/abs/2408.15083",
        "title": "Multitone PSK Modulation Design for Simultaneous Wireless Information and Power Transfer",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "IoT"
            ]
        ],
        "abstract": "Far-field wireless power transfer, based on radio frequency (RF) waves, came into the picture to fulfill the power need of large Internet of Things (IoT) networks, the backbone of the 5G and beyond era. However, RF communication signals carry both information as well as energy. Therefore, recently, simultaneous wireless information and power transfer (SWIPT) has attracted much attention in order to wirelessly charge these IoT devices. In this paper, we propose a novel N -tone multitone phase shift keying (PSK) modulation scheme, taking advantage of the non-linearity of integrated receiver rectifier architecture. The main advantage of the proposed modulation scheme is the reduction in ripple voltage, introduced by the symbol transmission through phases. Achievable power conversion efficiency (PCE) and bit error rate (BER) at the output are considered to measure the efficacy of the proposed modulation scheme. Simulation results are verified by the measurements over the designed rectifier circuitry. The effect of symbol phase range, modulation order, and the number of tones are analyzed. In the future, this transmission scheme can be utilized to satisfy the data and power requirements of low-power Internet of Things sensor networks.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15087",
        "abstract url": "https://arxiv.org/abs/2408.15087",
        "title": "Quantum Bisimilarity is a Congruence under Physically Admissible Schedulers",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The development of quantum algorithms and protocols calls for adequate modelling and verification techniques, which requires abstracting and focusing on the basic features of quantum concurrent systems, like CCS and CSP have done for their classical counterparts. So far, an equivalence relation is still missing that is a congruence for parallel composition and adheres to the limited discriminating power implied by quantum theory. In fact, defining an adequate bisimilarity for quantum-capable, concurrent systems proved a difficult task, because unconstrained non-determinism allows to spuriously discriminate indistinguishable quantum systems. We investigate this problem by enriching a linear quantum extension of CCS with simple physically admissible schedulers. We show that our approach suffices for deriving a well-behaved bisimilarity that satisfies the aforementioned desiderata.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15143",
        "abstract url": "https://arxiv.org/abs/2408.15143",
        "title": "A Preliminary Exploration Towards General Image Restoration",
        "rating": "-2",
        "keywords": [
            [
                "super-resolution",
                "deraining"
            ],
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the tremendous success of deep models in various individual image restoration tasks, there are at least two major technical challenges preventing these works from being applied to real-world usages: (1) the lack of generalization ability and (2) the complex and unknown degradations in real-world scenarios. Existing deep models, tailored for specific individual image restoration tasks, often fall short in effectively addressing these challenges. In this paper, we present a new problem called general image restoration (GIR) which aims to address these challenges within a unified model. GIR covers most individual image restoration tasks (\\eg, image denoising, deblurring, deraining and super-resolution) and their combinations for general purposes. This paper proceeds to delineate the essential aspects of GIR, including problem definition and the overarching significance of generalization performance. Moreover, the establishment of new datasets and a thorough evaluation framework for GIR models is discussed. We conduct a comprehensive evaluation of existing approaches for tackling the GIR challenge, illuminating their strengths and pragmatic challenges. By analyzing these approaches, we not only underscore the effectiveness of GIR but also highlight the difficulties in its practical implementation. At last, we also try to understand and interpret these models' behaviors to inspire the future direction. Our work can open up new valuable research directions and contribute to the research of general vision.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15150",
        "abstract url": "https://arxiv.org/abs/2408.15150",
        "title": "muPRL: A Mutation Testing Pipeline for Deep Reinforcement Learning based on Real Faults",
        "rating": "-2",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Reinforcement Learning (RL) is increasingly adopted to train agents that can deal with complex sequential tasks, such as driving an autonomous vehicle or controlling a humanoid robot. Correspondingly, novel approaches are needed to ensure that RL agents have been tested adequately before going to production. Among them, mutation testing is quite promising, especially under the assumption that the injected faults (mutations) mimic the real ones. In this paper, we first describe a taxonomy of real RL faults obtained by repository mining. Then, we present the mutation operators derived from such real faults and implemented in the tool muPRL. Finally, we discuss the experimental results, showing that muPRL is effective at discriminating strong from weak test generators, hence providing useful feedback to developers about the adequacy of the generated test scenarios.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted at ICSE '25"
    },
    {
        "paper id": "2408.15152",
        "abstract url": "https://arxiv.org/abs/2408.15152",
        "title": "Evaluation of Local Planner-Based Stanley Control in Autonomous RC Car Racing Series",
        "rating": "-2",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "trajectory",
                "LiDAR"
            ]
        ],
        "abstract": "This paper proposes a control technique for autonomous RC car racing. The presented method does not require any map-building phase beforehand since it operates only local path planning on the actual LiDAR point cloud. Racing control algorithms must have the capability to be optimized to the actual track layout for minimization of lap time. In the examined one, it is guaranteed with the improvement of the Stanley controller with additive control components to stabilize the movement in both low and high-speed ranges, and with the integration of an adaptive lookahead point to induce sharp and dynamic cornering for traveled distance reduction. The developed method is tested on a 1/10-sized RC car, and the tuning procedure from a base solution to the optimal setting in a real F1Tenth race is presented. Furthermore, the proposed method is evaluated with a comparison to a more simple reactive method, and in parallel to a more complex optimization-based technique that involves offline map building the global optimal trajectory calculation. The performance of the proposed method compared to the latter, referring to the lap time, is that the proposed one has only 8% lower average speed. This demonstrates that with appropriate tuning, a local planning-based method can be comparable with a more complex optimization-based one. Thus, the performance gap is lower than 10% from the state-of-the-art method. Moreover, the proposed technique has significantly higher similarity to real scenarios, therefore the results can be interesting in the context of automotive industry.",
        "subjects": [
            "cs.RO",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15177",
        "abstract url": "https://arxiv.org/abs/2408.15177",
        "title": "Regaining Trust: Impact of Transparent User Interface Design on Acceptance of Camera-Based In-Car Health Monitoring Systems",
        "rating": "-2",
        "keywords": [
            [
                "Health"
            ]
        ],
        "abstract": "Introducing in-car health monitoring systems offers substantial potential to improve driver safety. However, camera-based sensing technologies introduce significant privacy concerns. This study investigates the impact of transparent user interface design on user acceptance of these systems. We conducted an online study with 42 participants using prototypes varying in transparency, choice, and deception levels. The prototypes included three onboarding designs: (1) a traditional Terms and Conditions text, (2) a Business Nudge design that subtly encouraged users to accept default data-sharing options, and (3) a Transparent Walk-Through that provided clear, step-by-step explanations of data use and privacy policies. Our findings indicate that transparent design significantly affects user experience measures, including perceived creepiness, trust in data use, and trustworthiness of content. Transparent onboarding processes enhanced user experience and trust without significantly increasing onboarding time. These findings offer practical guidance for designing user-friendly and privacy-respecting in-car health monitoring systems.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "About to be published in the AutoUI '24 WiP proceedings"
    },
    {
        "paper id": "2408.15210",
        "abstract url": "https://arxiv.org/abs/2408.15210",
        "title": "Data-enabled Predictive Repetitive Control",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Many systems are subject to periodic disturbances and exhibit repetitive behaviour. Model-based repetitive control employs knowledge of such periodicity to attenuate periodic disturbances and has seen a wide range of successful industrial implementations. The aim of this paper is to develop a data-driven repetitive control method. In the developed framework, linear periodically time-varying (LPTV) behaviour is lifted to linear time-invariant (LTI) behaviour. Periodic disturbance mitigation is enabled by developing an extension of Willems' fundamental lemma for systems with exogenous disturbances. The resulting Data-enabled Predictive Repetitive Control (DeePRC) technique accounts for periodic system behaviour to perform attenuation of a periodic disturbance. Simulations demonstrate the ability of DeePRC to effectively mitigate periodic disturbances in the presence of noise.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Extended report"
    },
    {
        "paper id": "2408.15217",
        "abstract url": "https://arxiv.org/abs/2408.15217",
        "title": "Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "diagnosis",
                "Clinical",
                "retinal",
                "lesion"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Fundus Fluorescein Angiography (FFA) is a critical tool for assessing retinal vascular dynamics and aiding in the diagnosis of eye diseases. However, its invasive nature and less accessibility compared to Color Fundus (CF) images pose significant challenges. Current CF to FFA translation methods are limited to static generation. In this work, we pioneer dynamic FFA video generation from static CF images. We introduce an autoregressive GAN for smooth, memory-saving frame-by-frame FFA synthesis. To enhance the focus on dynamic lesion changes in FFA regions, we design a knowledge mask based on clinical experience. Leveraging this mask, our approach integrates innovative knowledge mask-guided techniques, including knowledge-boosted attention, knowledge-aware discriminators, and mask-enhanced patchNCE loss, aimed at refining generation in critical areas and addressing the pixel misalignment challenge. Our method achieves the best FVD of 1503.21 and PSNR of 11.81 compared to other common video generation approaches. Human assessment by an ophthalmologist confirms its high generation quality. Notably, our knowledge mask surpasses supervised lesion segmentation masks, offering a promising non-invasive alternative to traditional FFA for research and clinical applications. The code is available at https://github.com/Michi-3000/Fundus2Video.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "The paper has been accepted by Medical Image Computing and Computer Assisted Intervention Society (MICCAI) 2024"
    },
    {
        "paper id": "2408.15224",
        "abstract url": "https://arxiv.org/abs/2408.15224",
        "title": "SAM & SAM 2 in 3D Slicer: SegmentWithSAM Extension for Annotating Medical Images",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Creating annotations for 3D medical data is time-consuming and often requires highly specialized expertise. Various tools have been implemented to aid this process. Segment Anything Model 2 (SAM 2) offers a general-purpose prompt-based segmentation algorithm designed to annotate videos. In this paper, we adapt this model to the annotation of 3D medical images and offer our implementation in the form of an extension to the popular annotation software: 3D Slicer. Our extension allows users to place point prompts on 2D slices to generate annotation masks and propagate these annotations across entire volumes in either single-directional or bi-directional manners. Our code is publicly available on https://github.com/mazurowski-lab/SlicerSegmentWithSAM and can be easily installed directly from the Extension Manager of 3D Slicer as well.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.SE"
        ],
        "comment": "Future work: support for box and mask inputs for the video predictor of SAM 2"
    },
    {
        "paper id": "2408.15226",
        "abstract url": "https://arxiv.org/abs/2408.15226",
        "title": "Continuity of entropies via integral representations",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We show that Frenkel's integral representation of the quantum relative entropy provides a natural framework to derive continuity bounds for quantum information measures. Our main general result is a dimension-independent semi-continuity relation for the quantum relative entropy with respect to the first argument. Using it, we obtain a number of results: (1) a tight continuity relation for the conditional entropy in the case where the two states have equal marginals on the conditioning system, resolving a conjecture by Wilde in this special case; (2) a stronger version of the Fannes-Audenaert inequality on quantum entropy; (3) a tighter continuity relation for quantum capacity; (4) better estimates on the quantum capacity of approximately degradable channels; (5) an improved continuity relation for the entanglement cost; (6) general upper bounds on asymptotic transformation rates in infinite-dimensional entanglement theory; and (7) a proof of a conjecture due to Christandl, Ferrara, and Lancien on the continuity of 'filtered' relative entropy distances.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "math-ph"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2408.15235",
        "abstract url": "https://arxiv.org/abs/2408.15235",
        "title": "Learning-based Multi-View Stereo: A Survey",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "voxel",
                "depth",
                "NeRF"
            ],
            [
                "autonomous driving"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D reconstruction aims to recover the dense 3D structure of a scene. It plays an essential role in various applications such as Augmented/Virtual Reality (AR/VR), autonomous driving and robotics. Leveraging multiple views of a scene captured from different viewpoints, Multi-View Stereo (MVS) algorithms synthesize a comprehensive 3D representation, enabling precise reconstruction in complex environments. Due to its efficiency and effectiveness, MVS has become a pivotal method for image-based 3D reconstruction. Recently, with the success of deep learning, many learning-based MVS methods have been proposed, achieving impressive performance against traditional methods. We categorize these learning-based methods as: depth map-based, voxel-based, NeRF-based, 3D Gaussian Splatting-based, and large feed-forward methods. Among these, we focus significantly on depth map-based methods, which are the main family of MVS due to their conciseness, flexibility and scalability. In this survey, we provide a comprehensive review of the literature at the time of this writing. We investigate these learning-based methods, summarize their performances on popular benchmarks, and discuss promising future research directions in this area.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15337",
        "abstract url": "https://arxiv.org/abs/2408.15337",
        "title": "A Multi-Agent Reinforcement Learning Scheme for SFC Placement in Edge Computing Networks",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "In the 5G era and beyond, it is favorable to deploy latency-sensitive and reliability-aware services on edge computing networks in which the computing and network resources are more limited compared to cloud and core networks but can respond more promptly. These services can be composed as Service Function Chains (SFCs) which consist of a sequence of ordered Virtual Network Functions (VNFs). To achieve efficient edge resources allocation for SFC requests and optimal profit for edge service providers, we formulate the SFC placement problem in an edge environment and propose a multi-agent Reinforcement Learning (RL) scheme to address the problem. The proposed scheme employs a set of RL agents to collaboratively make SFC placement decisions, such as path selection, VNF configuration, and VNF deployment. Simulation results show our model can improve the profit of edge service providers by 12\\% compared with a heuristic solution.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15371",
        "abstract url": "https://arxiv.org/abs/2408.15371",
        "title": "Temporal Graph Neural Network-Powered Paper Recommendation on Dynamic Citation Networks",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Due to the rapid growth of scientific publications, identifying all related reference articles in the literature has become increasingly challenging yet highly demanding. Existing methods primarily assess candidate publications from a static perspective, focusing on the content of articles and their structural information, such as citation relationships. There is a lack of research regarding how to account for the evolving impact among papers on their embeddings. Toward this goal, this paper introduces a temporal dimension to paper recommendation strategies. The core idea is to continuously update a paper's embedding when new citation relationships appear, enhancing its relevance for future recommendations. Whenever a citation relationship is added to the literature upon the publication of a paper, the embeddings of the two related papers are updated through a Temporal Graph Neural Network (TGN). A learnable memory update module based on a Recurrent Neural Network (RNN) is utilized to study the evolution of the embedding of a paper in order to predict its reference impact in a future timestamp. Such a TGN-based model learns a pattern of how people's views of the paper may evolve, aiming to guide paper recommendations more precisely. Extensive experiments on an open citation network dataset, including 313,278 articles from https://paperswithcode.com/about PaperWithCode, have demonstrated the effectiveness of the proposed approach.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": "10 pages, 4 figures, accepted by SDU@AAAI-2024. The AAAI Workshop on Scientific Document Understanding (2024)"
    },
    {
        "paper id": "2408.15386",
        "abstract url": "https://arxiv.org/abs/2408.15386",
        "title": "Multi-Feature Aggregation in Diffusion Models for Enhanced Face Super-Resolution",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "Super-Resolution"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Super-resolution algorithms often struggle with images from surveillance environments due to adverse conditions such as unknown degradation, variations in pose, irregular illumination, and occlusions. However, acquiring multiple images, even of low quality, is possible with surveillance cameras. In this work, we develop an algorithm based on diffusion models that utilize a low-resolution image combined with features extracted from multiple low-quality images to generate a super-resolved image while minimizing distortions in the individual's identity. Unlike other algorithms, our approach recovers facial features without explicitly providing attribute information or without the need to calculate a gradient of a function during the reconstruction process. To the best of our knowledge, this is the first time multi-features combined with low-resolution images are used as conditioners to generate more reliable super-resolution images using stochastic differential equations. The FFHQ dataset was employed for training, resulting in state-of-the-art performance in facial recognition and verification metrics when evaluated on the CelebA and Quis-Campi datasets. Our code is publicly available at https://github.com/marcelowds/fasr",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for presentation at the Conference on Graphics, Patterns and Images (SIBGRAPI) 2024"
    },
    {
        "paper id": "2408.15429",
        "abstract url": "https://arxiv.org/abs/2408.15429",
        "title": "Generation of Compiler Backends from Formal Models of Hardware",
        "rating": "-2",
        "keywords": [
            [
                "FPGAs"
            ]
        ],
        "abstract": "Compilers convert between representations -- usually, from higher-level, human writable code to lower-level, machine-readable code. A compiler backend is the portion of the compiler containing optimizations and code generation routines for a specific hardware target. In this dissertation, I advocate for a specific way of building compiler backends: namely, by automatically generating them from explicit, formal models of hardware using automated reasoning algorithms. I describe how automatically generating compilers from formal models of hardware leads to increased optimization ability, stronger correctness guarantees, and reduced development time for compiler backends. As evidence, I present two case studies: first, Glenside, which uses equality saturation to increase the 3LA compiler's ability to offload operations to machine learning accelerators, and second, Lakeroad, a technology mapper for FPGAs which uses program synthesis and semantics extracted from Verilog to map hardware designs to complex, programmable hardware primitives.",
        "subjects": [
            "cs.PL",
            "cs.AR"
        ],
        "comment": "PhD thesis"
    },
    {
        "paper id": "2408.15439",
        "abstract url": "https://arxiv.org/abs/2408.15439",
        "title": "Towards observability of scientific applications",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "As software systems increase in complexity, conventional monitoring methods struggle to provide a comprehensive overview or identify performance issues, often missing unexpected problems. Observability, however, offers a holistic approach, providing methods and tools that gather and analyze detailed telemetry data to uncover hidden issues. Originally developed for cloud-native systems, modern observability is less prevalent in scientific computing, particularly in HPC clusters, due to differences in application architecture, execution environments, and technology stacks. This paper proposes and evaluates an end-to-end observability solution tailored for scientific computing in HPC environments. We address several challenges, including collection of application-level metrics, instrumentation, context propagation, and tracing. We argue that typical dashboards with charts are not sufficient for advanced observability-driven analysis of scientific applications. Consequently, we propose a different approach based on data analysis using DataFrames and a Jupyter environment. The proposed solution is implemented and evaluated on two medical scientific pipelines running on an HPC cluster.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15480",
        "abstract url": "https://arxiv.org/abs/2408.15480",
        "title": "Feelit: Combining Compliant Shape Displays with Vision-Based Tactile Sensors for Real-Time Teletaction",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Teletaction, the transmission of tactile feedback or touch, is a crucial aspect in the field of teleoperation. High-quality teletaction feedback allows users to remotely manipulate objects and increase the quality of the human-machine interface between the operator and the robot, making complex manipulation tasks possible. Advances in the field of teletaction for teleoperation however, have yet to make full use of the high-resolution 3D data provided by modern vision-based tactile sensors. Existing solutions for teletaction lack in one or more areas of form or function, such as fidelity or hardware footprint. In this paper, we showcase our design for a low-cost teletaction device that can utilize real-time high-resolution tactile information from vision-based tactile sensors, through both physical 3D surface reconstruction and shear displacement. We present our device, the Feelit, which uses a combination of a pin-based shape display and compliant mechanisms to accomplish this task. The pin-based shape display utilizes an array of 24 servomotors with miniature Bowden cables, giving the device a resolution of 6x4 pins in a 15x10 mm display footprint. Each pin can actuate up to 3 mm in 200 ms, while providing 80 N of force and 1.5 um of depth resolution. Shear displacement and rotation is achieved using a compliant mechanism design, allowing a minimum of 1 mm displacement laterally and 10 degrees of rotation. This real-time 3D tactile reconstruction is achieved with the use of a vision-based tactile sensor, the GelSight [1], along with an algorithm that samples the depth data and marker tracking to generate actuator commands. Through a series of experiments including shape recognition and relative weight identification, we show that our device has the potential to expand teletaction capabilities in the teleoperation space.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "IROS 2024"
    },
    {
        "paper id": "2408.15489",
        "abstract url": "https://arxiv.org/abs/2408.15489",
        "title": "Shared-PIM: Enabling Concurrent Computation and Data Flow for Faster Processing-in-DRAM",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Processing-in-Memory (PIM) enhances memory with computational capabilities, potentially solving energy and latency issues associated with data transfer between memory and processors. However, managing concurrent computation and data flow within the PIM architecture incurs significant latency and energy penalty for applications. This paper introduces Shared-PIM, an architecture for in-DRAM PIM that strategically allocates rows in memory banks, bolstered by memory peripherals, for concurrent processing and data movement. Shared-PIM enables simultaneous computation and data transfer within a memory bank. When compared to LISA, a state-of-the-art architecture that facilitates data transfers for in-DRAM PIM, Shared-PIM reduces data movement latency and energy by 5x and 1.2x respectively. Furthermore, when integrated to a state-of-the-art (SOTA) in-DRAM PIM architecture (pLUTo), Shared-PIM achieves 1.4x faster addition and multiplication, and thereby improves the performance of matrix multiplication (MM) tasks by 40%, polynomial multiplication (PMM) by 44%, and numeric number transfer (NTT) tasks by 31%. Moreover, for graph processing tasks like Breadth-First Search (BFS) and Depth-First Search (DFS), Shared-PIM achieves a 29% improvement in speed, all with an area overhead of just 7.16% compared to the baseline pLUTo.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15516",
        "abstract url": "https://arxiv.org/abs/2408.15516",
        "title": "Predicting Parameter Change's Effect on Cellular Network Time Series",
        "rating": "-2",
        "keywords": [
            [
                "forecasting"
            ]
        ],
        "abstract": "The cellular network provides convenient network access for ever-growing mobile phones. During the continuous optimization, operators can adjust cell parameters to enhance the Quality of Service (QoS) flexibly. A precise prediction of the parameter change's effect can help operators make proper parameter adjustments. This work focuses on predicting cell status (like the workload and QoS) after adjusting the cell parameters. The prediction will be conducted before an adjustment is actually applied to provide an early inspection. As it can be hard for available parameter adjustments with a limited number to cover all the parameter and user behavior combinations, we propose ParaSeer fusing domain knowledge on parameter adjustments into data-driven time series forecasting. ParaSeer organizes several pre-trained Transformers for adjustment-free time series forecasting, utilizing plenty of adjustment-free data. On the other hand, ParaSeer models the effect of adjusting the transmission power and cell individual offset (CIO) as a multiplier for the workload. We derive a formula to calculate the multiplier from the underlying mechanism of those two parameters, helping ParaSeer eliminate the thirst for data with parameter adjustments. We compare ParaSeer with baselines on two real-world datasets, where ParaSeer outperforms the best baseline by more than 25.8% in terms of RMSE. The extensive experiments further illustrate the contributions of ParaSeer's components.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15519",
        "abstract url": "https://arxiv.org/abs/2408.15519",
        "title": "Depth-Weighted Detection of Behaviours of Risk in People with Dementia using Cameras",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "health",
                "psychological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The behavioural and psychological symptoms of dementia, such as agitation and aggression, present a significant health and safety risk in residential care settings. Many care facilities have video cameras in place for digital monitoring of public spaces, which can be leveraged to develop an automated behaviours of risk detection system that can alert the staff to enable timely intervention and prevent the situation from escalating. However, one of the challenges in our previous study was the presence of false alarms due to obstruction of view by activities happening close to the camera. To address this issue, we proposed a novel depth-weighted loss function to train a customized convolutional autoencoder to enforce equivalent importance to the events happening both near and far from the cameras; thus, helping to reduce false alarms and making the method more suitable for real-world deployment. The proposed method was trained using data from nine participants with dementia across three cameras situated in a specialized dementia unit and achieved an area under the curve of receiver operating characteristic of $0.852$, $0.81$ and $0.768$ for the three cameras. Ablation analysis was conducted for the individual components of the proposed method and the performance of the proposed method was investigated for participant-specific and sex-specific behaviours of risk detection. The proposed method performed reasonably well in detecting behaviours of risk in people with dementia motivating further research toward the development of a behaviours of risk detection system suitable for deployment in video surveillance systems in care facilities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14817",
        "abstract url": "https://arxiv.org/abs/2408.14817",
        "title": "A Comprehensive Benchmark of Machine and Deep Learning Across Diverse Tabular Datasets",
        "rating": "-2.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "Tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The analysis of tabular datasets is highly prevalent both in scientific research and real-world applications of Machine Learning (ML). Unlike many other ML tasks, Deep Learning (DL) models often do not outperform traditional methods in this area. Previous comparative benchmarks have shown that DL performance is frequently equivalent or even inferior to models such as Gradient Boosting Machines (GBMs). In this study, we introduce a comprehensive benchmark aimed at better characterizing the types of datasets where DL models excel. Although several important benchmarks for tabular datasets already exist, our contribution lies in the variety and depth of our comparison: we evaluate 111 datasets with 20 different models, including both regression and classification tasks. These datasets vary in scale and include both those with and without categorical variables. Importantly, our benchmark contains a sufficient number of datasets where DL models perform best, allowing for a thorough analysis of the conditions under which DL models excel. Building on the results of this benchmark, we train a model that predicts scenarios where DL models outperform alternative methods with 86.1% accuracy (AUC 0.78). We present insights derived from this characterization and compare these findings to previous benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14875",
        "abstract url": "https://arxiv.org/abs/2408.14875",
        "title": "Adversarial Attacks and Defenses in Multivariate Time-Series Forecasting for Smart and Connected Infrastructures",
        "rating": "-2.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The emergence of deep learning models has revolutionized various industries over the last decade, leading to a surge in connected devices and infrastructures. However, these models can be tricked into making incorrect predictions with high confidence, leading to disastrous failures and security concerns. To this end, we explore the impact of adversarial attacks on multivariate time-series forecasting and investigate methods to counter them. Specifically, we employ untargeted white-box attacks, namely the Fast Gradient Sign Method (FGSM) and the Basic Iterative Method (BIM), to poison the inputs to the training process, effectively misleading the model. We also illustrate the subtle modifications to the inputs after the attack, which makes detecting the attack using the naked eye quite difficult. Having demonstrated the feasibility of these attacks, we develop robust models through adversarial training and model hardening. We are among the first to showcase the transferability of these attacks and defenses by extrapolating our work from the benchmark electricity data to a larger, 10-year real-world data used for predicting the time-to-failure of hard disks. Our experimental results confirm that the attacks and defenses achieve the desired security thresholds, leading to a 72.41% and 94.81% decrease in RMSE for the electricity and hard disk datasets respectively after implementing the adversarial defenses.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.PF"
        ],
        "comment": "17 pages, 32 figures"
    },
    {
        "paper id": "2408.14928",
        "abstract url": "https://arxiv.org/abs/2408.14928",
        "title": "Targetin the partition function of chemically disordered materials with a generative approach based on inverse variational autoencoders",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "alloys"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Computing atomic-scale properties of chemically disordered materials requires an efficient exploration of their vast configuration space. Traditional approaches such as Monte Carlo or Special Quasirandom Structures either entail sampling an excessive amount of configurations or do not ensure that the configuration space has been properly covered. In this work, we propose a novel approach where generative machine learning is used to yield a representative set of configurations for accurate property evaluation and provide accurate estimations of atomic-scale properties with minimal computational cost. Our method employs a specific type of variational autoencoder with inverse roles for the encoder and decoder, enabling the application of an unsupervised active learning scheme that does not require any initial training database. The model iteratively generates configuration batches, whose properties are computed with conventional atomic-scale methods. These results are then fed back into the model to estimate the partition function, repeating the process until convergence. We illustrate our approach by computing point-defect formation energies and concentrations in (U, Pu)O2 mixed-oxide fuels. In addition, the ML model provides valuable insights into the physical factors influencing the target property. Our method is generally applicable to explore other properties, such as atomic-scale diffusion coefficients, in ideally or non-ideally disordered materials like high-entropy alloys.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15018",
        "abstract url": "https://arxiv.org/abs/2408.15018",
        "title": "Cross-subject Brain Functional Connectivity Analysis for Multi-task Cognitive State Evaluation",
        "rating": "-2.5",
        "keywords": [
            [
                "flight"
            ],
            [
                "psychological",
                "physiological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Cognition refers to the function of information perception and processing, which is the fundamental psychological essence of human beings. It is responsible for reasoning and decision-making, while its evaluation is significant for the aviation domain in mitigating potential safety risks. Existing studies tend to use varied methods for cognitive state evaluation yet have limitations in timeliness, generalisation, and interpretability. Accordingly, this study adopts brain functional connectivity with electroencephalography signals to capture associations in brain regions across multiple subjects for evaluating real-time cognitive states. Specifically, a virtual reality-based flight platform is constructed with multi-screen embedded. Three distinctive cognitive tasks are designed and each has three degrees of difficulty. Thirty subjects are acquired for analysis and evaluation. The results are interpreted through different perspectives, including inner-subject and cross-subject for task-wise and gender-wise underlying brain functional connectivity. Additionally, this study incorporates questionnaire-based, task performance-based, and physiological measure-based approaches to fairly label the trials. A multi-class cognitive state evaluation is further conducted with the active brain connections. Benchmarking results demonstrate that the identified brain regions have considerable influences in cognition, with a multi-class accuracy rate of 95.83% surpassing existing studies. The derived findings bring significance to understanding the dynamic relationships among human brain functional regions, cross-subject cognitive behaviours, and decision-making, which have promising practical application values.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15041",
        "abstract url": "https://arxiv.org/abs/2408.15041",
        "title": "Earth Observation Satellite Scheduling with Graph Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "Satellite"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The Earth Observation Satellite Planning (EOSP) is a difficult optimization problem with considerable practical interest. A set of requested observations must be scheduled on an agile Earth observation satellite while respecting constraints on their visibility window, as well as maneuver constraints that impose varying delays between successive observations. In addition, the problem is largely oversubscribed: there are much more candidate observations than what can possibly be achieved. Therefore, one must select the set of observations that will be performed while maximizing their weighted cumulative benefit, and propose a feasible schedule for these observations. As previous work mostly focused on heuristic and iterative search algorithms, this paper presents a new technique for selecting and scheduling observations based on Graph Neural Networks (GNNs) and Deep Reinforcement Learning (DRL). GNNs are used to extract relevant information from the graphs representing instances of the EOSP, and DRL drives the search for optimal schedules. Our simulations show that it is able to learn on small problem instances and generalize to larger real-world instances, with very competitive performance compared to traditional approaches.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Accepted at 17th European Workshop on Reinforcement Learning (EWRL 2024)"
    },
    {
        "paper id": "2408.15294",
        "abstract url": "https://arxiv.org/abs/2408.15294",
        "title": "Evaluating the Predictive Features of Person-Centric Knowledge Graph Embeddings: Unfolding Ablation Studies",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "biomedical",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Developing novel predictive models with complex biomedical information is challenging due to various idiosyncrasies related to heterogeneity, standardization or sparseness of the data. We previously introduced a person-centric ontology to organize information about individual patients, and a representation learning framework to extract person-centric knowledge graphs (PKGs) and to train Graph Neural Networks (GNNs). In this paper, we propose a systematic approach to examine the results of GNN models trained with both structured and unstructured information from the MIMIC-III dataset. Through ablation studies on different clinical, demographic, and social data, we show the robustness of this approach in identifying predictive features in PKGs for the task of readmission prediction.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Published in the 34th Medical Informatics Europe Conference"
    },
    {
        "paper id": "2408.15328",
        "abstract url": "https://arxiv.org/abs/2408.15328",
        "title": "Artificially intelligent Maxwell's demon for optimal control of open quantum systems",
        "rating": "-2.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Feedback control of open quantum systems is of fundamental importance for practical applications in various contexts, ranging from quantum computation to quantum error correction and quantum metrology. Its use in the context of thermodynamics further enables the study of the interplay between information and energy. However, deriving optimal feedback control strategies is highly challenging, as it involves the optimal control of open quantum systems, the stochastic nature of quantum measurement, and the inclusion of policies that maximize a long-term time- and trajectory-averaged goal. In this work, we employ a reinforcement learning approach to automate and capture the role of a quantum Maxwell's demon: the agent takes the literal role of discovering optimal feedback control strategies in qubit-based systems that maximize a trade-off between measurement-powered cooling and measurement efficiency. Considering weak or projective quantum measurements, we explore different regimes based on the ordering between the thermalization, the measurement, and the unitary feedback timescales, finding different and highly non-intuitive, yet interpretable, strategies. In the thermalization-dominated regime, we find strategies with elaborate finite-time thermalization protocols conditioned on measurement outcomes. In the measurement-dominated regime, we find that optimal strategies involve adaptively measuring different qubit observables reflecting the acquired information, and repeating multiple weak measurements until the quantum state is \"sufficiently pure\", leading to random walks in state space. Finally, we study the case when all timescales are comparable, finding new feedback control strategies that considerably outperform more intuitive ones. We discuss a two-qubit example where we explore the role of entanglement and conclude discussing the scaling of our results to quantum many-body systems.",
        "subjects": [
            "quant-ph",
            "cond-mat.mes-hall",
            "cs.LG"
        ],
        "comment": "16+10 pages, 21 figures"
    },
    {
        "paper id": "2408.15428",
        "abstract url": "https://arxiv.org/abs/2408.15428",
        "title": "HEAD: A Bandwidth-Efficient Cooperative Perception Approach for Heterogeneous Connected and Autonomous Vehicles",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR"
            ],
            [
                "Bird's-eye View",
                "BEV"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "In cooperative perception studies, there is often a trade-off between communication bandwidth and perception performance. While current feature fusion solutions are known for their excellent object detection performance, transmitting the entire sets of intermediate feature maps requires substantial bandwidth. Furthermore, these fusion approaches are typically limited to vehicles that use identical detection models. Our goal is to develop a solution that supports cooperative perception across vehicles equipped with different modalities of sensors. This method aims to deliver improved perception performance compared to late fusion techniques, while achieving precision similar to the state-of-art intermediate fusion, but requires an order of magnitude less bandwidth. We propose HEAD, a method that fuses features from the classification and regression heads in 3D object detection networks. Our method is compatible with heterogeneous detection networks such as LiDAR PointPillars, SECOND, VoxelNet, and camera Bird's-eye View (BEV) Encoder. Given the naturally smaller feature size in the detection heads, we design a self-attention mechanism to fuse the classification head and a complementary feature fusion layer to fuse the regression head. Our experiments, comprehensively evaluated on the V2V4Real and OPV2V datasets, demonstrate that HEAD is a fusion method that effectively balances communication bandwidth and perception performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024 Workshop"
    },
    {
        "paper id": "2408.14851",
        "abstract url": "https://arxiv.org/abs/2408.14851",
        "title": "Graph and Sequential Neural Networks in Session-based Recommendation: A Survey",
        "rating": "-3",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recent years have witnessed the remarkable success of recommendation systems (RSs) in alleviating the information overload problem. As a new paradigm of RSs, session-based recommendation (SR) specializes in users' short-term preference capture and aims to provide a more dynamic and timely recommendation based on the ongoing interacted actions. In this survey, we will give a comprehensive overview of the recent works on SR. First, we clarify the definitions of various SR tasks and introduce the characteristics of session-based recommendation against other recommendation tasks. Then, we summarize the existing methods in two categories: sequential neural network based methods and graph neural network (GNN) based methods. The standard frameworks and technical are also introduced. Finally, we discuss the challenges of SR and new research directions in this area.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14861",
        "abstract url": "https://arxiv.org/abs/2408.14861",
        "title": "Optimal Joint Radar and Communication User Association in Cell-Free mMIMO Systems",
        "rating": "-3",
        "keywords": [
            [
                "Radar"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "The cell-free massive multiple-input multiple-output (CF-mMIMO) systems are crucial for 6G development due to their high spectral efficiency and uniform user-experienced data rates. A key aspect of CF-mMIMO is user association (UA) and optimal cluster formation. Traditional methods focusing solely on communication-related metrics fall short in this context, as sensing is becoming integral to 6G. This study delves into a framework for joint radar and communication (JRC) in CF-mMIMO systems and investigates JRC-based UA techniques. We propose a novel method to optimize UA, enhancing both communication spectral efficiency and sensing accuracy. Existing literature has not explored this dual requirement integration for UA. Our proposed two-step scheme optimizes UA clusters for both communication and sensing. The first step involves selecting access points (APs) based on channel quality, followed by a second step that further refines the selection by choosing APs from the initial group that are also optimal for sensing. We utilize the signal-clutter plus noise ratio to exclude APs with clutter in front of the user equipment (UE) and the AP view angle, ensuring that radar echoes are received only from the specific UE, not the surrounding clutter. Theoretical analysis and simulations demonstrate that the same APs optimized for communication are not necessarily optimal for sensing, highlighting the need for schemes that incorporate sensing requirements in UA. The results show the effectiveness of the proposed method, showing its potential to improve CF-mMIMO system performance in JRC scenarios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14873",
        "abstract url": "https://arxiv.org/abs/2408.14873",
        "title": "Robo-GS: A Physics Consistent Spatial-Temporal Model for Robotic Arm with Hybrid Representation",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "Physics"
            ]
        ],
        "abstract": "Real2Sim2Real plays a critical role in robotic arm control and reinforcement learning, yet bridging this gap remains a significant challenge due to the complex physical properties of robots and the objects they manipulate. Existing methods lack a comprehensive solution to accurately reconstruct real-world objects with spatial representations and their associated physics attributes. We propose a Real2Sim pipeline with a hybrid representation model that integrates mesh geometry, 3D Gaussian kernels, and physics attributes to enhance the digital asset representation of robotic arms. This hybrid representation is implemented through a Gaussian-Mesh-Pixel binding technique, which establishes an isomorphic mapping between mesh vertices and Gaussian models. This enables a fully differentiable rendering pipeline that can be optimized through numerical solvers, achieves high-fidelity rendering via Gaussian Splatting, and facilitates physically plausible simulation of the robotic arm's interaction with its environment using mesh-based methods. The code,full presentation and datasets will be made publicly available at our website https://robostudioapp.com",
        "subjects": [
            "cs.RO",
            "math.NA",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14879",
        "abstract url": "https://arxiv.org/abs/2408.14879",
        "title": "Adversarial Manhole: Challenging Monocular Depth Estimation and Semantic Segmentation Models with Patch Attack",
        "rating": "-3",
        "keywords": [
            [
                "Depth"
            ],
            [
                "autonomous driving"
            ],
            [
                "navigation"
            ],
            [
                "Attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Monocular depth estimation (MDE) and semantic segmentation (SS) are crucial for the navigation and environmental interpretation of many autonomous driving systems. However, their vulnerability to practical adversarial attacks is a significant concern. This paper presents a novel adversarial attack using practical patches that mimic manhole covers to deceive MDE and SS models. The goal is to cause these systems to misinterpret scenes, leading to false detections of near obstacles or non-passable objects. We use Depth Planar Mapping to precisely position these patches on road surfaces, enhancing the attack's effectiveness. Our experiments show that these adversarial patches cause a 43% relative error in MDE and achieve a 96% attack success rate in SS. These patches create affected error regions over twice their size in MDE and approximately equal to their size in SS. Our studies also confirm the patch's effectiveness in physical simulations, the adaptability of the patches across different target models, and the effectiveness of our proposed modules, highlighting their practical implications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for WISA 2024. Code and dataset: https://github.com/naufalso/adversarial-manhole"
    },
    {
        "paper id": "2408.14905",
        "abstract url": "https://arxiv.org/abs/2408.14905",
        "title": "A nonlinear phase-field model of corrosion with charging kinetics of electric double layer",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "chemical"
            ]
        ],
        "abstract": "A nonlinear phase-field model is developed to simulate corrosion damage. The motion of the electrode$-$ electrolyte interface follows the usual kinetic rate theory for chemical reactions based on the Butler-Volmer equation. The model links the surface polarization variation associated with the charging kinetics of an electric double layer (EDL) to the mesoscale transport. The effects of the EDL are integrated as a boundary condition on the solution potential equation. The boundary condition controls the magnitude of the solution potential at the electrode-electrolyte interface. The ion concentration field outside the EDL is obtained by solving the electro-diffusion equation and Ohm's law for the solution potential. The model is validated against the classic benchmark pencil electrode test. The framework developed reproduces experimental measurements of both pit kinetics and transient current density response. The model enables more accurate information on corrosion damage, current density, and environmental response in terms of the distribution of electric potential and charged species. The sensitivity analysis for different properties of the EDL is performed to investigate their role in the electrochemical response of the system. Simulation results show that the properties of the EDL significantly influence the transport of ionic species in the electrolyte.",
        "subjects": [
            "physics.chem-ph",
            "cs.CE",
            "physics.app-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14941",
        "abstract url": "https://arxiv.org/abs/2408.14941",
        "title": "BOX3D: Lightweight Camera-LiDAR Fusion for 3D Object Detection and Localization",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "LiDAR"
            ],
            [
                "robotics"
            ],
            [
                "Graphs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Object detection and global localization play a crucial role in robotics, spanning across a great spectrum of applications from autonomous cars to multi-layered 3D Scene Graphs for semantic scene understanding. This article proposes BOX3D, a novel multi-modal and lightweight scheme for localizing objects of interest by fusing the information from RGB camera and 3D LiDAR. BOX3D is structured around a three-layered architecture, building up from the local perception of the incoming sequential sensor data to the global perception refinement that covers for outliers and the general consistency of each object's observation. More specifically, the first layer handles the low-level fusion of camera and LiDAR data for initial 3D bounding box extraction. The second layer converts each LiDAR's scan 3D bounding boxes to the world coordinate frame and applies a spatial pairing and merging mechanism to maintain the uniqueness of objects observed from different viewpoints. Finally, BOX3D integrates the third layer that supervises the consistency of the results on the global map iteratively, using a point-to-voxel comparison for identifying all points in the global map that belong to the object. Benchmarking results of the proposed novel architecture are showcased in multiple experimental trials on public state-of-the-art large-scale dataset of urban environments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Presented in MED 2024"
    },
    {
        "paper id": "2408.14977",
        "abstract url": "https://arxiv.org/abs/2408.14977",
        "title": "LN-Gen: Rectal Lymph Nodes Generation via Anatomical Features",
        "rating": "-3",
        "keywords": [
            [
                "SDF"
            ],
            [
                "diffusion"
            ],
            [
                "diagnosis",
                "cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Accurate segmentation of rectal lymph nodes is crucial for the staging and treatment planning of rectal cancer. However, the complexity of the surrounding anatomical structures and the scarcity of annotated data pose significant challenges. This study introduces a novel lymph node synthesis technique aimed at generating diverse and realistic synthetic rectal lymph node samples to mitigate the reliance on manual annotation. Unlike direct diffusion methods, which often produce masks that are discontinuous and of suboptimal quality, our approach leverages an implicit SDF-based method for mask generation, ensuring the production of continuous, stable, and morphologically diverse masks. Experimental results demonstrate that our synthetic data significantly improves segmentation performance. Our work highlights the potential of diffusion model for accurately synthesizing structurally complex lesions, such as lymph nodes in rectal cancer, alleviating the challenge of limited annotated data in this field and aiding in advancements in rectal cancer diagnosis and treatment.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2408.14986",
        "abstract url": "https://arxiv.org/abs/2408.14986",
        "title": "A High Altitude Platform-Based 3D Geometrical Channel Model for Beamforming Characterization in Future 6G Flying Ad-Hoc Networks",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "Growing requirements of future wireless communication systems, such as high data rates, high reliability, and low latency, make the active usage of Non-Terrestrial Networks (NTN) an inevitable necessity. In this regard, High Altitude Platforms (HAPs) have drawn great attention in recent years due to their unique characteristics such as high coverage, long operational durability, and ad-hoc movement. However, for the active usage of HAPs, channel models for their various usage scenarios must be well-defined, especially in those cases where the sophisticated multiple-input multiple-output (MIMO) techniques, such as beamforming, are utilized to increase the data rate. Therefore, in this study, an air-to-air (A2A) three dimensional (3D) geometrical channel model is proposed to characterize the beamforming capabilities of non-stationary HAP networks operating at millimeter wave (mmWave) frequency band. In this regard, the 3D geometry of the two HAPs in the air is analyzed, and the effect of Doppler due to the movement of HAPs is interrogated as well as its effect on the signal-to-noise ratio (SNR). The final outputs of this study show that the proposed A2A channel model is applicable to characterize the future sixth generation (6G) HAP networks when the mmWave is used to utilize beamforming with a large number of antennas.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15026",
        "abstract url": "https://arxiv.org/abs/2408.15026",
        "title": "Sequence-aware Pre-training for Echocardiography Probe Guidance",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "6-DOF"
            ],
            [
                "navigation"
            ],
            [
                "Cardiac"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Cardiac ultrasound probe guidance aims to help novices adjust the 6-DOF probe pose to obtain high-quality sectional images. Cardiac ultrasound faces two major challenges: (1) the inherently complex structure of the heart, and (2) significant individual variations. Previous works have only learned the population-averaged 2D and 3D structures of the heart rather than personalized cardiac structural features, leading to a performance bottleneck. Clinically, we observed that sonographers adjust their understanding of a patient's cardiac structure based on prior scanning sequences, thereby modifying their scanning strategies. Inspired by this, we propose a sequence-aware self-supervised pre-training method. Specifically, our approach learns personalized 2D and 3D cardiac structural features by predicting the masked-out images and actions in a scanning sequence. We hypothesize that if the model can predict the missing content it has acquired a good understanding of the personalized cardiac structure. In the downstream probe guidance task, we also introduced a sequence modeling approach that models individual cardiac structural information based on the images and actions from historical scan data, enabling more accurate navigation decisions. Experiments on a large-scale dataset with 1.36 million samples demonstrated that our proposed sequence-aware paradigm can significantly reduce navigation errors, with translation errors decreasing by 15.90% to 36.87% and rotation errors decreasing by 11.13% to 20.77%, compared to state-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Tech Report"
    },
    {
        "paper id": "2408.15118",
        "abstract url": "https://arxiv.org/abs/2408.15118",
        "title": "DIFR3CT: Latent Diffusion for Probabilistic 3D CT Reconstruction from Few Planar X-Rays",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "CT",
                "x-ray",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Computed Tomography (CT) scans are the standard-of-care for the visualization and diagnosis of many clinical ailments, and are needed for the treatment planning of external beam radiotherapy. Unfortunately, the availability of CT scanners in low- and mid-resource settings is highly variable. Planar x-ray radiography units, in comparison, are far more prevalent, but can only provide limited 2D observations of the 3D anatomy. In this work we propose DIFR3CT, a 3D latent diffusion model, that can generate a distribution of plausible CT volumes from one or few (<10) planar x-ray observations. DIFR3CT works by fusing 2D features from each x-ray into a joint 3D space, and performing diffusion conditioned on these fused features in a low-dimensional latent space. We conduct extensive experiments demonstrating that DIFR3CT is better than recent sparse CT reconstruction baselines in terms of standard pixel-level (PSNR, SSIM) on both the public LIDC and in-house post-mastectomy CT datasets. We also show that DIFR3CT supports uncertainty quantification via Monte Carlo sampling, which provides an opportunity to measure reconstruction reliability. Finally, we perform a preliminary pilot study evaluating DIFR3CT for automated breast radiotherapy contouring and planning -- and demonstrate promising feasibility. Our code is available at https://github.com/yransun/DIFR3CT.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "11 pages, 9 figures"
    },
    {
        "paper id": "2408.15132",
        "abstract url": "https://arxiv.org/abs/2408.15132",
        "title": "Faster Cycle Detection in the Congested Clique",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "We provide a fast distributed algorithm for detecting $h$-cycles in the \\textsf{Congested Clique} model, whose running time decreases as the number of $h$-cycles in the graph increases. In undirected graphs, constant-round algorithms are known for cycles of even length. Our algorithm greatly improves upon the state of the art for odd values of $h$. Moreover, our running time applies also to directed graphs, in which case the improvement is for all values of $h$. Further, our techniques allow us to obtain a triangle detection algorithm in the quantum variant of this model, which is faster than prior work. A key technical contribution we develop to obtain our fast cycle detection algorithm is a new algorithm for computing the product of many pairs of small matrices in parallel, which may be of independent interest.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "comment": "37 pages. To appear in proceedings of DISC 2024"
    },
    {
        "paper id": "2408.15221",
        "abstract url": "https://arxiv.org/abs/2408.15221",
        "title": "LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet",
        "rating": "-3",
        "keywords": [
            [
                "unlearning"
            ],
            [
                "attacks"
            ],
            [
                "biosecurity"
            ],
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Recent large language model (LLM) defenses have greatly improved models' ability to refuse harmful queries, even when adversarially attacked. However, LLM defenses are primarily evaluated against automated adversarial attacks in a single turn of conversation, an insufficient threat model for real-world malicious use. We demonstrate that multi-turn human jailbreaks uncover significant vulnerabilities, exceeding 70% attack success rate (ASR) on HarmBench against defenses that report single-digit ASRs with automated single-turn attacks. Human jailbreaks also reveal vulnerabilities in machine unlearning defenses, successfully recovering dual-use biosecurity knowledge from unlearned models. We compile these results into Multi-Turn Human Jailbreaks (MHJ), a dataset of 2,912 prompts across 537 multi-turn jailbreaks. We publicly release MHJ alongside a compendium of jailbreak tactics developed across dozens of commercial red teaming engagements, supporting research towards stronger LLM defenses.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CR",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15242",
        "abstract url": "https://arxiv.org/abs/2408.15242",
        "title": "Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "Drone"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Robust and realistic rendering for large-scale road scenes is essential in autonomous driving simulation. Recently, 3D Gaussian Splatting (3D-GS) has made groundbreaking progress in neural rendering, but the general fidelity of large-scale road scene renderings is often limited by the input imagery, which usually has a narrow field of view and focuses mainly on the street-level local area. Intuitively, the data from the drone's perspective can provide a complementary viewpoint for the data from the ground vehicle's perspective, enhancing the completeness of scene reconstruction and rendering. However, training naively with aerial and ground images, which exhibit large view disparity, poses a significant convergence challenge for 3D-GS, and does not demonstrate remarkable improvements in performance on road views. In order to enhance the novel view synthesis of road views and to effectively use the aerial information, we design an uncertainty-aware training method that allows aerial images to assist in the synthesis of areas where ground images have poor learning outcomes instead of weighting all pixels equally in 3D-GS training like prior work did. We are the first to introduce the cross-view uncertainty to 3D-GS by matching the car-view ensemble-based rendering uncertainty to aerial images, weighting the contribution of each pixel to the training process. Additionally, to systematically quantify evaluation metrics, we assemble a high-quality synthesized dataset comprising both aerial and ground images for road scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "BMVC2024 Project Page: https://sainingzhang.github.io/project/uc-gs/ Code: https://github.com/SainingZhang/uc-gs/"
    },
    {
        "paper id": "2408.15373",
        "abstract url": "https://arxiv.org/abs/2408.15373",
        "title": "Handling Geometric Domain Shifts in Semantic Segmentation of Surgical RGB and Hyperspectral Images",
        "rating": "-3",
        "keywords": [
            [
                "Surgical",
                "surgery",
                "Organ"
            ],
            [
                "Hyperspectral Images"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Robust semantic segmentation of intraoperative image data holds promise for enabling automatic surgical scene understanding and autonomous robotic surgery. While model development and validation are primarily conducted on idealistic scenes, geometric domain shifts, such as occlusions of the situs, are common in real-world open surgeries. To close this gap, we (1) present the first analysis of state-of-the-art (SOA) semantic segmentation models when faced with geometric out-of-distribution (OOD) data, and (2) propose an augmentation technique called \"Organ Transplantation\", to enhance generalizability. Our comprehensive validation on six different OOD datasets, comprising 600 RGB and hyperspectral imaging (HSI) cubes from 33 pigs, each annotated with 19 classes, reveals a large performance drop in SOA organ segmentation models on geometric OOD data. This performance decline is observed not only in conventional RGB data (with a dice similarity coefficient (DSC) drop of 46 %) but also in HSI data (with a DSC drop of 45 %), despite the richer spectral information content. The performance decline increases with the spatial granularity of the input data. Our augmentation technique improves SOA model performance by up to 67 % for RGB data and 90 % for HSI data, achieving performance at the level of in-distribution performance on real OOD test data. Given the simplicity and effectiveness of our augmentation method, it is a valuable tool for addressing geometric domain shifts in surgical scene segmentation, regardless of the underlying model. Our code and pre-trained models are publicly available at https://github.com/IMSY-DKFZ/htc.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Silvia Seidlitz and Jan Sellner contributed equally"
    },
    {
        "paper id": "2408.15414",
        "abstract url": "https://arxiv.org/abs/2408.15414",
        "title": "Continuum Damage Model for Hydrogen Embrittlement in Ferritic Steels",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "industrial",
                "alloys"
            ]
        ],
        "abstract": "Hydrogen embrittlement of metals and alloys, particularly steels, has been an important scientific and engineering challenge in the Oil and Gas industry for many years. It impacts the integrity and performance of a wide range of structures and equipment such as downhole tubulars and pipelines in sour service in the Upstream (U/S) and hydro-processing reactors in the Downstream (D/S). In addition, the rapidly growing interest in hydrogen as an energy carrier for fuel cells and mobility or as a clean fuel/heat source for hard to decarbonize industrial processes, draws attention to this key challenge of materials integrity in handling hydrogen. The fundamental understanding of failure mechanism(s) and the capability to model material behavior is important for managing the integrity and for repurposing existing infrastructure for transporting hydrogen as well as for extending the life of structures. To that extent, the present work develops a robust mathematical model to estimate the strength degradation and embrittlement due to hydrogen in steels. The model incorporates hydrogen affected constitutive response of material, within the framework of finite element method. The modified constitutive response is a Gurson plasticity based continuum damage model and incorporates two vital aspects of NVC failure theory. These key aspects are (i) hydrogen enhanced localized dislocation plasticity, and (ii) hydrogen enhanced vacancy stabilization forming nano-voids. The deformation and damage in the material is coupled with trap mediated hydrogen diffusion. Calibration of damage model parameters is performed for X65 commercial linepipe steel. Finally, capability of the damage model is demonstrated with numerical simulation of round bar tensile tests on X65 steel under hydrogen exposure. The numerical simulations are shown to be in excellent agreement with experimental results.",
        "subjects": [
            "cs.CE",
            "math.NA"
        ],
        "comment": "39 pages, 7 figures, 1 table"
    },
    {
        "paper id": "2408.15458",
        "abstract url": "https://arxiv.org/abs/2408.15458",
        "title": "PersonalizedUS: Interpretable Breast Cancer Risk Assessment with Local Coverage Uncertainty Quantification",
        "rating": "-3",
        "keywords": [
            [
                "biopsies",
                "health",
                "Cancer",
                "clinical",
                "lesion"
            ],
            [
                "tabular"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Correctly assessing the malignancy of breast lesions identified during ultrasound examinations is crucial for effective clinical decision-making. However, the current \"golden standard\" relies on manual BI-RADS scoring by clinicians, often leading to unnecessary biopsies and a significant mental health burden on patients and their families. In this paper, we introduce PersonalizedUS, an interpretable machine learning system that leverages recent advances in conformal prediction to provide precise and personalized risk estimates with local coverage guarantees and sensitivity, specificity, and predictive values above 0.9 across various threshold levels. In particular, we identify meaningful lesion subgroups where distribution-free, model-agnostic conditional coverage holds, with approximately 90% of our prediction sets containing only the ground truth in most lesion subgroups, thus explicitly characterizing for which patients the model is most suitably applied. Moreover, we make available a curated tabular dataset of 1936 biopsied breast lesions from a recent observational multicenter study and benchmark the performance of several state-of-the-art learning algorithms. We also report a successful case study of the deployed system in the same multicenter context. Concrete clinical benefits include up to a 65% reduction in requested biopsies among BI-RADS 4a and 4b lesions, with minimal to no missed cancer cases.",
        "subjects": [
            "cs.LG",
            "eess.IV",
            "stat.ML"
        ],
        "comment": "9 pages, 5 figure, 2 tables"
    },
    {
        "paper id": "2408.15467",
        "abstract url": "https://arxiv.org/abs/2408.15467",
        "title": "Bio-inspired circular soft actuators for simulating defecation process of human rectum",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "Bio-inspired",
                "medical"
            ]
        ],
        "abstract": "Soft robots have found extensive applications in the medical field, particularly in rehabilitation exercises, assisted grasping, and artificial organs. Despite significant advancements in simulating various components of the digestive system, the rectum has been largely neglected due to societal stigma. This study seeks to address this gap by developing soft circular muscle actuators (CMAs) and rectum models to replicate the defecation process. Using soft materials, both the rectum and the actuators were fabricated to enable seamless integration and attachment. We designed, fabricated, and tested three types of CMAs and compared them to the simulated results. A pneumatic system was employed to control the actuators, and simulated stool was synthesized using sodium alginate and calcium chloride. Experimental results indicated that the third type of actuator exhibited superior performance in terms of area contraction and pressure generation. The successful simulation of the defecation process highlights the potential of these soft actuators in biomedical applications, providing a foundation for further research and development in the field of soft robotics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15473",
        "abstract url": "https://arxiv.org/abs/2408.15473",
        "title": "Power, Control, and Data Acquisition Systems for Rectal Simulator Integrated with Soft Pouch Actuators",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "health"
            ]
        ],
        "abstract": "Fecal incontinence (FI) is a significant health issue with various underlying causes. Research in this field is limited by social stigma and the lack of effective replication models. To address these challenges, we developed a sophisticated rectal simulator that integrates power, control, and data acquisition systems with soft pouch actuators. The system comprises four key subsystems: mechanical, electrical, pneumatic, and control and data acquisition. The mechanical subsystem utilizes common materials such as aluminum frames, wooden boards, and compact structural components to facilitate the installation and adjustment of electrical and control components. The electrical subsystem supplies power to regulators and sensors. The pneumatic system provides compressed air to actuators, enabling the simulation of FI. The control and data acquisition subsystem collects pressure data and regulates actuator movement. This comprehensive approach allows the robot to accurately replicate human defecation, managing various feces types including liquid, solid, and extremely solid. This innovation enhances our understanding of defecation and holds potential for advancing quality-of-life devices related to this condition.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15492",
        "abstract url": "https://arxiv.org/abs/2408.15492",
        "title": "Infinite-Horizon Optimal Wireless Control Over Shared State-Dependent Fading Channels for IIoT Systems",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "Industrial"
            ]
        ],
        "abstract": "Heterogeneous systems consisting of a multiloop wireless control system (WCS) and a mobile agent system (MAS) are ubiquitous in Industrial Internet of Things systems. Within these systems, positions of mobile agents may lead to shadow fading on the wireless channel that the WCS is controlled over and can significantly compromise its performance. This paper focuses on the infinite-horizon optimal control of MAS to ensure the performance of WCS while minimizing an average cost for the heterogeneous system subject to state and input constraints. Firstly, the state-dependent fading channel is modeled, which characterizes the interference among transmission links, and shows that the probability of a successful transmission for WCS depends on the state of MAS. A necessary and sufficient condition in terms of constrained set stabilization is then established to ensure the Lyapunov-like performance of WCS with expected decay rate. Secondly, using the semi-tensor product of matrices and constrained reachable sets, a criterion is presented to check the constrained set stabilization of MAS and to ensure the performance of WCS. In addition, a constrained optimal state transition graph is constructed to address state and input constraints, by resorting to which the feasibility analysis of the optimal control problem is presented. Finally, an algorithm is proposed for the construction of optimal input sequences by minimum-mean cycles for weighted graph. An illustrative example is provided to demonstrate effectiveness of the proposed method.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14951",
        "abstract url": "https://arxiv.org/abs/2408.14951",
        "title": "Domain-decoupled Physics-informed Neural Networks with Closed-form Gradients for Fast Model Learning of Dynamical Systems",
        "rating": "-3.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "graph"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-informed neural networks (PINNs) are trained using physical equations and can also incorporate unmodeled effects by learning from data. PINNs for control (PINCs) of dynamical systems are gaining interest due to their prediction speed compared to classical numerical integration methods for nonlinear state-space models, making them suitable for real-time control applications. We introduce the domain-decoupled physics-informed neural network (DD-PINN) to address current limitations of PINC in handling large and complex nonlinear dynamical systems. The time domain is decoupled from the feed-forward neural network to construct an Ansatz function, allowing for calculation of gradients in closed form. This approach significantly reduces training times, especially for large dynamical systems, compared to PINC, which relies on graph-based automatic differentiation. Additionally, the DD-PINN inherently fulfills the initial condition and supports higher-order excitation inputs, simplifying the training process and enabling improved prediction accuracy. Validation on three systems - a nonlinear mass-spring-damper, a five-mass-chain, and a two-link robot - demonstrates that the DD-PINN achieves significantly shorter training times. In cases where the PINC's prediction diverges, the DD-PINN's prediction remains stable and accurate due to higher physics loss reduction or use of a higher-order excitation input. The DD-PINN allows for fast and accurate learning of large dynamical systems previously out of reach for the PINC.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "Accepted to International Conference on Informatics in Control, Automation and Robotics (ICINCO) 2024"
    },
    {
        "paper id": "2408.15737",
        "abstract url": "https://arxiv.org/abs/2408.15737",
        "title": "TCNFormer: Temporal Convolutional Network Former for Short-Term Wind Speed Forecasting",
        "rating": "-3.5",
        "keywords": [
            [
                "CT"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Global environmental challenges and rising energy demands have led to extensive exploration of wind energy technologies. Accurate wind speed forecasting (WSF) is crucial for optimizing wind energy capture and ensuring system stability. However, predicting wind speed remains challenging due to its inherent randomness, fluctuation, and unpredictability. This study proposes the Temporal Convolutional Network Former (TCNFormer) for short-term (12-hour) wind speed forecasting. The TCNFormer integrates the Temporal Convolutional Network (TCN) and transformer encoder to capture the spatio-temporal features of wind speed. The transformer encoder consists of two distinct attention mechanisms: causal temporal multi-head self-attention (CT-MSA) and temporal external attention (TEA). CT-MSA ensures that the output of a step derives only from previous steps, i.e., causality. Locality is also introduced to improve efficiency. TEA explores potential relationships between different sample sequences in wind speed data. This study utilizes wind speed data from the NASA Prediction of Worldwide Energy Resources (NASA POWER) of Patenga Sea Beach, Chittagong, Bangladesh (latitude 22.2352\u00b0 N, longitude 91.7914\u00b0 E) over a year (six seasons). The findings indicate that the TCNFormer outperforms state-of-the-art models in prediction accuracy. The proposed TCNFormer presents a promising method for spatio-temporal WSF and may achieve desirable performance in real-world applications of wind power systems.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14885",
        "abstract url": "https://arxiv.org/abs/2408.14885",
        "title": "Three-Dimensional Vehicle Dynamics State Estimation for High-Speed Race Cars under varying Signal Quality",
        "rating": "-4",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Navigation"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "This work aims to present a three-dimensional vehicle dynamics state estimation under varying signal quality. Few researchers have investigated the impact of three-dimensional road geometries on the state estimation and, thus, neglect road inclination and banking. Especially considering high velocities and accelerations, the literature does not address these effects. Therefore, we compare two- and three-dimensional state estimation schemes to outline the impact of road geometries. We use an Extended Kalman Filter with a point-mass motion model and extend it by an additional formulation of reference angles. Furthermore, virtual velocity measurements significantly improve the estimation of road angles and the vehicle's side slip angle. We highlight the importance of steady estimations for vehicle motion control algorithms and demonstrate the challenges of degraded signal quality and Global Navigation Satellite System dropouts. The proposed adaptive covariance facilitates a smooth estimation and enables stable controller behavior. The developed state estimation has been deployed on a high-speed autonomous race car at various racetracks. Our findings indicate that our approach outperforms state-of-the-art vehicle dynamics state estimators and an industry-grade Inertial Navigation System. Further studies are needed to investigate the performance under varying track conditions and on other vehicle types.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been accepted at IROS 2024"
    },
    {
        "paper id": "2408.15084",
        "abstract url": "https://arxiv.org/abs/2408.15084",
        "title": "CR-Enabled NOMA Integrated Non-Terrestrial IoT Networks with Transmissive RIS",
        "rating": "-4",
        "keywords": [
            [
                "IoT"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "This work proposes a T-RIS-equipped LEO satellite communication in cognitive radio-enabled integrated NTNs. In the proposed system, a GEO satellite operates as a primary network, and a T-RIS-equipped LEO satellite operates as a secondary IoT network. The objective is to maximize the sum rate of T-RIS-equipped LEO satellite communication using downlink NOMA while ensuring the service quality of GEO cellular users. Our framework simultaneously optimizes the total transmit power of LEO, NOMA power allocation for LEO IoT (LIoT) and T-RIS phase shift design subject to the service quality of LIoT and interference temperature to the primary GEO network. To solve the non-convex sum rate maximization problem, we first adopt successive convex approximations to reduce the complexity of the formulated optimization. Then, we divide the problem into two parts, i.e., power allocation of LEO and phase shift design of T-RIS. The power allocation problem is solved using KKT conditions, while the phase shift problem is handled by Taylor approximation and semidefinite programming. Numerical results are provided to validate the proposed optimization framework.",
        "subjects": [
            "cs.ET",
            "eess.SP"
        ],
        "comment": "7,5"
    },
    {
        "paper id": "2408.15127",
        "abstract url": "https://arxiv.org/abs/2408.15127",
        "title": "T-FAKE: Synthesizing Thermal Images for Facial Landmarking",
        "rating": "-4",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "biometrics",
                "healthcare",
                "clinical",
                "Facial"
            ],
            [
                "Thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial analysis is a key component in a wide range of applications such as security, autonomous driving, entertainment, and healthcare. Despite the availability of various facial RGB datasets, the thermal modality, which plays a crucial role in life sciences, medicine, and biometrics, has been largely overlooked. To address this gap, we introduce the T-FAKE dataset, a new large-scale synthetic thermal dataset with sparse and dense landmarks. To facilitate the creation of the dataset, we propose a novel RGB2Thermal loss function, which enables the transfer of thermal style to RGB faces. By utilizing the Wasserstein distance between thermal and RGB patches and the statistical analysis of clinical temperature distributions on faces, we ensure that the generated thermal images closely resemble real samples. Using RGB2Thermal style transfer based on our RGB2Thermal loss function, we create the T-FAKE dataset, a large-scale synthetic thermal dataset of faces. Leveraging our novel T-FAKE dataset, probabilistic landmark prediction, and label adaptation networks, we demonstrate significant improvements in landmark detection methods on thermal images across different landmark conventions. Our models show excellent performance with both sparse 70-point landmarks and dense 478-point landmark annotations. Our code and models are available at https://github.com/phflot/tfake.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "22 pages, 12 figures, Philipp Flotho and Moritz Piening share equal contribution"
    },
    {
        "paper id": "2408.15159",
        "abstract url": "https://arxiv.org/abs/2408.15159",
        "title": "Empowering Sign Language Communication: Integrating Sentiment and Semantics for Facial Expression Synthesis",
        "rating": "-4",
        "keywords": [
            [
                "graph"
            ],
            [
                "Sign Language",
                "Facial"
            ],
            [
                "grammar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Translating written sentences from oral languages to a sequence of manual and non-manual gestures plays a crucial role in building a more inclusive society for deaf and hard-of-hearing people. Facial expressions (non-manual), in particular, are responsible for encoding the grammar of the sentence to be spoken, applying punctuation, pronouns, or emphasizing signs. These non-manual gestures are closely related to the semantics of the sentence being spoken and also to the utterance of the speaker's emotions. However, most Sign Language Production (SLP) approaches are centered on synthesizing manual gestures and do not focus on modeling the speakers expression. This paper introduces a new method focused in synthesizing facial expressions for sign language. Our goal is to improve sign language production by integrating sentiment information in facial expression generation. The approach leverages a sentence sentiment and semantic features to sample from a meaningful representation space, integrating the bias of the non-manual components into the sign language production process. To evaluate our method, we extend the Frechet Gesture Distance (FGD) and propose a new metric called Frechet Expression Distance (FED) and apply an extensive set of metrics to assess the quality of specific regions of the face. The experimental results showed that our method achieved state of the art, being superior to the competitors on How2Sign and PHOENIX14T datasets. Moreover, our architecture is based on a carefully designed graph pyramid that makes it simpler, easier to train, and capable of leveraging emotions to produce facial expressions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15218",
        "abstract url": "https://arxiv.org/abs/2408.15218",
        "title": "Histo-Diffusion: A Diffusion Super-Resolution Method for Digital Pathology with Comprehensive Quality Assessment",
        "rating": "-4",
        "keywords": [
            [
                "Diffusion",
                "Super-Resolution"
            ],
            [
                "diagnosis",
                "Whole Slide",
                "disease"
            ],
            [
                "Quality Assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Digital pathology has advanced significantly over the last decade, with Whole Slide Images (WSIs) encompassing vast amounts of data essential for accurate disease diagnosis. High-resolution WSIs are essential for precise diagnosis but technical limitations in scanning equipment and variablity in slide preparation can hinder obtaining these images. Super-resolution techniques can enhance low-resolution images; while Generative Adversarial Networks (GANs) have been effective in natural image super-resolution tasks, they often struggle with histopathology due to overfitting and mode collapse. Traditional evaluation metrics fall short in assessing the complex characteristics of histopathology images, necessitating robust histology-specific evaluation methods. We introduce Histo-Diffusion, a novel diffusion-based method specially designed for generating and evaluating super-resolution images in digital pathology. It includes a restoration module for histopathology prior and a controllable diffusion module for generating high-quality images. We have curated two histopathology datasets and proposed a comprehensive evaluation strategy which incorporates both full-reference and no-reference metrics to thoroughly assess the quality of digital pathology images. Comparative analyses on multiple datasets with state-of-the-art methods reveal that Histo-Diffusion outperforms GANs. Our method offers a versatile solution for histopathology image super-resolution, capable of handling multi-resolution generation from varied input sizes, providing valuable support in diagnostic processes.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "We have submitted our paper to Medical Image Analysis and are currently awaiting feedback"
    },
    {
        "paper id": "2408.15089",
        "abstract url": "https://arxiv.org/abs/2408.15089",
        "title": "SiHGNN: Leveraging Properties of Semantic Graphs for Efficient HGNN Acceleration",
        "rating": "-4.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "medical"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Heterogeneous Graph Neural Networks (HGNNs) have expanded graph representation learning to heterogeneous graph fields. Recent studies have demonstrated their superior performance across various applications, including medical analysis and recommendation systems, often surpassing existing methods. However, GPUs often experience inefficiencies when executing HGNNs due to their unique and complex execution patterns. Compared to traditional Graph Neural Networks, these patterns further exacerbate irregularities in memory access. To tackle these challenges, recent studies have focused on developing domain-specific accelerators for HGNNs. Nonetheless, most of these efforts have concentrated on optimizing the datapath or scheduling data accesses, while largely overlooking the potential benefits that could be gained from leveraging the inherent properties of the semantic graph, such as its topology, layout, and generation. In this work, we focus on leveraging the properties of semantic graphs to enhance HGNN performance. First, we analyze the Semantic Graph Build (SGB) stage and identify significant opportunities for data reuse during semantic graph generation. Next, we uncover the phenomenon of buffer thrashing during the Graph Feature Processing (GFP) stage, revealing potential optimization opportunities in semantic graph layout. Furthermore, we propose a lightweight hardware accelerator frontend for HGNNs, called SiHGNN. This accelerator frontend incorporates a tree-based Semantic Graph Builder for efficient semantic graph generation and features a novel Graph Restructurer for optimizing semantic graph layouts. Experimental results show that SiHGNN enables the state-of-the-art HGNN accelerator to achieve an average performance improvement of 2.95$\\times$.",
        "subjects": [
            "cs.AR",
            "cs.LG"
        ],
        "comment": "12 pages, 18 figures. arXiv admin note: text overlap with arXiv:2404.04792"
    },
    {
        "paper id": "2408.15008",
        "abstract url": "https://arxiv.org/abs/2408.15008",
        "title": "AEROBULL: A Center-of-Mass Displacing Aerial Vehicle Enabling Efficient High-Force Interaction",
        "rating": "-5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "industrial"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In various industrial sectors, inspection and maintenance tasks using UAV (Unmanned Aerial Vehicle) require substantial force application to ensure effective adherence and stable contact, posing significant challenges to existing solutions. This paper addresses these industrial needs by introducing a novel lightweight aerial platform (3.12kg) designed to exert high pushing forces on non-horizontal surfaces. To increase maneuverability, the proposed platform incorporates tiltable rotors with 5-DoF (Degree of Freedom) actuation. Moreover, it has an innovative shifting-mass mechanism that dynamically adjusts the system's CoM (Center of Mass) during contact-based task execution. A compliant EE (End-Effector) is applied to ensure a smooth interaction with the work surface. We provide a detailed study of the UAV's overall system design, hardware integration of the developed physical prototype, and software architecture of the proposed control algorithm. Physical experiments were conducted to validate the control design and explore the force generation capability of the designed platform via a pushing task. With a total mass of 3.12kg, the UAV exerted a maximum pushing force of above 28N being almost equal to its gravity force. Furthermore, the experiments illustrated the benefits of having displaced CoM by benchmarking with a fixed CoM configuration.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15372",
        "abstract url": "https://arxiv.org/abs/2408.15372",
        "title": "AutoPatch: Automated Generation of Hotpatches for Real-Time Embedded Devices",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "medical"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Real-time embedded devices like medical or industrial devices are increasingly targeted by cyber-attacks. Prompt patching is crucial to mitigate the serious consequences of such attacks on these devices. Hotpatching is an approach to apply a patch to mission-critical embedded devices without rebooting them. However, existing hotpatching approaches require developers to manually write the hotpatch for target systems, which is time-consuming and error-prone. To address these issues, we propose AutoPatch, a new hotpatching technique that automatically generates functionally equivalent hotpatches via static analysis of the official patches. AutoPatch introduces a new software triggering approach that supports diverse embedded devices, and preserves the functionality of the official patch. In contrast to prior work, AutoPatch does not rely on hardware support for triggering patches, or on executing patches in specialized virtual machines. We implemented AutoPatch using the LLVM compiler, and evaluated its efficiency, effectiveness and generality using 62 real CVEs on four embedded devices with different specifications and architectures running popular RTOSes. We found that AutoPatch can fix more than 90% of CVEs, and resolve the vulnerability successfully. The results revealed an average total delay of less than 12.7 $\u03bcs$ for fixing the vulnerabilities, representing a performance improvement of 50% over RapidPatch, a state-of-the-art approach. Further, our memory overhead, on average, was slightly lower than theirs (23%). Finally, AutoPatch was able to generate hotpatches for all four devices without any modifications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "17 pages , 5 figures and accepted in ACM CCS conference"
    },
    {
        "paper id": "2408.15394",
        "abstract url": "https://arxiv.org/abs/2408.15394",
        "title": "Seamless 5G Automotive Connectivity with Integrated Satellite Terrestrial Networks in C-Band",
        "rating": "-5",
        "keywords": [
            [
                "3D"
            ],
            [
                "5G"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "This paper examines integrated satellite-terrestrial networks (ISTNs) in urban environments, where terrestrial networks (TNs) and non-terrestrial networks (NTNs) share the same frequency band in the C-band which is considered the promising band for both systems. The dynamic issues in ISTNs, arising from the movement of low Earth orbit satellites (LEOSats) and the mobility of users (UEs), are addressed. The goal is to maximize the sum rate by optimizing link selection for UEs over time. To tackle this challenge, an efficient iterative algorithm is developed. Simulations using a realistic 3D map provide valuable insights into the impact of urban environments on ISTNs and also demonstrates the effectiveness of the proposed algorithm.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15108",
        "abstract url": "https://arxiv.org/abs/2408.15108",
        "title": "Assembly Theory Reduced to Shannon Entropy and Rendered Redundant by Naive Statistical Algorithms",
        "rating": "-6",
        "keywords": [
            [
                "biology"
            ],
            [
                "grammar"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Previously, we formally proved that any implementation of the concept of `copy number' underlying Assembly Theory (AT) and its assembly index (Ai) was equivalent to Shannon Entropy and not fundamentally or methodologically different from algorithms like ZIP and PNG via an LZ grammar. We show that the weak empirical correlation between Ai and LZW, which the authors offered as a defence against the previously proven result that the assembly index calculation method is an LZ scheme, is based on a misleading experiment. When the experiment is conducted properly the asymptotic convergence to LZ compression and Shannon Entropy is evident, and aligns with the mathematical proof previously provided. This completes both the theoretical and empirical demonstrations that any variation of the copy-number concept underlying AT, which resorts to counting the number of repetitions to arrive at a measure for life, is equivalent to statistical compression and Shannon Entropy. We demonstrate that the authors' `we-are-better-because-we-are-worse argument' does not withstand basic scrutiny, and that their primary empirical results separating organic from inorganic compounds have not only been previously reported -- sans claims to unify physics and biology -- but are also driven solely by molecular length, not by any special feature of life captured by their assembly index. Finally, we show that Ai is a special subcase of our Block Decomposition Method introduced almost a decade earlier.",
        "subjects": [
            "cs.IT",
            "cs.CC"
        ],
        "comment": "12 figures, 50 pages"
    },
    {
        "paper id": "2408.14820",
        "abstract url": "https://arxiv.org/abs/2408.14820",
        "title": "The period of $x^h + x + 1$ over GF(2)",
        "rating": "-10",
        "keywords": [],
        "abstract": "The periods of polynomials can be used to characterize discrete structures such as algebraic error control codes and feedback shift registers. We study trinomial $x^h+x+1$ over GF(2), which has the maximum number of consecutive zero coefficients and leads to efficient implementation. Existing results typically deal with finite values of $h$ and rely on computer computation methods for finding the periods. In contrast, here we derive closed-form expressions for the periods of this trinomial for infinite sets of $h$ values.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14923",
        "abstract url": "https://arxiv.org/abs/2408.14923",
        "title": "Unraveling the Airalo Ecosystem",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, we have witnessed myriad flavours of Mobile Network Aggregators (MNAs) which exploit the coverage footprint of a handful of base operators to provide global mobile connectivity. Under the MNA model, emerging operators reap the benefits of network softwarization and virtualization, including eSIM technology or control/data-plane separation. This paper investigates an emergent MNA type - a thick MNA - that relies on multiple (core) base operators from different economies to provision eSIM profiles, while employing gateway functions to the public internet located outside the respective base operators' home country. Specifically, our work is the first to capture the intricacies of Airalo - a thick MNA that operates in 219 countries. Unlike other MNAs that our community scrutinized, we show that Airalo often decouples the geographical location of the public internet gateway from the native country of the base operator via IPX Hub Breakout (IHBO). To map Airalo's underlying infrastructure, we ran web-based measurements that 14 volunteers performed while traveling and using an Airalo eSIM on their personal devices. We further dive into Airalo's performance by running device-based measurements (speedtest, traceroute, video streaming, etc.) in 10 countries with rooted Android devices. Finally, we examine Airalo's pricing by monitoring its marketplace.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "25 pages, 20 figures"
    },
    {
        "paper id": "2408.14937",
        "abstract url": "https://arxiv.org/abs/2408.14937",
        "title": "From Chaos to Consistency: The Role of CSAF in Streamlining Security Advisories",
        "rating": "-10",
        "keywords": [],
        "abstract": "Security advisories have become an important part of vulnerability management. They can be used to gather and distribute valuable information about vulnerabilities. Although there is a predefined broad format for advisories, it is not really standardized. As a result, their content and form vary greatly depending on the vendor. Thus, it is cumbersome and resource-intensive for security analysts to extract the relevant information. The Common Security Advisory Format (CSAF) aims to bring security advisories into a standardized format which is intended to solve existing problems and to enable automated processing of the advisories. However, a new standard only makes sense if it can benefit users. Hence the questions arise: Do security advisories cause issues in their current state? Which of these issues is CSAF able to resolve? What is the current state of automation? To investigate these questions, we interviewed three security experts, and then conducted an online survey with 197 participants. The results show that problems exist and can often be traced back to confusing and inconsistent structures and formats. CSAF attempts to solve precisely these problems. However, our results show that CSAF is currently rarely used. Although users perceive automation as necessary to improve the processing of security advisories, many are at the same time skeptical. One of the main reasons is that systems are not yet designed for automation and a migration would require vast amounts of resources.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "To appear in the Proceedings of the 2024 European Symposium on Usable Security (EuroUSEC 2024)"
    },
    {
        "paper id": "2408.14948",
        "abstract url": "https://arxiv.org/abs/2408.14948",
        "title": "Decentralized Unlabeled Multi-agent Pathfinding Via Target And Priority Swapping (With Supplementary)",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study a challenging variant of the multi-agent pathfinding problem (MAPF), when a set of agents must reach a set of goal locations, but it does not matter which agent reaches a specific goal - Anonymous MAPF (AMAPF). Current optimal and suboptimal AMAPF solvers rely on the existence of a centralized controller which is in charge of both target assignment and pathfinding. We extend the state of the art and present the first AMAPF solver capable of solving the problem at hand in a fully decentralized fashion, when each agent makes decisions individually and relies only on the local communication with the others. The core of our method is a priority and target swapping procedure tailored to produce consistent goal assignments (i.e. making sure that no two agents are heading towards the same goal). Coupled with an established rule-based path planning, we end up with a TP-SWAP, an efficient and flexible approach to solve decentralized AMAPF. On the theoretical side, we prove that TP-SWAP is complete (i.e. TP-SWAP guarantees that each target will be reached by some agent). Empirically, we evaluate TP-SWAP across a wide range of setups and compare it to both centralized and decentralized baselines. Indeed, TP-SWAP outperforms the fully-decentralized competitor and can even outperform the semi-decentralized one (i.e. the one relying on the initial consistent goal assignment) in terms of flowtime (a widespread cost objective in MAPF",
        "subjects": [
            "cs.MA"
        ],
        "comment": "This is a pre-print of the paper accepted to ECAI 2024. Its main body is similar the camera-ready version of the conference paper. In addition this pre-print contains Supplementary Material incorporating extended empirical results and analysis. It contains 10 pages, 8 figures, 4 tables"
    },
    {
        "paper id": "2408.14949",
        "abstract url": "https://arxiv.org/abs/2408.14949",
        "title": "The Asymptotic Cost of Complexity",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a measure of learning efficiency for non-finite state spaces. We characterize the complexity of a learning problem by the metric entropy of its state space. We then describe how learning efficiency is determined by this measure of complexity. This is, then, applied to two models where agents learn high-dimensional states.",
        "subjects": [
            "econ.TH",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14969",
        "abstract url": "https://arxiv.org/abs/2408.14969",
        "title": "Secrecy Performance Analysis of RIS-Aided Fluid Antenna Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper examines the impact of emerging fluid antenna systems (FAS) on reconfigurable intelligent surface (RIS)-aided secure communications. Specifically, we consider a classic wiretap channel, where a fixed-antenna transmitter sends confidential information to an FAS-equipped legitimate user with the help of an RIS, while an FAS-equipped eavesdropper attempts to decode the message. To evaluate the proposed wireless scenario, we first introduce the cumulative distribution function (CDF) and probability density function (PDF) of the signal-to-noise ratio (SNR) at each node, using the central limit theorem and the Gaussian copula function. We then derive a compact analytical expression for the secrecy outage probability (SOP). Our numerical results reveal how the incorporation of FAS and RIS can significantly enhance the performance of secure communications.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14974",
        "abstract url": "https://arxiv.org/abs/2408.14974",
        "title": "Finding Convincing Views to Endorse a Claim",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent studies investigated the challenge of assessing the strength of a given claim extracted from a dataset, particularly the claim's potential of being misleading and cherry-picked. We focus on claims that compare answers to an aggregate query posed on a view that selects tuples. The strength of a claim amounts to the question of how likely it is that the view is carefully chosen to support the claim, whereas less careful choices would lead to contradictory claims. We embark on the study of the reverse task that offers a complementary angle in the critical assessment of data-based claims: given a claim, find useful supporting views. The goal of this task is twofold. On the one hand, we aim to assist users in finding significant evidence of phenomena of interest. On the other hand, we wish to provide them with machinery to criticize or counter given claims by extracting evidence of opposing statements. To be effective, the supporting sub-population should be significant and defined by a ``natural'' view. We discuss several measures of naturalness and propose ways of extracting the best views under each measure (and combinations thereof). The main challenge is the computational cost, as na\u00efve search is infeasible. We devise anytime algorithms that deploy two main steps: (1) a preliminary construction of a ranked list of attribute combinations that are assessed using fast-to-compute features, and (2) an efficient search for the actual views based on each attribute combination. We present a thorough experimental study that shows the effectiveness of our algorithms in terms of quality and execution cost. We also present a user study to assess the usefulness of the naturalness measures.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2408.14980",
        "abstract url": "https://arxiv.org/abs/2408.14980",
        "title": "Effective Anonymous Messaging: the Role of Altruism",
        "rating": "-10",
        "keywords": [],
        "abstract": "Anonymous messaging and payments have gained momentum recently due to their impact on individuals, society, and the digital landscape. Fuzzy Message Detection (FMD) is a privacy-preserving protocol where an untrusted server performs message anonymously filtering for its clients. To prevent the server from linking the sender and the receiver, the latter can set how much cover traffic they should download along with genuine messages. This could cause unwanted messages to appear on the user's end, thereby creating a need to balance one's bandwidth cost with the desired level of unlinkability. Previous work showed that FMD is not viable with selfish users. In this paper, we model and analyze FMD using the tools of empirical game theory and show that the system needs at least a few altruistic users to operate properly. Utilizing real-world communication datasets, we characterize the emerging equilibria, quantify the impact of different types and levels of altruism, and assess the efficiency of potential outcomes versus socially optimal allocations. Moreover, taking a mechanism design approach, we show how the betweenness centrality (BC) measure can be utilized to achieve the social optimum.",
        "subjects": [
            "cs.GT",
            "cs.NI"
        ],
        "comment": "Accepted at GameSec24"
    },
    {
        "paper id": "2408.14982",
        "abstract url": "https://arxiv.org/abs/2408.14982",
        "title": "Ultra-Low-Complexity, Non-Linear Processing for MU-MIMO Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Non-linear detection schemes can substantially improve the achievable throughput and connectivity capabilities of uplink MU-MIMO systems that employ linear detection. However, the complexity requirements of existing non-linear soft detectors that provide substantial gains compared to linear ones are at least an order of magnitude more complex, making their adoption challenging. In particular, joint soft information computation involves solving multiple vector minimization problems, each with a complexity that scales exponentially with the number of users. This work introduces a novel ultra-low-complexity, non-linear detection scheme that performs joint Detection and Approximate Reliability Estimation (DARE). For the first time, DARE can substantially improve the achievable throughput (e.g., 40%) with less than 2x the complexity of linear MMSE, making non-linear processing extremely practical. To enable this, DARE includes a novel procedure to approximate the reliability of the received bits based on the region of the received observable that can efficiently approach the accurately calculated soft detection performance. In addition, we show that DARE can achieve a better throughput than linear detection when using just half the base station antennas, resulting in substantial power savings (e.g., 500 W). Consequently, DARE is a very strong candidate for future power-efficient MU-MIMO developments, even in the case of software-based implementations, as in the case of emerging Open-RAN systems. Furthermore, DARE can achieve the throughput of the state-of-the-art non-linear detectors with complexity requirements that are orders of magnitude lower.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Accepted for IEEE PIMRC"
    },
    {
        "paper id": "2408.15009",
        "abstract url": "https://arxiv.org/abs/2408.15009",
        "title": "Novel Road-Aware Line-of-Sight Probability Model for Urban Air Mobility",
        "rating": "-10",
        "keywords": [],
        "abstract": "As urban air mobility (UAM) emerges as a transformative solution to urban transportation, the demand for robust communication frameworks capable of supporting high-density aerial traffic becomes increasingly critical. An essential area of communications improvement is reliably characterizing and minimizing interference on UAM aircraft from other aircraft and ground vehicles. To achieve this, reliable and accurate line-of-sight (LOS) models must be used. In this work, we highlight the limitations of a LOS probability model extensively used in the literature in accurately predicting interference caused by smart ground vehicles. Then, we introduce a novel probability of LOS model that improves interference prediction by incorporating the urban topography and the dynamic positioning of ground vehicles on streets. Our model's parameters are derived from extensive simulations and validated through real-world urban settings to ensure reliability and applicability.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15031",
        "abstract url": "https://arxiv.org/abs/2408.15031",
        "title": "Once and for all: how to compose modules -- The composition calculus",
        "rating": "-10",
        "keywords": [],
        "abstract": "Computability theory is traditionally conceived as the theoretical basis of informatics. Nevertheless, numerous proposals transcend computability theory, in particular by emphasizing interaction of modules, or components, parts, constituents, as a fundamental computing feature. In a technical framework, interaction requires composition of modules. Hence, a most abstract, comprehensive theory of modules and their composition is required. To this end, we suggest a minimal set of postulates to characterize systems in the digital world that consist of interacting modules. For such systems, we suggest a calculus with a simple, yet most general composition operator which exhibits important properties, in particular associativity. We claim that this composition calculus provides not just another conceptual, formal framework, but that essentially all settings of modules and their composition can be based on this calculus. This claim is supported by a rich body of theorems, properties, special classes of modules, and case studies.",
        "subjects": [
            "cs.SE",
            "cs.FL"
        ],
        "comment": "18 pages, 11 figures, author prepared version of final manuscript accepted at ISoLA 2024"
    },
    {
        "paper id": "2408.15042",
        "abstract url": "https://arxiv.org/abs/2408.15042",
        "title": "Essentials of Petri nets",
        "rating": "-10",
        "keywords": [],
        "abstract": "This contribution highlights some concepts and aspects of Petri nets that are frequently neglected, but that the authors consider important or interesting, or that Carl Adam Petri emphasized.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "19 pages, 26 figures, author prepared version of the talk given at the Sixth Advanced Course on Petri Nets, September 3-8, 2023, Toru\u0144, Poland"
    },
    {
        "paper id": "2408.15049",
        "abstract url": "https://arxiv.org/abs/2408.15049",
        "title": "Scalable Supervisory Architecture for Autonomous Race Cars",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, the number and importance of autonomous racing leagues, and consequently the number of studies on them, has been growing. The seamless integration between different series has gained attention due to the scene's diversity. However, the high cost of full scale racing makes it a more accessible development model, to research at smaller form factors and scale up the achieved results. This paper presents a scalable architecture designed for autonomous racing that emphasizes modularity, adaptability to diverse configurations, and the ability to supervise parallel execution of pipelines that allows the use of different dynamic strategies. The system showcased consistent racing performance across different environments, demonstrated through successful participation in two relevant competitions. The results confirm the architecture's scalability and versatility, providing a robust foundation for the development of competitive autonomous racing systems. The successful application in real-world scenarios validates its practical effectiveness and highlights its potential for future advancements in autonomous racing technology.",
        "subjects": [
            "cs.RO",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15068",
        "abstract url": "https://arxiv.org/abs/2408.15068",
        "title": "On Controlling Knockout Tournaments Without Perfect Information",
        "rating": "-10",
        "keywords": [],
        "abstract": "Over the last decade, extensive research has been conducted on the algorithmic aspects of designing single-elimination (SE) tournaments. Addressing natural questions of algorithmic tractability, we identify key properties of input instances that enable the tournament designer to efficiently schedule the tournament in a way that maximizes the chances of a preferred player winning. Much of the prior algorithmic work on this topic focuses on the perfect (complete and deterministic) information scenario, especially in the context of fixed-parameter algorithm design. Our contributions constitute the first fixed-parameter tractability results applicable to more general settings of SE tournament design with potential imperfect information.",
        "subjects": [
            "cs.DS",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15082",
        "abstract url": "https://arxiv.org/abs/2408.15082",
        "title": "Compact Pixelated Microstrip Forward Broadside Coupler Using Binary Particle Swarm Optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a compact microstrip forward broadside coupler (MFBC) with high coupling level is proposed in the frequency band of 3.5-3.8 GHz. The coupler is composed of two parallel pixelated transmission lines. To validate the designstrategy, the proposed MFBC is fabricated and measured. The measured results demonstrate a forward coupler with 3 dB coupling, and a compact size of 0.12 \u03bbg x 0.10\u03bbg. Binary Particle Swarm Optimization (BPSO) design methodology and flexibility of pixelation enable us to optimize the proposed MFBC with desired coupling level and operating frequency within a fixed dimension. Also, low sensitivity to misalignment between two coupled TLs makes the proposed coupler a good candidate for near-field Wireless Power Transfer (WPT) application and sensors.",
        "subjects": [
            "eess.SY",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15109",
        "abstract url": "https://arxiv.org/abs/2408.15109",
        "title": "Comments or Issues: Where to Document Technical Debt?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Self-Admitted Technical Debt (SATD) is a form of Technical Debt where developers document the debt using source code comments (SATD-C) or issues (SATD-I). However, it is still unclear the circumstances that drive developers to choose one or another. In this paper, we survey authors of both types of debts using a large-scale dataset containing 74K SATD-C and 20K SATD-I instances, extracted from 190 GitHub projects. As a result, we provide 13 guidelines to support developers to decide when to use comments or issues to report Technical Debt.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15140",
        "abstract url": "https://arxiv.org/abs/2408.15140",
        "title": "GEM: A GEneral Memristive transistor model",
        "rating": "-10",
        "keywords": [],
        "abstract": "Neuromorphic devices, with their distinct advantages in energy efficiency and parallel processing, are pivotal in advancing artificial intelligence applications. Among these devices, memristive transistors have attracted significant attention due to their superior symmetry, stability, and retention characteristics compared to two-terminal memristors. However, the lack of a robust model that accurately captures their complex electrical behavior has hindered further exploration of their potential. In this work, we present the GEneral Memristive transistor model (GEM), a comprehensive voltage-controlled model that addresses this gap. The GEM model incorporates a state-dependent update function, a voltage-controlled moving window function, and a nonlinear current output function, enabling precise representation of the electrical characteristics of memristive transistors. In experiments, the GEM model not only demonstrates a 300% improvement in modeling the memory behavior but also accurately captures the inherent nonlinearities and physical limits of these devices. This advancement significantly enhances the realistic simulation of memristive transistors, thereby facilitating further exploration and application development.",
        "subjects": [
            "physics.app-ph",
            "eess.SP"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2408.15170",
        "abstract url": "https://arxiv.org/abs/2408.15170",
        "title": "Applications in CityLearn Gym Environment for Multi-Objective Control Benchmarking in Grid-Interactive Buildings and Districts",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is challenging to coordinate multiple distributed energy resources in a single or multiple buildings to ensure efficient and flexible operation. Advanced control algorithms such as model predictive control and reinforcement learning control provide solutions to this problem by effectively managing a distribution of distributed energy resource control tasks while adapting to unique building characteristics, and cooperating towards improving multi-objective key performance indicator. Yet, a research gap for advanced control adoption is the ability to benchmark algorithm performance. CityLearn addresses this gap an open-source Gym environment for the easy implementation and benchmarking of simple rule-based control and advanced algorithms that has an advantage of modeling simplicity, multi-agent control, district-level objectives, and control resiliency assessment. Here we demonstrate the functionalities of CityLearn using 17 different building control problems that have varying complexity with respect to the number of controllable distributed energy resources in buildings, the simplicity of the control algorithm, the control objective, and district size.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "To be published in IBPSA-USA SimBuild 2024 Conference"
    },
    {
        "paper id": "2408.15180",
        "abstract url": "https://arxiv.org/abs/2408.15180",
        "title": "Formalizing Mason-Stothers Theorem and its Corollaries in Lean 4",
        "rating": "-10",
        "keywords": [],
        "abstract": "The ABC conjecture implies many conjectures and theorems in number theory, including the celebrated Fermat's Last Theorem. Mason-Stothers Theorem is a function field analogue of the ABC conjecture that admits a much more elementary proof with many interesting consequences, including a polynomial version of Fermat's Last Theorem. While years of dedicated effort are expected for a full formalization of Fermat's Last Theorem, the simple proof of Mason-Stothers Theorem and its corollaries calls for an immediate formalization. We formalize an elementary proof of by Snyder in Lean 4, and also formalize many consequences of Mason-Stothers, including (i) non-solvability of Fermat-Cartan equations in polynomials, (ii) non-parametrizability of a certain elliptic curve, and (iii) Davenport's Theorem. We compare our work to existing formalizations of Mason-Stothers by Eberl in Isabelle and Wagemaker in Lean 3 respectively. Our formalization is based on the mathlib4 library of Lean 4, and is currently being ported back to mathlib4.",
        "subjects": [
            "cs.LO",
            "math.RA"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15193",
        "abstract url": "https://arxiv.org/abs/2408.15193",
        "title": "Data-driven distributionally robust MPC for systems with multiplicative noise: A semi-infinite semi-definite programming approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "This article introduces a novel distributionally robust model predictive control (DRMPC) algorithm for a specific class of controlled dynamical systems where the disturbance multiplies the state and control variables. These classes of systems arise in mathematical finance, where the paradigm of distributionally robust optimization (DRO) fits perfectly, and this serves as the primary motivation for this work. We recast the optimal control problem (OCP) as a semi-definite program with an infinite number of constraints, making the ensuing optimization problem a \\emph{semi-infinite semi-definite program} (SI-SDP). To numerically solve the SI-SDP, we advance an approach for solving convex semi-infinite programs (SIPs) to SI-SDPs and, subsequently, solve the DRMPC problem. A numerical example is provided to show the effectiveness of the algorithm.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "To appear in the proceedings of Mathematical Theory of Networks and Systems (MTNS) 2024"
    },
    {
        "paper id": "2408.15203",
        "abstract url": "https://arxiv.org/abs/2408.15203",
        "title": "On the Encoding Process in Decentralized Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation. The system involves K source processors, each holding some data modeled as a vector over a finite field. The remaining R processors are sinks, and each of which requires a linear combination of all data vectors. These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code. To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds. In every round, every processor sends and receives one message through each one of its p ports. Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data. We propose a framework that addresses the decentralized encoding problem on two levels. On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code. On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems. Our solutions are based on a newly-defined collective communication operation we call all-to-all encode.",
        "subjects": [
            "cs.DC",
            "cs.IT"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2205.05183"
    },
    {
        "paper id": "2408.15219",
        "abstract url": "https://arxiv.org/abs/2408.15219",
        "title": "FRAMER/Miu: Tagged Pointer-based Capability and Fundamental Cost of Memory Safety & Coherence (Position Paper)",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ensuring system correctness, such as memory safety, can eliminate security vulnerabilities that attackers could exploit in the first place. However, high and unpredictable performance degradation remains a primary challenge. Recognizing that it is extremely difficult to achieve complete system correctness for production deployment, researchers make trade-offs between performance, detection coverage, interoperability, precision, and detection timing. This research strikes a balance between comprehensive system protection and the costs required to obtain it, identifies the desirable roles of software and hardware, and presents a tagged pointer-based capability system as a stand-alone software solution and a prototype for future hardware design. This paper presents follow-up plans for the FRAMER/Miu generic framework to achieve these goals.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2408.15302",
        "abstract url": "https://arxiv.org/abs/2408.15302",
        "title": "Corrigendum to: A Systematic Study of DDR4 DRAM Faults in the Field",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper is a corrigendum to the paper by Beigi et al. published at HPCA 2023 https://doi.org/10.1109/HPCA56546.2023.10071066. The HPCA paper presented a detailed field data analysis of faults observed at scale in DDR4 DRAM from two different memory vendors. This analysis included a breakdown of fault patterns or modes. Upon further study of the data, we found a bug in how we decoded errors based on the logged row-bank-column address. Specifically, we found that some errors that occurred in one column were mis-interpreted as occurring in two non-adjacent columns. As a result of this, some single-bit faults were misclassified as partial-row faults (i.e., two-bit faults). Similarly, some single-column faults were misclassified as two-column faults. The result of these misclassification errors is that the proportion of single-bit faults is higher than reported in the paper, with a commensurate reduction in the fraction of certain types of multi-bit faults. These misclassifications also slightly change the Failure In Time (FIT) per DRAM device values presented in the original paper. In this corrigendum, we provide an updated version of the relevant tables and figures and point out the corresponding page numbers and references in the original paper that they replace.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15349",
        "abstract url": "https://arxiv.org/abs/2408.15349",
        "title": "This is the Way: Mitigating the Roll of an Autonomous Uncrewed Surface Vessel in Wavy Conditions Using Model Predictive Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "Though larger vessels may be well-equipped to deal with wavy conditions, smaller vessels are often more susceptible to disturbances. This paper explores the development of a nonlinear model predictive control (NMPC) system for Uncrewed Surface Vessels (USVs) in wavy conditions to minimize average roll. The NMPC is based on a prediction method that uses information about the vessel's dynamics and an assumed wave model. This method is able to mitigate the roll of an under-actuated USV in a variety of conditions by adjusting the weights of the cost function. The results show a reduction of 39% of average roll with a tuned controller in conditions with 1.75-metre sinusoidal waves. A general and intuitive tuning strategy is established. This preliminary work is a proof of concept which sets the stage for the leveraging of wave prediction methodologies to perform planning and control in real time for USVs in real-world scenarios and field trials.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "6 pages, 10 figures. To appear in Proceedings of the 2024 IEEE/RSJ International Conference on Robots and Systems (IROS), October 2024"
    },
    {
        "paper id": "2408.15377",
        "abstract url": "https://arxiv.org/abs/2408.15377",
        "title": "On Approximability of Satisfiable k-CSPs: V",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a framework of algorithm vs. hardness for all Max-CSPs and demonstrate it for a large class of predicates. This framework extends the work of Raghavendra [STOC, 2008], who showed a similar result for almost satisfiable Max-CSPs. Our framework is based on a new hybrid approximation algorithm, which uses a combination of the Gaussian elimination technique (i.e., solving a system of linear equations over an Abelian group) and the semidefinite programming relaxation. We complement our algorithm with a matching dictator vs. quasirandom test that has perfect completeness. The analysis of our dictator vs. quasirandom test is based on a novel invariance principle, which we call the mixed invariance principle. Our mixed invariance principle is an extension of the invariance principle of Mossel, O'Donnell and Oleszkiewicz [Annals of Mathematics, 2010] which plays a crucial role in Raghavendra's work. The mixed invariance principle allows one to relate 3-wise correlations over discrete probability spaces with expectations over spaces that are a mixture of Guassian spaces and Abelian groups, and may be of independent interest.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "85 pages"
    },
    {
        "paper id": "2408.15384",
        "abstract url": "https://arxiv.org/abs/2408.15384",
        "title": "Analysis of the Performance of the Matrix Multiplication Algorithm on the Cirrus Supercomputer",
        "rating": "-10",
        "keywords": [],
        "abstract": "Matrix multiplication is integral to various scientific and engineering disciplines, including machine learning, image processing, and gaming. With the increasing data volumes in areas like machine learning, the demand for efficient parallel processing of large matrices has grown significantly.This study explores the performance of both serial and parallel matrix multiplication on the Cirrus supercomputer at the University of Edinburgh. The results demonstrate the scalability and efficiency of these methods, providing insights for optimizing matrixmultiplication in real-world applications.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "9 papers, 9 figures"
    },
    {
        "paper id": "2408.15390",
        "abstract url": "https://arxiv.org/abs/2408.15390",
        "title": "Avoiding abelian and additive powers in rich words",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper concerns the avoidability of abelian and additive powers in infinite rich words. In particular, we construct an infinite additive $5$-power-free rich word over $\\{0,1\\}$ and an infinite additive $4$-power-free rich word over $\\{0, 1, 2\\}$. The alphabet sizes are as small as possible in both cases, even for abelian powers.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.FL"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2408.15401",
        "abstract url": "https://arxiv.org/abs/2408.15401",
        "title": "On Mobility Equity and the Promise of Emerging Transportation Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces a mobility equity metric (MEM) for evaluating fairness and accessibility in multi-modal intelligent transportation systems. The MEM simultaneously accounts for service accessibility and transportation costs across different modes of transportation and social demographics. We provide a data-driven validation of the proposed MEM to characterize the impact of various parameters in the metric across cities in the U.S. We subsequently develop a routing framework that aims to optimize MEM within a transportation network containing both public transit and private vehicles. Within this framework, a system planner provides routing suggestions to vehicles across all modes of transportation to maximize MEM. We evaluate our approach through numerical simulations, analyzing the impact of travel demands and compliance of private vehicles. This work provides insights into designing transportation systems that are not only efficient but also equitable, ensuring fair access to essential services across diverse populations.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "14 pages, 15 figures"
    },
    {
        "paper id": "2408.15411",
        "abstract url": "https://arxiv.org/abs/2408.15411",
        "title": "AUTOGENICS: Automated Generation of Context-Aware Inline Comments for Code Snippets on Programming Q&A Sites Using LLM",
        "rating": "-10",
        "keywords": [],
        "abstract": "Inline comments in the source code facilitate easy comprehension, reusability, and enhanced readability. However, code snippets in answers on Q&A sites like Stack Overflow (SO) often lack comments because answerers volunteer their time and often skip comments or explanations due to time constraints. Existing studies show that these online code examples are difficult to read and understand, making it difficult for developers (especially novices) to use them correctly and leading to misuse. Given these challenges, we introduced AUTOGENICS, a tool designed to integrate with SO to generate effective inline comments for code snippets in SO answers exploiting large language models (LLMs). Our contributions are threefold. First, we randomly select 400 answer code snippets from SO and generate inline comments for them using LLMs. We then manually evaluate these comments' effectiveness using four key metrics: accuracy, adequacy, conciseness, and usefulness. Overall, LLMs demonstrate promising effectiveness in generating inline comments for SO answer code snippets. Second, we surveyed 14 active SO users to perceive the effectiveness of these inline comments. The survey results are consistent with our previous manual evaluation. However, according to our evaluation, LLMs-generated comments are less effective for shorter code snippets and sometimes produce noisy comments. Third, to address the gaps, we introduced AUTOGENICS, which extracts additional context from question texts and generates context-aware inline comments. It also optimizes comments by removing noise (e.g., comments in import statements and variable declarations). We evaluate the effectiveness of AUTOGENICS-generated comments using the same four metrics that outperform those of standard LLMs. AUTOGENICS might (a) enhance code comprehension, (b) save time, and improve developers' ability to learn and reuse code more accurately.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted for presentation in the research track at the IEEE International Conference on Source Code Analysis & Manipulation (SCAM 2025)"
    },
    {
        "paper id": "2408.15415",
        "abstract url": "https://arxiv.org/abs/2408.15415",
        "title": "Hybrid Plant Models Call for a Different Plant Modelling Paradigm and a New Generation of Software (Heresy in the land of moles, fractions, & rigorous physical properties)",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper is an invitation to the process systems engineering community to change the paradigm for process plants. The goal is to achieve much easier convergence while retaining accuracy on par with the rigorous models. Accurate plant models of existing plants can be linear or much less nonlinear if they are based on mass component flows and stream properties per unit mass properties instead of molar flows and mole fractions. Accurate stream properties per unit mass can be calculated at stream specific conditions by linear approximations which in many instances eliminates mole fraction-based flash calculations. Hybrid data-driven node models fit naturally in this paradigm, since they used measured data, which is either in mass or in volumetric units, but never in moles. Instantiation of models at all levels of abstraction (planning, scheduling, optimization, and control models) from the same plant topology representation will ensure inheritance of solutions from mass-only to mass-and-energy to mass-and-energy-and-stream-properties, thereby ensuring consistency of solutions between these models. None of the existing software provides inheritance between different levels of plant abstraction (i.e. inheritance between models for different business applications) or different levels of abstractions per plant sections or per time periods, which motivates this exposition.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15435",
        "abstract url": "https://arxiv.org/abs/2408.15435",
        "title": "Globally Optimal Movable Antenna-Enhanced multi-user Communication: Discrete Antenna Positioning, Motion Power Consumption, and Imperfect CSI",
        "rating": "-10",
        "keywords": [],
        "abstract": "Movable antennas (MAs) represent a promising paradigm to enhance the spatial degrees of freedom of conventional multi-antenna systems by dynamically adapting the positions of antenna elements within a designated transmit area. In particular, by employing electro-mechanical MA drivers, the positions of the MA elements can be adjusted to shape a favorable spatial correlation for improving system performance. Although preliminary research has explored beamforming designs for MA systems, the intricacies of the power consumption and the precise positioning of MA elements are not well understood. Moreover, the assumption of perfect CSI adopted in the literature is impractical due to the significant pilot overhead and the extensive time to acquire perfect CSI. To address these challenges, we model the motion of MA elements through discrete steps and quantify the associated power consumption as a function of these movements. Furthermore, by leveraging the properties of the MA channel model, we introduce a novel CSI error model tailored for MA systems that facilitates robust resource allocation design. In particular, we optimize the beamforming and the MA positions at the BS to minimize the total BS power consumption, encompassing both radiated and MA motion power while guaranteeing a minimum required SINR for each user. To this end, novel algorithms exploiting the branch and bound (BnB) method are developed to obtain the optimal solution for perfect and imperfect CSI. Moreover, to support practical implementation, we propose low-complexity algorithms with guaranteed convergence by leveraging successive convex approximation (SCA). Our numerical results validate the optimality of the proposed BnB-based algorithms. Furthermore, we unveil that both proposed SCA-based algorithms approach the optimal performance within a few iterations, thus highlighting their practical advantages.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15445",
        "abstract url": "https://arxiv.org/abs/2408.15445",
        "title": "Towards cloud-native scientific workflow management",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cloud-native is an approach to building and running scalable applications in modern cloud infrastructures, with the Kubernetes container orchestration platform being often considered as a fundamental cloud-native building block. In this paper, we evaluate alternative execution models for scientific workflows in Kubernetes. We compare the simplest job-based model, its variant with task clustering, and finally we propose a cloud-native model based on microservices comprising auto-scalable worker-pools. We implement the proposed models in the HyperFlow workflow management system, and evaluate them using a large Montage workflow on a Kubernetes cluster. The results indicate that the proposed cloud-native worker-pools execution model achieves best performance in terms of average cluster utilization, resulting in a nearly 20\\% improvement of the workflow makespan compared to the best-performing job-based model. However, better performance comes at the cost of significantly higher complexity of the implementation and maintenance. We believe that our experiments provide a valuable insight into the performance, advantages and disadvantages of alternative cloud-native execution models for scientific workflows.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15456",
        "abstract url": "https://arxiv.org/abs/2408.15456",
        "title": "Convergence Analysis of Overparametrized LQR Formulations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Motivated by the growing use of Artificial Intelligence (AI) tools in control design, this paper takes the first steps towards bridging the gap between results from Direct Gradient methods for the Linear Quadratic Regulator (LQR), and neural networks. More specifically, it looks into the case where one wants to find a Linear Feed-Forward Neural Network (LFFNN) feedback that minimizes a LQR cost. This paper starts by computing the gradient formulas for the parameters of each layer, which are used to derive a key conservation law of the system. This conservation law is then leveraged to prove boundedness and global convergence of solutions to critical points, and invariance of the set of stabilizing networks under the training dynamics. This is followed by an analysis of the case where the LFFNN has a single hidden layer. For this case, the paper proves that the training converges not only to critical points but to the optimal feedback control law for all but a set of measure-zero of the initializations. These theoretical results are followed by an extensive analysis of a simple version of the problem (the ``vector case''), proving the theoretical properties of accelerated convergence and robustness for this simpler example. Finally, the paper presents numerical evidence of faster convergence of the training of general LFFNNs when compared to traditional direct gradient methods, showing that the acceleration of the solution is observable even when the gradient is not explicitly computed but estimated from evaluations of the cost function.",
        "subjects": [
            "eess.SY",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15475",
        "abstract url": "https://arxiv.org/abs/2408.15475",
        "title": "Verifying Solutions to Semantics-Guided Synthesis Problems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Semantics-Guided Synthesis (SemGuS) provides a framework to specify synthesis problems in a solver-agnostic and domain-agnostic way, by allowing a user to provide both the syntax and semantics of the language in which the desired program should be synthesized. Because synthesis and verification are closely intertwined, the SemGuS framework raises the problem of how to verify programs in a solver and domain-agnostic way. We prove that the problem of verifying whether a program is a valid solution to a SemGuS problem can be reduced to proving validity of a query in the `CLP calculus, a fixed-point logic that generalizes Constrained Horn Clauses and co-Constrained Horn Clauses. Our encoding into `CLP allows us to further classify the SemGuS verification problems into ones that are reducible to validity of (i) first-order-logic formulas, (ii) Constrained Horn Clauses, (iii) co-Constrained Horn Clauses, and (iv) `CLP queries. Furthermore, our encoding shines light on some limitations of the SemGuS framework, such as its inability to model nondeterminism and reactive synthesis. We thus propose a modification to SemGuS that makes it more expressive, and for which verifying solutions is exactly equivalent to proving validity of a query in the `CLP calculus. Our implementation of SemGuS verifiers based on the above encoding can verify instances that were not even encodable in previous work. Furthermore, we use our SemGuS verifiers within an enumeration-based SemGuS solver to correctly synthesize solutions to SemGuS problems that no previous SemGuS synthesizer could solve.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15481",
        "abstract url": "https://arxiv.org/abs/2408.15481",
        "title": "Joint Offloading and Beamforming Design in Integrating Sensing, Communication, and Computing Systems: A Distributed Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "When applying integrated sensing and communications (ISAC) in future mobile networks, many sensing tasks have low latency requirements, preferably being implemented at terminals. However, terminals often have limited computing capabilities and energy supply. In this paper, we investigate the effectiveness of leveraging the advanced computing capabilities of mobile edge computing (MEC) servers and the cloud server to address the sensing tasks of ISAC terminals. Specifically, we propose a novel three-tier integrated sensing, communication, and computing (ISCC) framework composed of one cloud server, multiple MEC servers, and multiple terminals, where the terminals can optionally offload sensing data to the MEC server or the cloud server. The offload message is sent via the ISAC waveform, whose echo is used for sensing. We jointly optimize the computation offloading and beamforming strategies to minimize the average execution latency while satisfying sensing requirements. In particular, we propose a low-complexity distributed algorithm to solve the problem. Firstly, we use the alternating direction method of multipliers (ADMM) and derive the closed-form solution for offloading decision variables. Subsequently, we convert the beamforming optimization sub-problem into a weighted minimum mean-square error (WMMSE) problem and propose a fractional programming based algorithm. Numerical results demonstrate that the proposed ISCC framework and distributed algorithm significantly reduce the execution latency and the energy consumption of sensing tasks at a lower computational complexity compared to existing schemes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "15 pages, 12 figures, submitted to IEEE journals for possible publication"
    },
    {
        "paper id": "2408.15485",
        "abstract url": "https://arxiv.org/abs/2408.15485",
        "title": "Software-defined Programmable Metamaterial Lens System for Dynamic Wireless Power Transfer Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "A software-defined 2-bit Programmable Transmit Metamaterial (PTM) array surface with beam steering capabilities is proposed for indoor dynamic Wireless Power Transfer (DWPT) applications. The novel metamaterial unit cell structure is designed based on transmission phase, amplitude, and electric field response to model DWPT using PTM. Theoretical analysis of the electric field (e-field), coupling effect, and current distribution at the metamaterial interface enhances the intelligence and reconfigurability of the PTM lens. The modeled 2-bit 6x6 array PTM is designed to operate at a frequency of 4 GHz. The reconfigurable architecture comprises a fixed system with a single-layer PTM lens capable of 60\u00b0 beam scanning. The PTM lens, along with a distribution board, is fabricated and experimentally tested. The results between simulation and measurements are in good agreement. The system enables dynamic optimisation of the beam pattern to track the positions of mobile users with minimal software-hardware complexity. This novel work presents a low-cost experiment achieving an average 90.7% beamforming accuracy throughout the analytical and measurement processes of DWPT for movable users, utilizing a programmable transmit metamaterial array.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2408.15486",
        "abstract url": "https://arxiv.org/abs/2408.15486",
        "title": "Compact Multi-Service Antenna for Sensing and Communication Using Reconfigurable Complementary Spiral Resonator",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a compact multi-service antenna (MSA) is presented for sensing and communication using a reconfigurable complementary spiral resonator. A three turns complementary spiral resonator (3-CSR) is inserted in the ground plane of a modified patch antenna to create a miniaturized structure. Two Positive-Intrinsic-Negative (PIN) diodes (D1, D2) are also integrated with the 3-CSR to achieve frequency reconfiguration. The proposed structure operates in three different modes i.e., dual-band joint communication and sensing antenna (JCASA), dual-band antenna, and single-band antenna. The required mode can be selected by changing the state of the PIN diodes. In mode-1, the first band (0.95-0.97 GHz) of the antenna is dedicated to sensing by using frequency domain reflectometry (FDR), while the second band (1.53-1.56 GHz) is allocated to communication. The sensing ability of the proposed structure is utilized to measure soil moisture using FDR. Based on the frequency shift, permittivity of the soil is observed to measure soil moisture. In mode-2 and mode-3, the structure operates as a standard dual and single band antenna, respectively, with a maximum gain of 1.5 dBi at 1.55 GHz. The proposed planar structure, with its simple geometry and a high sensitivity of 1.7%, is a suitable candidate for precision farming. The proposed structure is versatile and capable of being utilized as a single or dual-band antenna and also measuring permittivity of materials within the range of 1-20. Hence, it is adaptable to a range of applications.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    }
]