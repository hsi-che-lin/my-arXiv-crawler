[
    {
        "paper id": "2409.00397",
        "abstract url": "https://arxiv.org/abs/2409.00397",
        "title": "COSMo: CLIP Talks on Open-Set Multi-Target Domain Adaptation",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-Target Domain Adaptation (MTDA) entails learning domain-invariant information from a single source domain and applying it to multiple unlabeled target domains. Yet, existing MTDA methods predominantly focus on addressing domain shifts within visual features, often overlooking semantic features and struggling to handle unknown classes, resulting in what is known as Open-Set (OS) MTDA. While large-scale vision-language foundation models like CLIP show promise, their potential for MTDA remains largely unexplored. This paper introduces COSMo, a novel method that learns domain-agnostic prompts through source domain-guided prompt learning to tackle the MTDA problem in the prompt space. By leveraging a domain-specific bias network and separate prompts for known and unknown classes, COSMo effectively adapts across domain and class shifts. To the best of our knowledge, COSMo is the first method to address Open-Set Multi-Target DA (OSMTDA), offering a more realistic representation of real-world scenarios and addressing the challenges of both open-set and multi-target DA. COSMo demonstrates an average improvement of $5.1\\%$ across three challenging datasets: Mini-DomainNet, Office-31, and Office-Home, compared to other related DA methods adapted to operate within the OSMTDA setting. Code is available at: https://github.com/munish30monga/COSMo",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in BMVC 2024"
    },
    {
        "paper id": "2409.00486",
        "abstract url": "https://arxiv.org/abs/2409.00486",
        "title": "Multi-scale Multi-instance Visual Sound Localization and Segmentation",
        "rating": "2",
        "keywords": [
            [
                "audio-visual"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Visual sound localization is a typical and challenging problem that predicts the location of objects corresponding to the sound source in a video. Previous methods mainly used the audio-visual association between global audio and one-scale visual features to localize sounding objects in each image. Despite their promising performance, they omitted multi-scale visual features of the corresponding image, and they cannot learn discriminative regions compared to ground truths. To address this issue, we propose a novel multi-scale multi-instance visual sound localization framework, namely M2VSL, that can directly learn multi-scale semantic features associated with sound sources from the input image to localize sounding objects. Specifically, our M2VSL leverages learnable multi-scale visual features to align audio-visual representations at multi-level locations of the corresponding image. We also introduce a novel multi-scale multi-instance transformer to dynamically aggregate multi-scale cross-modal representations for visual sound localization. We conduct extensive experiments on VGGSound-Instruments, VGG-Sound Sources, and AVSBench benchmarks. The results demonstrate that the proposed M2VSL can achieve state-of-the-art performance on sounding object localization and segmentation.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00509",
        "abstract url": "https://arxiv.org/abs/2409.00509",
        "title": "LongRecipe: Recipe for Efficient Long Context Generalization in Large Languge Models",
        "rating": "2",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) face significant challenges in handling long-context tasks because of their limited effective context window size during pretraining, which restricts their ability to generalize over extended sequences. Meanwhile, extending the context window in LLMs through post-pretraining is highly resource-intensive. To address this, we introduce **LongRecipe**, an efficient training strategy for extending the context window of LLMs, including impactful token analysis, position index transformation, and training optimization strategies. It simulates long-sequence inputs while maintaining training efficiency and significantly improves the model's understanding of long-range dependencies. Experiments on three types of LLMs show that LongRecipe can utilize long sequences while requiring only 30% of the target context window size, and reduces computational training resource over 85% compared to full sequence training. Furthermore, LongRecipe also preserves the original LLM's capabilities in general tasks. Ultimately, *we can extend the effective context window of open-source LLMs from 8k to 128k, achieving performance close to GPT-4 with just one day of dedicated training using a single GPU with 80G memory.* Our code is released at the [link](https://github.com/zhiyuanhubj/LongRecipe).",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Wokr in Progress"
    },
    {
        "paper id": "2409.00551",
        "abstract url": "https://arxiv.org/abs/2409.00551",
        "title": "Testing and Evaluation of Large Language Models: Correctness, Non-Toxicity, and Fairness",
        "rating": "2",
        "keywords": [
            [
                "social bias"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs), such as ChatGPT, have rapidly penetrated into people's work and daily lives over the past few years, due to their extraordinary conversational skills and intelligence. ChatGPT has become the fastest-growing software in terms of user numbers in human history and become an important foundational model for the next generation of artificial intelligence applications. However, the generations of LLMs are not entirely reliable, often producing content with factual errors, biases, and toxicity. Given their vast number of users and wide range of application scenarios, these unreliable responses can lead to many serious negative impacts. This thesis introduces the exploratory works in the field of language model reliability during the PhD study, focusing on the correctness, non-toxicity, and fairness of LLMs from both software testing and natural language processing perspectives. First, to measure the correctness of LLMs, we introduce two testing frameworks, FactChecker and LogicAsker, to evaluate factual knowledge and logical reasoning accuracy, respectively. Second, for the non-toxicity of LLMs, we introduce two works for red-teaming LLMs. Third, to evaluate the fairness of LLMs, we introduce two evaluation frameworks, BiasAsker and XCulturalBench, to measure the social bias and cultural bias of LLMs, respectively.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SE"
        ],
        "comment": "PhD Thesis"
    },
    {
        "paper id": "2409.00592",
        "abstract url": "https://arxiv.org/abs/2409.00592",
        "title": "Hyper-Compression: Model Compression via Hyperfunction",
        "rating": "1.5",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The rapid growth of large models' size has far outpaced that of GPU memory. To bridge this gap, inspired by the succinct relationship between genotype and phenotype, we turn the model compression problem into the issue of parameter representation to propose the so-called hyper-compression. The hyper-compression uses a hyperfunction to represent the parameters of the target network, and notably, here the hyperfunction is designed per ergodic theory that relates to a problem: if a low-dimensional dynamic system can fill the high-dimensional space eventually. Empirically, the proposed hyper-compression enjoys the following merits: 1) \\textbf{P}referable compression ratio; 2) \\textbf{N}o post-hoc retraining; 3) \\textbf{A}ffordable inference time; and 4) \\textbf{S}hort compression time. It compresses LLaMA2-7B in an hour and achieves close-to-int4-quantization performance, without retraining and with a performance drop of less than 1\\%. Our work has the potential to invigorate the field of model compression, towards a harmony between the scaling law and the stagnation of hardware upgradation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00352",
        "abstract url": "https://arxiv.org/abs/2409.00352",
        "title": "Does Alignment Tuning Really Break LLMs' Internal Confidence?",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have shown remarkable progress, but their real-world application necessitates reliable calibration. This study conducts a comprehensive analysis of calibration degradation of LLMs across four dimensions: models, calibration metrics, tasks, and confidence extraction methods. Initial analysis showed that the relationship between alignment and calibration is not always a trade-off, but under stricter analysis conditions, we found the alignment process consistently harms calibration. This highlights the need for (1) a careful approach when measuring model confidences and calibration errors and (2) future research into algorithms that can help LLMs to achieve both instruction-following and calibration without sacrificing either.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00355",
        "abstract url": "https://arxiv.org/abs/2409.00355",
        "title": "YA-TA: Towards Personalized Question-Answering Teaching Assistants using Instructor-Student Dual Retrieval-augmented Knowledge Fusion",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Engagement between instructors and students plays a crucial role in enhancing students'academic performance. However, instructors often struggle to provide timely and personalized support in large classes. To address this challenge, we propose a novel Virtual Teaching Assistant (VTA) named YA-TA, designed to offer responses to students that are grounded in lectures and are easy to understand. To facilitate YA-TA, we introduce the Dual Retrieval-augmented Knowledge Fusion (DRAKE) framework, which incorporates dual retrieval of instructor and student knowledge and knowledge fusion for tailored response generation. Experiments conducted in real-world classroom settings demonstrate that the DRAKE framework excels in aligning responses with knowledge retrieved from both instructor and student sides. Furthermore, we offer additional extensions of YA-TA, such as a Q&A board and self-practice tools to enhance the overall learning experience. Our video is publicly available.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2409.00356",
        "abstract url": "https://arxiv.org/abs/2409.00356",
        "title": "Contrastive Augmentation: An Unsupervised Learning Approach for Keyword Spotting in Speech Technology",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper addresses the persistent challenge in Keyword Spotting (KWS), a fundamental component in speech technology, regarding the acquisition of substantial labeled data for training. Given the difficulty in obtaining large quantities of positive samples and the laborious process of collecting new target samples when the keyword changes, we introduce a novel approach combining unsupervised contrastive learning and a unique augmentation-based technique. Our method allows the neural network to train on unlabeled data sets, potentially improving performance in downstream tasks with limited labeled data sets. We also propose that similar high-level feature representations should be employed for speech utterances with the same keyword despite variations in speed or volume. To achieve this, we present a speech augmentation-based unsupervised learning method that utilizes the similarity between the bottleneck layer feature and the audio reconstructing information for auxiliary training. Furthermore, we propose a compressed convolutional architecture to address potential redundancy and non-informative information in KWS tasks, enabling the model to simultaneously learn local features and focus on long-term information. This method achieves strong performance on the Google Speech Commands V2 Dataset. Inspired by recent advancements in sign spotting and spoken term detection, our method underlines the potential of our contrastive learning approach in KWS and the advantages of Query-by-Example Spoken Term Detection strategies. The presented CAB-KWS provide new perspectives in the field of KWS, demonstrating effective ways to reduce data collection efforts and increase the system's robustness.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "This paper has been accepted by the ICPR2024"
    },
    {
        "paper id": "2409.00358",
        "abstract url": "https://arxiv.org/abs/2409.00358",
        "title": "Predicting the Target Word of Game-playing Conversations using a Low-Rank Dialect Adapter for Decoder Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Dialect adapters that improve the performance of LLMs for NLU tasks on certain sociolects/dialects/national varieties ('dialects' for the sake of brevity) have been reported for encoder models. In this paper, we extend the idea of dialect adapters to decoder models in our architecture called LoRDD. Using MD-3, a publicly available dataset of word game-playing conversations between dialectal speakers, our task is Target Word Prediction (TWP) from a masked conversation. LoRDD combines task adapters and dialect adapters where the latter employ contrastive learning on pseudo-parallel conversations from MD-3. Our results for en-IN conversations on two models (Mistral and Gemma) show that LoRDD outperforms four baselines on TWP, while bridging the performance gap with en-US by 12% on word similarity and 25% on accuracy. The focused contribution of LoRDD is in its promise for dialect adaptation of decoder models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "6 pages, 3 Figures, 5 Tables"
    },
    {
        "paper id": "2409.00369",
        "abstract url": "https://arxiv.org/abs/2409.00369",
        "title": "An Empirical Study on Information Extraction using Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Human-like large language models (LLMs), especially the most powerful and popular ones in OpenAI's GPT family, have proven to be very helpful for many natural language processing (NLP) related tasks. Therefore, various attempts have been made to apply LLMs to information extraction (IE), which is a fundamental NLP task that involves extracting information from unstructured plain text. To demonstrate the latest representative progress in LLMs' information extraction ability, we assess the information extraction ability of GPT-4 (the latest version of GPT at the time of writing this paper) from four perspectives: Performance, Evaluation Criteria, Robustness, and Error Types. Our results suggest a visible performance gap between GPT-4 and state-of-the-art (SOTA) IE methods. To alleviate this problem, considering the LLMs' human-like characteristics, we propose and analyze the effects of a series of simple prompt-based methods, which can be generalized to other LLMs and NLP tasks. Rich experiments show our methods' effectiveness and some of their remaining issues in improving GPT-4's information extraction ability.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2305.14450"
    },
    {
        "paper id": "2409.00408",
        "abstract url": "https://arxiv.org/abs/2409.00408",
        "title": "Multi-label Zero-Shot Audio Classification with Temporal Attention",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Zero-shot learning models are capable of classifying new classes by transferring knowledge from the seen classes using auxiliary information. While most of the existing zero-shot learning methods focused on single-label classification tasks, the present study introduces a method to perform multi-label zero-shot audio classification. To address the challenge of classifying multi-label sounds while generalizing to unseen classes, we adapt temporal attention. The temporal attention mechanism assigns importance weights to different audio segments based on their acoustic and semantic compatibility, thus enabling the model to capture the varying dominance of different sound classes within an audio sample by focusing on the segments most relevant for each class. This leads to more accurate multi-label zero-shot classification than methods employing temporally aggregated acoustic features without weighting, which treat all audio segments equally. We evaluate our approach on a subset of AudioSet against a zero-shot model using uniformly aggregated acoustic features, a zero-rule baseline, and the proposed method in the supervised scenario. Our results show that temporal attention enhances the zero-shot audio classification performance in multi-label scenario.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Accepted to International Workshop on Acoustic Signal Enhancement (IWAENC) 2024"
    },
    {
        "paper id": "2409.00414",
        "abstract url": "https://arxiv.org/abs/2409.00414",
        "title": "With Good MT There is No Need For End-to-End: A Case for Translate-then-Summarize Cross-lingual Summarization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent work has suggested that end-to-end system designs for cross-lingual summarization are competitive solutions that perform on par or even better than traditional pipelined designs. A closer look at the evidence reveals that this intuition is based on the results of only a handful of languages or using underpowered pipeline baselines. In this work, we compare these two paradigms for cross-lingual summarization on 39 source languages into English and show that a simple \\textit{translate-then-summarize} pipeline design consistently outperforms even an end-to-end system with access to enormous amounts of parallel data. For languages where our pipeline model does not perform well, we show that system performance is highly correlated with publicly distributed BLEU scores, allowing practitioners to establish the feasibility of a language pair a priori. Contrary to recent publication trends, our result suggests that the combination of individual progress of monolingual summarization and translation tasks offers better performance than an end-to-end system, suggesting that end-to-end designs should be considered with care.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00510",
        "abstract url": "https://arxiv.org/abs/2409.00510",
        "title": "Streamlining Forest Wildfire Surveillance: AI-Enhanced UAVs Utilizing the FLAME Aerial Video Dataset for Lightweight and Efficient Monitoring",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, unmanned aerial vehicles (UAVs) have played an increasingly crucial role in supporting disaster emergency response efforts by analyzing aerial images. While current deep-learning models focus on improving accuracy, they often overlook the limited computing resources of UAVs. This study recognizes the imperative for real-time data processing in disaster response scenarios and introduces a lightweight and efficient approach for aerial video understanding. Our methodology identifies redundant portions within the video through policy networks and eliminates this excess information using frame compression techniques. Additionally, we introduced the concept of a `station point,' which leverages future information in the sequential policy network, thereby enhancing accuracy. To validate our method, we employed the wildfire FLAME dataset. Compared to the baseline, our approach reduces computation costs by more than 13 times while boosting accuracy by 3$\\%$. Moreover, our method can intelligently select salient frames from the video, refining the dataset. This feature enables sophisticated models to be effectively trained on a smaller dataset, significantly reducing the time spent during the training process.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "accpeted by Proceedings of the International Conference on Intelligent Robots and Systems (2024 IROS)"
    },
    {
        "paper id": "2409.00527",
        "abstract url": "https://arxiv.org/abs/2409.00527",
        "title": "Post-OCR Text Correction for Bulgarian Historical Documents",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The digitization of historical documents is crucial for preserving the cultural heritage of the society. An important step in this process is converting scanned images to text using Optical Character Recognition (OCR), which can enable further search, information extraction, etc. Unfortunately, this is a hard problem as standard OCR tools are not tailored to deal with historical orthography as well as with challenging layouts. Thus, it is standard to apply an additional text correction step on the OCR output when dealing with such documents. In this work, we focus on Bulgarian, and we create the first benchmark dataset for evaluating the OCR text correction for historical Bulgarian documents written in the first standardized Bulgarian orthography: the Drinov orthography from the 19th century. We further develop a method for automatically generating synthetic data in this orthography, as well as in the subsequent Ivanchev orthography, by leveraging vast amounts of contemporary literature Bulgarian texts. We then use state-of-the-art LLMs and encoder-decoder framework which we augment with diagonal attention loss and copy and coverage mechanisms to improve the post-OCR text correction. The proposed method reduces the errors introduced during recognition and improves the quality of the documents by 25\\%, which is an increase of 16\\% compared to the state-of-the-art on the ICDAR 2019 Bulgarian dataset. We release our data and code at \\url{https://github.com/angelbeshirov/post-ocr-text-correction}.}",
        "subjects": [
            "cs.CL",
            "cs.DL",
            "cs.LG"
        ],
        "comment": "Accepted for publication in the International Journal on Digital Libraries"
    },
    {
        "paper id": "2409.00557",
        "abstract url": "https://arxiv.org/abs/2409.00557",
        "title": "Learning to Ask: When LLMs Meet Unclear Instruction",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Equipped with the capability to call functions, modern large language models (LLMs) can leverage external tools for addressing a range of tasks unattainable through language skills alone. However, the effective execution of these tools relies heavily not just on the advanced capabilities of LLMs but also on precise user instructions, which often cannot be ensured in the real world. To evaluate the performance of LLMs tool-use under imperfect instructions, we meticulously examine the real-world instructions queried from users, analyze the error patterns, and build a challenging tool-use benchmark called Noisy ToolBench (NoisyToolBench). We find that due to the next-token prediction training objective, LLMs tend to arbitrarily generate the missed argument, which may lead to hallucinations and risks. To address this issue, we propose a novel framework, Ask-when-Needed (AwN), which prompts LLMs to ask questions to users whenever they encounter obstacles due to unclear instructions. Moreover, to reduce the manual labor involved in user-LLM interaction and assess LLMs performance in tool utilization from both accuracy and efficiency perspectives, we design an automated evaluation tool named ToolEvaluator. Our experiments demonstrate that the AwN significantly outperforms existing frameworks for tool learning in the NoisyToolBench. We will release all related code and datasets to support future research.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00589",
        "abstract url": "https://arxiv.org/abs/2409.00589",
        "title": "Change-Aware Siamese Network for Surface Defects Segmentation under Complex Background",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the eye-catching breakthroughs achieved by deep visual networks in detecting region-level surface defects, the challenge of high-quality pixel-wise defect detection remains due to diverse defect appearances and data scarcity. To avoid over-reliance on defect appearance and achieve accurate defect segmentation, we proposed a change-aware Siamese network that solves the defect segmentation in a change detection framework. A novel multi-class balanced contrastive loss is introduced to guide the Transformer-based encoder, which enables encoding diverse categories of defects as the unified class-agnostic difference between defect and defect-free images. The difference presented by a distance map is then skip-connected to the change-aware decoder to assist in the location of both inter-class and out-of-class pixel-wise defects. In addition, we proposed a synthetic dataset with multi-class liquid crystal display (LCD) defects under a complex and disjointed background context, to demonstrate the advantages of change-based modeling over appearance-based modeling for defect segmentation. In our proposed dataset and two public datasets, our model achieves superior performances than the leading semantic segmentation methods, while maintaining a relatively small model size. Moreover, our model achieves a new state-of-the-art performance compared to the semi-supervised approaches in various supervision settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00597",
        "abstract url": "https://arxiv.org/abs/2409.00597",
        "title": "Multimodal Multi-turn Conversation Stance Detection: A Challenge Dataset and Effective Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Stance detection, which aims to identify public opinion towards specific targets using social media data, is an important yet challenging task. With the proliferation of diverse multimodal social media content including text, and images multimodal stance detection (MSD) has become a crucial research area. However, existing MSD studies have focused on modeling stance within individual text-image pairs, overlooking the multi-party conversational contexts that naturally occur on social media. This limitation stems from a lack of datasets that authentically capture such conversational scenarios, hindering progress in conversational MSD. To address this, we introduce a new multimodal multi-turn conversational stance detection dataset (called MmMtCSD). To derive stances from this challenging dataset, we propose a novel multimodal large language model stance detection framework (MLLM-SD), that learns joint stance representations from textual and visual modalities. Experiments on MmMtCSD show state-of-the-art performance of our proposed MLLM-SD approach for multimodal stance detection. We believe that MmMtCSD will contribute to advancing real-world applications of stance detection research.",
        "subjects": [
            "cs.MM",
            "cs.CL"
        ],
        "comment": "ACM MM2024"
    },
    {
        "paper id": "2409.00606",
        "abstract url": "https://arxiv.org/abs/2409.00606",
        "title": "Style Transfer: From Stitching to Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This article compares two style transfer methods in image processing: the traditional method, which synthesizes new images by stitching together small patches from existing images, and a modern machine learning-based approach that uses a segmentation network to isolate foreground objects and apply style transfer solely to the background. The traditional method excels in creating artistic abstractions but can struggle with seamlessness, whereas the machine learning method preserves the integrity of foreground elements while enhancing the background, offering improved aesthetic quality and computational efficiency. Our study indicates that machine learning-based methods are more suited for real-world applications where detail preservation in foreground elements is essential.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00608",
        "abstract url": "https://arxiv.org/abs/2409.00608",
        "title": "TinyAgent: Function Calling at the Edge",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Recent large language models (LLMs) have enabled the development of advanced agentic systems that can integrate various tools and APIs to fulfill user queries through function calling. However, the deployment of these LLMs on the edge has not been explored since they typically require cloud-based infrastructure due to their substantial model size and computational demands. To this end, we present TinyAgent, an end-to-end framework for training and deploying task-specific small language model agents capable of function calling for driving agentic systems at the edge. We first show how to enable accurate function calling for open-source models via the LLMCompiler framework. We then systematically curate a high-quality dataset for function calling, which we use to fine-tune two small language models, TinyAgent-1.1B and 7B. For efficient inference, we introduce a novel tool retrieval method to reduce the input prompt length and utilize quantization to further accelerate the inference speed. As a driving application, we demonstrate a local Siri-like system for Apple's MacBook that can execute user commands through text or voice input. Our results show that our models can achieve, and even surpass, the function-calling capabilities of larger models like GPT-4-Turbo, while being fully deployed at the edge. We open-source our dataset, models, and installable package and provide a demo video for our MacBook assistant agent.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00359",
        "abstract url": "https://arxiv.org/abs/2409.00359",
        "title": "Predicting Femicide in Veracruz: A Fuzzy Logic Approach with the Expanded MFM-FEM-VER-CP-2024 Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The article focuses on the urgent issue of femicide in Veracruz, Mexico, and the development of the MFM_FEM_VER_CP_2024 model, a mathematical framework designed to predict femicide risk using fuzzy logic. This model addresses the complexity and uncertainty inherent in gender based violence by formalizing risk factors such as coercive control, dehumanization, and the cycle of violence. These factors are mathematically modeled through membership functions that assess the degree of risk associated with various conditions, including personal relationships and specific acts of violence. The study enhances the original model by incorporating new rules and refining existing membership functions, which significantly improve the model predictive accuracy.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "24 pages, 2 tables, 3 figures"
    },
    {
        "paper id": "2409.00417",
        "abstract url": "https://arxiv.org/abs/2409.00417",
        "title": "Learning linear acyclic causal model including Gaussian noise using ancestral relationships",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper discusses algorithms for learning causal DAGs. The PC algorithm makes no assumptions other than the faithfulness to the causal model and can identify only up to the Markov equivalence class. LiNGAM assumes linearity and continuous non-Gaussian disturbances for the causal model, and the causal DAG defining LiNGAM is shown to be fully identifiable. The PC-LiNGAM, a hybrid of the PC algorithm and LiNGAM, can identify up to the distribution-equivalence pattern of a linear causal model, even in the presence of Gaussian disturbances. However, in the worst case, the PC-LiNGAM has factorial time complexity for the number of variables. In this paper, we propose an algorithm for learning the distribution-equivalence patterns of a linear causal model with a lower time complexity than PC-LiNGAM, using the causal ancestor finding algorithm in Maeda and Shimizu, which is generalized to account for Gaussian disturbances.",
        "subjects": [
            "cs.LG",
            "stat.ME"
        ],
        "comment": "30 pages, 6 figures"
    },
    {
        "paper id": "2409.00447",
        "abstract url": "https://arxiv.org/abs/2409.00447",
        "title": "The MERIT Dataset: Modelling and Efficiently Rendering Interpretable Transcripts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces the MERIT Dataset, a multimodal (text + image + layout) fully labeled dataset within the context of school reports. Comprising over 400 labels and 33k samples, the MERIT Dataset is a valuable resource for training models in demanding Visually-rich Document Understanding (VrDU) tasks. By its nature (student grade reports), the MERIT Dataset can potentially include biases in a controlled way, making it a valuable tool to benchmark biases induced in Language Models (LLMs). The paper outlines the dataset's generation pipeline and highlights its main features in the textual, visual, layout, and bias domains. To demonstrate the dataset's utility, we present a benchmark with token classification models, showing that the dataset poses a significant challenge even for SOTA models and that these would greatly benefit from including samples from the MERIT Dataset in their pretraining phase.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00459",
        "abstract url": "https://arxiv.org/abs/2409.00459",
        "title": "Gradient-Free Method for Heavily Constrained Nonconvex Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Zeroth-order (ZO) method has been shown to be a powerful method for solving the optimization problem where explicit expression of the gradients is difficult or infeasible to obtain. Recently, due to the practical value of the constrained problems, a lot of ZO Frank-Wolfe or projected ZO methods have been proposed. However, in many applications, we may have a very large number of nonconvex white/black-box constraints, which makes the existing zeroth-order methods extremely inefficient (or even not working) since they need to inquire function value of all the constraints and project the solution to the complicated feasible set. In this paper, to solve the nonconvex problem with a large number of white/black-box constraints, we proposed a doubly stochastic zeroth-order gradient method (DSZOG) with momentum method and adaptive step size. Theoretically, we prove DSZOG can converge to the $\u03b5$-stationary point of the constrained problem. Experimental results in two applications demonstrate the superiority of our method in terms of training time and accuracy compared with other ZO methods for the constrained problem.",
        "subjects": [
            "math.OC",
            "cs.DS",
            "cs.LG"
        ],
        "comment": "21 page, 12 figures, conference"
    },
    {
        "paper id": "2409.00478",
        "abstract url": "https://arxiv.org/abs/2409.00478",
        "title": "Simbanex: Similarity-based Exploration of IEEE VIS Publications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Embeddings are powerful tools for transforming complex and unstructured data into numeric formats suitable for computational analysis tasks. In this work, we use multiple embeddings for similarity calculations to be applied in bibliometrics and scientometrics. We build a multivariate network (MVN) from a large set of scientific publications and explore an aspect-driven analysis approach to reveal similarity patterns in the given publication data. By dividing our MVN into separately embeddable aspects, we are able to obtain a flexible vector representation which we use as input to a novel method of similarity-based clustering. Based on these preprocessing steps, we developed a visual analytics application, called Simbanex, that has been designed for the interactive visual exploration of similarity patterns within the underlying publications.",
        "subjects": [
            "cs.DL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00481",
        "abstract url": "https://arxiv.org/abs/2409.00481",
        "title": "DCIM-AVSR : Efficient Audio-Visual Speech Recognition via Dual Conformer Interaction Module",
        "rating": "0.5",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "facial"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Speech recognition is the technology that enables machines to interpret and process human speech, converting spoken language into text or commands. This technology is essential for applications such as virtual assistants, transcription services, and communication tools. The Audio-Visual Speech Recognition (AVSR) model enhances traditional speech recognition, particularly in noisy environments, by incorporating visual modalities like lip movements and facial expressions. While traditional AVSR models trained on large-scale datasets with numerous parameters can achieve remarkable accuracy, often surpassing human performance, they also come with high training costs and deployment challenges. To address these issues, we introduce an efficient AVSR model that reduces the number of parameters through the integration of a Dual Conformer Interaction Module (DCIM). In addition, we propose a pre-training method that further optimizes model performance by selectively updating parameters, leading to significant improvements in efficiency. Unlike conventional models that require the system to independently learn the hierarchical relationship between audio and visual modalities, our approach incorporates this distinction directly into the model architecture. This design enhances both efficiency and performance, resulting in a more practical and effective solution for AVSR tasks.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.00488",
        "abstract url": "https://arxiv.org/abs/2409.00488",
        "title": "Rapid Gyroscope Calibration: A Deep Learning Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Low-cost gyroscope calibration is essential for ensuring the accuracy and reliability of gyroscope measurements. Stationary calibration estimates the deterministic parts of measurement errors. To this end, a common practice is to average the gyroscope readings during a predefined period and estimate the gyroscope bias. Calibration duration plays a crucial role in performance, therefore, longer periods are preferred. However, some applications require quick startup times and calibration is therefore allowed only for a short time. In this work, we focus on reducing low-cost gyroscope calibration time using deep learning methods. We propose a deep-learning framework and explore the possibilities of using multiple real and virtual gyroscopes to improve the calibration performance of single gyroscopes. To train and validate our approach, we recorded a dataset consisting of 169 hours of gyroscope readings, using 24 gyroscopes of two different brands. We also created a virtual dataset consisting of simulated gyroscope readings. The two datasets were used to evaluate our proposed approach. One of our key achievements in this work is reducing gyroscope calibration time by up to 89% using three low-cost gyroscopes.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP"
        ],
        "comment": "10 Pages, 14 Figures,"
    },
    {
        "paper id": "2409.00493",
        "abstract url": "https://arxiv.org/abs/2409.00493",
        "title": "Evaluation of Prosumer Networks for Peak Load Management in Iran: A Distributed Contextual Stochastic Optimization Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Renewable prosumers face the complex challenge of balancing self-sufficiency with seamless grid and market integration. This paper introduces a novel prosumers network framework aimed at mitigating peak loads in Iran, particularly under the uncertainties inherent in renewable energy generation and demand. A cost-oriented integrated prediction and optimization approach is proposed, empowering prosumers to make informed decisions within a distributed contextual stochastic optimization (DCSO) framework. The problem is formulated as a bi-level two-stage multi-time scale optimization to determine optimal operation and interaction strategies under various scenarios, considering flexible resources. To facilitate grid integration, a novel consensus-based contextual information sharing mechanism is proposed. This approach enables coordinated collective behaviors and leverages contextual data more effectively. The overall problem is recast as a mixed-integer linear program (MILP) by incorporating optimality conditions and linearizing complementarity constraints. Additionally, a distributed algorithm using the consensus alternating direction method of multipliers (ADMM) is presented for computational tractability and privacy preservation. Numerical results highlights that integrating prediction with optimization and implementing a contextual information-sharing network among prosumers significantly reduces peak loads as well as total costs.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "eess.SY",
            "stat.ML"
        ],
        "comment": "10 pages, 26 figure, journal paper"
    },
    {
        "paper id": "2409.00494",
        "abstract url": "https://arxiv.org/abs/2409.00494",
        "title": "GenAI-powered Multi-Agent Paradigm for Smart Urban Mobility: Opportunities and Challenges for Integrating Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) with Intelligent Transportation Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Leveraging recent advances in generative AI, multi-agent systems are increasingly being developed to enhance the functionality and efficiency of smart city applications. This paper explores the transformative potential of large language models (LLMs) and emerging Retrieval-Augmented Generation (RAG) technologies in Intelligent Transportation Systems (ITS), paving the way for innovative solutions to address critical challenges in urban mobility. We begin by providing a comprehensive overview of the current state-of-the-art in mobility data, ITS, and Connected Vehicles (CV) applications. Building on this review, we discuss the rationale behind RAG and examine the opportunities for integrating these Generative AI (GenAI) technologies into the smart mobility sector. We propose a conceptual framework aimed at developing multi-agent systems capable of intelligently and conversationally delivering smart mobility services to urban commuters, transportation operators, and decision-makers. Our approach seeks to foster an autonomous and intelligent approach that (a) promotes science-based advisory to reduce traffic congestion, accidents, and carbon emissions at multiple scales, (b) facilitates public education and engagement in participatory mobility management, and (c) automates specialized transportation management tasks and the development of critical ITS platforms, such as data analytics and interpretation, knowledge representation, and traffic simulations. By integrating LLM and RAG, our approach seeks to overcome the limitations of traditional rule-based multi-agent systems, which rely on fixed knowledge bases and limited reasoning capabilities. This integration paves the way for a more scalable, intuitive, and automated multi-agent paradigm, driving advancements in ITS and urban mobility.",
        "subjects": [
            "cs.AI",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00546",
        "abstract url": "https://arxiv.org/abs/2409.00546",
        "title": "The Authentication Gap: Higher Education's Widespread Noncompliance with NIST Digital Identity Guidelines",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "We examine the authentication practices of a diverse set of 101 colleges and universities in the United States and Canada to determine compliance with five standards in NIST Special Publication 800-63-3 Digital Identity Guidelines. We find widespread noncompliance with standards for password expiration, password composition rules, and knowledge-based authentication. Many institutions still require or recommend noncompliant practices despite years of expert advice and standards to the contrary. Furthermore, we observe that regional and liberal arts colleges have generally lower documented compliance rates than national and global universities, motivating further investment in authentication security at these institutions. These results are a wake-up call that expert cybersecurity recommendations are not sufficiently influencing the policies of higher education institutions, leaving the sector vulnerable to increasingly prevalent ransomware and other cyberattacks.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "15 pages, 4 figures, 2 tables"
    },
    {
        "paper id": "2409.00553",
        "abstract url": "https://arxiv.org/abs/2409.00553",
        "title": "Multi-Output Distributional Fairness via Post-Processing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The post-processing approaches are becoming prominent techniques to enhance machine learning models' fairness because of their intuitiveness, low computational cost, and excellent scalability. However, most existing post-processing methods are designed for task-specific fairness measures and are limited to single-output models. In this paper, we introduce a post-processing method for multi-output models, such as the ones used for multi-task/multi-class classification and representation learning, to enhance a model's distributional parity, a task-agnostic fairness measure. Existing techniques to achieve distributional parity are based on the (inverse) cumulative density function of a model's output, which is limited to single-output models. Extending previous works, our method employs an optimal transport mapping to move a model's outputs across different groups towards their empirical Wasserstein barycenter. An approximation technique is applied to reduce the complexity of computing the exact barycenter and a kernel regression method is proposed for extending this process to out-of-sample data. Our empirical studies, which compare our method to current existing post-processing baselines on multi-task/multi-class classification and representation learning tasks, demonstrate the effectiveness of the proposed approach.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "17 pages, 4 figures"
    },
    {
        "paper id": "2409.00561",
        "abstract url": "https://arxiv.org/abs/2409.00561",
        "title": "Multi-Task Combinatorial Bandits for Budget Allocation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Today's top advertisers typically manage hundreds of campaigns simultaneously and consistently launch new ones throughout the year. A crucial challenge for marketing managers is determining the optimal allocation of limited budgets across various ad lines in each campaign to maximize cumulative returns, especially given the huge uncertainty in return outcomes. In this paper, we propose to formulate budget allocation as a multi-task combinatorial bandit problem and introduce a novel online budget allocation system. The proposed system: i) integrates a Bayesian hierarchical model to intelligently utilize the metadata of campaigns and ad lines and budget size, ensuring efficient information sharing; ii) provides the flexibility to incorporate diverse modeling techniques such as Linear Regression, Gaussian Processes, and Neural Networks, catering to diverse environmental complexities; and iii) employs the Thompson sampling (TS) technique to strike a balance between exploration and exploitation. Through offline evaluation and online experiments, our system demonstrates robustness and adaptability, effectively maximizing the overall cumulative returns. A Python implementation of the proposed procedure is available at https://anonymous.4open.science/r/MCMAB.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00563",
        "abstract url": "https://arxiv.org/abs/2409.00563",
        "title": "Sparse Mamba: Reinforcing Controllability In Structural State Space Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this article, we introduce the concept of controllability and observability to the M amba architecture in our Sparse-Mamba (S-Mamba) for natural language processing (NLP) applications. The structured state space model (SSM) development in recent studies, such as Mamba and Mamba2, outperformed and solved the computational inefficiency of transformers and large language models (LLMs) on longer sequences in small to medium NLP tasks. The Mamba SSMs architecture drops the need for attention layer or MLB blocks in transformers. However, the current Mamba models do not reinforce the controllability on state space equations in the calculation of A, B, C, and D matrices at each time step, which increase the complexity and the computational cost needed. In this article we show that the number of parameters can be significantly decreased by reinforcing controllability in the state space equations in the proposed Sparse-Mamba (S-Mamba), while maintaining the performance. The controllable n x n state matrix A is sparse and it has only n free parameters. Our novel approach will ensure a controllable system and could be the gate key for Mamba 3.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00564",
        "abstract url": "https://arxiv.org/abs/2409.00564",
        "title": "Using Deep Learning to Design High Aspect Ratio Fusion Devices",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The design of fusion devices is typically based on computationally expensive simulations. This can be alleviated using high aspect ratio models that employ a reduced number of free parameters, especially in the case of stellarator optimization where non-axisymmetric magnetic fields with a large parameter space are optimized to satisfy certain performance criteria. However, optimization is still required to find configurations with properties such as low elongation, high rotational transform, finite plasma beta, and good fast particle confinement. In this work, we train a machine learning model to construct configurations with favorable confinement properties by finding a solution to the inverse design problem, that is, obtaining a set of model input parameters for given desired properties. Since the solution of the inverse problem is non-unique, a probabilistic approach, based on mixture density networks, is used. It is shown that optimized configurations can be generated reliably using this method.",
        "subjects": [
            "physics.plasm-ph",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00571",
        "abstract url": "https://arxiv.org/abs/2409.00571",
        "title": "Enhancing Source Code Security with LLMs: Demystifying The Challenges and Generating Reliable Repairs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the recent unprecedented advancements in Artificial Intelligence (AI) computing, progress in Large Language Models (LLMs) is accelerating rapidly, presenting challenges in establishing clear guidelines, particularly in the field of security. That being said, we thoroughly identify and describe three main technical challenges in the security and software engineering literature that spans the entire LLM workflow, namely; \\textbf{\\textit{(i)}} Data Collection and Labeling; \\textbf{\\textit{(ii)}} System Design and Learning; and \\textbf{\\textit{(iii)}} Performance Evaluation. Building upon these challenges, this paper introduces \\texttt{SecRepair}, an instruction-based LLM system designed to reliably \\textit{identify}, \\textit{describe}, and automatically \\textit{repair} vulnerable source code. Our system is accompanied by a list of actionable guides on \\textbf{\\textit{(i)}} Data Preparation and Augmentation Techniques; \\textbf{\\textit{(ii)}} Selecting and Adapting state-of-the-art LLM Models; \\textbf{\\textit{(iii)}} Evaluation Procedures. \\texttt{SecRepair} uses a reinforcement learning-based fine-tuning with a semantic reward that caters to the functionality and security aspects of the generated code. Our empirical analysis shows that \\texttt{SecRepair} achieves a \\textit{12}\\% improvement in security code repair compared to other LLMs when trained using reinforcement learning. Furthermore, we demonstrate the capabilities of \\texttt{SecRepair} in generating reliable, functional, and compilable security code repairs against real-world test cases using automated evaluation metrics.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00575",
        "abstract url": "https://arxiv.org/abs/2409.00575",
        "title": "Online Optimization for Learning to Communicate over Time-Correlated Channels",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning techniques have garnered great interest in designing communication systems owing to their capacity in tacking with channel uncertainty. To provide theoretical guarantees for learning-based communication systems, some recent works analyze generalization bounds for devised methods based on the assumption of Independently and Identically Distributed (I.I.D.) channels, a condition rarely met in practical scenarios. In this paper, we drop the I.I.D. channel assumption and study an online optimization problem of learning to communicate over time-correlated channels. To address this issue, we further focus on two specific tasks: optimizing channel decoders for time-correlated fading channels and selecting optimal codebooks for time-correlated additive noise channels. For utilizing temporal dependence of considered channels to better learn communication systems, we develop two online optimization algorithms based on the optimistic online mirror descent framework. Furthermore, we provide theoretical guarantees for proposed algorithms via deriving sub-linear regret bound on the expected error probability of learned systems. Extensive simulation experiments have been conducted to validate that our presented approaches can leverage the channel correlation to achieve a lower average symbol error rate compared to baseline methods, consistent with our theoretical findings.",
        "subjects": [
            "cs.LG",
            "cs.IT"
        ],
        "comment": "14 pages, 4 figures, submitted for possible journal publication"
    },
    {
        "paper id": "2409.00584",
        "abstract url": "https://arxiv.org/abs/2409.00584",
        "title": "FastBO: Fast HPO and NAS with Adaptive Fidelity Identification",
        "rating": "0.5",
        "keywords": [
            [
                "architecture search",
                "NAS"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Hyperparameter optimization (HPO) and neural architecture search (NAS) are powerful in attaining state-of-the-art machine learning models, with Bayesian optimization (BO) standing out as a mainstream method. Extending BO into the multi-fidelity setting has been an emerging research topic, but faces the challenge of determining an appropriate fidelity for each hyperparameter configuration to fit the surrogate model. To tackle the challenge, we propose a multi-fidelity BO method named FastBO, which adaptively decides the fidelity for each configuration and efficiently offers strong performance. The advantages are achieved based on the novel concepts of efficient point and saturation point for each configuration.We also show that our adaptive fidelity identification strategy provides a way to extend any single-fidelity method to the multi-fidelity setting, highlighting its generality and applicability.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "The 18th European Conference on Computer Vision ECCV 2024 Women in Computer Vision Workshop"
    },
    {
        "paper id": "2409.00353",
        "abstract url": "https://arxiv.org/abs/2409.00353",
        "title": "RI-MAE: Rotation-Invariant Masked AutoEncoders for Self-Supervised Point Cloud Representation Learning",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Masked point modeling methods have recently achieved great success in self-supervised learning for point cloud data. However, these methods are sensitive to rotations and often exhibit sharp performance drops when encountering rotational variations. In this paper, we propose a novel Rotation-Invariant Masked AutoEncoders (RI-MAE) to address two major challenges: 1) achieving rotation-invariant latent representations, and 2) facilitating self-supervised reconstruction in a rotation-invariant manner. For the first challenge, we introduce RI-Transformer, which features disentangled geometry content, rotation-invariant relative orientation and position embedding mechanisms for constructing rotation-invariant point cloud latent space. For the second challenge, a novel dual-branch student-teacher architecture is devised. It enables the self-supervised learning via the reconstruction of masked patches within the learned rotation-invariant latent space. Each branch is based on an RI-Transformer, and they are connected with an additional RI-Transformer predictor. The teacher encodes all point patches, while the student solely encodes unmasked ones. Finally, the predictor predicts the latent features of the masked patches using the output latent embeddings from the student, supervised by the outputs from the teacher. Extensive experiments demonstrate that our method is robust to rotations, achieving the state-of-the-art performance on various downstream tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00381",
        "abstract url": "https://arxiv.org/abs/2409.00381",
        "title": "3D Gaussian Splatting for Large-scale 3D Surface Reconstruction from Aerial Images",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, 3D Gaussian Splatting (3DGS) has garnered significant attention. However, the unstructured nature of 3DGS poses challenges for large-scale surface reconstruction from aerial images. To address this gap, we propose the first large-scale surface reconstruction method for multi-view stereo (MVS) aerial images based on 3DGS, named Aerial Gaussian Splatting (AGS). Initially, we introduce a data chunking method tailored for large-scale aerial imagery, making the modern 3DGS technology feasible for surface reconstruction over extensive scenes. Additionally, we integrate the Ray-Gaussian Intersection method to obtain normal and depth information, facilitating geometric constraints. Finally, we introduce a multi-view geometric consistency constraint to enhance global geometric consistency and improve reconstruction accuracy. Our experiments on multiple datasets demonstrate for the first time that the GS-based technique can match traditional aerial MVS methods on geometric accuracy, and beat state-of-the-art GS-based methods on geometry and rendering quality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2409.00391",
        "abstract url": "https://arxiv.org/abs/2409.00391",
        "title": "Density Adaptive Attention-based Speech Network: Enhancing Feature Understanding for Mental Health Disorders",
        "rating": "0",
        "keywords": [
            [
                "parameter efficient"
            ],
            [
                "Health"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech-based depression detection poses significant challenges for automated detection due to its unique manifestation across individuals and data scarcity. Addressing these challenges, we introduce DAAMAudioCNNLSTM and DAAMAudioTransformer, two parameter efficient and explainable models for audio feature extraction and depression detection. DAAMAudioCNNLSTM features a novel CNN-LSTM framework with multi-head Density Adaptive Attention Mechanism (DAAM), focusing dynamically on informative speech segments. DAAMAudioTransformer, leveraging a transformer encoder in place of the CNN-LSTM architecture, incorporates the same DAAM module for enhanced attention and interpretability. These approaches not only enhance detection robustness and interpretability but also achieve state-of-the-art performance: DAAMAudioCNNLSTM with an F1 macro score of 0.702 and DAAMAudioTransformer with an F1 macro score of 0.72 on the DAIC-WOZ dataset, without reliance on supplementary information such as vowel positions and speaker information during training/validation as in previous approaches. Both models' significant explainability and efficiency in leveraging speech signals for depression detection represent a leap towards more reliable, clinically useful diagnostic tools, promising advancements in speech and mental health care. To foster further research in this domain, we make our code publicly available.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00399",
        "abstract url": "https://arxiv.org/abs/2409.00399",
        "title": "Rethinking Backdoor Detection Evaluation for Language Models",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Backdoor attacks, in which a model behaves maliciously when given an attacker-specified trigger, pose a major security risk for practitioners who depend on publicly released language models. Backdoor detection methods aim to detect whether a released model contains a backdoor, so that practitioners can avoid such vulnerabilities. While existing backdoor detection methods have high accuracy in detecting backdoored models on standard benchmarks, it is unclear whether they can robustly identify backdoors in the wild. In this paper, we examine the robustness of backdoor detectors by manipulating different factors during backdoor planting. We find that the success of existing methods highly depends on how intensely the model is trained on poisoned data during backdoor planting. Specifically, backdoors planted with either more aggressive or more conservative training are significantly more difficult to detect than the default ones. Our results highlight a lack of robustness of existing backdoor detectors and the limitations in current benchmark construction.",
        "subjects": [
            "cs.CL",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00410",
        "abstract url": "https://arxiv.org/abs/2409.00410",
        "title": "A Hybrid Transformer-Mamba Network for Single Image Deraining",
        "rating": "0",
        "keywords": [
            [
                "Deraining"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing deraining Transformers employ self-attention mechanisms with fixed-range windows or along channel dimensions, limiting the exploitation of non-local receptive fields. In response to this issue, we introduce a novel dual-branch hybrid Transformer-Mamba network, denoted as TransMamba, aimed at effectively capturing long-range rain-related dependencies. Based on the prior of distinct spectral-domain features of rain degradation and background, we design a spectral-banded Transformer blocks on the first branch. Self-attention is executed within the combination of the spectral-domain channel dimension to improve the ability of modeling long-range dependencies. To enhance frequency-specific information, we present a spectral enhanced feed-forward module that aggregates features in the spectral domain. In the second branch, Mamba layers are equipped with cascaded bidirectional state space model modules to additionally capture the modeling of both local and global information. At each stage of both the encoder and decoder, we perform channel-wise concatenation of dual-branch features and achieve feature fusion through channel reduction, enabling more effective integration of the multi-scale information from the Transformer and Mamba branches. To better reconstruct innate signal-level relations within clean images, we also develop a spectral coherence loss. Extensive experiments on diverse datasets and real-world images demonstrate the superiority of our method compared against the state-of-the-art approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 9 figures"
    },
    {
        "paper id": "2409.00449",
        "abstract url": "https://arxiv.org/abs/2409.00449",
        "title": "ActionPose: Pretraining 3D Human Pose Estimation with the Dark Knowledge of Action",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "2D-to-3D human pose lifting is an ill-posed problem due to depth ambiguity and occlusion. Existing methods relying on spatial and temporal consistency alone are insufficient to resolve these problems because they lack semantic information of the motions. To overcome this, we propose ActionPose, a framework that leverages action knowledge by aligning motion embeddings with text embeddings of fine-grained action labels. ActionPose operates in two stages: pretraining and fine-tuning. In the pretraining stage, the model learns to recognize actions and reconstruct 3D poses from masked and noisy 2D poses. During the fine-tuning stage, the model is further refined using real-world 3D human pose estimation datasets without action labels. Additionally, our framework incorporates masked body parts and masked time windows in motion modeling to mitigate the effects of ambiguous boundaries between actions in both temporal and spatial domains. Experiments demonstrate the effectiveness of ActionPose, achieving state-of-the-art performance in 3D pose estimation on public datasets, including Human3.6M and MPI-INF-3DHP. Specifically, ActionPose achieves an MPJPE of 36.7mm on Human3.6M with detected 2D poses as input and 15.5mm on MPI-INF-3DHP with ground-truth 2D poses as input.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00473",
        "abstract url": "https://arxiv.org/abs/2409.00473",
        "title": "Studying the Effects of Self-Attention on SAR Automatic Target Recognition",
        "rating": "0",
        "keywords": [
            [
                "radar",
                "vehicle"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Attention mechanisms are critically important in the advancement of synthetic aperture radar (SAR) automatic target recognition (ATR) systems. Traditional SAR ATR models often struggle with the noisy nature of the SAR data, frequently learning from background noise rather than the most relevant image features. Attention mechanisms address this limitation by focusing on crucial image components, such as the shadows and small parts of a vehicle, which are crucial for accurate target classification. By dynamically prioritizing these significant features, attention-based models can efficiently characterize the entire image with a few pixels, thus enhancing recognition performance. This capability allows for the discrimination of targets from background clutter, leading to more practical and robust SAR ATR models. We show that attention modules increase top-1 accuracy, improve input robustness, and are qualitatively more explainable on the MSTAR dataset.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00487",
        "abstract url": "https://arxiv.org/abs/2409.00487",
        "title": "TrackSSM: A General Motion Predictor by State-Space Model",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Temporal motion modeling has always been a key component in multiple object tracking (MOT) which can ensure smooth trajectory movement and provide accurate positional information to enhance association precision. However, current motion models struggle to be both efficient and effective across different application scenarios. To this end, we propose TrackSSM inspired by the recently popular state space models (SSM), a unified encoder-decoder motion framework that uses data-dependent state space model to perform temporal motion of trajectories. Specifically, we propose Flow-SSM, a module that utilizes the position and motion information from historical trajectories to guide the temporal state transition of object bounding boxes. Based on Flow-SSM, we design a flow decoder. It is composed of a cascaded motion decoding module employing Flow-SSM, which can use the encoded flow information to complete the temporal position prediction of trajectories. Additionally, we propose a Step-by-Step Linear (S$^2$L) training strategy. By performing linear interpolation between the positions of the object in the previous frame and the current frame, we construct the pseudo labels of step-by-step linear training, ensuring that the trajectory flow information can better guide the object bounding box in completing temporal transitions. TrackSSM utilizes a simple Mamba-Block to build a motion encoder for historical trajectories, forming a temporal motion model with an encoder-decoder structure in conjunction with the flow decoder. TrackSSM is applicable to various tracking scenarios and achieves excellent tracking performance across multiple benchmarks, further extending the potential of SSM-like temporal motion models in multi-object tracking tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00492",
        "abstract url": "https://arxiv.org/abs/2409.00492",
        "title": "Accurate Compression of Text-to-Image Diffusion Models via Vector Quantization",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image diffusion models have emerged as a powerful framework for high-quality image generation given textual prompts. Their success has driven the rapid development of production-grade diffusion models that consistently increase in size and already contain billions of parameters. As a result, state-of-the-art text-to-image models are becoming less accessible in practice, especially in resource-limited environments. Post-training quantization (PTQ) tackles this issue by compressing the pretrained model weights into lower-bit representations. Recent diffusion quantization techniques primarily rely on uniform scalar quantization, providing decent performance for the models compressed to 4 bits. This work demonstrates that more versatile vector quantization (VQ) may achieve higher compression rates for large-scale text-to-image diffusion models. Specifically, we tailor vector-based PTQ methods to recent billion-scale text-to-image models (SDXL and SDXL-Turbo), and show that the diffusion models of 2B+ parameters compressed to around 3 bits using VQ exhibit the similar image quality and textual alignment as previous 4-bit compression techniques.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "project page: https://yandex-research.github.io/vqdm"
    },
    {
        "paper id": "2409.00511",
        "abstract url": "https://arxiv.org/abs/2409.00511",
        "title": "RevCD -- Reversed Conditional Diffusion for Generalized Zero-Shot Learning",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In Generalized Zero-Shot Learning (GZSL), we aim to recognize both seen and unseen categories using a model trained only on seen categories. In computer vision, this translates into a classification problem, where knowledge from seen categories is transferred to unseen categories by exploiting the relationships between visual features and available semantic information, such as text corpora or manual annotations. However, learning this joint distribution is costly and requires one-to-one training with corresponding semantic information. We present a reversed conditional Diffusion-based model (RevCD) that mitigates this issue by generating semantic features synthesized from visual inputs by leveraging Diffusion models' conditional mechanisms. Our RevCD model consists of a cross Hadamard-Addition embedding of a sinusoidal time schedule and a multi-headed visual transformer for attention-guided embeddings. The proposed approach introduces three key innovations. First, we reverse the process of generating semantic space based on visual data, introducing a novel loss function that facilitates more efficient knowledge transfer. Second, we apply Diffusion models to zero-shot learning - a novel approach that exploits their strengths in capturing data complexity. Third, we demonstrate our model's performance through a comprehensive cross-dataset evaluation. The complete code will be available on GitHub.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00522",
        "abstract url": "https://arxiv.org/abs/2409.00522",
        "title": "EraseDraw: Learning to Insert Objects by Erasing Them from Images",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Creative processes such as painting often involve creating different components of an image one by one. Can we build a computational model to perform this task? Prior works often fail by making global changes to the image, inserting objects in unrealistic spatial locations, and generating inaccurate lighting details. We observe that while state-of-the-art models perform poorly on object insertion, they can remove objects and erase the background in natural images very well. Inverting the direction of object removal, we obtain high-quality data for learning to insert objects that are spatially, physically, and optically consistent with the surroundings. With this scalable automatic data generation pipeline, we can create a dataset for learning object insertion, which is used to train our proposed text conditioned diffusion model. Qualitative and quantitative experiments have shown that our model achieves state-of-the-art results in object insertion, particularly for in-the-wild images. We show compelling results on diverse insertion prompts and images across various domains.In addition, we automate iterative insertion by combining our insertion model with beam search guided by CLIP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00543",
        "abstract url": "https://arxiv.org/abs/2409.00543",
        "title": "How Does Diverse Interpretability of Textual Prompts Impact Medical Vision-Language Zero-Shot Tasks?",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Medical",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in medical vision-language pre-training (MedVLP) have significantly enhanced zero-shot medical vision tasks such as image classification by leveraging large-scale medical image-text pair pre-training. However, the performance of these tasks can be heavily influenced by the variability in textual prompts describing the categories, necessitating robustness in MedVLP models to diverse prompt styles. Yet, this sensitivity remains underexplored. In this work, we are the first to systematically assess the sensitivity of three widely-used MedVLP methods to a variety of prompts across 15 different diseases. To achieve this, we designed six unique prompt styles to mirror real clinical scenarios, which were subsequently ranked by interpretability. Our findings indicate that all MedVLP models evaluated show unstable performance across different prompt styles, suggesting a lack of robustness. Additionally, the models' performance varied with increasing prompt interpretability, revealing difficulties in comprehending complex medical concepts. This study underscores the need for further development in MedVLP methodologies to enhance their robustness to diverse zero-shot prompts.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00547",
        "abstract url": "https://arxiv.org/abs/2409.00547",
        "title": "Data Augmentation for Image Classification using Generative AI",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Scaling laws dictate that the performance of AI models is proportional to the amount of available data. Data augmentation is a promising solution to expanding the dataset size. Traditional approaches focused on augmentation using rotation, translation, and resizing. Recent approaches use generative AI models to improve dataset diversity. However, the generative methods struggle with issues such as subject corruption and the introduction of irrelevant artifacts. In this paper, we propose the Automated Generative Data Augmentation (AGA). The framework combines the utility of large language models (LLMs), diffusion models, and segmentation models to augment data. AGA preserves foreground authenticity while ensuring background diversity. Specific contributions include: i) segment and superclass based object extraction, ii) prompt diversity with combinatorial complexity using prompt decomposition, and iii) affine subject manipulation. We evaluate AGA against state-of-the-art (SOTA) techniques on three representative datasets, ImageNet, CUB, and iWildCam. The experimental evaluation demonstrates an accuracy improvement of 15.6% and 23.5% for in and out-of-distribution data compared to baseline models, respectively. There is also a 64.3% improvement in SIC score compared to the baselines.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "19 pages, 15 figures, 4 tables"
    },
    {
        "paper id": "2409.00562",
        "abstract url": "https://arxiv.org/abs/2409.00562",
        "title": "Comparative Analysis of Modality Fusion Approaches for Audio-Visual Person Identification and Verification",
        "rating": "0",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "facial"
            ],
            [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Multimodal learning involves integrating information from various modalities to enhance learning and comprehension. We compare three modality fusion strategies in person identification and verification by processing two modalities: voice and face. In this paper, a one-dimensional convolutional neural network is employed for x-vector extraction from voice, while the pre-trained VGGFace2 network and transfer learning are utilized for face modality. In addition, gammatonegram is used as speech representation in engagement with the Darknet19 pre-trained network. The proposed systems are evaluated using the K-fold cross-validation technique on the 118 speakers of the test set of the VoxCeleb2 dataset. The comparative evaluations are done for single-modality and three proposed multimodal strategies in equal situations. Results demonstrate that the feature fusion strategy of gammatonegram and facial features achieves the highest performance, with an accuracy of 98.37% in the person identification task. However, concatenating facial features with the x-vector reaches 0.62% for EER in verification tasks.",
        "subjects": [
            "eess.AS",
            "cs.CV",
            "cs.MM",
            "cs.SD"
        ],
        "comment": "This paper has been submitted to a conference"
    },
    {
        "paper id": "2409.00590",
        "abstract url": "https://arxiv.org/abs/2409.00590",
        "title": "COMOGen: A Controllable Text-to-3D Multi-object Generation Framework",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The controllability of 3D object generation methods is achieved through input text. Existing text-to-3D object generation methods primarily focus on generating a single object based on a single object description. However, these methods often face challenges in producing results that accurately correspond to our desired positions when the input text involves multiple objects. To address the issue of controllability in generating multiple objects, this paper introduces COMOGen, a COntrollable text-to-3D Multi-Object Generation framework. COMOGen enables the simultaneous generation of multiple 3D objects by the distillation of layout and multi-view prior knowledge. The framework consists of three modules: the layout control module, the multi-view consistency control module, and the 3D content enhancement module. Moreover, to integrate these three modules as an integral framework, we propose Layout Multi-view Score Distillation, which unifies two prior knowledge and further enhances the diversity and quality of generated 3D content. Comprehensive experiments demonstrate the effectiveness of our approach compared to the state-of-the-art methods, which represents a significant step forward in enabling more controlled and versatile text-based 3D content generation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00598",
        "abstract url": "https://arxiv.org/abs/2409.00598",
        "title": "Automatic Pseudo-Harmful Prompt Generation for Evaluating False Refusals in Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Safety-aligned large language models (LLMs) sometimes falsely refuse pseudo-harmful prompts, like \"how to kill a mosquito,\" which are actually harmless. Frequent false refusals not only frustrate users but also provoke a public backlash against the very values alignment seeks to protect. In this paper, we propose the first method to auto-generate diverse, content-controlled, and model-dependent pseudo-harmful prompts. Using this method, we construct an evaluation dataset called PHTest, which is ten times larger than existing datasets, covers more false refusal patterns, and separately labels controversial prompts. We evaluate 20 LLMs on PHTest, uncovering new insights due to its scale and labeling. Our findings reveal a trade-off between minimizing false refusals and improving safety against jailbreak attacks. Moreover, we show that many jailbreak defenses significantly increase the false refusal rates, thereby undermining usability. Our method and dataset can help developers evaluate and fine-tune safer and more usable LLMs. Our code and dataset are available at https://github.com/umd-huang-lab/FalseRefusal",
        "subjects": [
            "cs.CL",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00418",
        "abstract url": "https://arxiv.org/abs/2409.00418",
        "title": "Robust off-policy Reinforcement Learning via Soft Constrained Adversary",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recently, robust reinforcement learning (RL) methods against input observation have garnered significant attention and undergone rapid evolution due to RL's potential vulnerability. Although these advanced methods have achieved reasonable success, there have been two limitations when considering adversary in terms of long-term horizons. First, the mutual dependency between the policy and its corresponding optimal adversary limits the development of off-policy RL algorithms; although obtaining optimal adversary should depend on the current policy, this has restricted applications to off-policy RL. Second, these methods generally assume perturbations based only on the $L_p$-norm, even when prior knowledge of the perturbation distribution in the environment is available. We here introduce another perspective on adversarial RL: an f-divergence constrained problem with the prior knowledge distribution. From this, we derive two typical attacks and their corresponding robust learning frameworks. The evaluation of robustness is conducted and the results demonstrate that our proposed methods achieve excellent performance in sample-efficient off-policy RL.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "33 pages, 12 figures, 2 tables"
    },
    {
        "paper id": "2409.00421",
        "abstract url": "https://arxiv.org/abs/2409.00421",
        "title": "Reproducibility Study Of Learning Fair Graph Representations Via Automated Data Augmentations",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we undertake a reproducibility analysis of 'Learning Fair Graph Representations Via Automated Data Augmentations' by Ling et al. (2022). We assess the validity of the original claims focused on node classification tasks and explore the performance of the Graphair framework in link prediction tasks. Our investigation reveals that we can partially reproduce one of the original three claims and fully substantiate the other two. Additionally, we broaden the application of Graphair from node classification to link prediction across various datasets. Our findings indicate that, while Graphair demonstrates a comparable fairness-accuracy trade-off to baseline models for mixed dyadic-level fairness, it has a superior trade-off for subgroup dyadic-level fairness. These findings underscore Graphair's potential for wider adoption in graph-based learning. Our code base can be found on GitHub at https://github.com/juellsprott/graphair-reproducibility.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at TMLR, 15 pages, 6 figures, 9 tables (incl. Appendix)"
    },
    {
        "paper id": "2409.00438",
        "abstract url": "https://arxiv.org/abs/2409.00438",
        "title": "Breaking Down Financial News Impact: A Novel AI Approach with Geometric Hypergraphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the fast-paced and volatile financial markets, accurately predicting stock movements based on financial news is critical for investors and analysts. Traditional models often struggle to capture the intricate and dynamic relationships between news events and market reactions, limiting their ability to provide actionable insights. This paper introduces a novel approach leveraging Explainable Artificial Intelligence (XAI) through the development of a Geometric Hypergraph Attention Network (GHAN) to analyze the impact of financial news on market behaviours. Geometric hypergraphs extend traditional graph structures by allowing edges to connect multiple nodes, effectively modelling high-order relationships and interactions among financial entities and news events. This unique capability enables the capture of complex dependencies, such as the simultaneous impact of a single news event on multiple stocks or sectors, which traditional models frequently overlook. By incorporating attention mechanisms within hypergraphs, GHAN enhances the model's ability to focus on the most relevant information, ensuring more accurate predictions and better interpretability. Additionally, we employ BERT-based embeddings to capture the semantic richness of financial news texts, providing a nuanced understanding of the content. Using a comprehensive financial news dataset, our GHAN model addresses key challenges in financial news impact analysis, including the complexity of high-order interactions, the necessity for model interpretability, and the dynamic nature of financial markets. Integrating attention mechanisms and SHAP values within GHAN ensures transparency, highlighting the most influential factors driving market predictions. Empirical validation demonstrates the superior effectiveness of our approach over traditional sentiment analysis and time-series models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "16 pages, conference"
    },
    {
        "paper id": "2409.00448",
        "abstract url": "https://arxiv.org/abs/2409.00448",
        "title": "PSLF: A PID Controller-incorporated Second-order Latent Factor Analysis Model for Recommender System",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "A second-order-based latent factor (SLF) analysis model demonstrates superior performance in graph representation learning, particularly for high-dimensional and incomplete (HDI) interaction data, by incorporating the curvature information of the loss landscape. However, its objective function is commonly bi-linear and non-convex, causing the SLF model to suffer from a low convergence rate. To address this issue, this paper proposes a PID controller-incorporated SLF (PSLF) model, leveraging two key strategies: a) refining learning error estimation by incorporating the PID controller principles, and b) acquiring second-order information insights through Hessian-vector products. Experimental results on multiple HDI datasets indicate that the proposed PSLF model outperforms four state-of-the-art latent factor models based on advanced optimizers regarding convergence rates and generalization performance.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00604",
        "abstract url": "https://arxiv.org/abs/2409.00604",
        "title": "Spatio-spectral graph neural operator for solving computational mechanics problems on irregular domain and unstructured grid",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Scientific machine learning has seen significant progress with the emergence of operator learning. However, existing methods encounter difficulties when applied to problems on unstructured grids and irregular domains. Spatial graph neural networks utilize local convolution in a neighborhood to potentially address these challenges, yet they often suffer from issues such as over-smoothing and over-squashing in deep architectures. Conversely, spectral graph neural networks leverage global convolution to capture extensive features and long-range dependencies in domain graphs, albeit at a high computational cost due to Eigenvalue decomposition. In this paper, we introduce a novel approach, referred to as Spatio-Spectral Graph Neural Operator (Sp$^2$GNO) that integrates spatial and spectral GNNs effectively. This framework mitigates the limitations of individual methods and enables the learning of solution operators across arbitrary geometries, thus catering to a wide range of real-world problems. Sp$^2$GNO demonstrates exceptional performance in solving both time-dependent and time-independent partial differential equations on regular and irregular domains. Our approach is validated through comprehensive benchmarks and practical applications drawn from computational mechanics and scientific computing literature.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00607",
        "abstract url": "https://arxiv.org/abs/2409.00607",
        "title": "Flight Delay Prediction using Hybrid Machine Learning Approach: A Case Study of Major Airlines in the United States",
        "rating": "-0.5",
        "keywords": [
            [
                "Flight"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The aviation industry has experienced constant growth in air traffic since the deregulation of the U.S. airline industry in 1978. As a result, flight delays have become a major concern for airlines and passengers, leading to significant research on factors affecting flight delays such as departure, arrival, and total delays. Flight delays result in increased consumption of limited resources such as fuel, labor, and capital, and are expected to increase in the coming decades. To address the flight delay problem, this research proposes a hybrid approach that combines the feature of deep learning and classic machine learning techniques. In addition, several machine learning algorithms are applied on flight data to validate the results of proposed model. To measure the performance of the model, accuracy, precision, recall, and F1-score are calculated, and ROC and AUC curves are generated. The study also includes an extensive analysis of the flight data and each model to obtain insightful results for U.S. airlines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00350",
        "abstract url": "https://arxiv.org/abs/2409.00350",
        "title": "Monitoring arc-geodetic sets of oriented graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Monitoring edge-geodetic sets in a graph are subsets of vertices such that every edge of the graph must lie on all the shortest paths between two vertices of the monitoring set. These objects were introduced in a work by Foucaud, Krishna and Ramasubramony Sulochana with relation to several prior notions in the area of network monitoring like distance edge-monitoring. In this work, we explore the extension of those notions unto oriented graphs, modelling oriented networks, and call these objects monitoring arc-geodetic sets. We also define the lower and upper monitoring arc-geodetic number of an undirected graph as the minimum and maximum of the monitoring arc-geodetic number of all orientations of the graph. We determine the monitoring arc-geodetic number of fundamental graph classes such as bipartite graphs, trees, cycles, etc. Then, we characterize the graphs for which every monitoring arc-geodetic set is the entire set of vertices, and also characterize the solutions for tournaments. We also cover some complexity aspects by studying two algorithmic problems. We show that the problem of determining if an undirected graph has an orientation with the minimal monitoring arc-geodetic set being the entire set of vertices, is NP-hard. We also show that the problem of finding a monitoring arc-geodetic set of size at most $k$ is $NP$-complete when restricted to oriented graphs with maximum degree $4$.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00362",
        "abstract url": "https://arxiv.org/abs/2409.00362",
        "title": "UDGS-SLAM : UniDepth Assisted Gaussian Splatting for Monocular SLAM",
        "rating": "-1",
        "keywords": [
            [
                "Gaussian Splatting",
                "RGB-D",
                "depth"
            ],
            [
                "trajectory",
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in monocular neural depth estimation, particularly those achieved by the UniDepth network, have prompted the investigation of integrating UniDepth within a Gaussian splatting framework for monocular SLAM.This study presents UDGS-SLAM, a novel approach that eliminates the necessity of RGB-D sensors for depth estimation within Gaussian splatting framework. UDGS-SLAM employs statistical filtering to ensure local consistency of the estimated depth and jointly optimizes camera trajectory and Gaussian scene representation parameters. The proposed method achieves high-fidelity rendered images and low ATERMSE of the camera trajectory. The performance of UDGS-SLAM is rigorously evaluated using the TUM RGB-D dataset and benchmarked against several baseline methods, demonstrating superior performance across various scenarios. Additionally, an ablation study is conducted to validate design choices and investigate the impact of different network backbone encoders on system performance.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00388",
        "abstract url": "https://arxiv.org/abs/2409.00388",
        "title": "A method for detecting dead fish on large water surfaces based on improved YOLOv10",
        "rating": "-1",
        "keywords": [
            [
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Dead fish frequently appear on the water surface due to various factors. If not promptly detected and removed, these dead fish can cause significant issues such as water quality deterioration, ecosystem damage, and disease transmission. Consequently, it is imperative to develop rapid and effective detection methods to mitigate these challenges. Conventional methods for detecting dead fish are often constrained by manpower and time limitations, struggling to effectively manage the intricacies of aquatic environments. This paper proposes an end-to-end detection model built upon an enhanced YOLOv10 framework, designed specifically to swiftly and precisely detect deceased fish across extensive water surfaces.Key enhancements include: (1) Replacing YOLOv10's backbone network with FasterNet to reduce model complexity while maintaining high detection accuracy; (2) Improving feature fusion in the Neck section through enhanced connectivity methods and replacing the original C2f module with CSPStage modules; (3) Adding a compact target detection head to enhance the detection performance of smaller objects. Experimental results demonstrate significant improvements in P(precision), R(recall), and AP(average precision) compared to the baseline model YOLOv10n. Furthermore, our model outperforms other models in the YOLO series by significantly reducing model size and parameter count, while sustaining high inference speed and achieving optimal AP performance. The model facilitates rapid and accurate detection of dead fish in large-scale aquaculture systems. Finally, through ablation experiments, we systematically analyze and assess the contribution of each model component to the overall system performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00426",
        "abstract url": "https://arxiv.org/abs/2409.00426",
        "title": "Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "The vulnerability of machine learning models to Membership Inference Attacks (MIAs) has garnered considerable attention in recent years. These attacks determine whether a data sample belongs to the model's training set or not. Recent research has focused on reference-based attacks, which leverage difficulty calibration with independently trained reference models. While empirical studies have demonstrated its effectiveness, there is a notable gap in our understanding of the circumstances under which it succeeds or fails. In this paper, we take a further step towards a deeper understanding of the role of difficulty calibration. Our observations reveal inherent limitations in calibration methods, leading to the misclassification of non-members and suboptimal performance, particularly on high-loss samples. We further identify that these errors stem from an imperfect sampling of the potential distribution and a strong dependence of membership scores on the model parameters. By shedding light on these issues, we propose RAPID: a query-efficient and computation-efficient MIA that directly \\textbf{R}e-lever\\textbf{A}ges the original membershi\\textbf{P} scores to m\\textbf{I}tigate the errors in \\textbf{D}ifficulty calibration. Our experimental results, spanning 9 datasets and 5 model architectures, demonstrate that PETAL outperforms previous state-of-the-art attacks (e.g., LiRA and Canary offline) across different metrics while remaining computationally efficient. Our observations and analysis challenge the current de facto paradigm of difficulty calibration in high-precision inference, encouraging greater attention to the persistent risks posed by MIAs in more practical scenarios.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted by ACM CCS 2024"
    },
    {
        "paper id": "2409.00483",
        "abstract url": "https://arxiv.org/abs/2409.00483",
        "title": "Statistics of punctuation in experimental literature -- the remarkable case of \"Finnegans Wake\" by James Joyce",
        "rating": "-1",
        "keywords": [
            [
                "survival"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "As the recent studies indicate, the structure imposed onto written texts by the presence of punctuation develops patterns which reveal certain characteristics of universality. In particular, based on a large collection of classic literary works, it has been evidenced that the distances between consecutive punctuation marks, measured in terms of the number of words, obey the discrete Weibull distribution - a discrete variant of a distribution often used in survival analysis. The present work extends the analysis of punctuation usage patterns to more experimental pieces of world literature. It turns out that the compliance of the the distances between punctuation marks with the discrete Weibull distribution typically applies here as well. However, some of the works by James Joyce are distinct in this regard - in the sense that the tails of the relevant distributions are significantly thicker and, consequently, the corresponding hazard functions are decreasing functions not observed in typical literary texts in prose. \"Finnegans Wake\" - the same one to which science owes the word \"quarks\" for the most fundamental constituents of matter - is particularly striking in this context. At the same time, in all the studied texts, the sentence lengths - representing the distances between sentence-ending punctuation marks - reveal more freedom and are not constrained by the discrete Weibull distribution. This freedom in some cases translates into long-range nonlinear correlations, which manifest themselves in multifractality. Again, a text particularly spectacular in terms of multifractality is \"Finnegans Wake\".",
        "subjects": [
            "physics.soc-ph",
            "cs.CL",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00489",
        "abstract url": "https://arxiv.org/abs/2409.00489",
        "title": "Geospatial foundation models for image analysis: evaluating and enhancing NASA-IBM Prithvi's domain adaptability",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Research on geospatial foundation models (GFMs) has become a trending topic in geospatial artificial intelligence (AI) research due to their potential for achieving high generalizability and domain adaptability, reducing model training costs for individual researchers. Unlike large language models, such as ChatGPT, constructing visual foundation models for image analysis, particularly in remote sensing, encountered significant challenges such as formulating diverse vision tasks into a general problem framework. This paper evaluates the recently released NASA-IBM GFM Prithvi for its predictive performance on high-level image analysis tasks across multiple benchmark datasets. Prithvi was selected because it is one of the first open-source GFMs trained on time-series of high-resolution remote sensing imagery. A series of experiments were designed to assess Prithvi's performance as compared to other pre-trained task-specific AI models in geospatial image analysis. New strategies, including band adaptation, multi-scale feature generation, and fine-tuning techniques, are introduced and integrated into an image analysis pipeline to enhance Prithvi's domain adaptation capability and improve model performance. In-depth analyses reveal Prithvi's strengths and weaknesses, offering insights for both improving Prithvi and developing future visual foundation models for geospatial tasks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00499",
        "abstract url": "https://arxiv.org/abs/2409.00499",
        "title": "DAP: Diffusion-based Affordance Prediction for Multi-modality Storage",
        "rating": "-1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "6D"
            ],
            [
                "Diffusion"
            ],
            [
                "robotic manipulation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Solving storage problem: where objects must be accurately placed into containers with precise orientations and positions, presents a distinct challenge that extends beyond traditional rearrangement tasks. These challenges are primarily due to the need for fine-grained 6D manipulation and the inherent multi-modality of solution spaces, where multiple viable goal configurations exist for the same storage container. We present a novel Diffusion-based Affordance Prediction (DAP) pipeline for the multi-modal object storage problem. DAP leverages a two-step approach, initially identifying a placeable region on the container and then precisely computing the relative pose between the object and that region. Existing methods either struggle with multi-modality issues or computation-intensive training. Our experiments demonstrate DAP's superior performance and training efficiency over the current state-of-the-art RPDiff, achieving remarkable results on the RPDiff benchmark. Additionally, our experiments showcase DAP's data efficiency in real-world applications, an advancement over existing simulation-driven approaches. Our contribution fills a gap in robotic manipulation research by offering a solution that is both computationally efficient and capable of handling real-world variability. Code and supplementary material can be found at: https://github.com/changhaonan/DPS.git.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Paper Accepted by IROS2024. Arxiv version is 8 pages"
    },
    {
        "paper id": "2409.00513",
        "abstract url": "https://arxiv.org/abs/2409.00513",
        "title": "Plant detection from ultra high resolution remote sensing images: A Semantic Segmentation approach based on fuzzy loss",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this study, we tackle the challenge of identifying plant species from ultra high resolution (UHR) remote sensing images. Our approach involves introducing an RGB remote sensing dataset, characterized by millimeter-level spatial resolution, meticulously curated through several field expeditions across a mountainous region in France covering various landscapes. The task of plant species identification is framed as a semantic segmentation problem for its practical and efficient implementation across vast geographical areas. However, when dealing with segmentation masks, we confront instances where distinguishing boundaries between plant species and their background is challenging. We tackle this issue by introducing a fuzzy loss within the segmentation model. Instead of utilizing one-hot encoded ground truth (GT), our model incorporates Gaussian filter refined GT, introducing stochasticity during training. First experimental results obtained on both our UHR dataset and a public dataset are presented, showing the relevance of the proposed methodology, as well as the need for future improvement.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "5 pages, 5 figures, 2 tables"
    },
    {
        "paper id": "2409.00518",
        "abstract url": "https://arxiv.org/abs/2409.00518",
        "title": "Mapping earth mounds from space",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing",
                "satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Regular patterns of vegetation are considered widespread landscapes, although their global extent has never been estimated. Among them, spotted landscapes are of particular interest in the context of climate change. Indeed, regularly spaced vegetation spots in semi-arid shrublands result from extreme resource depletion and prefigure catastrophic shift of the ecosystem to a homogeneous desert, while termite mounds also producing spotted landscapes were shown to increase robustness to climate change. Yet, their identification at large scale calls for automatic methods, for instance using the popular deep learning framework, able to cope with a vast amount of remote sensing data, e.g., optical satellite imagery. In this paper, we tackle this problem and benchmark some state-of-the-art deep networks on several landscapes and geographical areas. Despite the promising results we obtained, we found that more research is needed to be able to map automatically these earth mounds from space.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "6 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2409.00530",
        "abstract url": "https://arxiv.org/abs/2409.00530",
        "title": "Incremental Open-set Domain Adaptation",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Catastrophic forgetting makes neural network models unstable when learning visual domains consecutively. The neural network model drifts to catastrophic forgetting-induced low performance of previously learnt domains when training with new domains. We illuminate this current neural network model weakness and develop a forgetting-resistant incremental learning strategy. Here, we propose a new unsupervised incremental open-set domain adaptation (IOSDA) issue for image classification. Open-set domain adaptation adds complexity to the incremental domain adaptation issue since each target domain has more classes than the Source domain. In IOSDA, the model learns training with domain streams phase by phase in incremented time. Inference uses test data from all target domains without revealing their identities. We proposed IOSDA-Net, a two-stage learning pipeline, to solve the problem. The first module replicates prior domains from random noise using a generative framework and creates a pseudo source domain. In the second step, this pseudo source is adapted to the present target domain. We test our model on Office-Home, DomainNet, and UPRN-RSDA, a newly curated optical remote sensing dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00536",
        "abstract url": "https://arxiv.org/abs/2409.00536",
        "title": "Formal Verification and Control with Conformal Prediction",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "robot",
                "navigation"
            ]
        ],
        "abstract": "In this survey, we design formal verification and control algorithms for autonomous systems with practical safety guarantees using conformal prediction (CP), a statistical tool for uncertainty quantification. We focus on learning-enabled autonomous systems (LEASs) in which the complexity of learning-enabled components (LECs) is a major bottleneck that hampers the use of existing model-based verification and design techniques. Instead, we advocate for the use of CP, and we will demonstrate its use in formal verification, systems and control theory, and robotics. We argue that CP is specifically useful due to its simplicity (easy to understand, use, and modify), generality (requires no assumptions on learned models and data distributions, i.e., is distribution-free), and efficiency (real-time capable and accurate). We pursue the following goals with this survey. First, we provide an accessible introduction to CP for non-experts who are interested in using CP to solve problems in autonomy. Second, we show how to use CP for the verification of LECs, e.g., for verifying input-output properties of neural networks. Third and fourth, we review recent articles that use CP for safe control design as well as offline and online verification of LEASs. We summarize their ideas in a unifying framework that can deal with the complexity of LEASs in a computationally efficient manner. In our exposition, we consider simple system specifications, e.g., robot navigation tasks, as well as complex specifications formulated in temporal logic formalisms. Throughout our survey, we compare to other statistical techniques (e.g., scenario optimization, PAC-Bayes theory, etc.) and how these techniques have been used in verification and control. Lastly, we point the reader to open problems and future research directions.",
        "subjects": [
            "eess.SY",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00544",
        "abstract url": "https://arxiv.org/abs/2409.00544",
        "title": "Large Language Models-Enabled Digital Twins for Precision Medicine in Rare Gynecological Tumors",
        "rating": "-1",
        "keywords": [
            [
                "biomarkers",
                "cancer",
                "clinical",
                "tumor",
                "organ"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Rare gynecological tumors (RGTs) present major clinical challenges due to their low incidence and heterogeneity. The lack of clear guidelines leads to suboptimal management and poor prognosis. Molecular tumor boards accelerate access to effective therapies by tailoring treatment based on biomarkers, beyond cancer type. Unstructured data that requires manual curation hinders efficient use of biomarker profiling for therapy matching. This study explores the use of large language models (LLMs) to construct digital twins for precision medicine in RGTs. Our proof-of-concept digital twin system integrates clinical and biomarker data from institutional and published cases (n=21) and literature-derived data (n=655 publications with n=404,265 patients) to create tailored treatment plans for metastatic uterine carcinosarcoma, identifying options potentially missed by traditional, single-source analysis. LLM-enabled digital twins efficiently model individual patient trajectories. Shifting to a biology-based rather than organ-based tumor definition enables personalized care that could advance RGT management and thus enhance patient outcomes.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "q-bio.QM",
            "stat.ML"
        ],
        "comment": "20 pages, 2 figures, 3 tables, supplements, original article"
    },
    {
        "paper id": "2409.00556",
        "abstract url": "https://arxiv.org/abs/2409.00556",
        "title": "FADE: Few-shot/zero-shot Anomaly Detection Engine using Large Vision-Language Model",
        "rating": "-1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic image anomaly detection is important for quality inspection in the manufacturing industry. The usual unsupervised anomaly detection approach is to train a model for each object class using a dataset of normal samples. However, a more realistic problem is zero-/few-shot anomaly detection where zero or only a few normal samples are available. This makes the training of object-specific models challenging. Recently, large foundation vision-language models have shown strong zero-shot performance in various downstream tasks. While these models have learned complex relationships between vision and language, they are not specifically designed for the tasks of anomaly detection. In this paper, we propose the Few-shot/zero-shot Anomaly Detection Engine (FADE) which leverages the vision-language CLIP model and adjusts it for the purpose of industrial anomaly detection. Specifically, we improve language-guided anomaly segmentation 1) by adapting CLIP to extract multi-scale image patch embeddings that are better aligned with language and 2) by automatically generating an ensemble of text prompts related to industrial anomaly detection. 3) We use additional vision-based guidance from the query and reference images to further improve both zero-shot and few-shot anomaly detection. On the MVTec-AD (and VisA) dataset, FADE outperforms other state-of-the-art methods in anomaly segmentation with pixel-AUROC of 89.6% (91.5%) in zero-shot and 95.4% (97.5%) in 1-normal-shot. Code is available at https://github.com/BMVC-FADE/BMVC-FADE.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 2 figures, Accepted for BMVC 2024"
    },
    {
        "paper id": "2409.00558",
        "abstract url": "https://arxiv.org/abs/2409.00558",
        "title": "Compositional 3D-aware Video Generation with LLM Director",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "text-to-video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Significant progress has been made in text-to-video generation through the use of powerful generative models and large-scale internet data. However, substantial challenges remain in precisely controlling individual concepts within the generated video, such as the motion and appearance of specific characters and the movement of viewpoints. In this work, we propose a novel paradigm that generates each concept in 3D representation separately and then composes them with priors from Large Language Models (LLM) and 2D diffusion models. Specifically, given an input textual prompt, our scheme consists of three stages: 1) We leverage LLM as the director to first decompose the complex query into several sub-prompts that indicate individual concepts within the video~(\\textit{e.g.}, scene, objects, motions), then we let LLM to invoke pre-trained expert models to obtain corresponding 3D representations of concepts. 2) To compose these representations, we prompt multi-modal LLM to produce coarse guidance on the scales and coordinates of trajectories for the objects. 3) To make the generated frames adhere to natural image distribution, we further leverage 2D diffusion priors and use Score Distillation Sampling to refine the composition. Extensive experiments demonstrate that our method can generate high-fidelity videos from text with diverse motion and flexible control over each concept. Project page: \\url{https://aka.ms/c3v}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00565",
        "abstract url": "https://arxiv.org/abs/2409.00565",
        "title": "Two-Stage Hierarchical and Explainable Feature Selection Framework for Dimensionality Reduction in Sleep Staging",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "EEG"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Sleep is crucial for human health, and EEG signals play a significant role in sleep research. Due to the high-dimensional nature of EEG signal data sequences, data visualization and clustering of different sleep stages have been challenges. To address these issues, we propose a two-stage hierarchical and explainable feature selection framework by incorporating a feature selection algorithm to improve the performance of dimensionality reduction. Inspired by topological data analysis, which can analyze the structure of high-dimensional data, we extract topological features from the EEG signals to compensate for the structural information loss that happens in traditional spectro-temporal data analysis. Supported by the topological visualization of the data from different sleep stages and the classification results, the proposed features are proven to be effective supplements to traditional features. Finally, we compare the performances of three dimensionality reduction algorithms: Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE), and Uniform Manifold Approximation and Projection (UMAP). Among them, t-SNE achieved the highest accuracy of 79.8%, but considering the overall performance in terms of computational resources and metrics, UMAP is the optimal choice.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00572",
        "abstract url": "https://arxiv.org/abs/2409.00572",
        "title": "The Persistent Robot Charging Problem for Long-Duration Autonomy",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "This paper introduces a novel formulation aimed at determining the optimal schedule for recharging a fleet of $n$ heterogeneous robots, with the primary objective of minimizing resource utilization. This study provides a foundational framework applicable to Multi-Robot Mission Planning, particularly in scenarios demanding Long-Duration Autonomy (LDA) or other contexts that necessitate periodic recharging of multiple robots. A novel Integer Linear Programming (ILP) model is proposed to calculate the optimal initial conditions (partial charge) for individual robots, leading to the minimal utilization of charging stations. This formulation was further generalized to maximize the servicing time for robots given adequate charging stations. The efficacy of the proposed formulation is evaluated through a comparative analysis, measuring its performance against the thrift price scheduling algorithm documented in the existing literature. The findings not only validate the effectiveness of the proposed approach but also underscore its potential as a valuable tool in optimizing resource allocation for a range of robotic and engineering applications.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00582",
        "abstract url": "https://arxiv.org/abs/2409.00582",
        "title": "CRUD-Capable Mobile Apps with R and shinyMobile: a Case Study in Rapid Prototyping",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "\"Harden\" is a Progressive Web Application (PWA) for Ecological Momentary Assessment (EMA) developed mostly in R, which runs on all platforms with an internet connection, including iOS and Android. It leverages the shinyMobile package for creating a reactive mobile user interface (UI), PostgreSQL for the database backend, and Google Cloud Run for scalable hosting in the cloud, with serverless execution. Using this technology stack, it was possible to rapidly prototype a fully CRUD-capable (Create, Read, Update, Delete) mobile app, with persistent user data across sessions, interactive graphs, and real-time statistical calculation. This framework is compared with current alternative frameworks for creating data science apps; it is argued that the shinyMobile package provides one of the most efficient methods for rapid prototyping and creation of statistical mobile apps that require advanced graphing capabilities. This paper outlines the methodology used to create the Harden application, and discusses the advantages and limitations of the shinyMobile approach to app development. It is hoped that this information will encourage other programmers versed in R to consider developing mobile apps with this framework.",
        "subjects": [
            "cs.SE",
            "stat.ME"
        ],
        "comment": "10 pages, 2 figures"
    },
    {
        "paper id": "2409.00591",
        "abstract url": "https://arxiv.org/abs/2409.00591",
        "title": "Attention-Guided Multi-scale Interaction Network for Face Super-Resolution",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, CNN and Transformer hybrid networks demonstrated excellent performance in face super-resolution (FSR) tasks. Since numerous features at different scales in hybrid networks, how to fuse these multi-scale features and promote their complementarity is crucial for enhancing FSR. However, existing hybrid network-based FSR methods ignore this, only simply combining the Transformer and CNN. To address this issue, we propose an attention-guided Multi-scale interaction network (AMINet), which contains local and global feature interactions as well as encoder-decoder phases feature interactions. Specifically, we propose a Local and Global Feature Interaction Module (LGFI) to promote fusions of global features and different receptive fields' local features extracted by our Residual Depth Feature Extraction Module (RDFE). Additionally, we propose a Selective Kernel Attention Fusion Module (SKAF) to adaptively select fusions of different features within LGFI and encoder-decoder phases. Our above design allows the free flow of multi-scale features from within modules and between encoder and decoder, which can promote the complementarity of different scale features to enhance FSR. Comprehensive experiments confirm that our method consistently performs well with less computational consumption and faster inference.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 8 figures, 8 tables"
    },
    {
        "paper id": "2409.00603",
        "abstract url": "https://arxiv.org/abs/2409.00603",
        "title": "Uncertainty-oriented Order Learning for Facial Beauty Prediction",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Previous Facial Beauty Prediction (FBP) methods generally model FB feature of an image as a point on the latent space, and learn a mapping from the point to a precise score. Although existing regression methods perform well on a single dataset, they are inclined to be sensitive to test data and have weak generalization ability. We think they underestimate two inconsistencies existing in the FBP problem: 1. inconsistency of FB standards among multiple datasets, and 2. inconsistency of human cognition on FB of an image. To address these issues, we propose a new Uncertainty-oriented Order Learning (UOL), where the order learning addresses the inconsistency of FB standards by learning the FB order relations among face images rather than a mapping, and the uncertainty modeling represents the inconsistency in human cognition. The key contribution of UOL is a designed distribution comparison module, which enables conventional order learning to learn the order of uncertain data. Extensive experiments on five datasets show that UOL outperforms the state-of-the-art methods on both accuracy and generalization ability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00605",
        "abstract url": "https://arxiv.org/abs/2409.00605",
        "title": "Average-case optimization analysis for distributed consensus algorithms on regular graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "The consensus problem in distributed computing involves a network of agents aiming to compute the average of their initial vectors through local communication, represented by an undirected graph. This paper focuses on the studying of this problem using an average-case analysis approach, particularly over regular graphs. Traditional algorithms for solving the consensus problem often rely on worst-case performance evaluation scenarios, which may not reflect typical performance in real-world applications. Instead, we apply average-case analysis, focusing on the expected spectral distribution of eigenvalues to obtain a more realistic view of performance. Key contributions include deriving the optimal method for consensus on regular graphs, showing its relation to the Heavy Ball method, analyzing its asymptotic convergence rate, and comparing it to various first-order methods through numerical experiments.",
        "subjects": [
            "math.OC",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00374",
        "abstract url": "https://arxiv.org/abs/2409.00374",
        "title": "Towards understanding Diffusion Models (on Graphs)",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models have emerged from various theoretical and methodological perspectives, each offering unique insights into their underlying principles. In this work, we provide an overview of the most prominent approaches, drawing attention to their striking analogies -- namely, how seemingly diverse methodologies converge to a similar mathematical formulation of the core problem. While our ultimate goal is to understand these models in the context of graphs, we begin by conducting experiments in a simpler setting to build foundational insights. Through an empirical investigation of different diffusion and sampling techniques, we explore three critical questions: (1) What role does noise play in these models? (2) How significantly does the choice of the sampling method affect outcomes? (3) What function is the neural network approximating, and is high complexity necessary for optimal performance? Our findings aim to enhance the understanding of diffusion models and in the long run their application in graph machine learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00400",
        "abstract url": "https://arxiv.org/abs/2409.00400",
        "title": "An Enhanced Batch Query Architecture in Real-time Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial",
                "Recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In industrial recommendation systems on websites and apps, it is essential to recall and predict top-n results relevant to user interests from a content pool of billions within milliseconds. To cope with continuous data growth and improve real-time recommendation performance, we have designed and implemented a high-performance batch query architecture for real-time recommendation systems. Our contributions include optimizing hash structures with a cacheline-aware probing method to enhance coalesced hashing, as well as the implementation of a hybrid storage key-value service built upon it. Our experiments indicate this approach significantly surpasses conventional hash tables in batch query throughput, achieving up to 90% of the query throughput of random memory access when incorporating parallel optimization. The support for NVMe, integrating two-tier storage for hot and cold data, notably reduces resource consumption. Additionally, the system facilitates dynamic updates, automated sharding of attributes and feature embedding tables, and introduces innovative protocols for consistency in batch queries, thereby enhancing the effectiveness of real-time incremental learning updates. This architecture has been deployed and in use in the bilibili recommendation system for over a year, a video content community with hundreds of millions of users, supporting 10x increase in model computation with minimal resource growth, improving outcomes while preserving the system's real-time performance.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": "8 pages, 10 figures, CIKM 2024 Applied Research Paper"
    },
    {
        "paper id": "2409.00458",
        "abstract url": "https://arxiv.org/abs/2409.00458",
        "title": "Dynamical system prediction from sparse observations using deep neural networks with Voronoi tessellation and physics constraint",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the success of various methods in addressing the issue of spatial reconstruction of dynamical systems with sparse observations, spatio-temporal prediction for sparse fields remains a challenge. Existing Kriging-based frameworks for spatio-temporal sparse field prediction fail to meet the accuracy and inference time required for nonlinear dynamic prediction problems. In this paper, we introduce the Dynamical System Prediction from Sparse Observations using Voronoi Tessellation (DSOVT) framework, an innovative methodology based on Voronoi tessellation which combines convolutional encoder-decoder (CED) and long short-term memory (LSTM) and utilizing Convolutional Long Short-Term Memory (ConvLSTM). By integrating Voronoi tessellations with spatio-temporal deep learning models, DSOVT is adept at predicting dynamical systems with unstructured, sparse, and time-varying observations. CED-LSTM maps Voronoi tessellations into a low-dimensional representation for time series prediction, while ConvLSTM directly uses these tessellations in an end-to-end predictive model. Furthermore, we incorporate physics constraints during the training process for dynamical systems with explicit formulas. Compared to purely data-driven models, our physics-based approach enables the model to learn physical laws within explicitly formulated dynamics, thereby enhancing the robustness and accuracy of rolling forecasts. Numerical experiments on real sea surface data and shallow water systems clearly demonstrate our framework's accuracy and computational efficiency with sparse and time-varying observations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00485",
        "abstract url": "https://arxiv.org/abs/2409.00485",
        "title": "Advancing Machine Learning in Industry 4.0: Benchmark Framework for Rare-event Prediction in Chemical Processes",
        "rating": "-1.5",
        "keywords": [
            [
                "Chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Previously, using forward-flux sampling (FFS) and machine learning (ML), we developed multivariate alarm systems to counter rare un-postulated abnormal events. Our alarm systems utilized ML-based predictive models to quantify committer probabilities as functions of key process variables (e.g., temperature, concentrations, and the like), with these data obtained in FFS simulations. Herein, we introduce a novel and comprehensive benchmark framework for rare-event prediction, comparing ML algorithms of varying complexity, including Linear Support-Vector Regressor and k-Nearest Neighbors, to more sophisticated algorithms, such as Random Forests, XGBoost, LightGBM, CatBoost, Dense Neural Networks, and TabNet. This evaluation uses comprehensive performance metrics, such as: $\\textit{RMSE}$, model training, testing, hyperparameter tuning and deployment times, and number and efficiency of alarms. These balance model accuracy, computational efficiency, and alarm-system efficiency, identifying optimal ML strategies for predicting abnormal rare events, enabling operators to obtain safer and more reliable plant operations.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "eess.SY"
        ],
        "comment": "This is a preprint for our manuscript to be submitted for publication in Computers and Chemical Engineering Journal. Pages: 22 (including Appendix and References). Figures: 9 (main) + 3 (Appendix). Tables: 3 (main) + 3 (Appendix)"
    },
    {
        "paper id": "2409.00588",
        "abstract url": "https://arxiv.org/abs/2409.00588",
        "title": "Diffusion Policy Policy Optimization",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce Diffusion Policy Policy Optimization, DPPO, an algorithmic framework including best practices for fine-tuning diffusion-based policies (e.g. Diffusion Policy) in continuous control and robot learning tasks using the policy gradient (PG) method from reinforcement learning (RL). PG methods are ubiquitous in training RL policies with other policy parameterizations; nevertheless, they had been conjectured to be less efficient for diffusion-based policies. Surprisingly, we show that DPPO achieves the strongest overall performance and efficiency for fine-tuning in common benchmarks compared to other RL methods for diffusion-based policies and also compared to PG fine-tuning of other policy parameterizations. Through experimental investigation, we find that DPPO takes advantage of unique synergies between RL fine-tuning and the diffusion parameterization, leading to structured and on-manifold exploration, stable training, and strong policy robustness. We further demonstrate the strengths of DPPO in a range of realistic settings, including simulated robotic tasks with pixel observations, and via zero-shot deployment of simulation-trained policies on robot hardware in a long-horizon, multi-stage manipulation task. Website with code: diffusion-ppo.github.io",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Website: diffusion-ppo.github.io"
    },
    {
        "paper id": "2409.00368",
        "abstract url": "https://arxiv.org/abs/2409.00368",
        "title": "Facilitating AI and System Operator Synergy: Active Learning-Enhanced Digital Twin Architecture for Day-Ahead Load Forecasting",
        "rating": "-2",
        "keywords": [
            [
                "Forecasting"
            ]
        ],
        "abstract": "In this paper, we introduce a synergistic approach between artificial intelligence and system operators through an innovative digital twin architecture, integrated with an active learning framework, to enhance short-term load forecasting. Central to this architecture is the incorporation of sophisticated data pipelines, facilitating the real-time ingestion, processing and analysis of grid-related data. Utilizing a recurrent neural network architecture, our model generates day-ahead load forecasts together with prediction confidence intervals, strengthening system operator trust in the model's predictive reliability and enhancing their ability to respond to evolving grid conditions effectively. The active learning framework iteratively refines the predictions by incorporating real-time feedback based on forecast uncertainty, utilizing newly available data to continuously enhance forecasting accuracy and confidence. This AI-assisted strategy is exemplified in a case study of the Greek transmission system. It demonstrates the potential to transform short-term load forecasting, thereby increasing the reliability and operational efficiency of modern power grids. This approach marks a significant step forward in the digitalization and intelligent management of power systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00372",
        "abstract url": "https://arxiv.org/abs/2409.00372",
        "title": "First Competition on Presentation Attack Detection on ID Card",
        "rating": "-2",
        "keywords": [
            [
                "Attack"
            ],
            [
                "Biometrics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper summarises the Competition on Presentation Attack Detection on ID Cards (PAD-IDCard) held at the 2024 International Joint Conference on Biometrics (IJCB2024). The competition attracted a total of ten registered teams, both from academia and industry. In the end, the participating teams submitted five valid submissions, with eight models to be evaluated by the organisers. The competition presented an independent assessment of current state-of-the-art algorithms. Today, no independent evaluation on cross-dataset is available; therefore, this work determined the state-of-the-art on ID cards. To reach this goal, a sequestered test set and baseline algorithms were used to evaluate and compare all the proposals. The sequestered test dataset contains ID cards from four different countries. In summary, a team that chose to be \"Anonymous\" reached the best average ranking results of 74.80%, followed very closely by the \"IDVC\" team with 77.65%.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00387",
        "abstract url": "https://arxiv.org/abs/2409.00387",
        "title": "Progressive Residual Extraction based Pre-training for Speech Representation Learning",
        "rating": "-2",
        "keywords": [
            [
                "speech enhancement"
            ],
            [
                "voice conversion"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Self-supervised learning (SSL) has garnered significant attention in speech processing, excelling in linguistic tasks such as speech recognition. However, jointly improving the performance of pre-trained models on various downstream tasks, each requiring different speech information, poses significant challenges. To this purpose, we propose a progressive residual extraction based self-supervised learning method, named ProgRE. Specifically, we introduce two lightweight and specialized task modules into an encoder-style SSL backbone to enhance its ability to extract pitch variation and speaker information from speech. Furthermore, to prevent the interference of reinforced pitch variation and speaker information with irrelevant content information learning, we residually remove the information extracted by these two modules from the main branch. The main branch is then trained using HuBERT's speech masking prediction to ensure the performance of the Transformer's deep-layer features on content tasks. In this way, we can progressively extract pitch variation, speaker, and content representations from the input speech. Finally, we can combine multiple representations with diverse speech information using different layer weights to obtain task-specific representations for various downstream tasks. Experimental results indicate that our proposed method achieves joint performance improvements on various tasks, such as speaker identification, speech recognition, emotion recognition, speech enhancement, and voice conversion, compared to excellent SSL methods such as wav2vec2.0, HuBERT, and WavLM.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00404",
        "abstract url": "https://arxiv.org/abs/2409.00404",
        "title": "Expanding self-orthogonal codes over a ring $\\Z_4$ to self-dual codes and unimodular lattices",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Self-dual codes have been studied actively because they are connected with mathematical structures including block designs and lattices and have practical applications in quantum error-correcting codes and secret sharing schemes. Nevertheless, there has been less attention to construct self-dual codes from self-orthogonal codes with smaller dimensions. Hence, the main purpose of this paper is to propose a way to expand any self-orthogonal code over a ring $\\Z_4$ to many self-dual codes over $\\Z_4$. We show that all self-dual codes over $\\Z_4$ of lengths $4$ to $8$ can be constructed this way. Furthermore, we have found five new self-dual codes over $\\Z_4$ of lengths $27, 28, 29, 33,$ and $34$ with the highest Euclidean weight $12$. Moreover, using Construction $A$ applied to our new Euclidean-optimal self-dual codes over $\\Z_4$, we have constructed a new odd extremal unimodular lattice in dimension 34 whose kissing number was not previously known.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00442",
        "abstract url": "https://arxiv.org/abs/2409.00442",
        "title": "Separation of Body and Background in Radiological Images. A Practical Python Code",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "MRI",
                "CT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Radiological images, such as magnetic resonance imaging (MRI) and computed tomography (CT) images, typically consist of a body part and a dark background. For many analyses, it is necessary to separate the body part region from the background. In this article, we present a Python code designed to separate body and background regions in 2D and 3D radiological images. We tested the algorithm on various MRI and CT images of different body parts, including the brain, neck, and abdominal regions. Additionally, we introduced a method for intensity normalization and outlier restriction, adjusted for data conversion into 8-bit unsigned integer (UINT8) format, and examined its effects on body-background separation. Our Python code is available for use with proper citation.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "14 pages, 8 figures"
    },
    {
        "paper id": "2409.00444",
        "abstract url": "https://arxiv.org/abs/2409.00444",
        "title": "Personalized Pricing Decisions Through Adversarial Risk Analysis",
        "rating": "-2",
        "keywords": [
            [
                "forecast"
            ]
        ],
        "abstract": "Pricing decisions stand out as one of the most critical tasks a company faces, particularly in today's digital economy. As with other business decision-making problems, pricing unfolds in a highly competitive and uncertain environment. Traditional analyses in this area have heavily relied on game theory and its variants. However, an important drawback of these approaches is their reliance on common knowledge assumptions, which are hardly tenable in competitive business domains. This paper introduces an innovative personalized pricing framework designed to assist decision-makers in undertaking pricing decisions amidst competition, considering both buyer's and competitors' preferences. Our approach (i) establishes a coherent framework for modeling competition mitigating common knowledge assumptions; (ii) proposes a principled method to forecast competitors' pricing and customers' purchasing decisions, acknowledging major business uncertainties; and, (iii) encourages structured thinking about the competitors' problems, thus enriching the solution process. To illustrate these properties, in addition to a general pricing template, we outline two specifications - one from the retail domain and a more intricate one from the pension fund domain.",
        "subjects": [
            "cs.GT",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00475",
        "abstract url": "https://arxiv.org/abs/2409.00475",
        "title": "BaseMirror: Automatic Reverse Engineering of Baseband Commands from Android's Radio Interface Layer",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "attack"
            ]
        ],
        "abstract": "In modern mobile devices, baseband is an integral component running on top of cellular processors to handle crucial radio communications. However, recent research reveals significant vulnerabilities in these basebands, posing serious security risks like remote code execution. Yet, effectively scrutinizing basebands remains a daunting task, as they run closed-source and proprietary software on vendor-specific chipsets. Existing analysis methods are limited by their dependence on manual processes and heuristic approaches, reducing their scalability. This paper introduces a novel approach to unveil security issues in basebands from a unique perspective: to uncover vendor-specific baseband commands from the Radio Interface Layer (RIL), a hardware abstraction layer interfacing with basebands. To demonstrate this concept, we have designed and developed BaseMirror, a static binary analysis tool to automatically reverse engineer baseband commands from vendor-specific RIL binaries. It utilizes a bidirectional taint analysis algorithm to adeptly identify baseband commands from an enhanced control flow graph enriched with reconstructed virtual function calls. Our methodology has been applied to 28 vendor RIL libraries, encompassing a wide range of Samsung Exynos smartphone models on the market. Remarkably, BaseMirror has uncovered 873 unique baseband commands undisclosed to the public. Based on these results, we develop an automated attack discovery framework to successfully derive and validate 8 zero-day vulnerabilities that trigger denial of cellular service and arbitrary file access on a Samsung Galaxy A53 device. These findings have been reported and confirmed by Samsung and a bug bounty was awarded to us.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This is the extended version of the CCS 2024 paper with the same title"
    },
    {
        "paper id": "2409.00501",
        "abstract url": "https://arxiv.org/abs/2409.00501",
        "title": "Leaky Wave Antenna-Equipped RF Chipless Tags for Orientation Estimation",
        "rating": "-2",
        "keywords": [
            [
                "radar"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "Accurate orientation estimation of an object in a scene is critical in robotics, aerospace, augmented reality, and medicine, as it supports scene understanding. This paper introduces a novel orientation estimation approach leveraging radio frequency (RF) sensing technology and leaky-wave antennas (LWAs). Specifically, we propose a framework for a radar system to estimate the orientation of a \\textit{dumb} LWA-equipped backscattering tag, marking the first exploration of this method in the literature. Our contributions include a comprehensive framework for signal modeling and orientation estimation with multi-subcarrier transmissions, and the formulation of a maximum likelihood estimator (MLE). Moreover, we analyze the impact of imperfect tag location information, revealing that it minimally affects estimation accuracy. Exploiting related results, we propose an approximate MLE and introduce a low-complexity radiation-pointing angle-based estimator with near-optimal performance. We derive the feasible orientation estimation region of the latter and show that it depends mainly on the system bandwidth. Our analytical results are validated through Monte Carlo simulations and reveal that the low-complexity estimator achieves near-optimal accuracy and that its feasible orientation estimation region is also approximately shared by the other estimators. Finally, we show that the optimal number of subcarriers increases with sensing time under a power budget constraint.",
        "subjects": [
            "eess.SP",
            "eess.SY"
        ],
        "comment": "14 pages, 2 tables, 8 figs. Submitted to IEEE TWC"
    },
    {
        "paper id": "2409.00552",
        "abstract url": "https://arxiv.org/abs/2409.00552",
        "title": "Digit Recognition using Multimodal Spiking Neural Networks",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "biologically"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Spiking neural networks (SNNs) are the third generation of neural networks that are biologically inspired to process data in a fashion that emulates the exchange of signals in the brain. Within the Computer Vision community SNNs have garnered significant attention due in large part to the availability of event-based sensors that produce a spatially resolved spike train in response to changes in scene radiance. SNNs are used to process event-based data due to their neuromorphic nature. The proposed work examines the neuromorphic advantage of fusing multiple sensory inputs in classification tasks. Specifically we study the performance of a SNN in digit classification by passing in a visual modality branch (Neuromorphic-MNIST [N-MNIST]) and an auditory modality branch (Spiking Heidelberg Digits [SHD]) from datasets that were created using event-based sensors to generate a series of time-dependent events. It is observed that multi-modal SNNs outperform unimodal visual and unimodal auditory SNNs. Furthermore, it is observed that the process of sensory fusion is insensitive to the depth at which the visual and auditory branches are combined. This work achieves a 98.43% accuracy on the combined N-MNIST and SHD dataset using a multimodal SNN that concatenates the visual and auditory branches at a late depth.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "4 pages, 2 figures, submitted to 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing"
    },
    {
        "paper id": "2409.00577",
        "abstract url": "https://arxiv.org/abs/2409.00577",
        "title": "Fast Prototyping of Distributed Stream Processing Applications with stream2gym",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Stream processing applications have been widely adopted due to real-time data analytics demands, e.g., fraud detection, video analytics, IoT applications. Unfortunately, prototyping and testing these applications is still a cumbersome process for developers that usually requires an expensive testbed and deep multi-disciplinary expertise, including in areas such as networking, distributed systems, and data engineering. As a result, it takes a long time to deploy stream processing applications into production and yet users face several correctness and performance issues. In this paper, we present stream2gym, a tool for the fast prototyping of large-scale distributed stream processing applications. stream2gym builds on Mininet, a widely adopted network emulation platform, and provides a high-level interface to enable developers to easily test their applications under various operating conditions. We demonstrate the benefits of stream2gym by prototyping and testing several applications as well as reproducing key findings from prior research work in video analytics and network traffic monitoring. Moreover, we show stream2gym presents accurate results compared to a hardware testbed while consuming a small amount of resources (enough to be supported in a single commodity laptop even when emulating a dozen of processing nodes).",
        "subjects": [
            "cs.DC",
            "cs.NI"
        ],
        "comment": "11 pages, 9 figures (excluding subfigures), accepted in IEEE ICDCS 2023"
    },
    {
        "paper id": "2409.00585",
        "abstract url": "https://arxiv.org/abs/2409.00585",
        "title": "McCaD: Multi-Contrast MRI Conditioned, Adaptive Adversarial Diffusion Model for High-Fidelity MRI Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "MRI",
                "clinical",
                "tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Magnetic Resonance Imaging (MRI) is instrumental in clinical diagnosis, offering diverse contrasts that provide comprehensive diagnostic information. However, acquiring multiple MRI contrasts is often constrained by high costs, long scanning durations, and patient discomfort. Current synthesis methods, typically focused on single-image contrasts, fall short in capturing the collective nuances across various contrasts. Moreover, existing methods for multi-contrast MRI synthesis often fail to accurately map feature-level information across multiple imaging contrasts. We introduce McCaD (Multi-Contrast MRI Conditioned Adaptive Adversarial Diffusion), a novel framework leveraging an adversarial diffusion model conditioned on multiple contrasts for high-fidelity MRI synthesis. McCaD significantly enhances synthesis accuracy by employing a multi-scale, feature-guided mechanism, incorporating denoising and semantic encoders. An adaptive feature maximization strategy and a spatial feature-attentive loss have been introduced to capture more intrinsic features across multiple contrasts. This facilitates a precise and comprehensive feature-guided denoising process. Extensive experiments on tumor and healthy multi-contrast MRI datasets demonstrated that the McCaD outperforms state-of-the-art baselines quantitively and qualitatively. The code is provided with supplementary materials.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00587",
        "abstract url": "https://arxiv.org/abs/2409.00587",
        "title": "FLUX that Plays Music",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Music",
                "text-to-music"
            ],
            [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper explores a simple extension of diffusion-based rectified flow Transformers for text-to-music generation, termed as FluxMusic. Generally, along with design in advanced Flux\\footnote{https://github.com/black-forest-labs/flux} model, we transfers it into a latent VAE space of mel-spectrum. It involves first applying a sequence of independent attention to the double text-music stream, followed by a stacked single music stream for denoised patch prediction. We employ multiple pre-trained text encoders to sufficiently capture caption semantic information as well as inference flexibility. In between, coarse textual information, in conjunction with time step embeddings, is utilized in a modulation mechanism, while fine-grained textual details are concatenated with the music patch sequence as inputs. Through an in-depth study, we demonstrate that rectified flow training with an optimized architecture significantly outperforms established diffusion methods for the text-to-music task, as evidenced by various automatic metrics and human preference evaluations. Our experimental data, code, and model weights are made publicly available at: \\url{https://github.com/feizc/FluxMusic}.",
        "subjects": [
            "cs.SD",
            "cs.CV",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00593",
        "abstract url": "https://arxiv.org/abs/2409.00593",
        "title": "Online Temporal Fusion for Vectorized Map Construction in Mapless Autonomous Driving",
        "rating": "-2",
        "keywords": [
            [
                "voxel"
            ],
            [
                "Autonomous Driving"
            ]
        ],
        "abstract": "To reduce the reliance on high-definition (HD) maps, a growing trend in autonomous driving is leveraging on-board sensors to generate vectorized maps online. However, current methods are mostly constrained by processing only single-frame inputs, which hampers their robustness and effectiveness in complex scenarios. To overcome this problem, we propose an online map construction system that exploits the long-term temporal information to build a consistent vectorized map. First, the system efficiently fuses all historical road marking detections from an off-the-shelf network into a semantic voxel map, which is implemented using a hashing-based strategy to exploit the sparsity of road elements. Then reliable voxels are found by examining the fused information and incrementally clustered into an instance-level representation of road markings. Finally, the system incorporates domain knowledge to estimate the geometric and topological structures of roads, which can be directly consumed by the planning and control (PnC) module. Through experiments conducted in complicated urban environments, we have demonstrated that the output of our system is more consistent and accurate than the network output by a large margin and can be effectively used in a closed-loop autonomous driving system.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 9 figures"
    },
    {
        "paper id": "2409.00610",
        "abstract url": "https://arxiv.org/abs/2409.00610",
        "title": "ProteinRPN: Towards Accurate Protein Function Prediction with Graph-Based Region Proposals",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "bioinformatics",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Protein function prediction is a crucial task in bioinformatics, with significant implications for understanding biological processes and disease mechanisms. While the relationship between sequence and function has been extensively explored, translating protein structure to function continues to present substantial challenges. Various models, particularly, CNN and graph-based deep learning approaches that integrate structural and functional data, have been proposed to address these challenges. However, these methods often fall short in elucidating the functional significance of key residues essential for protein functionality, as they predominantly adopt a retrospective perspective, leading to suboptimal performance. Inspired by region proposal networks in computer vision, we introduce the Protein Region Proposal Network (ProteinRPN) for accurate protein function prediction. Specifically, the region proposal module component of ProteinRPN identifies potential functional regions (anchors) which are refined through the hierarchy-aware node drop pooling layer favoring nodes with defined secondary structures and spatial proximity. The representations of the predicted functional nodes are enriched using attention mechanisms and subsequently fed into a Graph Multiset Transformer, which is trained with supervised contrastive (SupCon) and InfoNCE losses on perturbed protein structures. Our model demonstrates significant improvements in predicting Gene Ontology (GO) terms, effectively localizing functional residues within protein structures. The proposed framework provides a robust, scalable solution for protein function annotation, advancing the understanding of protein structure-function relationships in computational biology.",
        "subjects": [
            "q-bio.QM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00375",
        "abstract url": "https://arxiv.org/abs/2409.00375",
        "title": "Statistical Distance-Guided Unsupervised Domain Adaptation for Automated Multi-Class Cardiovascular Magnetic Resonance Image Quality Assessment",
        "rating": "-3",
        "keywords": [
            [
                "cardiac"
            ],
            [
                "Quality Assessment"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "This study proposes an attention-based statistical distance-guided unsupervised domain adaptation model for multi-class cardiovascular magnetic resonance (CMR) image quality assessment. The proposed model consists of a feature extractor, a label predictor and a statistical distance estimator. An annotated dataset as the source set and an unlabeled dataset as the target set with different statistical distributions are considered inputs. The statistical distance estimator approximates the Wasserstein distance between the extracted feature vectors from the source and target data in a mini-batch. The label predictor predicts data labels of source data and uses a combinational loss function for training, which includes cross entropy and centre loss functions plus the estimated value of the distance estimator. Four datasets, including imaging and k-space data, were used to evaluate the proposed model in identifying four common CMR imaging artefacts: respiratory and cardiac motions, Gibbs ringing and Aliasing. The results of the extensive experiments showed that the proposed model, both in image and k-space analysis, has an acceptable performance in covering the domain shift between the source and target sets. The model explainability evaluations and the ablation studies confirmed the proper functioning and effectiveness of all the model's modules. The proposed model outperformed the previous studies regarding performance and the number of examined artefacts. The proposed model can be used for CMR post-imaging quality control or in large-scale cohort studies for image and k-space quality assessment due to the appropriate performance in domain shift coverage without a tedious data-labelling process.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00383",
        "abstract url": "https://arxiv.org/abs/2409.00383",
        "title": "\"I Wanted to Create my Ideal Self\": Exploring Avatar Perception of LGBTQ+ Users for Therapy in Virtual Reality",
        "rating": "-3",
        "keywords": [
            [
                "Avatar"
            ],
            [
                "health",
                "physiological"
            ]
        ],
        "abstract": "In this paper we explore the potential of utilizing Virtual Reality (VR) as a therapeutic tool for supporting individuals in the LGBTQ+ community, who often face elevated risks of mental health issues. Specifically, we investigated the effectiveness of using pre-existing avatars compared to allowing individuals to create their own avatars through a website, and their experience in a VR space when using these avatars. We conducted a user study (n=10) measuring heart rate variability (HRV) and gathering subjective feedback through semi-structured interviews conducted in VR. Avatar creation was facilitated using an online platform, and conversations took place within a two-user VR space developed in a commercially available VR application. Our findings suggest that users significantly prefer creating their own avatars in the context of therapy sessions, and while there was no statistically significant difference, there was a consistent trend of enhanced physiological response when using self-made avatars in VR. This study provides initial empirical support for the importance of custom avatar creation in utilizing VR for therapy within the LGBTQ+ community.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00395",
        "abstract url": "https://arxiv.org/abs/2409.00395",
        "title": "Self-supervised Fusarium Head Blight Detection with Hyperspectral Image and Feature Mining",
        "rating": "-3",
        "keywords": [
            [
                "Diagnosis",
                "disease"
            ],
            [
                "Remote Sensing",
                "Hyperspectral Image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Fusarium Head Blight (FHB) is a serious fungal disease affecting wheat (including durum), barley, oats, other small cereal grains, and corn. Effective monitoring and accurate detection of FHB are crucial to ensuring stable and reliable food security. Traditionally, trained agronomists and surveyors perform manual identification, a method that is labor-intensive, impractical, and challenging to scale. With the advancement of deep learning and Hyper-spectral Imaging (HSI) and Remote Sensing (RS) technologies, employing deep learning, particularly Convolutional Neural Networks (CNNs), has emerged as a promising solution. Notably, wheat infected with serious FHB may exhibit significant differences on the spectral compared to mild FHB one, which is particularly advantageous for hyperspectral image-based methods. In this study, we propose a self-unsupervised classification method based on HSI endmember extraction strategy and top-K bands selection, designed to analyze material signatures in HSIs to derive discriminative feature representations. This approach does not require expensive device or complicate algorithm design, making it more suitable for practical uses. Our method has been effectively validated in the Beyond Visible Spectrum: AI for Agriculture Challenge 2024. The source code is easy to reproduce and available at {https://github.com/VanLinLin/Automated-Crop-Disease-Diagnosis-from-Hyperspectral-Imagery-3rd}.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Beyond Visible Spectrum: AI for Agriculture Challenge, in conjunted with ICPR 2024"
    },
    {
        "paper id": "2409.00405",
        "abstract url": "https://arxiv.org/abs/2409.00405",
        "title": "UAV-Enabled Wireless Networks for Integrated Sensing and Learning-Oriented Communication",
        "rating": "-3",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Future wireless networks are envisioned to support both sensing and artificial intelligence (AI) services. However, conventional integrated sensing and communication (ISAC) networks may not be suitable due to the ignorance of diverse task-specific data utilities in different AI applications. In this letter, a full-duplex unmanned aerial vehicle (UAV)-enabled wireless network providing sensing and edge learning services is investigated. To maximize the learning performance while ensuring sensing quality, a convergence-guaranteed iterative algorithm is developed to jointly determine the uplink time allocation, as well as UAV trajectory and transmit power. Simulation results show that the proposed algorithm significantly outperforms the baselines and demonstrate the critical tradeoff between sensing and learning performance.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "5 pages and 6 figures. This article was submitted to IEEE for possible publication"
    },
    {
        "paper id": "2409.00497",
        "abstract url": "https://arxiv.org/abs/2409.00497",
        "title": "Security Loophole Induced by Photorefractive Effect in Continous-variable Quantum Key Distribution System",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Modulators based on the Mach-Zehnder interferometer (MZI) structure are widely used in continuous-variable quantum key distribution (CVQKD) systems. MZI-based variable optical attenuator (VOA) and amplitude modulator can reshape the waveform and control the intensity of coherent state signal to realize secret key information modulation in CVQKD system. However, these devices are not ideal, internal and external effects like non-linear effect and temperature may degrade their performance. In this paper, we analyzed the security loophole of CVQKD under the photorefractive effect (PE), which originates from the crystal characteristic of lithium niobate (LN). It is found that the refractive index change of modulators because of PE may lead to an overestimate or underestimate of the final secret key rate. This allows Eve to perform further attacks like intercept-resend to get more secret key information. To solve this problem, several countermeasures are proposed, which can effectively eliminate potential risks.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00594",
        "abstract url": "https://arxiv.org/abs/2409.00594",
        "title": "CSAC Drift Modeling Considering GPS Signal Quality in the Case of GPS Signal Unavailability",
        "rating": "-3",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "The Global Positioning System (GPS), one of the Global Navigation Satellite Systems (GNSS), provides accurate position, navigation and time (PNT) information to various applications. One of the application that is highly receiving attention is satellite vehicles, especially Low Earth Orbit (LEO) satellites. Due to their limited ways to get PNT information and low performance of their onboard clocks, GPS system time (GPST) provided by GPS is a good reference clock to synchronize. However, GPS is well-known for its vulnerability to intentional or unintentional interference. This study aims to maintain the onboard clock with less error relative to the GPST even when the GPS signal is disrupted. In this study, we analyzed two major factors that affects the quality of the GPS measurements: the number of the visible satellites and the geometry of the satellites. Then, we proposed a weighted model for a Chip-Scale Atomic Clock (CSAC) that mitigates the clock error relative to the GPST while considering the two factors. Based on this model, a stand-alone CSAC could maintain its error less than 4 microseconds, even in a situation where no GPS signals are received for 12 hours.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.00393",
        "abstract url": "https://arxiv.org/abs/2409.00393",
        "title": "Lyapunov Neural ODE Feedback Control Policies",
        "rating": "-3.5",
        "keywords": [
            [
                "biomedical"
            ],
            [
                "thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep neural networks are increasingly used as an effective way to represent control policies in a wide-range of learning-based control methods. For continuous-time optimal control problems (OCPs), which are central to many decision-making tasks, control policy learning can be cast as a neural ordinary differential equation (NODE) problem wherein state and control constraints are naturally accommodated. This paper presents a Lyapunov-NODE control (L-NODEC) approach to solving continuous-time OCPs for the case of stabilizing a known constrained nonlinear system around a terminal equilibrium point. We propose a Lyapunov loss formulation that incorporates a control-theoretic Lyapunov condition into the problem of learning a state-feedback neural control policy. We establish that L-NODEC ensures exponential stability of the controlled system, as well as its adversarial robustness to uncertain initial conditions. The performance of L-NODEC is illustrated on a benchmark double integrator problem and for optimal control of thermal dose delivery using a cold atmospheric plasma biomedical system. L-NODEC can substantially reduce the inference time necessary to reach the equilibrium state.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00529",
        "abstract url": "https://arxiv.org/abs/2409.00529",
        "title": "Type-Based Verification of Connectivity Constraints in Lattice Surgery",
        "rating": "-5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "Surgery"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Fault-tolerant quantum computation using lattice surgery can be abstracted as operations on graphs, wherein each logical qubit corresponds to a vertex of the graph, and multi-qubit measurements are accomplished by connecting the vertices with paths between them. Operations attempting to connect vertices without a valid path will result in abnormal termination. As the permissible paths may evolve during execution, it is necessary to statically verify that the execution of a quantum program can be completed. This paper introduces a type-based method to statically verify that well-typed programs can be executed without encountering halts induced by surgery operations. Alongside, we present $\\mathcal{Q}_{LS}$, a first-order quantum programming language to formalize the execution model of surgery operations. Furthermore, we provide a type checking algorithm by reducing the type checking problem to the offline dynamic connectivity problem.",
        "subjects": [
            "quant-ph",
            "cs.PL"
        ],
        "comment": "29 pages, the extended version of the paper accepted by APLAS 2024"
    },
    {
        "paper id": "2409.00364",
        "abstract url": "https://arxiv.org/abs/2409.00364",
        "title": "Resource Management for IRS-Assisted Full-Duplex Integrated Sensing, Communication and Computing Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate an intelligent reflecting surface (IRS) assisted full-duplex (FD) integrated sensing, communication and computing system. Specifically, an FD base station (BS) provides service for uplink and downlink transmission, and a local cache is connected to the BS through a backhaul link to store data. Meanwhile, active sensing elements are deployed on the IRS to receive target echo signals. On this basis, in order to evaluate the overall performance of the system under consideration, we propose a system utility maximization problem while ensuring the sensing quality, expressed as the difference between the sum of communication throughput, total computation bits (offloading bits and local computation bits) and the total backhaul cost for content delivery. This makes the problem difficult to solve due to the highly non-convex coupling of the optimization variables. To effectively solve this problem, we first design the most effective caching strategy. Then, we develop an algorithm based on weighted minimum mean square error, alternative direction method of multipliers, majorization-minimization framework, semi-definite relaxation techniques, and several complex transformations to jointly solve the optimization variables. Finally, simulation results are provided to verify the utility performance of the proposed algorithm and demonstrate the advantages of the proposed scheme compared with the baseline scheme.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00367",
        "abstract url": "https://arxiv.org/abs/2409.00367",
        "title": "Distributionally Robust Joint Chance-Constrained Optimization for Electricity Imbalance in Iran: Integrating Renewables and Storage",
        "rating": "-10",
        "keywords": [],
        "abstract": "Iran's power grid faces mounting challenges due to the widening gap between rapidly increasing peak demand and lagging sustainable capacity expansion or load management. Prosumers have become key players in reducing grid load and offering valuable flexible services, but their effectiveness is hampered by a lack of knowledge about uncertain parameters and their probability distributions. This study introduces a novel two-stage multi-time scale distributionally robust optimization framework integrated with joint chance constraints to effectively manage the operation of prosumers and their energy sharing to mitigate overall peak load imbalances under uncertainties. In a data-driven setting and by leveraging historical data, the proposed model is reformulated as a tractable second-order conic constrained quadratic programing (SOCP). By considering real-world complexities based on realistic-data such as diverse load profiles and intermittent renewable generation, our approach demonstrates enhanced energy management system performance, even in out-of-sample scenarios. The synergy of distributed energy resources and coordinated flexibility within the network is instrumental in achieving substantial reductions in peak load and improving grid resilience.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "9 pages; 11 figures, journal paper"
    },
    {
        "paper id": "2409.00376",
        "abstract url": "https://arxiv.org/abs/2409.00376",
        "title": "Skill Dominance Analysis of Two(Four) player, Four(Five) dice Variant of the Ludo Game",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper examines two different variants of the Ludo game, involving multiple dice and a fixed number of total turns. Within each variant, multiple game lengths (total no. of turns) are considered. To compare the two variants, a set of intuitive, rule-based strategies is designed, representing different broad methods of strategic play. Game play is simulated between bots (automated software applications executing repetitive tasks over a network) following these strategies. The expected results are computed using certain game theoretic and probabilistic explanations, helping to understand the performance of the different strategies. The different strategies are further analyzed using win percentage in a large number of simulations, and Nash Equilibrium strategies are computed for both variants for a varying number of total turns. The Nash Equilibrium strategies across different game lengths are compared. A clear distinction between performances of strategies is observed, with more sophisticated strategies beating the naive one. A gradual shift in optimal strategy profiles is observed with changing game length, and certain sophisticated strategies even confound each other's performance while playing against each other.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "28 pages, 9 figures"
    },
    {
        "paper id": "2409.00402",
        "abstract url": "https://arxiv.org/abs/2409.00402",
        "title": "Generalized Orthogonal Chirp Division Multiplexing in Doubly Selective Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, orthogonal chirp division modulation (OCDM) has gained attention as a robust communication waveform due to its strong resistance to both time-domain and frequency-domain interference. However, similar to orthogonal frequency division multiplexing (OFDM), OCDM suffers from a high peak-to-average power ratio (PAPR), resulting in increased hardware costs and reduced energy efficiency of the transmitter's power amplifiers. In this work, we introduce a novel unitary transform called the Generalized Discrete Fresnel Transform (GDFnT) and propose a new waveform based on this transform, named Generalized Orthogonal Chirp Division Modulation (GOCDM). In GOCDM, data symbols from the constellation diagram are independently placed in the Generalized Fresnel (GF) domain. We derive the GF-domain channel matrix for the GOCDM system under time-frequency doubly selective channels and leverages the sparsity of the GF-domain channel matrix to design an iterative receiver based on the message-passing algorithm. Simulation results demonstrate that GOCDM achieves better PAPR performance than OCDM without compromising bit error rate (BER) performance.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00411",
        "abstract url": "https://arxiv.org/abs/2409.00411",
        "title": "AI-powered test automation tools: A systematic review and empirical evaluation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context: Test engineers are looking at more ways to test systems more effectively and efficiently. With recent advances in the field of AI (Artificial Intelligence), a large number of AI-powered test automation tools have emerged, which can help make testing more effective and efficient. Objective: We investigate the features provided by existing AI-based test automation tools. We also empirically evaluate the performance of two AI-based testing tools by applying them on two selected open-source Software Under Test (SUT). We empirically evaluate how the AI features can be helpful for effectiveness and efficiency of testing. We also study the limitations of the AI features in AI-based test tools. Method: To accomplish the objective, a Multivocal Literature Review (MLR) study was conducted to investigate the landscape of the AI-based test automation tools in the industry. Moreover, an empirical assessment is also conducted to empirically analyze two AI-based test automation tools by using it on two open-source projects. To determine the need of AI for selected feature, the same feature was created without the use of ML to explore its limitations which can be avoided using AI. Results: Our results are based on 55 AI-based test automation tools. Furthermore, an empirical assessment was performed by selecting two of the 55 tools analyzed as part of the MLR. Conclusion: This paper explores the potential benefits and limitations of AI-based test automation tools. The limitations explored can be used as inspiration to develop better AI-based test tools.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00413",
        "abstract url": "https://arxiv.org/abs/2409.00413",
        "title": "iToT: An Interactive System for Customized Tree-of-Thought Generation",
        "rating": "-10",
        "keywords": [],
        "abstract": "As language models have become increasingly successful at a wide array of tasks, different prompt engineering methods have been developed alongside them in order to adapt these models to new tasks. One of them is Tree-of-Thoughts (ToT), a prompting strategy and framework for language model inference and problem-solving. It allows the model to explore multiple solution paths and select the best course of action, producing a tree-like structure of intermediate steps (i.e., thoughts). This method was shown to be effective for several problem types. However, the official implementation has a high barrier to usage as it requires setup overhead and incorporates task-specific problem templates which are difficult to generalize to new problem types. It also does not allow user interaction to improve or suggest new thoughts. We introduce iToT (interactive Tree-of-Thoughts), a generalized and interactive Tree of Thought prompting system. iToT allows users to explore each step of the model's problem-solving process as well as to correct and extend the model's thoughts. iToT revolves around a visual interface that facilitates simple and generic ToT usage and transparentizes the problem-solving process to users. This facilitates a better understanding of which thoughts and considerations lead to the model's final decision. Through three case studies, we demonstrate the usefulness of iToT in different human-LLM co-writing tasks.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "6 pages excl. figures and comments; 8 figures. Will appear in IEEE 2024 NLVIZ Workshop"
    },
    {
        "paper id": "2409.00424",
        "abstract url": "https://arxiv.org/abs/2409.00424",
        "title": "Optimization-Based Control of Distributed Battery Storage in Distribution Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a combined global-local control approach to regulate voltage and minimize power losses in distribution networks with high integration of distributed energy resources (DERs). Local controllers embed the fast acting proportional volt-var-watt control law and have their gain (slope) coefficients updated regularly by a global optimization problem at a slower time-scale. Design of optimal coefficients preserve overall system stability and encapsulate inverter and energy limits of controllable DERs. The proposed approach is formulated based on a linear network model (LinDistFlow) and suitable approximations to produce a convex multi-period optimization formulation. Numerical simulations with real-world customer data and two different distribution feeders revealed that our approach provides substantial voltage regulation, while reducing losses by 11 per cent and peak substation power by 26 per cent compared to other state-of-the-art algorithms.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00429",
        "abstract url": "https://arxiv.org/abs/2409.00429",
        "title": "Flexible Ramping Product Procurement in Day-Ahead Markets",
        "rating": "-10",
        "keywords": [],
        "abstract": "Flexible ramping products (FRPs) emerge as a promising instrument for addressing steep and uncertain ramping needs through market mechanisms. Initial implementations of FRPs in North American electricity markets, however, revealed several shortcomings in existing FRP designs. In many instances, FRP prices failed to signal the true value of ramping capacity, most notably evident in zero FRP prices observed in a myriad of periods during which the system was in acute need for rampable capacity. These periods were marked by scheduled but undeliverable FRPs, often calling for operator out-of-market actions. On top of that, the methods used for procuring FRPs have been primarily rule-based, lacking explicit economic underpinnings. In this paper, we put forth an alternative framework for FRP procurement, which seeks to set FRP requirements and schedule FRP awards such that the expected system operation cost is minimized. Using real world data from U.S. ISOs, we showcase the relative merits of the framework in (i) reducing the total system operation cost, (ii) improving price formation, (iii) enhancing the the deliverability of FRP awards, and (iv) reducing the need for out-of-market actions.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00461",
        "abstract url": "https://arxiv.org/abs/2409.00461",
        "title": "Interference-Cancellation-Based Channel Knowledge Map Construction and Its Applications to Channel Estimation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Channel knowledge map (CKM) is viewed as a digital twin of wireless channels, providing location-specific channel knowledge for environment-aware communications. A fundamental problem in CKM-assisted communications is how to construct the CKM efficiently. Current research focuses on interpolating or predicting channel knowledge based on error-free channel knowledge from measured regions, ignoring the extraction of channel knowledge. This paper addresses this gap by unifying the extraction and representation of channel knowledge. We propose a novel CKM construction framework that leverages the received signals of the base station (BS) as online and low-cost data. Specifically, we partition the BS coverage area into spatial grids. The channel knowledge per grid is represented by a set of multi-path powers, delays, and angles, based on the principle of spatial consistency. In the extraction of these channel parameters, the challenges lie in strong inter-cell interferences and non-linear relationship between received signals and channel parameters. To address these issues, we formulate the problem of CKM construction into a problem of Bayesian inference, employing a block-sparsity prior model to characterize the path-loss differences of interferers. Under the Bayesian inference framework, we develop a hybrid message-passing algorithm for the interference-cancellation-based CKM construction. Based on the CKM, we obtain the joint frequency-space covariance of user channel and design a CKM-assisted Bayesian channel estimator. The computational complexity of the channel estimator is substantially reduced by exploiting the CKM-derived covariance structure. Numerical results show that the proposed CKM provides accurate channel parameters at low signal-to-interference-plus-noise ratio (SINR) and that the CKM-assisted channel estimator significantly outperforms state-of-the-art counterparts.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00465",
        "abstract url": "https://arxiv.org/abs/2409.00465",
        "title": "Moldable Exceptions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Debugging is hard. Interactive debuggers are mostly the same. They show you a stack, a way to sample the state of the stack, and, if the debugger is live, a way to step through execution. The standard interactive debugger for a general-purpose programming language provided by a mainstream IDE mostly offers a low-level interface in terms of generic language constructs to track down and fix bugs. A custom debugger, such as those developed for specific application domains, offers alternative interfaces more suitable to the specific execution context of the program being debugged. Custom debuggers offering contextual debugging views and actions can greatly improve our ability to reason about the current problem. Implementing such custom debuggers, however, is non-trivial, and poses a barrier to improving the debugging experience. In this paper we introduce \"moldable exceptions\", a lightweight mechanism to adapt a debugger's interface based on contextual information provided by a raised exception. We present, through a series of examples, how moldable exceptions can enhance a live programming environment.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00466",
        "abstract url": "https://arxiv.org/abs/2409.00466",
        "title": "Energy-efficient Functional Split in Non-terrestrial Open Radio Access Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the integration of Open Radio Access Network (O-RAN) within non-terrestrial networks (NTN), and optimizing the dynamic functional split between Centralized Units (CU) and Distributed Units (DU) for enhanced energy efficiency in the network. We introduce a novel framework utilizing a Deep Q-Network (DQN)-based reinforcement learning approach to dynamically find the optimal RAN functional split option and the best NTN-based RAN network out of the available NTN-platforms according to real-time conditions, traffic demands, and limited energy resources in NTN platforms. This approach supports capability of adapting to various NTN-based RANs across different platforms such as LEO satellites and high-altitude platform stations (HAPS), enabling adaptive network reconfiguration to ensure optimal service quality and energy utilization. Simulation results validate the effectiveness of our method, offering significant improvements in energy efficiency and sustainability under diverse NTN scenarios.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00469",
        "abstract url": "https://arxiv.org/abs/2409.00469",
        "title": "Enhancing Bistable Vibration Energy Harvesters with Tunable Circuits: A Comparative Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this article, we present an analysis of the effects of nonlinear circuits on bistable vibration energy harvesters. We begin by introducing an analytical model for bistable vibration energy harvesters and demonstrate that the impact of nonlinear circuits can be characterized by two factors: electrically-induced damping and electrically-induced stiffness. Subsequently, we investigate how these factors influence the power-frequency response of the harvester. Our findings reveal that electrically-induced damping significantly affects the bistable vibration energy harvester dynamics, whereas electrically-induced stiffness has minimal impact, which is a notable difference from the behavior of linear harvesters connected to nonlinear circuits. Thereafter, we conduct a comparative study of bistable energy harvesters connected to different nonlinear circuits already well documented in the literature. Our analysis demonstrates that, in most cases, the parallel synchronized switch harvesting on inductor circuit yields superior performance due to its ability to maximize electrically-induced damping. These comparative assessments and conclusions are evaluated within the framework of our proposed models and are contrasted with results obtained from linear vibration energy harvesters. The derived comparison maps presented at the end of this paper offer quantitative justification for selecting the optimal circuit for bistable energy harvesters, while deepening our comprehension of the intricate dynamics associated with nonlinear harvesters coupled with nonlinear circuits.",
        "subjects": [
            "physics.app-ph",
            "eess.SY"
        ],
        "comment": "15 pages, 13 figures, 2 Appendices"
    },
    {
        "paper id": "2409.00495",
        "abstract url": "https://arxiv.org/abs/2409.00495",
        "title": "TimeFloats: Train-in-Memory with Time-Domain Floating-Point Scalar Products",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we propose \"TimeFloats,\" an efficient train-in-memory architecture that performs 8-bit floating-point scalar product operations in the time domain. While building on the compute-in-memory paradigm's integrated storage and inferential computations, TimeFloats additionally enables floating-point computations, thus facilitating DNN training within the same memory structures. Traditional compute-in-memory approaches with conventional ADCs and DACs face challenges such as higher power consumption and increased design complexity, especially at advanced CMOS nodes. In contrast, TimeFloats leverages time-domain signal processing to avoid conventional domain converters. It operates predominantly with digital building blocks, reducing power consumption and noise sensitivity while enabling high-resolution computations and easier integration with conventional digital circuits. Our simulation results demonstrate an energy efficiency of 22.1 TOPS/W while evaluating the design on 15 nm CMOS technology.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00503",
        "abstract url": "https://arxiv.org/abs/2409.00503",
        "title": "Non-negative Sparse Recovery at Minimal Sampling Rate",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is known that sparse recovery is possible if the number of measurements is in the order of the sparsity, but the corresponding decoders either lack polynomial decoding time or robustness to noise. Commonly, decoders that rely on a null space property are being used. These achieve polynomial time decoding and are robust to additive noise but pay the price by requiring more measurements. The non-negative least residual has been established as such a decoder for non-negative recovery. A new equivalent condition for uniform, robust recovery of non-negative sparse vectors with the non-negative least residual that is not based on null space properties is introduced. It is shown that the number of measurements for this equivalent condition only needs to be in the order of the sparsity. Further, it is explained why the robustness to additive noise is similar, but not equal, to the robustness of decoders based on null space properties.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2409.00512",
        "abstract url": "https://arxiv.org/abs/2409.00512",
        "title": "Communicating in the Mediumband:What it is and Why it Matters",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper, based on recent research, articulates the opportunities and challenges posed by an emerging area of study known as ``mediumband wireless communication'', which refers to digital radio-frequency (RF) wireless communication through mediumband channels. This class of channels that falls in the transitional region between the narrowband and broadband channels, in many ways, is unique and shows significant potential. For instance, the effect of a highly unfavourable non-line-of-sight (NLoS) propagation environment can be transformed into a significantly favourable condition without making any intervention on the original propagation environment, but by simply communicating in the mediumband. The more unfavourable a propagation environment for wireless communication, the higher the potential gain by communicating in the mediumband. In this paper, using lay language as much as possible, we elaborate the unique properties of mediumband channels and implications of communicating in the mediumband for wider wireless communication along with some future research directions.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "10 pages, 10 figures, Accepted for publication in IEEE Communication Magazine"
    },
    {
        "paper id": "2409.00514",
        "abstract url": "https://arxiv.org/abs/2409.00514",
        "title": "Example-driven development: bridging tests and documentation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software systems should be explainable, that is, they should help us to answer questions while exploring, developing or using them. Textual documentation is a very weak form of explanation, since it is not causally connected to the code, so easily gets out of date. Tests, on the other hand, are causally connected to code, but they are also a weak form of explanation. Although some tests encode interesting scenarios that answer certain questions about how the system works, most tests don't make interesting reading. Examples are tests that are also factories for interesting system entities. Instead of simply succeeding or failing, an example returns the object under test so that it can be inspected, or reused to compose further tests. An example is causally connected to the system, is always live and tested, and can be embedded into live documentation. Although technically examples constitute just a small change to the way that to test methods work, their impact is potentially ground-breaking. We show (i) how Example-Driven Development (EDD) enriches TDD with live programming, (ii) how examples can be molded with tiny tools to answer analysis questions, and (iii) how examples can be embedded within live documentation to make a system explainable.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00517",
        "abstract url": "https://arxiv.org/abs/2409.00517",
        "title": "Over-the-Air Computation in Cell-Free Massive MIMO Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Over-the-air computation (AirComp) is considered as a communication-efficient solution for data aggregation and distributed learning by exploiting the superposition properties of wireless multi-access channels. However, AirComp is significantly affected by the uneven signal attenuation experienced by different wireless devices. Recently, Cell-free Massive MIMO (mMIMO) has emerged as a promising technology to provide uniform coverage and high rates by joint coherent transmission. In this paper, we investigate AirComp in Cell-free mMIMO systems, taking into account spatially correlated fading and channel estimation errors. In particular, we propose optimal designs of transmit coefficients and receive combing at different levels of cooperation among access points. Numerical results demonstrate that Cell-free mMIMO using fully centralized processing significantly outperforms conventional Cellular mMIMO with regard to the mean squared error (MSE). Moreover, we show that Cell-free mMIMO using local processing and large-scale fading decoding can achieve a lower MSE than Cellular mMIMO when the wireless devices have limited power budgets.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This paper has been accepted by IEEE CAMAD 2024"
    },
    {
        "paper id": "2409.00526",
        "abstract url": "https://arxiv.org/abs/2409.00526",
        "title": "Mathematical Optimization-Based Period Estimation with Outliers and Missing Observations",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider the frequency estimation of periodic signals using noisy time-of-arrival (TOA) information with missing (sparse) data contaminated with outliers. We tackle the problem from a mathematical optimization standpoint, formulating it as a linear regression with an unknown increasing integer independent variable and outliers. Assuming an upper bound on the variance of the noise, we derive an online, parallelizable, near-CRLB optimization-based algorithm amortized to a linear complexity. We demonstrate the outstanding robustness of our algorithm to noise and outliers by testing it against diverse randomly generated signals. Our algorithm handles outliers by design and yields precise estimations even with up to 20% of contaminated data.",
        "subjects": [
            "math.OC",
            "eess.SP"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2409.00538",
        "abstract url": "https://arxiv.org/abs/2409.00538",
        "title": "Review of meta-heuristic optimization algorithms to tune the PID controller parameters for automatic voltage regulator",
        "rating": "-10",
        "keywords": [],
        "abstract": "A Proportional- Integral- Derivative (PID) controller is required to bring a system back to the stable operating region as soon as possible following a disturbance or discrepancy. For successful operation of the PID controller, it is necessary to design the controller parameters in a manner that will render low optimization complexity, less memory for operation, fast convergence, and should be able to operate dynamically. Recent investigations have postulated many different meta-heuristic algorithms for efficient tuning of PID controller under various system milieus. However, researchers have seldom compared their custom made objective functions with previous investigations while proposing new algorithmic methods. This paper focuses on a detailed study on the research progress, deficiency, accomplishment and future scopes of recently proposed heuristic algorithms to designing and tuning the PID controller parameters for an automatic voltage regulator (AVR) system. Objective functions, including ITSE, ITAE, IAE, ISE, and ZLG, are considered to enumerate a measurable outcome of the algorithms. Considering a slight variation in the sytem gain parameters of the algorithms, the observed PID gain with ITSE results in 0.81918 - 1.9499 for K_p, 0.24366 - 1.4608 for K_i, and 0.31840 - 0.9683 for K_d. Whereas with ITAE the values are 0.24420 - 1.2771, 0.14230 - 0.8471, and 0.04270 - 0.4775, respectively. The time domain and frequency domain characteristics also changes significantly with each objective function. Our outlined comparison will be a guideline for investigating any newer algorithms in the field.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00550",
        "abstract url": "https://arxiv.org/abs/2409.00550",
        "title": "CASA: A Framework for SLO and Carbon-Aware Autoscaling and Scheduling in Serverless Cloud Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Serverless computing is an emerging cloud computing paradigm that can reduce costs for cloud providers and their customers. However, serverless cloud platforms have stringent performance requirements (due to the need to execute short duration functions in a timely manner) and a growing carbon footprint. Traditional carbon-reducing techniques such as shutting down idle containers can reduce performance by increasing cold-start latencies of containers required in the future. This can cause higher violation rates of service level objectives (SLOs). Conversely, traditional latency-reduction approaches of prewarming containers or keeping them alive when not in use can improve performance but increase the associated carbon footprint of the serverless cluster platform. To strike a balance between sustainability and performance, in this paper, we propose a novel carbon- and SLO-aware framework called CASA to schedule and autoscale containers in a serverless cloud computing cluster. Experimental results indicate that CASA reduces the operational carbon footprint of a FaaS cluster by up to 2.6x while also reducing the SLO violation rate by up to 1.4x compared to the state-of-the-art.",
        "subjects": [
            "cs.DC",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00559",
        "abstract url": "https://arxiv.org/abs/2409.00559",
        "title": "Prophet Inequality from Samples: Is the More the Merrier?",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study a variant of the single-choice prophet inequality problem where the decision-maker does not know the underlying distribution and has only access to a set of samples from the distributions. Rubinstein et al. [2020] showed that the optimal competitive-ratio of $\\frac{1}{2}$ can surprisingly be obtained by observing a set of $n$ samples, one from each of the distributions. In this paper, we prove that this competitive-ratio of $\\frac{1}{2}$ becomes unattainable when the decision-maker is provided with a set of more samples. We then examine the natural class of ordinal static threshold algorithms, where the algorithm selects the $i$-th highest ranked sample, sets this sample as a static threshold, and then chooses the first value that exceeds this threshold. We show that the best possible algorithm within this class achieves a competitive-ratio of $0.433$. Along the way, we utilize the tools developed in the paper and provide an alternative proof of the main result of Rubinstein et al. [2020].",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00568",
        "abstract url": "https://arxiv.org/abs/2409.00568",
        "title": "Armadillo and Eigen: A Tale of Two Linear Algebra Libraries",
        "rating": "-10",
        "keywords": [],
        "abstract": "This article introduces `cpp11eigen`, a new R package that integrates the powerful Eigen C++ library for linear algebra into the R programming environment. This article provides a detailed comparison between Armadillo and Eigen speed and syntax. The `cpp11eigen` package simplifies a part of the process of using C++ within R by offering additional ease of integration for those who require high-performance linear algebra operations in their R workflows. This work aims to discuss the tradeoff between computational efficiency and accessibility.",
        "subjects": [
            "cs.MS",
            "cs.PL",
            "stat.CO"
        ],
        "comment": "11 pages, 0 figures, 4 tables"
    },
    {
        "paper id": "2409.00581",
        "abstract url": "https://arxiv.org/abs/2409.00581",
        "title": "Learning and Control from Similarity Between Heterogeneous Systems: A Behavioral Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes basic definitions of similarity and similarity indexes between heterogeneous linear systems and presents a similarity-based learning control strategy. By exploring geometric properties of admissible behaviors of linear systems, the similarity indexes between two admissible behaviors of heterogeneous systems are defined as the principal angles between their subspace components, and an efficient strategy for calculating the similarity indexes is developed. By leveraging the similarity indexes, a similarity-based learning control strategy is proposed via projection techniques. With the application of the similarity-based learning control strategy, host system can efficiently accomplish the same tasks by leveraging the successful experience of guest system, without the necessity to repeat the trial-and-error process experienced by the guest system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    }
]