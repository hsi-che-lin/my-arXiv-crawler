[
    {
        "paper id": "2409.00887",
        "abstract url": "https://arxiv.org/abs/2409.00887",
        "title": "User-Specific Dialogue Generation with User Profile-Aware Pre-Training Model and Parameter-Efficient Fine-Tuning",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper addresses user-specific dialogs. In contrast to previous research on personalized dialogue focused on achieving virtual user dialogue as defined by persona descriptions, user-specific dialogue aims to reproduce real-user dialogue beyond persona-based dialogue. Fine-tuning using the target user's dialogue history is an efficient learning method for a user-specific model. However, it is prone to overfitting and model destruction due to the small amount of data. Therefore, we propose a learning method for user-specific models by combining parameter-efficient fine-tuning with a pre-trained dialogue model that includes user profiles. Parameter-efficient fine-tuning adds a small number of parameters to the entire model, so even small amounts of training data can be trained efficiently and are robust to model destruction. In addition, the pre-trained model, which is learned by adding simple prompts for automatically inferred user profiles, can generate speech with enhanced knowledge of the user's profile, even when there is little training data during fine-tuning. In experiments, we compared the proposed model with large-language-model utterance generation using prompts containing users' personal information. Experiments reproducing real users' utterances revealed that the proposed model can generate utterances with higher reproducibility than the compared methods, even with a small model.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00674",
        "abstract url": "https://arxiv.org/abs/2409.00674",
        "title": "MERLiN: Single-Shot Material Estimation and Relighting for Photometric Stereo",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Photometric stereo typically demands intricate data acquisition setups involving multiple light sources to recover surface normals accurately. In this paper, we propose MERLiN, an attention-based hourglass network that integrates single image-based inverse rendering and relighting within a single unified framework. We evaluate the performance of photometric stereo methods using these relit images and demonstrate how they can circumvent the underlying challenge of complex data acquisition. Our physically-based model is trained on a large synthetic dataset containing complex shapes with spatially varying BRDF and is designed to handle indirect illumination effects to improve material reconstruction and relighting. Through extensive qualitative and quantitative evaluation, we demonstrate that the proposed framework generalizes well to real-world images, achieving high-quality shape, material estimation, and relighting. We assess these synthetically relit images over photometric stereo benchmark methods for their physical correctness and resulting normal estimation accuracy, paving the way towards single-shot photometric stereo through physically-based relighting. This work allows us to address the single image-based inverse rendering problem holistically, applying well to both synthetic and real data and taking a step towards mitigating the challenge of data acquisition in photometric stereo.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in ECCV 2024"
    },
    {
        "paper id": "2409.00625",
        "abstract url": "https://arxiv.org/abs/2409.00625",
        "title": "Entity-Aware Biaffine Attention Model for Improved Constituent Parsing with Reduced Entity Violations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Constituency parsing involves analyzing a sentence by breaking it into sub-phrases, or constituents. While many deep neural models have achieved state-of-the-art performance in this task, they often overlook the entity-violating issue, where an entity fails to form a complete sub-tree in the resultant parsing tree. To address this, we propose an entity-aware biaffine attention model for constituent parsing. This model incorporates entity information into the biaffine attention mechanism by using additional entity role vectors for potential phrases, which enhances the parsing accuracy. We introduce a new metric, the Entity Violating Rate (EVR), to quantify the extent of entity violations in parsing results. Experiments on three popular datasets-ONTONOTES, PTB, and CTB-demonstrate that our model achieves the lowest EVR while maintaining high precision, recall, and F1-scores comparable to existing models. Further evaluation in downstream tasks, such as sentence sentiment analysis, highlights the effectiveness of our model and the validity of the proposed EVR metric.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00626",
        "abstract url": "https://arxiv.org/abs/2409.00626",
        "title": "Correcting FLORES Evaluation Dataset for Four African Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper describes the corrections made to the FLORES evaluation (dev and devtest) dataset for four African languages, namely Hausa, Northern Sotho (Sepedi), Xitsonga and isiZulu. The original dataset, though groundbreaking in its coverage of low-resource languages, exhibited various inconsistencies and inaccuracies in the reviewed languages that could potentially hinder the integrity of the evaluation of downstream tasks in natural language processing (NLP), especially machine translation. Through a meticulous review process by native speakers, several corrections were identified and implemented, improving the dataset's overall quality and reliability. For each language, we provide a concise summary of the errors encountered and corrected, and also present some statistical analysis that measure the difference between the existing and corrected datasets. We believe that our corrections enhance the linguistic accuracy and reliability of the data and, thereby, contributing to more effective evaluation of NLP tasks involving the four African languages.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00696",
        "abstract url": "https://arxiv.org/abs/2409.00696",
        "title": "Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Rating-based human evaluation has become an essential tool to accurately evaluate the impressive performance of Large language models (LLMs). However, current rating systems suffer from several critical limitations. Specifically, they fail to account for human biases that significantly influence evaluation results, require large and expensive preference datasets to obtain accurate ratings, and do not facilitate meaningful comparisons of model ratings across different tasks. To address these issues, we introduce Polyrating, an expressive and flexible rating system based on maximum a posteriori estimation that enables a more nuanced and thorough analysis of model performance at lower costs. Polyrating can detect and quantify biases affecting human preferences, ensuring fairer model comparisons. Furthermore, Polyrating can reduce the cost of human evaluations by up to $41\\%$ for new models and up to $77\\%$ for new tasks by leveraging existing benchmark scores. Lastly, Polyrating enables direct comparisons of ratings across different tasks, providing a comprehensive understanding of an LLMs' strengths, weaknesses, and relative performance across different applications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00721",
        "abstract url": "https://arxiv.org/abs/2409.00721",
        "title": "Who Would Chatbots Vote For? Political Preferences of ChatGPT and Gemini in the 2024 European Union Elections",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "This study examines the political bias of chatbots powered by large language models, namely ChatGPT and Gemini, in the context of the 2024 European Parliament elections. The research focused on the evaluation of political parties represented in the European Parliament across 27 EU Member States by these generative artificial intelligence (AI) systems. The methodology involved daily data collection through standardized prompts on both platforms. The results revealed a stark contrast: while Gemini mostly refused to answer political questions, ChatGPT provided consistent ratings. The analysis showed a significant bias in ChatGPT in favor of left-wing and centrist parties, with the highest ratings for the Greens/European Free Alliance. In contrast, right-wing parties, particularly the Identity and Democracy group, received the lowest ratings. The study identified key factors influencing the ratings, including attitudes toward European integration and perceptions of democratic values. The findings highlight the need for a critical approach to information provided by generative AI systems in a political context and call for more transparency and regulation in this area.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.CL",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00731",
        "abstract url": "https://arxiv.org/abs/2409.00731",
        "title": "A Critical Analysis on Machine Learning Techniques for Video-based Human Activity Recognition of Surveillance Systems: A Review",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Upsurging abnormal activities in crowded locations such as airports, train stations, bus stops, shopping malls, etc., urges the necessity for an intelligent surveillance system. An intelligent surveillance system can differentiate between normal and suspicious activities from real-time video analysis that will enable to take appropriate measures regarding the level of an anomaly instantaneously and efficiently. Video-based human activity recognition has intrigued many researchers with its pressing issues and a variety of applications ranging from simple hand gesture recognition to crucial behavior recognition in a surveillance system. This paper provides a critical survey of video-based Human Activity Recognition (HAR) techniques beginning with an examination of basic approaches for detecting and recognizing suspicious behavior followed by a critical analysis of machine learning and deep learning techniques such as Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Hidden Markov Model (HMM), K-means Clustering etc. A detailed investigation and comparison are done on these learning techniques on the basis of feature extraction techniques, parameter initialization, and optimization algorithms, accuracy, etc. The purpose of this review is to prioritize positive schemes and to assist researchers with emerging advancements in this field's future endeavors. This paper also pragmatically discusses existing challenges in the field of HAR and examines the prospects in the field.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00741",
        "abstract url": "https://arxiv.org/abs/2409.00741",
        "title": "Trust And Balance: Few Trusted Samples Pseudo-Labeling and Temperature Scaled Loss for Effective Source-Free Unsupervised Domain Adaptation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep Neural Networks have significantly impacted many computer vision tasks. However, their effectiveness diminishes when test data distribution (target domain) deviates from the one of training data (source domain). In situations where target labels are unavailable and the access to the labeled source domain is restricted due to data privacy or memory constraints, Source-Free Unsupervised Domain Adaptation (SF-UDA) has emerged as a valuable tool. Recognizing the key role of SF-UDA under these constraints, we introduce a novel approach marked by two key contributions: Few Trusted Samples Pseudo-labeling (FTSP) and Temperature Scaled Adaptive Loss (TSAL). FTSP employs a limited subset of trusted samples from the target data to construct a classifier to infer pseudo-labels for the entire domain, showing simplicity and improved accuracy. Simultaneously, TSAL, designed with a unique dual temperature scheduling, adeptly balance diversity, discriminability, and the incorporation of pseudo-labels in the unsupervised adaptation objective. Our methodology, that we name Trust And Balance (TAB) adaptation, is rigorously evaluated on standard datasets like Office31 and Office-Home, and on less common benchmarks such as ImageCLEF-DA and Adaptiope, employing both ResNet50 and ViT-Large architectures. Our results compare favorably with, and in most cases surpass, contemporary state-of-the-art techniques, underscoring the effectiveness of our methodology in the SF-UDA landscape.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00751",
        "abstract url": "https://arxiv.org/abs/2409.00751",
        "title": "Self-Supervised Vision Transformers for Writer Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "While methods based on Vision Transformers (ViT) have achieved state-of-the-art performance in many domains, they have not yet been applied successfully in the domain of writer retrieval. The field is dominated by methods using handcrafted features or features extracted from Convolutional Neural Networks. In this work, we bridge this gap and present a novel method that extracts features from a ViT and aggregates them using VLAD encoding. The model is trained in a self-supervised fashion without any need for labels. We show that extracting local foreground features is superior to using the ViT's class token in the context of writer retrieval. We evaluate our method on two historical document collections. We set a new state-at-of-art performance on the Historical-WI dataset (83.1\\% mAP), and the HisIR19 dataset (95.0\\% mAP). Additionally, we demonstrate that our ViT feature extractor can be directly applied to modern datasets such as the CVL database (98.6\\% mAP) without any fine-tuning.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00755",
        "abstract url": "https://arxiv.org/abs/2409.00755",
        "title": "Trusted Unified Feature-Neighborhood Dynamics for Multi-View Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Multi-view classification (MVC) faces inherent challenges due to domain gaps and inconsistencies across different views, often resulting in uncertainties during the fusion process. While Evidential Deep Learning (EDL) has been effective in addressing view uncertainty, existing methods predominantly rely on the Dempster-Shafer combination rule, which is sensitive to conflicting evidence and often neglects the critical role of neighborhood structures within multi-view data. To address these limitations, we propose a Trusted Unified Feature-NEighborhood Dynamics (TUNED) model for robust MVC. This method effectively integrates local and global feature-neighborhood (F-N) structures for robust decision-making. Specifically, we begin by extracting local F-N structures within each view. To further mitigate potential uncertainties and conflicts in multi-view fusion, we employ a selective Markov random field that adaptively manages cross-view neighborhood dependencies. Additionally, we employ a shared parameterized evidence extractor that learns global consensus conditioned on local F-N structures, thereby enhancing the global integration of multi-view features. Experiments on benchmark datasets show that our method improves accuracy and robustness over existing approaches, particularly in scenarios with high uncertainty and conflicting views. The code will be made available at https://github.com/JethroJames/TUNED.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Ongoing work: 13pages, 13figures, 12 tables"
    },
    {
        "paper id": "2409.00777",
        "abstract url": "https://arxiv.org/abs/2409.00777",
        "title": "VDPI: Video Deblurring with Pseudo-inverse Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video deblurring is a challenging task that aims to recover sharp sequences from blur and noisy observations. The image-formation model plays a crucial role in traditional model-based methods, constraining the possible solutions. However, this is only the case for some deep learning-based methods. Despite deep-learning models achieving better results, traditional model-based methods remain widely popular due to their flexibility. An increasing number of scholars combine the two to achieve better deblurring performance. This paper proposes introducing knowledge of the image-formation model into a deep learning network by using the pseudo-inverse of the blur. We use a deep network to fit the blurring and estimate pseudo-inverse. Then, we use this estimation, combined with a variational deep-learning network, to deblur the video sequence. Notably, our experimental results demonstrate that such modifications can significantly improve the performance of deep learning models for video deblurring. Furthermore, our experiments on different datasets achieved notable performance improvements, proving that our proposed method can generalize to different scenarios and cameras.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00781",
        "abstract url": "https://arxiv.org/abs/2409.00781",
        "title": "Generating Media Background Checks for Automated Source Critical Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Not everything on the internet is true. This unfortunate fact requires both humans and models to perform complex reasoning about credibility when working with retrieved information. In NLP, this problem has seen little attention. Indeed, retrieval-augmented models are not typically expected to distrust retrieved documents. Human experts overcome the challenge by gathering signals about the context, reliability, and tendency of source documents - that is, they perform source criticism. We propose a novel NLP task focused on finding and summarising such signals. We introduce a new dataset of 6,709 \"media background checks\" derived from Media Bias / Fact Check, a volunteer-run website documenting media bias. We test open-source and closed-source LLM baselines with and without retrieval on this dataset, finding that retrieval greatly improves performance. We furthermore carry out human evaluation, demonstrating that 1) media background checks are helpful for humans, and 2) media background checks are helpful for retrieval-augmented models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00800",
        "abstract url": "https://arxiv.org/abs/2409.00800",
        "title": "Comparing Discrete and Continuous Space LLMs for Speech Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper investigates discrete and continuous speech representations in Large Language Model (LLM)-based Automatic Speech Recognition (ASR), organizing them by feature continuity and training approach into four categories: supervised and unsupervised for both discrete and continuous types. We further classify LLMs based on their input and autoregressive feedback into continuous and discrete-space models. Using specialized encoders and comparative analysis with a Joint-Training-From-Scratch Language Model (JTFS LM) and pre-trained LLaMA2-7b, we provide a detailed examination of their effectiveness. Our work marks the first extensive comparison of speech representations in LLM-based ASR and explores various modeling techniques. We present an open-sourced achievement of a state-of-the-art Word Error Rate (WER) of 1.69\\% on LibriSpeech using a HuBERT encoder, offering valuable insights for advancing ASR and natural language processing (NLP) research.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "InterSpeech 2024"
    },
    {
        "paper id": "2409.00815",
        "abstract url": "https://arxiv.org/abs/2409.00815",
        "title": "Serialized Speech Information Guidance with Overlapped Encoding Separation for Multi-Speaker Automatic Speech Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Serialized output training (SOT) attracts increasing attention due to its convenience and flexibility for multi-speaker automatic speech recognition (ASR). However, it is not easy to train with attention loss only. In this paper, we propose the overlapped encoding separation (EncSep) to fully utilize the benefits of the connectionist temporal classification (CTC) and attention hybrid loss. This additional separator is inserted after the encoder to extract the multi-speaker information with CTC losses. Furthermore, we propose the serialized speech information guidance SOT (GEncSep) to further utilize the separated encodings. The separated streams are concatenated to provide single-speaker information to guide attention during decoding. The experimental results on LibriMix show that the single-speaker encoding can be separated from the overlapped encoding. The CTC loss helps to improve the encoder representation under complex scenarios. GEncSep further improved performance.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00819",
        "abstract url": "https://arxiv.org/abs/2409.00819",
        "title": "LibriheavyMix: A 20,000-Hour Dataset for Single-Channel Reverberant Multi-Talker Speech Separation, ASR and Speaker Diarization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The evolving speech processing landscape is increasingly focused on complex scenarios like meetings or cocktail parties with multiple simultaneous speakers and far-field conditions. Existing methodologies for addressing these challenges fall into two categories: multi-channel and single-channel solutions. Single-channel approaches, notable for their generality and convenience, do not require specific information about microphone arrays. This paper presents a large-scale far-field overlapping speech dataset, crafted to advance research in speech separation, recognition, and speaker diarization. This dataset is a critical resource for decoding ``Who said What and When'' in multi-talker, reverberant environments, a daunting challenge in the field. Additionally, we introduce a pipeline system encompassing speech separation, recognition, and diarization as a foundational benchmark. Evaluations on the WHAMR! dataset validate the broad applicability of the proposed data.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "InterSpeech 2024"
    },
    {
        "paper id": "2409.00844",
        "abstract url": "https://arxiv.org/abs/2409.00844",
        "title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid development and dynamic nature of large language models (LLMs) make it difficult for conventional quantitative benchmarks to accurately assess their capabilities. We propose report cards, which are human-interpretable, natural language summaries of model behavior for specific skills or topics. We develop a framework to evaluate report cards based on three criteria: specificity (ability to distinguish between models), faithfulness (accurate representation of model capabilities), and interpretability (clarity and relevance to humans). We also propose an iterative algorithm for generating report cards without human supervision and explore its efficacy by ablating various design choices. Through experimentation with popular LLMs, we demonstrate that report cards provide insights beyond traditional benchmarks and can help address the need for a more interpretable and holistic evaluation of LLMs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "11 pages, 8 figures"
    },
    {
        "paper id": "2409.00855",
        "abstract url": "https://arxiv.org/abs/2409.00855",
        "title": "LanguaShrink: Reducing Token Overhead with Psycholinguistics",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As large language models (LLMs) improve their capabilities in handling complex tasks, the issues of computational cost and efficiency due to long prompts are becoming increasingly prominent. To accelerate model inference and reduce costs, we propose an innovative prompt compression framework called LanguaShrink. Inspired by the observation that LLM performance depends on the density and position of key information in the input prompts, LanguaShrink leverages psycholinguistic principles and the Ebbinghaus memory curve to achieve task-agnostic prompt compression. This effectively reduces prompt length while preserving essential information. We referred to the training method of OpenChat.The framework introduces part-of-speech priority compression and data distillation techniques, using smaller models to learn compression targets and employing a KL-regularized reinforcement learning strategy for training.\\cite{wang2023openchat} Additionally, we adopt a chunk-based compression algorithm to achieve adjustable compression rates. We evaluate our method on multiple datasets, including LongBench, ZeroScrolls, Arxiv Articles, and a newly constructed novel test set. Experimental results show that LanguaShrink maintains semantic similarity while achieving up to 26 times compression. Compared to existing prompt compression methods, LanguaShrink improves end-to-end latency by 1.43 times.",
        "subjects": [
            "cs.CL",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00856",
        "abstract url": "https://arxiv.org/abs/2409.00856",
        "title": "Benchmarking LLM Code Generation for Audio Programming with Visual Dataflow Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Node-based programming languages are increasingly popular in media arts coding domains. These languages are designed to be accessible to users with limited coding experience, allowing them to achieve creative output without an extensive programming background. Using LLM-based code generation to further lower the barrier to creative output is an exciting opportunity. However, the best strategy for code generation for visual node-based programming languages is still an open question. In particular, such languages have multiple levels of representation in text, each of which may be used for code generation. In this work, we explore the performance of LLM code generation in audio programming tasks in visual programming languages at multiple levels of representation. We explore code generation through metaprogramming code representations for these languages (i.e., coding the language using a different high-level text-based programming language), as well as through direct node generation with JSON. We evaluate code generated in this way for two visual languages for audio programming on a benchmark set of coding problems. We measure both correctness and complexity of the generated code. We find that metaprogramming results in more semantically correct generated code, given that the code is well-formed (i.e., is syntactically correct and runs). We also find that prompting for richer metaprogramming using randomness and loops led to more complex code.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00872",
        "abstract url": "https://arxiv.org/abs/2409.00872",
        "title": "Self-evolving Agents with reflective and memory-augmented abilities",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have made significant advances in the field of natural language processing, but they still face challenges such as continuous decision-making. In this research, we propose a novel framework by integrating iterative feedback, reflective mechanisms, and a memory optimization mechanism based on the Ebbinghaus forgetting curve, it significantly enhances the agents' capabilities in handling multi-tasking and long-span information.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00877",
        "abstract url": "https://arxiv.org/abs/2409.00877",
        "title": "Digital Twins in Additive Manufacturing: A Systematic Review",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Digital Twins (DTs) are becoming popular in Additive Manufacturing (AM) due to their ability to create virtual replicas of physical components of AM machines, which helps in real-time production monitoring. Advanced techniques such as Machine Learning (ML), Augmented Reality (AR), and simulation-based models play key roles in developing intelligent and adaptable DTs in manufacturing processes. However, questions remain regarding scalability, the integration of high-quality data, and the computational power required for real-time applications in developing DTs. Understanding the current state of DTs in AM is essential to address these challenges and fully utilize their potential in advancing AM processes. Considering this opportunity, this work aims to provide a comprehensive overview of DTs in AM by addressing the following four research questions: (1) What are the key types of DTs used in AM and their specific applications? (2) What are the recent developments and implementations of DTs? (3) How are DTs employed in process improvement and hybrid manufacturing? (4) How are DTs integrated with Industry 4.0 technologies? By discussing current applications and techniques, we aim to offer a better understanding and potential future research directions for researchers and practitioners in AM and DTs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00903",
        "abstract url": "https://arxiv.org/abs/2409.00903",
        "title": "MV-Match: Multi-View Matching for Domain-Adaptive Identification of Plant Nutrient Deficiencies",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "An early, non-invasive, and on-site detection of nutrient deficiencies is critical to enable timely actions to prevent major losses of crops caused by lack of nutrients. While acquiring labeled data is very expensive, collecting images from multiple views of a crop is straightforward. Despite its relevance for practical applications, unsupervised domain adaptation where multiple views are available for the labeled source domain as well as the unlabeled target domain is an unexplored research area. In this work, we thus propose an approach that leverages multiple camera views in the source and target domain for unsupervised domain adaptation. We evaluate the proposed approach on two nutrient deficiency datasets. The proposed method achieves state-of-the-art results on both datasets compared to other unsupervised domain adaptation methods. The dataset and source code are available at https://github.com/jh-yi/MV-Match.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "BMVC 2024 camera-ready version"
    },
    {
        "paper id": "2409.00909",
        "abstract url": "https://arxiv.org/abs/2409.00909",
        "title": "ViRED: Prediction of Visual Relations in Engineering Drawings",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "To accurately understand engineering drawings, it is essential to establish the correspondence between images and their description tables within the drawings. Existing document understanding methods predominantly focus on text as the main modality, which is not suitable for documents containing substantial image information. In the field of visual relation detection, the structure of the task inherently limits its capacity to assess relationships among all entity pairs in the drawings. To address this issue, we propose a vision-based relation detection model, named ViRED, to identify the associations between tables and circuits in electrical engineering drawings. Our model mainly consists of three parts: a vision encoder, an object encoder, and a relation decoder. We implement ViRED using PyTorch to evaluate its performance. To validate the efficacy of ViRED, we conduct a series of experiments. The experimental results indicate that, within the engineering drawing dataset, our approach attained an accuracy of 96\\% in the task of relation prediction, marking a substantial improvement over existing methodologies. The results also show that ViRED can inference at a fast speed even when there are numerous objects in a single engineering drawing.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2409.00912",
        "abstract url": "https://arxiv.org/abs/2409.00912",
        "title": "Merging Multiple Datasets for Improved Appearance-Based Gaze Estimation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multiple datasets have been created for training and testing appearance-based gaze estimators. Intuitively, more data should lead to better performance. However, combining datasets to train a single esti-mator rarely improves gaze estimation performance. One reason may be differences in the experimental protocols used to obtain the gaze sam-ples, resulting in differences in the distributions of head poses, gaze an-gles, illumination, etc. Another reason may be the inconsistency between methods used to define gaze angles (label mismatch). We propose two innovations to improve the performance of gaze estimation by leveraging multiple datasets, a change in the estimator architecture and the intro-duction of a gaze adaptation module. Most state-of-the-art estimators merge information extracted from images of the two eyes and the entire face either in parallel or combine information from the eyes first then with the face. Our proposed Two-stage Transformer-based Gaze-feature Fusion (TTGF) method uses transformers to merge information from each eye and the face separately and then merge across the two eyes. We argue that this improves head pose invariance since changes in head pose affect left and right eye images in different ways. Our proposed Gaze Adaptation Module (GAM) method handles annotation inconsis-tency by applying a Gaze Adaption Module for each dataset to correct gaze estimates from a single shared estimator. This enables us to combine information across datasets despite differences in labeling. Our experi-ments show that these innovations improve gaze estimation performance over the SOTA both individually and collectively (by 10% - 20%). Our code is available at https://github.com/HKUST-NISL/GazeSetMerge.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.00918",
        "abstract url": "https://arxiv.org/abs/2409.00918",
        "title": "LuWu: An End-to-End In-Network Out-of-Core Optimizer for 100B-Scale Model-in-Network Data-Parallel Training on Distributed GPUs",
        "rating": "1",
        "keywords": [
            [
                "memory-efficient"
            ]
        ],
        "abstract": "The recent progress made in large language models (LLMs) has brought tremendous application prospects to the world. The growing model size demands LLM training on multiple GPUs, while data parallelism is the most popular distributed training strategy due to its simplicity, efficiency, and scalability. Current systems adopt the model-sharded data parallelism to enable memory-efficient training, however, existing model-sharded data-parallel systems fail to efficiently utilize GPU on a commodity GPU cluster with 100 Gbps (or 200 Gbps) inter-GPU bandwidth due to 1) severe interference between collective operation and GPU computation and 2) heavy CPU optimizer overhead. Recent works propose in-network aggregation (INA) to relieve the network bandwidth pressure in data-parallel training, but they are incompatible with model sharding due to the network design. To this end, we propose LuWu, a novel in-network optimizer that enables efficient model-in-network data-parallel training of a 100B-scale model on distributed GPUs. Such new data-parallel paradigm keeps a similar communication pattern as model-sharded data parallelism but with a centralized in-network optimizer execution. The key idea is to offload the entire optimizer states and parameters from GPU workers onto an in-network optimizer node and to offload the entire collective communication from GPU-implemented NCCL to SmartNIC-SmartSwitch co-optimization. The experimental results show that LuWu outperforms the state-of-the-art training system by 3.98x when training on a 175B model on an 8-worker cluster.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00920",
        "abstract url": "https://arxiv.org/abs/2409.00920",
        "title": "ToolACE: Winning the Points of LLM Function Calling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Function calling significantly extends the application boundary of large language models, where high-quality and diverse training data is critical for unlocking this capability. However, real function-calling data is quite challenging to collect and annotate, while synthetic data generated by existing pipelines tends to lack coverage and accuracy. In this paper, we present ToolACE, an automatic agentic pipeline designed to generate accurate, complex, and diverse tool-learning data. ToolACE leverages a novel self-evolution synthesis process to curate a comprehensive API pool of 26,507 diverse APIs. Dialogs are further generated through the interplay among multiple agents, guided by a formalized thinking process. To ensure data accuracy, we implement a dual-layer verification system combining rule-based and model-based checks. We demonstrate that models trained on our synthesized data, even with only 8B parameters, achieve state-of-the-art performance on the Berkeley Function-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a subset of the data are publicly available at https://huggingface.co/Team-ACE.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "21 pages, 22 figures"
    },
    {
        "paper id": "2409.00926",
        "abstract url": "https://arxiv.org/abs/2409.00926",
        "title": "Towards Student Actions in Classroom Scenes: New Dataset and Baseline",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Analyzing student actions is an important and challenging task in educational research. Existing efforts have been hampered by the lack of accessible datasets to capture the nuanced action dynamics in classrooms. In this paper, we present a new multi-label student action video (SAV) dataset for complex classroom scenes. The dataset consists of 4,324 carefully trimmed video clips from 758 different classrooms, each labeled with 15 different actions displayed by students in classrooms. Compared to existing behavioral datasets, our dataset stands out by providing a wide range of real classroom scenarios, high-quality video data, and unique challenges, including subtle movement differences, dense object engagement, significant scale differences, varied shooting angles, and visual occlusion. The increased complexity of the dataset brings new opportunities and challenges for benchmarking action detection. Innovatively, we also propose a new baseline method, a visual transformer for enhancing attention to key local details in small and dense object regions. Our method achieves excellent performance with mean Average Precision (mAP) of 67.9\\% and 27.4\\% on SAV and AVA, respectively. This paper not only provides the dataset but also calls for further research into AI-driven educational tools that may transform teaching methodologies and learning outcomes. The code and dataset will be released at https://github.com/Ritatanz/SAV.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00935",
        "abstract url": "https://arxiv.org/abs/2409.00935",
        "title": "Self-Judge: Selective Instruction Following with Alignment Self-Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Pre-trained large language models (LLMs) can be tailored to adhere to human instructions through instruction tuning. However, due to shifts in the distribution of test-time data, they may not always execute instructions accurately, potentially generating factual errors or misaligned content when acting as chat assistants. To enhance the reliability of LLMs in following instructions, we propose the study of selective instruction following, whereby the system declines to execute instructions if the anticipated response quality is low. We train judge models that can predict numerical quality scores for model responses. To address data scarcity, we introduce Self-J, a novel self-training framework for developing judge models without needing human-annotated quality scores. Our method leverages the model's inherent self-evaluation capability to extract information about response quality from labeled instruction-tuning data. It incorporates a gold reference answer to facilitate self-evaluation and recalibrates by assessing the semantic similarity between the response sample and the gold reference. During the training phase, we implement self-distillation as a regularization technique to enhance the capability of reference-free estimation. To validate alignment evaluation on general instruction-following tasks, we collect large-scale high-quality instructions from Hugging Face for model training and evaluation. Extensive experiments on five open-source models show that our method correlates much more with GPT-4 than strong baselines, e.g., supervised models distilled from GPT-4 and GPT-3.5-turbo. Our analysis shows our model's strong generalization across domains. Additionally, our judge models serve as good reward models, e.g., boosting WizardLM-13B-V1.2 from 89.17 to 92.48 and from 12.03 to 15.90 in version v1 and v2 of AlpacaEval respectively using best-of-32 sampling with our judge models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2409.00940",
        "abstract url": "https://arxiv.org/abs/2409.00940",
        "title": "Large Language Models for Automatic Detection of Sensitive Topics",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Sensitive information detection is crucial in content moderation to maintain safe online communities. Assisting in this traditionally manual process could relieve human moderators from overwhelming and tedious tasks, allowing them to focus solely on flagged content that may pose potential risks. Rapidly advancing large language models (LLMs) are known for their capability to understand and process natural language and so present a potential solution to support this process. This study explores the capabilities of five LLMs for detecting sensitive messages in the mental well-being domain within two online datasets and assesses their performance in terms of accuracy, precision, recall, F1 scores, and consistency. Our findings indicate that LLMs have the potential to be integrated into the moderation workflow as a convenient and precise detection tool. The best-performing model, GPT-4o, achieved an average accuracy of 99.5\\% and an F1-score of 0.99. We discuss the advantages and potential challenges of using LLMs in the moderation workflow and suggest that future research should address the ethical considerations of utilising this technology.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "2024 Oz CHI conference"
    },
    {
        "paper id": "2409.00629",
        "abstract url": "https://arxiv.org/abs/2409.00629",
        "title": "Assessing the Impact of Upselling in Online Fantasy Sports",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study explores the impact of upselling on user engagement. We model users' deposit behaviour on the fantasy sports platform Dream11. Subsequently, we develop an experimental framework to evaluate the effect of upselling using an intensity parameter. Our live experiments on user deposit behaviour reveal decreased user recall with heightened upselling intensity. Our findings indicate that increased upselling intensity improves user deposit metrics and concurrently diminishes user satisfaction and conversion rates. We conduct robust counterfactual analysis and train causal meta-learners to personalise users' upselling intensity levels to reach an optimal trade-off point.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00634",
        "abstract url": "https://arxiv.org/abs/2409.00634",
        "title": "Indoor Sensing with Measurements",
        "rating": "0.5",
        "keywords": [
            [
                "ICASSP"
            ]
        ],
        "abstract": "The cellular wireless networks are evolving towards acquiring newer capabilities, such as sensing, which will support novel use cases and applications. Many of these require indoor sensing capabilities, which can be realized by exploiting the perturbation in the indoor channel. In this work, we conduct an indoor channel measurement campaign to study these perturbations and develop AI-based algorithms for estimating sensing parameters. We develop several AI methods based on CNN and tree-based ensemble architectures for sensing. We show that the presence of a passive target like a person can be detected from the channel perturbation of a single link with more than 90 % accuracy with a simple CNN based AI algorithm. However, sensing the position of a passive target is far more challenging requiring more complex AI algorithms and deployments. We show that the position of the human in the indoor room can be estimated within the average position error of 0.7 m with a deployment having three links and employing complex AI architecture for position estimation. We also compare the results with the baseline algorithm to demonstrate the utility of the proposed method.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "4 Pages of technical content and 5th page with reference. Submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.00706",
        "abstract url": "https://arxiv.org/abs/2409.00706",
        "title": "Abstaining Machine Learning -- Philosophical Considerations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper establishes a connection between the fields of machine learning (ML) and philosophy concerning the phenomenon of behaving neutrally. It investigates a specific class of ML systems capable of delivering a neutral response to a given task, referred to as abstaining machine learning systems, that has not yet been studied from a philosophical perspective. The paper introduces and explains various abstaining machine learning systems, and categorizes them into distinct types. An examination is conducted on how abstention in the different machine learning system types aligns with the epistemological counterpart of suspended judgment, addressing both the nature of suspension and its normative profile. Additionally, a philosophical analysis is suggested on the autonomy and explainability of the abstaining response. It is argued, specifically, that one of the distinguished types of abstaining systems is preferable as it aligns more closely with our criteria for suspended judgment. Moreover, it is better equipped to autonomously generate abstaining outputs and offer explanations for abstaining outputs when compared to the other type.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Part of the published PhD Thesis: Daniela Schuster. Suspension of Judgment in Artificial Intelligence-Uncovering Uncertainty in Data-Based and Logic-Based Systems. PhD thesis, University of Konstanz, 2024. http://nbn-resolving.de/urn:nbn:de:bsz:352-2-1r3gwq4l5jlwr2"
    },
    {
        "paper id": "2409.00707",
        "abstract url": "https://arxiv.org/abs/2409.00707",
        "title": "ReMOVE: A Reference-free Metric for Object Erasure",
        "rating": "0.5",
        "keywords": [
            [
                "diffusion",
                "inpainting",
                "image editing"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "We introduce $\\texttt{ReMOVE}$, a novel reference-free metric for assessing object erasure efficacy in diffusion-based image editing models post-generation. Unlike existing measures such as LPIPS and CLIPScore, $\\texttt{ReMOVE}$ addresses the challenge of evaluating inpainting without a reference image, common in practical scenarios. It effectively distinguishes between object removal and replacement. This is a key issue in diffusion models due to stochastic nature of image generation. Traditional metrics fail to align with the intuitive definition of inpainting, which aims for (1) seamless object removal within masked regions (2) while preserving the background continuity. $\\texttt{ReMOVE}$ not only correlates with state-of-the-art metrics and aligns with human perception but also captures the nuanced aspects of the inpainting process, providing a finer-grained evaluation of the generated outputs.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at The First Workshop on the Evaluation of Generative Foundation Models (EvGENFM) at CVPR 2024"
    },
    {
        "paper id": "2409.00717",
        "abstract url": "https://arxiv.org/abs/2409.00717",
        "title": "Multi-Agent Reinforcement Learning from Human Feedback: Data Coverage and Algorithmic Techniques",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We initiate the study of Multi-Agent Reinforcement Learning from Human Feedback (MARLHF), exploring both theoretical foundations and empirical validations. We define the task as identifying Nash equilibrium from a preference-only offline dataset in general-sum games, a problem marked by the challenge of sparse feedback signals. Our theory establishes the upper complexity bounds for Nash Equilibrium in effective MARLHF, demonstrating that single-policy coverage is inadequate and highlighting the importance of unilateral dataset coverage. These theoretical insights are verified through comprehensive experiments. To enhance the practical performance, we further introduce two algorithmic techniques. (1) We propose a Mean Squared Error (MSE) regularization along the time axis to achieve a more uniform reward distribution and improve reward learning outcomes. (2) We utilize imitation learning to approximate the reference policy, ensuring stability and effectiveness in training. Our findings underscore the multifaceted approach required for MARLHF, paving the way for effective preference-based multi-agent systems.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00733",
        "abstract url": "https://arxiv.org/abs/2409.00733",
        "title": "Benign Overfitting for $\u03b1$ Sub-exponential Input",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper investigates the phenomenon of benign overfitting in binary classification problems with heavy-tailed input distributions. We extend the analysis of maximum margin classifiers to $\u03b1$ sub-exponential distributions, where $\u03b1\\in (0,2]$, generalizing previous work that focused on sub-gaussian inputs. Our main result provides generalization error bounds for linear classifiers trained using gradient descent on unregularized logistic loss in this heavy-tailed setting. We prove that under certain conditions on the dimensionality $p$ and feature vector magnitude $\\|\u03bc\\|$, the misclassification error of the maximum margin classifier asymptotically approaches the noise level. This work contributes to the understanding of benign overfitting in more robust distribution settings and demonstrates that the phenomenon persists even with heavier-tailed inputs than previously studied.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00742",
        "abstract url": "https://arxiv.org/abs/2409.00742",
        "title": "Simulation of Social Media-Driven Bubble Formation in Financial Markets using an Agent-Based Model with Hierarchical Influence Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We propose that a tree-like hierarchical structure represents a simple and effective way to model the emergent behaviour of financial markets, especially markets where there exists a pronounced intersection between social media influences and investor behaviour. To explore this hypothesis, we introduce an agent-based model of financial markets, where trading agents are embedded in a hierarchical network of communities, and communities influence the strategies and opinions of traders. Empirical analysis of the model shows that its behaviour conforms to several stylized facts observed in real financial markets; and the model is able to realistically simulate the effects that social media-driven phenomena, such as echo chambers and pump-and-dump schemes, have on financial markets.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "q-fin.TR"
        ],
        "comment": "11 pages, 7 figures, To appear in Proceedings of 36th European Modeling and Simulation Symposium (EMSS), 21st International Multidisciplinary Modelling and Simulation Multiconference (I3M), Tenerife, Spain, Sep. 2024"
    },
    {
        "paper id": "2409.00753",
        "abstract url": "https://arxiv.org/abs/2409.00753",
        "title": "Generalized Multi-hop Traffic Pressure for Heterogeneous Traffic Perimeter Control",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Perimeter control prevents loss of traffic network capacity due to congestion in urban areas. Homogeneous perimeter control allows all access points to a protected region to have the same maximal permitted inflow. However, homogeneous perimeter control performs poorly when the congestion in the protected region is heterogeneous (e.g., imbalanced demand) since the homogeneous perimeter control does not consider location-specific traffic conditions around the perimeter. When the protected region has spatially heterogeneous congestion, it can often make sense to modulate the perimeter inflow rate to be higher near low-density regions and vice versa for high-density regions. To assist with this modulation, we can leverage the concept of 1-hop traffic pressure to measure intersection-level traffic congestion. However, as we show, 1-hop pressure turns out to be too spatially myopic for perimeter control and hence we formulate multi-hop generalizations of pressure that look ``deeper'' inside the perimeter beyond the entry intersection. In addition, we formulate a simple heterogeneous perimeter control methodology that can leverage this novel multi-hop pressure to redistribute the total permitted inflow provided by the homogeneous perimeter controller. Experimental results show that our heterogeneous perimeter control policies leveraging multi-hop pressure significantly outperform homogeneous perimeter control in scenarios where the origin-destination flows are highly imbalanced with high spatial heterogeneity.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": "21 pages main body, 12 figures, journal paper"
    },
    {
        "paper id": "2409.00768",
        "abstract url": "https://arxiv.org/abs/2409.00768",
        "title": "Rethinking Image Super-Resolution from Training Data Perspectives",
        "rating": "0.5",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "In this work, we investigate the understudied effect of the training data used for image super-resolution (SR). Most commonly, novel SR methods are developed and benchmarked on common training datasets such as DIV2K and DF2K. However, we investigate and rethink the training data from the perspectives of diversity and quality, {thereby addressing the question of ``How important is SR training for SR models?''}. To this end, we propose an automated image evaluation pipeline. With this, we stratify existing high-resolution image datasets and larger-scale image datasets such as ImageNet and PASS to compare their performances. We find that datasets with (i) low compression artifacts, (ii) high within-image diversity as judged by the number of different objects, and (iii) a large number of images from ImageNet or PASS all positively affect SR performance. We hope that the proposed simple-yet-effective dataset curation pipeline will inform the construction of SR datasets in the future and yield overall better models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV2024"
    },
    {
        "paper id": "2409.00823",
        "abstract url": "https://arxiv.org/abs/2409.00823",
        "title": "Enhancing Anti-Money Laundering Efforts with Network-Based Algorithms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The global banking system has faced increasing challenges in combating money laundering, necessitating advanced methods for detecting suspicious transactions. Anti-money laundering (or AML) approaches have often relied on predefined thresholds and machine learning algorithms using flagged transaction data, which are limited by the availability and accuracy of existing datasets. In this paper, we introduce a novel algorithm that leverages network analysis to detect potential money laundering activities within large-scale transaction data. Utilizing an anonymized transactional dataset from Co\u00f6peratieve Rabobank U.A., our method combines community detection via the Louvain algorithm and small cycle detection to identify suspicious transaction patterns below the regulatory reporting thresholds. Our approach successfully identifies cycles of transactions that may indicate layering steps in money laundering, providing a valuable tool for financial institutions to enhance their AML efforts. The results suggest the efficacy of our algorithm in pinpointing potentially illicit activities that evade current detection methods.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00824",
        "abstract url": "https://arxiv.org/abs/2409.00824",
        "title": "Accelerating Hybrid Agent-Based Models and Fuzzy Cognitive Maps: How to Combine Agents who Think Alike?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "While Agent-Based Models can create detailed artificial societies based on individual differences and local context, they can be computationally intensive. Modelers may offset these costs through a parsimonious use of the model, for example by using smaller population sizes (which limits analyses in sub-populations), running fewer what-if scenarios, or accepting more uncertainty by performing fewer simulations. Alternatively, researchers may accelerate simulations via hardware solutions (e.g., GPU parallelism) or approximation approaches that operate a tradeoff between accuracy and compute time. In this paper, we present an approximation that combines agents who `think alike', thus reducing the population size and the compute time. Our innovation relies on representing agent behaviors as networks of rules (Fuzzy Cognitive Maps) and empirically evaluating different measures of distance between these networks. Then, we form groups of think-alike agents via community detection and simplify them to a representative agent. Case studies show that our simplifications remain accuracy.",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "comment": "To appear at the 2024 Winter Simulation Conference"
    },
    {
        "paper id": "2409.00826",
        "abstract url": "https://arxiv.org/abs/2409.00826",
        "title": "Digital Homunculi: Reimagining Democracy Research with Generative Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The pace of technological change continues to outstrip the evolution of democratic institutions, creating an urgent need for innovative approaches to democratic reform. However, the experimentation bottleneck - characterized by slow speed, high costs, limited scalability, and ethical risks - has long hindered progress in democracy research. This paper proposes a novel solution: employing generative artificial intelligence (GenAI) to create synthetic data through the simulation of digital homunculi, GenAI-powered entities designed to mimic human behavior in social contexts. By enabling rapid, low-risk experimentation with alternative institutional designs, this approach could significantly accelerate democratic innovation. I examine the potential of GenAI-assisted research to mitigate current limitations in democratic experimentation, including the ability to simulate large-scale societal interactions and test complex institutional mechanisms. While acknowledging potential risks such as algorithmic bias, reproducibility challenges, and AI alignment issues, I argue that the benefits of synthetic data are likely to outweigh their drawbacks if implemented with proper caution. To address existing challenges, I propose a range of technical, methodological, and institutional adaptations. The paper concludes with a call for interdisciplinary collaboration in the development and implementation of GenAI-assisted methods in democracy research, highlighting their potential to bridge the gap between democratic theory and practice in an era of rapid technological change.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "36 pages"
    },
    {
        "paper id": "2409.00837",
        "abstract url": "https://arxiv.org/abs/2409.00837",
        "title": "You-Only-Randomize-Once: Shaping Statistical Properties in Constraint-based PCG",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In procedural content generation, modeling the generation task as a constraint satisfaction problem lets us define local and global constraints on the generated output. However, a generator's perceived quality often involves statistics rather than just hard constraints. For example, we may desire that generated outputs use design elements with a similar distribution to that of reference designs. However, such statistical properties cannot be expressed directly as a hard constraint on the generation of any one output. In contrast, methods which do not use a general-purpose constraint solver, such as Gumin's implementation of the WaveFunctionCollapse (WFC) algorithm, can control output statistics but have limited constraint propagation ability and cannot express non-local constraints. In this paper, we introduce You-Only-Randomize-Once (YORO) pre-rolling, a method for crafting a decision variable ordering for a constraint solver that encodes desired statistics in a constraint-based generator. Using a solver-based WFC as an example, we show that this technique effectively controls the statistics of tile-grid outputs generated by several off-the-shelf SAT solvers, while still enforcing global constraints on the outputs.1 Our approach is immediately applicable to WFC-like generation problems and it offers a conceptual starting point for controlling the design element statistics in other constraint-based generators.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": "Published in Foundations of Digital Games (FDG) 2024. 10 pages, 6 figures"
    },
    {
        "paper id": "2409.00841",
        "abstract url": "https://arxiv.org/abs/2409.00841",
        "title": "Universal Approximation of Operators with Transformers and Neural Integral Operators",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the universal approximation properties of transformers and neural integral operators for operators in Banach spaces. In particular, we show that the transformer architecture is a universal approximator of integral operators between H\u00f6lder spaces. Moreover, we show that a generalized version of neural integral operators, based on the Gavurin integral, are universal approximators of arbitrary operators between Banach spaces. Lastly, we show that a modified version of transformer, which uses Leray-Schauder mappings, is a universal approximator of operators between arbitrary Banach spaces.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": "13 pages. Comments are welcome!"
    },
    {
        "paper id": "2409.00847",
        "abstract url": "https://arxiv.org/abs/2409.00847",
        "title": "The Design of an LLM-powered Unstructured Analytics System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "LLMs demonstrate an uncanny ability to process unstructured data, and as such, have the potential to go beyond search and run complex, semantic analyses at scale. We describe the design of an unstructured analytics system, Aryn, and the tenets and use cases that motivate its design. With Aryn, users can specify queries in natural language and the system automatically determines a semantic plan and executes it to compute an answer from a large collection of unstructured documents using LLMs. At the core of Aryn is Sycamore, a declarative document processing engine, built using Ray, that provides a reliable distributed abstraction called {\\em DocSets}. Sycamore allows users to analyze, enrich, and transform complex documents at scale. Aryn also comprises Luna, a query planner that translates natural language queries to Sycamore scripts, and the Aryn Partitioner, which takes raw PDFs and document images, and converts them to DocSets for downstream processing. Using Aryn, we demonstrate a real world use case for analyzing accident reports from the National Transportation Safety Board (NTSB), and discuss some of the major challenges we encountered in deploying Aryn in the wild.",
        "subjects": [
            "cs.DB",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "6 pages, 3 figures"
    },
    {
        "paper id": "2409.00879",
        "abstract url": "https://arxiv.org/abs/2409.00879",
        "title": "Beyond Parameter Count: Implicit Bias in Soft Mixture of Experts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The traditional viewpoint on Sparse Mixture of Experts (MoE) models is that instead of training a single large expert, which is computationally expensive, we can train many small experts. The hope is that if the total parameter count of the small experts equals that of the singular large expert, then we retain the representation power of the large expert while gaining computational tractability and promoting expert specialization. The recently introduced Soft MoE replaces the Sparse MoE's discrete routing mechanism with a differentiable gating function that smoothly mixes tokens. While this smooth gating function successfully mitigates the various training instabilities associated with Sparse MoE, it is unclear whether it induces implicit biases that affect Soft MoE's representation power or potential for expert specialization. We prove that Soft MoE with a single arbitrarily powerful expert cannot represent simple convex functions. This justifies that Soft MoE's success cannot be explained by the traditional viewpoint of many small experts collectively mimicking the representation power of a single large expert, and that multiple experts are actually necessary to achieve good representation power (even for a fixed total parameter count). Continuing along this line of investigation, we introduce a notion of expert specialization for Soft MoE, and while varying the number of experts yet fixing the total parameter count, we consider the following (computationally intractable) task. Given any input, how can we discover the expert subset that is specialized to predict this input's label? We empirically show that when there are many small experts, the architecture is implicitly biased in a fashion that allows us to efficiently approximate the specialized expert subset. Our method can be easily implemented to potentially reduce computation during inference.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "21 pages, 5 figures, 13 tables"
    },
    {
        "paper id": "2409.00880",
        "abstract url": "https://arxiv.org/abs/2409.00880",
        "title": "Compressing VAE-Based Out-of-Distribution Detectors for Embedded Deployment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Out-of-distribution (OOD) detectors can act as safety monitors in embedded cyber-physical systems by identifying samples outside a machine learning model's training distribution to prevent potentially unsafe actions. However, OOD detectors are often implemented using deep neural networks, which makes it difficult to meet real-time deadlines on embedded systems with memory and power constraints. We consider the class of variational autoencoder (VAE) based OOD detectors where OOD detection is performed in latent space, and apply quantization, pruning, and knowledge distillation. These techniques have been explored for other deep models, but no work has considered their combined effect on latent space OOD detection. While these techniques increase the VAE's test loss, this does not correspond to a proportional decrease in OOD detection performance and we leverage this to develop lean OOD detectors capable of real-time inference on embedded CPUs and GPUs. We propose a design methodology that combines all three compression techniques and yields a significant decrease in memory and execution time while maintaining AUROC for a given OOD detector. We demonstrate this methodology with two existing OOD detectors on a Jetson Nano and reduce GPU and CPU inference time by 20% and 28% respectively while keeping AUROC within 5% of the baseline.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to IEEE RTCSA 2024"
    },
    {
        "paper id": "2409.00894",
        "abstract url": "https://arxiv.org/abs/2409.00894",
        "title": "Improving Adaptivity via Over-Parameterization in Sequence Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "It is well known that eigenfunctions of a kernel play a crucial role in kernel regression. Through several examples, we demonstrate that even with the same set of eigenfunctions, the order of these functions significantly impacts regression outcomes. Simplifying the model by diagonalizing the kernel, we introduce an over-parameterized gradient descent in the realm of sequence model to capture the effects of various orders of a fixed set of eigen-functions. This method is designed to explore the impact of varying eigenfunction orders. Our theoretical results show that the over-parameterization gradient flow can adapt to the underlying structure of the signal and significantly outperform the vanilla gradient flow method. Moreover, we also demonstrate that deeper over-parameterization can further enhance the generalization capability of the model. These results not only provide a new perspective on the benefits of over-parameterization and but also offer insights into the adaptivity and generalization potential of neural networks beyond the kernel regime.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00899",
        "abstract url": "https://arxiv.org/abs/2409.00899",
        "title": "MarsCode Agent: AI-native Automated Bug Fixing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advances in large language models (LLMs) have shown significant potential to automate various software development tasks, including code completion, test generation, and bug fixing. However, the application of LLMs for automated bug fixing remains challenging due to the complexity and diversity of real-world software systems. In this paper, we introduce MarsCode Agent, a novel framework that leverages LLMs to automatically identify and repair bugs in software code. MarsCode Agent combines the power of LLMs with advanced code analysis techniques to accurately localize faults and generate patches. Our approach follows a systematic process of planning, bug reproduction, fault localization, candidate patch generation, and validation to ensure high-quality bug fixes. We evaluated MarsCode Agent on SWE-bench, a comprehensive benchmark of real-world software projects, and our results show that MarsCode Agent achieves a high success rate in bug fixing compared to most of the existing automated approaches.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Yizhou Liu and Pengfei Gao contributed equally and the order is determined by rolling the dice. Chao Peng is the corresponding author"
    },
    {
        "paper id": "2409.00913",
        "abstract url": "https://arxiv.org/abs/2409.00913",
        "title": "Generalized Continuous-Time Models for Nesterov's Accelerated Gradient Methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent research has indicated a substantial rise in interest in understanding Nesterov's accelerated gradient methods via their continuous-time models. However, most existing studies focus on specific classes of Nesterov's methods, which hinders the attainment of an in-depth understanding and a unified perspective. To address this deficit, we present generalized continuous-time models that cover a broad range of Nesterov's methods, including those previously studied under existing continuous-time frameworks. Our key contributions are as follows. First, we identify the convergence rates of the generalized models, eliminating the need to determine the convergence rate for any specific continuous-time model derived from them. Second, we show that six existing continuous-time models are special cases of our generalized models, thereby positioning our framework as a unifying tool for analyzing and understanding these models. Third, we design a restart scheme for Nesterov's methods based on our generalized models and show that it ensures a monotonic decrease in objective function values. Owing to the broad applicability of our models, this scheme can be used to a broader class of Nesterov's methods compared to the original restart scheme. Fourth, we uncover a connection between our generalized models and gradient flow in continuous time, showing that the accelerated convergence rates of our generalized models can be attributed to a time reparametrization in gradient flow. Numerical experiment results are provided to support our theoretical analyses and results.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00921",
        "abstract url": "https://arxiv.org/abs/2409.00921",
        "title": "Statically Contextualizing Large Language Models with Typed Holes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models (LLMs) have reshaped the landscape of program synthesis. However, contemporary LLM-based code completion systems often hallucinate broken code because they lack appropriate context, particularly when working with definitions not in the training data nor near the cursor. This paper demonstrates that tight integration with the type and binding structure of a language, as exposed by its language server, can address this contextualization problem in a token-efficient manner. In short, we contend that AIs need IDEs, too! In particular, we integrate LLM code generation into the Hazel live program sketching environment. The Hazel Language Server identifies the type and typing context of the hole being filled, even in the presence of errors, ensuring that a meaningful program sketch is always available. This allows prompting with codebase-wide contextual information not lexically local to the cursor, nor necessarily in the same file, but that is likely to be semantically local to the developer's goal. Completions synthesized by the LLM are then iteratively refined via further dialog with the language server. To evaluate these techniques, we introduce MVUBench, a dataset of model-view-update (MVU) web applications. These applications serve as challenge problems due to their reliance on application-specific data structures. We find that contextualization with type definitions is particularly impactful. After introducing our ideas in the context of Hazel we duplicate our techniques and port MVUBench to TypeScript in order to validate the applicability of these methods to higher-resource languages. Finally, we outline ChatLSP, a conservative extension to the Language Server Protocol (LSP) that language servers can implement to expose capabilities that AI code completion systems of various designs can use to incorporate static context when generating prompts for an LLM.",
        "subjects": [
            "cs.PL",
            "cs.AI",
            "cs.SE"
        ],
        "comment": "To appear at OOPSLA2024"
    },
    {
        "paper id": "2409.00617",
        "abstract url": "https://arxiv.org/abs/2409.00617",
        "title": "Does Knowledge Localization Hold True? Surprising Differences Between Entity and Relation Perspectives in Language Models",
        "rating": "0",
        "keywords": [
            [
                "knowledge editing"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models encapsulate knowledge and have demonstrated superior performance on various natural language processing tasks. Recent studies have localized this knowledge to specific model parameters, such as the MLP weights in intermediate layers. This study investigates the differences between entity and relational knowledge through knowledge editing. Our findings reveal that entity and relational knowledge cannot be directly transferred or mapped to each other. This result is unexpected, as logically, modifying the entity or the relation within the same knowledge triplet should yield equivalent outcomes. To further elucidate the differences between entity and relational knowledge, we employ causal analysis to investigate how relational knowledge is stored in pre-trained models. Contrary to prior research suggesting that knowledge is stored in MLP weights, our experiments demonstrate that relational knowledge is also significantly encoded in attention modules. This insight highlights the multifaceted nature of knowledge storage in language models, underscoring the complexity of manipulating specific types of knowledge within these models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "CIKM 2024"
    },
    {
        "paper id": "2409.00618",
        "abstract url": "https://arxiv.org/abs/2409.00618",
        "title": "YOLOO: You Only Learn from Others Once",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal 3D multi-object tracking (MOT) typically necessitates extensive computational costs of deep neural networks (DNNs) to extract multi-modal representations. In this paper, we propose an intriguing question: May we learn from multiple modalities only during training to avoid multi-modal input in the inference phase? To answer it, we propose \\textbf{YOLOO}, a novel multi-modal 3D MOT paradigm: You Only Learn from Others Once. YOLOO empowers the point cloud encoder to learn a unified tri-modal representation (UTR) from point clouds and other modalities, such as images and textual cues, all at once. Leveraging this UTR, YOLOO achieves efficient tracking solely using the point cloud encoder without compromising its performance, fundamentally obviating the need for computationally intensive DNNs. Specifically, YOLOO includes two core components: a unified tri-modal encoder (UTEnc) and a flexible geometric constraint (F-GC) module. UTEnc integrates a point cloud encoder with image and text encoders adapted from pre-trained CLIP. It seamlessly fuses point cloud information with rich visual-textual knowledge from CLIP into the point cloud encoder, yielding highly discriminative UTRs that facilitate the association between trajectories and detections. Additionally, F-GC filters out mismatched associations with similar representations but significant positional discrepancies. It further enhances the robustness of UTRs without requiring any scene-specific tuning, addressing a key limitation of customized geometric constraints (e.g., 3D IoU). Lastly, high-quality 3D trajectories are generated by a traditional data association component. By integrating these advancements into a multi-modal 3D MOT scheme, our YOLOO achieves substantial gains in both robustness and efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00638",
        "abstract url": "https://arxiv.org/abs/2409.00638",
        "title": "IGEV++: Iterative Multi-range Geometry Encoding Volumes for Stereo Matching",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Stereo matching is a core component in many computer vision and robotics systems. Despite significant advances over the last decade, handling matching ambiguities in ill-posed regions and large disparities remains an open challenge. In this paper, we propose a new deep network architecture, called IGEV++, for stereo matching. The proposed IGEV++ builds Multi-range Geometry Encoding Volumes (MGEV) that encode coarse-grained geometry information for ill-posed regions and large disparities and fine-grained geometry information for details and small disparities. To construct MGEV, we introduce an adaptive patch matching module that efficiently and effectively computes matching costs for large disparity ranges and/or ill-posed regions. We further propose a selective geometry feature fusion module to adaptively fuse multi-range and multi-granularity geometry features in MGEV. We then index the fused geometry features and input them to ConvGRUs to iteratively update the disparity map. MGEV allows to efficiently handle large disparities and ill-posed regions, such as occlusions and textureless regions, and enjoys rapid convergence during iterations. Our IGEV++ achieves the best performance on the Scene Flow test set across all disparity ranges, up to 768px. Our IGEV++ also achieves state-of-the-art accuracy on the Middlebury, ETH3D, KITTI 2012, and 2015 benchmarks. Specifically, IGEV++ achieves a 3.23% 2-pixel outlier rate (Bad 2.0) on the large disparity benchmark, Middlebury, representing error reductions of 31.9% and 54.8% compared to RAFT-Stereo and GMStereo, respectively. We also present a real-time version of IGEV++ that achieves the best performance among all published real-time methods on the KITTI benchmarks. The code is publicly available at https://github.com/gangweiX/IGEV-plusplus",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 10 figures"
    },
    {
        "paper id": "2409.00654",
        "abstract url": "https://arxiv.org/abs/2409.00654",
        "title": "Seed-to-Seed: Image Translation in Diffusion Seed Space",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "GAN",
                "image editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce Seed-to-Seed Translation (StS), a novel approach for Image-to-Image Translation using diffusion models (DMs), aimed at translations that require close adherence to the structure of the source image. In contrast to existing methods that modify images during the diffusion sampling process, we leverage the semantic information encoded within the space of inverted seeds of a pretrained DM, dubbed as the seed-space. We demonstrate that inverted seeds can be used for discriminative tasks, and can also be manipulated to achieve desired transformations in an unpaired image-to-image translation setting. Our method involves training an sts-GAN, an unpaired translation model between source and target seeds, based on CycleGAN. The final translated images are obtained by initiating the DM's sampling process from the translated seeds. A ControlNet is used to ensure the structural preservation of the input image. We demonstrate the effectiveness of our approach for the task of translating automotive scenes, showcasing superior performance compared to existing GAN-based and diffusion-based methods, as well as for several other unpaired image translation tasks. Our approach offers a fresh perspective on leveraging the semantic information encoded within the seed-space of pretrained DMs for effective image editing and manipulation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00657",
        "abstract url": "https://arxiv.org/abs/2409.00657",
        "title": "HopGNN: Boosting Distributed GNN Training Efficiency via Feature-Centric Model Migration",
        "rating": "0",
        "keywords": [
            [
                "Training Efficiency"
            ],
            [
                "GNN",
                "graph"
            ]
        ],
        "abstract": "Distributed training of graph neural networks (GNNs) has become a crucial technique for processing large graphs. Prevalent GNN frameworks are model-centric, necessitating the transfer of massive graph vertex features to GNN models, which leads to a significant communication bottleneck. Recognizing that the model size is often significantly smaller than the feature size, we propose LeapGNN, a feature-centric framework that reverses this paradigm by bringing GNN models to vertex features. To make it truly effective, we first propose a micrograph-based training strategy that trains the model using a refined structure with superior locality to reduce remote feature retrieval. Then, we devise a feature pre-gathering approach that merges multiple fetch operations into a single one to eliminate redundant feature transmissions. Finally, we employ a micrograph-based merging method that adjusts the number of micrographs for each worker to minimize kernel switches and synchronization overhead. Our experimental results demonstrate that LeapGNN achieves a performance speedup of up to 4.2x compared to the state-of-the-art method, namely P3.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00665",
        "abstract url": "https://arxiv.org/abs/2409.00665",
        "title": "Disparity Estimation Using a Quad-Pixel Sensor",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A quad-pixel (QP) sensor is increasingly integrated into commercial mobile cameras. The QP sensor has a unit of 2$\\times$2 four photodiodes under a single microlens, generating multi-directional phase shifting when out-focus blurs occur. Similar to a dual-pixel (DP) sensor, the phase shifting can be regarded as stereo disparity and utilized for depth estimation. Based on this, we propose a QP disparity estimation network (QPDNet), which exploits abundant QP information by fusing vertical and horizontal stereo-matching correlations for effective disparity estimation. We also present a synthetic pipeline to generate a training dataset from an existing RGB-Depth dataset. Experimental results demonstrate that our QPDNet outperforms state-of-the-art stereo and DP methods. Our code and synthetic dataset are available at https://github.com/Zhuofeng-Wu/QPDNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00690",
        "abstract url": "https://arxiv.org/abs/2409.00690",
        "title": "Decoupled and Interactive Regression Modeling for High-performance One-stage 3D Object Detection",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Inadequate bounding box modeling in regression tasks constrains the performance of one-stage 3D object detection. Our study reveals that the primary reason lies in two aspects: (1) The limited center-offset prediction seriously impairs the bounding box localization since many highest response positions significantly deviate from object centers. (2) The low-quality sample ignored in regression tasks significantly impacts the bounding box prediction since it produces unreliable quality (IoU) rectification. To tackle these problems, we propose Decoupled and Interactive Regression Modeling (DIRM) for one-stage detection. Specifically, Decoupled Attribute Regression (DAR) is implemented to facilitate long regression range modeling for the center attribute through an adaptive multi-sample assignment strategy that deeply decouples bounding box attributes. On the other hand, to enhance the reliability of IoU predictions for low-quality results, Interactive Quality Prediction (IQP) integrates the classification task, proficient in modeling negative samples, with quality prediction for joint optimization. Extensive experiments on Waymo and ONCE datasets demonstrate that DIRM significantly improves the performance of several state-of-the-art methods with minimal additional inference latency. Notably, DIRM achieves state-of-the-art detection performance on both the Waymo and ONCE datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00698",
        "abstract url": "https://arxiv.org/abs/2409.00698",
        "title": "Enhancing Remote Sensing Vision-Language Models for Zero-Shot Scene Classification",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-Language Models for remote sensing have shown promising uses thanks to their extensive pretraining. However, their conventional usage in zero-shot scene classification methods still involves dividing large images into patches and making independent predictions, i.e., inductive inference, thereby limiting their effectiveness by ignoring valuable contextual information. Our approach tackles this issue by utilizing initial predictions based on text prompting and patch affinity relationships from the image encoder to enhance zero-shot capabilities through transductive inference, all without the need for supervision and at a minor computational cost. Experiments on 10 remote sensing datasets with state-of-the-art Vision-Language Models demonstrate significant accuracy improvements over inductive zero-shot classification. Our source code is publicly available on Github: https://github.com/elkhouryk/RS-TransCLIP",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00727",
        "abstract url": "https://arxiv.org/abs/2409.00727",
        "title": "Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Text-attributed graph (TAG) is an important type of graph structured data with text descriptions for each node. Few- and zero-shot node classification on TAGs have many applications in fields such as academia and social networks. However, the two tasks are challenging due to the lack of supervision signals, and existing methods only use the contrastive loss to align graph-based node embedding and language-based text embedding. In this paper, we propose Hound to improve accuracy by introducing more supervision signals, and the core idea is to go beyond the node-text pairs that come with data. Specifically, we design three augmentation techniques, i.e., node perturbation, text matching, and semantics negation to provide more reference nodes for each text and vice versa. Node perturbation adds/drops edges to produce diversified node embeddings that can be matched with a text. Text matching retrieves texts with similar embeddings to match with a node. Semantics negation uses a negative prompt to construct a negative text with the opposite semantics, which is contrasted with the original node and text. We evaluate Hound on 5 datasets and compare with 13 state-of-the-art baselines. The results show that Hound consistently outperforms all baselines, and its accuracy improvements over the best-performing baseline are usually over 5%.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00729",
        "abstract url": "https://arxiv.org/abs/2409.00729",
        "title": "ContextCite: Attributing Model Generation to Context",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "How do language models use information provided as context when generating a response? Can we infer whether a particular generated statement is actually grounded in the context, a misinterpretation, or fabricated? To help answer these questions, we introduce the problem of context attribution: pinpointing the parts of the context (if any) that led a model to generate a particular statement. We then present ContextCite, a simple and scalable method for context attribution that can be applied on top of any existing language model. Finally, we showcase the utility of ContextCite through three applications: (1) helping verify generated statements (2) improving response quality by pruning the context and (3) detecting poisoning attacks. We provide code for ContextCite at https://github.com/MadryLab/context-cite.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00736",
        "abstract url": "https://arxiv.org/abs/2409.00736",
        "title": "MoManifold: Learning to Measure 3D Human Motion via Decoupled Joint Acceleration Manifolds",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Incorporating temporal information effectively is important for accurate 3D human motion estimation and generation which have wide applications from human-computer interaction to AR/VR. In this paper, we present MoManifold, a novel human motion prior, which models plausible human motion in continuous high-dimensional motion space. Different from existing mathematical or VAE-based methods, our representation is designed based on the neural distance field, which makes human dynamics explicitly quantified to a score and thus can measure human motion plausibility. Specifically, we propose novel decoupled joint acceleration manifolds to model human dynamics from existing limited motion data. Moreover, we introduce a novel optimization method using the manifold distance as guidance, which facilitates a variety of motion-related tasks. Extensive experiments demonstrate that MoManifold outperforms existing SOTAs as a prior in several downstream tasks such as denoising real-world human mocap data, recovering human motion from partial 3D observations, mitigating jitters for SMPL-based pose estimators, and refining the results of motion in-betweening.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by BMVC 2024. Supplementary material is included at the end of the main paper (12 pages, 11 figures, 5 tables)"
    },
    {
        "paper id": "2409.00786",
        "abstract url": "https://arxiv.org/abs/2409.00786",
        "title": "Zero-Shot Paragraph-level Handwriting Imitation with Latent Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The imitation of cursive handwriting is mainly limited to generating handwritten words or lines. Multiple synthetic outputs must be stitched together to create paragraphs or whole pages, whereby consistency and layout information are lost. To close this gap, we propose a method for imitating handwriting at the paragraph level that also works for unseen writing styles. Therefore, we introduce a modified latent diffusion model that enriches the encoder-decoder mechanism with specialized loss functions that explicitly preserve the style and content. We enhance the attention mechanism of the diffusion model with adaptive 2D positional encoding and the conditioning mechanism to work with two modalities simultaneously: a style image and the target text. This significantly improves the realism of the generated handwriting. Our approach sets a new benchmark in our comprehensive evaluation. It outperforms all existing imitation methods at both line and paragraph levels, considering combined style and content preservation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00787",
        "abstract url": "https://arxiv.org/abs/2409.00787",
        "title": "The Dark Side of Human Feedback: Poisoning Large Language Models via User Inputs",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated great capabilities in natural language understanding and generation, largely attributed to the intricate alignment process using human feedback. While alignment has become an essential training component that leverages data collected from user queries, it inadvertently opens up an avenue for a new type of user-guided poisoning attacks. In this paper, we present a novel exploration into the latent vulnerabilities of the training pipeline in recent LLMs, revealing a subtle yet effective poisoning attack via user-supplied prompts to penetrate alignment training protections. Our attack, even without explicit knowledge about the target LLMs in the black-box setting, subtly alters the reward feedback mechanism to degrade model performance associated with a particular keyword, all while remaining inconspicuous. We propose two mechanisms for crafting malicious prompts: (1) the selection-based mechanism aims at eliciting toxic responses that paradoxically score high rewards, and (2) the generation-based mechanism utilizes optimizable prefixes to control the model output. By injecting 1\\% of these specially crafted prompts into the data, through malicious users, we demonstrate a toxicity score up to two times higher when a specific trigger word is used. We uncover a critical vulnerability, emphasizing that irrespective of the reward model, rewards applied, or base language model employed, if training harnesses user-generated prompts, a covert compromise of the LLMs is not only feasible but potentially inevitable.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00788",
        "abstract url": "https://arxiv.org/abs/2409.00788",
        "title": "Modeling Text-Label Alignment for Hierarchical Text Classification",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Hierarchical Text Classification (HTC) aims to categorize text data based on a structured label hierarchy, resulting in predicted labels forming a sub-hierarchy tree. The semantics of the text should align with the semantics of the labels in this sub-hierarchy. With the sub-hierarchy changing for each sample, the dynamic nature of text-label alignment poses challenges for existing methods, which typically process text and labels independently. To overcome this limitation, we propose a Text-Label Alignment (TLA) loss specifically designed to model the alignment between text and labels. We obtain a set of negative labels for a given text and its positive label set. By leveraging contrastive learning, the TLA loss pulls the text closer to its positive label and pushes it away from its negative label in the embedding space. This process aligns text representations with related labels while distancing them from unrelated ones. Building upon this framework, we introduce the Hierarchical Text-Label Alignment (HTLA) model, which leverages BERT as the text encoder and GPTrans as the graph encoder and integrates text-label embeddings to generate hierarchy-aware representations. Experimental results on benchmark datasets and comparison with existing baselines demonstrate the effectiveness of HTLA for HTC.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted in ECML-PKDD 2024 Research Track"
    },
    {
        "paper id": "2409.00807",
        "abstract url": "https://arxiv.org/abs/2409.00807",
        "title": "Diffusion based multi-domain neuroimaging harmonization method with preservation of anatomical details",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "GAN"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Multi-center neuroimaging studies face technical variability due to batch differences across sites, which potentially hinders data aggregation and impacts study reliability.Recent efforts in neuroimaging harmonization have aimed to minimize these technical gaps and reduce technical variability across batches. While Generative Adversarial Networks (GAN) has been a prominent method for addressing image harmonization tasks, GAN-harmonized images suffer from artifacts or anatomical distortions. Given the advancements of denoising diffusion probabilistic model which produces high-fidelity images, we have assessed the efficacy of the diffusion model for neuroimaging harmonization. we have demonstrated the diffusion model's superior capability in harmonizing images from multiple domains, while GAN-based methods are limited to harmonizing images between two domains per model. Our experiments highlight that the learned domain invariant anatomical condition reinforces the model to accurately preserve the anatomical details while differentiating batch differences at each diffusion step. Our proposed method has been tested on two public neuroimaging dataset ADNI1 and ABIDE II, yielding harmonization results with consistent anatomy preservation and superior FID score compared to the GAN-based methods. We have conducted multiple analysis including extensive quantitative and qualitative evaluations against the baseline models, ablation study showcasing the benefits of the learned conditions, and improvements in the consistency of perivascular spaces (PVS) segmentation through harmonization.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00829",
        "abstract url": "https://arxiv.org/abs/2409.00829",
        "title": "Curvy: A Parametric Cross-section based Surface Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this work, we present a novel approach for reconstructing shape point clouds using planar sparse cross-sections with the help of generative modeling. We present unique challenges pertaining to the representation and reconstruction in this problem setting. Most methods in the classical literature lack the ability to generalize based on object class and employ complex mathematical machinery to reconstruct reliable surfaces. We present a simple learnable approach to generate a large number of points from a small number of input cross-sections over a large dataset. We use a compact parametric polyline representation using adaptive splitting to represent the cross-sections and perform learning using a Graph Neural Network to reconstruct the underlying shape in an adaptive manner reducing the dependence on the number of cross-sections provided.",
        "subjects": [
            "cs.CV",
            "cs.CG",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00839",
        "abstract url": "https://arxiv.org/abs/2409.00839",
        "title": "Entropy Loss: An Interpretability Amplifier of 3D Object Detection Network for Intelligent Driving",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "With the increasing complexity of the traffic environment, the significance of safety perception in intelligent driving is intensifying. Traditional methods in the field of intelligent driving perception rely on deep learning, which suffers from limited interpretability, often described as a \"black box.\" This paper introduces a novel type of loss function, termed \"Entropy Loss,\" along with an innovative training strategy. Entropy Loss is formulated based on the functionality of feature compression networks within the perception model. Drawing inspiration from communication systems, the information transmission process in a feature compression network is expected to demonstrate steady changes in information volume and a continuous decrease in information entropy. By modeling network layer outputs as continuous random variables, we construct a probabilistic model that quantifies changes in information volume. Entropy Loss is then derived based on these expectations, guiding the update of network parameters to enhance network interpretability. Our experiments indicate that the Entropy Loss training strategy accelerates the training process. Utilizing the same 60 training epochs, the accuracy of 3D object detection models using Entropy Loss on the KITTI test set improved by up to 4.47\\% compared to models without Entropy Loss, underscoring the method's efficacy. The implementation code is available at \\url{https://github.com/yhbcode000/Eloss-Interpretability}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00884",
        "abstract url": "https://arxiv.org/abs/2409.00884",
        "title": "A Novel Hybrid Parameter-Efficient Fine-Tuning Approach for Hippocampus Segmentation and Alzheimer's Disease Diagnosis",
        "rating": "0",
        "keywords": [
            [
                "Parameter-Efficient",
                "Efficient Fine-Tuning"
            ],
            [
                "medical",
                "Diagnosis",
                "Disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Deep learning methods have significantly advanced medical image segmentation, yet their success hinges on large volumes of manually annotated data, which require specialized expertise for accurate labeling. Additionally, these methods often demand substantial computational resources, particularly for three-dimensional medical imaging tasks. Consequently, applying deep learning techniques for medical image segmentation with limited annotated data and computational resources remains a critical challenge. In this paper, we propose a novel parameter-efficient fine-tuning strategy, termed HyPS, which employs a hybrid parallel and serial architecture. HyPS updates a minimal subset of model parameters, thereby retaining the pre-trained model's original knowledge tructure while enhancing its ability to learn specific features relevant to downstream tasks. We apply this strategy to the state-of-the-art SwinUNETR model for medical image segmentation. Initially, the model is pre-trained on the BraTs2021 dataset, after which the HyPS method is employed to transfer it to three distinct hippocampus datasets.Extensive experiments demonstrate that HyPS outperforms baseline methods, especially in scenarios with limited training samples. Furthermore, based on the segmentation results, we calculated the hippocampal volumes of subjects from the ADNI dataset and combined these with metadata to classify disease types. In distinguishing Alzheimer's disease (AD) from cognitively normal (CN) individuals, as well as early mild cognitive impairment (EMCI) from late mild cognitive impairment (LMCI), HyPS achieved classification accuracies of 83.78% and 64.29%, respectively. These findings indicate that the HyPS method not only facilitates effective hippocampal segmentation using pre-trained models but also holds potential for aiding Alzheimer's disease detection. Our code is publicly available.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00896",
        "abstract url": "https://arxiv.org/abs/2409.00896",
        "title": "A Noise and Edge extraction-based dual-branch method for Shallowfake and Deepfake Localization",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The trustworthiness of multimedia is being increasingly evaluated by advanced Image Manipulation Localization (IML) techniques, resulting in the emergence of the IML field. An effective manipulation model necessitates the extraction of non-semantic differential features between manipulated and legitimate sections to utilize artifacts. This requires direct comparisons between the two regions.. Current models employ either feature approaches based on handcrafted features, convolutional neural networks (CNNs), or a hybrid approach that combines both. Handcrafted feature approaches presuppose tampering in advance, hence restricting their effectiveness in handling various tampering procedures, but CNNs capture semantic information, which is insufficient for addressing manipulation artifacts. In order to address these constraints, we have developed a dual-branch model that integrates manually designed feature noise with conventional CNN features. This model employs a dual-branch strategy, where one branch integrates noise characteristics and the other branch integrates RGB features using the hierarchical ConvNext Module. In addition, the model utilizes edge supervision loss to acquire boundary manipulation information, resulting in accurate localization at the edges. Furthermore, this architecture utilizes a feature augmentation module to optimize and refine the presentation of attributes. The shallowfakes dataset (CASIA, COVERAGE, COLUMBIA, NIST16) and deepfake dataset Faceforensics++ (FF++) underwent thorough testing to demonstrate their outstanding ability to extract features and their superior performance compared to other baseline models. The AUC score achieved an astounding 99%. The model is superior in comparison and easily outperforms the existing state-of-the-art (SoTA) models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00904",
        "abstract url": "https://arxiv.org/abs/2409.00904",
        "title": "Multi-scale Temporal Fusion Transformer for Incomplete Vehicle Trajectory Prediction",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "Trajectory",
                "Vehicle"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Motion prediction plays an essential role in autonomous driving systems, enabling autonomous vehicles to achieve more accurate local-path planning and driving decisions based on predictions of the surrounding vehicles. However, existing methods neglect the potential missing values caused by object occlusion, perception failures, etc., which inevitably degrades the trajectory prediction performance in real traffic scenarios. To address this limitation, we propose a novel end-to-end framework for incomplete vehicle trajectory prediction, named Multi-scale Temporal Fusion Transformer (MTFT), which consists of the Multi-scale Attention Head (MAH) and the Continuity Representation-guided Multi-scale Fusion (CRMF) module. Specifically, the MAH leverages the multi-head attention mechanism to parallelly capture multi-scale motion representation of trajectory from different temporal granularities, thus mitigating the adverse effect of missing values on prediction. Furthermore, the multi-scale motion representation is input into the CRMF module for multi-scale fusion to obtain the robust temporal feature of the vehicle. During the fusion process, the continuity representation of vehicle motion is first extracted across time steps to guide the fusion, ensuring that the resulting temporal feature incorporates both detailed information and the overall trend of vehicle motion, which facilitates the accurate decoding of future trajectory that is consistent with the vehicle's motion trend. We evaluate the proposed model on four datasets derived from highway and urban traffic scenarios. The experimental results demonstrate its superior performance in the incomplete vehicle trajectory prediction task compared with state-of-the-art models, e.g., a comprehensive performance improvement of more than 39% on the HighD dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00633",
        "abstract url": "https://arxiv.org/abs/2409.00633",
        "title": "Make Your ViT-based Multi-view 3D Detectors Faster via Token Compression",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Slow inference speed is one of the most crucial concerns for deploying multi-view 3D detectors to tasks with high real-time requirements like autonomous driving. Although many sparse query-based methods have already attempted to improve the efficiency of 3D detectors, they neglect to consider the backbone, especially when using Vision Transformers (ViT) for better performance. To tackle this problem, we explore the efficient ViT backbones for multi-view 3D detection via token compression and propose a simple yet effective method called TokenCompression3D (ToC3D). By leveraging history object queries as foreground priors of high quality, modeling 3D motion information in them, and interacting them with image tokens through the attention mechanism, ToC3D can effectively determine the magnitude of information densities of image tokens and segment the salient foreground tokens. With the introduced dynamic router design, ToC3D can weigh more computing resources to important foreground tokens while compressing the information loss, leading to a more efficient ViT-based multi-view 3D detector. Extensive results on the large-scale nuScenes dataset show that our method can nearly maintain the performance of recent SOTA with up to 30% inference speedup, and the improvements are consistent after scaling up the ViT and input resolution. The code will be made at https://github.com/DYZhang09/ToC3D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2409.00668",
        "abstract url": "https://arxiv.org/abs/2409.00668",
        "title": "Data-driven ODE modeling of the high-frequency complex dynamics of a fluid flow",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In our previous paper [N. Tsutsumi, K. Nakai and Y. Saiki, Chaos 32, 091101 (2022)], we proposed a method for constructing a system of differential equations of chaotic behavior from only observable deterministic time series, which we call the radial function-based regression (RfR) method. However, when the targeted variable's behavior is rather complex, the direct application of the RfR method does not function well. In this study, we propose a novel method of modeling such dynamics, including the high-frequency intermittent behavior of a fluid flow, by considering another variable (base variable) showing relatively simple, less intermittent behavior. We construct an autonomous joint model composed of two parts: the first is an autonomous system of a base variable, and the other concerns the targeted variable being affected by a term involving the base variable to demonstrate complex dynamics. The constructed joint model succeeded in not only inferring a short trajectory but also reconstructing chaotic sets and statistical properties obtained from a long trajectory such as the density distributions of the actual dynamics.",
        "subjects": [
            "nlin.CD",
            "cs.LG",
            "physics.data-an",
            "stat.ML"
        ],
        "comment": "7pages, 6figures"
    },
    {
        "paper id": "2409.00670",
        "abstract url": "https://arxiv.org/abs/2409.00670",
        "title": "Towards Faster Graph Partitioning via Pre-training and Inductive Inference",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph partitioning (GP) is a classic problem that divides the node set of a graph into densely-connected blocks. Following the IEEE HPEC Graph Challenge and recent advances in pre-training techniques (e.g., large-language models), we propose PR-GPT (Pre-trained & Refined Graph ParTitioning) based on a novel pre-training & refinement paradigm. We first conduct the offline pre-training of a deep graph learning (DGL) model on small synthetic graphs with various topology properties. By using the inductive inference of DGL, one can directly generalize the pre-trained model (with frozen model parameters) to large graphs and derive feasible GP results. We also use the derived partition as a good initialization of an efficient GP method (e.g., InfoMap) to further refine the quality of partitioning. In this setting, the online generalization and refinement of PR-GPT can not only benefit from the transfer ability regarding quality but also ensure high inference efficiency without re-training. Based on a mechanism of reducing the scale of a graph to be processed by the refinement method, PR-GPT also has the potential to support streaming GP. Experiments on the Graph Challenge benchmark demonstrate that PR-GPT can ensure faster GP on large-scale graphs without significant quality degradation, compared with running a refinement method from scratch. We will make our code public at https://github.com/KuroginQin/PRGPT.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": "Champion winner of IEEE HPEC 2024 Graph Challenge (https://graphchallenge.mit.edu/champions)"
    },
    {
        "paper id": "2409.00687",
        "abstract url": "https://arxiv.org/abs/2409.00687",
        "title": "When Heterophily Meets Heterogeneous Graphs: Latent Graphs Guided Unsupervised Representation Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Unsupervised heterogeneous graph representation learning (UHGRL) has gained increasing attention due to its significance in handling practical graphs without labels. However, heterophily has been largely ignored, despite its ubiquitous presence in real-world heterogeneous graphs. In this paper, we define semantic heterophily and propose an innovative framework called Latent Graphs Guided Unsupervised Representation Learning (LatGRL) to handle this problem. First, we develop a similarity mining method that couples global structures and attributes, enabling the construction of fine-grained homophilic and heterophilic latent graphs to guide the representation learning. Moreover, we propose an adaptive dual-frequency semantic fusion mechanism to address the problem of node-level semantic heterophily. To cope with the massive scale of real-world data, we further design a scalable implementation. Extensive experiments on benchmark datasets validate the effectiveness and efficiency of our proposed framework. The source code and datasets have been made available at https://github.com/zxlearningdeep/LatGRL.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SI"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.00730",
        "abstract url": "https://arxiv.org/abs/2409.00730",
        "title": "Generating Physical Dynamics under Priors",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generating physically feasible dynamics in a data-driven context is challenging, especially when adhering to physical priors expressed in specific equations or formulas. Existing methodologies often overlook the integration of physical priors, resulting in violation of basic physical laws and suboptimal performance. In this paper, we introduce a novel framework that seamlessly incorporates physical priors into diffusion-based generative models to address this limitation. Our approach leverages two categories of priors: 1) distributional priors, such as roto-translational invariance, and 2) physical feasibility priors, including energy and momentum conservation laws and PDE constraints. By embedding these priors into the generative process, our method can efficiently generate physically realistic dynamics, encompassing trajectories and flows. Empirical evaluations demonstrate that our method produces high-quality dynamics across a diverse array of physical phenomena with remarkable robustness, underscoring its potential to advance data-driven studies in AI4Physics. Our contributions signify a substantial advancement in the field of generative modeling, offering a robust solution to generate accurate and physically consistent dynamics.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00749",
        "abstract url": "https://arxiv.org/abs/2409.00749",
        "title": "Assessing UHD Image Quality from Aesthetics, Distortions, and Saliency",
        "rating": "-0.5",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "UHD images, typically with resolutions equal to or higher than 4K, pose a significant challenge for efficient image quality assessment (IQA) algorithms, as adopting full-resolution images as inputs leads to overwhelming computational complexity and commonly used pre-processing methods like resizing or cropping may cause substantial loss of detail. To address this problem, we design a multi-branch deep neural network (DNN) to assess the quality of UHD images from three perspectives: global aesthetic characteristics, local technical distortions, and salient content perception. Specifically, aesthetic features are extracted from low-resolution images downsampled from the UHD ones, which lose high-frequency texture information but still preserve the global aesthetics characteristics. Technical distortions are measured using a fragment image composed of mini-patches cropped from UHD images based on the grid mini-patch sampling strategy. The salient content of UHD images is detected and cropped to extract quality-aware features from the salient regions. We adopt the Swin Transformer Tiny as the backbone networks to extract features from these three perspectives. The extracted features are concatenated and regressed into quality scores by a two-layer multi-layer perceptron (MLP) network. We employ the mean square error (MSE) loss to optimize prediction accuracy and the fidelity loss to optimize prediction monotonicity. Experimental results show that the proposed model achieves the best performance on the UHD-IQA dataset while maintaining the lowest computational complexity, demonstrating its effectiveness and efficiency. Moreover, the proposed model won first prize in ECCV AIM 2024 UHD-IQA Challenge. The code is available at https://github.com/sunwei925/UIQA.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "The proposed model won first prize in ECCV AIM 2024 Pushing the Boundaries of Blind Photo Quality Assessment Challenge"
    },
    {
        "paper id": "2409.00810",
        "abstract url": "https://arxiv.org/abs/2409.00810",
        "title": "A Novel Self-Attention-Enabled Weighted Ensemble-Based Convolutional Neural Network Framework for Distributed Denial of Service Attack Classification",
        "rating": "-0.5",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Distributed Denial of Service (DDoS) attacks are a major concern in network security, as they overwhelm systems with excessive traffic, compromise sensitive data, and disrupt network services. Accurately detecting these attacks is crucial to protecting network infrastructure. Traditional approaches, such as single Convolutional Neural Networks (CNNs) or conventional Machine Learning (ML) algorithms like Decision Trees (DTs) and Support Vector Machines (SVMs), struggle to extract the diverse features needed for precise classification, resulting in suboptimal performance. This research addresses this gap by introducing a novel approach for DDoS attack detection. The proposed method combines three distinct CNN architectures: SA-Enabled CNN with XGBoost, SA-Enabled CNN with LSTM, and SA-Enabled CNN with Random Forest. Each model extracts features at multiple scales, while self-attention mechanisms enhance feature integration and relevance. The weighted ensemble approach ensures that both prominent and subtle features contribute to the final classification, improving adaptability to evolving attack patterns and novel threats. The proposed method achieves a precision of 98.71%, an F1-score of 98.66%, a recall of 98.63%, and an accuracy of 98.69%, outperforming traditional methods and setting a new benchmark in DDoS attack detection. This innovative approach addresses critical limitations in current models and advances the state of the art in network security.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "19 pages, 3 tables, 9 figures"
    },
    {
        "paper id": "2409.00845",
        "abstract url": "https://arxiv.org/abs/2409.00845",
        "title": "Image-to-Lidar Relational Distillation for Autonomous Driving Data",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "Autonomous Driving",
                "Lidar"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Pre-trained on extensive and diverse multi-modal datasets, 2D foundation models excel at addressing 2D tasks with little or no downstream supervision, owing to their robust representations. The emergence of 2D-to-3D distillation frameworks has extended these capabilities to 3D models. However, distilling 3D representations for autonomous driving datasets presents challenges like self-similarity, class imbalance, and point cloud sparsity, hindering the effectiveness of contrastive distillation, especially in zero-shot learning contexts. Whereas other methodologies, such as similarity-based distillation, enhance zero-shot performance, they tend to yield less discriminative representations, diminishing few-shot performance. We investigate the gap in structure between the 2D and the 3D representations that result from state-of-the-art distillation frameworks and reveal a significant mismatch between the two. Additionally, we demonstrate that the observed structural gap is negatively correlated with the efficacy of the distilled representations on zero-shot and few-shot 3D semantic segmentation. To bridge this gap, we propose a relational distillation framework enforcing intra-modal and cross-modal constraints, resulting in distilled 3D representations that closely capture the structure of the 2D representation. This alignment significantly enhances 3D representation performance over those learned through contrastive distillation in zero-shot segmentation tasks. Furthermore, our relational loss consistently improves the quality of 3D representations in both in-distribution and out-of-distribution few-shot segmentation tasks, outperforming approaches that rely on the similarity loss.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ECCV 2024"
    },
    {
        "paper id": "2409.00901",
        "abstract url": "https://arxiv.org/abs/2409.00901",
        "title": "On the optimal approximation of Sobolev and Besov functions using deep ReLU neural networks",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper studies the problem of how efficiently functions in the Sobolev spaces $\\mathcal{W}^{s,q}([0,1]^d)$ and Besov spaces $\\mathcal{B}^s_{q,r}([0,1]^d)$ can be approximated by deep ReLU neural networks with width $W$ and depth $L$, when the error is measured in the $L^p([0,1]^d)$ norm. This problem has been studied by several recent works, which obtained the approximation rate $\\mathcal{O}((WL)^{-2s/d})$ up to logarithmic factors when $p=q=\\infty$, and the rate $\\mathcal{O}(L^{-2s/d})$ for networks with fixed width when the Sobolev embedding condition $1/q -1/p<s/d$ holds. We generalize these results by showing that the rate $\\mathcal{O}((WL)^{-2s/d})$ indeed holds under the Sobolev embedding condition. It is known that this rate is optimal up to logarithmic factors. The key tool in our proof is a novel encoding of sparse vectors by using deep ReLU neural networks with varied width and depth, which may be of independent interest.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00614",
        "abstract url": "https://arxiv.org/abs/2409.00614",
        "title": "DAMe: Personalized Federated Social Event Detection with Dual Aggregation Mechanism",
        "rating": "-1",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Training social event detection models through federated learning (FedSED) aims to improve participants' performance on the task. However, existing federated learning paradigms are inadequate for achieving FedSED's objective and exhibit limitations in handling the inherent heterogeneity in social data. This paper proposes a personalized federated learning framework with a dual aggregation mechanism for social event detection, namely DAMe. We present a novel local aggregation strategy utilizing Bayesian optimization to incorporate global knowledge while retaining local characteristics. Moreover, we introduce a global aggregation strategy to provide clients with maximum external knowledge of their preferences. In addition, we incorporate a global-local event-centric constraint to prevent local overfitting and ``client-drift''. Experiments within a realistic simulation of a natural federated setting, utilizing six social event datasets spanning six languages and two social media platforms, along with an ablation study, have demonstrated the effectiveness of the proposed framework. Further robustness analyses have shown that DAMe is resistant to injection attacks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "CIKM 2024"
    },
    {
        "paper id": "2409.00639",
        "abstract url": "https://arxiv.org/abs/2409.00639",
        "title": "Artificial Intelligence in Gastrointestinal Bleeding Analysis for Video Capsule Endoscopy: Insights, Innovations, and Prospects (2008-2023)",
        "rating": "-1",
        "keywords": [
            [
                "endoscopic"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The escalating global mortality and morbidity rates associated with gastrointestinal (GI) bleeding, compounded by the complexities and limitations of traditional endoscopic methods, underscore the urgent need for a critical review of current methodologies used for addressing this condition. With an estimated 300,000 annual deaths worldwide, the demand for innovative diagnostic and therapeutic strategies is paramount. The introduction of Video Capsule Endoscopy (VCE) has marked a significant advancement, offering a comprehensive, non-invasive visualization of the digestive tract that is pivotal for detecting bleeding sources unattainable by traditional methods. Despite its benefits, the efficacy of VCE is hindered by diagnostic challenges, including time-consuming analysis and susceptibility to human error. This backdrop sets the stage for exploring Machine Learning (ML) applications in automating GI bleeding detection within capsule endoscopy, aiming to enhance diagnostic accuracy, reduce manual labor, and improve patient outcomes. Through an exhaustive analysis of 113 papers published between 2008 and 2023, this review assesses the current state of ML methodologies in bleeding detection, highlighting their effectiveness, challenges, and prospective directions. It contributes an in-depth examination of AI techniques in VCE frame analysis, offering insights into open-source datasets, mathematical performance metrics, and technique categorization. The paper sets a foundation for future research to overcome existing challenges, advancing gastrointestinal diagnostics through interdisciplinary collaboration and innovation in ML applications.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00641",
        "abstract url": "https://arxiv.org/abs/2409.00641",
        "title": "Deep Probabilistic Traversability with Test-time Adaptation for Uncertainty-aware Planetary Rover Navigation",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "Traversability assessment of deformable terrain is vital for safe rover navigation on planetary surfaces. Machine learning (ML) is a powerful tool for traversability prediction but faces predictive uncertainty. This uncertainty leads to prediction errors, increasing the risk of wheel slips and immobilization for planetary rovers. To address this issue, we integrate principal approaches to uncertainty handling -- quantification, exploitation, and adaptation -- into a single learning and planning framework for rover navigation. The key concept is \\emph{deep probabilistic traversability}, forming the basis of an end-to-end probabilistic ML model that predicts slip distributions directly from rover traverse observations. This probabilistic model quantifies uncertainties in slip prediction and exploits them as traversability costs in path planning. Its end-to-end nature also allows adaptation of pre-trained models with in-situ traverse experience to reduce uncertainties. We perform extensive simulations in synthetic environments that pose representative uncertainties in planetary analog terrains. Experimental results show that our method achieves more robust path planning under novel environmental conditions than existing approaches.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 4 figures. Submitted to IEEE Robotics and Automation Letters (RA-L)"
    },
    {
        "paper id": "2409.00643",
        "abstract url": "https://arxiv.org/abs/2409.00643",
        "title": "Learning to Singulate Objects in Packed Environments using a Dexterous Hand",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "robotic manipulation"
            ]
        ],
        "abstract": "Robotic object singulation, where a robot must isolate, grasp, and retrieve a target object in a cluttered environment, is a fundamental challenge in robotic manipulation. This task is difficult due to occlusions and how other objects act as obstacles for manipulation. A robot must also reason about the effect of object-object interactions as it tries to singulate the target. Prior work has explored object singulation in scenarios where there is enough free space to perform relatively long pushes to separate objects, in contrast to when space is tight and objects have little separation from each other. In this paper, we propose the Singulating Objects in Packed Environments (SOPE) framework. We propose a novel method that involves a displacement-based state representation and a multi-phase reinforcement learning procedure that enables singulation using the 16-DOF Allegro Hand. We demonstrate extensive experiments in Isaac Gym simulation, showing the ability of our system to singulate a target object in clutter. We directly transfer the policy trained in simulation to the real world. Over 250 physical robot manipulation trials, our method obtains success rates of 79.2%, outperforming alternative learning and non-learning methods.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00647",
        "abstract url": "https://arxiv.org/abs/2409.00647",
        "title": "Modifying the U-Net's Encoder-Decoder Architecture for Segmentation of Tumors in Breast Ultrasound Images",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Segmentation is one of the most significant steps in image processing. Segmenting an image is a technique that makes it possible to separate a digital image into various areas based on the different characteristics of pixels in the image. In particular, segmentation of breast ultrasound images is widely used for cancer identification. As a result of image segmentation, it is possible to make early diagnoses of diseases via medical images in a very effective way. Due to various ultrasound artifacts and noises, including speckle noise, low signal-to-noise ratio, and intensity heterogeneity, the process of accurately segmenting medical images, such as ultrasound images, is still a challenging task. In this paper, we present a new method to improve the accuracy and effectiveness of breast ultrasound image segmentation. More precisely, we propose a Neural Network (NN) based on U-Net and an encoder-decoder architecture. By taking U-Net as the basis, both encoder and decoder parts are developed by combining U-Net with other Deep Neural Networks (Res-Net and MultiResUNet) and introducing a new approach and block (Co-Block), which preserves as much as possible the low-level and the high-level features. The designed network is evaluated using the Breast Ultrasound Images (BUSI) Dataset. It consists of 780 images and the images are categorized into three classes, which are normal, benign, and malignant. According to our extensive evaluations of a public breast ultrasound dataset, the designed network segments the breast lesions more accurately than other state-of-the-art deep learning methods. With only 8.88M parameters, our network (CResU-Net) obtained 76.88%, 71.5%, 90.3%, and 97.4% in terms of Dice similarity coefficients (DSC), Intersection over Union (IoU), Area under curve (AUC), and global accuracy (ACC), respectively, on BUSI dataset.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00649",
        "abstract url": "https://arxiv.org/abs/2409.00649",
        "title": "DeReStainer: H&E to IHC Pathological Image Translation via Decoupled Staining Channels",
        "rating": "-1",
        "keywords": [
            [
                "cancer",
                "disease",
                "Pathological"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Breast cancer is a highly fatal disease among cancers in women, and early detection is crucial for treatment. HER2 status, a valuable diagnostic marker based on Immunohistochemistry (IHC) staining, is instrumental in determining breast cancer status. The high cost of IHC staining and the ubiquity of Hematoxylin and Eosin (H&E) staining make the conversion from H&E to IHC staining essential. In this article, we propose a destain-restain framework for converting H&E staining to IHC staining, leveraging the characteristic that H&E staining and IHC staining of the same tissue sections share the Hematoxylin channel. We further design loss functions specifically for Hematoxylin and Diaminobenzidin (DAB) channels to generate IHC images exploiting insights from separated staining channels. Beyond the benchmark metrics on BCI contest, we have developed semantic information metrics for the HER2 level. The experimental results demonstrated that our method outperforms previous open-sourced methods in terms of image intrinsic property and semantic information.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00673",
        "abstract url": "https://arxiv.org/abs/2409.00673",
        "title": "Study of Dropout in PointPillars with 3D Object Detection",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "3D object detection is critical for autonomous driving, leveraging deep learning techniques to interpret LiDAR data. The PointPillars architecture is a prominent model in this field, distinguished by its efficient use of LiDAR data. This study provides an analysis of enhancing the performance of PointPillars model under various dropout rates to address overfitting and improve model generalization. Dropout, a regularization technique, involves randomly omitting neurons during training, compelling the network to learn robust and diverse features. We systematically compare the effects of different enhancement techniques on the model's regression performance during training and its accuracy, measured by Average Precision (AP) and Average Orientation Similarity (AOS). Our findings offer insights into the optimal enhancements, contributing to improved 3D object detection in autonomous driving applications.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00694",
        "abstract url": "https://arxiv.org/abs/2409.00694",
        "title": "IAFI-FCOS: Intra- and across-layer feature interaction FCOS model for lesion detection of CT images",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "CT",
                "disease",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Effective lesion detection in medical image is not only rely on the features of lesion region,but also deeply relative to the surrounding information.However,most current methods have not fully utilize it.What is more,multi-scale feature fusion mechanism of most traditional detectors are unable to transmit detail information without loss,which makes it hard to detect small and boundary ambiguous lesion in early stage disease.To address the above issues,we propose a novel intra- and across-layer feature interaction FCOS model (IAFI-FCOS) with a multi-scale feature fusion mechanism ICAF-FPN,which is a network structure with intra-layer context augmentation (ICA) block and across-layer feature weighting (AFW) block.Therefore,the traditional FCOS detector is optimized by enriching the feature representation from two perspectives.Specifically,the ICA block utilizes dilated attention to augment the context information in order to capture long-range dependencies between the lesion region and the surrounding.The AFW block utilizes dual-axis attention mechanism and weighting operation to obtain the efficient across-layer interaction features,enhancing the representation of detailed features.Our approach has been extensively experimented on both the private pancreatic lesion dataset and the public DeepLesion dataset,our model achieves SOTA results on the pancreatic lesion dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "2024 IJCNN"
    },
    {
        "paper id": "2409.00695",
        "abstract url": "https://arxiv.org/abs/2409.00695",
        "title": "Curriculum Prompting Foundation Models for Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Adapting large pre-trained foundation models, e.g., SAM, for medical image segmentation remains a significant challenge. A crucial step involves the formulation of a series of specialized prompts that incorporate specific clinical instructions. Past works have been heavily reliant on a singular type of prompt for each instance, necessitating manual input of an ideally correct prompt, which is less efficient. To tackle this issue, we propose to utilize prompts of different granularity, which are sourced from original images to provide a broader scope of clinical insights. However, combining prompts of varying types can pose a challenge due to potential conflicts. In response, we have designed a coarse-to-fine mechanism, referred to as curriculum prompting, that progressively integrates prompts of different types. Through extensive experiments on three public medical datasets across various modalities, we demonstrate the effectiveness of our proposed approach, which not only automates the prompt generation process but also yields superior performance compared to other SAM-based medical image segmentation methods. Code is available at: https://github.com/AnnaZzz-zxq/Curriculum-Prompting.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted by MICCAI 2024"
    },
    {
        "paper id": "2409.00705",
        "abstract url": "https://arxiv.org/abs/2409.00705",
        "title": "Antagonist Inhibition Control in Redundant Tendon-driven Structures Based on Human Reciprocal Innervation for Wide Range Limb Motion of Musculoskeletal Humanoids",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "The body structure of an anatomically correct tendon-driven musculoskeletal humanoid is complex, and the difference between its geometric model and the actual robot is very large because expressing the complex routes of tendon wires in a geometric model is very difficult. If we move a tendon-driven musculoskeletal humanoid by the tendon wire lengths of the geometric model, unintended muscle tension and slack will emerge. In some cases, this can lead to the wreckage of the actual robot. To solve this problem, we focused on reciprocal innervation in the human nervous system, and then implemented antagonist inhibition control (AIC) based on the reflex. This control makes it possible to avoid unnecessary internal muscle tension and slack of tendon wires caused by model error, and to perform wide range motion safely for a long time. To verify its effectiveness, we applied AIC to the upper limb of the tendon-driven musculoskeletal humanoid, Kengoro, and succeeded in dangling for 14 minutes and doing pull-ups.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at IEEE Robotics and Automation Letters"
    },
    {
        "paper id": "2409.00712",
        "abstract url": "https://arxiv.org/abs/2409.00712",
        "title": "Unveiling the Bandwidth Nightmare: CDN Compression Format Conversion Attacks",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Content Delivery Networks (CDNs) are designed to enhance network performance and protect against web attack traffic for their hosting websites. And the HTTP compression request mechanism primarily aims to reduce unnecessary network transfers. However, we find that the specification failed to consider the security risks introduced when CDNs meet compression requests. In this paper, we present a novel HTTP amplification attack, CDN Compression Format Convert (CDN-Convet) Attacks. It allows attackers to massively exhaust not only the outgoing bandwidth of the origin servers deployed behind CDNs but also the bandwidth of CDN surrogate nodes. We examined the CDN-Convet attacks on 11 popular CDNs to evaluate the feasibility and real-world impacts. Our experimental results show that all these CDNs are affected by the CDN-Convet attacks. We have also disclosed our findings to affected CDN providers and have received constructive feedback.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2409.00718",
        "abstract url": "https://arxiv.org/abs/2409.00718",
        "title": "Multiscale Color Guided Attention Ensemble Classifier for Age-Related Macular Degeneration using Concurrent Fundus and Optical Coherence Tomography Images",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Automatic diagnosis techniques have evolved to identify age-related macular degeneration (AMD) by employing single modality Fundus images or optical coherence tomography (OCT). To classify ocular diseases, fundus and OCT images are the most crucial imaging modalities used in the clinical setting. Most deep learning-based techniques are established on a single imaging modality, which contemplates the ocular disorders to a specific extent and disregards other modality that comprises exhaustive information among distinct imaging modalities. This paper proposes a modality-specific multiscale color space embedding integrated with the attention mechanism based on transfer learning for classification (MCGAEc), which can efficiently extract the distinct modality information at various scales using the distinct color spaces. In this work, we first introduce the modality-specific multiscale color space encoder model, which includes diverse feature representations by integrating distinct characteristic color spaces on a multiscale into a unified framework. The extracted features from the prior encoder module are incorporated with the attention mechanism to extract the global features representation, which is integrated with the prior extracted features and transferred to the random forest classifier for the classification of AMD. To analyze the performance of the proposed MCGAEc method, a publicly available multi-modality dataset from Project Macula for AMD is utilized and compared with the existing models.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "27th International Conference on Pattern Recognition (ICPR) 2024"
    },
    {
        "paper id": "2409.00724",
        "abstract url": "https://arxiv.org/abs/2409.00724",
        "title": "BUET Multi-disease Heart Sound Dataset: A Comprehensive Auscultation Dataset for Developing Computer-Aided Diagnostic Systems",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "diagnosing",
                "disease",
                "Cardiac"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Cardiac auscultation, an integral tool in diagnosing cardiovascular diseases (CVDs), often relies on the subjective interpretation of clinicians, presenting a limitation in consistency and accuracy. Addressing this, we introduce the BUET Multi-disease Heart Sound (BMD-HS) dataset - a comprehensive and meticulously curated collection of heart sound recordings. This dataset, encompassing 864 recordings across five distinct classes of common heart sounds, represents a broad spectrum of valvular heart diseases, with a focus on diagnostically challenging cases. The standout feature of the BMD-HS dataset is its innovative multi-label annotation system, which captures a diverse range of diseases and unique disease states. This system significantly enhances the dataset's utility for developing advanced machine learning models in automated heart sound classification and diagnosis. By bridging the gap between traditional auscultation practices and contemporary data-driven diagnostic methods, the BMD-HS dataset is poised to revolutionize CVD diagnosis and management, providing an invaluable resource for the advancement of cardiac health research. The dataset is publicly available at this link: https://github.com/mHealthBuet/BMD-HS-Dataset.",
        "subjects": [
            "eess.SP",
            "cs.AI",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "14 pages, 13 figures"
    },
    {
        "paper id": "2409.00728",
        "abstract url": "https://arxiv.org/abs/2409.00728",
        "title": "On the Price of Decentralization in Decentralized Detection",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Fundamental limits on the error probabilities of a family of decentralized detection algorithms (eg., the social learning rule proposed by Lalitha et al. over directed graphs are investigated. In decentralized detection, a network of nodes locally exchanging information about the samples they observe with their neighbors to collectively infer the underlying unknown hypothesis. Each node in the network weighs the messages received from its neighbors to form its private belief and only requires knowledge of the data generating distribution of its observation. In this work, it is first shown that while the original social learning rule of Lalitha et al. achieves asymptotically vanishing error probabilities as the number of samples tends to infinity, it suffers a gap in the achievable error exponent compared to the centralized case. The gap is due to the network imbalance caused by the local weights that each node chooses to weigh the messages received from its neighbors. To close this gap, a modified learning rule is proposed and shown to achieve error exponents as large as those in the centralized setup. This implies that there is essentially no first-order penalty caused by decentralization in the exponentially decaying rate of error probabilities.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Submitted to the IEEE Transactions on Information Theory"
    },
    {
        "paper id": "2409.00744",
        "abstract url": "https://arxiv.org/abs/2409.00744",
        "title": "DSLO: Deep Sequence LiDAR Odometry Based on Inconsistent Spatio-temporal Propagation",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a 3D point cloud sequence learning model based on inconsistent spatio-temporal propagation for LiDAR odometry, termed DSLO. It consists of a pyramid structure with a spatial information reuse strategy, a sequential pose initialization module, a gated hierarchical pose refinement module, and a temporal feature propagation module. First, spatial features are encoded using a point feature pyramid, with features reused in successive pose estimations to reduce computational overhead. Second, a sequential pose initialization method is introduced, leveraging the high-frequency sampling characteristic of LiDAR to initialize the LiDAR pose. Then, a gated hierarchical pose refinement mechanism refines poses from coarse to fine by selectively retaining or discarding motion information from different layers based on gate estimations. Finally, temporal feature propagation is proposed to incorporate the historical motion information from point cloud sequences, and address the spatial inconsistency issue when transmitting motion information embedded in point clouds between frames. Experimental results on the KITTI odometry dataset and Argoverse dataset demonstrate that DSLO outperforms state-of-the-art methods, achieving at least a 15.67\\% improvement on RTE and a 12.64\\% improvement on RRE, while also achieving a 34.69\\% reduction in runtime compared to baseline methods. Our implementation will be available at https://github.com/IRMVLab/DSLO.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "6 pages, 5 figures, accepted by IROS 2024"
    },
    {
        "paper id": "2409.00747",
        "abstract url": "https://arxiv.org/abs/2409.00747",
        "title": "Dependency-Aware Code Naturalness",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Code naturalness, which captures repetitiveness and predictability in programming languages, has proven valuable for various code-related tasks in software engineering. However, precisely measuring code naturalness remains a fundamental challenge. Existing methods measure code naturalness over individual lines of code while ignoring the deep semantic relations among different lines, e.g., program dependency, which may negatively affect the precision of the measure. In this study, we aim to perform the first empirical study to investigate whether incorporating code dependency, instead of analyzing individual lines, can enhance the precision of measuring code naturalness. To achieve that, we first propose a new method named DAN for measuring code naturalness by incorporating the rich dependency information in the code. Specifically, DAN extracts multiple sequences of code lines by traversing the program dependency graph, where different code lines are connected by dependencies in each sequence, and then the code naturalness will be measured by taking each sequence as a whole. In this way, the dependency information can be well captured. Finally, we have conducted an extensive study to evaluate the influence of code dependency for measuring code naturalness with DAN, and compared it with the state-of-the-art methods under three emerging application scenarios of code naturalness. The results demonstrate that DAN can not only better distinguish natural and unnatural code, but also substantially boost two important downstream applications of code naturalness, i.e., distinguishing buggy and non-buggy code lines and data cleansing for training better code models, reflecting the significance of code dependency in measuring code naturalness.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00766",
        "abstract url": "https://arxiv.org/abs/2409.00766",
        "title": "Dynamic Subgoal based Path Formation and Task Allocation: A NeuroFleets Approach to Scalable Swarm Robotics",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "robot",
                "navigation"
            ]
        ],
        "abstract": "This paper addresses the challenges of exploration and navigation in unknown environments from the perspective of evolutionary swarm robotics. A key focus is on path formation, which is essential for enabling cooperative swarm robots to navigate effectively. We designed the task allocation and path formation process based on a finite state machine, ensuring systematic decision-making and efficient state transitions. The approach is decentralized, allowing each robot to make decisions independently based on local information, which enhances scalability and robustness. We present a novel subgoal-based path formation method that establishes paths between locations by leveraging visually connected subgoals. Simulation experiments conducted in the Argos simulator show that this method successfully forms paths in the majority of trials. However, inter-collision (traffic) among numerous robots during path formation can negatively impact performance. To address this issue, we propose a task allocation strategy that uses local communication protocols and light signal-based communication to manage robot deployment. This strategy assesses the distance between points and determines the optimal number of robots needed for the path formation task, thereby reducing unnecessary exploration and traffic congestion. The performance of both the subgoal-based path formation method and the task allocation strategy is evaluated by comparing the path length, time, and resource usage against the A* algorithm. Simulation results demonstrate the effectiveness of our approach, highlighting its scalability, robustness, and fault tolerance.",
        "subjects": [
            "cs.RO",
            "cs.MA"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2312.16606"
    },
    {
        "paper id": "2409.00770",
        "abstract url": "https://arxiv.org/abs/2409.00770",
        "title": "Survey of Results on the ModPath and ModCycle Problems",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "This note summarizes the state of what is known about the tractability of the problem ModPath, which asks if an input undirected graph contains a simple st-path whose length satisfies modulo constraints. We also consider the problem ModCycle, which asks for the existence of a simple cycle subject to such constraints. We also discuss the status of these problems on directed graphs, and on restricted classes of graphs. We explain connections to the problem variant asking for a constant vertex-disjoint number of such paths or cycles, and discuss links to other related work.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "11 pages. Unpublished note surveying existing work"
    },
    {
        "paper id": "2409.00779",
        "abstract url": "https://arxiv.org/abs/2409.00779",
        "title": "Unbalanced Fingerprint Classification for Hybrid Fingerprint Orientation Maps",
        "rating": "-1",
        "keywords": [
            [
                "biometric"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel fingerprint classification technique based on a multi-layered fuzzy logic classifier. We target the cause of missed detection by identifying the fingerprints at an early stage among dry, standard, and wet. Scanned images are classified based on clarity correlated with the proposed feature points. We also propose a novel adaptive algorithm based on eigenvector space for generating new samples to overcome the multiclass imbalance. Proposed methods improve the performance of ensemble learners. It was also found that the new approach performs better than the neural-network based classification methods. Early-stage improvements give a suitable dataset for fingerprint detection models. Leveraging the novel classifier, the best set of `standard' labelled fingerprints is used to generate a unique hybrid fingerprint orientation map (HFOM). We introduce a novel min-rotate max-flow optimization method inspired by the min-cut max-flow algorithm. The unique properties of HFOM generation introduce a new use case for biometric data protection by using HFOM as a virtual proxy of fingerprints.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 18 figures, 4 Tables The work mainly focuses on fingerprint classification and hybrid fingerprint orientation map (HFOM) generation. It highlights the security use cases of HFOM, eg. data encryption"
    },
    {
        "paper id": "2409.00784",
        "abstract url": "https://arxiv.org/abs/2409.00784",
        "title": "SonoHaptics: An Audio-Haptic Cursor for Gaze-Based Object Selection in XR",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "We introduce SonoHaptics, an audio-haptic cursor for gaze-based 3D object selection. SonoHaptics addresses challenges around providing accurate visual feedback during gaze-based selection in Extended Reality (XR), e.g., lack of world-locked displays in no- or limited-display smart glasses and visual inconsistencies. To enable users to distinguish objects without visual feedback, SonoHaptics employs the concept of cross-modal correspondence in human perception to map visual features of objects (color, size, position, material) to audio-haptic properties (pitch, amplitude, direction, timbre). We contribute data-driven models for determining cross-modal mappings of visual features to audio and haptic features, and a computational approach to automatically generate audio-haptic feedback for objects in the user's environment. SonoHaptics provides global feedback that is unique to each object in the scene, and local feedback to amplify differences between nearby objects. Our comparative evaluation shows that SonoHaptics enables accurate object identification and selection in a cluttered scene without visual feedback.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "UIST 2024"
    },
    {
        "paper id": "2409.00799",
        "abstract url": "https://arxiv.org/abs/2409.00799",
        "title": "DMRA: An Adaptive Line Spectrum Estimation Method through Dynamical Multi-Resolution of Atoms",
        "rating": "-1",
        "keywords": [
            [
                "super-resolution"
            ]
        ],
        "abstract": "We proposed a novel dense line spectrum super-resolution algorithm, the DMRA, that leverages dynamical multi-resolution of atoms technique to address the limitation of traditional compressed sensing methods when handling dense point-source signals. The algorithm utilizes a smooth $\\tanh$ relaxation function to replace the $\\ell_0$ norm, promoting sparsity and jointly estimating the frequency atoms and complex gains. To reduce computational complexity and improve frequency estimation accuracy, a two-stage strategy was further introduced to dynamically adjust the number of the optimized degrees of freedom. The strategy first increases candidate frequencies through local refinement, then applies a sparse selector to eliminate insignificant frequencies, thereby adaptively adjusting the degrees of freedom to improve estimation accuracy. Theoretical analysis were provided to validate the proposed method for multi-parameter estimations. Computational results demonstrated that this algorithm achieves good super-resolution performance in various practical scenarios and outperforms the state-of-the-art methods in terms of frequency estimation accuracy and computational efficiency.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00804",
        "abstract url": "https://arxiv.org/abs/2409.00804",
        "title": "Leveraging SeNet and ResNet Synergy within an Encoder-Decoder Architecture for Glioma Detection",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "diagnosis",
                "MRI",
                "cancer",
                "tumor"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Brain tumors are abnormalities that can severely impact a patient's health, leading to life-threatening conditions such as cancer. These can result in various debilitating effects, including neurological issues, cognitive impairment, motor and sensory deficits, as well as emotional and behavioral changes. These symptoms significantly affect a patient's quality of life, making early diagnosis and timely treatment essential to prevent further deterioration. However, accurately segmenting the tumor region from medical images, particularly MRI scans, is a challenging and time-consuming task that requires the expertise of radiologists. Manual segmentation can also be prone to human errors. To address these challenges, this research leverages the synergy of SeNet and ResNet architectures within an encoder-decoder framework, designed specifically for glioma detection and segmentation. The proposed model incorporates the power of SeResNet-152 as the backbone, integrated into a robust encoder-decoder structure to enhance feature extraction and improve segmentation accuracy. This novel approach significantly reduces the dependency on manual tasks and improves the precision of tumor identification. Evaluation of the model demonstrates strong performance, achieving 87% in Dice Coefficient, 89.12% in accuracy, 88% in IoU score, and 82% in mean IoU score, showcasing its effectiveness in tackling the complex problem of brain tumor segmentation.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "9 pages, 6 figures, 1 table"
    },
    {
        "paper id": "2409.00822",
        "abstract url": "https://arxiv.org/abs/2409.00822",
        "title": "RTop-K: Ultra-Fast Row-Wise Top-K Algorithm and GPU Implementation for Neural Networks",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ]
        ],
        "abstract": "Top-k algorithms are essential in various applications, from high-performance computing and information retrieval to big data and neural network model training. This paper introduces RTop-K, a highly efficient parallel row-wise top-k selection algorithm designed for GPUs. RTop-K employs a Binary Search-based approach to optimize resource allocation and provides a scalable solution that significantly accelerates top-k operations. We perform a theoretical analysis of the effects of early stopping in our algorithm, demonstrating that it maintains the accuracy of neural network models while enhancing performance. Comprehensive tests show that our GPU implementation of RTop-K outperforms other row-wise top-k GPU implementations, with minimal impact on testing accuracy when early stopping is applied. Notably, RTop-K achieves speed increases ranging from 4.245$\\times$ to 9.506$\\times$ with early stopping, and 3.936$\\times$ without early stopping, compared to state-of-the-art implementations. The proposed methods offer significant improvements in the training and inference of Graph Neural Networks (GNNs), addressing critical challenges in latency and throughput on GPU platforms.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00827",
        "abstract url": "https://arxiv.org/abs/2409.00827",
        "title": "Log-concavity of the independence polynomials of $\\mathbf{W}_{p}$ graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Let $G$ be a $\\mathbf{W}_{p}$ graph if $n\\geq p$ and every $p$ pairwise disjoint independent sets of $G$ are contained within $p$ pairwise disjoint maximum independent sets. In this paper, we establish that every $\\mathbf{W}_{p}$ graph $G$ is $p$-quasi-regularizable if and only if $n\\geq (p+1)\u03b1$, where $\u03b1$ is the independence number of $G$. This finding ensures that the independence polynomial of a connected $\\mathbf{W}_{p}$ graph $G$ is log-concave whenever $(p+1)\u03b1\\leq n\\leq 2p\u03b1+p+1$. Furthermore, we demonstrate that the independence polynomial of the clique corona $G\\circ K_{p}$ is invariably log-concave for all $p\\geq 1$. As an application, we validate a long-standing conjecture claiming that the independence polynomial of a very well-covered graph is unimodal.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "16 pages, 2 figures"
    },
    {
        "paper id": "2409.00831",
        "abstract url": "https://arxiv.org/abs/2409.00831",
        "title": "GroomCap: High-Fidelity Prior-Free Hair Capture",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Despite recent advances in multi-view hair reconstruction, achieving strand-level precision remains a significant challenge due to inherent limitations in existing capture pipelines. We introduce GroomCap, a novel multi-view hair capture method that reconstructs faithful and high-fidelity hair geometry without relying on external data priors. To address the limitations of conventional reconstruction algorithms, we propose a neural implicit representation for hair volume that encodes high-resolution 3D orientation and occupancy from input views. This implicit hair volume is trained with a new volumetric 3D orientation rendering algorithm, coupled with 2D orientation distribution supervision, to effectively prevent the loss of structural information caused by undesired orientation blending. We further propose a Gaussian-based hair optimization strategy to refine the traced hair strands with a novel chained Gaussian representation, utilizing direct photometric supervision from images. Our results demonstrate that GroomCap is able to capture high-quality hair geometries that are not only more precise and detailed than existing methods but also versatile enough for a range of applications.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "Accepted by SIGGRAPH Asia 2024"
    },
    {
        "paper id": "2409.00863",
        "abstract url": "https://arxiv.org/abs/2409.00863",
        "title": "Fisher Information guided Purification against Backdoor Attacks",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point Cloud"
            ],
            [
                "Attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Studies on backdoor attacks in recent years suggest that an adversary can compromise the integrity of a deep neural network (DNN) by manipulating a small set of training samples. Our analysis shows that such manipulation can make the backdoor model converge to a bad local minima, i.e., sharper minima as compared to a benign model. Intuitively, the backdoor can be purified by re-optimizing the model to smoother minima. However, a na\u00efve adoption of any optimization targeting smoother minima can lead to sub-optimal purification techniques hampering the clean test accuracy. Hence, to effectively obtain such re-optimization, inspired by our novel perspective establishing the connection between backdoor removal and loss smoothness, we propose Fisher Information guided Purification (FIP), a novel backdoor purification framework. Proposed FIP consists of a couple of novel regularizers that aid the model in suppressing the backdoor effects and retaining the acquired knowledge of clean data distribution throughout the backdoor removal procedure through exploiting the knowledge of Fisher Information Matrix (FIM). In addition, we introduce an efficient variant of FIP, dubbed as Fast FIP, which reduces the number of tunable parameters significantly and obtains an impressive runtime gain of almost $5\\times$. Extensive experiments show that the proposed method achieves state-of-the-art (SOTA) performance on a wide range of backdoor defense benchmarks: 5 different tasks -- Image Recognition, Object Detection, Video Action Recognition, 3D point Cloud, Language Generation; 11 different datasets including ImageNet, PASCAL VOC, UCF101; diverse model architectures spanning both CNN and vision transformer; 14 different backdoor attacks, e.g., Dynamic, WaNet, LIRA, ISSBA, etc.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ACM CCS 2024. arXiv admin note: text overlap with arXiv:2306.17441"
    },
    {
        "paper id": "2409.00866",
        "abstract url": "https://arxiv.org/abs/2409.00866",
        "title": "Vehicle-to-Everything (V2X) Communication: A Roadside Unit for Adaptive Intersection Control of Autonomous Electric Vehicles",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "Recent advances in autonomous vehicle technologies and cellular network speeds motivate developments in vehicle-to-everything (V2X) communications. Enhanced road safety features and improved fuel efficiency are some of the motivations behind V2X for future transportation systems. Adaptive intersection control systems have considerable potential to achieve these goals by minimizing idle times and predicting short-term future traffic conditions. Integrating V2X into traffic management systems introduces the infrastructure necessary to make roads safer for all users and initiates the shift towards more intelligent and connected cities. To demonstrate our solution, we implement both a simulated and real-world representation of a 4-way intersection and crosswalk scenario with 2 self-driving electric vehicles, a roadside unit (RSU), and traffic light. Our architecture minimizes fuel consumption through intersections by reducing acceleration and braking by up to 75.35%. We implement a cost-effective solution to intelligent and connected intersection control to serve as a proof-of-concept model suitable as the basis for continued research and development. Code for this project is available at https://github.com/MMachado05/REU-2024.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Supported by the National Science Foundation under Grants No. 2150292 and 2150096"
    },
    {
        "paper id": "2409.00867",
        "abstract url": "https://arxiv.org/abs/2409.00867",
        "title": "Kinematics & Dynamics Library for Baxter Arm",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "robot"
            ]
        ],
        "abstract": "The Baxter robot is a standard research platform used widely in research tasks, supported with an SDK provided by the developers, Rethink Robotics. Despite the ubiquitous use of the robot, the official software support is sub-standard. Especially, the native IK service has a low success rate and is often inconsistent. This unreliable behavior makes Baxter difficult to use for experiments and the research community is in need of a more reliable software support to control the robot. We present our work towards creating a Python based software library supporting the kinematics and dynamics of the Baxter robot. Our toolbox contains implementation of pose and velocity kinematics with support for Jacobian operations for redundancy resolution. We present the implementation and performance of our library, along with a comparison with PyKDL. Keywords- Baxter Research Robot, Manipulator Kinematics, Iterative IK, Dynamical Model, Redundant Manipulator",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00873",
        "abstract url": "https://arxiv.org/abs/2409.00873",
        "title": "Equitable Skin Disease Prediction Using Transfer Learning and Domain Adaptation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosing",
                "cancer",
                "Disease"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of dermatology, the complexity of diagnosing skin conditions manually necessitates the expertise of dermatologists. Accurate identification of various skin ailments, ranging from cancer to inflammatory diseases, is paramount. However, existing artificial intelligence (AI) models in dermatology face challenges, particularly in accurately diagnosing diseases across diverse skin tones, with a notable performance gap in darker skin. Additionally, the scarcity of publicly available, unbiased datasets hampers the development of inclusive AI diagnostic tools. To tackle the challenges in accurately predicting skin conditions across diverse skin tones, we employ a transfer-learning approach that capitalizes on the rich, transferable knowledge from various image domains. Our method integrates multiple pre-trained models from a wide range of sources, including general and specific medical images, to improve the robustness and inclusiveness of the skin condition predictions. We rigorously evaluated the effectiveness of these models using the Diverse Dermatology Images (DDI) dataset, which uniquely encompasses both underrepresented and common skin tones, making it an ideal benchmark for assessing our approach. Among all methods, Med-ViT emerged as the top performer due to its comprehensive feature representation learned from diverse image sources. To further enhance performance, we conducted domain adaptation using additional skin image datasets such as HAM10000. This adaptation significantly improved model performance across all models.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00876",
        "abstract url": "https://arxiv.org/abs/2409.00876",
        "title": "Rapid GPU-Based Pangenome Graph Layout",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Computational Pangenomics is an emerging field that studies genetic variation using a graph structure encompassing multiple genomes. Visualizing pangenome graphs is vital for understanding genome diversity. Yet, handling large graphs can be challenging due to the high computational demands of the graph layout process. In this work, we conduct a thorough performance characterization of a state-of-the-art pangenome graph layout algorithm, revealing significant data-level parallelism, which makes GPUs a promising option for compute acceleration. However, irregular data access and the algorithm's memory-bound nature present significant hurdles. To overcome these challenges, we develop a solution implementing three key optimizations: a cache-friendly data layout, coalesced random states, and warp merging. Additionally, we propose a quantitative metric for scalable evaluation of pangenome layout quality. Evaluated on 24 human whole-chromosome pangenomes, our GPU-based solution achieves a 57.3x speedup over the state-of-the-art multithreaded CPU baseline without layout quality loss, reducing execution time from hours to minutes.",
        "subjects": [
            "cs.DC",
            "cs.CE",
            "cs.DS"
        ],
        "comment": "SC 2024"
    },
    {
        "paper id": "2409.00895",
        "abstract url": "https://arxiv.org/abs/2409.00895",
        "title": "Whole-Body Control Through Narrow Gaps From Pixels To Action",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "flight"
            ]
        ],
        "abstract": "Flying through body-size narrow gaps in the environment is one of the most challenging moments for an underactuated multirotor. We explore a purely data-driven method to master this flight skill in simulation, where a neural network directly maps pixels and proprioception to continuous low-level control commands. This learned policy enables whole-body control through gaps with different geometries demanding sharp attitude changes (e.g., near-vertical roll angle). The policy is achieved by successive model-free reinforcement learning (RL) and online observation space distillation. The RL policy receives (virtual) point clouds of the gaps' edges for scalable simulation and is then distilled into the high-dimensional pixel space. However, this flight skill is fundamentally expensive to learn by exploring due to restricted feasible solution space. We propose to reset the agent as states on the trajectories by a model-based trajectory optimizer to alleviate this problem. The presented training pipeline is compared with baseline methods, and ablation studies are conducted to identify the key ingredients of our method. The immediate next step is to scale up the variation of gap sizes and geometries in anticipation of emergent policies and demonstrate the sim-to-real transformation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "9 pages, 8 figures, 2 tables"
    },
    {
        "paper id": "2409.00917",
        "abstract url": "https://arxiv.org/abs/2409.00917",
        "title": "Large Scale Unsupervised Brain MRI Image",
        "rating": "-1",
        "keywords": [
            [
                "MRI"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we summarize the methods and experimental results we proposed for Task 2 in the learn2reg 2024 Challenge. This task focuses on unsupervised registration of anatomical structures in brain MRI images between different patients. The difficulty lies in: (1) without segmentation labels, and (2) a large amount of data. To address these challenges, we built an efficient backbone network and explored several schemes to further enhance registration accuracy. Under the guidance of the NCC loss function and smoothness regularization loss function, we obtained a smooth and reasonable deformation field. According to the leaderboard, our method achieved a Dice coefficient of 77.34%, which is 1.4% higher than the TransMorph. Overall, we won second place on the leaderboard for Task 2.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "MICCAI Learn2Reg 2024 Challenge & WBIR 2024 Workshop on Biomedical Imaging Registration"
    },
    {
        "paper id": "2409.00924",
        "abstract url": "https://arxiv.org/abs/2409.00924",
        "title": "MedSAM-U: Uncertainty-Guided Auto Multi-Prompt Adaptation for Reliable MedSAM",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Medical Segment Anything Model (MedSAM) has shown remarkable performance in medical image segmentation, drawing significant attention in the field. However, its sensitivity to varying prompt types and locations poses challenges. This paper addresses these challenges by focusing on the development of reliable prompts that enhance MedSAM's accuracy. We introduce MedSAM-U, an uncertainty-guided framework designed to automatically refine multi-prompt inputs for more reliable and precise medical image segmentation. Specifically, we first train a Multi-Prompt Adapter integrated with MedSAM, creating MPA-MedSAM, to adapt to diverse multi-prompt inputs. We then employ uncertainty-guided multi-prompt to effectively estimate the uncertainties associated with the prompts and their initial segmentation results. In particular, a novel uncertainty-guided prompts adaptation technique is then applied automatically to derive reliable prompts and their corresponding segmentation outcomes. We validate MedSAM-U using datasets from multiple modalities to train a universal image segmentation model. Compared to MedSAM, experimental results on five distinct modal datasets demonstrate that the proposed MedSAM-U achieves an average performance improvement of 1.7\\% to 20.5\\% across uncertainty-guided prompts.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 4 figures"
    },
    {
        "paper id": "2409.00933",
        "abstract url": "https://arxiv.org/abs/2409.00933",
        "title": "SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis",
        "rating": "-1",
        "keywords": [
            [
                "Text-to-Speech"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The long speech sequence has been troubling language models (LM) based TTS approaches in terms of modeling complexity and efficiency. This work proposes SoCodec, a semantic-ordered multi-stream speech codec, to address this issue. It compresses speech into a shorter, multi-stream discrete semantic sequence with multiple tokens at each frame. Meanwhile, the ordered product quantization is proposed to constrain this sequence into an ordered representation. It can be applied with a multi-stream delayed LM to achieve better autoregressive generation along both time and stream axes in TTS. The experimental result strongly demonstrates the effectiveness of the proposed approach, achieving superior performance over baseline systems even if compressing the frameshift of speech from 20ms to 240ms (12x). The ablation studies further validate the importance of learning the proposed ordered multi-stream semantic representation in pursuing shorter speech sequences for efficient LM-based TTS.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by SLT 2024"
    },
    {
        "paper id": "2409.00620",
        "abstract url": "https://arxiv.org/abs/2409.00620",
        "title": "Enhancing Vectorized Map Perception with Historical Rasterized Maps",
        "rating": "-1.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "BEV"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "In autonomous driving, there is growing interest in end-to-end online vectorized map perception in bird's-eye-view (BEV) space, with an expectation that it could replace traditional high-cost offline high-definition (HD) maps. However, the accuracy and robustness of these methods can be easily compromised in challenging conditions, such as occlusion or adverse weather, when relying only on onboard sensors. In this paper, we propose HRMapNet, leveraging a low-cost Historical Rasterized Map to enhance online vectorized map perception. The historical rasterized map can be easily constructed from past predicted vectorized results and provides valuable complementary information. To fully exploit a historical map, we propose two novel modules to enhance BEV features and map element queries. For BEV features, we employ a feature aggregation module to encode features from both onboard images and the historical map. For map element queries, we design a query initialization module to endow queries with priors from the historical map. The two modules contribute to leveraging map information in online perception. Our HRMapNet can be integrated with most online vectorized map perception methods. We integrate it in two state-of-the-art methods, significantly improving their performance on both the nuScenes and Argoverse 2 datasets. The source code is released at https://github.com/HXMap/HRMapNet.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2409.00640",
        "abstract url": "https://arxiv.org/abs/2409.00640",
        "title": "Time-series Crime Prediction Across the United States Based on Socioeconomic and Political Factors",
        "rating": "-1.5",
        "keywords": [
            [
                "Crime"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional crime prediction techniques are slow and inefficient when generating predictions as crime increases rapidly \\cite{r15}. To enhance traditional crime prediction methods, a Long Short-Term Memory and Gated Recurrent Unit model was constructed using datasets involving gender ratios, high school graduation rates, political status, unemployment rates, and median income by state over multiple years. While there may be other crime prediction tools, personalizing the model with hand picked factors allows a unique gap for the project. Producing an effective model would allow policymakers to strategically allocate specific resources and legislation in geographic areas that are impacted by crime, contributing to the criminal justice field of research \\cite{r2A}. The model has an average total loss value of 70.792.30, and a average percent error of 9.74 percent, however both of these values are impacted by extreme outliers and with the correct optimization may be corrected.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00644",
        "abstract url": "https://arxiv.org/abs/2409.00644",
        "title": "Knowledge-data fusion oriented traffic state estimation: A stochastic physics-informed deep learning approach",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-informed deep learning (PIDL)-based models have recently garnered remarkable success in traffic state estimation (TSE). However, the prior knowledge used to guide regularization training in current mainstream architectures is based on deterministic physical models. The drawback is that a solely deterministic model fails to capture the universally observed traffic flow dynamic scattering effect, thereby yielding unreliable outcomes for traffic control. This study, for the first time, proposes stochastic physics-informed deep learning (SPIDL) for traffic state estimation. The idea behind such SPIDL is simple and is based on the fact that a stochastic fundamental diagram provides the entire range of possible speeds for any given density with associated probabilities. Specifically, we select percentile-based fundamental diagram and distribution-based fundamental diagram as stochastic physics knowledge, and design corresponding physics-uninformed neural networks for effective fusion, thereby realizing two specific SPIDL models, namely \\text{$\u03b1$}-SPIDL and \\text{$\\cal B$}-SPIDL. The main contribution of SPIDL lies in addressing the \"overly centralized guidance\" caused by the one-to-one speed-density relationship in deterministic models during neural network training, enabling the network to digest more reliable knowledge-based constraints.Experiments on the real-world dataset indicate that proposed SPIDL models achieve accurate traffic state estimation in sparse data scenarios. More importantly, as expected, SPIDL models reproduce well the scattering effect of field observations, demonstrating the effectiveness of fusing stochastic physics model knowledge with deep learning frameworks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "under review in Information Fusion"
    },
    {
        "paper id": "2409.00658",
        "abstract url": "https://arxiv.org/abs/2409.00658",
        "title": "Nasdaq-100 Companies' Hiring Insights: A Topic-based Classification Approach to the Labor Market",
        "rating": "-1.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The emergence of new and disruptive technologies makes the economy and labor market more unstable. To overcome this kind of uncertainty and to make the labor market more comprehensible, we must employ labor market intelligence techniques, which are predominantly based on data analysis. Companies use job posting sites to advertise their job vacancies, known as online job vacancies (OJVs). LinkedIn is one of the most utilized websites for matching the supply and demand sides of the labor market; companies post their job vacancies on their job pages, and LinkedIn recommends these jobs to job seekers who are likely to be interested. However, with the vast number of online job vacancies, it becomes challenging to discern overarching trends in the labor market. In this paper, we propose a data mining-based approach for job classification in the modern online labor market. We employed structural topic modeling as our methodology and used the NASDAQ-100 indexed companies' online job vacancies on LinkedIn as the input data. We discover that among all 13 job categories, Marketing, Branding, and Sales; Software Engineering; Hardware Engineering; Industrial Engineering; and Project Management are the most frequently posted job classifications. This study aims to provide a clearer understanding of job market trends, enabling stakeholders to make informed decisions in a rapidly evolving employment landscape.",
        "subjects": [
            "econ.GN",
            "cs.AI"
        ],
        "comment": "17 pages, 4 figures, 1 table. Presented at the International Conference on Optimization and Data Science in Industrial Engineering (ODSIE 2023)"
    },
    {
        "paper id": "2409.00664",
        "abstract url": "https://arxiv.org/abs/2409.00664",
        "title": "Video-based Analysis Reveals Atypical Social Gaze in People with Autism Spectrum Disorder",
        "rating": "-1.5",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we present a quantitative and comprehensive analysis of social gaze in people with autism spectrum disorder (ASD). Diverging from traditional first-person camera perspectives based on eye-tracking technologies, this study utilizes a third-person perspective database from the Autism Diagnostic Observation Schedule, 2nd Edition (ADOS-2) interview videos, encompassing ASD participants and neurotypical individuals as a reference group. Employing computational models, we extracted and processed gaze-related features from the videos of both participants and examiners. The experimental samples were divided into three groups based on the presence of social gaze abnormalities and ASD diagnosis. This study quantitatively analyzed four gaze features: gaze engagement, gaze variance, gaze density map, and gaze diversion frequency. Furthermore, we developed a classifier trained on these features to identify gaze abnormalities in ASD participants. Together, we demonstrated the effectiveness of analyzing social gaze in people with ASD in naturalistic settings, showcasing the potential of third-person video perspectives in enhancing ASD diagnosis through gaze analysis.",
        "subjects": [
            "q-bio.NC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00667",
        "abstract url": "https://arxiv.org/abs/2409.00667",
        "title": "Comprehensive Botnet Detection by Mitigating Adversarial Attacks, Navigating the Subtleties of Perturbation Distances and Fortifying Predictions with Conformal Layers",
        "rating": "-1.5",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Botnets are computer networks controlled by malicious actors that present significant cybersecurity challenges. They autonomously infect, propagate, and coordinate to conduct cybercrimes, necessitating robust detection methods. This research addresses the sophisticated adversarial manipulations posed by attackers, aiming to undermine machine learning-based botnet detection systems. We introduce a flow-based detection approach, leveraging machine learning and deep learning algorithms trained on the ISCX and ISOT datasets. The detection algorithms are optimized using the Genetic Algorithm and Particle Swarm Optimization to obtain a baseline detection method. The Carlini & Wagner (C&W) attack and Generative Adversarial Network (GAN) generate deceptive data with subtle perturbations, targeting each feature used for classification while preserving their semantic and syntactic relationships, which ensures that the adversarial samples retain meaningfulness and realism. An in-depth analysis of the required L2 distance from the original sample for the malware sample to misclassify is performed across various iteration checkpoints, showing different levels of misclassification at different L2 distances of the Pertrub sample from the original sample. Our work delves into the vulnerability of various models, examining the transferability of adversarial examples from a Neural Network surrogate model to Tree-based algorithms. Subsequently, models that initially misclassified the perturbed samples are retrained, enhancing their resilience and detection capabilities. In the final phase, a conformal prediction layer is integrated, significantly rejecting incorrect predictions, of 58.20 % in the ISCX dataset and 98.94 % in the ISOT dataset.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "46 pages"
    },
    {
        "paper id": "2409.00701",
        "abstract url": "https://arxiv.org/abs/2409.00701",
        "title": "A Novel Taxonomy for Navigating and Classifying Synthetic Data in Healthcare Applications",
        "rating": "-1.5",
        "keywords": [
            [
                "Healthcare"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Data-driven technologies have improved the efficiency, reliability and effectiveness of healthcare services, but come with an increasing demand for data, which is challenging due to privacy-related constraints on sharing data in healthcare contexts. Synthetic data has recently gained popularity as potential solution, but in the flurry of current research it can be hard to oversee its potential. This paper proposes a novel taxonomy of synthetic data in healthcare to navigate the landscape in terms of three main varieties. Data Proportion comprises different ratios of synthetic data in a dataset and associated pros and cons. Data Modality refers to the different data formats amenable to synthesis and format-specific challenges. Data Transformation concerns improving specific aspects of a dataset like its utility or privacy with synthetic data. Our taxonomy aims to help researchers in the healthcare domain interested in synthetic data to grasp what types of datasets, data modalities, and transformations are possible with synthetic data, and where the challenges and overlaps between the varieties lie.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Accepted at the 23rd EFMI Special Topic Conference, Romania, November 2024"
    },
    {
        "paper id": "2409.00743",
        "abstract url": "https://arxiv.org/abs/2409.00743",
        "title": "Interpretable Clustering: A Survey",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, much of the research on clustering algorithms has primarily focused on enhancing their accuracy and efficiency, frequently at the expense of interpretability. However, as these methods are increasingly being applied in high-stakes domains such as healthcare, finance, and autonomous systems, the need for transparent and interpretable clustering outcomes has become a critical concern. This is not only necessary for gaining user trust but also for satisfying the growing ethical and regulatory demands in these fields. Ensuring that decisions derived from clustering algorithms can be clearly understood and justified is now a fundamental requirement. To address this need, this paper provides a comprehensive and structured review of the current state of explainable clustering algorithms, identifying key criteria to distinguish between various methods. These insights can effectively assist researchers in making informed decisions about the most suitable explainable clustering methods for specific application contexts, while also promoting the development and adoption of clustering algorithms that are both efficient and transparent.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "11 pages, 2 figures"
    },
    {
        "paper id": "2409.00754",
        "abstract url": "https://arxiv.org/abs/2409.00754",
        "title": "Cooperative Path Planning with Asynchronous Multiagent Reinforcement Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "graphs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we study the shortest path problem (SPP) with multiple source-destination pairs (MSD), namely MSD-SPP, to minimize average travel time of all shortest paths. The inherent traffic capacity limits within a road network contributes to the competition among vehicles. Multi-agent reinforcement learning (MARL) model cannot offer effective and efficient path planning cooperation due to the asynchronous decision making setting in MSD-SPP, where vehicles (a.k.a agents) cannot simultaneously complete routing actions in the previous time step. To tackle the efficiency issue, we propose to divide an entire road network into multiple sub-graphs and subsequently execute a two-stage process of inter-region and intra-region route planning. To address the asynchronous issue, in the proposed asyn-MARL framework, we first design a global state, which exploits a low-dimensional vector to implicitly represent the joint observations and actions of multi-agents. Then we develop a novel trajectory collection mechanism to decrease the redundancy in training trajectories. Additionally, we design a novel actor network to facilitate the cooperation among vehicles towards the same or close destinations and a reachability graph aimed at preventing infinite loops in routing paths. On both synthetic and real road networks, our evaluation result demonstrates that our approach outperforms state-of-the-art planning approaches.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00848",
        "abstract url": "https://arxiv.org/abs/2409.00848",
        "title": "Federated Aggregation of Mallows Rankings: A Comparative Analysis of Borda and Lehmer Coding",
        "rating": "-1.5",
        "keywords": [
            [
                "biomedical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Rank aggregation combines multiple ranked lists into a consensus ranking. In fields like biomedical data sharing, rankings may be distributed and require privacy. This motivates the need for federated rank aggregation protocols, which support distributed, private, and communication-efficient learning across multiple clients with local data. We present the first known federated rank aggregation methods using Borda scoring and Lehmer codes, focusing on the sample complexity for federated algorithms on Mallows distributions with a known scaling factor $\u03c6$ and an unknown centroid permutation $\u03c3_0$. Federated Borda approach involves local client scoring, nontrivial quantization, and privacy-preserving protocols. We show that for $\u03c6\\in [0,1)$, and arbitrary $\u03c3_0$ of length $N$, it suffices for each of the $L$ clients to locally aggregate $\\max\\{C_1(\u03c6), C_2(\u03c6)\\frac{1}{L}\\log \\frac{N}\u03b4\\}$ rankings, where $C_1(\u03c6)$ and $C_2(\u03c6)$ are constants, quantize the result, and send it to the server who can then recover $\u03c3_0$ with probability $\\geq 1-\u03b4$. Communication complexity scales as $NL \\log N$. Our results represent the first rigorous analysis of Borda's method in centralized and distributed settings under the Mallows model. Federated Lehmer coding approach creates a local Lehmer code for each client, using a coordinate-majority aggregation approach with specialized quantization methods for efficiency and privacy. We show that for $\u03c6+\u03c6^2<1+\u03c6^N$, and arbitrary $\u03c3_0$ of length $N$, it suffices for each of the $L$ clients to locally aggregate $\\max\\{C_3(\u03c6), C_4(\u03c6)\\frac{1}{L}\\log \\frac{N}\u03b4\\}$ rankings, where $C_3(\u03c6)$ and $C_4(\u03c6)$ are constants. Clients send truncated Lehmer coordinate histograms to the server, which can recover $\u03c3_0$ with probability $\\geq 1-\u03b4$. Communication complexity is $\\sim O(N\\log NL\\log L)$.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00908",
        "abstract url": "https://arxiv.org/abs/2409.00908",
        "title": "EnsLoss: Stochastic Calibrated Loss Ensembles for Preventing Overfitting in Classification",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Empirical risk minimization (ERM) with a computationally feasible surrogate loss is a widely accepted approach for classification. Notably, the convexity and calibration (CC) properties of a loss function ensure consistency of ERM in maximizing accuracy, thereby offering a wide range of options for surrogate losses. In this article, we propose a novel ensemble method, namely \\textsc{EnsLoss}, which extends the ensemble learning concept to combine loss functions within the ERM framework. A key feature of our method is the consideration on preserving the ``legitimacy'' of the combined losses, i.e., ensuring the CC properties. Specifically, we first transform the CC conditions of losses into loss-derivatives, thereby bypassing the need for explicit loss functions and directly generating calibrated loss-derivatives. Therefore, inspired by Dropout, \\textsc{EnsLoss} enables loss ensembles through one training process with doubly stochastic gradient descent (i.e., random batch samples and random calibrated loss-derivatives). We theoretically establish the statistical consistency of our approach and provide insights into its benefits. The numerical effectiveness of \\textsc{EnsLoss} compared to fixed loss methods is demonstrated through experiments on a broad range of 14 OpenML tabular datasets and 46 image datasets with various deep learning architectures. Python repository and source code are available on \\textsc{GitHub} at \\url{https://github.com/statmlben/rankseg}.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": "31 pages; 4 figures"
    },
    {
        "paper id": "2409.00661",
        "abstract url": "https://arxiv.org/abs/2409.00661",
        "title": "Research on LLM Acceleration Using the High-Performance RISC-V Processor \"Xiangshan\" (Nanhu Version) Based on the Open-Source Matrix Instruction Set Extension (Vector Dot Product)",
        "rating": "-2",
        "keywords": [
            [
                "FPGA"
            ]
        ],
        "abstract": "Considering the high-performance and low-power requirements of edge AI, this study designs a specialized instruction set processor for edge AI based on the RISC-V instruction set architecture, addressing practical issues in digital signal processing for edge devices. This design enhances the execution efficiency of edge AI and reduces its energy consumption with limited hardware overhead, meeting the demands for efficient large language model (LLM) inference computation in edge AI applications. The main contributions of this paper are as follows: For the characteristics of large language models, custom instructions were extended based on the RISC-V instruction set to perform vector dot product calculations, accelerating the computation of large language models on dedicated vector dot product acceleration hardware. Based on the open-source high-performance RISC-V processor core XiangShan Nanhu architecture, the vector dot product specialized instruction set processor Nanhu-vdot was implemented, which adds vector dot product calculation units and pipeline processing logic on top of the XiangShan Nanhu.The Nanhu-vdot underwent FPGA hardware testing, achieving over four times the speed of scalar methods in vector dot product computation. Using a hardware-software co-design approach for second-generation Generative Pre-Trained Transformer (GPT-2) model inference, the speed improved by approximately 30% compared to pure software implementation with almost no additional consumption of hardware resources and power consumption.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "10 pages, in Chinese language, 6 figures"
    },
    {
        "paper id": "2409.00678",
        "abstract url": "https://arxiv.org/abs/2409.00678",
        "title": "Automatic Grouping of Redundant Sensors and Actuators Using Functional and Spatial Connections: Application to Muscle Grouping for Musculoskeletal Humanoids",
        "rating": "-2",
        "keywords": [
            [
                "robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "For a robot with redundant sensors and actuators distributed throughout its body, it is difficult to construct a controller or a neural network using all of them due to computational cost and complexity. Therefore, it is effective to extract functionally related sensors and actuators, group them, and construct a controller or a network for each of these groups. In this study, the functional and spatial connections among sensors and actuators are embedded into a graph structure and a method for automatic grouping is developed. Taking a musculoskeletal humanoid with a large number of redundant muscles as an example, this method automatically divides all the muscles into regions such as the forearm, upper arm, scapula, neck, etc., which has been done by humans based on a geometric model. The functional relationship among the muscles and the spatial relationship of the neural connections are calculated without a geometric model.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at IEEE Robotics and Automation Letters"
    },
    {
        "paper id": "2409.00685",
        "abstract url": "https://arxiv.org/abs/2409.00685",
        "title": "Accurate Forgetting for All-in-One Image Restoration Model",
        "rating": "-2",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "Image Restoration",
                "haze"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Privacy protection has always been an ongoing topic, especially for AI. Currently, a low-cost scheme called Machine Unlearning forgets the private data remembered in the model. Specifically, given a private dataset and a trained neural network, we need to use e.g. pruning, fine-tuning, and gradient ascent to remove the influence of the private dataset on the neural network. Inspired by this, we try to use this concept to bridge the gap between the fields of image restoration and security, creating a new research idea. We propose the scene for the All-In-One model (a neural network that restores a wide range of degraded information), where a given dataset such as haze, or rain, is private and needs to be eliminated from the influence of it on the trained model. Notably, we find great challenges in this task to remove the influence of sensitive data while ensuring that the overall model performance remains robust, which is akin to directing a symphony orchestra without specific instruments while keeping the playing soothing. Here we explore a simple but effective approach: Instance-wise Unlearning through the use of adversarial examples and gradient ascent techniques. Our approach is a low-cost solution compared to the strategy of retraining the model from scratch, where the gradient ascent trick forgets the specified data and the performance of the adversarial sample maintenance model is robust. Through extensive experimentation on two popular unified image restoration models, we show that our approach effectively preserves knowledge of remaining data while unlearning a given degradation type.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00702",
        "abstract url": "https://arxiv.org/abs/2409.00702",
        "title": "MARS: Matching Attribute-aware Representations for Text-based Sequential Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Sequential recommendation aims to predict the next item a user is likely to prefer based on their sequential interaction history. Recently, text-based sequential recommendation has emerged as a promising paradigm that uses pre-trained language models to exploit textual item features to enhance performance and facilitate knowledge transfer to unseen datasets. However, existing text-based recommender models still struggle with two key challenges: (i) representing users and items with multiple attributes, and (ii) matching items with complex user interests. To address these challenges, we propose a novel model, Matching Attribute-aware Representations for Text-based Sequential Recommendation (MARS)}. MARS extracts detailed user and item representations through attribute-aware text encoding, capturing diverse user intents with multiple attribute-aware representations. It then computes user-item scores via attribute-wise interaction matching, effectively capturing attribute-level user preferences. Our extensive experiments demonstrate that MARS significantly outperforms existing sequential models, achieving improvements of up to 24.43% and 29.26% in Recall@10 and NDCG@10 across five benchmark datasets. Code is available at https://github.com/junieberry/MARS",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00708",
        "abstract url": "https://arxiv.org/abs/2409.00708",
        "title": "Wasm-R3: Record-Reduce-Replay for Realistic and Standalone WebAssembly Benchmarks",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "WebAssembly (Wasm for short) brings a new, powerful capability to the web as well as Edge, IoT, and embedded systems. Wasm is a portable, compact binary code format with high performance and robust sandboxing properties. As Wasm applications grow in size and importance, the complex performance characteristics of diverse Wasm engines demand robust, representative benchmarks for proper tuning. Stopgap benchmark suites, such as PolyBenchC and libsodium, continue to be used in the literature, though they are known to be unrepresentative. Porting of more complex suites remains difficult because Wasm lacks many system APIs and extracting real-world Wasm benchmarks from the web is difficult due to complex host interactions. To address this challenge, we introduce Wasm-R3, the first record and replay technique for Wasm. Wasm-R3 transparently injects instrumentation into Wasm modules to record an execution trace from inside the module, then reduces the execution trace via several optimizations, and finally produces a replay module that is executable sandalone without any host environment - on any engine. The benchmarks created by our approach are (i) realistic, because the approach records real-world web applications, (ii) faithful to the original execution, because the replay benchmark includes the unmodified original code, only adding emulation of host interactions, and (iii) standalone, because the replay benchmarks run on any engine. Applying Wasm-R3 to web-based Wasm applications in the wild demonstrates the correctness of our approach as well as the effectiveness of our optimizations, which reduce the recorded traces by 99.53 percent and the size of the replay benchmark by 9.98 percent. We release the resulting benchmark suite of 27 applications, called Wasm-R3-Bench, to the community, to inspire a new generation of realistic and standalone Wasm benchmarks.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "Accepted at OOPSLA 2024"
    },
    {
        "paper id": "2409.00716",
        "abstract url": "https://arxiv.org/abs/2409.00716",
        "title": "Enhancing Multi-Stream Beamforming Through CQIs For 5G NR FDD Massive MIMO Communications: A Tuning-Free Scheme",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "In the fifth-generation new radio (5G NR) frequency division duplex (FDD) massive multiple-input and multiple-output (MIMO) systems, downlink beamforming relies on the acquisition of downlink channel state information (CSI). Codebook based limited feedback schemes have been proposed and widely used in practice to recover the downlink CSI with low communication overhead. In such schemes, the performance of downlink beamforming is determined by the codebook design and the codebook indicator feedback. However, limited by the quantization quality of the codebook, directly utilizing the codeword indicated by the feedback as the beamforming vector cannot achieve high performance. Therefore, other feedback values, such as channel qualification indicator (CQI), should be considered to enhance beamforming. In this paper, we present the relation between CQI and the optimal beamforming vectors, based on which an empirical Bayes based intelligent tuning-free algorithm is devised to learn the optimal beamforming vector and the associated regularization parameter. The proposed algorithm can handle different communication scenarios of MIMO systems, including single stream and multiple streams data transmission scenarios. Numerical results have shown the excellent performance of the proposed algorithm in terms of both beamforming vector acquisition and regularization parameter learning.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00720",
        "abstract url": "https://arxiv.org/abs/2409.00720",
        "title": "Fair Reciprocal Recommendation in Matching Markets",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recommender systems play an increasingly crucial role in shaping people's opportunities, particularly in online dating platforms. It is essential from the user's perspective to increase the probability of matching with a suitable partner while ensuring an appropriate level of fairness in the matching opportunities. We investigate reciprocal recommendation in two-sided matching markets between agents divided into two sides. In our model, a match is considered successful only when both individuals express interest in each other. Additionally, we assume that agents prefer to appear prominently in the recommendation lists presented to those on the other side. We define each agent's opportunity to be recommended and introduce its fairness criterion, envy-freeness, from the perspective of fair division theory. The recommendations that approximately maximize the expected number of matches, empirically obtained by heuristic algorithms, are likely to result in significant unfairness of opportunity. Therefore, there can be a trade-off between maximizing the expected matches and ensuring fairness of opportunity. To address this challenge, we propose a method to find a policy that is close to being envy-free by leveraging the Nash social welfare function. Experiments on synthetic and real-world datasets demonstrate the effectiveness of our approach in achieving both relatively high expected matches and fairness for opportunities of both sides in reciprocal recommender systems.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted at RecSys2024"
    },
    {
        "paper id": "2409.00723",
        "abstract url": "https://arxiv.org/abs/2409.00723",
        "title": "Estimating Channels With Hundreds of Sub-Paths for MU-MIMO Uplink: A Structured High-Rank Tensor Approach",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "This letter introduces a structured high-rank tensor approach for estimating sub-6G uplink channels in multi-user multiple-input and multiple-output (MU-MIMO) systems. To tackle the difficulty of channel estimation in sub-6G bands with hundreds of sub-paths, our approach fully exploits the physical structure of channel and establishes the link between sub-6G channel model and a high-rank four-dimensional (4D) tensor Canonical Polyadic Decomposition (CPD) with three factor matrices being Vandermonde-constrained. Accordingly, a stronger uniqueness property is derived in this work. This model supports an efficient one-pass algorithm for estimating sub-path parameters, which ensures plug-in compatibility with the widely-used baseline. Our method performs much better than the state-of-the-art tensor-based techniques on the simulations adhering to the 3GPP 5G protocols.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00726",
        "abstract url": "https://arxiv.org/abs/2409.00726",
        "title": "LPUWF-LDM: Enhanced Latent Diffusion Model for Precise Late-phase UWF-FA Generation on Limited Dataset",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "medical",
                "lesion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Ultra-Wide-Field Fluorescein Angiography (UWF-FA) enables precise identification of ocular diseases using sodium fluorescein, which can be potentially harmful. Existing research has developed methods to generate UWF-FA from Ultra-Wide-Field Scanning Laser Ophthalmoscopy (UWF-SLO) to reduce the adverse reactions associated with injections. However, these methods have been less effective in producing high-quality late-phase UWF-FA, particularly in lesion areas and fine details. Two primary challenges hinder the generation of high-quality late-phase UWF-FA: the scarcity of paired UWF-SLO and early/late-phase UWF-FA datasets, and the need for realistic generation at lesion sites and potential blood leakage regions. This study introduces an improved latent diffusion model framework to generate high-quality late-phase UWF-FA from limited paired UWF images. To address the challenges as mentioned earlier, our approach employs a module utilizing Cross-temporal Regional Difference Loss, which encourages the model to focus on the differences between early and late phases. Additionally, we introduce a low-frequency enhanced noise strategy in the diffusion forward process to improve the realism of medical images. To further enhance the mapping capability of the variational autoencoder module, especially with limited datasets, we implement a Gated Convolutional Encoder to extract additional information from conditional images. Our Latent Diffusion Model for Ultra-Wide-Field Late-Phase Fluorescein Angiography (LPUWF-LDM) effectively reconstructs fine details in late-phase UWF-FA and achieves state-of-the-art results compared to other existing methods when working with limited datasets. Our source code is available at: https://github.com/Tinysqua/****.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "13 pages, 7 figures"
    },
    {
        "paper id": "2409.00750",
        "abstract url": "https://arxiv.org/abs/2409.00750",
        "title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Text-to-Speech"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Nowadays, large-scale text-to-speech (TTS) systems are primarily divided into two types: autoregressive and non-autoregressive. The autoregressive systems have certain deficiencies in robustness and cannot control speech duration. In contrast, non-autoregressive systems require explicit prediction of phone-level duration, which may compromise their naturalness. We introduce the Masked Generative Codec Transformer (MaskGCT), a fully non-autoregressive model for TTS that does not require precise alignment information between text and speech. MaskGCT is a two-stage model: in the first stage, the model uses text to predict semantic tokens extracted from a speech self-supervised learning (SSL) model, and in the second stage, the model predicts acoustic tokens conditioned on these semantic tokens. MaskGCT follows the \\textit{mask-and-predict} learning paradigm. During training, MaskGCT learns to predict masked semantic or acoustic tokens based on given conditions and prompts. During inference, the model generates tokens of a specified length in a parallel manner. We scale MaskGCT to a large-scale multilingual dataset with 100K hours of in-the-wild speech. Our experiments demonstrate that MaskGCT achieves superior or competitive performance compared to state-of-the-art zero-shot TTS systems in terms of quality, similarity, and intelligibility while offering higher generation efficiency than diffusion-based or autoregressive TTS models. Audio samples are available at https://maskgct.github.io.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00774",
        "abstract url": "https://arxiv.org/abs/2409.00774",
        "title": "SITUATE: Indoor Human Trajectory Prediction through Geometric Features and Self-Supervised Vision Representation",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Patterns of human motion in outdoor and indoor environments are substantially different due to the scope of the environment and the typical intentions of people therein. While outdoor trajectory forecasting has received significant attention, indoor forecasting is still an underexplored research area. This paper proposes SITUATE, a novel approach to cope with indoor human trajectory prediction by leveraging equivariant and invariant geometric features and a self-supervised vision representation. The geometric learning modules model the intrinsic symmetries and human movements inherent in indoor spaces. This concept becomes particularly important because self-loops at various scales and rapid direction changes often characterize indoor trajectories. On the other hand, the vision representation module is used to acquire spatial-semantic information about the environment to predict users' future locations more accurately. We evaluate our method through comprehensive experiments on the two most famous indoor trajectory forecasting datasets, i.e., TH\u00d6R and Supermarket, obtaining state-of-the-art performance. Furthermore, we also achieve competitive results in outdoor scenarios, showing that indoor-oriented forecasting models generalize better than outdoor-oriented ones. The source code is available at https://github.com/intelligolabs/SITUATE.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted at the 27th International Conference on Pattern Recognition (ICPR 2024)"
    },
    {
        "paper id": "2409.00798",
        "abstract url": "https://arxiv.org/abs/2409.00798",
        "title": "An Optimized Binning and Probabilistic Slice Sharing Algorithm for Motion Correction in Abdominal DW-MRI",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "diagnosis",
                "MRI",
                "lesion"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Abdominal diffusion-weighted magnetic resonance imaging (DW-MRI) is a powerful, non-invasive technique for characterizing lesions and facilitating early diagnosis. However, respiratory motion during a scan can degrade image quality. Binning image slices into respiratory phases may reduce motion artifacts, but when the standard binning algorithm is applied to DW-MRI, reconstructed volumes are often incomplete because they lack slices along the superior-inferior axis. Missing slices create black stripes within images, and prolonged scan times are required to generate complete volumes. In this study, we propose a new binning algorithm to minimize missing slices. We acquired free-breathing and shallow-breathing abdominal DW-MRI scans on seven volunteers and used our algorithm to correct for motion in free-breathing scans. First, we drew the optimal rigid bin partitions in the respiratory signal using a dynamic programming approach, assigning each slice to one bin. We then designed a probabilistic approach for selecting some slices to belong in two bins. Our proposed binning algorithm resulted in significantly fewer missing slices than standard binning (p<1.0e-16), yielding an average reduction of 82.98+/-6.07%. Our algorithm also improved lesion conspicuity and reduced motion artifacts in DW-MR images and Apparent Diffusion Coefficient (ADC) maps. ADC maps created from free-breathing images corrected for motion with our algorithm showed lower intra-subject variability compared to uncorrected free-breathing and shallow-breathing maps (p<0.001). Additionally, shallow-breathing ADC maps showed more consistency with corrected free-breathing maps rather than uncorrected free-breathing maps (p<0.01). Our proposed binning algorithm's efficacy in reducing missing slices increases anatomical accuracy and allows for shorter acquisition times compared to standard binning.",
        "subjects": [
            "eess.IV",
            "eess.SP"
        ],
        "comment": "16 pages, 5 figures"
    },
    {
        "paper id": "2409.00821",
        "abstract url": "https://arxiv.org/abs/2409.00821",
        "title": "Real-Time Weather Image Classification with SVM",
        "rating": "-2",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "haze"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate classification of weather conditions in images is essential for enhancing the performance of object detection and classification models under varying weather conditions. This paper presents a comprehensive study on classifying weather conditions in images into four categories: rainy, low light, haze, and clear. The motivation for this work stems from the need to improve the reliability and efficiency of automated systems, such as autonomous vehicles and surveillance, which must operate under diverse weather conditions. Misclassification of weather conditions can lead to significant performance degradation in these systems, making robust weather classification crucial. Utilizing the Support Vector Machine (SVM) algorithm, our approach leverages a robust set of features, including brightness, saturation, noise level, blur metric, edge strength, motion blur, Local Binary Patterns (LBP) mean and variance for radii 1, 2, and 3, edges mean and variance, and color histogram mean and variance for blue, green, and red channels. Our SVM-based method achieved a notable accuracy of 92.8%, surpassing typical benchmarks in the literature, which range from 80% to 90% for classical machine learning methods. While deep learning methods can achieve up to 94% accuracy, our approach offers a competitive advantage in terms of computational efficiency and real-time classification capabilities. Detailed analysis of each feature's contribution highlights the effectiveness of texture, color, and edge-related features in capturing the unique characteristics of different weather conditions. This research advances the state-of-the-art in weather image classification and provides insights into the critical features necessary for accurate weather condition differentiation, underscoring the potential of SVMs in practical applications where accuracy is paramount.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00825",
        "abstract url": "https://arxiv.org/abs/2409.00825",
        "title": "A Physical Layer Analysis of Entropy in Delay-Based PUFs Implemented on FPGAs",
        "rating": "-2",
        "keywords": [
            [
                "FPGAs"
            ]
        ],
        "abstract": "Physical Unclonable Functions (PUFs) leverage signal variations that occur within the device as a source of entropy. On-chip instrumentation is utilized by some PUF architectures to measure and digitize these variations, which are then processed into bitstrings and secret keys for use in security functions such as authentication and encryption. In many cases, the variations in the measured signals are introduced by a sequence of components in the circuit structure defined by the PUF architecture. In particular, the Hardware-Embedded deLay PUF (HELP) measures delay variations that occur in combinational logic paths on Field Programmable Gate Arrays (FPGAs), which are composed of a set of interconnecting wires (nodes) and look-up tables (LUTs). Previous investigations of variations in these path delays show that it is possible to derive high quality bitstrings, i.e., those which exhibit high levels of uniqueness and randomness across the device population. However, the underlying source and level of variations associated with the constituent components of the paths remain unknown. In this paper, we apply statistical averaging and differencing techniques to derive estimates for the delay variation associated with an FPGA's basic components, namely LUTs and nodes, as a means of fully characterizing the PUF's source of entropy. The analysis is carried out on a set of 50,015 path delay measurements collected from a set of 20 Xilinx Zynq 7020 SoC-class FPGAs, on which 25 identical instances of a functional unit are instantiated, for a total of 500 instances.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00828",
        "abstract url": "https://arxiv.org/abs/2409.00828",
        "title": "Smarter k-Partitioning of ZX-Diagrams for Improved Quantum Circuit Simulation",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We introduce a novel method for strong classical simulation of quantum circuits based on optimally k-partitioning ZX-diagrams, reducing each part individually, and then efficiently cross-referencing their results to conclude the overall probability amplitude of the original circuit. We then analyse how this method fares against the alternatives for circuits of various size, shape, and interconnectedness and demonstrate how it is often liable to outperform those alternatives in speed by orders of magnitude.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "comment": "26 pages, 27 figures (11 excluding inline), 2 algorithms, and 1 table"
    },
    {
        "paper id": "2409.00851",
        "abstract url": "https://arxiv.org/abs/2409.00851",
        "title": "Dissecting Temporal Understanding in Text-to-Audio Retrieval",
        "rating": "-2",
        "keywords": [
            [
                "text-to-video"
            ],
            [
                "Text-to-Audio"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent advancements in machine learning have fueled research on multimodal tasks, such as for instance text-to-video and text-to-audio retrieval. These tasks require models to understand the semantic content of video and audio data, including objects, and characters. The models also need to learn spatial arrangements and temporal relationships. In this work, we analyse the temporal ordering of sounds, which is an understudied problem in the context of text-to-audio retrieval. In particular, we dissect the temporal understanding capabilities of a state-of-the-art model for text-to-audio retrieval on the AudioCaps and Clotho datasets. Additionally, we introduce a synthetic text-audio dataset that provides a controlled setting for evaluating temporal capabilities of recent models. Lastly, we present a loss function that encourages text-audio models to focus on the temporal ordering of events. Code and data are available at https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/dtu/.",
        "subjects": [
            "cs.IR",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "9 pages, 5 figures, ACM Multimedia 2024, https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/dtu/"
    },
    {
        "paper id": "2409.00869",
        "abstract url": "https://arxiv.org/abs/2409.00869",
        "title": "Detection, Recognition and Pose Estimation of Tabletop Objects",
        "rating": "-2",
        "keywords": [
            [
                "robotics",
                "robot"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The problem of cleaning a messy table using Deep Neural Networks is a very interesting problem in both social and industrial robotics. This project focuses on the social application of this technology. A neural network model that is capable of detecting and recognizing common tabletop objects, such as a mug, mouse, or stapler is developed. The model also predicts the angle at which these objects are placed on a table,with respect to some reference. Assuming each object has a fixed intended position and orientation on the tabletop, the orientation of a particular object predicted by the deep learning model can be used to compute the transformation matrix to move the object from its initial position to the intended position. This can be fed to a pick and place robot to carry out the transfer.This paper talks about the deep learning approaches used in this project for object detection and orientation estimation.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00889",
        "abstract url": "https://arxiv.org/abs/2409.00889",
        "title": "Geno-Weaving: Low-Complexity Capacity-Achieving DNA Storage",
        "rating": "-2",
        "keywords": [
            [
                "DNA"
            ]
        ],
        "abstract": "As a possible implementation of data storage using DNA, multiple strands of DNA are stored in a liquid container so that, in the future, they can be read by an array of DNA readers in parallel. These readers will sample the strands with replacement to produce a random number of noisy reads for each strand. An essential component of such a data storage system is how to reconstruct data out of these unsorted, repetitive, and noisy reads. It is known that if a single read can be modeled by a substitution channel $W$, then the overall capacity can be expressed by the \"Poisson-ization\" of $W$. In this paper, we lay down a rateless code along each strand to encode its index; we then lay down a capacity-achieving block code at the same position across all strands to protect data. That weaves a low-complexity coding scheme that achieves DNA's capacity.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "18 pages, 5 figures"
    },
    {
        "paper id": "2409.00919",
        "abstract url": "https://arxiv.org/abs/2409.00919",
        "title": "MMT-BERT: Chord-aware Symbolic Music Generation Based on Multitrack Music Transformer and MusicBERT",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Music"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We propose a novel symbolic music representation and Generative Adversarial Network (GAN) framework specially designed for symbolic multitrack music generation. The main theme of symbolic music generation primarily encompasses the preprocessing of music data and the implementation of a deep learning framework. Current techniques dedicated to symbolic music generation generally encounter two significant challenges: training data's lack of information about chords and scales and the requirement of specially designed model architecture adapted to the unique format of symbolic music representation. In this paper, we solve the above problems by introducing new symbolic music representation with MusicLang chord analysis model. We propose our MMT-BERT architecture adapting to the representation. To build a robust multitrack music generator, we fine-tune a pre-trained MusicBERT model to serve as the discriminator, and incorporate relativistic standard loss. This approach, supported by the in-depth understanding of symbolic music encoded within MusicBERT, fortifies the consonance and humanity of music generated by our method. Experimental results demonstrate the effectiveness of our approach which strictly follows the state-of-the-art methods.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "Accepted to the 25th International Society for Music Information Retrieval Conference (ISMIR 2024)"
    },
    {
        "paper id": "2409.00651",
        "abstract url": "https://arxiv.org/abs/2409.00651",
        "title": "Adapting Physics-Informed Neural Networks for Bifurcation Detection in Ecological Migration Models",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "In this study, we explore the application of Physics-Informed Neural Networks (PINNs) to the analysis of bifurcation phenomena in ecological migration models. By integrating the fundamental principles of diffusion-advection-reaction equations with deep learning techniques, we address the complexities of species migration dynamics, particularly focusing on the detection and analysis of Hopf bifurcations. Traditional numerical methods for solving partial differential equations (PDEs) often involve intricate calculations and extensive computational resources, which can be restrictive in high-dimensional problems. In contrast, PINNs offer a more flexible and efficient alternative, bypassing the need for grid discretization and allowing for mesh-free solutions. Our approach leverages the DeepXDE framework, which enhances the computational efficiency and applicability of PINNs in solving high-dimensional PDEs. We validate our results against conventional methods and demonstrate that PINNs not only provide accurate bifurcation predictions but also offer deeper insights into the underlying dynamics of diffusion processes. Despite these advantages, the study also identifies challenges such as the high computational costs and the sensitivity of PINN performance to network architecture and hyperparameter settings. Future work will focus on optimizing these algorithms and expanding their application to other complex systems involving bifurcations. The findings from this research have significant implications for the modeling and analysis of ecological systems, providing a powerful tool for predicting and understanding complex dynamical behaviors.",
        "subjects": [
            "nlin.CD",
            "cs.CY",
            "cs.LG",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00795",
        "abstract url": "https://arxiv.org/abs/2409.00795",
        "title": "Analysis of a mathematical model for malaria using data-driven approach",
        "rating": "-2.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Medical",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Malaria is one of the deadliest diseases in the world, every year millions of people become victims of this disease and many even lose their lives. Medical professionals and the government could take accurate measures to protect the people only when the disease dynamics are understood clearly. In this work, we propose a compartmental model to study the dynamics of malaria. We consider the transmission rate dependent on temperature and altitude. We performed the steady state analysis on the proposed model and checked the stability of the disease-free and endemic steady state. An artificial neural network (ANN) is applied to the formulated model to predict the trajectory of all five compartments following the mathematical analysis. Three different neural network architectures namely Artificial neural network (ANN), convolution neural network (CNN), and Recurrent neural network (RNN) are used to estimate these parameters from the trajectory of the data. To understand the severity of a disease, it is essential to calculate the risk associated with the disease. In this work, the risk is calculated using dynamic mode decomposition(DMD) from the trajectory of the infected people.",
        "subjects": [
            "q-bio.PE",
            "cs.LG",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00858",
        "abstract url": "https://arxiv.org/abs/2409.00858",
        "title": "Trustworthy Human-AI Collaboration: Reinforcement Learning with Human Feedback and Physics Knowledge for Safe Autonomous Driving",
        "rating": "-2.5",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the field of autonomous driving, developing safe and trustworthy autonomous driving policies remains a significant challenge. Recently, Reinforcement Learning with Human Feedback (RLHF) has attracted substantial attention due to its potential to enhance training safety and sampling efficiency. Nevertheless, existing RLHF-enabled methods often falter when faced with imperfect human demonstrations, potentially leading to training oscillations or even worse performance than rule-based approaches. Inspired by the human learning process, we propose Physics-enhanced Reinforcement Learning with Human Feedback (PE-RLHF). This novel framework synergistically integrates human feedback (e.g., human intervention and demonstration) and physics knowledge (e.g., traffic flow model) into the training loop of reinforcement learning. The key advantage of PE-RLHF is its guarantee that the learned policy will perform at least as well as the given physics-based policy, even when human feedback quality deteriorates, thus ensuring trustworthy safety improvements. PE-RLHF introduces a Physics-enhanced Human-AI (PE-HAI) collaborative paradigm for dynamic action selection between human and physics-based actions, employs a reward-free approach with a proxy value function to capture human preferences, and incorporates a minimal intervention mechanism to reduce the cognitive load on human mentors. Extensive experiments across diverse driving scenarios demonstrate that PE-RLHF significantly outperforms traditional methods, achieving state-of-the-art (SOTA) performance in safety, efficiency, and generalizability, even with varying quality of human feedback. The philosophy behind PE-RLHF not only advances autonomous driving technology but can also offer valuable insights for other safety-critical domains. Demo video and code are available at: \\https://zilin-huang.github.io/PE-RLHF-website/",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "33 pages, 20 figures"
    },
    {
        "paper id": "2409.00923",
        "abstract url": "https://arxiv.org/abs/2409.00923",
        "title": "Development of Occupancy Prediction Algorithm for Underground Parking Lots",
        "rating": "-2.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "BEV"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The core objective of this study is to address the perception challenges faced by autonomous driving in adverse environments like basements. Initially, this paper commences with data collection in an underground garage. A simulated underground garage model is established within the CARLA simulation environment, and SemanticKITTI format occupancy ground truth data is collected in this simulated setting. Subsequently, the study integrates a Transformer-based Occupancy Network model to complete the occupancy grid prediction task within this scenario. A comprehensive BEV perception framework is designed to enhance the accuracy of neural network models in dimly lit, challenging autonomous driving environments. Finally, experiments validate the accuracy of the proposed solution's perception performance in basement scenarios. The proposed solution is tested on our self-constructed underground garage dataset, SUSTech-COE-ParkingLot, yielding satisfactory results.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00622",
        "abstract url": "https://arxiv.org/abs/2409.00622",
        "title": "Roundabout Dilemma Zone Data Mining and Forecasting with Trajectory Prediction and Graph Neural Networks",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory",
                "vehicle"
            ],
            [
                "Graph"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Traffic roundabouts, as complex and critical road scenarios, pose significant safety challenges for autonomous vehicles. In particular, the encounter of a vehicle with a dilemma zone (DZ) at a roundabout intersection is a pivotal concern. This paper presents an automated system that leverages trajectory forecasting to predict DZ events, specifically at traffic roundabouts. Our system aims to enhance safety standards in both autonomous and manual transportation. The core of our approach is a modular, graph-structured recurrent model that forecasts the trajectories of diverse agents, taking into account agent dynamics and integrating heterogeneous data, such as semantic maps. This model, based on graph neural networks, aids in predicting DZ events and enhances traffic management decision-making. We evaluated our system using a real-world dataset of traffic roundabout intersections. Our experimental results demonstrate that our dilemma forecasting system achieves a high precision with a low false positive rate of 0.1. This research represents an advancement in roundabout DZ data mining and forecasting, contributing to the assurance of intersection safety in the era of autonomous vehicles.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00700",
        "abstract url": "https://arxiv.org/abs/2409.00700",
        "title": "Seeing Your Speech Style: A Novel Zero-Shot Identity-Disentanglement Face-based Voice Conversion",
        "rating": "-3",
        "keywords": [
            [
                "facial"
            ],
            [
                "Voice Conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Face-based Voice Conversion (FVC) is a novel task that leverages facial images to generate the target speaker's voice style. Previous work has two shortcomings: (1) suffering from obtaining facial embeddings that are well-aligned with the speaker's voice identity information, and (2) inadequacy in decoupling content and speaker identity information from the audio input. To address these issues, we present a novel FVC method, Identity-Disentanglement Face-based Voice Conversion (ID-FaceVC), which overcomes the above two limitations. More precisely, we propose an Identity-Aware Query-based Contrastive Learning (IAQ-CL) module to extract speaker-specific facial features, and a Mutual Information-based Dual Decoupling (MIDD) module to purify content features from audio, ensuring clear and high-quality voice conversion. Besides, unlike prior works, our method can accept either audio or text inputs, offering controllable speech generation with adjustable emotional tone and speed. Extensive experiments demonstrate that ID-FaceVC achieves state-of-the-art performance across various metrics, with qualitative and user study results confirming its effectiveness in naturalness, similarity, and diversity. Project website with audio samples and code can be found at https://id-facevc.github.io.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00719",
        "abstract url": "https://arxiv.org/abs/2409.00719",
        "title": "Reliability-considered Multi-platoon's Groupcasting using the Resource Sharing Method",
        "rating": "-3",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "5G"
            ]
        ],
        "abstract": "In the context of 5G platoon communications, the Platoon Leader Vehicle (PLV) employs groupcasting to transmit control messages to Platoon Member Vehicles (PMVs). Due to the restricted transmission power for groupcasting, it may need to pick one PMV as the Platoon Relay Vehicle (PRV) to be responsible for re-groupcasting messages of PLVs. To optimize the usage of limited spectrum resources, resource sharing can adopted to enhance spectrum efficiency within the platoon. This study proposes a resource allocation method, which is called Resource Sharing for Platoon Groupcasting (RSPG), for platoon groupcasting based on transmission reliability. RSPG utilizes tripartite matching to assign a subchannel to either a PLV or PRV that shares the assigned subchannel with the corresponding individual entity (IE), which does not belong to any platoon. The simulation results show that the proposed method performs better in terms of the QoS satisfaction rate of IEs, the number of allocated subchannels for platoons, and spectral efficiency.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "9 Pages, 11 Figures"
    },
    {
        "paper id": "2409.00864",
        "abstract url": "https://arxiv.org/abs/2409.00864",
        "title": "Automated Cinematography Motion Planning for UAVs",
        "rating": "-3",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "This project aimed to develop an automated cinematography platform using an unmanned aerial vehicle. Quadcopters are a great platform for shooting aerial scenes but are difficult to maneuver smoothly and can require expertise to pilot. We aim to design an algorithm to enable automated cinematography of a desired object of interest. Given the location of an object and other obstacles in the environment, the drone is able to plan its trajectory while simultaneously keeping the desired object in the video frame and avoiding obstacles. The high maneuverability of quadcopter platforms coupled with the desire for smooth movement and stability from camera platforms means a robust motion planning algorithm must be developed which can take advantage of the quadcopter's abilities while creating motion paths which satisfy the ultimate goal of capturing aerial video. This project aims to research, develop, simulate, and test such an algorithm.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00897",
        "abstract url": "https://arxiv.org/abs/2409.00897",
        "title": "Infiltrating the Sky: Data Delay and Overflow Attacks in Earth Observation Constellations",
        "rating": "-3",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "satellite"
            ]
        ],
        "abstract": "Low Earth Orbit (LEO) Earth Observation (EO) satellites have changed the way we monitor Earth. Acting like moving cameras, EO satellites are formed in constellations with different missions and priorities, and capture vast data that needs to be transmitted to the ground for processing. However, EO satellites have very limited downlink communication capability, limited by transmission bandwidth, number and location of ground stations, and small transmission windows due to high velocity satellite movement. To optimize resource utilization, EO constellations are expected to share communication spectrum and ground stations for maximum communication efficiency. In this paper, we investigate a new attack surface exposed by resource competition in EO constellations, targeting the delay or drop of Earth monitoring data using legitimate EO services. Specifically, an attacker can inject high-priority requests to temporarily preempt low-priority data transmission windows. Furthermore, we show that by utilizing predictable satellite dynamics, an attacker can intelligently target critical data from low-priority satellites, either delaying its delivery or irreversibly dropping the data. We formulate two attacks, the data delay attack and the data overflow attack, design algorithms to assist attackers in devising attack strategies, and analyze their feasibility or optimality in typical scenarios. We then conduct trace-driven simulations using real-world satellite images and orbit data to evaluate the success probability of launching these attacks under realistic satellite communication settings. We also discuss possible defenses against these attacks.",
        "subjects": [
            "cs.NI",
            "cs.CR",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00853",
        "abstract url": "https://arxiv.org/abs/2409.00853",
        "title": "JaxLife: An Open-Ended Agentic Simulator",
        "rating": "-3.5",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Human intelligence emerged through the process of natural selection and evolution on Earth. We investigate what it would take to re-create this process in silico. While past work has often focused on low-level processes (such as simulating physics or chemistry), we instead take a more targeted approach, aiming to evolve agents that can accumulate open-ended culture and technologies across generations. Towards this, we present JaxLife: an artificial life simulator in which embodied agents, parameterized by deep neural networks, must learn to survive in an expressive world containing programmable systems. First, we describe the environment and show that it can facilitate meaningful Turing-complete computation. We then analyze the evolved emergent agents' behavior, such as rudimentary communication protocols, agriculture, and tool use. Finally, we investigate how complexity scales with the amount of compute used. We believe JaxLife takes a step towards studying evolved behavior in more open-ended simulations. Our code is available at https://github.com/luchris429/JaxLife",
        "subjects": [
            "cs.AI",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00861",
        "abstract url": "https://arxiv.org/abs/2409.00861",
        "title": "Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering",
        "rating": "-4",
        "keywords": [
            [
                "graph"
            ],
            [
                "medical"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) frequently lack domain-specific knowledge and even fine-tuned models tend to hallucinate. Hence, more reliable models that can include external knowledge are needed. We present a pipeline, 4StepFocus, and specifically a preprocessing step, that can substantially improve the answers of LLMs. This is achieved by providing guided access to external knowledge making use of the model's ability to capture relational context and conduct rudimentary reasoning by themselves. The method narrows down potentially correct answers by triplets-based searches in a semi-structured knowledge base in a direct, traceable fashion, before switching to latent representations for ranking those candidates based on unstructured data. This distinguishes it from related methods that are purely based on latent representations. 4StepFocus consists of the steps: 1) Triplet generation for extraction of relational data by an LLM, 2) substitution of variables in those triplets to narrow down answer candidates employing a knowledge graph, 3) sorting remaining candidates with a vector similarity search involving associated non-structured data, 4) reranking the best candidates by the LLM with background data provided. Experiments on a medical, a product recommendation, and an academic paper search test set demonstrate that this approach is indeed a powerful augmentation. It not only adds relevant traceable background information from information retrieval, but also improves performance considerably in comparison to state-of-the-art methods. This paper presents a novel, largely unexplored direction and therefore provides a wide range of future work opportunities. Used source code is available at https://github.com/kramerlab/4StepFocus.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.LO"
        ],
        "comment": "9 pages, published at IJCLR 2024"
    },
    {
        "paper id": "2409.00735",
        "abstract url": "https://arxiv.org/abs/2409.00735",
        "title": "AgGym: An agricultural biotic stress simulation environment for ultra-precision management planning",
        "rating": "-5.5",
        "keywords": [
            [
                "biotic",
                "disease"
            ],
            [
                "chemical"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Agricultural production requires careful management of inputs such as fungicides, insecticides, and herbicides to ensure a successful crop that is high-yielding, profitable, and of superior seed quality. Current state-of-the-art field crop management relies on coarse-scale crop management strategies, where entire fields are sprayed with pest and disease-controlling chemicals, leading to increased cost and sub-optimal soil and crop management. To overcome these challenges and optimize crop production, we utilize machine learning tools within a virtual field environment to generate localized management plans for farmers to manage biotic threats while maximizing profits. Specifically, we present AgGym, a modular, crop and stress agnostic simulation framework to model the spread of biotic stresses in a field and estimate yield losses with and without chemical treatments. Our validation with real data shows that AgGym can be customized with limited data to simulate yield outcomes under various biotic stress conditions. We further demonstrate that deep reinforcement learning (RL) policies can be trained using AgGym for designing ultra-precise biotic stress mitigation strategies with potential to increase yield recovery with less chemicals and lower cost. Our proposed framework enables personalized decision support that can transform biotic stress management from being schedule based and reactive to opportunistic and prescriptive. We also release the AgGym software implementation as a community resource and invite experts to contribute to this open-sourced publicly available modular environment framework. The source code can be accessed at: https://github.com/SCSLabISU/AgGym.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00816",
        "abstract url": "https://arxiv.org/abs/2409.00816",
        "title": "Comparison of Encryption Algorithms for Wearable Devices in IoT Systems",
        "rating": "-6",
        "keywords": [
            [
                "medical"
            ],
            [
                "IoT"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "The Internet of Things (IoT) expansion has brought a new era of connected devices, including wearable devices like smartwatches and medical monitors, that are becoming integral parts of our daily lives. These devices not only offer innovative functionalities but also generate and transmit plenty of sensitive data, making their security and privacy the primary concerns. Given the unique challenges posed by wearable devices, such as limited computational resources and the need for real-time data processing, encryption stands as a cornerstone for safeguarding the integrity and confidentiality of the data they handle. Various encryption algorithms, each with its own set of advantages and limitations, are available to meet the diverse security and computational needs of wearable IoT devices. As we move into an age where quantum computing could potentially disrupt traditional encryption methods, choosing a suitable encryption algorithm becomes even more critical. This paper explores and evaluates the suitability of different encryption methods in the context of wearable IoT devices, considering current and future security challenges.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00830",
        "abstract url": "https://arxiv.org/abs/2409.00830",
        "title": "Building FKG.in: a Knowledge Graph for Indian Food",
        "rating": "-6",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biochemistry",
                "Health"
            ],
            [
                "recommendation"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents an ontology design along with knowledge engineering, and multilingual semantic reasoning techniques to build an automated system for assimilating culinary information for Indian food in the form of a knowledge graph. The main focus is on designing intelligent methods to derive ontology designs and capture all-encompassing knowledge about food, recipes, ingredients, cooking characteristics, and most importantly, nutrition, at scale. We present our ongoing work in this workshop paper, describe in some detail the relevant challenges in curating knowledge of Indian food, and propose our high-level ontology design. We also present a novel workflow that uses AI, LLM, and language technology to curate information from recipe blog sites in the public domain to build knowledge graphs for Indian food. The methods for knowledge curation proposed in this paper are generic and can be replicated for any domain. The design is application-agnostic and can be used for AI-driven smart analysis, building recommendation systems for Personalized Digital Health, and complementing the knowledge graph for Indian food with contextual information such as user information, food biochemistry, geographic information, agricultural information, etc.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.IR"
        ],
        "comment": "14 pages, 3 figures, 25 references, Formal Ontology in Information Systems Conference 2024 - Integrated Food Ontology Workshop"
    },
    {
        "paper id": "2409.00615",
        "abstract url": "https://arxiv.org/abs/2409.00615",
        "title": "MetaDigiHuman: Haptic Interfaces for Digital Humans in Metaverse",
        "rating": "-10",
        "keywords": [],
        "abstract": "The way we engage with digital spaces and the digital world has undergone rapid changes in recent years, largely due to the emergence of the Metaverse. As technology continues to advance, the demand for sophisticated and immersive interfaces to interact with the Metaverse has become increasingly crucial. Haptic interfaces have been developed to meet this need and provide users with tactile feedback and realistic touch sensations. These interfaces play a vital role in creating a more authentic and immersive experience within the Metaverse. This article introduces the concept of MetaDigiHuman, a groundbreaking framework that combines blended digital humans and haptic interfaces. By harnessing cutting-edge technologies, MetaDigiHuman enables seamless and immersive interaction within the Metaverse. Through this framework, users can simulate the sensation of touching, feeling, and interacting with digital beings as if they were physically present in the environments, offering a more compelling and immersive experience within the Metaverse.",
        "subjects": [
            "cs.HC",
            "cs.MM"
        ],
        "comment": "5 pages, 2 figures"
    },
    {
        "paper id": "2409.00616",
        "abstract url": "https://arxiv.org/abs/2409.00616",
        "title": "Incorporating General Contact Surfaces in the Kinematics of Tendon-Driven Rolling-Contact Joint Mechanisms",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents the first kinematic modeling of tendon-driven rolling-contact joint mechanisms with general contact surfaces subject to external loads. We derived the kinematics as a set of recursive equations and developed efficient iterative algorithms to solve for both tendon force actuation and tendon displacement actuation. The configuration predictions of the kinematics were experimentally validated using a prototype mechanism. Our MATLAB implementation of the proposed kinematic is available at https://github.com/hjhdog1/RollingJoint.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "10 pages, 13 figures"
    },
    {
        "paper id": "2409.00628",
        "abstract url": "https://arxiv.org/abs/2409.00628",
        "title": "Energy-Efficient Designs for SIM-Based Broadcast MIMO Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Stacked intelligent metasurface (SIM), which consists of multiple layers of intelligent metasurfaces, is emerging as a promising solution for future wireless communication systems. In this timely context, we focus on broadcast multiple-input multiple-output (MIMO) systems and aim to characterize their energy efficiency (EE) performance. To gain a comprehensive understanding of the potential of SIM, we consider both dirty paper coding (DPC) and linear precoding and formulate the corresponding EE maximization problems. For DPC, we employ the broadcast channel (BC)-multiple-access channel (MAC) duality to obtain an equivalent problem, and optimize users' covariance matrices using the successive convex approximation (SCA) method, which is based on a tight lower bound of the achievable sum-rate, in combination with Dinkelbach's method. Since optimizing the phase shifts of the SIM meta-elements is an optimization problem of extremely large size, we adopt a conventional projected gradient-based method for its simplicity. A similar approach is derived for the case of linear precoding. Simulation results show that the proposed optimization methods for the considered SIM-based systems can significantly improve the EE, compared to the conventional counterparts. Also, we demonstrate that the number of SIM meta-elements and their distribution across the SIM layers have a significant impact on both the achievable sum-rate and EE performance.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "13 pages, 6 figures"
    },
    {
        "paper id": "2409.00630",
        "abstract url": "https://arxiv.org/abs/2409.00630",
        "title": "LLMs as Evaluators: A Novel Approach to Evaluate Bug Report Summarization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Summarizing software artifacts is an important task that has been thoroughly researched. For evaluating software summarization approaches, human judgment is still the most trusted evaluation. However, it is time-consuming and fatiguing for evaluators, making it challenging to scale and reproduce. Large Language Models (LLMs) have demonstrated remarkable capabilities in various software engineering tasks, motivating us to explore their potential as automatic evaluators for approaches that aim to summarize software artifacts. In this study, we investigate whether LLMs can evaluate bug report summarization effectively. We conducted an experiment in which we presented the same set of bug summarization problems to humans and three LLMs (GPT-4o, LLaMA-3, and Gemini) for evaluation on two tasks: selecting the correct bug report title and bug report summary from a set of options. Our results show that LLMs performed generally well in evaluating bug report summaries, with GPT-4o outperforming the other LLMs. Additionally, both humans and LLMs showed consistent decision-making, but humans experienced fatigue, impacting their accuracy over time. Our results indicate that LLMs demonstrate potential for being considered as automated evaluators for bug report summarization, which could allow scaling up evaluations while reducing human evaluators effort and fatigue.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00631",
        "abstract url": "https://arxiv.org/abs/2409.00631",
        "title": "There is a deep 1-generic set",
        "rating": "-10",
        "keywords": [],
        "abstract": "An infinite binary sequence is Bennett deep if, for any computable time bound, the difference between the time-bounded prefix-free Kolmogorov complexity and the prefix-free Kolmogorov complexity of its initial segments is eventually unbounded. It is known that weakly 2-generic sets are shallow, i.e. not deep. In this paper, we show that there is a deep 1-generic set.",
        "subjects": [
            "math.LO",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00636",
        "abstract url": "https://arxiv.org/abs/2409.00636",
        "title": "A Learnable Agent Collaboration Network Framework for Personalized Multimodal AI Search Engine",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language models (LLMs) and retrieval-augmented generation (RAG) techniques have revolutionized traditional information access, enabling AI agent to search and summarize information on behalf of users during dynamic dialogues. Despite their potential, current AI search engines exhibit considerable room for improvement in several critical areas. These areas include the support for multimodal information, the delivery of personalized responses, the capability to logically answer complex questions, and the facilitation of more flexible interactions. This paper proposes a novel AI Search Engine framework called the Agent Collaboration Network (ACN). The ACN framework consists of multiple specialized agents working collaboratively, each with distinct roles such as Account Manager, Solution Strategist, Information Manager, and Content Creator. This framework integrates mechanisms for picture content understanding, user profile tracking, and online evolution, enhancing the AI search engine's response quality, personalization, and interactivity. A highlight of the ACN is the introduction of a Reflective Forward Optimization method (RFO), which supports the online synergistic adjustment among agents. This feature endows the ACN with online learning capabilities, ensuring that the system has strong interactive flexibility and can promptly adapt to user feedback. This learning method may also serve as an optimization approach for agent-based systems, potentially influencing other domains of agent applications.",
        "subjects": [
            "cs.IR",
            "cs.MA"
        ],
        "comment": "ACMMM 2024 MMGR WORKSHOP"
    },
    {
        "paper id": "2409.00666",
        "abstract url": "https://arxiv.org/abs/2409.00666",
        "title": "Support + Belief = Decision Trust",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present SBTrust, a logical framework designed to formalize decision trust. Our logic integrates a doxastic modality with a novel non-monotonic conditional operator that establishes a positive support relation between statements, and is closely related to a known dyadic deontic modality. For SBTrust, we provide semantics, proof theory and complexity results, as well as motivating examples. Compared to existing approaches, our framework seamlessly accommodates the integration of multiple factors in the emergence of trust.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00671",
        "abstract url": "https://arxiv.org/abs/2409.00671",
        "title": "InvariantStock: Learning Invariant Features for Mastering the Shifting Market",
        "rating": "-10",
        "keywords": [],
        "abstract": "Accurately predicting stock returns is crucial for effective portfolio management. However, existing methods often overlook a fundamental issue in the market, namely, distribution shifts, making them less practical for predicting future markets or newly listed stocks. This study introduces a novel approach to address this challenge by focusing on the acquisition of invariant features across various environments, thereby enhancing robustness against distribution shifts. Specifically, we present InvariantStock, a designed learning framework comprising two key modules: an environment-aware prediction module and an environment-agnostic module. Through the designed learning of these two modules, the proposed method can learn invariant features across different environments in a straightforward manner, significantly improving its ability to handle distribution shifts in diverse market settings. Our results demonstrate that the proposed InvariantStock not only delivers robust and accurate predictions but also outperforms existing baseline methods in both prediction tasks and backtesting within the dynamically changing markets of China and the United States.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00672",
        "abstract url": "https://arxiv.org/abs/2409.00672",
        "title": "Orientable and negative orientable sequences",
        "rating": "-10",
        "keywords": [],
        "abstract": "Analogously to de Bruijn sequences, orientable sequences have application in automatic position-location applications and, until recently, studies of these sequences focused on the binary case. In recent work by Alhakim et al., a range of methods of construction were described for orientable sequences over arbitrary finite alphabets; some of these methods involve using negative orientable sequences as a building block. In this paper we describe three techniques for generating such negative orientable sequences, as well as upper bounds on their period. We then go on to show how these negative orientable sequences can be used to generate orientable sequences with period close to the maximum possible for every non-binary alphabet size and for every tuple length. In doing so we use two closely related approaches described by Alhakim et al.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00676",
        "abstract url": "https://arxiv.org/abs/2409.00676",
        "title": "Fixing Code Generation Errors for Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Code generation leverages artificial intelligence technologies, particularly Large Language Models (LLMs), to automatically produce source code, enhancing software development efficiency and reducing repetitive tasks. However, the LLMs' generated code often fails to pass test cases and requires substantial human effort to fix errors. Previous studies focused on better prompts or improving LLMs' capability but ignored why LLMs failed. In this paper, we first reproduced 14 LLMs, including GPT-3.5-turbo and 13 open-source LLMs, on the HumanEval dataset. We extracted 12,837 code generation errors and conducted an in-depth analysis of their causes, which led to the identification of 19 distinct error causes. Our empirical analysis indicated that three of these causes can be directly fixed. Consequently, we proposed a fixing method called LlmFix, which addresses these three types of errors through a three-step process: filtering code for indentation correction, truncating redundant generated code, and importing missing modules. Experimental results demonstrate that LlmFix can fix these three types of errors, significantly improving the performance of 14 LLMs on HumanEval and MBPP datasets with average increases of 9.5% and 5.4%, respectively.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00688",
        "abstract url": "https://arxiv.org/abs/2409.00688",
        "title": "Universal Finite-State and Self-Stabilizing Computation in Anonymous Dynamic Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "A network is said to be \"anonymous\" if its agents are indistinguishable from each other; it is \"dynamic\" if its communication links may appear or disappear unpredictably over time. Assuming that an anonymous dynamic network is always connected and each of its $n$ agents is initially given an input, it takes $2n$ communication rounds for the agents to compute an arbitrary (frequency-based) function of such inputs (Di Luna-Viglietta, DISC 2023). It is known that, without making additional assumptions on the network and without knowing the number of agents $n$, it is impossible to compute most functions and explicitly terminate. In fact, current state-of-the-art algorithms only achieve stabilization, i.e., allow each agent to return an output after every communication round; outputs can be changed, and are guaranteed to be all correct after $2n$ rounds. Such algorithms rely on the incremental construction of a data structure called \"history tree\", which is augmented at every round. Thus, they end up consuming an unlimited amount of memory, and are also prone to errors in case of memory loss or corruption. In this paper, we provide a general self-stabilizing algorithm for anonymous dynamic networks that stabilizes in $\\max\\{4n-2h, 2h\\}$ rounds (where $h$ measures the amount of corrupted data initially present in the memory of each agent), as well as a general finite-state algorithm that stabilizes in $3n^2$ rounds. Our work improves upon previously known methods that only apply to static networks (Boldi-Vigna, Dist. Comp. 2002). In addition, we develop new fundamental techniques and operations involving history trees, which are of independent interest.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "21 pages, 5 figures"
    },
    {
        "paper id": "2409.00689",
        "abstract url": "https://arxiv.org/abs/2409.00689",
        "title": "AirCompSim: A Discrete Event Simulator for Air Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Air components, including UAVs, planes, balloons, and satellites have been widely utilized since the fixed capacity of ground infrastructure cannot meet the dynamic load of the users. However, since those air components should be coordinated in order to achieve the desired quality of service, several next-generation paradigms have been defined including air computing. Nevertheless, even though many studies and open research issues exist for air computing, there are limited test environments that cannot satisfy the performance evaluation requirements of the dynamic environment. Therefore, in this study, we introduce our discrete event simulator, AirCompSim, which fulfills an air computing environment considering dynamically changing requirements, loads, and capacities through its modular structure. To show its capabilities, a dynamic capacity enhancement scenario is used for investigating the effect of the number of users, UAVs, and requirements of different application types on the average task success rate, service time, and server utilization. The results demonstrate that AirCompSim can be used for experiments in air computing.",
        "subjects": [
            "cs.NI",
            "cs.ET"
        ],
        "comment": "6 pages, 8 figures, 2 tables"
    },
    {
        "paper id": "2409.00737",
        "abstract url": "https://arxiv.org/abs/2409.00737",
        "title": "Data Collectives as a means to Improve Accountability, Combat Surveillance and Reduce Inequalities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Platform-based laborers face unprecedented challenges and working conditions that result from algorithmic opacity, insufficient data transparency, and unclear policies and regulations. The CSCW and HCI communities increasingly turn to worker data collectives as a means to advance related policy and regulation, hold platforms accountable for data transparency and disclosure, and empower the collective worker voice. However, fundamental questions remain for designing, governing and sustaining such data infrastructures. In this workshop, we leverage frameworks such as data feminism to design sustainable and power-aware data collectives that tackle challenges present in various types of online labor platforms (e.g., ridesharing, freelancing, crowdwork, carework). While data collectives aim to support worker collectives and complement relevant policy initiatives, the goal of this workshop is to encourage their designers to consider topics of governance, privacy, trust, and transparency. In this one-day session, we convene research and advocacy community members to reflect on critical platform work issues (e.g., worker surveillance, discrimination, wage theft, insufficient platform accountability) as well as to collaborate on codesigning data collectives that ethically and equitably address these concerns by supporting working collectivism and informing policy development.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00738",
        "abstract url": "https://arxiv.org/abs/2409.00738",
        "title": "Misaligned Over-The-Air Computation of Multi-Sensor Data with Wiener-Denoiser Network",
        "rating": "-10",
        "keywords": [],
        "abstract": "In data driven deep learning, distributed sensing and joint computing bring heavy load for computing and communication. To face the challenge, over-the-air computation (OAC) has been proposed for multi-sensor data aggregation, which enables the server to receive a desired function of massive sensing data during communication. However, the strict synchronization and accurate channel estimation constraints in OAC are hard to be satisfied in practice, leading to time and channel-gain misalignment. The paper formulates the misalignment problem as a non-blind image deblurring problem. At the receiver side, we first use the Wiener filter to deblur, followed by a U-Net network designed for further denoising. Our method is capable to exploit the inherent correlations in the signal data via learning, thus outperforms traditional methods in term of accuracy. Our code is available at https://github.com/auto-Dog/MOAC_deep",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Accepted by PICASSO@MobiCom' 24"
    },
    {
        "paper id": "2409.00739",
        "abstract url": "https://arxiv.org/abs/2409.00739",
        "title": "Designing and Evaluating Scalable Privacy Awareness and Control User Interfaces for Mixed Reality",
        "rating": "-10",
        "keywords": [],
        "abstract": "As Mixed Reality (MR) devices become increasingly popular across industries, they raise significant privacy and ethical concerns due to their capacity to collect extensive data on users and their environments. This paper highlights the urgent need for privacy-aware user interfaces that educate and empower both users and bystanders, enabling them to understand, control, and manage data collection and sharing. Key research questions include improving user awareness of privacy implications, developing usable privacy controls, and evaluating the effectiveness of these measures in real-world settings. The proposed research roadmap aims to embed privacy considerations into the design and development of MR technologies, promoting responsible innovation that safeguards user privacy while preserving the functionality and appeal of these emerging technologies.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Workshop Paper for CHI'24 Shaping The Future: Developing Principles for Policy Recommendations for Responsible Innovation in Virtual Worlds"
    },
    {
        "paper id": "2409.00740",
        "abstract url": "https://arxiv.org/abs/2409.00740",
        "title": "VPVet: Vetting Privacy Policies of Virtual Reality Apps",
        "rating": "-10",
        "keywords": [],
        "abstract": "Virtual reality (VR) apps can harvest a wider range of user data than web/mobile apps running on personal computers or smartphones. Existing law and privacy regulations emphasize that VR developers should inform users of what data are collected/used/shared (CUS) through privacy policies. However, privacy policies in the VR ecosystem are still in their early stages, and many developers fail to write appropriate privacy policies that comply with regulations and meet user expectations. In this paper, we propose VPVet to automatically vet privacy policy compliance issues for VR apps. VPVet first analyzes the availability and completeness of a VR privacy policy and then refines its analysis based on three key criteria: granularity, minimization, and consistency of CUS statements. Our study establishes the first and currently largest VR privacy policy dataset named VRPP, consisting of privacy policies of 11,923 different VR apps from 10 mainstream platforms. Our vetting results reveal severe privacy issues within the VR ecosystem, including the limited availability and poor quality of privacy policies, along with their coarse granularity, lack of adaptation to VR traits and the inconsistency between CUS statements in privacy policies and their actual behaviors. We open-source VPVet system along with our findings at repository https://github.com/kalamoo/PPAudit, aiming to raise awareness within the VR community and pave the way for further research in this field.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages, 13 figures (including subfigures), 13 tables. To appear on ACM CCS 2024"
    },
    {
        "paper id": "2409.00764",
        "abstract url": "https://arxiv.org/abs/2409.00764",
        "title": "tl;dr: Chill, y'all: AI Will Not Devour SE",
        "rating": "-10",
        "keywords": [],
        "abstract": "Social media provide a steady diet of dire warnings that artificial intelligence (AI) will make software engineering (SE) irrelevant or obsolete. To the contrary, the engineering discipline of software is rich and robust; it encompasses the full scope of software design, development, deployment, and practical use; and it has regularly assimilated radical new offerings from AI. Current AI innovations such as machine learning, large language models (LLMs) and generative AI will offer new opportunities to extend the models and methods of SE. They may automate some routine development processes, and they will bring new kinds of components and architectures. If we're fortunate they may force SE to rethink what we mean by correctness and reliability. They will not, however, render SE irrelevant.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "13 pages, accepted at Onward! Essays at SPLASH 2024"
    },
    {
        "paper id": "2409.00771",
        "abstract url": "https://arxiv.org/abs/2409.00771",
        "title": "Scalable Neighborhood Local Search for Single-Machine Scheduling with Family Setup Times",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we study the task of scheduling jobs on a single machine with sequence dependent family setup times under the goal of minimizing the makespan, that is, the completion time of the last job in the schedule. This notoriously NP-hard problem is highly relevant in practical productions and requires heuristics that provide good solutions quickly in order to deal with large instances. In this paper, we present a heuristic based on the approach of parameterized local search. That is, we aim to replace a given solution by a better solution having distance at most $k$ in a pre-defined distance measure. This is done multiple times in a hill-climbing manner, until a locally optimal solution is reached. We analyze the trade-off between the allowed distance $k$ and the algorithm's running time for four natural distance measures. Example of allowed operations for our considered distance measures are: swapping $k$ pairs of jobs in the sequence, or rearranging $k$ consecutive jobs. For two distance measures, we show that finding an improvement for given $k$ can be done in $f(k) \\cdot n^{\\mathcal{O}(1)}$ time, while such a running time for the other two distance measures is unlikely. We provide a preliminary experimental evaluation of our local search approaches.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00794",
        "abstract url": "https://arxiv.org/abs/2409.00794",
        "title": "ExpoSort: Beating the quasi-polynomial-time barrier for reluctant sorting",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce the algorithm ExpoSort, a groundbreaking method that sorts an array of $n$ numbers in a spectacularly inefficient $\u0398(2^n)$ time. ExpoSort proudly claims the title of the first reluctant algorithm to decisively surpass the quasi-polynomial running time $\u03a9(n^{\\log n/(2+\\varepsilon)})$ of the notoriously sluggish SlowSort algorithm by Broder and Stolfi [ACM SIGACT News, 1984]. In the ongoing quest for the slowest possible sort, ExpoSort redefines what it means to take one's time. Remarkably, ExpoSort achieves this feat with one of the simplest pseudocodes among all known sorting algorithms. However, a slight modification -- merely moving one recursive call inside an if statement -- transforms ExpoSort into an astonishingly well-camouflaged variant of the classic InsertionSort with best- and worst-case running times of $\u0398(n)$ and $\u0398(n^3)$, respectively. This dual nature of ExpoSort serves as a reminder of the utmost care required when crafting pessimal algorithms, where a slight lapse in judgment could result in accidentally producing an embarrassingly practical algorithm.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00797",
        "abstract url": "https://arxiv.org/abs/2409.00797",
        "title": "Leveraging parallelizability and channel structure in THz-band, Tbps channel-code decoding",
        "rating": "-10",
        "keywords": [],
        "abstract": "As advancements close the gap between current device capabilities and the requirements for terahertz (THz)-band communications, the demand for terabit-per-second (Tbps) circuits is on the rise. This paper addresses the challenge of achieving Tbps data rates in THz-band communications by focusing on the baseband computation bottleneck. We propose leveraging parallel processing and pseudo-soft information (PSI) across multicarrier THz channels for efficient channel code decoding. We map bits to transmission resources using shorter code-words to enhance parallelizability and reduce complexity. Additionally, we integrate channel state information into PSI to alleviate the processing overhead of soft decoding. Results demonstrate that PSI-aided decoding of 64-bit code-words halves the complexity of 128-bit hard decoding under comparable effective rates, while introducing a 4 dB gain at a $10^{-3}$ block error rate. The proposed scheme approximates soft decoding with significant complexity reduction at a graceful performance cost.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00801",
        "abstract url": "https://arxiv.org/abs/2409.00801",
        "title": "Container Data Item: An Abstract Datatype for Efficient Container-based Edge Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present Container Data Item (CDI), an abstract datatype that allows multiple containers to efficiently operate on a common data item while preserving their strong security and isolation semantics. Application developers can use CDIs to enable multiple containers to operate on the same data, synchronize execution among themselves, and control the ownership of the shared data item during runtime. These containers may reside on the same server or different servers. CDI is designed to support microservice based applications comprised of a set of interconnected microservices, each implemented by a separate dedicated container. CDI preserves the important isolation semantics of containers by ensuring that exactly one container owns a CDI object at any instant and the ownership of a CDI object may be transferred from one container to another only by the current CDI object owner. We present three different implementations of CDI that allow different containers residing on the same server as well containers residing on different servers to use CDI for efficiently operating on a common data item. The paper provides an extensive performance evaluation of CDI along with two representative applications, an augmented reality application and a decentralized workflow orchestrator.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00832",
        "abstract url": "https://arxiv.org/abs/2409.00832",
        "title": "Satisficing Equilibrium",
        "rating": "-10",
        "keywords": [],
        "abstract": "In a $\\textit{satisficing equilibrium}$ each agent plays one of their $k$ best pure actions, but not necessarily their best action. We show that satisficing equilibria in which agents play only their best or second-best action exist in almost all games. In fact, in almost all games, there exist satisficing equilibria in which all but one agent best-respond and the remaining agent plays at least a second-best action. By contrast, more than one third of games possess no pure Nash equilibrium. In addition to providing static foundations for satisficing equilibria, we show that a parsimonious dynamic converges to satisficing equilibria in almost all games. We apply our results to market design and show that a mediator who can control a single agent can enforce stability in most games. Finally, we use our results to study the existence of $\u03b5$-equilibria.",
        "subjects": [
            "econ.TH",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00836",
        "abstract url": "https://arxiv.org/abs/2409.00836",
        "title": "Performance Analysis of Outdoor THz Links under Mixture Gamma Fading with Misalignment",
        "rating": "-10",
        "keywords": [],
        "abstract": "The precision of link-level theoretical performance analysis for emerging wireless communication paradigms is critical. Recent studies have demonstrated the excellent fitting capabilities of the mixture gamma (MG) distribution in representing small-scale fading in outdoor terahertz (THz)-band scenarios. Our study establishes an in-depth performance analysis for outdoor point-to-point THz links under realistic configurations, incorporating MG small-scale fading combined with the misalignment effect. We derive closed-form expressions for the bit-error probability, outage probability, and ergodic capacity. Furthermore, we conduct an asymptotic analysis of these metrics at high signal-to-noise ratios and derive the necessary convergence conditions. Simulation results, leveraging precise measurement-based channel parameters in various configurations, closely align with the derived analytical equations.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00846",
        "abstract url": "https://arxiv.org/abs/2409.00846",
        "title": "Undecidability of Translational Tiling of the 4-dimensional Space with a Set of 4 Polyhypercubes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, Greenfeld and Tao disproof the conjecture that translational tilings of a single tile can always be periodic [Ann. Math. 200(2024), 301-363]. In another paper [to appear in J. Eur. Math. Soc.], they also show that if the dimension $n$ is part of the input, the translational tiling for subsets of $\\mathbb{Z}^n$ with one tile is undecidable. These two results are very strong pieces of evidence for the conjecture that translational tiling of $\\mathbb{Z}^n$ with a monotile is undecidable, for some fixed $n$. This paper shows that translational tiling of the $3$-dimensional space with a set of $5$ polycubes is undecidable. By introducing a technique that lifts a set of polycubes and its tiling from $3$-dimensional space to $4$-dimensional space, we manage to show that translational tiling of the $4$-dimensional space with a set of $4$ tiles is undecidable. This is a step towards the attempt to settle the conjecture of the undecidability of translational tiling of the $n$-dimensional space with a monotile, for some fixed $n$.",
        "subjects": [
            "math.CO",
            "cs.CC",
            "math.MG"
        ],
        "comment": "18 pages, 20 figures"
    },
    {
        "paper id": "2409.00852",
        "abstract url": "https://arxiv.org/abs/2409.00852",
        "title": "Achieving Optimal Short-Blocklength Secrecy Rate Using Multi-Kernel PAC Codes for the Binary Erasure Wiretap Channel",
        "rating": "-10",
        "keywords": [],
        "abstract": "We investigate practical short-blocklength coding for the semi-deterministic binary erasure wiretap channel (BE-WTC), where the main channel to the legitimate receiver is noiseless, and the eavesdropper's channel is a binary erasure channel (BEC). It is shown that under the average total variation distance secrecy metric, multi-kernel polarization-adjusted convolutional (MK-PAC) codes can achieve the best possible theoretical secrecy rate at blocklengths of 16, 32, 64, and 128 if the secrecy leakage is less than or equal to certain values.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Paper accepted for presentation at the 2024 IEEE International Symposium on Information Theory and Its Applications (ISITA 2024)"
    },
    {
        "paper id": "2409.00854",
        "abstract url": "https://arxiv.org/abs/2409.00854",
        "title": "Scaler: Efficient and Effective Cross Flow Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Performance analysis is challenging as different components (e.g.,different libraries, and applications) of a complex system can interact with each other. However, few existing tools focus on understanding such interactions. To bridge this gap, we propose a novel analysis method \"Cross Flow Analysis (XFA)\" that monitors the interactions/flows across these components. We also built the Scaler profiler that provides a holistic view of the time spent on each component (e.g., library or application) and every API inside each component. This paper proposes multiple new techniques, such as Universal Shadow Table, and Relation-Aware Data Folding. These techniques enable Scaler to achieve low runtime overhead, low memory overhead, and high profiling accuracy. Based on our extensive experimental results, Scaler detects multiple unknown performance issues inside widely-used applications, and therefore will be a useful complement to existing work. The reproduction package including the source code, benchmarks, and evaluation scripts, can be found at https://doi.org/10.5281/zenodo.13336658.",
        "subjects": [
            "cs.PF"
        ],
        "comment": "Paper has been accepted by ASE'24"
    },
    {
        "paper id": "2409.00860",
        "abstract url": "https://arxiv.org/abs/2409.00860",
        "title": "A Counterfactual Explanation Framework for Retrieval Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Explainability has become a crucial concern in today's world, aiming to enhance transparency in machine learning and deep learning models. Information retrieval is no exception to this trend. In existing literature on explainability of information retrieval, the emphasis has predominantly been on illustrating the concept of relevance concerning a retrieval model. The questions addressed include why a document is relevant to a query, why one document exhibits higher relevance than another, or why a specific set of documents is deemed relevant for a query. However, limited attention has been given to understanding why a particular document is considered non-relevant to a query with respect to a retrieval model. In an effort to address this gap, our work focus on the question of what terms need to be added within a document to improve its ranking. This in turn answers the question of which words played a role in not being favored by a retrieval model for a particular query. We use an optimization framework to solve the above-mentioned research problem. % To the best of our knowledge, we mark the first attempt to tackle this specific counterfactual problem. Our experiments show the effectiveness of our proposed approach in predicting counterfactuals for both statistical (e.g. BM25) and deep-learning-based models (e.g. DRMM, DSSM, ColBERT).",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00862",
        "abstract url": "https://arxiv.org/abs/2409.00862",
        "title": "User-Driven Value Alignment: Understanding Users' Perceptions and Strategies for Addressing Biased and Discriminatory Statements in AI Companions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language model-based AI companions are increasingly viewed by users as friends or romantic partners, leading to deep emotional bonds. However, they can generate biased, discriminatory, and harmful outputs. Recently, users are taking the initiative to address these harms and re-align AI companions. We introduce the concept of user-driven value alignment, where users actively identify, challenge, and attempt to correct AI outputs they perceive as harmful, aiming to guide the AI to better align with their values. We analyzed 77 social media posts about discriminatory AI statements and conducted semi-structured interviews with 20 experienced users. Our analysis revealed six common types of discriminatory statements perceived by users, how users make sense of those AI behaviors, and seven user-driven alignment strategies, such as gentle persuasion and anger expression. We discuss implications for supporting user-driven value alignment in future AI systems, where users and their communities have greater agency.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "17 pages, 1 figure"
    },
    {
        "paper id": "2409.00875",
        "abstract url": "https://arxiv.org/abs/2409.00875",
        "title": "The Impact of Generative AI-Powered Code Generation Tools on Software Engineer Hiring: Recruiters' Experiences, Perceptions, and Strategies",
        "rating": "-10",
        "keywords": [],
        "abstract": "The rapid advancements in Generative AI (GenAI) tools, such as ChatGPT and GitHub Copilot, are transforming software engineering by automating code generation tasks. While these tools improve developer productivity, they also present challenges for organizations and hiring professionals in evaluating software engineering candidates' true abilities and potential. Although there is existing research on these tools in both industry and academia, there is a lack of research on how these tools specifically affect the hiring process. Therefore, this study aims to explore recruiters' experiences and perceptions regarding GenAI-powered code generation tools, as well as their challenges and strategies for evaluating candidates. Findings from our survey of 32 industry professionals indicate that although most participants are familiar with such tools, the majority of organizations have not adjusted their candidate evaluation methods to account for candidates' use/knowledge of these tools. There are mixed opinions on whether candidates should be allowed to use these tools during interviews, with many participants valuing candidates who can effectively demonstrate their skills in using these tools. Additionally, most participants believe that it is important to incorporate GenAI-powered code generation tools into computer science curricula and mention the key risks and benefits of doing so.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "This paper was accepted for publication at the 58th Hawaii International Conference on System Sciences (HICSS) - Software Technology Track"
    },
    {
        "paper id": "2409.00882",
        "abstract url": "https://arxiv.org/abs/2409.00882",
        "title": "SAFE: Advancing Large Language Models in Leveraging Semantic and Syntactic Relationships for Software Vulnerability Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software vulnerabilities (SVs) have emerged as a prevalent and critical concern for safety-critical security systems. This has spurred significant advancements in utilizing AI-based methods, including machine learning and deep learning, for software vulnerability detection (SVD). While AI-based methods have shown promising performance in SVD, their effectiveness on real-world, complex, and diverse source code datasets remains limited in practice. To tackle this challenge, in this paper, we propose a novel framework that enhances the capability of large language models to learn and utilize semantic and syntactic relationships from source code data for SVD. As a result, our approach can enable the acquisition of fundamental knowledge from source code data while adeptly utilizing crucial relationships, i.e., semantic and syntactic associations, to effectively address the software vulnerability detection (SVD) problem. The rigorous and extensive experimental results on three real-world challenging datasets (i.e., ReVeal, D2A, and Devign) demonstrate the superiority of our approach over the effective and state-of-the-art baselines. In summary, on average, our SAFE approach achieves higher performances from 4.79% to 9.15% for F1-measure and from 16.93% to 21.70% for Recall compared to the baselines across all datasets used.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00890",
        "abstract url": "https://arxiv.org/abs/2409.00890",
        "title": "Towards Investigating Biases in Spoken Conversational Search",
        "rating": "-10",
        "keywords": [],
        "abstract": "Voice-based systems like Amazon Alexa, Google Assistant, and Apple Siri, along with the growing popularity of OpenAI's ChatGPT and Microsoft's Copilot, serve diverse populations, including visually impaired and low-literacy communities. This reflects a shift in user expectations from traditional search to more interactive question-answering models. However, presenting information effectively in voice-only channels remains challenging due to their linear nature. This limitation can impact the presentation of complex queries involving controversial topics with multiple perspectives. Failing to present diverse viewpoints may perpetuate or introduce biases and affect user attitudes. Balancing information load and addressing biases is crucial in designing a fair and effective voice-based system. To address this, we (i) review how biases and user attitude changes have been studied in screen-based web search, (ii) address challenges in studying these changes in voice-based settings like SCS, (iii) outline research questions, and (iv) propose an experimental setup with variables, data, and instruments to explore biases in a voice-based setting like Spoken Conversational Search.",
        "subjects": [
            "cs.HC",
            "cs.IR"
        ],
        "comment": "Accepted Late-Breaking Results at ACM ICMI Companion 2024"
    },
    {
        "paper id": "2409.00905",
        "abstract url": "https://arxiv.org/abs/2409.00905",
        "title": "Throughput Optimization in Cache-aided Networks: An Opportunistic Probing and Scheduling Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper addresses the challenges of throughput optimization in wireless cache-aided cooperative networks. We propose an opportunistic cooperative probing and scheduling strategy for efficient content delivery. The strategy involves the base station probing the relaying channels and cache states of multiple cooperative nodes, thereby enabling opportunistic user scheduling for content delivery. Leveraging the theory of Sequentially Planned Decision (SPD) optimization, we dynamically formulate decisions on cooperative probing and stopping time. Our proposed Reward Expected Thresholds (RET)-based strategy optimizes opportunistic probing and scheduling. This approach significantly enhances system throughput by exploiting gains from local caching, cooperative transmission and time diversity. Simulations confirm the effectiveness and practicality of the proposed Media Access Control (MAC) strategy.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "2024 IEEE GLOBECOM, Cape Town, South Africa"
    },
    {
        "paper id": "2409.00922",
        "abstract url": "https://arxiv.org/abs/2409.00922",
        "title": "ProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Documentation via Large Language Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only \\$8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30\\% of the predicted high-risk option combinations, which was 32.85\\% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2409.00925",
        "abstract url": "https://arxiv.org/abs/2409.00925",
        "title": "Convolutional Beamspace Beamforming for Low-Complexity Far-Field and Near-Field MU-MIMO Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Inter-user interference (IUI) mitigation has been an essential issue for multi-user multiple-input multiple-output (MU-MIMO) communications. The commonly used linear processing schemes include the maximum-ratio combining (MRC), zero-forcing (ZF) and minimum mean squared error (MMSE) beamforming, which may result in the unfavorable performance or complexity as the antenna number grows. In this paper, we introduce a low-complexity linear beamforming solution for the IUI mitigation by using the convolutional beamspace (CBS) technique. Specifically, the dimension of channel matrix can be significantly reduced via the CBS preprocessing, thanks to its beamspace and spatial filtering effects. However, existing methods of the spatial filter design mainly benefit from the Vandermonde structure of channel matrix, which only holds for the far-field scenario with the uniform plane wave (UPW) model. As the antenna size increases, this characteristic may vanish in the near-field region of the array, where the uniform spherical wave (USW) propagation becomes dominant. To gain useful insights, we first investigate the beamforming design and performance analysis of the CBS-based beamforming based on the UPW model. Our results unveil that the proposed CBS-based MMSE beamforming is able to achieve a near-optimal performance but demands remarkably lower complexity than classical ZF and MMSE schemes. Furthermore, our analysis is also extended to the near-field case. To this end, a novel optimization-based CBS approach is proposed for preserving spatial filtering effects, thus rendering the compatibility of the CBS-based beamforming. Finally, numerical results are provided to demonstrate the effectiveness of our proposed CBS-based beamforming method.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00934",
        "abstract url": "https://arxiv.org/abs/2409.00934",
        "title": "New Upper bounds for KL-divergence Based on Integral Norms",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, some new upper bounds for KL-divergence based on $L^1, L^2$ and $L^\\infty$ norms of density functions are discussed. Our findings unveil that the convergence in KL-divergence sense sandwiches between the convergence of density functions in terms of $L^1$ and $L^2$ norms. Furthermore, we endeavor to apply our newly derived upper bounds to the analysis of the rate theorem of the entropic conditional central limit theorem.",
        "subjects": [
            "math.PR",
            "cs.IT"
        ],
        "comment": "23"
    },
    {
        "paper id": "2409.00936",
        "abstract url": "https://arxiv.org/abs/2409.00936",
        "title": "Distributed Optimization under Edge Agreement with Application in Battery Network Management",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates a distributed optimization problem under edge agreements, where each agent in the network is also subject to local convex constraints. Generalized from the concept of consensus, a group of edge agreements represents the constraints defined for neighboring agents, with each pair of neighboring agents required to satisfy one edge agreement constraint. Edge agreements are defined locally to allow more flexibility than a global consensus, enabling heterogeneous coordination within the network. This paper proposes a discrete-time algorithm to solve such problems, providing a theoretical analysis to prove its convergence. Additionally, this paper illustrates the connection between the theory of distributed optimization under edge agreements and distributed model predictive control through a distributed battery network energy management problem. This approach enables a new perspective to formulate and solve network control and optimization problems.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.00941",
        "abstract url": "https://arxiv.org/abs/2409.00941",
        "title": "Frequency-Position-Fluid Antenna Array for Ultra-dense Connectivity in Terahertz Beamforming Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The position-fluid antenna (PFA) architecture has become one of the appealing technologies to support ubiquitous connectivity demand in next-generation wireless systems. Specifically, allowing the antenna to adjust its physical position to one of the predefined ports within a fixed region can introduce additional spatial diversity and improve the signal-to-interference-plus-noise ratio (SINR). In addition, frequency diversity is also widely-explored through frequency interleaving in the terahertz (THz) band. However, the operating bandwidth of one antenna is usually limited to 10% of the central frequency, which imposes a waste of the ultra-broad bandwidth in the THz band. In light of this, a frequency-position-fluid antenna (FPFA) system is proposed in this paper to facilitate ultra-dense connectivity. Specifically, antennas with non-overlapping operating frequency ranges are deployed at the base station (BS) to expand the total available bandwidth and provide frequency domain diversity, while the PFA-enabled users are capable of providing the spatial domain diversity. The channel model is first derived, based on which a channel correlation-based frequency allocation strategy is proposed. Then, a minimum-projection-based port selection algorithm is developed with singular-value-decomposition (SVD) precoders. Simulation results show that the proposed FPFA architecture exhibits steady performance with an increasing number of users, and outperforms the PFA and the fixed-antenna system in ultra-dense user deployment.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    }
]