[
    {
        "paper id": "2409.01821",
        "abstract url": "https://arxiv.org/abs/2409.01821",
        "title": "When Does Visual Prompting Outperform Linear Probing for Vision-Language Models? A Likelihood Perspective",
        "rating": "3",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "Vision-Language"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Adapting pre-trained models to new tasks can exhibit varying effectiveness across datasets. Visual prompting, a state-of-the-art parameter-efficient transfer learning method, can significantly improve the performance of out-of-distribution tasks. On the other hand, linear probing, a standard transfer learning method, can sometimes become the best approach. We propose a log-likelihood ratio (LLR) approach to analyze the comparative benefits of visual prompting and linear probing. By employing the LLR score alongside resource-efficient visual prompts approximations, our cost-effective measure attains up to a 100-fold reduction in run time compared to full training, while achieving prediction accuracies up to $91\\%$. The source code is available at $\\href{https://github.com/IBM/VP-LLR}{\\texttt{VP-LLR}}$.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01883",
        "abstract url": "https://arxiv.org/abs/2409.01883",
        "title": "Boosting Vision-Language Models for Histopathology Classification: Predict all at once",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The development of vision-language models (VLMs) for histo-pathology has shown promising new usages and zero-shot performances. However, current approaches, which decompose large slides into smaller patches, focus solely on inductive classification, i.e., prediction for each patch is made independently of the other patches in the target test data. We extend the capability of these large models by introducing a transductive approach. By using text-based predictions and affinity relationships among patches, our approach leverages the strong zero-shot capabilities of these new VLMs without any additional labels. Our experiments cover four histopathology datasets and five different VLMs. Operating solely in the embedding space (i.e., in a black-box setting), our approach is highly efficient, processing $10^5$ patches in just a few seconds, and shows significant accuracy improvements over inductive zero-shot classification. Code available at https://github.com/FereshteShakeri/Histo-TransCLIP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01658",
        "abstract url": "https://arxiv.org/abs/2409.01658",
        "title": "From Yes-Men to Truth-Tellers: Addressing Sycophancy in Large Language Models with Pinpoint Tuning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Large Language Models (LLMs) tend to prioritize adherence to user prompts over providing veracious responses, leading to the sycophancy issue. When challenged by users, LLMs tend to admit mistakes and provide inaccurate responses even if they initially provided the correct answer. Recent works propose to employ supervised fine-tuning (SFT) to mitigate the sycophancy issue, while it typically leads to the degeneration of LLMs' general capability. To address the challenge, we propose a novel supervised pinpoint tuning (SPT), where the region-of-interest modules are tuned for a given objective. Specifically, SPT first reveals and verifies a small percentage (<5%) of the basic modules, which significantly affect a particular behavior of LLMs. i.e., sycophancy. Subsequently, SPT merely fine-tunes these identified modules while freezing the rest. To verify the effectiveness of the proposed SPT, we conduct comprehensive experiments, demonstrating that SPT significantly mitigates the sycophancy issue of LLMs (even better than SFT). Moreover, SPT introduces limited or even no side effects on the general capability of LLMs. Our results shed light on how to precisely, effectively, and efficiently explain and improve the targeted ability of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ICML 2024"
    },
    {
        "paper id": "2409.01659",
        "abstract url": "https://arxiv.org/abs/2409.01659",
        "title": "Interpreting and Improving Large Language Models in Arithmetic Calculation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated remarkable potential across numerous applications and have shown an emergent ability to tackle complex reasoning tasks, such as mathematical computations. However, even for the simplest arithmetic calculations, the intrinsic mechanisms behind LLMs remain mysterious, making it challenging to ensure reliability. In this work, we delve into uncovering a specific mechanism by which LLMs execute calculations. Through comprehensive experiments, we find that LLMs frequently involve a small fraction (< 5%) of attention heads, which play a pivotal role in focusing on operands and operators during calculation processes. Subsequently, the information from these operands is processed through multi-layer perceptrons (MLPs), progressively leading to the final solution. These pivotal heads/MLPs, though identified on a specific dataset, exhibit transferability across different datasets and even distinct tasks. This insight prompted us to investigate the potential benefits of selectively fine-tuning these essential heads/MLPs to boost the LLMs' computational performance. We empirically find that such precise tuning can yield notable enhancements on mathematical prowess, without compromising the performance on non-mathematical tasks. Our work serves as a preliminary exploration into the arithmetic calculation abilities inherent in LLMs, laying a solid foundation to reveal more intricate mathematical tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ICML 2024 (oral)"
    },
    {
        "paper id": "2409.01686",
        "abstract url": "https://arxiv.org/abs/2409.01686",
        "title": "Frequency-Spatial Entanglement Learning for Camouflaged Object Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Camouflaged object detection has attracted a lot of attention in computer vision. The main challenge lies in the high degree of similarity between camouflaged objects and their surroundings in the spatial domain, making identification difficult. Existing methods attempt to reduce the impact of pixel similarity by maximizing the distinguishing ability of spatial features with complicated design, but often ignore the sensitivity and locality of features in the spatial domain, leading to sub-optimal results. In this paper, we propose a new approach to address this issue by jointly exploring the representation in the frequency and spatial domains, introducing the Frequency-Spatial Entanglement Learning (FSEL) method. This method consists of a series of well-designed Entanglement Transformer Blocks (ETB) for representation learning, a Joint Domain Perception Module for semantic enhancement, and a Dual-domain Reverse Parser for feature integration in the frequency and spatial domains. Specifically, the ETB utilizes frequency self-attention to effectively characterize the relationship between different frequency bands, while the entanglement feed-forward network facilitates information interaction between features of different domains through entanglement learning. Our extensive experiments demonstrate the superiority of our FSEL over 21 state-of-the-art methods, through comprehensive quantitative and qualitative comparisons in three widely-used datasets. The source code is available at: https://github.com/CSYSI/FSEL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ECCV 2024"
    },
    {
        "paper id": "2409.01726",
        "abstract url": "https://arxiv.org/abs/2409.01726",
        "title": "Mahalanobis Distance-based Multi-view Optimal Transport for Multi-view Crowd Localization",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Multi-view crowd localization predicts the ground locations of all people in the scene. Typical methods usually estimate the crowd density maps on the ground plane first, and then obtain the crowd locations. However, the performance of existing methods is limited by the ambiguity of the density maps in crowded areas, where local peaks can be smoothed away. To mitigate the weakness of density map supervision, optimal transport-based point supervision methods have been proposed in the single-image crowd localization tasks, but have not been explored for multi-view crowd localization yet. Thus, in this paper, we propose a novel Mahalanobis distance-based multi-view optimal transport (M-MVOT) loss specifically designed for multi-view crowd localization. First, we replace the Euclidean-based transport cost with the Mahalanobis distance, which defines elliptical iso-contours in the cost function whose long-axis and short-axis directions are guided by the view ray direction. Second, the object-to-camera distance in each view is used to adjust the optimal transport cost of each location further, where the wrong predictions far away from the camera are more heavily penalized. Finally, we propose a strategy to consider all the input camera views in the model loss (M-MVOT) by computing the optimal transport cost for each ground-truth point based on its closest camera. Experiments demonstrate the advantage of the proposed method over density map-based or common Euclidean distance-based optimal transport loss on several multi-view crowd localization datasets. Project page: https://vcc.tech/research/2024/MVOT.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2409.01814",
        "abstract url": "https://arxiv.org/abs/2409.01814",
        "title": "Segmenting Object Affordances: Reproducibility and Sensitivity to Scale",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Visual affordance segmentation identifies image regions of an object an agent can interact with. Existing methods re-use and adapt learning-based architectures for semantic segmentation to the affordance segmentation task and evaluate on small-size datasets. However, experimental setups are often not reproducible, thus leading to unfair and inconsistent comparisons. In this work, we benchmark these methods under a reproducible setup on two single objects scenarios, tabletop without occlusions and hand-held containers, to facilitate future comparisons. We include a version of a recent architecture, Mask2Former, re-trained for affordance segmentation and show that this model is the best-performing on most testing sets of both scenarios. Our analysis shows that models are not robust to scale variations when object resolutions differ from those in the training set.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Paper accepted to Workshop on Assistive Computer Vision and Robotics (ACVR) in European Conference on Computer Vision (ECCV) 2024; 24 pages, 9 figures, 5 tables. Code and trained models are available at https://apicis.github.io/aff-seg/"
    },
    {
        "paper id": "2409.01609",
        "abstract url": "https://arxiv.org/abs/2409.01609",
        "title": "EDCSSM: Edge Detection with Convolutional State Space Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Edge detection in images is the foundation of many complex tasks in computer graphics. Due to the feature loss caused by multi-layer convolution and pooling architectures, learning-based edge detection models often produce thick edges and struggle to detect the edges of small objects in images. Inspired by state space models, this paper presents an edge detection algorithm which effectively addresses the aforementioned issues. The presented algorithm obtains state space variables of the image from dual-input channels with minimal down-sampling processes and utilizes these state variables for real-time learning and memorization of image text. Additionally, to achieve precise edges while filtering out false edges, a post-processing algorithm called wind erosion has been designed to handle the binary edge map. To further enhance the processing speed of the algorithm, we have designed parallel computing circuits for the most computationally intensive parts of presented algorithm, significantly improving computational speed and efficiency. Experimental results demonstrate that the proposed algorithm achieves precise thin edge localization and exhibits noise suppression capabilities across various types of images. With the parallel computing circuits, the algorithm to achieve processing speeds exceeds 30 FPS on 5K images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01610",
        "abstract url": "https://arxiv.org/abs/2409.01610",
        "title": "Decompose the model: Mechanistic interpretability in image models with Generalized Integrated Gradients (GIG)",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In the field of eXplainable AI (XAI) in language models, the progression from local explanations of individual decisions to global explanations with high-level concepts has laid the groundwork for mechanistic interpretability, which aims to decode the exact operations. However, this paradigm has not been adequately explored in image models, where existing methods have primarily focused on class-specific interpretations. This paper introduces a novel approach to systematically trace the entire pathway from input through all intermediate layers to the final output within the whole dataset. We utilize Pointwise Feature Vectors (PFVs) and Effective Receptive Fields (ERFs) to decompose model embeddings into interpretable Concept Vectors. Then, we calculate the relevance between concept vectors with our Generalized Integrated Gradients (GIG), enabling a comprehensive, dataset-wide analysis of model behavior. We validate our method of concept extraction and concept attribution in both qualitative and quantitative evaluations. Our approach advances the understanding of semantic significance within image models, offering a holistic view of their operational mechanics.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01618",
        "abstract url": "https://arxiv.org/abs/2409.01618",
        "title": "High-Precision UWB-Based Real-Time Locating System for Rodent Behavioral Studies in Naturalistic Habitats",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Rodent has proven to be the premier model for behavioral studies. Rats and mice have been raised and maintained in conventional cage environment for investigations. In contrast, the enhanced naturalistic habitat has been demonstrated to be a better setting, especially when behaviors and social interactions are desired. The habitat enables rodents to perform all natural activities with intrinsic phenotypes and importantly, interactions among individuals. The important elements of behavioral studies related to animals is to have precise tracking and collect accurate signals of multiple animals during interactions. Most of the existing approaches use video tracking and thus often face difficulties as rodents are nocturnal and often stay in tunnels underground. Here, we employed the ultra wideband technology to establish a novel tracking method for both overground and underground circumstances. UWB model DWM1001C was used with a custom-made device worn by the animal. A simplified habitat with a size of four-by-two feet was designed to demonstrate the performance of the system. The study evaluated the positioning system accuracy errors below one centimeter for LoS and less than ten centimeters for the NLoS. Generally, this work provides a more accurate and proven experiment to localize the moving object in the indoor building with concrete structures and signal processing data and introduces novel advancement techniques to the use of UWB.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2409.01627",
        "abstract url": "https://arxiv.org/abs/2409.01627",
        "title": "Dynamic Guidance Adversarial Distillation with Enhanced Teacher Knowledge",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of Adversarial Distillation (AD), strategic and precise knowledge transfer from an adversarially robust teacher model to a less robust student model is paramount. Our Dynamic Guidance Adversarial Distillation (DGAD) framework directly tackles the challenge of differential sample importance, with a keen focus on rectifying the teacher model's misclassifications. DGAD employs Misclassification-Aware Partitioning (MAP) to dynamically tailor the distillation focus, optimizing the learning process by steering towards the most reliable teacher predictions. Additionally, our Error-corrective Label Swapping (ELS) corrects misclassifications of the teacher on both clean and adversarially perturbed inputs, refining the quality of knowledge transfer. Further, Predictive Consistency Regularization (PCR) guarantees consistent performance of the student model across both clean and adversarial inputs, significantly enhancing its overall robustness. By integrating these methodologies, DGAD significantly improves upon the accuracy of clean data and fortifies the model's defenses against sophisticated adversarial threats. Our experimental validation on CIFAR10, CIFAR100, and Tiny ImageNet datasets, employing various model architectures, demonstrates the efficacy of DGAD, establishing it as a promising approach for enhancing both the robustness and accuracy of student models in adversarial settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01666",
        "abstract url": "https://arxiv.org/abs/2409.01666",
        "title": "In Defense of RAG in the Era of Long-Context Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Overcoming the limited context limitations in early-generation LLMs, retrieval-augmented generation (RAG) has been a reliable solution for context-based answer generation in the past. Recently, the emergence of long-context LLMs allows the models to incorporate much longer text sequences, making RAG less attractive. Recent studies show that long-context LLMs significantly outperform RAG in long-context applications. Unlike the existing works favoring the long-context LLM over RAG, we argue that the extremely long context in LLMs suffers from a diminished focus on relevant information and leads to potential degradation in answer quality. This paper revisits the RAG in long-context answer generation. We propose an order-preserve retrieval-augmented generation (OP-RAG) mechanism, which significantly improves the performance of RAG for long-context question-answer applications. With OP-RAG, as the number of retrieved chunks increases, the answer quality initially rises, and then declines, forming an inverted U-shaped curve. There exist sweet points where OP-RAG could achieve higher answer quality with much less tokens than long-context LLM taking the whole context as input. Extensive experiments on public benchmark demonstrate the superiority of our OP-RAG.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01667",
        "abstract url": "https://arxiv.org/abs/2409.01667",
        "title": "VProChart: Answering Chart Question through Visual Perception Alignment Agent and Programmatic Solution Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Charts are widely used for data visualization across various fields, including education, research, and business. Chart Question Answering (CQA) is an emerging task focused on the automatic interpretation and reasoning of data presented in charts. However, chart images are inherently difficult to interpret, and chart-related questions often involve complex logical and numerical reasoning, which hinders the performance of existing models. This paper introduces VProChart, a novel framework designed to address these challenges in CQA by integrating a lightweight Visual Perception Alignment Agent (VPAgent) and a Programmatic Solution Reasoning approach. VPAgent aligns and models chart elements based on principles of human visual perception, enhancing the understanding of chart context. The Programmatic Solution Reasoning approach leverages large language models (LLMs) to transform natural language reasoning questions into structured solution programs, facilitating precise numerical and logical reasoning. Extensive experiments on benchmark datasets such as ChartQA and PlotQA demonstrate that VProChart significantly outperforms existing methods, highlighting its capability in understanding and reasoning with charts.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01672",
        "abstract url": "https://arxiv.org/abs/2409.01672",
        "title": "Enhancing Fine-Grained Visual Recognition in the Low-Data Regime Through Feature Magnitude Regularization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Training a fine-grained image recognition model with limited data presents a significant challenge, as the subtle differences between categories may not be easily discernible amidst distracting noise patterns. One commonly employed strategy is to leverage pretrained neural networks, which can generate effective feature representations for constructing an image classification model with a restricted dataset. However, these pretrained neural networks are typically trained for different tasks than the fine-grained visual recognition (FGVR) task at hand, which can lead to the extraction of less relevant features. Moreover, in the context of building FGVR models with limited data, these irrelevant features can dominate the training process, overshadowing more useful, generalizable discriminative features. Our research has identified a surprisingly simple solution to this challenge: we introduce a regularization technique to ensure that the magnitudes of the extracted features are evenly distributed. This regularization is achieved by maximizing the uniformity of feature magnitude distribution, measured through the entropy of the normalized features. The motivation behind this regularization is to remove bias in feature magnitudes from pretrained models, where some features may be more prominent and, consequently, more likely to be used for classification. Additionally, we have developed a dynamic weighting mechanism to adjust the strength of this regularization throughout the learning process. Despite its apparent simplicity, our approach has demonstrated significant performance improvements across various fine-grained visual recognition datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01679",
        "abstract url": "https://arxiv.org/abs/2409.01679",
        "title": "Adaptive Explicit Knowledge Transfer for Knowledge Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Logit-based knowledge distillation (KD) for classification is cost-efficient compared to feature-based KD but often subject to inferior performance. Recently, it was shown that the performance of logit-based KD can be improved by effectively delivering the probability distribution for the non-target classes from the teacher model, which is known as `implicit (dark) knowledge', to the student model. Through gradient analysis, we first show that this actually has an effect of adaptively controlling the learning of implicit knowledge. Then, we propose a new loss that enables the student to learn explicit knowledge (i.e., the teacher's confidence about the target class) along with implicit knowledge in an adaptive manner. Furthermore, we propose to separate the classification and distillation tasks for effective distillation and inter-class relationship modeling. Experimental results demonstrate that the proposed method, called adaptive explicit knowledge transfer (AEKT) method, achieves improved performance compared to the state-of-the-art KD methods on the CIFAR-100 and ImageNet datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "19 pages, 5 figures"
    },
    {
        "paper id": "2409.01728",
        "abstract url": "https://arxiv.org/abs/2409.01728",
        "title": "Shuffle Mamba: State Space Models with Random Shuffle for Multi-Modal Image Fusion",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal image fusion integrates complementary information from different modalities to produce enhanced and informative images. Although State-Space Models, such as Mamba, are proficient in long-range modeling with linear complexity, most Mamba-based approaches use fixed scanning strategies, which can introduce biased prior information. To mitigate this issue, we propose a novel Bayesian-inspired scanning strategy called Random Shuffle, supplemented by an theoretically-feasible inverse shuffle to maintain information coordination invariance, aiming to eliminate biases associated with fixed sequence scanning. Based on this transformation pair, we customized the Shuffle Mamba Framework, penetrating modality-aware information representation and cross-modality information interaction across spatial and channel axes to ensure robust interaction and an unbiased global receptive field for multi-modal image fusion. Furthermore, we develop a testing methodology based on Monte-Carlo averaging to ensure the model's output aligns more closely with expected results. Extensive experiments across multiple multi-modal image fusion tasks demonstrate the effectiveness of our proposed method, yielding excellent fusion quality over state-of-the-art alternatives. Code will be available upon acceptance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01749",
        "abstract url": "https://arxiv.org/abs/2409.01749",
        "title": "QPOPSS: Query and Parallelism Optimized Space-Saving for Finding Frequent Stream Elements",
        "rating": "1",
        "keywords": [
            [
                "memory-efficient"
            ]
        ],
        "abstract": "The frequent elements problem, a key component in demanding stream-data analytics, involves selecting elements whose occurrence exceeds a user-specified threshold. Fast, memory-efficient $\u03b5$-approximate synopsis algorithms select all frequent elements but may overestimate them depending on $\u03b5$ (user-defined parameter). Evolving applications demand performance only achievable by parallelization. However, algorithmic guarantees concerning concurrent updates and queries have been overlooked. We propose Query and Parallelism Optimized Space-Saving (QPOPSS), providing concurrency guarantees. The design includes an implementation of the \\emph{Space-Saving} algorithm supporting fast queries, implying minimal overlap with concurrent updates. QPOPSS integrates this with the distribution of work and fine-grained synchronization among threads, swiftly balancing high throughput, high accuracy, and low memory consumption. Our analysis, under various concurrency and data distribution conditions, shows space and approximation bounds. Our empirical evaluation relative to representative state-of-the-art methods reveals that QPOPSS's multi-threaded throughput scales linearly while maintaining the highest accuracy, with orders of magnitude smaller memory footprint.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01754",
        "abstract url": "https://arxiv.org/abs/2409.01754",
        "title": "Empirical evidence of Large Language Model's influence on human spoken communication",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) agents now interact with billions of humans in natural language, thanks to advances in Large Language Models (LLMs) like ChatGPT. This raises the question of whether AI has the potential to shape a fundamental aspect of human culture: the way we speak. Recent analyses revealed that scientific publications already exhibit evidence of AI-specific language. But this evidence is inconclusive, since scientists may simply be using AI to copy-edit their writing. To explore whether AI has influenced human spoken communication, we transcribed and analyzed about 280,000 English-language videos of presentations, talks, and speeches from more than 20,000 YouTube channels of academic institutions. We find a significant shift in the trend of word usage specific to words distinctively associated with ChatGPT following its release. These findings provide the first empirical evidence that humans increasingly imitate LLMs in their spoken language. Our results raise societal and policy-relevant concerns about the potential of AI to unintentionally reduce linguistic diversity, or to be deliberately misused for mass manipulation. They also highlight the need for further investigation into the feedback loops between machine behavior and human culture.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.CL",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01763",
        "abstract url": "https://arxiv.org/abs/2409.01763",
        "title": "FC-KAN: Function Combinations in Kolmogorov-Arnold Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we introduce FC-KAN, a Kolmogorov-Arnold Network (KAN) that leverages combinations of popular mathematical functions such as B-splines, wavelets, and radial basis functions on low-dimensional data through element-wise operations. We explore several methods for combining the outputs of these functions, including sum, element-wise product, the addition of sum and element-wise product, quadratic function representation, and concatenation. In our experiments, we compare FC-KAN with multi-layer perceptron network (MLP) and other existing KANs, such as BSRBF-KAN, EfficientKAN, FastKAN, and FasterKAN, on the MNIST and Fashion-MNIST datasets. A variant of FC-KAN, which uses a combination of outputs from B-splines and Difference of Gaussians (DoG) in the form of a quadratic function, outperformed all other models on the average of 5 independent training runs. We expect that FC-KAN can leverage function combinations to design future KANs. Our repository is publicly available at: https://github.com/hoangthangta/FC_KAN.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "9 pages, 1 figure"
    },
    {
        "paper id": "2409.01776",
        "abstract url": "https://arxiv.org/abs/2409.01776",
        "title": "Steered Response Power-Based Direction-of-Arrival Estimation Exploiting an Auxiliary Microphone",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Accurately estimating the direction-of-arrival (DOA) of a speech source using a compact microphone array (CMA) is often complicated by background noise and reverberation. A commonly used DOA estimation method is the steered response power with phase transform (SRP-PHAT) function, which has been shown to work reliably in moderate levels of noise and reverberation. Since for closely spaced microphones the spatial coherence of noise and reverberation may be high over an extended frequency range, this may negatively affect the SRP-PHAT spectra, resulting in DOA estimation errors. Assuming the availability of an auxiliary microphone at an unknown position which is spatially separated from the CMA, in this paper we propose to compute the SRP-PHAT spectra between the microphones of the CMA based on the SRP-PHAT spectra between the auxiliary microphone and the microphones of the CMA. For different levels of noise and reverberation, we show how far the auxiliary microphone needs to be spatially separated from the CMA for the auxiliary microphone-based SRP-PHAT spectra to be more reliable than the SRP-PHAT spectra without the auxiliary microphone. These findings are validated based on simulated microphone signals for several auxiliary microphone positions and two different noise and reverberation conditions.",
        "subjects": [
            "eess.AS",
            "cs.SD",
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures, conference: EUSIPCO 2024 in Lyon"
    },
    {
        "paper id": "2409.01780",
        "abstract url": "https://arxiv.org/abs/2409.01780",
        "title": "State-of-the-art Advances of Deep-learning Linguistic Steganalysis Research",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the evolution of generative linguistic steganography techniques, conventional steganalysis falls short in robustly quantifying the alterations induced by steganography, thereby complicating detection. Consequently, the research paradigm has pivoted towards deep-learning-based linguistic steganalysis. This study offers a comprehensive review of existing contributions and evaluates prevailing developmental trajectories. Specifically, we first provided a formalized exposition of the general formulas for linguistic steganalysis, while comparing the differences between this field and the domain of text classification. Subsequently, we classified the existing work into two levels based on vector space mapping and feature extraction models, thereby comparing the research motivations, model advantages, and other details. A comparative analysis of the experiments is conducted to assess the performances. Finally, the challenges faced by this field are discussed, and several directions for future development and key issues that urgently need to be addressed are proposed.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by 2023 International Conference on Data, Information and Computing Science"
    },
    {
        "paper id": "2409.01794",
        "abstract url": "https://arxiv.org/abs/2409.01794",
        "title": "Estimating Joint interventional distributions from marginal interventional data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In this paper we show how to exploit interventional data to acquire the joint conditional distribution of all the variables using the Maximum Entropy principle. To this end, we extend the Causal Maximum Entropy method to make use of interventional data in addition to observational data. Using Lagrange duality, we prove that the solution to the Causal Maximum Entropy problem with interventional constraints lies in the exponential family, as in the Maximum Entropy solution. Our method allows us to perform two tasks of interest when marginal interventional distributions are provided for any subset of the variables. First, we show how to perform causal feature selection from a mixture of observational and single-variable interventional data, and, second, how to infer joint interventional distributions. For the former task, we show on synthetically generated data, that our proposed method outperforms the state-of-the-art method on merging datasets, and yields comparable results to the KCI-test which requires access to joint observations of all variables.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Duality Principles for Modern Machine Learning workshop at ICML 2023, 2nd and 3rd author equal contribution"
    },
    {
        "paper id": "2409.01806",
        "abstract url": "https://arxiv.org/abs/2409.01806",
        "title": "LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI Planning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Effective planning is essential for the success of any task, from organizing a vacation to routing autonomous vehicles and developing corporate strategies. It involves setting goals, formulating plans, and allocating resources to achieve them. LLMs are particularly well-suited for automated planning due to their strong capabilities in commonsense reasoning. They can deduce a sequence of actions needed to achieve a goal from a given state and identify an effective course of action. However, it is frequently observed that plans generated through direct prompting often fail upon execution. Our survey aims to highlight the existing challenges in planning with language models, focusing on key areas such as embodied environments, optimal scheduling, competitive and cooperative games, task decomposition, reasoning, and planning. Through this study, we explore how LLMs transform AI planning and provide unique insights into the future of LM-assisted planning.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01808",
        "abstract url": "https://arxiv.org/abs/2409.01808",
        "title": "Dialogue You Can Trust: Human and AI Perspectives on Generated Conversations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "As dialogue systems and chatbots increasingly integrate into everyday interactions, the need for efficient and accurate evaluation methods becomes paramount. This study explores the comparative performance of human and AI assessments across a range of dialogue scenarios, focusing on seven key performance indicators (KPIs): Coherence, Innovation, Concreteness, Goal Contribution, Commonsense Contradiction, Incorrect Fact, and Redundancy. Utilizing the GPT-4o API, we generated a diverse dataset of conversations and conducted a two-part experimental analysis. In Experiment 1, we evaluated multi-party conversations on Coherence, Innovation, Concreteness, and Goal Contribution, revealing that GPT models align closely with human judgments. Notably, both human and AI evaluators exhibited a tendency towards binary judgment rather than linear scaling, highlighting a shared challenge in these assessments. Experiment 2 extended the work of Finch et al. (2023) by focusing on dyadic dialogues and assessing Commonsense Contradiction, Incorrect Fact, and Redundancy. The results indicate that while GPT-4o demonstrates strong performance in maintaining factual accuracy and commonsense reasoning, it still struggles with reducing redundancy and self-contradiction. Our findings underscore the potential of GPT models to closely replicate human evaluation in dialogue systems, while also pointing to areas for improvement. This research offers valuable insights for advancing the development and implementation of more refined dialogue evaluation methodologies, contributing to the evolution of more effective and human-like AI communication tools.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "17 pages, 15 figures, shorter version submitted to 22nd Annual Workshop of the Australasian Language Technology Association (ALTA'24)"
    },
    {
        "paper id": "2409.01835",
        "abstract url": "https://arxiv.org/abs/2409.01835",
        "title": "Towards Generative Class Prompt Learning for Few-shot Visual Recognition",
        "rating": "1",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "diffusion",
                "text-to-image"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Although foundational vision-language models (VLMs) have proven to be very successful for various semantic discrimination tasks, they still struggle to perform faithfully for fine-grained categorization. Moreover, foundational models trained on one domain do not generalize well on a different domain without fine-tuning. We attribute these to the limitations of the VLM's semantic representations and attempt to improve their fine-grained visual awareness using generative modeling. Specifically, we propose two novel methods: Generative Class Prompt Learning (GCPL) and Contrastive Multi-class Prompt Learning (CoMPLe). Utilizing text-to-image diffusion models, GCPL significantly improves the visio-linguistic synergy in class embeddings by conditioning on few-shot exemplars with learnable class prompts. CoMPLe builds on this foundation by introducing a contrastive learning component that encourages inter-class separation during the generative optimization process. Our empirical results demonstrate that such a generative class prompt learning approach substantially outperform existing methods, offering a better alternative to few shot image recognition challenges. The source code will be made available at: https://github.com/soumitri2001/GCPL.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Accepted at BMVC 2024"
    },
    {
        "paper id": "2409.01854",
        "abstract url": "https://arxiv.org/abs/2409.01854",
        "title": "AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The relation extraction (RE) in complex scenarios faces challenges such as diverse relation types and ambiguous relations between entities within a single sentence, leading to the poor performance of pure \"text-in, text-out\" language models (LMs). To address these challenges, in this paper, we propose an agent-based RE framework, namely AgentRE, which fully leverages the potential of large language models (LLMs) including memory, retrieval and reflection, to achieve RE in complex scenarios. Specifically, three major modules are built in AgentRE serving as the tools to help the agent acquire and process various useful information, thereby obtaining improved RE performance. Our extensive experimental results upon two datasets in English and Chinese demonstrate our AgentRE's superior performance, especially in low-resource scenarios. Additionally, the trajectories generated by AgentRE can be refined to construct a high-quality training dataset incorporating different reasoning methods, which can be used to fine-tune smaller models. Code is available at https://github.com/Lightblues/AgentRE.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by CIKM 2024"
    },
    {
        "paper id": "2409.01871",
        "abstract url": "https://arxiv.org/abs/2409.01871",
        "title": "Real-Time Indoor Object Detection based on hybrid CNN-Transformer Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Real-time object detection in indoor settings is a challenging area of computer vision, faced with unique obstacles such as variable lighting and complex backgrounds. This field holds significant potential to revolutionize applications like augmented and mixed realities by enabling more seamless interactions between digital content and the physical world. However, the scarcity of research specifically fitted to the intricacies of indoor environments has highlighted a clear gap in the literature. To address this, our study delves into the evaluation of existing datasets and computational models, leading to the creation of a refined dataset. This new dataset is derived from OpenImages v7, focusing exclusively on 32 indoor categories selected for their relevance to real-world applications. Alongside this, we present an adaptation of a CNN detection model, incorporating an attention mechanism to enhance the model's ability to discern and prioritize critical features within cluttered indoor scenes. Our findings demonstrate that this approach is not just competitive with existing state-of-the-art models in accuracy and speed but also opens new avenues for research and application in the field of real-time indoor object detection.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01882",
        "abstract url": "https://arxiv.org/abs/2409.01882",
        "title": "Investigating Expert-in-the-Loop LLM Discourse Patterns for Ancient Intertextual Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study explores the potential of large language models (LLMs) for identifying and examining intertextual relationships within biblical, Koine Greek texts. By evaluating the performance of LLMs on various intertextuality scenarios the study demonstrates that these models can detect direct quotations, allusions, and echoes between texts. The LLM's ability to generate novel intertextual observations and connections highlights its potential to uncover new insights. However, the model also struggles with long query passages and the inclusion of false intertextual dependences, emphasizing the importance of expert evaluation. The expert-in-the-loop methodology presented offers a scalable approach for intertextual research into the complex web of intertextuality within and beyond the biblical corpus.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01890",
        "abstract url": "https://arxiv.org/abs/2409.01890",
        "title": "A Fresh Take on Stale Embeddings: Improving Dense Retriever Training with Corrector Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In dense retrieval, deep encoders provide embeddings for both inputs and targets, and the softmax function is used to parameterize a distribution over a large number of candidate targets (e.g., textual passages for information retrieval). Significant challenges arise in training such encoders in the increasingly prevalent scenario of (1) a large number of targets, (2) a computationally expensive target encoder model, (3) cached target embeddings that are out-of-date due to ongoing training of target encoder parameters. This paper presents a simple and highly scalable response to these challenges by training a small parametric corrector network that adjusts stale cached target embeddings, enabling an accurate softmax approximation and thereby sampling of up-to-date high scoring \"hard negatives.\" We theoretically investigate the generalization properties of our proposed target corrector, relating the complexity of the network, staleness of cached representations, and the amount of training data. We present experimental results on large benchmark dense retrieval datasets as well as on QA with retrieval augmented language models. Our approach matches state-of-the-art results even when no target embedding updates are made during training beyond an initial cache from the unsupervised pre-trained model, providing a 4-80x reduction in re-embedding computational cost.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2409.01893",
        "abstract url": "https://arxiv.org/abs/2409.01893",
        "title": "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) with extended context windows have significantly improved tasks such as information extraction, question answering, and complex planning scenarios. In order to achieve success in long context tasks, a large amount of work has been done to enhance the long context capabilities of the model through synthetic data. Existing methods typically utilize the Self-Instruct framework to generate instruction tuning data for better long context capability improvement. However, our preliminary experiments indicate that less than 35% of generated samples are multi-hop, and more than 40% exhibit poor quality, limiting comprehensive understanding and further research. To improve the quality of synthetic data, we propose the Multi-agent Interactive Multi-hop Generation (MIMG) framework, incorporating a Quality Verification Agent, a Single-hop Question Generation Agent, a Multiple Question Sampling Strategy, and a Multi-hop Question Merger Agent. This framework improves the data quality, with the proportion of high-quality, multi-hop, and diverse data exceeding 85%. Furthermore, we systematically investigate strategies for document selection, question merging, and validation techniques through extensive experiments across various models. Our findings show that our synthetic high-quality long-context instruction data significantly enhances model performance, even surpassing models trained on larger amounts of human-annotated data. Our code is available at: https://github.com/WowCZ/LongMIT.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2409.02020",
        "abstract url": "https://arxiv.org/abs/2409.02020",
        "title": "Efficient Point Cloud Classification via Offline Distillation Framework and Negative-Weight Self-Distillation Technique",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement in point cloud processing technologies has significantly increased the demand for efficient and compact models that achieve high-accuracy classification. Knowledge distillation has emerged as a potent model compression technique. However, traditional KD often requires extensive computational resources for forward inference of large teacher models, thereby reducing training efficiency for student models and increasing resource demands. To address these challenges, we introduce an innovative offline recording strategy that avoids the simultaneous loading of both teacher and student models, thereby reducing hardware demands. This approach feeds a multitude of augmented samples into the teacher model, recording both the data augmentation parameters and the corresponding logit outputs. By applying shape-level augmentation operations such as random scaling and translation, while excluding point-level operations like random jittering, the size of the records is significantly reduced. Additionally, to mitigate the issue of small student model over-imitating the teacher model's outputs and converging to suboptimal solutions, we incorporate a negative-weight self-distillation strategy. Experimental results demonstrate that the proposed distillation strategy enables the student model to achieve performance comparable to state-of-the-art models while maintaining lower parameter count. This approach strikes an optimal balance between performance and complexity. This study highlights the potential of our method to optimize knowledge distillation for point cloud classification tasks, particularly in resource-constrained environments, providing a novel solution for efficient point cloud analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02026",
        "abstract url": "https://arxiv.org/abs/2409.02026",
        "title": "Foundations of Large Language Model Compression -- Part 1: Weight Quantization",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, compression of large language models (LLMs) has emerged as an important problem to allow language model deployment on resource-constrained devices, reduce computational costs, and mitigate the environmental footprint of large-scale AI infrastructure. In this paper, we present the foundations of LLM quantization from a convex optimization perspective and propose a quantization method that builds on these foundations and outperforms previous methods. Our quantization framework, CVXQ, scales to models containing hundreds of billions of weight parameters and provides users with the flexibility to compress models to any specified model size, post-training. A reference implementation of CVXQ can be obtained from https://github.com/seannz/cvxq.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2409.02041",
        "abstract url": "https://arxiv.org/abs/2409.02041",
        "title": "The USTC-NERCSLIP Systems for the CHiME-8 NOTSOFAR-1 Challenge",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This technical report outlines our submission system for the CHiME-8 NOTSOFAR-1 Challenge. The primary difficulty of this challenge is the dataset recorded across various conference rooms, which captures real-world complexities such as high overlap rates, background noises, a variable number of speakers, and natural conversation styles. To address these issues, we optimized the system in several aspects: For front-end speech signal processing, we introduced a data-driven joint training method for diarization and separation (JDS) to enhance audio quality. Additionally, we also integrated traditional guided source separation (GSS) for multi-channel track to provide complementary information for the JDS. For back-end speech recognition, we enhanced Whisper with WavLM, ConvNeXt, and Transformer innovations, applying multi-task training and Noise KLD augmentation, to significantly advance ASR robustness and accuracy. Our system attained a Time-Constrained minimum Permutation Word Error Rate (tcpWER) of 14.265% and 22.989% on the CHiME-8 NOTSOFAR-1 Dev-set-2 multi-channel and single-channel tracks, respectively.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02049",
        "abstract url": "https://arxiv.org/abs/2409.02049",
        "title": "Low-Resolution Face Recognition via Adaptable Instance-Relation Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Low-resolution face recognition is a challenging task due to the missing of informative details. Recent approaches based on knowledge distillation have proven that high-resolution clues can well guide low-resolution face recognition via proper knowledge transfer. However, due to the distribution difference between training and testing faces, the learned models often suffer from poor adaptability. To address that, we split the knowledge transfer process into distillation and adaptation steps, and propose an adaptable instance-relation distillation approach to facilitate low-resolution face recognition. In the approach, the student distills knowledge from high-resolution teacher in both instance level and relation level, providing sufficient cross-resolution knowledge transfer. Then, the learned student can be adaptable to recognize low-resolution faces with adaptive batch normalization in inference. In this manner, the capability of recovering missing details of familiar low-resolution faces can be effectively enhanced, leading to a better knowledge transfer. Extensive experiments on low-resolution face recognition clearly demonstrate the effectiveness and adaptability of our approach.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "comment": "Accepted by IJCNN 2024"
    },
    {
        "paper id": "2409.02050",
        "abstract url": "https://arxiv.org/abs/2409.02050",
        "title": "Enhancing Code-Switching Speech Recognition with LID-Based Collaborative Mixture of Experts Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Due to the inherent difficulty in modeling phonetic similarities across different languages, code-switching speech recognition presents a formidable challenge. This study proposes a Collaborative-MoE, a Mixture of Experts (MoE) model that leverages a collaborative mechanism among expert groups. Initially, a preceding routing network explicitly learns Language Identification (LID) tasks and selects experts based on acquired LID weights. This process ensures robust routing information to the MoE layer, mitigating interference from diverse language domains on expert network parameter updates. The LID weights are also employed to facilitate inter-group collaboration, enabling the integration of language-specific representations. Furthermore, within each language expert group, a gating network operates unsupervised to foster collaboration on attributes beyond language. Extensive experiments demonstrate the efficacy of our approach, achieving significant performance enhancements compared to alternative methods. Importantly, our method preserves the efficient inference capabilities characteristic of MoE models without necessitating additional pre-training.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted to IEEE SLT 2024"
    },
    {
        "paper id": "2409.02060",
        "abstract url": "https://arxiv.org/abs/2409.02060",
        "title": "OLMoE: Open Mixture-of-Experts Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce OLMoE, a fully open, state-of-the-art language model leveraging sparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but uses only 1B per input token. We pretrain it on 5 trillion tokens and further adapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available models with similar active parameters, even surpassing larger ones like Llama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE training, analyze routing in our model showing high specialization, and open-source all aspects of our work: model weights, training data, code, and logs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "61 pages (24 main), 36 figures, 14 tables"
    },
    {
        "paper id": "2409.02076",
        "abstract url": "https://arxiv.org/abs/2409.02076",
        "title": "Spinning the Golden Thread: Benchmarking Long-Form Generation in Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The abilities of long-context language models (LMs) are often evaluated using the \"Needle-in-a-Haystack\" (NIAH) test, which comprises tasks designed to assess a model's ability to identify specific information (\"needle\") within large text sequences (\"haystack\"). While these benchmarks measure how well models understand long-context input sequences, they do not effectively gauge the quality of long-form text generation--a critical aspect for applications such as design proposals and creative writing. To address this gap, we have introduced a new long-form text evaluation benchmark, Spinning the Golden Thread (SGT), which tests models' ability to identify specific events within generated long text sequences. In this benchmark, we prompt long-context LMs to create long-form text that must include particular events or constraints and evaluate their ability to incorporate these elements. We evaluated ten long-context LMs across four distinct scenarios, three types of prompt instructions, and two different generation-length settings (16K and 32K). Although these models perform well on NIAH benchmarks, none demonstrated satisfactory performance on the Spinning the Golden Thread, raising concerns about their ability to generate coherent long-form text that follows instructions. Additionally, as the length of the generated text increases, all models exhibit a significant drop in performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02078",
        "abstract url": "https://arxiv.org/abs/2409.02078",
        "title": "Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for Political Text",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Social scientists quickly adopted large language models due to their ability to annotate documents without supervised training, an ability known as zero-shot learning. However, due to their compute demands, cost, and often proprietary nature, these models are often at odds with replication and open science standards. This paper introduces the Political DEBATE (DeBERTa Algorithm for Textual Entailment) language models for zero-shot and few-shot classification of political documents. These models are not only as good, or better than, state-of-the art large language models at zero and few-shot classification, but are orders of magnitude more efficient and completely open source. By training the models on a simple random sample of 10-25 documents, they can outperform supervised classifiers trained on hundreds or thousands of documents and state-of-the-art generative models with complex, engineered prompts. Additionally, we release the PolNLI dataset used to train these models -- a corpus of over 200,000 political documents with highly accurate labels across over 800 classification tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "26 pages, 5 figures"
    },
    {
        "paper id": "2409.01612",
        "abstract url": "https://arxiv.org/abs/2409.01612",
        "title": "Lexicographic optimization-based approaches to learning a representative model for multi-criteria sorting with non-monotonic criteria",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deriving a representative model using value function-based methods from the perspective of preference disaggregation has emerged as a prominent and growing topic in multi-criteria sorting (MCS) problems. A noteworthy observation is that many existing approaches to learning a representative model for MCS problems traditionally assume the monotonicity of criteria, which may not always align with the complexities found in real-world MCS scenarios. Consequently, this paper proposes some approaches to learning a representative model for MCS problems with non-monotonic criteria through the integration of the threshold-based value-driven sorting procedure. To do so, we first define some transformation functions to map the marginal values and category thresholds into a UTA-like functional space. Subsequently, we construct constraint sets to model non-monotonic criteria in MCS problems and develop optimization models to check and rectify the inconsistency of the decision maker's assignment example preference information. By simultaneously considering the complexity and discriminative power of the models, two distinct lexicographic optimization-based approaches are developed to derive a representative model for MCS problems with non-monotonic criteria. Eventually, we offer an illustrative example and conduct comprehensive simulation experiments to elaborate the feasibility and validity of the proposed approaches.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "45 pages, 12 figures"
    },
    {
        "paper id": "2409.01614",
        "abstract url": "https://arxiv.org/abs/2409.01614",
        "title": "On-chain Validation of Tracking Data Messages (TDM) Using Distributed Deep Learning on a Proof of Stake (PoS) Blockchain",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Trustless tracking of Resident Space Objects (RSOs) is crucial for Space Situational Awareness (SSA), especially during adverse situations. The importance of transparent SSA cannot be overstated, as it is vital for ensuring space safety and security. In an era where RSO location information can be easily manipulated, the risk of RSOs being used as weapons is a growing concern. The Tracking Data Message (TDM) is a standardized format for broadcasting RSO observations. However, the varying quality of observations from diverse sensors poses challenges to SSA reliability. While many countries operate space assets, relatively few have SSA capabilities, making it crucial to ensure the accuracy and reliability of the data. Current practices assume complete trust in the transmitting party, leaving SSA capabilities vulnerable to adversarial actions such as spoofing TDMs. This work introduces a trustless mechanism for TDM validation and verification using deep learning over blockchain. By leveraging the trustless nature of blockchain, our approach eliminates the need for a central authority, establishing consensus-based truth. We propose a state-of-the-art, transformer-based orbit propagator that outperforms traditional methods like SGP4, enabling cross-validation of multiple observations for a single RSO. This deep learning-based transformer model can be distributed over a blockchain, allowing interested parties to host a node that contains a part of the distributed deep learning model. Our system comprises decentralised observers and validators within a Proof of Stake (PoS) blockchain. Observers contribute TDM data along with a stake to ensure honesty, while validators run the propagation and validation algorithms. The system rewards observers for contributing verified TDMs and penalizes those submitting unverifiable data.",
        "subjects": [
            "cs.CR",
            "astro-ph.EP",
            "cs.LG"
        ],
        "comment": "Accepted for AMOS 2024"
    },
    {
        "paper id": "2409.01633",
        "abstract url": "https://arxiv.org/abs/2409.01633",
        "title": "Dreaming is All You Need",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In classification tasks, achieving a harmonious balance between exploration and precision is of paramount importance. To this end, this research introduces two novel deep learning models, SleepNet and DreamNet, to strike this balance. SleepNet seamlessly integrates supervised learning with unsupervised ``sleep\" stages using pre-trained encoder models. Dedicated neurons within SleepNet are embedded in these unsupervised features, forming intermittent ``sleep\" blocks that facilitate exploratory learning. Building upon the foundation of SleepNet, DreamNet employs full encoder-decoder frameworks to reconstruct the hidden states, mimicking the human \"dreaming\" process. This reconstruction process enables further exploration and refinement of the learned representations. Moreover, the principle ideas of our SleepNet and DreamNet are generic and can be applied to both computer vision and natural language processing downstream tasks. Through extensive empirical evaluations on diverse image and text datasets, SleepNet and DreanNet have demonstrated superior performance compared to state-of-the-art models, showcasing the strengths of unsupervised exploration and supervised precision afforded by our innovative approaches.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01687",
        "abstract url": "https://arxiv.org/abs/2409.01687",
        "title": "A sparse PAC-Bayesian approach for high-dimensional quantile prediction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantile regression, a robust method for estimating conditional quantiles, has advanced significantly in fields such as econometrics, statistics, and machine learning. In high-dimensional settings, where the number of covariates exceeds sample size, penalized methods like lasso have been developed to address sparsity challenges. Bayesian methods, initially connected to quantile regression via the asymmetric Laplace likelihood, have also evolved, though issues with posterior variance have led to new approaches, including pseudo/score likelihoods. This paper presents a novel probabilistic machine learning approach for high-dimensional quantile prediction. It uses a pseudo-Bayesian framework with a scaled Student-t prior and Langevin Monte Carlo for efficient computation. The method demonstrates strong theoretical guarantees, through PAC-Bayes bounds, that establish non-asymptotic oracle inequalities, showing minimax-optimal prediction error and adaptability to unknown sparsity. Its effectiveness is validated through simulations and real-world data, where it performs competitively against established frequentist and Bayesian techniques.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01688",
        "abstract url": "https://arxiv.org/abs/2409.01688",
        "title": "Differentially Private Kernel Density Estimation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a refined differentially private (DP) data structure for kernel density estimation (KDE), offering not only improved privacy-utility tradeoff but also better efficiency over prior results. Specifically, we study the mathematical problem: given a similarity function $f$ (or DP KDE) and a private dataset $X \\subset \\mathbb{R}^d$, our goal is to preprocess $X$ so that for any query $y\\in\\mathbb{R}^d$, we approximate $\\sum_{x \\in X} f(x, y)$ in a differentially private fashion. The best previous algorithm for $f(x,y) =\\| x - y \\|_1$ is the node-contaminated balanced binary tree by [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. Their algorithm requires $O(nd)$ space and time for preprocessing with $n=|X|$. For any query point, the query time is $d \\log n$, with an error guarantee of $(1+\u03b1)$-approximation and $\u03b5^{-1} \u03b1^{-0.5} d^{1.5} R \\log^{1.5} n$. In this paper, we improve the best previous result [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024] in three aspects: - We reduce query time by a factor of $\u03b1^{-1} \\log n$. - We improve the approximation ratio from $\u03b1$ to 1. - We reduce the error dependence by a factor of $\u03b1^{-0.5}$. From a technical perspective, our method of constructing the search tree differs from previous work [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. In prior work, for each query, the answer is split into $\u03b1^{-1} \\log n$ numbers, each derived from the summation of $\\log n$ values in interval tree countings. In contrast, we construct the tree differently, splitting the answer into $\\log n$ numbers, where each is a smart combination of two distance values, two counting values, and $y$ itself. We believe our tree structure may be of independent interest.",
        "subjects": [
            "cs.DS",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01696",
        "abstract url": "https://arxiv.org/abs/2409.01696",
        "title": "On the Vulnerability of Skip Connections to Model Inversion Attacks",
        "rating": "0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Skip connections are fundamental architecture designs for modern deep neural networks (DNNs) such as CNNs and ViTs. While they help improve model performance significantly, we identify a vulnerability associated with skip connections to Model Inversion (MI) attacks, a type of privacy attack that aims to reconstruct private training data through abusive exploitation of a model. In this paper, as a pioneer work to understand how DNN architectures affect MI, we study the impact of skip connections on MI. We make the following discoveries: 1) Skip connections reinforce MI attacks and compromise data privacy. 2) Skip connections in the last stage are the most critical to attack. 3) RepVGG, an approach to remove skip connections in the inference-time architectures, could not mitigate the vulnerability to MI attacks. 4) Based on our findings, we propose MI-resilient architecture designs for the first time. Without bells and whistles, we show in extensive experiments that our MI-resilient architectures can outperform state-of-the-art (SOTA) defense methods in MI robustness. Furthermore, our MI-resilient architectures are complementary to existing MI defense methods. Our project is available at https://Pillowkoh.github.io/projects/RoLSS/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2409.01762",
        "abstract url": "https://arxiv.org/abs/2409.01762",
        "title": "Decoding finger velocity from cortical spike trains with recurrent spiking neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Invasive cortical brain-machine interfaces (BMIs) can significantly improve the life quality of motor-impaired patients. Nonetheless, externally mounted pedestals pose an infection risk, which calls for fully implanted systems. Such systems, however, must meet strict latency and energy constraints while providing reliable decoding performance. While recurrent spiking neural networks (RSNNs) are ideally suited for ultra-low-power, low-latency processing on neuromorphic hardware, it is unclear whether they meet the above requirements. To address this question, we trained RSNNs to decode finger velocity from cortical spike trains (CSTs) of two macaque monkeys. First, we found that a large RSNN model outperformed existing feedforward spiking neural networks (SNNs) and artificial neural networks (ANNs) in terms of their decoding accuracy. We next developed a tiny RSNN with a smaller memory footprint, low firing rates, and sparse connectivity. Despite its reduced computational requirements, the resulting model performed substantially better than existing SNN and ANN decoders. Our results thus demonstrate that RSNNs offer competitive CST decoding performance under tight resource constraints and are promising candidates for fully implanted ultra-low-power BMIs with the potential to revolutionize patient care.",
        "subjects": [
            "q-bio.NC",
            "cs.HC",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "5 pages, 2 figures. This work has been submitted to the IEEE BioCAS 2024 conference"
    },
    {
        "paper id": "2409.01771",
        "abstract url": "https://arxiv.org/abs/2409.01771",
        "title": "Adoption of smartphones among older adults and the role of perceived threat of cyberattacks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Adoption of smartphones by older adults (i.e., 65+ years old) is poorly understood, especially in relation to cybersecurity and cyberthreats. In this study, we focus on the perceived threat of cyberattacks as a potential barrier to smartphone adoption and use among older adults. The study also aims at investigating the differences between users and non-users of smartphones. We conducted a quantitative cross-sectional survey of older adults in Slovenia (N = 535). The results of covariance-based structural equation modeling indicate consistent support for the associations of intention to use (ItU) with perceived usefulness (PU), subjective norm (SN) and attitude toward use (AtU), the association between ease of use (EoU) and PU, the association between hedonic motivation (HM) and AtU, and the association between smartphone technology anxiety (STA) and fear of use (FoU). Even though the negative association between perceived threat (PT) and ItU was significant in the full sample, the non-user and the not aware subsamples, its role in adoption of smartphones among older adults remains puzzling. We uncovered significant positive associations between PT and AtU (except in the not aware subsample), and PT and PU which we could not fully explain in our study. The results of our study provide some insights on how campaigns promoting adoption of smartphones among older adults, workshops, training and informal teaching might be improved.",
        "subjects": [
            "cs.CY",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01793",
        "abstract url": "https://arxiv.org/abs/2409.01793",
        "title": "Task Weighting through Gradient Projection for Multitask Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In multitask learning, conflicts between task gradients are a frequent issue degrading a model's training performance. This is commonly addressed by using the Gradient Projection algorithm PCGrad that often leads to faster convergence and improved performance metrics. In this work, we present a method to adapt this algorithm to simultaneously also perform task prioritization. Our approach differs from traditional task weighting performed by scaling task losses in that our weighting scheme applies only in cases where tasks are in conflict, but lets the training proceed unhindered otherwise. We replace task weighting factors by a probability distribution that determines which task gradients get projected in conflict cases. Our experiments on the nuScenes, CIFAR-100, and CelebA datasets confirm that our approach is a practical method for task weighting. Paired with multiple different task weighting schemes, we observe a significant improvement in the performance metrics of most tasks compared to Gradient Projection with uniform projection probabilities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01815",
        "abstract url": "https://arxiv.org/abs/2409.01815",
        "title": "Learning State-Dependent Policy Parametrizations for Dynamic Technician Routing with Rework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Home repair and installation services require technicians to visit customers and resolve tasks of different complexity. Technicians often have heterogeneous skills and working experiences. The geographical spread of customers makes achieving only perfect matches between technician skills and task requirements impractical. Additionally, technicians are regularly absent due to sickness. With non-perfect assignments regarding task requirement and technician skill, some tasks may remain unresolved and require a revisit and rework. Companies seek to minimize customer inconvenience due to delay. We model the problem as a sequential decision process where, over a number of service days, customers request service while heterogeneously skilled technicians are routed to serve customers in the system. Each day, our policy iteratively builds tours by adding \"important\" customers. The importance bases on analytical considerations and is measured by respecting routing efficiency, urgency of service, and risk of rework in an integrated fashion. We propose a state-dependent balance of these factors via reinforcement learning. A comprehensive study shows that taking a few non-perfect assignments can be quite beneficial for the overall service quality. We further demonstrate the value provided by a state-dependent parametrization.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01823",
        "abstract url": "https://arxiv.org/abs/2409.01823",
        "title": "DAOs of Collective Intelligence? Unraveling the Complexity of Blockchain Governance in Decentralized Autonomous Organizations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Decentralized autonomous organizations (DAOs) have transformed organizational structures by shifting from traditional hierarchical control to decentralized approaches, leveraging blockchain and cryptoeconomics. Despite managing significant funds and building global networks, DAOs face challenges like declining participation, increasing centralization, and inabilities to adapt to changing environments, which stifle innovation. This paper explores DAOs as complex systems and applies complexity science to explain their inefficiencies. In particular, we discuss DAO challenges, their complex nature, and introduce the self-organization mechanisms of collective intelligence, digital democracy, and adaptation. By applying these mechansims to improve DAO design and construction, a practical design framework for DAOs is created. This contribution lays a foundation for future research at the intersection of complexity science and DAOs.",
        "subjects": [
            "cs.CY",
            "cs.ET",
            "physics.app-ph",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01829",
        "abstract url": "https://arxiv.org/abs/2409.01829",
        "title": "Deep non-parametric logistic model with case-control data and external summary information",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The case-control sampling design serves as a pivotal strategy in mitigating the imbalanced structure observed in binary data. We consider the estimation of a non-parametric logistic model with the case-control data supplemented by external summary information. The incorporation of external summary information ensures the identifiability of the model. We propose a two-step estimation procedure. In the first step, the external information is utilized to estimate the marginal case proportion. In the second step, the estimated proportion is used to construct a weighted objective function for parameter training. A deep neural network architecture is employed for functional approximation. We further derive the non-asymptotic error bound of the proposed estimator. Following this the convergence rate is obtained and is shown to reach the optimal speed of the non-parametric regression estimation. Simulation studies are conducted to evaluate the theoretical findings of the proposed method. A real data example is analyzed for illustration.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "26 pages, 2 figures, 3 tables"
    },
    {
        "paper id": "2409.01869",
        "abstract url": "https://arxiv.org/abs/2409.01869",
        "title": "Feature-Based Interpretable Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "For optimization models to be used in practice, it is crucial that users trust the results. A key factor in this aspect is the interpretability of the solution process. A previous framework for inherently interpretable optimization models used decision trees to map instances to solutions of the underlying optimization model. Based on this work, we investigate how we can use more general optimization rules to further increase interpretability and at the same time give more freedom to the decision maker. The proposed rules do not map to a concrete solution but to a set of solutions characterized by common features. To find such optimization rules, we present an exact methodology using mixed-integer programming formulations as well as heuristics. We also outline the challenges and opportunities that these methods present. In particular, we demonstrate the improvement in solution quality that our approach offers compared to existing frameworks for interpretable optimization and we discuss the relationship between interpretability and performance. These findings are supported by experiments using both synthetic and real-world data.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01872",
        "abstract url": "https://arxiv.org/abs/2409.01872",
        "title": "Latent Distillation for Continual Object Detection at the Edge",
        "rating": "0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "While numerous methods achieving remarkable performance exist in the Object Detection literature, addressing data distribution shifts remains challenging. Continual Learning (CL) offers solutions to this issue, enabling models to adapt to new data while maintaining performance on previous data. This is particularly pertinent for edge devices, common in dynamic environments like automotive and robotics. In this work, we address the memory and computation constraints of edge devices in the Continual Learning for Object Detection (CLOD) scenario. Specifically, (i) we investigate the suitability of an open-source, lightweight, and fast detector, namely NanoDet, for CLOD on edge devices, improving upon larger architectures used in the literature. Moreover, (ii) we propose a novel CL method, called Latent Distillation~(LD), that reduces the number of operations and the memory required by state-of-the-art CL approaches without significantly compromising detection performance. Our approach is validated using the well-known VOC and COCO benchmarks, reducing the distillation parameter overhead by 74\\% and the Floating Points Operations~(FLOPs) by 56\\% per model update compared to other distillation methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "ECCV workshops, Computational Aspects of Deep Learning (CADL) 2024"
    },
    {
        "paper id": "2409.01880",
        "abstract url": "https://arxiv.org/abs/2409.01880",
        "title": "Preserving the Ephemeral: Instagram Story Archiving with the Tidal Tales Plugin",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "We introduce the Tidal Tales Plugin, a Firefox extension for efficiently collecting and archiving of Instagram stories, addressing the challenges of ephemeral data in social media research. It enables an automated collection of story metadata and media files without risking account bans. It contributes to Web Science by facilitating expansive, long-term studies with enhanced data access and integrity.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01908",
        "abstract url": "https://arxiv.org/abs/2409.01908",
        "title": "Bayesian CART models for aggregate claim modeling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes three types of Bayesian CART (or BCART) models for aggregate claim amount, namely, frequency-severity models, sequential models and joint models. We propose a general framework for the BCART models applicable to data with multivariate responses, which is particularly useful for the joint BCART models with a bivariate response: the number of claims and aggregate claim amount. To facilitate frequency-severity modeling, we investigate BCART models for the right-skewed and heavy-tailed claim severity data by using various distributions. We discover that the Weibull distribution is superior to gamma and lognormal distributions, due to its ability to capture different tail characteristics in tree models. Additionally, we find that sequential BCART models and joint BCART models, which incorporate dependence between the number of claims and average severity, are beneficial and thus preferable to the frequency-severity BCART models in which independence is assumed. The effectiveness of these models' performance is illustrated by carefully designed simulations and real insurance data.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "q-fin.ST",
            "stat.AP",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01909",
        "abstract url": "https://arxiv.org/abs/2409.01909",
        "title": "LUK: Empowering Log Understanding with Expert Knowledge from Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Logs play a critical role in providing essential information for system monitoring and troubleshooting. Recently, with the success of pre-trained language models (PLMs) and large language models (LLMs) in natural language processing (NLP), smaller PLMs (such as BERT) and LLMs (like ChatGPT) have become the current mainstream approaches for log analysis. While LLMs possess rich knowledge, their high computational costs and unstable performance make LLMs impractical for analyzing logs directly. In contrast, smaller PLMs can be fine-tuned for specific tasks even with limited computational resources, making them more practical. However, these smaller PLMs face challenges in understanding logs comprehensively due to their limited expert knowledge. To better utilize the knowledge embedded within LLMs for log understanding, this paper introduces a novel knowledge enhancement framework, called LUK, which acquires expert knowledge from LLMs to empower log understanding on a smaller PLM. Specifically, we design a multi-expert collaboration framework based on LLMs consisting of different roles to acquire expert knowledge. In addition, we propose two novel pre-training tasks to enhance the log pre-training with expert knowledge. LUK achieves state-of-the-art results on different log analysis tasks and extensive experiments demonstrate expert knowledge from LLMs can be utilized more effectively to understand logs.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2409.01927",
        "abstract url": "https://arxiv.org/abs/2409.01927",
        "title": "From Grounding to Planning: Benchmarking Bottlenecks in Web Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "General web-based agents are increasingly essential for interacting with complex web environments, yet their performance in real-world web applications remains poor, yielding extremely low accuracy even with state-of-the-art frontier models. We observe that these agents can be decomposed into two primary components: Planning and Grounding. Yet, most existing research treats these agents as black boxes, focusing on end-to-end evaluations which hinder meaningful improvements. We sharpen the distinction between the planning and grounding components and conduct a novel analysis by refining experiments on the Mind2Web dataset. Our work proposes a new benchmark for each of the components separately, identifying the bottlenecks and pain points that limit agent performance. Contrary to prevalent assumptions, our findings suggest that grounding is not a significant bottleneck and can be effectively addressed with current techniques. Instead, the primary challenge lies in the planning component, which is the main source of performance degradation. Through this analysis, we offer new insights and demonstrate practical suggestions for improving the capabilities of web agents, paving the way for more reliable agents.",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01930",
        "abstract url": "https://arxiv.org/abs/2409.01930",
        "title": "Efficient LLM Context Distillation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper specifically investigates context distillation a method that extends the utility of task-specific examples by internalizing them, thus augmenting the example set accessible for model inference.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01958",
        "abstract url": "https://arxiv.org/abs/2409.01958",
        "title": "Private Electronic Payments with Self-Custody and Zero-Knowledge Verified Reissuance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This article builds upon the protocol for digital transfers described by Goodell, Toliver, and Nakib, which combines privacy by design for consumers with strong compliance enforcement for recipients of payments and self-validating assets that carry their own verifiable provenance information. We extend the protocol to allow for the verification that reissued assets were created in accordance with rules prohibiting the creation of new assets by anyone but the issuer, without exposing information about the circumstances in which the assets were created that could be used to identify the payer. The modified protocol combines an audit log with zero-knowledge proofs, so that a consumer spending an asset can demonstrate that there exists a valid entry on the audit log that is associated with the asset, without specifying which entry it is. This property is important as a means to allow money to be reissued within the system without the involvement of system operators within the zone of control of the original issuer. Additionally, we identify a key property of privacy-respecting electronic payments, wherein the payer is not required to retain secrets arising from one transaction until the following transaction, and argue that this property is essential to framing security requirements for storage of digital assets and the risk of blackmail or coercion as a way to exfiltrate information about payment history. We claim that the design of our protocol strongly protects the anonymity of payers with respect to their payment transactions, while preventing the creation of assets by any party other than the original issuer without destroying assets of equal value.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "19 pages, 3 figures"
    },
    {
        "paper id": "2409.01968",
        "abstract url": "https://arxiv.org/abs/2409.01968",
        "title": "Learning Machines: In Search of a Concept Oriented Language",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "What is the next step after the data/digital revolution? What do we need the most to reach this aim? How machines can memorize, learn or discover? What should they be able to do to be qualified as \"intelligent\"? These questions relate to the next generation \"intelligent\" machines. Probably, these machines should be able to handle knowledge discovery, decision-making and concepts. In this paper, we will take into account some historical contributions and discuss these different questions through an analogy to human intelligence. Also, a general framework for a concept oriented language will be proposed.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 8 figures"
    },
    {
        "paper id": "2409.01980",
        "abstract url": "https://arxiv.org/abs/2409.01980",
        "title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems. Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities. The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field. This survey focuses on the problem of anomaly and OOD detection under the context of LLMs. We propose a new taxonomy to categorize existing approaches into three classes based on the role played by LLMs. Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field. We also provide an up-to-date reading list of relevant papers.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "under review"
    },
    {
        "paper id": "2409.01984",
        "abstract url": "https://arxiv.org/abs/2409.01984",
        "title": "Observing Context Improves Disparity Estimation when Race is Unobserved",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "In many domains, it is difficult to obtain the race data that is required to estimate racial disparity. To address this problem, practitioners have adopted the use of proxy methods which predict race using non-protected covariates. However, these proxies often yield biased estimates, especially for minority groups, limiting their real-world utility. In this paper, we introduce two new contextual proxy models that advance existing methods by incorporating contextual features in order to improve race estimates. We show that these algorithms demonstrate significant performance improvements in estimating disparities on real-world home loan and voter data. We establish that achieving unbiased disparity estimates with contextual proxies relies on mean-consistency, a calibration-like condition.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01985",
        "abstract url": "https://arxiv.org/abs/2409.01985",
        "title": "UNSURE: Unknown Noise level Stein's Unbiased Risk Estimator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, many self-supervised learning methods for image reconstruction have been proposed that can learn from noisy data alone, bypassing the need for ground-truth references. Most existing methods cluster around two classes: i) Noise2Self and similar cross-validation methods that require very mild knowledge about the noise distribution, and ii) Stein's Unbiased Risk Estimator (SURE) and similar approaches that assume full knowledge of the distribution. The first class of methods is often suboptimal compared to supervised learning, and the second class is often impractical, as the noise level is generally unknown in real-world applications. In this paper, we provide a theoretical framework that characterizes this expressivity-robustness trade-off and propose a new approach based on SURE, but unlike the standard SURE, does not require knowledge about the noise level. Throughout a series of experiments, we show that the proposed estimator outperforms other existing self-supervised methods on various imaging inverse problems.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01990",
        "abstract url": "https://arxiv.org/abs/2409.01990",
        "title": "Contemporary Model Compression on Large Language Models Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have revolutionized natural language processing by achieving state-of-the-art results across a variety of tasks. However, the computational demands of LLM inference, including high memory consumption and slow processing speeds, pose significant challenges for real-world applications, particularly on resource-constrained devices. Efficient inference is crucial for scaling the deployment of LLMs to a broader range of platforms, including mobile and edge devices. This survey explores contemporary techniques in model compression that address these challenges by reducing the size and computational requirements of LLMs while maintaining their performance. We focus on model-level compression methods, including quantization, knowledge distillation, and pruning, as well as system-level optimizations like KV cache efficient design. Each of these methodologies offers a unique approach to optimizing LLMs, from reducing numerical precision to transferring knowledge between models and structurally simplifying neural networks. Additionally, we discuss emerging trends in system-level design that further enhance the efficiency of LLM inference. This survey aims to provide a comprehensive overview of current advancements in model compression and their potential to make LLMs more accessible and practical for diverse applications.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02017",
        "abstract url": "https://arxiv.org/abs/2409.02017",
        "title": "AI Governance in Higher Education: Case Studies of Guidance at Big Ten Universities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Generative AI has drawn significant attention from stakeholders in higher education. As it introduces new opportunities for personalized learning and tutoring support, it simultaneously poses challenges to academic integrity and leads to ethical issues. Consequently, governing responsible AI usage within higher education institutions (HEIs) becomes increasingly important. Leading universities have already published guidelines on Generative AI, with most attempting to embrace this technology responsibly. This study provides a new perspective by focusing on strategies for responsible AI governance as demonstrated in these guidelines. Through a case study of 14 prestigious universities in the United States, we identified the multi-unit governance of AI, the role-specific governance of AI, and the academic characteristics of AI governance from their AI guidelines. The strengths and potential limitations of these strategies and characteristics are discussed. The findings offer practical implications for guiding responsible AI usage in HEIs and beyond.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02052",
        "abstract url": "https://arxiv.org/abs/2409.02052",
        "title": "Robust Fourier Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fourier embedding has shown great promise in removing spectral bias during neural network training. However, it can still suffer from high generalization errors, especially when the labels or measurements are noisy. We demonstrate that introducing a simple diagonal layer after the Fourier embedding layer makes the network more robust to measurement noise, effectively prompting it to learn sparse Fourier features. We provide theoretical justifications for this Fourier feature learning, leveraging recent developments in diagonal networks and implicit regularization in neural networks. Under certain conditions, our proposed approach can also learn functions that are noisy mixtures of nonlinear functions of Fourier features. Numerical experiments validate the effectiveness of our proposed architecture, supporting our theory.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "31 pages, 9 figures"
    },
    {
        "paper id": "2409.02066",
        "abstract url": "https://arxiv.org/abs/2409.02066",
        "title": "Robust Clustering on High-Dimensional Data with Stochastic Quantization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses the limitations of traditional vector quantization (clustering) algorithms, particularly K-Means and its variant K-Means++, and explores the Stochastic Quantization (SQ) algorithm as a scalable alternative for high-dimensional unsupervised and semi-supervised learning problems. Some traditional clustering algorithms suffer from inefficient memory utilization during computation, necessitating the loading of all data samples into memory, which becomes impractical for large-scale datasets. While variants such as Mini-Batch K-Means partially mitigate this issue by reducing memory usage, they lack robust theoretical convergence guarantees due to the non-convex nature of clustering problems. In contrast, the Stochastic Quantization algorithm provides strong theoretical convergence guarantees, making it a robust alternative for clustering tasks. We demonstrate the computational efficiency and rapid convergence of the algorithm on an image classification problem with partially labeled data, comparing model accuracy across various ratios of labeled to unlabeled data. To address the challenge of high dimensionality, we trained Triplet Network to encode images into low-dimensional representations in a latent space, which serve as a basis for comparing the efficiency of both the Stochastic Quantization algorithm and traditional quantization algorithms. Furthermore, we enhance the algorithm's convergence speed by introducing modifications with an adaptive learning rate.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "21 page, 5 figures, to be published in the International Scientific Technical Journal \"Problems of Control and Informatics\""
    },
    {
        "paper id": "2409.02077",
        "abstract url": "https://arxiv.org/abs/2409.02077",
        "title": "FastEnsemble: A new scalable ensemble clustering method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Many community detection algorithms are stochastic in nature, and their output can vary based on different input parameters and random seeds. Consensus clustering methods, such as FastConsensus and ECG, combine clusterings from multiple runs of the same clustering algorithm, in order to improve stability and accuracy. In this study we present a new consensus clustering method, FastEnsemble, and show that it provides advantages over both FastConsensus and ECG. Furthermore, FastEnsemble is designed for use with any clustering method, and we show results using \\ourmethod with Leiden optimizing modularity or the Constant Potts model. FastEnsemble is available in Github at https://github.com/ytabatabaee/fast-ensemble",
        "subjects": [
            "cs.SI"
        ],
        "comment": "12 pages, 5 figures, submitted to a conference"
    },
    {
        "paper id": "2409.02079",
        "abstract url": "https://arxiv.org/abs/2409.02079",
        "title": "Synthetic Data Generation and Automated Multidimensional Data Labeling for AI/ML in General and Circular Coordinates",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Insufficient amounts of available training data is a critical challenge for both development and deployment of artificial intelligence and machine learning (AI/ML) models. This paper proposes a unified approach to both synthetic data generation (SDG) and automated data labeling (ADL) with a unified SDG-ADL algorithm. SDG-ADL uses multidimensional (n-D) representations of data visualized losslessly with General Line Coordinates (GLCs), relying on reversible GLC properties to visualize n-D data in multiple GLCs. This paper demonstrates use of the new Circular Coordinates in Static and Dynamic forms, used with Parallel Coordinates and Shifted Paired Coordinates, since each GLC exemplifies unique data properties, such as interattribute n-D distributions and outlier detection. The approach is interactively implemented in computer software with the Dynamic Coordinates Visualization system (DCVis). Results with real data are demonstrated in case studies, evaluating impact on classifiers.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 17 figures, 11 tables"
    },
    {
        "paper id": "2409.02100",
        "abstract url": "https://arxiv.org/abs/2409.02100",
        "title": "On a heuristic approach to the description of consciousness as a hypercomplex system state and the possibility of machine consciousness (German edition)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This article presents a heuristic view that shows that the inner states of consciousness experienced by every human being have a physical but imaginary hypercomplex basis. The hypercomplex description is necessary because certain processes of consciousness cannot be physically measured in principle, but nevertheless exist. Based on theoretical considerations, it could be possible - as a result of mathematical investigations into a so-called bicomplex algebra - to generate and use hypercomplex system states on machines in a targeted manner. The hypothesis of the existence of hypercomplex system states on machines is already supported by the surprising performance of highly complex AI systems. However, this has yet to be proven. In particular, there is a lack of experimental data that distinguishes such systems from other systems, which is why this question will be addressed in later articles. This paper describes the developed bicomplex algebra and possible applications of these findings to generate hypercomplex energy states on machines. In the literature, such system states are often referred to as machine consciousness. The article uses mathematical considerations to explain how artificial consciousness could be generated and what advantages this would have for such AI systems.",
        "subjects": [
            "cs.AI",
            "math.AC",
            "physics.app-ph"
        ],
        "comment": "7 pages, in German language. 1 figure"
    },
    {
        "paper id": "2409.02101",
        "abstract url": "https://arxiv.org/abs/2409.02101",
        "title": "Towards Real-World Adverse Weather Image Restoration: Enhancing Clearness and Semantics with Vision-Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This paper addresses the limitations of adverse weather image restoration approaches trained on synthetic data when applied to real-world scenarios. We formulate a semi-supervised learning framework employing vision-language models to enhance restoration performance across diverse adverse weather conditions in real-world settings. Our approach involves assessing image clearness and providing semantics using vision-language models on real data, serving as supervision signals for training restoration models. For clearness enhancement, we use real-world data, utilizing a dual-step strategy with pseudo-labels assessed by vision-language models and weather prompt learning. For semantic enhancement, we integrate real-world data by adjusting weather conditions in vision-language model descriptions while preserving semantic meaning. Additionally, we introduce an effective training strategy to bootstrap restoration performance. Our approach achieves superior results in real-world adverse weather image restoration, demonstrated through qualitative and quantitative comparisons with state-of-the-art works.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2409.01652",
        "abstract url": "https://arxiv.org/abs/2409.01652",
        "title": "ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "3D",
                "RGB-D"
            ],
            [
                "robot",
                "Robotic Manipulation"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Representing robotic manipulation tasks as constraints that associate the robot and the environment is a promising way to encode desired robot behaviors. However, it remains unclear how to formulate the constraints such that they are 1) versatile to diverse tasks, 2) free of manual labeling, and 3) optimizable by off-the-shelf solvers to produce robot actions in real-time. In this work, we introduce Relational Keypoint Constraints (ReKep), a visually-grounded representation for constraints in robotic manipulation. Specifically, ReKep is expressed as Python functions mapping a set of 3D keypoints in the environment to a numerical cost. We demonstrate that by representing a manipulation task as a sequence of Relational Keypoint Constraints, we can employ a hierarchical optimization procedure to solve for robot actions (represented by a sequence of end-effector poses in SE(3)) with a perception-action loop at a real-time frequency. Furthermore, in order to circumvent the need for manual specification of ReKep for each new task, we devise an automated procedure that leverages large vision models and vision-language models to produce ReKep from free-form language instructions and RGB-D observations. We present system implementations on a wheeled single-arm platform and a stationary dual-arm platform that can perform a large variety of manipulation tasks, featuring multi-stage, in-the-wild, bimanual, and reactive behaviors, all without task-specific data or environment models. Website at https://rekep-robot.github.io.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01662",
        "abstract url": "https://arxiv.org/abs/2409.01662",
        "title": "Efficiently Expanding Receptive Fields: Local Split Attention and Parallel Aggregation for Enhanced Large-scale Point Cloud Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Expanding the receptive field in a deep learning model for large-scale 3D point cloud segmentation is an effective technique for capturing rich contextual information, which consequently enhances the network's ability to learn meaningful features. However, this often leads to increased computational complexity and risk of overfitting, challenging the efficiency and effectiveness of the learning paradigm. To address these limitations, we propose the Local Split Attention Pooling (LSAP) mechanism to effectively expand the receptive field through a series of local split operations, thus facilitating the acquisition of broader contextual knowledge. Concurrently, it optimizes the computational workload associated with attention-pooling layers to ensure a more streamlined processing workflow. Based on LSAP, a Parallel Aggregation Enhancement (PAE) module is introduced to enable parallel processing of data using both 2D and 3D neighboring information to further enhance contextual representations within the network. In light of the aforementioned designs, we put forth a novel framework, designated as LSNet, for large-scale point cloud semantic segmentation. Extensive evaluations demonstrated the efficacy of seamlessly integrating the proposed PAE module into existing frameworks, yielding significant improvements in mean intersection over union (mIoU) metrics, with a notable increase of up to 11%. Furthermore, LSNet demonstrated superior performance compared to state-of-the-art semantic segmentation networks on three benchmark datasets, including S3DIS, Toronto3D, and SensatUrban. It is noteworthy that our method achieved a substantial speedup of approximately 38.8% compared to those employing similar-sized receptive fields, which serves to highlight both its computational efficiency and practical utility in real-world large-scale scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01691",
        "abstract url": "https://arxiv.org/abs/2409.01691",
        "title": "When 3D Partial Points Meets SAM: Tooth Point Cloud Segmentation with Sparse Labels",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Tooth point cloud segmentation is a fundamental task in many orthodontic applications. Current research mainly focuses on fully supervised learning which demands expensive and tedious manual point-wise annotation. Although recent weakly-supervised alternatives are proposed to use weak labels for 3D segmentation and achieve promising results, they tend to fail when the labels are extremely sparse. Inspired by the powerful promptable segmentation capability of the Segment Anything Model (SAM), we propose a framework named SAMTooth that leverages such capacity to complement the extremely sparse supervision. To automatically generate appropriate point prompts for SAM, we propose a novel Confidence-aware Prompt Generation strategy, where coarse category predictions are aggregated with confidence-aware filtering. Furthermore, to fully exploit the structural and shape clues in SAM's outputs for assisting the 3D feature learning, we advance a Mask-guided Representation Learning that re-projects the generated tooth masks of SAM into 3D space and constrains these points of different teeth to possess distinguished representations. To demonstrate the effectiveness of the framework, we conduct experiments on the public dataset and surprisingly find with only 0.1\\% annotations (one point per tooth), our method can surpass recent weakly supervised methods by a large margin, and the performance is even comparable to the recent fully-supervised methods, showcasing the significant potential of applying SAM to 3D perception tasks with sparse labels. Code is available at https://github.com/CUHK-AIM-Group/SAMTooth.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To appear at MICCAI24"
    },
    {
        "paper id": "2409.01761",
        "abstract url": "https://arxiv.org/abs/2409.01761",
        "title": "PRoGS: Progressive Rendering of Gaussian Splats",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Over the past year, 3D Gaussian Splatting (3DGS) has received significant attention for its ability to represent 3D scenes in a perceptually accurate manner. However, it can require a substantial amount of storage since each splat's individual data must be stored. While compression techniques offer a potential solution by reducing the memory footprint, they still necessitate retrieving the entire scene before any part of it can be rendered. In this work, we introduce a novel approach for progressively rendering such scenes, aiming to display visible content that closely approximates the final scene as early as possible without loading the entire scene into memory. This approach benefits both on-device rendering applications limited by memory constraints and streaming applications where minimal bandwidth usage is preferred. To achieve this, we approximate the contribution of each Gaussian to the final scene and construct an order of prioritization on their inclusion in the rendering process. Additionally, we demonstrate that our approach can be combined with existing compression methods to progressively render (and stream) 3DGS scenes, optimizing bandwidth usage by focusing on the most important splats within a scene. Overall, our work establishes a foundation for making remotely hosted 3DGS content more quickly accessible to end-users in over-the-top consumption scenarios, with our results showing significant improvements in quality across all metrics compared to existing methods.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01781",
        "abstract url": "https://arxiv.org/abs/2409.01781",
        "title": "Dual Advancement of Representation Learning and Clustering for Sparse and Noisy Images",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Sparse and noisy images (SNIs), like those in spatial gene expression data, pose significant challenges for effective representation learning and clustering, which are essential for thorough data analysis and interpretation. In response to these challenges, we propose Dual Advancement of Representation Learning and Clustering (DARLC), an innovative framework that leverages contrastive learning to enhance the representations derived from masked image modeling. Simultaneously, DARLC integrates cluster assignments in a cohesive, end-to-end approach. This integrated clustering strategy addresses the \"class collision problem\" inherent in contrastive learning, thus improving the quality of the resulting representations. To generate more plausible positive views for contrastive learning, we employ a graph attention network-based technique that produces denoised images as augmented data. As such, our framework offers a comprehensive approach that improves the learning of representations by enhancing their local perceptibility, distinctiveness, and the understanding of relational semantics. Furthermore, we utilize a Student's t mixture model to achieve more robust and adaptable clustering of SNIs. Extensive experiments, conducted across 12 different types of datasets consisting of SNIs, demonstrate that DARLC surpasses the state-of-the-art methods in both image clustering and generating image representations that accurately capture gene interactions. Code is available at https://github.com/zipging/DARLC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01782",
        "abstract url": "https://arxiv.org/abs/2409.01782",
        "title": "UWStereo: A Large Synthetic Dataset for Underwater Stereo Matching",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite recent advances in stereo matching, the extension to intricate underwater settings remains unexplored, primarily owing to: 1) the reduced visibility, low contrast, and other adverse effects of underwater images; 2) the difficulty in obtaining ground truth data for training deep learning models, i.e. simultaneously capturing an image and estimating its corresponding pixel-wise depth information in underwater environments. To enable further advance in underwater stereo matching, we introduce a large synthetic dataset called UWStereo. Our dataset includes 29,568 synthetic stereo image pairs with dense and accurate disparity annotations for left view. We design four distinct underwater scenes filled with diverse objects such as corals, ships and robots. We also induce additional variations in camera model, lighting, and environmental effects. In comparison with existing underwater datasets, UWStereo is superior in terms of scale, variation, annotation, and photo-realistic image quality. To substantiate the efficacy of the UWStereo dataset, we undertake a comprehensive evaluation compared with nine state-of-the-art algorithms as benchmarks. The results indicate that current models still struggle to generalize to new domains. Hence, we design a new strategy that learns to reconstruct cross domain masked images before stereo matching training and integrate a cross view attention enhancement module that aggregates long-range content information to enhance the generalization ability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12pages"
    },
    {
        "paper id": "2409.01787",
        "abstract url": "https://arxiv.org/abs/2409.01787",
        "title": "LLM-GAN: Construct Generative Adversarial Network Through Large Language Models For Explainable Fake News Detection",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Explainable fake news detection predicts the authenticity of news items with annotated explanations. Today, Large Language Models (LLMs) are known for their powerful natural language understanding and explanation generation abilities. However, presenting LLMs for explainable fake news detection remains two main challenges. Firstly, fake news appears reasonable and could easily mislead LLMs, leaving them unable to understand the complex news-faking process. Secondly, utilizing LLMs for this task would generate both correct and incorrect explanations, which necessitates abundant labor in the loop. In this paper, we propose LLM-GAN, a novel framework that utilizes prompting mechanisms to enable an LLM to become Generator and Detector and for realistic fake news generation and detection. Our results demonstrate LLM-GAN's effectiveness in both prediction performance and explanation quality. We further showcase the integration of LLM-GAN to a cloud-native AI platform to provide better fake news detection service in the cloud.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01807",
        "abstract url": "https://arxiv.org/abs/2409.01807",
        "title": "EPRecon: An Efficient Framework for Real-Time Panoptic 3D Reconstruction from Monocular Video",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "voxel",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Panoptic 3D reconstruction from a monocular video is a fundamental perceptual task in robotic scene understanding. However, existing efforts suffer from inefficiency in terms of inference speed and accuracy, limiting their practical applicability. We present EPRecon, an efficient real-time panoptic 3D reconstruction framework. Current volumetric-based reconstruction methods usually utilize multi-view depth map fusion to obtain scene depth priors, which is time-consuming and poses challenges to real-time scene reconstruction. To end this, we propose a lightweight module to directly estimate scene depth priors in a 3D volume for reconstruction quality improvement by generating occupancy probabilities of all voxels. In addition, to infer richer panoptic features from occupied voxels, EPRecon extracts panoptic features from both voxel features and corresponding image features, obtaining more detailed and comprehensive instance-level semantic information and achieving more accurate segmentation results. Experimental results on the ScanNetV2 dataset demonstrate the superiority of EPRecon over current state-of-the-art methods in terms of both panoptic 3D reconstruction quality and real-time inference. Code is available at https://github.com/zhen6618/EPRecon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01813",
        "abstract url": "https://arxiv.org/abs/2409.01813",
        "title": "Reassessing Noise Augmentation Methods in the Context of Adversarial Speech",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this study, we investigate if noise-augmented training can concurrently improve adversarial robustness in automatic speech recognition (ASR) systems. We conduct a comparative analysis of the adversarial robustness of four different state-of-the-art ASR architectures, where each of the ASR architectures is trained under three different augmentation conditions: one subject to background noise, speed variations, and reverberations, another subject to speed variations only, and a third without any form of data augmentation. The results demonstrate that noise augmentation not only improves model performance on noisy speech but also the model's robustness to adversarial attacks.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01879",
        "abstract url": "https://arxiv.org/abs/2409.01879",
        "title": "SPiKE: 3D Human Pose from Point Cloud Sequences",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Human Pose Estimation (HPE) is the task of locating keypoints of the human body in 3D space from 2D or 3D representations such as RGB images, depth maps or point clouds. Current HPE methods from depth and point clouds predominantly rely on single-frame estimation and do not exploit temporal information from sequences. This paper presents SPiKE, a novel approach to 3D HPE using point cloud sequences. Unlike existing methods that process frames of a sequence independently, SPiKE leverages temporal context by adopting a Transformer architecture to encode spatio-temporal relationships between points across the sequence. By partitioning the point cloud into local volumes and using spatial feature extraction via point spatial convolution, SPiKE ensures efficient processing by the Transformer while preserving spatial integrity per timestamp. Experiments on the ITOP benchmark for 3D HPE show that SPiKE reaches 89.19% mAP, achieving state-of-the-art performance with significantly lower inference times. Extensive ablations further validate the effectiveness of sequence exploitation and our algorithmic choices. Code and models are available at: https://github.com/iballester/SPiKE",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 4 figures"
    },
    {
        "paper id": "2409.01935",
        "abstract url": "https://arxiv.org/abs/2409.01935",
        "title": "Map-Assisted Remote-Sensing Image Compression at Extremely Low Bitrates",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Remote-sensing (RS) image compression at extremely low bitrates has always been a challenging task in practical scenarios like edge device storage and narrow bandwidth transmission. Generative models including VAEs and GANs have been explored to compress RS images into extremely low-bitrate streams. However, these generative models struggle to reconstruct visually plausible images due to the highly ill-posed nature of extremely low-bitrate image compression. To this end, we propose an image compression framework that utilizes a pre-trained diffusion model with powerful natural image priors to achieve high-realism reconstructions. However, diffusion models tend to hallucinate small structures and textures due to the significant information loss at limited bitrates. Thus, we introduce vector maps as semantic and structural guidance and propose a novel image compression approach named Map-Assisted Generative Compression (MAGC). MAGC employs a two-stage pipeline to compress and decompress RS images at extremely low bitrates. The first stage maps an image into a latent representation, which is then further compressed in a VAE architecture to save bitrates and serves as implicit guidance in the subsequent diffusion process. The second stage conducts a conditional diffusion model to generate a visually pleasing and semantically accurate result using implicit guidance and explicit semantic guidance. Quantitative and qualitative comparisons show that our method outperforms standard codecs and other learning-based methods in terms of perceptual quality and semantic accuracy. The dataset and code will be publicly available at https://github.com/WHUyyx/MAGC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01936",
        "abstract url": "https://arxiv.org/abs/2409.01936",
        "title": "Optimizing CLIP Models for Image Retrieval with Maintained Joint-Embedding Alignment",
        "rating": "0",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Contrastive Language and Image Pairing (CLIP), a transformative method in multimedia retrieval, typically trains two neural networks concurrently to generate joint embeddings for text and image pairs. However, when applied directly, these models often struggle to differentiate between visually distinct images that have similar captions, resulting in suboptimal performance for image-based similarity searches. This paper addresses the challenge of optimizing CLIP models for various image-based similarity search scenarios, while maintaining their effectiveness in text-based search tasks such as text-to-image retrieval and zero-shot classification. We propose and evaluate two novel methods aimed at refining the retrieval capabilities of CLIP without compromising the alignment between text and image embeddings. The first method involves a sequential fine-tuning process: initially optimizing the image encoder for more precise image retrieval and subsequently realigning the text encoder to these optimized image embeddings. The second approach integrates pseudo-captions during the retrieval-optimization phase to foster direct alignment within the embedding space. Through comprehensive experiments, we demonstrate that these methods enhance CLIP's performance on various benchmarks, including image retrieval, k-NN classification, and zero-shot text-based classification, while maintaining robustness in text-to-image retrieval. Our optimized models permit maintaining a single embedding per image, significantly simplifying the infrastructure needed for large-scale multi-modal similarity search systems.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01944",
        "abstract url": "https://arxiv.org/abs/2409.01944",
        "title": "FuzzCoder: Byte-level Fuzzing Test via Large Language Model",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Fuzzing is an important dynamic program analysis technique designed for finding vulnerabilities in complex software. Fuzzing involves presenting a target program with crafted malicious input to cause crashes, buffer overflows, memory errors, and exceptions. Crafting malicious inputs in an efficient manner is a difficult open problem and the best approaches often apply uniform random mutations to pre-existing valid inputs. In this work, we propose to adopt fine-tuned large language models (FuzzCoder) to learn patterns in the input files from successful attacks to guide future fuzzing explorations. Specifically, we develop a framework to leverage the code LLMs to guide the mutation process of inputs in fuzzing. The mutation process is formulated as the sequence-to-sequence modeling, where LLM receives a sequence of bytes and then outputs the mutated byte sequence. FuzzCoder is fine-tuned on the created instruction dataset (Fuzz-Instruct), where the successful fuzzing history is collected from the heuristic fuzzing tool. FuzzCoder can predict mutation locations and strategies locations in input files to trigger abnormal behaviors of the program. Experimental results show that FuzzCoder based on AFL (American Fuzzy Lop) gain significant improvements in terms of effective proportion of mutation (EPM) and number of crashes (NC) for various input formats including ELF, JPG, MP3, and XML.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2409.01966",
        "abstract url": "https://arxiv.org/abs/2409.01966",
        "title": "MetaFood3D: Large 3D Food Object Dataset with Nutrition Values",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "RGB-D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Food computing is both important and challenging in computer vision (CV). It significantly contributes to the development of CV algorithms due to its frequent presence in datasets across various applications, ranging from classification and instance segmentation to 3D reconstruction. The polymorphic shapes and textures of food, coupled with high variation in forms and vast multimodal information, including language descriptions and nutritional data, make food computing a complex and demanding task for modern CV algorithms. 3D food modeling is a new frontier for addressing food-related problems, due to its inherent capability to deal with random camera views and its straightforward representation for calculating food portion size. However, the primary hurdle in the development of algorithms for food object analysis is the lack of nutrition values in existing 3D datasets. Moreover, in the broader field of 3D research, there is a critical need for domain-specific test datasets. To bridge the gap between general 3D vision and food computing research, we propose MetaFood3D. This dataset consists of 637 meticulously labeled 3D food objects across 108 categories, featuring detailed nutrition information, weight, and food codes linked to a comprehensive nutrition database. The dataset emphasizes intra-class diversity and includes rich modalities such as textured mesh files, RGB-D videos, and segmentation masks. Experimental results demonstrate our dataset's significant potential for improving algorithm performance, highlight the challenging gap between video captures and 3D scanned data, and show the strength of the MetaFood3D dataset in high-quality data generation, simulation, and augmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Dataset is coming soon"
    },
    {
        "paper id": "2409.01971",
        "abstract url": "https://arxiv.org/abs/2409.01971",
        "title": "Snapshot: Towards Application-centered Models for Pedestrian Trajectory Prediction in Urban Traffic Environments",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "Trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper explores pedestrian trajectory prediction in urban traffic while focusing on both model accuracy and real-world applicability. While promising approaches exist, they are often not publicly available, revolve around pedestrian datasets excluding traffic-related information, or resemble architectures that are either not real-time capable or robust. To address these limitations, we first introduce a dedicated benchmark based on Argoverse 2, specifically targeting pedestrians in urban settings. Following this, we present Snapshot, a modular, feed-forward neural network that outperforms the current state of the art while utilizing significantly less information. Despite its agent-centric encoding scheme, Snapshot demonstrates scalability, real-time performance, and robustness to varying motion histories. Moreover, by integrating Snapshot into a modular autonomous driving software stack, we showcase its real-world applicability",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 Pages, 9 Figures"
    },
    {
        "paper id": "2409.01998",
        "abstract url": "https://arxiv.org/abs/2409.01998",
        "title": "SA-MLP: Enhancing Point Cloud Classification with Efficient Addition and Shift Operations in MLP Architectures",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study addresses the computational inefficiencies in point cloud classification by introducing novel MLP-based architectures inspired by recent advances in CNN optimization. Traditional neural networks heavily rely on multiplication operations, which are computationally expensive. To tackle this, we propose Add-MLP and Shift-MLP, which replace multiplications with addition and shift operations, respectively, significantly enhancing computational efficiency. Building on this, we introduce SA-MLP, a hybrid model that intermixes alternately distributed shift and adder layers to replace MLP layers, maintaining the original number of layers without freezing shift layer weights. This design contrasts with the ShiftAddNet model from previous literature, which replaces convolutional layers with shift and adder layers, leading to a doubling of the number of layers and limited representational capacity due to frozen shift weights. Moreover, SA-MLP optimizes learning by setting distinct learning rates and optimizers specifically for the adder and shift layers, fully leveraging their complementary strengths. Extensive experiments demonstrate that while Add-MLP and Shift-MLP achieve competitive performance, SA-MLP significantly surpasses the multiplication-based baseline MLP model and achieves performance comparable to state-of-the-art MLP-based models. This study offers an efficient and effective solution for point cloud classification, balancing performance with computational efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02007",
        "abstract url": "https://arxiv.org/abs/2409.02007",
        "title": "PMT-MAE: Dual-Branch Self-Supervised Learning with Distillation for Efficient Point Cloud Classification",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Advances in self-supervised learning are essential for enhancing feature extraction and understanding in point cloud processing. This paper introduces PMT-MAE (Point MLP-Transformer Masked Autoencoder), a novel self-supervised learning framework for point cloud classification. PMT-MAE features a dual-branch architecture that integrates Transformer and MLP components to capture rich features. The Transformer branch leverages global self-attention for intricate feature interactions, while the parallel MLP branch processes tokens through shared fully connected layers, offering a complementary feature transformation pathway. A fusion mechanism then combines these features, enhancing the model's capacity to learn comprehensive 3D representations. Guided by the sophisticated teacher model Point-M2AE, PMT-MAE employs a distillation strategy that includes feature distillation during pre-training and logit distillation during fine-tuning, ensuring effective knowledge transfer. On the ModelNet40 classification task, achieving an accuracy of 93.6\\% without employing voting strategy, PMT-MAE surpasses the baseline Point-MAE (93.2\\%) and the teacher Point-M2AE (93.4\\%), underscoring its ability to learn discriminative 3D point cloud representations. Additionally, this framework demonstrates high efficiency, requiring only 40 epochs for both pre-training and fine-tuning. PMT-MAE's effectiveness and efficiency render it well-suited for scenarios with limited computational resources, positioning it as a promising solution for practical point cloud analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02084",
        "abstract url": "https://arxiv.org/abs/2409.02084",
        "title": "GraspSplats: Efficient Manipulation with 3D Feature Splatting",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "3D",
                "depth",
                "NeRF"
            ],
            [
                "robot"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The ability for robots to perform efficient and zero-shot grasping of object parts is crucial for practical applications and is becoming prevalent with recent advances in Vision-Language Models (VLMs). To bridge the 2D-to-3D gap for representations to support such a capability, existing methods rely on neural fields (NeRFs) via differentiable rendering or point-based projection methods. However, we demonstrate that NeRFs are inappropriate for scene changes due to their implicitness and point-based methods are inaccurate for part localization without rendering-based optimization. To amend these issues, we propose GraspSplats. Using depth supervision and a novel reference feature computation method, GraspSplats generates high-quality scene representations in under 60 seconds. We further validate the advantages of Gaussian-based representation by showing that the explicit and optimized geometry in GraspSplats is sufficient to natively support (1) real-time grasp sampling and (2) dynamic and articulated object manipulation with point trackers. With extensive experiments on a Franka robot, we demonstrate that GraspSplats significantly outperforms existing methods under diverse task settings. In particular, GraspSplats outperforms NeRF-based methods like F3RM and LERF-TOGO, and 2D detection methods.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project webpage: https://graspsplats.github.io/"
    },
    {
        "paper id": "2409.02097",
        "abstract url": "https://arxiv.org/abs/2409.02097",
        "title": "LinFusion: 1 GPU, 1 Minute, 16K Image",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Modern diffusion models, particularly those utilizing a Transformer-based UNet for denoising, rely heavily on self-attention operations to manage complex spatial relationships, thus achieving impressive generation performance. However, this existing paradigm faces significant challenges in generating high-resolution visual content due to its quadratic time and memory complexity with respect to the number of spatial tokens. To address this limitation, we aim at a novel linear attention mechanism as an alternative in this paper. Specifically, we begin our exploration from recently introduced models with linear complexity, e.g., Mamba, Mamba2, and Gated Linear Attention, and identify two key features-attention normalization and non-causal inference-that enhance high-resolution visual generation performance. Building on these insights, we introduce a generalized linear attention paradigm, which serves as a low-rank approximation of a wide spectrum of popular linear token mixers. To save the training cost and better leverage pre-trained models, we initialize our models and distill the knowledge from pre-trained StableDiffusion (SD). We find that the distilled model, termed LinFusion, achieves performance on par with or superior to the original SD after only modest training, while significantly reducing time and memory complexity. Extensive experiments on SD-v1.5, SD-v2.1, and SD-XL demonstrate that LinFusion delivers satisfactory zero-shot cross-resolution generation performance, generating high-resolution images like 16K resolution. Moreover, it is highly compatible with pre-trained SD components, such as ControlNet and IP-Adapter, requiring no adaptation efforts. Codes are available at https://github.com/Huage001/LinFusion.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Work in Progress. Codes are available at https://github.com/Huage001/LinFusion"
    },
    {
        "paper id": "2409.02108",
        "abstract url": "https://arxiv.org/abs/2409.02108",
        "title": "Unveiling Deep Shadows: A Survey on Image and Video Shadow Detection, Removal, and Generation in the Era of Deep Learning",
        "rating": "0",
        "keywords": [
            [
                "video editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Shadows are formed when light encounters obstacles, leading to areas of diminished illumination. In computer vision, shadow detection, removal, and generation are crucial for enhancing scene understanding, refining image quality, ensuring visual consistency in video editing, and improving virtual environments. This paper presents a comprehensive survey of shadow detection, removal, and generation in images and videos within the deep learning landscape over the past decade, covering tasks, deep models, datasets, and evaluation metrics. Our key contributions include a comprehensive survey of shadow analysis, standardization of experimental comparisons, exploration of the relationships among model size, speed, and performance, a cross-dataset generalization study, identification of open issues and future directions, and provision of publicly available resources to support further research.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.MM"
        ],
        "comment": "Publicly available results, trained models, and evaluation metrics at https://github.com/xw-hu/Unveiling-Deep-Shadows"
    },
    {
        "paper id": "2409.01607",
        "abstract url": "https://arxiv.org/abs/2409.01607",
        "title": "Data-driven topology design based on principal component analysis for 3D structural design problems",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Topology optimization is a structural design methodology widely utilized to address engineering challenges. However, sensitivity-based topology optimization methods struggle to solve optimization problems characterized by strong non-linearity. Leveraging the sensitivity-free nature and high capacity of deep generative models, data-driven topology design (DDTD) methodology is considered an effective solution to this problem. Despite this, the training effectiveness of deep generative models diminishes when input size exceeds a threshold while maintaining high degrees of freedom is crucial for accurately characterizing complex structures. To resolve the conflict between the both, we propose DDTD based on principal component analysis (PCA). Its core idea is to replace the direct training of deep generative models with material distributions by using a principal component score matrix obtained from PCA computation and to obtain the generated material distributions with new features through the restoration process. We apply the proposed PCA-based DDTD to the problem of minimizing the maximum stress in 3D structural mechanics and demonstrate it can effectively address the current challenges faced by DDTD that fail to handle 3D structural design problems. Various experiments are conducted to demonstrate the effectiveness and practicability of the proposed PCA-based DDTD.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "19 pages, 18 figures"
    },
    {
        "paper id": "2409.01656",
        "abstract url": "https://arxiv.org/abs/2409.01656",
        "title": "Graphons of Line Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A graphon is the limit of a converging graph sequence. Graphons of dense graphs are useful as they can act as a blueprint and generate graphs of arbitrary size with similar properties. But for sparse graphs this is not the case. Sparse graphs converge to the zero graphon, making the generated graphs empty or edgeless. Thus, the classical graphon definition fails for sparse graphs. Several methods have been proposed to overcome this limitation and to understand sparse graphs more deeply. However, the fragile nature of sparse graphs makes these methods mathematically complex. In this paper we show a simple method that can shed light on a certain subset of sparse graphs. The method involves mapping the original graphs to their line graphs. Line graphs map edges to vertices and connects edges when edges in the original graph share a vertex. We show that graphs satisfying a particular property, which we call the square-degree property are sparse, but give rise to dense line graphs. In particular, star graphs satisfy the square-degree property resulting in dense line graphs and non-zero graphons of line graphs. Similarly, superlinear preferential attachment graphs give rise to dense line graphs almost surely. In contrast, dense graphs, including Erdos-Renyi graphs make the line graphs sparse, resulting in the zero graphon.",
        "subjects": [
            "stat.ML",
            "cs.DM",
            "cs.LG",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01668",
        "abstract url": "https://arxiv.org/abs/2409.01668",
        "title": "Pureformer-VC: Non-parallel One-Shot Voice Conversion with Pure Transformer Blocks and Triplet Discriminative Training",
        "rating": "-0.5",
        "keywords": [
            [
                "Voice Conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "One-shot voice conversion(VC) aims to change the timbre of any source speech to match that of the unseen target speaker with only one speech sample. Existing style transfer-based VC methods relied on speech representation disentanglement and suffered from accurately and independently encoding each speech component and recomposing back to converted speech effectively. To tackle this, we proposed Pureformer-VC, which utilizes Conformer blocks to build a disentangled encoder, and Zipformer blocks to build a style transfer decoder as the generator. In the decoder, we used effective styleformer blocks to integrate speaker characteristics into the generated speech effectively. The models used the generative VAE loss for encoding components and triplet loss for unsupervised discriminative training. We applied the styleformer method to Zipformer's shared weights for style transfer. The experimental results show that the proposed model achieves comparable subjective scores and exhibits improvements in objective metrics compared to existing methods in a one-shot voice conversion scenario.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "submmited to ICASSP 2025"
    },
    {
        "paper id": "2409.01690",
        "abstract url": "https://arxiv.org/abs/2409.01690",
        "title": "Taming CLIP for Fine-grained and Structured Visual Understanding of Museum Exhibits",
        "rating": "-0.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.CV",
                "cs.CL"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "CLIP is a powerful and widely used tool for understanding images in the context of natural language descriptions to perform nuanced tasks. However, it does not offer application-specific fine-grained and structured understanding, due to its generic nature. In this work, we aim to adapt CLIP for fine-grained and structured -- in the form of tabular data -- visual understanding of museum exhibits. To facilitate such understanding we (a) collect, curate, and benchmark a dataset of 200K+ image-table pairs, and (b) develop a method that allows predicting tabular outputs for input images. Our dataset is the first of its kind in the public domain. At the same time, the proposed method is novel in leveraging CLIP's powerful representations for fine-grained and tabular understanding. The proposed method (MUZE) learns to map CLIP's image embeddings to the tabular structure by means of a proposed transformer-based parsing network (parseNet). More specifically, parseNet enables prediction of missing attribute values while integrating context from known attribute-value pairs for an input image. We show that this leads to significant improvement in accuracy. Through exhaustive experiments, we show the effectiveness of the proposed method on fine-grained and structured understanding of museum exhibits, by achieving encouraging results in a newly established benchmark. Our dataset and source-code can be found at: https://github.com/insait-institute/MUZE",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Accepted to ECCV 2024"
    },
    {
        "paper id": "2409.01713",
        "abstract url": "https://arxiv.org/abs/2409.01713",
        "title": "Interpreting Outliers in Time Series Data through Decoding Autoencoder",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Outlier detection is a crucial analytical tool in various fields. In critical systems like manufacturing, malfunctioning outlier detection can be costly and safety-critical. Therefore, there is a significant need for explainable artificial intelligence (XAI) when deploying opaque models in such environments. This study focuses on manufacturing time series data from a German automotive supply industry. We utilize autoencoders to compress the entire time series and then apply anomaly detection techniques to its latent features. For outlier interpretation, we (i) adopt widely used XAI techniques to the autoencoder's encoder. Additionally, (ii) we propose AEE, Aggregated Explanatory Ensemble, a novel approach that fuses explanations of multiple XAI techniques into a single, more expressive interpretation. For evaluation of explanations, (iii) we propose a technique to measure the quality of encoder explanations quantitatively. Furthermore, we qualitatively assess the effectiveness of outlier explanations with domain expertise.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "14 pages, 8 figures, accepted at TempXAI @ ECML-PKDD"
    },
    {
        "paper id": "2409.01730",
        "abstract url": "https://arxiv.org/abs/2409.01730",
        "title": "Federated Prediction-Powered Inference from Decentralized Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In various domains, the increasing application of machine learning allows researchers to access inexpensive predictive data, which can be utilized as auxiliary data for statistical inference. Although such data are often unreliable compared to gold-standard datasets, Prediction-Powered Inference (PPI) has been proposed to ensure statistical validity despite the unreliability. However, the challenge of `data silos' arises when the private gold-standard datasets are non-shareable for model training, leading to less accurate predictive models and invalid inferences. In this paper, we introduces the Federated Prediction-Powered Inference (Fed-PPI) framework, which addresses this challenge by enabling decentralized experimental data to contribute to statistically valid conclusions without sharing private information. The Fed-PPI framework involves training local models on private data, aggregating them through Federated Learning (FL), and deriving confidence intervals using PPI computation. The proposed framework is evaluated through experiments, demonstrating its effectiveness in producing valid confidence intervals.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01832",
        "abstract url": "https://arxiv.org/abs/2409.01832",
        "title": "Beyond Unconstrained Features: Neural Collapse for Shallow Neural Networks with General Data",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural collapse (NC) is a phenomenon that emerges at the terminal phase of the training (TPT) of deep neural networks (DNNs). The features of the data in the same class collapse to their respective sample means and the sample means exhibit a simplex equiangular tight frame (ETF). In the past few years, there has been a surge of works that focus on explaining why the NC occurs and how it affects generalization. Since the DNNs are notoriously difficult to analyze, most works mainly focus on the unconstrained feature model (UFM). While the UFM explains the NC to some extent, it fails to provide a complete picture of how the network architecture and the dataset affect NC. In this work, we focus on shallow ReLU neural networks and try to understand how the width, depth, data dimension, and statistical property of the training dataset influence the neural collapse. We provide a complete characterization of when the NC occurs for two or three-layer neural networks. For two-layer ReLU neural networks, a sufficient condition on when the global minimizer of the regularized empirical risk function exhibits the NC configuration depends on the data dimension, sample size, and the signal-to-noise ratio in the data instead of the network width. For three-layer neural networks, we show that the NC occurs as long as the first layer is sufficiently wide. Regarding the connection between NC and generalization, we show the generalization heavily depends on the SNR (signal-to-noise ratio) in the data: even if the NC occurs, the generalization can still be bad provided that the SNR in the data is too low. Our results significantly extend the state-of-the-art theoretical analysis of the N C under the UFM by characterizing the emergence of the N C under shallow nonlinear networks and showing how it depends on data properties and network architecture.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01952",
        "abstract url": "https://arxiv.org/abs/2409.01952",
        "title": "Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) have long been recognized as vulnerable to backdoor attacks. By providing poisoned training data in the fine-tuning process, the attacker can implant a backdoor into the victim model. This enables input samples meeting specific textual trigger patterns to be classified as target labels of the attacker's choice. While such black-box attacks have been well explored in both computer vision and natural language processing (NLP), backdoor attacks relying on white-box attack philosophy have hardly been thoroughly investigated. In this paper, we take the first step to introduce a new type of backdoor attack that conceals itself within the underlying model architecture. Specifically, we pcricKet1996!ropose to design separate backdoor modules consisting of two functions: trigger detection and noise injection. The add-on modules of model architecture layers can detect the presence of input trigger tokens and modify layer weights using Gaussian noise to disturb the feature distribution of the baseline model. We conduct extensive experiments to evaluate our attack methods using two model architecture settings on five different large language datasets. We demonstrate that the training-free architectural backdoor on a large language model poses a genuine threat. Unlike the-state-of-art work, it can survive the rigorous fine-tuning and retraining process, as well as evade output probability-based defense methods (i.e. BDDR). All the code and data is available https://github.com/SiSL-URI/Arch_Backdoor_LLM.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01989",
        "abstract url": "https://arxiv.org/abs/2409.01989",
        "title": "Improving Electrolyte Performance for Target Cathode Loading Using Interpretable Data-Driven Approach",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Higher loading of active electrode materials is desired in batteries, especially those based on conversion reactions, for enhanced energy density and cost efficiency. However, increasing active material loading in electrodes can cause significant performance depreciation due to internal resistance, shuttling, and parasitic side reactions, which can be alleviated to a certain extent by a compatible design of electrolytes. In this work, a data-driven approach is leveraged to find a high-performing electrolyte formulation for a novel interhalogen battery custom to the target cathode loading. An electrolyte design consisting of 4 solvents and 4 salts is experimentally devised for a novel interhalogen battery based on a multi-electron redox reaction. The experimental dataset with variable electrolyte compositions and active cathode loading, is used to train a graph-based deep learning model mapping changing variables in the battery's material design to its specific capacity. The trained model is used to further optimize the electrolyte formulation compositions for enhancing the battery capacity at a target cathode loading by a two-fold approach: large-scale screening and interpreting electrolyte design principles for different cathode loadings. The data-driven approach is demonstrated to bring about an additional 20% increment in the specific capacity of the battery over capacities obtained from the experimental optimization.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cond-mat.mtrl-sci"
        ],
        "comment": "34 Pages, 5 Figures, 2 Tables"
    },
    {
        "paper id": "2409.01992",
        "abstract url": "https://arxiv.org/abs/2409.01992",
        "title": "QueryCheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Query-based systems (QBSs) are one of the key approaches for sharing data. QBSs allow analysts to request aggregate information from a private protected dataset. Attacks are a crucial part of ensuring QBSs are truly privacy-preserving. The development and testing of attacks is however very labor-intensive and unable to cope with the increasing complexity of systems. Automated approaches have been shown to be promising but are currently extremely computationally intensive, limiting their applicability in practice. We here propose QueryCheetah, a fast and effective method for automated discovery of privacy attacks against QBSs. We instantiate QueryCheetah on attribute inference attacks and show it to discover stronger attacks than previous methods while being 18 times faster than the state-of-the-art automated approach. We then show how QueryCheetah allows system developers to thoroughly evaluate the privacy risk, including for various attacker strengths and target individuals. We finally show how QueryCheetah can be used out-of-the-box to find attacks in larger syntaxes and workarounds around ad-hoc defenses.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "This is an extended version of the ACM CCS paper which includes appendices"
    },
    {
        "paper id": "2409.02006",
        "abstract url": "https://arxiv.org/abs/2409.02006",
        "title": "Robust Fitting on a Gate Quantum Computer",
        "rating": "-0.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Gate quantum computers generate significant interest due to their potential to solve certain difficult problems such as prime factorization in polynomial time. Computer vision researchers have long been attracted to the power of quantum computers. Robust fitting, which is fundamentally important to many computer vision pipelines, has recently been shown to be amenable to gate quantum computing. The previous proposed solution was to compute Boolean influence as a measure of outlyingness using the Bernstein-Vazirani quantum circuit. However, the method assumed a quantum implementation of an $\\ell_\\infty$ feasibility test, which has not been demonstrated. In this paper, we take a big stride towards quantum robust fitting: we propose a quantum circuit to solve the $\\ell_\\infty$ feasibility test in the 1D case, which allows to demonstrate for the first time quantum robust fitting on a real gate quantum computer, the IonQ Aria. We also show how 1D Boolean influences can be accumulated to compute Boolean influences for higher-dimensional non-linear models, which we experimentally validate on real benchmark datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by the European Conference on Computer Vision 2024 (ECCV2024) as Oral. The paper is written for a computer vision audience who generally has minimal quantum physics background"
    },
    {
        "paper id": "2409.02064",
        "abstract url": "https://arxiv.org/abs/2409.02064",
        "title": "Personalized Federated Learning via Active Sampling",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Consider a collection of data generators which could represent, e.g., humans equipped with a smart-phone or wearables. We want to train a personalized (or tailored) model for each data generator even if they provide only small local datasets. The available local datasets might fail to provide sufficient statistical power to train high-dimensional models (such as deep neural networks) effectively. One possible solution is to identify similar data generators and pool their local datasets to obtain a sufficiently large training set. This paper proposes a novel method for sequentially identifying similar (or relevant) data generators. Our method is similar in spirit to active sampling methods but does not require exchange of raw data. Indeed, our method evaluates the relevance of a data generator by evaluating the effect of a gradient step using its local dataset. This evaluation can be performed in a privacy-friendly fashion without sharing raw data. We extend this method to non-parametric models by a suitable generalization of the gradient step to update a hypothesis using the local dataset provided by a data generator.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02074",
        "abstract url": "https://arxiv.org/abs/2409.02074",
        "title": "RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Malicious shell commands are linchpins to many cyber-attacks, but may not be easy to understand by security analysts due to complicated and often disguised code structures. Advances in large language models (LLMs) have unlocked the possibility of generating understandable explanations for shell commands. However, existing general-purpose LLMs suffer from a lack of expert knowledge and a tendency to hallucinate in the task of shell command explanation. In this paper, we present Raconteur, a knowledgeable, expressive and portable shell command explainer powered by LLM. Raconteur is infused with professional knowledge to provide comprehensive explanations on shell commands, including not only what the command does (i.e., behavior) but also why the command does it (i.e., purpose). To shed light on the high-level intent of the command, we also translate the natural-language-based explanation into standard technique & tactic defined by MITRE ATT&CK, the worldwide knowledge base of cybersecurity. To enable Raconteur to explain unseen private commands, we further develop a documentation retriever to obtain relevant information from complementary documentations to assist the explanation process. We have created a large-scale dataset for training and conducted extensive experiments to evaluate the capability of Raconteur in shell command explanation. The experiments verify that Raconteur is able to provide high-quality explanations and in-depth insight of the intent of the command.",
        "subjects": [
            "cs.CR",
            "cs.HC",
            "cs.LG",
            "cs.SE"
        ],
        "comment": "Accepted by NDSS Symposium 2025. Please cite this paper as \"Jiangyi Deng, Xinfeng Li, Yanjiao Chen, Yijie Bai, Haiqin Weng, Yan Liu, Tao Wei, Wenyuan Xu. RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer. In the 32nd Annual Network and Distributed System Security Symposium (NDSS 2025).\""
    },
    {
        "paper id": "2409.01608",
        "abstract url": "https://arxiv.org/abs/2409.01608",
        "title": "LiDAR-Aided Millimeter-Wave Range Extension using a Passive Mirror Reflector",
        "rating": "-1",
        "keywords": [
            [
                "LiDAR"
            ]
        ],
        "abstract": "Passive reflectors mitigate millimeter-wave (mmwave) link blockages by extending coverage to non-line-ofsight (NLoS) regions. However, their deployment often leads to irregular reflected beam patterns and coverage gaps. This results in rapid channel fluctuations and potential outages. In this paper, we propose two LiDAR-aided link enhancement techniques to address these challenges. Leveraging user position information, we introduce a location-dependent link control strategy and a user selection technique to improve NLoS link reliability and coverage. Experimental results validate the efficacy of the proposed techniques in reducing outages and enhancing NLoS signal strength.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01617",
        "abstract url": "https://arxiv.org/abs/2409.01617",
        "title": "High Precision Positioning System",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "SAPPO is a high-precision, low-cost and highly scalable indoor localization system. The system is designed using modified HC-SR04 ultrasound transducers as a base to be used as distance meters between beacons and mobile robots. Additionally, it has a very unusual arrangement of its elements, such that the beacons and the array of transmitters of the mobile robot are located in very close planes, in a horizontal emission arrangement, parallel to the ground, achieving a range per transducer of almost 12 meters. SAPPO represents a significant leap forward in ultrasound localization systems, in terms of reducing the density of beacons while maintaining average precision in the millimeter range.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "in Spanish language"
    },
    {
        "paper id": "2409.01622",
        "abstract url": "https://arxiv.org/abs/2409.01622",
        "title": "T1-contrast Enhanced MRI Generation from Multi-parametric MRI for Glioma Patients with Latent Tumor Conditioning",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "Tumor"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Objective: Gadolinium-based contrast agents (GBCAs) are commonly used in MRI scans of patients with gliomas to enhance brain tumor characterization using T1-weighted (T1W) MRI. However, there is growing concern about GBCA toxicity. This study develops a deep-learning framework to generate T1-postcontrast (T1C) from pre-contrast multiparametric MRI. Approach: We propose the tumor-aware vision transformer (TA-ViT) model that predicts high-quality T1C images. The predicted tumor region is significantly improved (P < .001) by conditioning the transformer layers from predicted segmentation maps through adaptive layer norm zero mechanism. The predicted segmentation maps were generated with the multi-parametric residual (MPR) ViT model and transformed into a latent space to produce compressed, feature-rich representations. The TA-ViT model predicted T1C MRI images of 501 glioma cases. Selected patients were split into training (N=400), validation (N=50), and test (N=51) sets. Main Results: Both qualitative and quantitative results demonstrate that the TA-ViT model performs superior against the benchmark MRP-ViT model. Our method produces synthetic T1C MRI with high soft tissue contrast and more accurately reconstructs both the tumor and whole brain volumes. The synthesized T1C images achieved remarkable improvements in both tumor and healthy tissue regions compared to the MRP-ViT model. For healthy tissue and tumor regions, the results were as follows: NMSE: 8.53 +/- 4.61E-4; PSNR: 31.2 +/- 2.2; NCC: 0.908 +/- .041 and NMSE: 1.22 +/- 1.27E-4, PSNR: 41.3 +/- 4.7, and NCC: 0.879 +/- 0.042, respectively. Significance: The proposed method generates synthetic T1C images that closely resemble real T1C images. Future development and application of this approach may enable contrast-agent-free MRI for brain tumor patients, eliminating the risk of GBCA toxicity and simplifying the MRI scan protocol.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2407.02616"
    },
    {
        "paper id": "2409.01647",
        "abstract url": "https://arxiv.org/abs/2409.01647",
        "title": "Correlation Properties in Channels with von Mises-Fisher Distribution of Scatterers",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "This letter presents simple analytical expressions for the spatial and temporal correlation functions in channels with von Mises-Fisher (vMF) scattering. In contrast to previous results, the expressions presented here are exact and based only on elementary functions, clearly revealing the impact of the underlying parameters. The derived results are validated by a comparison against numerical integration result, where an exact match is observed. To demonstrate their utility, the presented results are used to analyze spatial correlation across different antenna array geometries and to investigate temporal correlation of a fluctuating radar signal from a moving target.",
        "subjects": [
            "eess.SP",
            "stat.OT"
        ],
        "comment": "Submitted to IEEE Wireless Communications Letters (submitted on 2024-05-14; revised and resubmitted on 2024-08-26)"
    },
    {
        "paper id": "2409.01661",
        "abstract url": "https://arxiv.org/abs/2409.01661",
        "title": "$S^2$NeRF: Privacy-preserving Training Framework for NeRF",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "attack"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRF) have revolutionized 3D computer vision and graphics, facilitating novel view synthesis and influencing sectors like extended reality and e-commerce. However, NeRF's dependence on extensive data collection, including sensitive scene image data, introduces significant privacy risks when users upload this data for model training. To address this concern, we first propose SplitNeRF, a training framework that incorporates split learning (SL) techniques to enable privacy-preserving collaborative model training between clients and servers without sharing local data. Despite its benefits, we identify vulnerabilities in SplitNeRF by developing two attack methods, Surrogate Model Attack and Scene-aided Surrogate Model Attack, which exploit the shared gradient data and a few leaked scene images to reconstruct private scene information. To counter these threats, we introduce $S^2$NeRF, secure SplitNeRF that integrates effective defense mechanisms. By introducing decaying noise related to the gradient norm into the shared gradient information, $S^2$NeRF preserves privacy while maintaining a high utility of the NeRF model. Our extensive evaluations across multiple datasets demonstrate the effectiveness of $S^2$NeRF against privacy breaches, confirming its viability for secure NeRF training in sensitive applications.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "To appear in the ACM Conference on Computer and Communications Security (CCS'24), October 14-18, 2024, Salt Lake City, UT, USA"
    },
    {
        "paper id": "2409.01704",
        "abstract url": "https://arxiv.org/abs/2409.01704",
        "title": "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Traditional OCR systems (OCR-1.0) are increasingly unable to meet people's usage due to the growing demand for intelligent processing of man-made optical characters. In this paper, we collectively refer to all artificial optical signals (e.g., plain texts, math/molecular formulas, tables, charts, sheet music, and even geometric shapes) as \"characters\" and propose the General OCR Theory along with an excellent model, namely GOT, to promote the arrival of OCR-2.0. The GOT, with 580M parameters, is a unified, elegant, and end-to-end model, consisting of a high-compression encoder and a long-contexts decoder. As an OCR-2.0 model, GOT can handle all the above \"characters\" under various OCR tasks. On the input side, the model supports commonly used scene- and document-style images in slice and whole-page styles. On the output side, GOT can generate plain or formatted results (markdown/tikz/smiles/kern) via an easy prompt. Besides, the model enjoys interactive OCR features, i.e., region-level recognition guided by coordinates or colors. Furthermore, we also adapt dynamic resolution and multi-page OCR technologies to GOT for better practicality. In experiments, we provide sufficient results to prove the superiority of our model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01723",
        "abstract url": "https://arxiv.org/abs/2409.01723",
        "title": "Holes in Convex and Simple Drawings",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Gons and holes in point sets have been extensively studied in the literature. For simple drawings of the complete graph a generalization of the Erd\u0151s--Szekeres theorem is known and empty triangles have been investigated. We introduce a notion of $k$-holes for simple drawings and study their existence with respect to the convexity hierarchy. We present a family of simple drawings without 4-holes and prove a generalization of Gerken's empty hexagon theorem for convex drawings. A crucial intermediate step will be the structural investigation of pseudolinear subdrawings in convex~drawings.",
        "subjects": [
            "cs.CG",
            "cs.DM",
            "math.GT"
        ],
        "comment": "This article appears in the proceedings of GD2024"
    },
    {
        "paper id": "2409.01732",
        "abstract url": "https://arxiv.org/abs/2409.01732",
        "title": "Intersection Graphs with and without Product Structure",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "A graph class $\\mathcal{G}$ admits product structure if there exists a constant $k$ such that every $G \\in \\mathcal{G}$ is a subgraph of $H \\boxtimes P$ for a path $P$ and some graph $H$ of treewidth $k$. Famously, the class of planar graphs, as well as many beyond-planar graph classes are known to admit product structure. However, we have only few tools to prove the absence of product structure, and hence know of only a few interesting examples of classes. Motivated by the transition between product structure and no product structure, we investigate subclasses of intersection graphs in the plane (e.g., disk intersection graphs) and present necessary and sufficient conditions for these to admit product structure. Specifically, for a set $S \\subset \\mathbb{R}^2$ (e.g., a disk) and a real number $\u03b1\\in [0,1]$, we consider intersection graphs of $\u03b1$-free homothetic copies of $S$. That is, each vertex $v$ is a homothetic copy of $S$ of which at least an $\u03b1$-portion is not covered by other vertices, and there is an edge between $u$ and $v$ if and only if $u \\cap v \\neq \\emptyset$. For $\u03b1= 1$ we have contact graphs, which are in most cases planar, and hence admit product structure. For $\u03b1= 0$ we have (among others) all complete graphs, and hence no product structure. In general, there is a threshold value $\u03b1^*(S) \\in [0,1]$ such that $\u03b1$-free homothetic copies of $S$ admit product structure for all $\u03b1> \u03b1^*(S)$ and do not admit product structure for all $\u03b1< \u03b1^*(S)$. We show for a large family of sets $S$, including all triangles and all trapezoids, that it holds $\u03b1^*(S) = 1$, i.e., we have no product structure, except for the contact graphs (when $\u03b1= 1$). For other sets $S$, including regular $n$-gons for infinitely many values of $n$, we show that $0 < \u03b1^*(S) < 1$ by proving upper and lower bounds.",
        "subjects": [
            "math.CO",
            "cs.CG",
            "cs.DM"
        ],
        "comment": "An extended abstract of this paper appears in the proceedings of the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024)"
    },
    {
        "paper id": "2409.01733",
        "abstract url": "https://arxiv.org/abs/2409.01733",
        "title": "Improving the Crossing Lemma by Characterizing Dense 2-Planar and 3-Planar Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "The classical Crossing Lemma by Ajtai et al.~and Leighton from 1982 gave an important lower bound of $c \\frac{m^3}{n^2}$ for the number of crossings in any drawing of a given graph of $n$ vertices and $m$ edges. The original value was $c= 1/100$, which then has gradually been improved. Here, the bounds for the density of $k$-planar graphs played a central role. Our new insight is that for $k=2,3$ the $k$-planar graphs have substantially fewer edges if specific local configurations that occur in drawings of $k$-planar graphs of maximum density are forbidden. Therefore, we are able to derive better bounds for the crossing number $\\text{cr}(G)$ of a given graph $G$. In particular, we achieve a bound of $\\text{cr}(G) \\ge \\frac{73}{18}m-\\frac{305}{18}(n-2)$ for the range of $5n < m \\le 6n$, while our second bound $\\text{cr}(G) \\ge 5m - \\frac{407}{18}(n-2)$ is even stronger for larger $m>6n$. For $m > 6.79n$, we finally apply the standard probabilistic proof from the BOOK and obtain an improved constant of $c>1/27.61$ in the Crossing Lemma. Note that the previous constant was $1/29$. Although this improvement is not too impressive, we consider our technique as an important new tool, which might be helpful in various other applications.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01788",
        "abstract url": "https://arxiv.org/abs/2409.01788",
        "title": "DogeFuzz: A Simple Yet Efficient Grey-box Fuzzer for Ethereum Smart Contracts",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Ethereum is a distributed, peer-to-peer blockchain infrastructure that has attracted billions of dollars. Perhaps due to its success, Ethereum has become a target for various kinds of attacks, motivating researchers to explore different techniques to identify vulnerabilities in EVM bytecode (the language of the Ethereum Virtual Machine), including formal verification, symbolic execution, and fuzz testing. Although recent studies empirically compare smart contract fuzzers, there is a lack of literature investigating how simpler greybox fuzzers compare to more advanced ones. To fill this gap, in this paper, we present DogeFuzz, an extensible infrastructure for fuzzing Ethereum smart contracts, currently supporting black-box fuzzing and two grey-box fuzzing strategies: coverage-guided grey-box fuzzing (DogeFuzz-G) and directed grey-box fuzzing (DogeFuzz-DG). We conduct a series of experiments using benchmarks already available in the literature and compare the DogeFuzz strategies with state-of-the-art fuzzers for smart contracts. Surprisingly, although DogeFuzz does not leverage advanced techniques for improving input generation (such as symbolic execution or machine learning), DogeFuzz outperforms sFuzz and ILF, two state-of-the-art fuzzers. Nonetheless, the Smartian fuzzer shows higher code coverage and bug-finding capabilities than DogeFuzz.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": "16 pages,published in SBSEG 2024 conference"
    },
    {
        "paper id": "2409.01790",
        "abstract url": "https://arxiv.org/abs/2409.01790",
        "title": "Training on the Benchmark Is Not All You Need",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The success of Large Language Models (LLMs) relies heavily on the huge amount of pre-training data learned in the pre-training phase. The opacity of the pre-training process and the training data causes the results of many benchmark tests to become unreliable. If any model has been trained on a benchmark test set, it can seriously hinder the health of the field. In order to automate and efficiently test the capabilities of large language models, numerous mainstream benchmarks adopt a multiple-choice format. As the swapping of the contents of multiple-choice options does not affect the meaning of the question itself, we propose a simple and effective data leakage detection method based on this property. Specifically, we shuffle the contents of the options in the data to generate the corresponding derived data sets, and then detect data leakage based on the model's log probability distribution over the derived data sets. If there is a maximum and outlier in the set of log probabilities, it indicates that the data is leaked. Our method is able to work under black-box conditions without access to model training data or weights, effectively identifying data leakage from benchmark test sets in model pre-training data, including both normal scenarios and complex scenarios where options may have been shuffled intentionally or unintentionally. Through experiments based on two LLMs and benchmark designs, we demonstrate the effectiveness of our method. In addition, we evaluate the degree of data leakage of 31 mainstream open-source LLMs on four benchmark datasets and give a ranking of the leaked LLMs for each benchmark, and we find that the Qwen family of LLMs has the highest degree of data leakage.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01824",
        "abstract url": "https://arxiv.org/abs/2409.01824",
        "title": "DarthShader: Fuzzing WebGPU Shader Translators & Compilers",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "A recent trend towards running more demanding web applications, such as video games or client-side LLMs, in the browser has led to the adoption of the WebGPU standard that provides a cross-platform API exposing the GPU to websites. This opens up a new attack surface: Untrusted web content is passed through to the GPU stack, which traditionally has been optimized for performance instead of security. Worsening the problem, most of WebGPU cannot be run in the tightly sandboxed process that manages other web content, which eases the attacker's path to compromising the client machine. Contrasting its importance, WebGPU shader processing has received surprisingly little attention from the automated testing community. Part of the reason is that shader translators expect highly structured and statically typed input, which renders typical fuzzing mutations ineffective. Complicating testing further, shader translation consists of a complex multi-step compilation pipeline, each stage presenting unique requirements and challenges. In this paper, we propose DarthShader, the first language fuzzer that combines mutators based on an intermediate representation with those using a more traditional abstract syntax tree. The key idea is that the individual stages of the shader compilation pipeline are susceptible to different classes of faults, requiring entirely different mutation strategies for thorough testing. By fuzzing the full pipeline, we ensure that we maintain a realistic attacker model. In an empirical evaluation, we show that our method outperforms the state-of-the-art fuzzers regarding code coverage. Furthermore, an extensive ablation study validates our key design. DarthShader found a total of 39 software faults in all modern browsers -- Chrome, Firefox, and Safari -- that prior work missed. For 15 of them, the Chrome team assigned a CVE, acknowledging the impact of our results.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01825",
        "abstract url": "https://arxiv.org/abs/2409.01825",
        "title": "AstroMAE: Redshift Prediction Using a Masked Autoencoder with a Novel Fine-Tuning Architecture",
        "rating": "-1",
        "keywords": [
            [
                "astronomy"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Redshift prediction is a fundamental task in astronomy, essential for understanding the expansion of the universe and determining the distances of astronomical objects. Accurate redshift prediction plays a crucial role in advancing our knowledge of the cosmos. Machine learning (ML) methods, renowned for their precision and speed, offer promising solutions for this complex task. However, traditional ML algorithms heavily depend on labeled data and task-specific feature extraction. To overcome these limitations, we introduce AstroMAE, an innovative approach that pretrains a vision transformer encoder using a masked autoencoder method on Sloan Digital Sky Survey (SDSS) images. This technique enables the encoder to capture the global patterns within the data without relying on labels. To the best of our knowledge, AstroMAE represents the first application of a masked autoencoder to astronomical data. By ignoring labels during the pretraining phase, the encoder gathers a general understanding of the data. The pretrained encoder is subsequently fine-tuned within a specialized architecture tailored for redshift prediction. We evaluate our model against various vision transformer architectures and CNN-based models, demonstrating the superior performance of AstroMAEs pretrained model and fine-tuning architecture.",
        "subjects": [
            "cs.CV",
            "astro-ph.GA",
            "astro-ph.IM",
            "cs.CE",
            "cs.LG"
        ],
        "comment": "This paper has been accepted to 2024 IEEE 20th International Conference on e-Science"
    },
    {
        "paper id": "2409.01856",
        "abstract url": "https://arxiv.org/abs/2409.01856",
        "title": "Explicit Second-order LiDAR Bundle Adjustment Algorithm Using Mean Squared Group Metric",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Bundle Adjustment (BA) algorithm is a widely used nonlinear optimization technique in the backend of Simultaneous Localization and Mapping (SLAM) systems. By leveraging the co-view relationships of landmarks from multiple perspectives, it constructs a joint estimation model for both poses and landmarks, enabling the system to generate refined maps and reduce front-end localization errors. However, applying BA to LiDAR data presents unique challenges due to the large volume of 3D points typically present in point clouds, making robust and accurate model solving more complex. In this work, we propose a novel mean square group metric (MSGM). This metric applies mean square transformation to uniformly process the measurement of plane landmarks from a single perspective. The transformed metric ensures scale interpretability while avoiding the time-consuming point-by-point calculations. By integrating a robust kernel function, the metrics involved in the BA model are reweighted, enhancing the robustness of the solution process. On the basis of the proposed robust LiDAR BA model, we derived an explicit second-order estimator (RSO-BA). This estimator employs analytical formulas for Hessian and gradient calculations, ensuring the precision of the BA solution. We evaluated the proposed RSO-BA estimator against existing implicit second-order and explicit approximate second-order estimators using the publicly available datasets. The experimental results demonstrate that the RSO-BA estimator outperforms its counterparts regarding registration accuracy and robustness, particularly in large-scale or complex unstructured environments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01864",
        "abstract url": "https://arxiv.org/abs/2409.01864",
        "title": "The Role of Large Language Models in Musicology: Are We Ready to Trust the Machines?",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this work, we explore the use and reliability of Large Language Models (LLMs) in musicology. From a discussion with experts and students, we assess the current acceptance and concerns regarding this, nowadays ubiquitous, technology. We aim to go one step further, proposing a semi-automatic method to create an initial benchmark using retrieval-augmented generation models and multiple-choice question generation, validated by human experts. Our evaluation on 400 human-validated questions shows that current vanilla LLMs are less reliable than retrieval augmented generation from music dictionaries. This paper suggests that the potential of LLMs in musicology requires musicology driven research that can specialized LLMs by including accurate and reliable domain knowledge.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CL",
            "cs.DL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01889",
        "abstract url": "https://arxiv.org/abs/2409.01889",
        "title": "Weakly Leveled Planarity with Bounded Span",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This paper studies planar drawings of graphs in which each vertex is represented as a point along a sequence of horizontal lines, called levels, and each edge is either a horizontal segment or a strictly $y$-monotone curve. A graph is $s$-span weakly leveled planar if it admits such a drawing where the edges have span at most $s$; the span of an edge is the number of levels it touches minus one. We investigate the problem of computing $s$-span weakly leveled planar drawings from both the computational and the combinatorial perspectives. We prove the problem to be para-NP-hard with respect to its natural parameter $s$ and investigate its complexity with respect to widely used structural parameters. We show the existence of a polynomial-size kernel with respect to vertex cover number and prove that the problem is FPT when parameterized by treedepth. We also present upper and lower bounds on the span for various graph classes. Notably, we show that cycle trees, a family of $2$-outerplanar graphs generalizing Halin graphs, are $\u0398(\\log n)$-span weakly leveled planar and $4$-span weakly leveled planar when $3$-connected. As a byproduct of these combinatorial results, we obtain improved bounds on the edge-length ratio of the graph families under consideration.",
        "subjects": [
            "cs.CG",
            "cs.DS"
        ],
        "comment": "Appears in the Proceedings of the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024)"
    },
    {
        "paper id": "2409.01928",
        "abstract url": "https://arxiv.org/abs/2409.01928",
        "title": "Comprehensive Equity Index (CEI): Definition and Application to Bias Evaluation in Biometrics",
        "rating": "-1",
        "keywords": [
            [
                "Biometrics"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We present a novel metric designed, among other applications, to quantify biased behaviors of machine learning models. As its core, the metric consists of a new similarity metric between score distributions that balances both their general shapes and tails' probabilities. In that sense, our proposed metric may be useful in many application areas. Here we focus on and apply it to the operational evaluation of face recognition systems, with special attention to quantifying demographic biases; an application where our metric is especially useful. The topic of demographic bias and fairness in biometric recognition systems has gained major attention in recent years. The usage of these systems has spread in society, raising concerns about the extent to which these systems treat different population groups. A relevant step to prevent and mitigate demographic biases is first to detect and quantify them. Traditionally, two approaches have been studied to quantify differences between population groups in machine learning literature: 1) measuring differences in error rates, and 2) measuring differences in recognition score distributions. Our proposed Comprehensive Equity Index (CEI) trade-offs both approaches combining both errors from distribution tails and general distribution shapes. This new metric is well suited to real-world scenarios, as measured on NIST FRVT evaluations, involving high-performance systems and realistic face databases including a wide range of covariates and demographic groups. We first show the limitations of existing metrics to correctly assess the presence of biases in realistic setups and then propose our new metric to tackle these limitations. We tested the proposed metric with two state-of-the-art models and four widely used databases, showing its capacity to overcome the main flaws of previous bias metrics.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted paper for the 27th International Conference on Pattern Recognition (ICPR) 2024"
    },
    {
        "paper id": "2409.01941",
        "abstract url": "https://arxiv.org/abs/2409.01941",
        "title": "Towards Leveraging Large Language Models for Automated Medical Q&A Evaluation",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper explores the potential of using Large Language Models (LLMs) to automate the evaluation of responses in medical Question and Answer (Q\\&A) systems, a crucial form of Natural Language Processing. Traditionally, human evaluation has been indispensable for assessing the quality of these responses. However, manual evaluation by medical professionals is time-consuming and costly. Our study examines whether LLMs can reliably replicate human evaluations by using questions derived from patient data, thereby saving valuable time for medical experts. While the findings suggest promising results, further research is needed to address more specific or complex questions that were beyond the scope of this initial investigation.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "10 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2409.01955",
        "abstract url": "https://arxiv.org/abs/2409.01955",
        "title": "Adaptive Stochastic Predictive Control from Noisy Data: A Sampling-based Approach",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "In this work, an adaptive predictive control scheme for linear systems with unknown parameters and bounded additive disturbances is proposed. In contrast to related adaptive control approaches that robustly consider the parametric uncertainty, the proposed method handles all uncertainties stochastically by employing an online adaptive sampling-based approximation of chance constraints. The approach requires initial data in the form of a short input-output trajectory and distributional knowledge of the disturbances. This prior knowledge is used to construct an initial set of data-consistent system parameters and a distribution that allows for sample generation. As new data stream in online, the set of consistent system parameters is adapted by exploiting set membership identification. Consequently, chance constraints are deterministically approximated using a probabilistic scaling approach by sampling from the set of system parameters. In combination with a robust constraint on the first predicted step, recursive feasibility of the proposed predictive controller and closed-loop constraint satisfaction are guaranteed. A numerical example demonstrates the efficacy of the proposed method.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted for presentation at the 63rd IEEE Conference on Decision and Control (CDC2024)"
    },
    {
        "paper id": "2409.01965",
        "abstract url": "https://arxiv.org/abs/2409.01965",
        "title": "Exploiting Six-Dimensional Movable Antenna for Wireless Sensing",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Six-dimensional movable antenna (6DMA) is an emerging technology that is able to fully exploit the spatial variation of wireless channels by controlling the 3D positions and 3D rotations of distributed antennas/antenna surfaces at the transmitter/receiver. In this letter, we apply 6DMA at the base station (BS) to enhance its wireless sensing performance over a given set of regions. To this end, we first divide each region into a number of equal-size subregions and select one typical target location within each subregion. Then, we derive an expression for the Cramer-Rao bound (CRB) for estimating the directions of arrival (DoAs) from these typical target locations in all regions, which sheds light on the sensing performance of 6DMA enhanced systems in terms of a power gain and a geometric gain. Next, we minimize the CRB for DoA estimation via jointly optimizing the positions and rotations of all 6DMAs at the BS, subject to practical movement constraints, and propose an efficient algorithm to solve the resulting non-convex optimization problem sub-optimally. Finally, simulation results demonstrate the significant improvement in DoA estimation accuracy achieved by the proposed 6DMA sensing scheme as compared to various benchmark schemes, for both isotropic and directive antenna radiation patterns.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "5 figures"
    },
    {
        "paper id": "2409.01975",
        "abstract url": "https://arxiv.org/abs/2409.01975",
        "title": "1DCNNTrans: BISINDO Sign Language Interpreters in Improving the Inclusiveness of Public Services",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Indonesia ranks fourth globally in the number of deaf cases. Individuals with hearing impairments often find communication challenging, necessitating the use of sign language. However, there are limited public services that offer such inclusivity. On the other hand, advancements in artificial intelligence (AI) present promising solutions to overcome communication barriers faced by the deaf. This study aims to explore the application of AI in developing models for a simplified sign language translation app and dictionary, designed for integration into public service facilities, to facilitate communication for individuals with hearing impairments, thereby enhancing inclusivity in public services. The researchers compared the performance of LSTM and 1D CNN + Transformer (1DCNNTrans) models for sign language recognition. Through rigorous testing and validation, it was found that the LSTM model achieved an accuracy of 94.67%, while the 1DCNNTrans model achieved an accuracy of 96.12%. Model performance evaluation indicated that although the LSTM exhibited lower inference latency, it showed weaknesses in classifying classes with similar keypoints. In contrast, the 1DCNNTrans model demonstrated greater stability and higher F1 scores for classes with varying levels of complexity compared to the LSTM model. Both models showed excellent performance, exceeding 90% validation accuracy and demonstrating rapid classification of 50 sign language gestures.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.01988",
        "abstract url": "https://arxiv.org/abs/2409.01988",
        "title": "Compressed learning based onboard semantic compression for remote sensing platforms",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Earth observation (EO) plays a crucial role in creating and sustaining a resilient and prosperous society that has far reaching consequences for all life and the planet itself. Remote sensing platforms like satellites, airborne platforms, and more recently dones and UAVs are used for EO. They collect large amounts of data and this needs to be downlinked to Earth for further processing and analysis. Bottleneck for such high throughput acquisition is the downlink bandwidth. Data-centric solutions to image compression is required to address this deluge. In this work, semantic compression is studied through a compressed learning framework that utilizes only fast and sparse matrix-vector multiplication to encode the data. Camera noise and a communication channel are the considered sources of distortion. The complete semantic communication pipeline then consists of a learned low-complexity compression matrix that acts on the noisy camera output to generate onboard a vector of observations that is downlinked through a communication channel, processed through an unrolled network and then fed to a deep learning model performing the necessary downstream tasks; image classification is studied. Distortions are compensated by unrolling layers of NA-ALISTA with a wavelet sparsity prior. Decoding is thus a plug-n-play approach designed according to the camera/environment information and downstream task. The deep learning model for the downstream task is jointly fine-tuned with the compression matrix and the unrolled network through the loss function in an end-to-end fashion. It is shown that addition of a recovery loss along with the task dependent losses improves the downstream performance in noisy settings at low compression ratios.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01995",
        "abstract url": "https://arxiv.org/abs/2409.01995",
        "title": "vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders",
        "rating": "-1",
        "keywords": [
            [
                "Voice Conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We propose a new speech discrete token vocoder, vec2wav 2.0, which advances voice conversion (VC). We use discrete tokens from speech self-supervised models as the content features of source speech, and treat VC as a prompted vocoding task. To amend the loss of speaker timbre in the content tokens, vec2wav 2.0 utilizes the WavLM features to provide strong timbre-dependent information. A novel adaptive Snake activation function is proposed to better incorporate timbre into the waveform reconstruction process. In this way, vec2wav 2.0 learns to alter the speaker timbre appropriately given different reference prompts. Also, no supervised data is required for vec2wav 2.0 to be effectively trained. Experimental results demonstrate that vec2wav 2.0 outperforms all other baselines to a considerable margin in terms of audio quality and speaker similarity in any-to-any VC. Ablation studies verify the effects made by the proposed techniques. Moreover, vec2wav 2.0 achieves competitive cross-lingual VC even only trained on monolingual corpus. Thus, vec2wav 2.0 shows timbre can potentially be manipulated only by speech token vocoders, pushing the frontiers of VC and speech synthesis.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2409.02011",
        "abstract url": "https://arxiv.org/abs/2409.02011",
        "title": "Deep learning for objective estimation of Parkinsonian tremor severity",
        "rating": "-1",
        "keywords": [
            [
                "disease",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate assessment of Parkinsonian tremor is vital for monitoring disease progression and evaluating treatment efficacy. We introduce a pixel-based deep learning model designed to analyse postural tremor in Parkinson's disease (PD) from video data, overcoming the limitations of traditional pose estimation techniques. Trained on 2,742 assessments from five specialised movement disorder centres across two continents, the model demonstrated robust concordance with clinical evaluations. It effectively predicted treatment effects for levodopa and deep brain stimulation (DBS), detected lateral asymmetry of symptoms, and differentiated between different tremor severities. Feature space analysis revealed a non-linear, structured distribution of tremor severity, with low-severity scores occupying a larger portion of the feature space. The model also effectively identified outlier videos, suggesting its potential for adaptive learning and quality control in clinical settings. Our approach offers a scalable and objective method for tremor scoring, with potential integration into other MDS-UPDRS motor assessments, including bradykinesia and gait. The system's adaptability and performance underscore its promise for high-frequency, longitudinal monitoring of PD symptoms, complementing clinical expertise and enhancing decision-making in patient management. Future work will extend this pixel-based methodology to other cardinal symptoms of PD, aiming to develop a comprehensive, multi-symptom model for automated Parkinson's disease severity assessment.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02018",
        "abstract url": "https://arxiv.org/abs/2409.02018",
        "title": "TransDAE: Dual Attention Mechanism in a Hierarchical Transformer for Efficient Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare",
                "diagnosis",
                "disease",
                "organ"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In healthcare, medical image segmentation is crucial for accurate disease diagnosis and the development of effective treatment strategies. Early detection can significantly aid in managing diseases and potentially prevent their progression. Machine learning, particularly deep convolutional neural networks, has emerged as a promising approach to addressing segmentation challenges. Traditional methods like U-Net use encoding blocks for local representation modeling and decoding blocks to uncover semantic relationships. However, these models often struggle with multi-scale objects exhibiting significant variations in texture and shape, and they frequently fail to capture long-range dependencies in the input data. Transformers designed for sequence-to-sequence predictions have been proposed as alternatives, utilizing global self-attention mechanisms. Yet, they can sometimes lack precise localization due to insufficient granular details. To overcome these limitations, we introduce TransDAE: a novel approach that reimagines the self-attention mechanism to include both spatial and channel-wise associations across the entire feature space, while maintaining computational efficiency. Additionally, TransDAE enhances the skip connection pathway with an inter-scale interaction module, promoting feature reuse and improving localization accuracy. Remarkably, TransDAE outperforms existing state-of-the-art methods on the Synaps multi-organ dataset, even without relying on pre-trained weights.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02035",
        "abstract url": "https://arxiv.org/abs/2409.02035",
        "title": "A Modern Take on Visual Relationship Reasoning for Grasp Planning",
        "rating": "-1",
        "keywords": [
            [
                "robotic manipulation"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Interacting with real-world cluttered scenes pose several challenges to robotic agents that need to understand complex spatial dependencies among the observed objects to determine optimal pick sequences or efficient object retrieval strategies. Existing solutions typically manage simplified scenarios and focus on predicting pairwise object relationships following an initial object detection phase, but often overlook the global context or struggle with handling redundant and missing object relations. In this work, we present a modern take on visual relational reasoning for grasp planning. We introduce D3GD, a novel testbed that includes bin picking scenes with up to 35 objects from 97 distinct categories. Additionally, we propose D3G, a new end-to-end transformer-based dependency graph generation model that simultaneously detects objects and produces an adjacency matrix representing their spatial relationships. Recognizing the limitations of standard metrics, we employ the Average Precision of Relationships for the first time to evaluate model performance, conducting an extensive experimental benchmark. The obtained results establish our approach as the new state-of-the-art for this task, laying the foundation for future research in robotic manipulation. We publicly release the code and dataset at https://paolotron.github.io/d3g.github.io.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02038",
        "abstract url": "https://arxiv.org/abs/2409.02038",
        "title": "BEAVER: An Enterprise Benchmark for Text-to-SQL",
        "rating": "-1",
        "keywords": [
            [
                "SQL"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Existing text-to-SQL benchmarks have largely been constructed using publicly available tables from the web with human-generated tests containing question and SQL statement pairs. They typically show very good results and lead people to think that LLMs are effective at text-to-SQL tasks. In this paper, we apply off-the-shelf LLMs to a benchmark containing enterprise data warehouse data. In this environment, LLMs perform poorly, even when standard prompt engineering and RAG techniques are utilized. As we will show, the reasons for poor performance are largely due to three characteristics: (1) public LLMs cannot train on enterprise data warehouses because they are largely in the \"dark web\", (2) schemas of enterprise tables are more complex than the schemas in public data, which leads the SQL-generation task innately harder, and (3) business-oriented questions are often more complex, requiring joins over multiple tables and aggregations. As a result, we propose a new dataset BEAVER, sourced from real enterprise data warehouses together with natural language queries and their correct SQL statements which we collected from actual user history. We evaluated this dataset using recent LLMs and demonstrated their poor performance on this task. We hope this dataset will facilitate future researchers building more sophisticated text-to-SQL systems which can do better on this important class of data.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02046",
        "abstract url": "https://arxiv.org/abs/2409.02046",
        "title": "Human-AI Collaborative Multi-modal Multi-rater Learning for Endometriosis Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "surgery",
                "Diagnosis",
                "MRI",
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Endometriosis, affecting about 10\\% of individuals assigned female at birth, is challenging to diagnose and manage. Diagnosis typically involves the identification of various signs of the disease using either laparoscopic surgery or the analysis of T1/T2 MRI images, with the latter being quicker and cheaper but less accurate. A key diagnostic sign of endometriosis is the obliteration of the Pouch of Douglas (POD). However, even experienced clinicians struggle with accurately classifying POD obliteration from MRI images, which complicates the training of reliable AI models. In this paper, we introduce the \\underline{H}uman-\\underline{AI} \\underline{Co}llaborative \\underline{M}ulti-modal \\underline{M}ulti-rater Learning (HAICOMM) methodology to address the challenge above. HAICOMM is the first method that explores three important aspects of this problem: 1) multi-rater learning to extract a cleaner label from the multiple ``noisy'' labels available per training sample; 2) multi-modal learning to leverage the presence of T1/T2 MRI images for training and testing; and 3) human-AI collaboration to build a system that leverages the predictions from clinicians and the AI model to provide more accurate classification than standalone clinicians and AI models. Presenting results on the multi-rater T1/T2 MRI endometriosis dataset that we collected to validate our methodology, the proposed HAICOMM model outperforms an ensemble of clinicians, noisy-label learning models, and multi-rater learning methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02056",
        "abstract url": "https://arxiv.org/abs/2409.02056",
        "title": "F2former: When Fractional Fourier Meets Deep Wiener Deconvolution and Selective Frequency Transformer for Image Deblurring",
        "rating": "-1",
        "keywords": [
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent progress in image deblurring techniques focuses mainly on operating in both frequency and spatial domains using the Fourier transform (FT) properties. However, their performance is limited due to the dependency of FT on stationary signals and its lack of capability to extract spatial-frequency properties. In this paper, we propose a novel approach based on the Fractional Fourier Transform (FRFT), a unified spatial-frequency representation leveraging both spatial and frequency components simultaneously, making it ideal for processing non-stationary signals like images. Specifically, we introduce a Fractional Fourier Transformer (F2former), where we combine the classical fractional Fourier based Wiener deconvolution (F2WD) as well as a multi-branch encoder-decoder transformer based on a new fractional frequency aware transformer block (F2TB). We design F2TB consisting of a fractional frequency aware self-attention (F2SA) to estimate element-wise product attention based on important frequency components and a novel feed-forward network based on frequency division multiplexing (FM-FFN) to refine high and low frequency features separately for efficient latent clear image restoration. Experimental results for the cases of both motion deblurring as well as defocus deblurring show that the performance of our proposed method is superior to other state-of-the-art (SOTA) approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "20 pages, 21 figures"
    },
    {
        "paper id": "2409.02081",
        "abstract url": "https://arxiv.org/abs/2409.02081",
        "title": "Physical Rule-Guided Convolutional Neural Network",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The black-box nature of Convolutional Neural Networks (CNNs) and their reliance on large datasets limit their use in complex domains with limited labeled data. Physics-Guided Neural Networks (PGNNs) have emerged to address these limitations by integrating scientific principles and real-world knowledge, enhancing model interpretability and efficiency. This paper proposes a novel Physics-Guided CNN (PGCNN) architecture that incorporates dynamic, trainable, and automated LLM-generated, widely recognized rules integrated into the model as custom layers to address challenges like limited data and low confidence scores. The PGCNN is evaluated on multiple datasets, demonstrating superior performance compared to a baseline CNN model. Key improvements include a significant reduction in false positives and enhanced confidence scores for true detection. The results highlight the potential of PGCNNs to improve CNN performance for broader application areas.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02094",
        "abstract url": "https://arxiv.org/abs/2409.02094",
        "title": "Software Verification with CPAchecker 3.0: Tutorial and User Guide (Extended Version)",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This tutorial provides an introduction to CPAchecker for users. CPAchecker is a flexible and configurable framework for software verification and testing. The framework provides many abstract domains, such as BDDs, explicit values, intervals, memory graphs, and predicates, and many program-analysis and model-checking algorithms, such as abstract interpretation, bounded model checking, Impact, interpolation-based model checking, k -induction, PDR, predicate abstraction, and symbolic execution. This tutorial presents basic use cases for CPAchecker in formal software verification, focusing on its main verification techniques with their strengths and weaknesses. It also shows further use cases of CPAchecker for test-case generation and witness-based result validation. The envisioned readers are assumed to possess a background in automatic formal verification and program analysis, but prior knowledge of CPAchecker is not required. This tutorial and user guide is based on CPAchecker in version 3.0. This user guide's latest version and other documentation are available at https://cpachecker.sosy-lab.org/doc.php.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": "39 pages, 17 figures, 6 tables"
    },
    {
        "paper id": "2409.02095",
        "abstract url": "https://arxiv.org/abs/2409.02095",
        "title": "DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Despite significant advancements in monocular depth estimation for static images, estimating video depth in the open world remains challenging, since open-world videos are extremely diverse in content, motion, camera movement, and length. We present DepthCrafter, an innovative method for generating temporally consistent long depth sequences with intricate details for open-world videos, without requiring any supplementary information such as camera poses or optical flow. DepthCrafter achieves generalization ability to open-world videos by training a video-to-depth model from a pre-trained image-to-video diffusion model, through our meticulously designed three-stage training strategy with the compiled paired video-depth datasets. Our training approach enables the model to generate depth sequences with variable lengths at one time, up to 110 frames, and harvest both precise depth details and rich content diversity from realistic and synthetic datasets. We also propose an inference strategy that processes extremely long videos through segment-wise estimation and seamless stitching. Comprehensive evaluations on multiple datasets reveal that DepthCrafter achieves state-of-the-art performance in open-world video depth estimation under zero-shot settings. Furthermore, DepthCrafter facilitates various downstream applications, including depth-based visual effects and conditional video generation.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "comment": "Project webpage: https://depthcrafter.github.io"
    },
    {
        "paper id": "2409.02098",
        "abstract url": "https://arxiv.org/abs/2409.02098",
        "title": "CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through Corpus Retrieval and Augmentation",
        "rating": "-1",
        "keywords": [
            [
                "biology"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Building high-quality datasets for specialized tasks is a time-consuming and resource-intensive process that often requires specialized domain knowledge. We propose Corpus Retrieval and Augmentation for Fine-Tuning (CRAFT), a method for generating synthetic datasets, given a small number of user-written few-shots that demonstrate the task to be performed. Given the few-shot examples, we use large-scale public web-crawled corpora and similarity-based document retrieval to find other relevant human-written documents. Lastly, instruction-tuned large language models (LLMs) augment the retrieved documents into custom-formatted task samples, which then can be used for fine-tuning. We demonstrate that CRAFT can efficiently generate large-scale task-specific training datasets for four diverse tasks: biology question-answering (QA), medicine QA and commonsense QA as well as summarization. Our experiments show that CRAFT-based models outperform or achieve comparable performance to general LLMs for QA tasks, while CRAFT-based summarization models outperform models trained on human-curated data by 46 preference points.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02104",
        "abstract url": "https://arxiv.org/abs/2409.02104",
        "title": "DynOMo: Online Point Tracking by Dynamic Online Monocular Gaussian Reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian splatting"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reconstructing scenes and tracking motion are two sides of the same coin. Tracking points allow for geometric reconstruction [14], while geometric reconstruction of (dynamic) scenes allows for 3D tracking of points over time [24, 39]. The latter was recently also exploited for 2D point tracking to overcome occlusion ambiguities by lifting tracking directly into 3D [38]. However, above approaches either require offline processing or multi-view camera setups both unrealistic for real-world applications like robot navigation or mixed reality. We target the challenge of online 2D and 3D point tracking from unposed monocular camera input introducing Dynamic Online Monocular Reconstruction (DynOMo). We leverage 3D Gaussian splatting to reconstruct dynamic scenes in an online fashion. Our approach extends 3D Gaussians to capture new content and object motions while estimating camera movements from a single RGB frame. DynOMo stands out by enabling emergence of point trajectories through robust image feature reconstruction and a novel similarity-enhanced regularization term, without requiring any correspondence-level supervision. It sets the first baseline for online point tracking with monocular unposed cameras, achieving performance on par with existing methods. We aim to inspire the community to advance online point tracking and reconstruction, expanding the applicability to diverse real-world scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01626",
        "abstract url": "https://arxiv.org/abs/2409.01626",
        "title": "AQ-PINNs: Attention-Enhanced Quantum Physics-Informed Neural Networks for Carbon-Efficient Climate Modeling",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum",
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The growing computational demands of artificial intelligence (AI) in addressing climate change raise significant concerns about inefficiencies and environmental impact, as highlighted by the Jevons paradox. We propose an attention-enhanced quantum physics-informed neural networks model (AQ-PINNs) to tackle these challenges. This approach integrates quantum computing techniques into physics-informed neural networks (PINNs) for climate modeling, aiming to enhance predictive accuracy in fluid dynamics governed by the Navier-Stokes equations while reducing the computational burden and carbon footprint. By harnessing variational quantum multi-head self-attention mechanisms, our AQ-PINNs achieve a 51.51% reduction in model parameters compared to classical multi-head self-attention methods while maintaining comparable convergence and loss. It also employs quantum tensor networks to enhance representational capacity, which can lead to more efficient gradient computations and reduced susceptibility to barren plateaus. Our AQ-PINNs represent a crucial step towards more sustainable and effective climate modeling solutions.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.01630",
        "abstract url": "https://arxiv.org/abs/2409.01630",
        "title": "SafeEmbodAI: a Safety Framework for Mobile Robots in Embodied AI Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Embodied AI systems, including AI-powered robots that autonomously interact with the physical world, stand to be significantly advanced by Large Language Models (LLMs), which enable robots to better understand complex language commands and perform advanced tasks with enhanced comprehension and adaptability, highlighting their potential to improve embodied AI capabilities. However, this advancement also introduces safety challenges, particularly in robotic navigation tasks. Improper safety management can lead to failures in complex environments and make the system vulnerable to malicious command injections, resulting in unsafe behaviours such as detours or collisions. To address these issues, we propose \\textit{SafeEmbodAI}, a safety framework for integrating mobile robots into embodied AI systems. \\textit{SafeEmbodAI} incorporates secure prompting, state management, and safety validation mechanisms to secure and assist LLMs in reasoning through multi-modal data and validating responses. We designed a metric to evaluate mission-oriented exploration, and evaluations in simulated environments demonstrate that our framework effectively mitigates threats from malicious commands and improves performance in various environment settings, ensuring the safety of embodied AI systems. Notably, In complex environments with mixed obstacles, our method demonstrates a significant performance increase of 267\\% compared to the baseline in attack scenarios, highlighting its robustness in challenging conditions.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01635",
        "abstract url": "https://arxiv.org/abs/2409.01635",
        "title": "PMLBmini: A Tabular Classification Benchmark Suite for Data-Scarce Applications",
        "rating": "-1.5",
        "keywords": [
            [
                "Tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In practice, we are often faced with small-sized tabular data. However, current tabular benchmarks are not geared towards data-scarce applications, making it very difficult to derive meaningful conclusions from empirical comparisons. We introduce PMLBmini, a tabular benchmark suite of 44 binary classification datasets with sample sizes $\\leq$ 500. We use our suite to thoroughly evaluate current automated machine learning (AutoML) frameworks, off-the-shelf tabular deep neural networks, as well as classical linear models in the low-data regime. Our analysis reveals that state-of-the-art AutoML and deep learning approaches often fail to appreciably outperform even a simple logistic regression baseline, but we also identify scenarios where AutoML and deep learning methods are indeed reasonable to apply. Our benchmark suite, available on https://github.com/RicardoKnauer/TabMini , allows researchers and practitioners to analyze their own methods and challenge their data efficiency.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "AutoML 2024 Workshop Track"
    },
    {
        "paper id": "2409.01641",
        "abstract url": "https://arxiv.org/abs/2409.01641",
        "title": "Unveiling Advanced Frequency Disentanglement Paradigm for Low-Light Image Enhancement",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Previous low-light image enhancement (LLIE) approaches, while employing frequency decomposition techniques to address the intertwined challenges of low frequency (e.g., illumination recovery) and high frequency (e.g., noise reduction), primarily focused on the development of dedicated and complex networks to achieve improved performance. In contrast, we reveal that an advanced disentanglement paradigm is sufficient to consistently enhance state-of-the-art methods with minimal computational overhead. Leveraging the image Laplace decomposition scheme, we propose a novel low-frequency consistency method, facilitating improved frequency disentanglement optimization. Our method, seamlessly integrating with various models such as CNNs, Transformers, and flow-based and diffusion models, demonstrates remarkable adaptability. Noteworthy improvements are showcased across five popular benchmarks, with up to 7.68dB gains on PSNR achieved for six state-of-the-art models. Impressively, our approach maintains efficiency with only 88K extra parameters, setting a new standard in the challenging realm of low-light image enhancement.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV 2024, Github \\url{https://github.com/redrock303/ADF-LLIE}"
    },
    {
        "paper id": "2409.01712",
        "abstract url": "https://arxiv.org/abs/2409.01712",
        "title": "Toward Capturing Genetic Epistasis From Multivariate Genome-Wide Association Studies Using Mixed-Precision Kernel Ridge Regression",
        "rating": "-1.5",
        "keywords": [
            [
                "BioBank"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We exploit the widening margin in tensor-core performance between [FP64/FP32/FP16/INT8,FP64/FP32/FP16/FP8/INT8] on NVIDIA [Ampere,Hopper] GPUs to boost the performance of output accuracy-preserving mixed-precision computation of Genome-Wide Association Studies (GWAS) of 305K patients from the UK BioBank, the largest-ever GWAS cohort studied for genetic epistasis using a multivariate approach. Tile-centric adaptive-precision linear algebraic techniques motivated by reducing data motion gain enhanced significance with low-precision GPU arithmetic. At the core of Kernel Ridge Regression (KRR) techniques for GWAS lie compute-bound cubic-complexity matrix operations that inhibit scaling to aspirational dimensions of the population, genotypes, and phenotypes. We accelerate KRR matrix generation by redesigning the computation for Euclidean distances to engage INT8 tensor cores while exploiting symmetry.We accelerate solution of the regularized KRR systems by deploying a new four-precision Cholesky-based solver, which, at 1.805 mixed-precision ExaOp/s on a nearly full Alps system, outperforms the state-of-the-art CPU-only REGENIE GWAS software by five orders of magnitude.",
        "subjects": [
            "q-bio.GN",
            "cs.AR",
            "cs.LG",
            "cs.MS",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01899",
        "abstract url": "https://arxiv.org/abs/2409.01899",
        "title": "PINNIES: An Efficient Physics-Informed Neural Network Framework to Integral Operator Problems",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces an efficient tensor-vector product technique for the rapid and accurate approximation of integral operators within physics-informed deep learning frameworks. Our approach leverages neural network architectures to evaluate problem dynamics at specific points, while employing Gaussian quadrature formulas to approximate the integral components, even in the presence of infinite domains or singularities. We demonstrate the applicability of this method to both Fredholm and Volterra integral operators, as well as to optimal control problems involving continuous time. Additionally, we outline how this approach can be extended to approximate fractional derivatives and integrals and propose a fast matrix-vector product algorithm for efficiently computing the fractional Caputo derivative. In the numerical section, we conduct comprehensive experiments on forward and inverse problems. For forward problems, we evaluate the performance of our method on over 50 diverse mathematical problems, including multi-dimensional integral equations, systems of integral equations, partial and fractional integro-differential equations, and various optimal control problems in delay, fractional, multi-dimensional, and nonlinear configurations. For inverse problems, we test our approach on several integral equations and fractional integro-differential problems. Finally, we introduce the pinnies Python package to facilitate the implementation and usability of the proposed method.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": "The PiNNIEs python package is available at https://github.com/alirezaafzalaghaei/pinnies"
    },
    {
        "paper id": "2409.01914",
        "abstract url": "https://arxiv.org/abs/2409.01914",
        "title": "GradINN: Gradient Informed Neural Network",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We propose Gradient Informed Neural Networks (GradINNs), a methodology inspired by Physics Informed Neural Networks (PINNs) that can be used to efficiently approximate a wide range of physical systems for which the underlying governing equations are completely unknown or cannot be defined, a condition that is often met in complex engineering problems. GradINNs leverage prior beliefs about a system's gradient to constrain the predicted function's gradient across all input dimensions. This is achieved using two neural networks: one modeling the target function and an auxiliary network expressing prior beliefs, e.g., smoothness. A customized loss function enables training the first network while enforcing gradient constraints derived from the auxiliary network. We demonstrate the advantages of GradINNs, particularly in low-data regimes, on diverse problems spanning non time-dependent systems (Friedman function, Stokes Flow) and time-dependent systems (Lotka-Volterra, Burger's equation). Experimental results showcase strong performance compared to standard neural networks and PINN-like approaches across all tested scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01932",
        "abstract url": "https://arxiv.org/abs/2409.01932",
        "title": "Modeling IoT Traffic Patterns: Insights from a Statistical Analysis of an MTC Dataset",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Internet-of-Things (IoT) is rapidly expanding, connecting numerous devices and becoming integral to our daily lives. As this occurs, ensuring efficient traffic management becomes crucial. Effective IoT traffic management requires modeling and predicting intrincate machine-type communication (MTC) dynamics, for which machine-learning (ML) techniques are certainly appealing. However, obtaining comprehensive and high-quality datasets, along with accessible platforms for reproducing ML-based predictions, continues to impede the research progress. In this paper, we aim to fill this gap by characterizing the Smart Campus MTC dataset provided by the University of Oulu. Specifically, we perform a comprehensive statistical analysis of the MTC traffic utilizing goodness-of-fit tests, including well-established tests such as Kolmogorov-Smirnov, Anderson-Darling, chi-squared, and root mean square error. The analysis centers on examining and evaluating three models that accurately represent the two most significant MTC traffic types: periodic updating and event-driven, which are also identified from the dataset. The results demonstrate that the models accurately characterize the traffic patterns. The Poisson point process model exhibits the best fit for event-driven patterns with errors below 11%, while the quasi-periodic model fits accurately the periodic updating traffic with errors below 7%.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": "SSRN:4655476"
    },
    {
        "paper id": "2409.01977",
        "abstract url": "https://arxiv.org/abs/2409.01977",
        "title": "Counterfactual Fairness by Combining Factual and Counterfactual Predictions",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In high-stake domains such as healthcare and hiring, the role of machine learning (ML) in decision-making raises significant fairness concerns. This work focuses on Counterfactual Fairness (CF), which posits that an ML model's outcome on any individual should remain unchanged if they had belonged to a different demographic group. Previous works have proposed methods that guarantee CF. Notwithstanding, their effects on the model's predictive performance remains largely unclear. To fill in this gap, we provide a theoretical study on the inherent trade-off between CF and predictive performance in a model-agnostic manner. We first propose a simple but effective method to cast an optimal but potentially unfair predictor into a fair one without losing the optimality. By analyzing its excess risk in order to achieve CF, we quantify this inherent trade-off. Further analysis on our method's performance with access to only incomplete causal knowledge is also conducted. Built upon it, we propose a performant algorithm that can be applied in such scenarios. Experiments on both synthetic and semi-synthetic datasets demonstrate the validity of our analysis and methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01978",
        "abstract url": "https://arxiv.org/abs/2409.01978",
        "title": "Application of Langevin Dynamics to Advance the Quantum Natural Gradient Optimization Algorithm",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A Quantum Natural Gradient (QNG) algorithm for optimization of variational quantum circuits has been proposed recently. In this study, we employ the Langevin equation with a QNG stochastic force to demonstrate that its discrete-time solution gives a generalized form of the above-specified algorithm, which we call Momentum-QNG. Similar to other optimization algorithms with the momentum term, such as the Stochastic Gradient Descent with momentum, RMSProp with momentum and Adam, Momentum-QNG is more effective to escape local minima and plateaus in the variational parameter space and, therefore, achieves a better convergence behavior compared to the basic QNG. Our open-source code is available at https://github.com/borbysh/Momentum-QNG",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.02002",
        "abstract url": "https://arxiv.org/abs/2409.02002",
        "title": "The overlooked need for Ethics in Complexity Science: Why it matters",
        "rating": "-1.5",
        "keywords": [
            [
                "biotechnology"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Complexity science, despite its broad scope and potential impact, has not kept pace with fields like artificial intelligence, biotechnology and social sciences in addressing ethical concerns. The field lacks a comprehensive ethical framework, leaving us, as a community, vulnerable to ethical challenges and dilemmas. Other areas have gone through similar experiences and created, with discussions and working groups, their guides, policies and recommendations. Therefore, here we highlight the critical absence of formal guidelines, dedicated ethical committees, and widespread discussions on ethics within the complexity science community. Drawing on insights from the disciplines mentioned earlier, we propose a roadmap to enhance ethical awareness and action. Our recommendations include (i) initiating supportive mechanisms to develop ethical guidelines specific to complex systems research, (ii) creating open-access resources, and (iii) fostering inclusive dialogues to ensure that complexity science can responsibly tackle societal challenges and achieve a more inclusive environment. By initiating this dialogue, we aim to encourage a necessary shift in how ethics is integrated into complexity research, positioning the field to address contemporary challenges more effectively.",
        "subjects": [
            "physics.soc-ph",
            "cs.CY"
        ],
        "comment": "7 pages, 2 figures, 1 Annexus, 1 table"
    },
    {
        "paper id": "2409.02008",
        "abstract url": "https://arxiv.org/abs/2409.02008",
        "title": "When Digital Twin Meets 6G: Concepts, Obstacles, and Research Prospects",
        "rating": "-1.5",
        "keywords": [
            [
                "6G"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The convergence of digital twin technology and the emerging 6G network presents both challenges and numerous research opportunities. This article explores the potential synergies between digital twin and 6G, highlighting the key challenges and proposing fundamental principles for their integration. We discuss the unique requirements and capabilities of digital twin in the context of 6G networks, such as sustainable deployment, real-time synchronization, seamless migration, predictive analytic, and closed-loop control. Furthermore, we identify research opportunities for leveraging digital twin and artificial intelligence to enhance various aspects of 6G, including network optimization, resource allocation, security, and intelligent service provisioning. This article aims to stimulate further research and innovation at the intersection of digital twin and 6G, paving the way for transformative applications and services in the future.",
        "subjects": [
            "cs.NI",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2409.02069",
        "abstract url": "https://arxiv.org/abs/2409.02069",
        "title": "A Deployed Online Reinforcement Learning Algorithm In An Oral Health Clinical Trial",
        "rating": "-1.5",
        "keywords": [
            [
                "Health",
                "disease",
                "Clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Dental disease is a prevalent chronic condition associated with substantial financial burden, personal suffering, and increased risk of systemic diseases. Despite widespread recommendations for twice-daily tooth brushing, adherence to recommended oral self-care behaviors remains sub-optimal due to factors such as forgetfulness and disengagement. To address this, we developed Oralytics, a mHealth intervention system designed to complement clinician-delivered preventative care for marginalized individuals at risk for dental disease. Oralytics incorporates an online reinforcement learning algorithm to determine optimal times to deliver intervention prompts that encourage oral self-care behaviors. We have deployed Oralytics in a registered clinical trial. The deployment required careful design to manage challenges specific to the clinical trials setting in the U.S. In this paper, we (1) highlight key design decisions of the RL algorithm that address these challenges and (2) conduct a re-sampling analysis to evaluate algorithm design decisions. A second phase (randomized control trial) of Oralytics is planned to start in spring 2025.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01628",
        "abstract url": "https://arxiv.org/abs/2409.01628",
        "title": "CTG-KrEW: Generating Synthetic Structured Contextually Correlated Content by Conditional Tabular GAN with K-Means Clustering and Efficient Word Embedding",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Tabular"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Conditional Tabular Generative Adversarial Networks (CTGAN) and their various derivatives are attractive for their ability to efficiently and flexibly create synthetic tabular data, showcasing strong performance and adaptability. However, there are certain critical limitations to such models. The first is their inability to preserve the semantic integrity of contextually correlated words or phrases. For instance, skillset in freelancer profiles is one such attribute where individual skills are semantically interconnected and indicative of specific domain interests or qualifications. The second challenge of traditional approaches is that, when applied to generate contextually correlated tabular content, besides generating semantically shallow content, they consume huge memory resources and CPU time during the training stage. To address these problems, we introduce a novel framework, CTGKrEW (Conditional Tabular GAN with KMeans Clustering and Word Embedding), which is adept at generating realistic synthetic tabular data where attributes are collections of semantically and contextually coherent words. CTGKrEW is trained and evaluated using a dataset from Upwork, a realworld freelancing platform. Comprehensive experiments were conducted to analyze the variability, contextual similarity, frequency distribution, and associativity of the generated data, along with testing the framework's system feasibility. CTGKrEW also takes around 99\\% less CPU time and 33\\% less memory footprints than the conventional approach. Furthermore, we developed KrEW, a web application to facilitate the generation of realistic data containing skill-related information. This application, available at https://riyasamanta.github.io/krew.html, is freely accessible to both the general public and the research community.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01648",
        "abstract url": "https://arxiv.org/abs/2409.01648",
        "title": "Computing Range Consistent Answers to Aggregation Queries via Rewriting",
        "rating": "-2",
        "keywords": [
            [
                "SQL"
            ]
        ],
        "abstract": "We consider the problem of answering conjunctive queries with aggregation on database instances that may violate primary key constraints. In SQL, these queries follow the SELECT-FROM-WHERE-GROUP BY format, where the WHERE-clause involves a conjunction of equalities, and the SELECT-clause can incorporate aggregate operators like MAX, MIN, SUM, AVG, or COUNT. Repairs of a database instance are defined as inclusion-maximal subsets that satisfy all primary keys. For a given query, our primary objective is to identify repairs that yield the lowest aggregated value among all possible repairs. We particularly investigate queries for which this lowest aggregated value can be determined through a rewriting in first-order logic with aggregate operators.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01701",
        "abstract url": "https://arxiv.org/abs/2409.01701",
        "title": "Low Layer Functional Split Management in 5G and Beyond: Architecture and Self-adaptation",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Radio Access Network (RAN) disaggregation is emerging as a key trend in beyond 5G, as it offers new opportunities for more flexible deployments and intelligent network management. A relevant problem in disaggregated RAN is the functional split selection, which dynamically decides which baseband (BB) functions of a base station are kept close to the radio units and which ones are centralized. In this context, this paper firstly presents an architectural framework for supporting this concept relying on the O-RAN architecture. Then, the paper analyzes how the functional split can be optimized to adapt to the different load conditions while minimizing energy costs.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": "2024 19th International Symposium on Wireless Communication Systems (ISWCS)"
    },
    {
        "paper id": "2409.01707",
        "abstract url": "https://arxiv.org/abs/2409.01707",
        "title": "Quantum Byzantine Agreement Against Full-information Adversary",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We exhibit that, when given a classical Byzantine agreement protocol designed in the private-channel model, it is feasible to construct a quantum agreement protocol that can effectively handle a full-information adversary. Notably, both protocols have equivalent levels of resilience, round complexity, and communication complexity. In the classical private-channel scenario, participating players are limited to exchanging classical bits, with the adversary lacking knowledge of the exchanged messages. In contrast, in the quantum full-information setting, participating players can exchange qubits, while the adversary possesses comprehensive and accurate visibility into the system's state and messages. By showcasing the reduction from quantum to classical frameworks, this paper demonstrates the strength and flexibility of quantum protocols in addressing security challenges posed by adversaries with increased visibility. It underscores the potential of leveraging quantum principles to improve security measures without compromising on efficiency or resilience. By applying our reduction, we demonstrate quantum advantages in the round complexity of asynchronous Byzantine agreement protocols in the full-information model. It is well known that in the full-information model, any classical protocol requires $\u03a9(n)$ rounds to solve Byzantine agreement with probability one even against Fail-stop adversary when resilience $t=\u0398(n)$. We show that quantum protocols can achieve $O(1)$ rounds (i) with resilience $t<n/2$ against a Fail-stop adversary, and (ii) with resilience $t<n/(3+\u03b5)$ against a Byzantine adversary for any constant $\u03b5>0$, therefore surpassing the classical lower bound.",
        "subjects": [
            "quant-ph",
            "cs.DC"
        ],
        "comment": "26 pages. This is the extended version of the paper presented at DISC2024. It includes extra results in Appendix D that were not included in the conference submission due to page constraints"
    },
    {
        "paper id": "2409.01722",
        "abstract url": "https://arxiv.org/abs/2409.01722",
        "title": "ACCESS-FL: Agile Communication and Computation for Efficient Secure Aggregation in Stable Federated Learning Networks",
        "rating": "-2",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Federated Learning (FL) is a promising distributed learning framework designed for privacy-aware applications. FL trains models on client devices without sharing the client's data and generates a global model on a server by aggregating model updates. Traditional FL approaches risk exposing sensitive client data when plain model updates are transmitted to the server, making them vulnerable to security threats such as model inversion attacks where the server can infer the client's original training data from monitoring the changes of the trained model in different rounds. Google's Secure Aggregation (SecAgg) protocol addresses this threat by employing a double-masking technique, secret sharing, and cryptography computations in honest-but-curious and adversarial scenarios with client dropouts. However, in scenarios without the presence of an active adversary, the computational and communication cost of SecAgg significantly increases by growing the number of clients. To address this issue, in this paper, we propose ACCESS-FL, a communication-and-computation-efficient secure aggregation method designed for honest-but-curious scenarios in stable FL networks with a limited rate of client dropout. ACCESS-FL reduces the computation/communication cost to a constant level (independent of the network size) by generating shared secrets between only two clients and eliminating the need for double masking, secret sharing, and cryptography computations. To evaluate the performance of ACCESS-FL, we conduct experiments using the MNIST, FMNIST, and CIFAR datasets to verify the performance of our proposed method. The evaluation results demonstrate that our proposed method significantly reduces computation and communication overhead compared to state-of-the-art methods, SecAgg and SecAgg+.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01725",
        "abstract url": "https://arxiv.org/abs/2409.01725",
        "title": "4D-CAT: Synthesis of 4D Coronary Artery Trees from Systole and Diastole",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "medical",
                "diagnosis",
                "CT",
                "cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The three-dimensional vascular model reconstructed from CT images is widely used in medical diagnosis. At different phases, the beating of the heart can cause deformation of vessels, resulting in different vascular imaging states and false positive diagnostic results. The 4D model can simulate a complete cardiac cycle. Due to the dose limitation of contrast agent injection in patients, it is valuable to synthesize a 4D coronary artery trees through finite phases imaging. In this paper, we propose a method for generating a 4D coronary artery trees, which maps the systole to the diastole through deformation field prediction, interpolates on the timeline, and the motion trajectory of points are obtained. Specifically, the centerline is used to represent vessels and to infer deformation fields using cube-based sorting and neural networks. Adjacent vessel points are aggregated and interpolated based on the deformation field of the centerline point to obtain displacement vectors of different phases. Finally, the proposed method is validated through experiments to achieve the registration of non-rigid vascular points and the generation of 4D coronary trees.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01764",
        "abstract url": "https://arxiv.org/abs/2409.01764",
        "title": "Gradient events: improved acquisition of visual information in event cameras",
        "rating": "-2",
        "keywords": [
            [
                "event cameras"
            ],
            [
                "bio-inspired"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The current event cameras are bio-inspired sensors that respond to brightness changes in the scene asynchronously and independently for every pixel, and transmit these changes as ternary event streams. Event cameras have several benefits over conventional digital cameras, such as significantly higher temporal resolution and pixel bandwidth resulting in reduced motion blur, and very high dynamic range. However, they also introduce challenges such as the difficulty of applying existing computer vision algorithms to the output event streams, and the flood of uninformative events in the presence of oscillating light sources. Here we propose a new type of event, the gradient event, which benefits from the same properties as a conventional brightness event, but which is by design much less sensitive to oscillating light sources, and which enables considerably better grayscale frame reconstruction. We show that the gradient event -based video reconstruction outperforms existing state-of-the-art brightness event -based methods by a significant margin, when evaluated on publicly available event-to-video datasets. Our results show how gradient information can be used to significantly improve the acquisition of visual information by an event camera.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 6 figures. This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement no 101016734"
    },
    {
        "paper id": "2409.01855",
        "abstract url": "https://arxiv.org/abs/2409.01855",
        "title": "Graph-based Modeling and Simulation of Emergency Services Communication Systems",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "attack"
            ]
        ],
        "abstract": "Emergency Services Communication Systems (ESCS) are evolving into Internet Protocol based communication networks, promising enhancements to their function, availability, and resilience. This increase in complexity and cyber-attack surface demands better understanding of these systems' breakdown dynamics under extreme circumstances. Existing ESCS research largely overlooks simulation and the little work that exists focuses primarily on cybersecurity threats and neglects critical factors such as non-stationarity of call arrivals. This paper introduces a robust, adaptable graph-based simulation framework and essential mathematical models for ESCS simulation. The framework uses a representation of ESCSes where each vertex is a communicating finite-state machine that exchanges messages along edges and whose behavior is governed by a discrete event queuing model. Call arrival burstiness and its connection to emergency incidents is modeled through a cluster point process. Model applicability is demonstrated through simulations of the Seattle Police Department ESCS. Ongoing work is developing GPU implementation and exploring use in cybersecurity tabletop exercises.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2409.01867",
        "abstract url": "https://arxiv.org/abs/2409.01867",
        "title": "ASD-Chat: An Innovative Dialogue Intervention System for Children with Autism based on LLM and VB-MAPP",
        "rating": "-2",
        "keywords": [
            [
                "medical",
                "healthcare",
                "diagnosis",
                "clinical"
            ]
        ],
        "abstract": "Early diagnosis and professional intervention can help children with autism spectrum disorder (ASD) return to normal life. However, the scarcity and imbalance of professional medical resources currently prevent many autistic children from receiving the necessary diagnosis and intervention. Therefore, numerous paradigms have been proposed that use computer technology to assist or independently conduct ASD interventions, with the aim of alleviating the aforementioned problem. However, these paradigms often lack a foundation in clinical intervention methods and suffer from a lack of personalization. Addressing these concerns, we propose ASD-Chat, a social intervention system based on VB-MAPP (Verbal Behavior Milestones Assessment and Placement Program) and powered by ChatGPT as the backbone for dialogue generation. Specifically, we designed intervention paradigms and prompts based on the clinical intervention method VB-MAPP and utilized ChatGPT's generative capabilities to facilitate social dialogue interventions. Experimental results demonstrate that our proposed system achieves competitive intervention effects to those of professional interventionists, making it a promising tool for long-term interventions in real healthcare scenario in the future.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01885",
        "abstract url": "https://arxiv.org/abs/2409.01885",
        "title": "Activity-Guided Industrial Anomalous Sound Detection against Interferences",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "Industrial"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We address a practical scenario of anomaly detection for industrial sound data, where the sound of a target machine is corrupted by background noise and interference from neighboring machines. Overcoming this challenge is difficult since the interference is often virtually indistinguishable from the target machine without additional information. To address the issue, we propose SSAD, a framework of source separation (SS) followed by anomaly detection (AD), which leverages machine activity information, often readily available in practical settings. SSAD consists of two components: (i) activity-informed SS, enabling effective source separation even given interference with similar timbre, and (ii) two-step masking, robustifying anomaly detection by emphasizing anomalies aligned with the machine activity. Our experiments demonstrate that SSAD achieves comparable accuracy to a baseline with full access to clean signals, while SSAD is provided only a corrupted signal and activity information. In addition, thanks to the activity-informed SS and AD with the two-step masking, SSAD outperforms standard approaches, particularly in cases with interference. It highlights the practical efficacy of SSAD in addressing the complexities of anomaly detection in industrial sound data.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Thsis is an extended version of https://ieeexplore.ieee.org/document/10095113"
    },
    {
        "paper id": "2409.01896",
        "abstract url": "https://arxiv.org/abs/2409.01896",
        "title": "Mixed Regular and Impulsive Sampled-data LQR",
        "rating": "-2",
        "keywords": [
            [
                "MRI"
            ]
        ],
        "abstract": "We investigate the benefits of combining regular and impulsive inputs for the control of sampled-data linear time-invariant systems. We first observe that adding an impulsive term to a regular, zero-order-hold controller may help enlarging the set of sampling periods under which controllability is preserved by sampling. In this context, we provide a tailored Hautus-like necessary and sufficient condition under which controllability of the mixed regular, impulsive (MRI) sampled-data model is preserved. We then focus on LQR optimal control. After having presented the optimal controllers for the sampled-data LQR control in the MRI setting, we consider the scenario where an impulsive disturbance affects the dynamics and is known ahead of time. The solution to the so-called preview LQR is presented exploiting both regular and impulsive input components. Numerical examples, that include an insulin infusion benchmark, illustrate that leveraging both future disturbance information and MRI controls may lead to significant performance improvements.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01901",
        "abstract url": "https://arxiv.org/abs/2409.01901",
        "title": "3D-LEX v1.0: 3D Lexicons for American Sign Language and Sign Language of the Netherlands",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Sign Language",
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "In this work, we present an efficient approach for capturing sign language in 3D, introduce the 3D-LEX v1.0 dataset, and detail a method for semi-automatic annotation of phonetic properties. Our procedure integrates three motion capture techniques encompassing high-resolution 3D poses, 3D handshapes, and depth-aware facial features, and attains an average sampling rate of one sign every 10 seconds. This includes the time for presenting a sign example, performing and recording the sign, and archiving the capture. The 3D-LEX dataset includes 1,000 signs from American Sign Language and an additional 1,000 signs from the Sign Language of the Netherlands. We showcase the dataset utility by presenting a simple method for generating handshape annotations directly from 3D-LEX. We produce handshape labels for 1,000 signs from American Sign Language and evaluate the labels in a sign recognition task. The labels enhance gloss recognition accuracy by 5% over using no handshape annotations, and by 1% over expert annotations. Our motion capture data supports in-depth analysis of sign features and facilitates the generation of 2D projections from any viewpoint. The 3D-LEX collection has been aligned with existing sign language benchmarks and linguistic resources, to support studies in 3D-aware sign language processing.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01915",
        "abstract url": "https://arxiv.org/abs/2409.01915",
        "title": "Integration of Augmented Reality and Mobile Robot Indoor SLAM for Enhanced Spatial Awareness",
        "rating": "-2",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "This research explores the integration of indoor Simultaneous Localization and Mapping (SLAM) with Augmented Reality (AR) to enhance situational awareness, improving safety in hazardous or emergency situations. The main contribution of this work is to enable mobile robots to provide real-time spatial perception to users who are not co-located with the robot. This is a comprehensive approach, including selecting suitable sensors for indoor SLAM, designing and building a platform, developing methods to display maps on AR devices, implementing this into software on an AR device, and improving the robustness of communication and localization between the robot and AR device in real-world testing. By taking this approach and analyzing each component of the integrated system, this paper highlights numerous areas for future research that can further advance the integration of SLAM and AR technologies. These advancements aim to significantly improve safety and efficiency during rescue operations.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2409.01957",
        "abstract url": "https://arxiv.org/abs/2409.01957",
        "title": "Power Control and Random Serving Mode Allocation for CJT-NCJT Hybrid Mode Enabled Cell-Free Massive MIMO With Limited Fronthauls",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "With a great potential of improving the service fairness and quality for user equipments (UEs), cell-free massive multiple-input multiple-output (mMIMO) has been regarded as an emerging candidate for 6G network architectures. Under ideal assumptions, the coherent joint transmission (CJT) serving mode has been considered as an optimal option for cell-free mMIMO systems, since it can achieve coherent cooperation gain among the access points. However, when considering the limited fronthaul constraint in practice, the non-coherent joint transmission (NCJT) serving mode is likely to outperform CJT, since the former requires much lower fronthaul resources. In other words, the performance excellence and worseness of single serving mode (CJT or NCJT) depends on the fronthaul capacity, and any single transmission mode cannot perfectly adapt the capacity limited fronthaul. To explore the performance potential of the cell-free mMIMO system with limited fronthauls by harnessing the merits of CJT and NCJT, we propose a CJT-NCJT hybrid serving mode framework, in which UEs are allocated to operate on CJT or NCJT serving mode. To improve the sum-rate of the system with low complexity, we first propose a probability-based random serving mode allocation scheme. With a given serving mode, a successive convex approximation-based power allocation algorithm is proposed to maximize the system's sum-rate. Simulation results demonstrate the superiority of the proposed scheme.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 2 figures, accepted by GLOBECOM 2024"
    },
    {
        "paper id": "2409.01969",
        "abstract url": "https://arxiv.org/abs/2409.01969",
        "title": "Connectivity structure and dynamics of nonlinear recurrent neural networks",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "We develop a theory to analyze how structure in connectivity shapes the high-dimensional, internally generated activity of nonlinear recurrent neural networks. Using two complementary methods -- a path-integral calculation of fluctuations around the saddle point, and a recently introduced two-site cavity approach -- we derive analytic expressions that characterize important features of collective activity, including its dimensionality and temporal correlations. To model structure in the coupling matrices of real neural circuits, such as synaptic connectomes obtained through electron microscopy, we introduce the random-mode model, which parameterizes a coupling matrix using random input and output modes and a specified spectrum. This model enables systematic study of the effects of low-dimensional structure in connectivity on neural activity. These effects manifest in features of collective activity, that we calculate, and can be undetectable when analyzing only single-neuron activities. We derive a relation between the effective rank of the coupling matrix and the dimension of activity. By extending the random-mode model, we compare the effects of single-neuron heterogeneity and low-dimensional connectivity. We also investigate the impact of structured overlaps between input and output modes, a feature of biological coupling matrices. Our theory provides tools to relate neural-network architecture and collective dynamics in artificial and biological systems.",
        "subjects": [
            "q-bio.NC",
            "cond-mat.dis-nn",
            "cs.NE"
        ],
        "comment": "35 pages, 11 figures"
    },
    {
        "paper id": "2409.02010",
        "abstract url": "https://arxiv.org/abs/2409.02010",
        "title": "Ternary Tree Fermion-to-Qubit Mapping with Hamiltonian Aware Optimization",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "This paper introduces the Hamiltonian-Aware Ternary Tree (HATT) framework to compile optimized Fermion-to-qubit mapping for specific Fermionic Hamiltonians. In the simulation of Fermionic quantum systems, efficient Fermion-to-qubit mapping plays a critical role in transforming the Fermionic system into a qubit system. HATT utilizes ternary tree mapping and a bottom-up construction procedure to generate Hamiltonian aware Fermion-to-qubit mapping to reduce the Pauli weight of the qubit Hamiltonian, resulting in lower quantum simulation circuit overhead. Additionally, our optimizations retain the important vacuum state preservation property in our Fermion-to-qubit mapping and reduce the complexity of our algorithm from $O(N^4)$ to $O(N^3)$. Evaluations and simulations of various Fermionic systems demonstrate a significant reduction in both Pauli weight and circuit complexity, alongside excellent scalability to larger systems. Experiments on the Ionq quantum computer also show the advantages of our approach in noise resistance in quantum simulations.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02044",
        "abstract url": "https://arxiv.org/abs/2409.02044",
        "title": "FedMinds: Privacy-Preserving Personalized Brain Visual Decoding",
        "rating": "-2",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "fMRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Exploring the mysteries of the human brain is a long-term research topic in neuroscience. With the help of deep learning, decoding visual information from human brain activity fMRI has achieved promising performance. However, these decoding models require centralized storage of fMRI data to conduct training, leading to potential privacy security issues. In this paper, we focus on privacy preservation in multi-individual brain visual decoding. To this end, we introduce a novel framework called FedMinds, which utilizes federated learning to protect individuals' privacy during model training. In addition, we deploy individual adapters for each subject, thus allowing personalized visual decoding. We conduct experiments on the authoritative NSD datasets to evaluate the performance of the proposed framework. The results demonstrate that our framework achieves high-precision visual decoding along with privacy protection.",
        "subjects": [
            "q-bio.NC",
            "cs.CV",
            "cs.DC",
            "eess.IV"
        ],
        "comment": "5 pages, Accepted by JCRAI 2024"
    },
    {
        "paper id": "2409.02045",
        "abstract url": "https://arxiv.org/abs/2409.02045",
        "title": "AllWeatherNet:Unified Image enhancement for autonomous driving under adverse weather and lowlight-conditions",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "Image enhancement"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Adverse conditions like snow, rain, nighttime, and fog, pose challenges for autonomous driving perception systems. Existing methods have limited effectiveness in improving essential computer vision tasks, such as semantic segmentation, and often focus on only one specific condition, such as removing rain or translating nighttime images into daytime ones. To address these limitations, we propose a method to improve the visual quality and clarity degraded by such adverse conditions. Our method, AllWeather-Net, utilizes a novel hierarchical architecture to enhance images across all adverse conditions. This architecture incorporates information at three semantic levels: scene, object, and texture, by discriminating patches at each level. Furthermore, we introduce a Scaled Illumination-aware Attention Mechanism (SIAM) that guides the learning towards road elements critical for autonomous driving perception. SIAM exhibits robustness, remaining unaffected by changes in weather conditions or environmental scenes. AllWeather-Net effectively transforms images into normal weather and daytime scenes, demonstrating superior image enhancement results and subsequently enhancing the performance of semantic segmentation, with up to a 5.3% improvement in mIoU in the trained domain. We also show our model's generalization ability by applying it to unseen domains without re-training, achieving up to 3.9% mIoU improvement. Code can be accessed at: https://github.com/Jumponthemoon/AllWeatherNet.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02048",
        "abstract url": "https://arxiv.org/abs/2409.02048",
        "title": "ViewCrafter: Taming Video Diffusion Models for High-fidelity Novel View Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite recent advancements in neural 3D reconstruction, the dependence on dense multi-view captures restricts their broader applicability. In this work, we propose \\textbf{ViewCrafter}, a novel method for synthesizing high-fidelity novel views of generic scenes from single or sparse images with the prior of video diffusion model. Our method takes advantage of the powerful generation capabilities of video diffusion model and the coarse 3D clues offered by point-based representation to generate high-quality video frames with precise camera pose control. To further enlarge the generation range of novel views, we tailored an iterative view synthesis strategy together with a camera trajectory planning algorithm to progressively extend the 3D clues and the areas covered by the novel views. With ViewCrafter, we can facilitate various applications, such as immersive experiences with real-time rendering by efficiently optimizing a 3D-GS representation using the reconstructed 3D points and the generated novel views, and scene-level text-to-3D generation for more imaginative content creation. Extensive experiments on diverse datasets demonstrate the strong generalization capability and superior performance of our method in synthesizing high-fidelity and consistent novel views.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://drexubery.github.io/ViewCrafter/"
    },
    {
        "paper id": "2409.02055",
        "abstract url": "https://arxiv.org/abs/2409.02055",
        "title": "Wireless Mobile Distributed-MIMO for 6G",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "The paper proposes a new architecture for Distributed MIMO (D-MIMO) in which the base station (BS) jointly transmits with wireless mobile nodes to serve users (UEs) within a cell for 6G communication systems. The novelty of the architecture lies in the wireless mobile nodes participating in joint D-MIMO transmission with the BS (referred to as D-MIMO nodes), which are themselves users on the network. The D-MIMO nodes establish wireless connections with the BS, are generally near the BS, and ideally benefit from higher SNR links and better connections with edge-located UEs. These D-MIMO nodes can be existing handset UEs, Unmanned Aerial Vehicles (UAVs), or Vehicular UEs. Since the D-MIMO nodes are users sharing the access channel, the proposed architecture operates in two phases. First, the BS communicates with the D-MIMO nodes to forward data for the joint transmission, and then the BS and D-MIMO nodes jointly serve the UEs through coherent D-MIMO operation. Capacity analysis of this architecture is studied based on realistic 3GPP channel models, and the paper demonstrates that despite the two-phase operation, the proposed architecture enhances the system's capacity compared to the baseline where the BS communicates directly with the UEs.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01676",
        "abstract url": "https://arxiv.org/abs/2409.01676",
        "title": "Classifier-Free Diffusion-Based Weakly-Supervised Approach for Health Indicator Derivation in Rotating Machines: Advancing Early Fault Detection and Condition Monitoring",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Health"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deriving health indicators of rotating machines is crucial for their maintenance. However, this process is challenging for the prevalent adopted intelligent methods since they may take the whole data distributions, not only introducing noise interference but also lacking the explainability. To address these issues, we propose a diffusion-based weakly-supervised approach for deriving health indicators of rotating machines, enabling early fault detection and continuous monitoring of condition evolution. This approach relies on a classifier-free diffusion model trained using healthy samples and a few anomalies. This model generates healthy samples. and by comparing the differences between the original samples and the generated ones in the envelope spectrum, we construct an anomaly map that clearly identifies faults. Health indicators are then derived, which can explain the fault types and mitigate noise interference. Comparative studies on two cases demonstrate that the proposed method offers superior health monitoring effectiveness and robustness compared to baseline models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01685",
        "abstract url": "https://arxiv.org/abs/2409.01685",
        "title": "Optimizing Mortality Prediction for ICU Heart Failure Patients: Leveraging XGBoost and Advanced Machine Learning with the MIMIC-III Database",
        "rating": "-2.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Heart failure affects millions of people worldwide, significantly reducing quality of life and leading to high mortality rates. Despite extensive research, the relationship between heart failure and mortality rates among ICU patients is not fully understood, indicating the need for more accurate prediction models. This study analyzed data from 1,177 patients over 18 years old from the MIMIC-III database, identified using ICD-9 codes. Preprocessing steps included handling missing data, removing duplicates, treating skewness, and using oversampling techniques to address data imbalances. Through rigorous feature selection using Variance Inflation Factor (VIF), expert clinical input, and ablation studies, 46 key features were identified to enhance model performance. Our analysis compared several machine learning models, including Logistic Regression, Support Vector Machine (SVM), Random Forest, LightGBM, and XGBoost. XGBoost emerged as the superior model, achieving a test AUC-ROC of 0.9228 (95\\% CI 0.8748 - 0.9613), significantly outperforming our previous work (AUC-ROC of 0.8766) and the best results reported in existing literature (AUC-ROC of 0.824). The improved model's success is attributed to advanced feature selection methods, robust preprocessing techniques, and comprehensive hyperparameter optimization through Grid-Search. SHAP analysis and feature importance evaluations based on XGBoost highlighted key variables like leucocyte count and RDW, providing valuable insights into the clinical factors influencing mortality risk. This framework offers significant support for clinicians, enabling them to identify high-risk ICU heart failure patients and improve patient outcomes through timely and informed interventions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01731",
        "abstract url": "https://arxiv.org/abs/2409.01731",
        "title": "Stacked ensemble\\-based mutagenicity prediction model using multiple modalities with graph attention network",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "biologists",
                "cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mutagenicity is a concern due to its association with genetic mutations which can result in a variety of negative consequences, including the development of cancer. Earlier identification of mutagenic compounds in the drug development process is therefore crucial for preventing the progression of unsafe candidates and reducing development costs. While computational techniques, especially machine learning models have become increasingly prevalent for this endpoint, they rely on a single modality. In this work, we introduce a novel stacked ensemble based mutagenicity prediction model which incorporate multiple modalities such as simplified molecular input line entry system (SMILES) and molecular graph. These modalities capture diverse information about molecules such as substructural, physicochemical, geometrical and topological. To derive substructural, geometrical and physicochemical information, we use SMILES, while topological information is extracted through a graph attention network (GAT) via molecular graph. Our model uses a stacked ensemble of machine learning classifiers to make predictions using these multiple features. We employ the explainable artificial intelligence (XAI) technique SHAP (Shapley Additive Explanations) to determine the significance of each classifier and the most relevant features in the prediction. We demonstrate that our method surpasses SOTA methods on two standard datasets across various metrics. Notably, we achieve an area under the curve of 95.21\\% on the Hansen benchmark dataset, affirming the efficacy of our method in predicting mutagenicity. We believe that this research will captivate the interest of both clinicians and computational biologists engaged in translational research.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submitted to a journal"
    },
    {
        "paper id": "2409.01903",
        "abstract url": "https://arxiv.org/abs/2409.01903",
        "title": "A randomized simulation trial evaluating ABiMed, a clinical decision support system for medication reviews and polypharmacy management",
        "rating": "-2.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Background: Medication review is a structured interview of the patient, performed by the pharmacist and aimed at optimizing drug treatments. In practice, medication review is a long and cognitively-demanding task that requires specific knowledge. Clinical practice guidelines have been proposed, but their application is tedious. Methods: We designed ABiMed, a clinical decision support system for medication reviews, based on the implementation of the STOPP/START v2 guidelines and on the visual presentation of aggregated drug knowledge using tables, graphs and flower glyphs. We evaluated ABiMed with 39 community pharmacists during a randomized simulation trial, each pharmacist performing a medication review for two fictitious patients without ABiMed, and two others with ABiMed. We recorded the problems identified by the pharmacists, the interventions proposed, the response time, the perceived usability and the comments. Pharmacists' medication reviews were compared to an expert-designed gold standard. Results: With ABiMed, pharmacists found 1.6 times more relevant drug-related problems during the medication review (p=1.1e-12) and proposed better interventions (p=9.8e-9), without needing more time (p=0.56). The System Usability Scale score is 82.7, which is ranked \"excellent\". In their comments, pharmacists appreciated the visual aspect of ABiMed and its ability to compare the current treatment with the proposed one. A multifactor analysis showed no difference in the support offered by ABiMed according to the pharmacist's age or sex, in terms of percentage of problems identified or quality of the proposed interventions. Conclusions: The use of an intelligent and visual clinical decision support system can help pharmacists when they perform medication reviews. Our main perspective is the validation of the system in clinical conditions.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.01974",
        "abstract url": "https://arxiv.org/abs/2409.01974",
        "title": "Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents",
        "rating": "-2.5",
        "keywords": [
            [
                "robot",
                "navigation"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In nature, active inference agents must learn how observations of the world represent the state of the agent. In engineering, the physics behind sensors is often known reasonably accurately and measurement functions can be incorporated into generative models. When a measurement function is non-linear, the transformed variable is typically approximated with a Gaussian distribution to ensure tractable inference. We show that Gaussian approximations that are sensitive to the curvature of the measurement function, such as a second-order Taylor approximation, produce a state-dependent ambiguity term. This induces a preference over states, based on how accurately the state can be inferred from the observation. We demonstrate this preference with a robot navigation experiment where agents plan trajectories.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.RO",
            "stat.ML"
        ],
        "comment": "13 pages, 3 figures. Accepted to the International Workshop on Active Inference 2024"
    },
    {
        "paper id": "2409.01650",
        "abstract url": "https://arxiv.org/abs/2409.01650",
        "title": "Exact computation of Transfer Entropy with Path Weight Sampling",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Information processing in networks entails a dynamical transfer of information between stochastic variables. Transfer entropy is widely used for quantification of the directional transfer of information between input and output trajectories. However, currently there is no exact technique to quantify transfer entropy given the dynamical model of a general network. Here we introduce an exact computational algorithm, Transfer Entropy-Path Weight Sampling (TE-PWS), to quantify transfer entropy and its variants in an arbitrary network in the presence of multiple hidden variables, nonlinearity, transient conditions, and feedback. TE-PWS extends a recently introduced algorithm Path Weight Sampling (PWS) and uses techniques from the statistical physics of polymers and trajectory sampling. We apply TE-PWS to linear and nonlinear systems to reveal how transfer entropy can overcome naive applications of data processing inequalities in presence of feedback.",
        "subjects": [
            "q-bio.MN",
            "cond-mat.soft",
            "cond-mat.stat-mech",
            "cs.IT",
            "physics.bio-ph"
        ],
        "comment": "12 pages, 4 figures"
    },
    {
        "paper id": "2409.01695",
        "abstract url": "https://arxiv.org/abs/2409.01695",
        "title": "USTC-KXDIGIT System Description for ASVspoof5 Challenge",
        "rating": "-3",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "attacks"
            ],
            [
                "voice conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper describes the USTC-KXDIGIT system submitted to the ASVspoof5 Challenge for Track 1 (speech deepfake detection) and Track 2 (spoofing-robust automatic speaker verification, SASV). Track 1 showcases a diverse range of technical qualities from potential processing algorithms and includes both open and closed conditions. For these conditions, our system consists of a cascade of a frontend feature extractor and a back-end classifier. We focus on extensive embedding engineering and enhancing the generalization of the back-end classifier model. Specifically, the embedding engineering is based on hand-crafted features and speech representations from a self-supervised model, used for closed and open conditions, respectively. To detect spoof attacks under various adversarial conditions, we trained multiple systems on an augmented training set. Additionally, we used voice conversion technology to synthesize fake audio from genuine audio in the training set to enrich the synthesis algorithms. To leverage the complementary information learned by different model architectures, we employed activation ensemble and fused scores from different systems to obtain the final decision score for spoof detection. During the evaluation phase, the proposed methods achieved 0.3948 minDCF and 14.33% EER in the close condition, and 0.0750 minDCF and 2.59% EER in the open condition, demonstrating the robustness of our submitted systems under adversarial conditions. In Track 2, we continued using the CM system from Track 1 and fused it with a CNN-based ASV system. This approach achieved 0.2814 min-aDCF in the closed condition and 0.0756 min-aDCF in the open condition, showcasing superior performance in the SASV system.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "ASVspoof5 workshop paper"
    },
    {
        "paper id": "2409.01706",
        "abstract url": "https://arxiv.org/abs/2409.01706",
        "title": "Classically estimating observables of noiseless quantum circuits",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "We present a classical algorithm for estimating expectation values of arbitrary observables on most quantum circuits across all circuit architectures and depths, including those with all-to-all connectivity. We prove that for any architecture where each circuit layer is equipped with a measure invariant under single-qubit rotations, our algorithm achieves a small error $\\varepsilon$ on all circuits except for a small fraction $\u03b4$. The computational time is polynomial in qubit count and circuit depth for any small constant $\\varepsilon, \u03b4$, and quasi-polynomial for inverse-polynomially small $\\varepsilon, \u03b4$. For non-classically-simulable input states or observables, the expectation values can be estimated by augmenting our algorithm with classical shadows of the relevant state or observable. Our approach leverages a Pauli-path method under Heisenberg evolution. While prior works are limited to noisy quantum circuits, we establish classical simulability in noiseless regimes. Given that most quantum circuits in an architecture exhibit chaotic and locally scrambling behavior, our work demonstrates that estimating observables of such quantum dynamics is classically tractable across all geometries.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "math-ph"
        ],
        "comment": "Main text: 8 pages, 3 figures. Appendices: 25 pages, 1 figure"
    },
    {
        "paper id": "2409.01797",
        "abstract url": "https://arxiv.org/abs/2409.01797",
        "title": "Frugal RIS-aided 3D Localization with CFO under LoS and NLoS Conditions",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "In this paper, we investigate 3-D localization and frequency synchronization with multiple reconfigurable intelligent surfaces (RISs) in the presence of carrier frequency offset (CFO) for a stationary user equipment (UE). In line with the 6G goals of sustainability and efficiency, we focus on a frugal communication scenario with minimal spatial and spectral resources (i.e., narrowband single-input single-ouput system), considering both the presence and blockage of the line-of-sight (LoS) path between the base station (BS) and the UE. We design a generalized likelihood ratio test (GLRT)-based LoS detector, channel parameter estimation and localization algorithms, with varying complexity. To verify the efficiency of our estimators, we compare the root mean-squared error (RMSE) to the Cram\u00e9r- Rao bound (CRB) of the unknown parameters. We also evaluate the sensitivity of our algorithms to the presence of uncontrolled multi-path components (MPC) and various levels of CFO. Simulation results showcase the effectiveness of the proposed algorithms under minimal hardware and spectral requirements, and a wide range of operating conditions, thereby confirming the viability of RIS-aided frugal localization in 6G scenarios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 11 figures"
    },
    {
        "paper id": "2409.01803",
        "abstract url": "https://arxiv.org/abs/2409.01803",
        "title": "Performance Level Evaluation Model based on ELM",
        "rating": "-3",
        "keywords": [
            [
                "flight"
            ],
            [
                "physiological"
            ]
        ],
        "abstract": "Human factor evaluation is crucial in designing civil aircraft cockpits. This process relies on the physiological and cognitive characteristics of the flight crew to ensure that the cockpit design aligns with their capabilities and enhances flight safety. Modern physiological data acquisition and analysis technology, developed to replace traditional subjective human evaluation, has become an effective method for verifying and evaluating cockpit human factors design. Given the high-dimensional and complex nature of pilot physiological signals, these uncertainties significantly impact pilot performance. This paper proposes a pilot performance evaluation model based on an Extreme Learning Machine (ELM) to predict flight performance through pilots' physiological signals and further explores the quantitative relationship between human factors and civil aviation safety.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "6 pages, 7 figures"
    },
    {
        "paper id": "2409.01816",
        "abstract url": "https://arxiv.org/abs/2409.01816",
        "title": "GeoBEV: Learning Geometric BEV Representation for Multi-view 3D Object Detection",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "LiDAR"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Bird's-Eye-View (BEV) representation has emerged as a mainstream paradigm for multi-view 3D object detection, demonstrating impressive perceptual capabilities. However, existing methods overlook the geometric quality of BEV representation, leaving it in a low-resolution state and failing to restore the authentic geometric information of the scene. In this paper, we identify the reasons why previous approaches are constrained by low BEV representation resolution and propose Radial-Cartesian BEV Sampling (RC-Sampling), enabling efficient generation of high-resolution dense BEV representations without the need for complex operators. Additionally, we design a novel In-Box Label to substitute the traditional depth label generated from the LiDAR points. This label reflects the actual geometric structure of objects rather than just their surfaces, injecting real-world geometric information into the BEV representation. Furthermore, in conjunction with the In-Box Label, a Centroid-Aware Inner Loss (CAI Loss) is developed to capture the fine-grained inner geometric structure of objects. Finally, we integrate the aforementioned modules into a novel multi-view 3D object detection framework, dubbed GeoBEV. Extensive experiments on the nuScenes dataset exhibit that GeoBEV achieves state-of-the-art performance, highlighting its effectiveness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01876",
        "abstract url": "https://arxiv.org/abs/2409.01876",
        "title": "CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention",
        "rating": "-3",
        "keywords": [
            [
                "Avatar"
            ],
            [
                "Diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion-based video generation technology has advanced significantly, catalyzing a proliferation of research in human animation. However, the majority of these studies are confined to same-modality driving settings, with cross-modality human body animation remaining relatively underexplored. In this paper, we introduce, an end-to-end audio-driven human animation framework that ensures hand integrity, identity consistency, and natural motion. The key design of CyberHost is the Region Codebook Attention mechanism, which improves the generation quality of facial and hand animations by integrating fine-grained local features with learned motion pattern priors. Furthermore, we have developed a suite of human-prior-guided training strategies, including body movement map, hand clarity score, pose-aligned reference feature, and local enhancement supervision, to improve synthesis results. To our knowledge, CyberHost is the first end-to-end audio-driven human diffusion model capable of facilitating zero-shot video generation within the scope of human body. Extensive experiments demonstrate that CyberHost surpasses previous works in both quantitative and qualitative aspects.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01881",
        "abstract url": "https://arxiv.org/abs/2409.01881",
        "title": "The Impact of Run-Time Variability on Side-Channel Attacks Targeting FPGAs",
        "rating": "-3",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "FPGAs"
            ]
        ],
        "abstract": "To defeat side-channel attacks, many recent countermeasures work by enforcing random run-time variability to the target computing platform in terms of clock jitters, frequency and voltage scaling, and phase shift, also combining the contributions from different actuators to maximize the side-channel resistance of the target. However, the robustness of such solutions seems strongly influenced by several hyper-parameters for which an in-depth analysis is still missing. This work proposes a fine-grained dynamic voltage and frequency scaling actuator to investigate the effectiveness of recent desynchronization countermeasures with the goal of highlighting the link between the enforced run-time variability and the vulnerability to side-channel attacks of cryptographic implementations targeting FPGAs. The analysis of the results collected from real hardware allowed for a comprehensive understanding of the protection offered by run-time variability countermeasures against side-channel attacks.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "comment": "Accepted for lecture presentation at 2024 31st IEEE International Conference on Electronics, Circuits and Systems (ICECS), Nancy, France, Nov. 18-20, 2024"
    },
    {
        "paper id": "2409.01942",
        "abstract url": "https://arxiv.org/abs/2409.01942",
        "title": "Quantum Algorithms for One-Sided Crossing Minimization",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "We present singly-exponential quantum algorithms for the One-Sided Crossing Minimization (OSCM) problem. Given an $n$-vertex bipartite graph $G=(U,V,E\\subseteq U \\times V)$, a $2$-level drawing $(\u03c0_U,\u03c0_V)$ of $G$ is described by a linear ordering $\u03c0_U: U \\leftrightarrow \\{1,\\dots,|U|\\}$ of $U$ and linear ordering $\u03c0_V: V \\leftrightarrow \\{1,\\dots,|V|\\}$ of $V$. For a fixed linear ordering $\u03c0_U$ of $U$, the OSCM problem seeks to find a linear ordering $\u03c0_V$ of $V$ that yields a $2$-level drawing $(\u03c0_U,\u03c0_V)$ of $G$ with the minimum number of edge crossings. We show that OSCM can be viewed as a set problem over $V$ amenable for exact algorithms with a quantum speedup with respect to their classical counterparts. First, we exploit the quantum dynamic programming framework of Ambainis et al. [Quantum Speedups for Exponential-Time Dynamic Programming Algorithms. SODA 2019] to devise a QRAM-based algorithm that solves OSCM in $O^*(1.728^n)$ time and space. Second, we use quantum divide and conquer to obtain an algorithm that solves OSCM without using QRAM in $O^*(2^n)$ time and polynomial space.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "comment": "This is the long version of a paper to appear at the 32nd International Symposium on Graph Drawing and Network Visualization (GD '24)"
    },
    {
        "paper id": "2409.02070",
        "abstract url": "https://arxiv.org/abs/2409.02070",
        "title": "Explicit Differentiable Slicing and Global Deformation for Cardiac Mesh Reconstruction",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "graph"
            ],
            [
                "biophysics",
                "medical",
                "health",
                "MRI",
                "CT",
                "Cardiac"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Mesh reconstruction of the cardiac anatomy from medical images is useful for shape and motion measurements and biophysics simulations to facilitate the assessment of cardiac function and health. However, 3D medical images are often acquired as 2D slices that are sparsely sampled and noisy, and mesh reconstruction on such data is a challenging task. Traditional voxel-based approaches rely on pre- and post-processing that compromises image fidelity, while mesh-level deep learning approaches require mesh annotations that are difficult to get. Therefore, direct cross-domain supervision from 2D images to meshes is a key technique for advancing 3D learning in medical imaging, but it has not been well-developed. While there have been attempts to approximate the optimized meshes' slicing, few existing methods directly use 2D slices to supervise mesh reconstruction in a differentiable manner. Here, we propose a novel explicit differentiable voxelization and slicing (DVS) algorithm that allows gradient backpropagation to a mesh from its slices, facilitating refined mesh optimization directly supervised by the losses defined on 2D images. Further, we propose an innovative framework for extracting patient-specific left ventricle (LV) meshes from medical images by coupling DVS with a graph harmonic deformation (GHD) mesh morphing descriptor of cardiac shape that naturally preserves mesh quality and smoothness during optimization. Experimental results demonstrate that our method achieves state-of-the-art performance in cardiac mesh reconstruction tasks from CT and MRI, with an overall Dice score of 90% on multi-datasets, outperforming existing approaches. The proposed method can further quantify clinically useful parameters such as ejection fraction and global myocardial strains, closely matching the ground truth and surpassing the traditional voxel-based approach in sparse images.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01642",
        "abstract url": "https://arxiv.org/abs/2409.01642",
        "title": "Acoustic Levitation for Environmental Remediation: An Effective Approach for Containment and Forecasting of Oil Spills",
        "rating": "-4",
        "keywords": [
            [
                "chemical"
            ],
            [
                "Forecasting"
            ]
        ],
        "abstract": "The ocean ecology is badly impacted by large-scale oil spills, plastic waste, and chemical pollution, which destroy ecosystems and endanger marine life. Acknowledging the detrimental effects of oil spills on ecosystems, our research aims to establish the foundation for creative methods to lessen their impact. With an emphasis on the containment and prediction of oil spills, this research investigates the potential of acoustic levitation as a cutting-edge technique for environmental cleanup. Effectively separating and eliminating pollutants without causing additional ecological harm is a major issue for traditional oil spill cleanup techniques. Acoustic levitation provides a non-invasive, accurate, and effective alternative by using sound waves to precisely and subtly separate oil droplets from water in controlled environments. This proposed approach can reduce the negative effects on the environment and increase the efficacy of cleanup efforts. The findings have been examined and assessed by proof of concept experiments with oil droplets, identifying the relationship between the intensity of ultrasonic pressure and the proportion of oil droplets collected.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01646",
        "abstract url": "https://arxiv.org/abs/2409.01646",
        "title": "BEVNav: Robot Autonomous Navigation Via Spatial-Temporal Contrastive Learning in Bird's-Eye View",
        "rating": "-4",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "Robot",
                "Navigation"
            ],
            [
                "Bird's-Eye View",
                "BEV"
            ]
        ],
        "abstract": "Goal-driven mobile robot navigation in map-less environments requires effective state representations for reliable decision-making. Inspired by the favorable properties of Bird's-Eye View (BEV) in point clouds for visual perception, this paper introduces a novel navigation approach named BEVNav. It employs deep reinforcement learning to learn BEV representations and enhance decision-making reliability. First, we propose a self-supervised spatial-temporal contrastive learning approach to learn BEV representations. Spatially, two randomly augmented views from a point cloud predict each other, enhancing spatial features. Temporally, we combine the current observation with consecutive frames' actions to predict future features, establishing the relationship between observation transitions and actions to capture temporal cues. Then, incorporating this spatial-temporal contrastive learning in the Soft Actor-Critic reinforcement learning framework, our BEVNav offers a superior navigation policy. Extensive experiments demonstrate BEVNav's robustness in environments with dense pedestrians, outperforming state-of-the-art methods across multiple benchmarks. \\rev{The code will be made publicly available at https://github.com/LanrenzzzZ/BEVNav.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01768",
        "abstract url": "https://arxiv.org/abs/2409.01768",
        "title": "Mapping Safe Zones for Co-located Human-UAV Interaction",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "UAV",
                "drone"
            ]
        ],
        "abstract": "Recent advances in robotics bring us closer to the reality of living, co-habiting, and sharing personal spaces with robots. However, it is not clear how close a co-located robot can be to a human in a shared environment without making the human uncomfortable or anxious. This research aims to map safe and comfortable zones for co-located aerial robots. The objective is to identify the distances at which a drone causes discomfort to a co-located human and to create a map showing no-fly, moderate-fly, and safe-fly zones. We recruited a total of 18 participants and conducted two indoor laboratory experiments, one with a single drone and the other set with two drones. Our results show that multiple drones cause more discomfort when close to a co-located human than a single drone. We observed that distances below 200 cm caused discomfort, the moderate fly zone was 200 - 300 cm, and the safe-fly zone was any distance greater than 300 cm in single drone experiments. The safe zones were pushed further away by 100 cm for the multiple drone experiments. In this paper, we present the preliminary findings on safe-fly zones for multiple drones. Further work would investigate the impact of a higher number of aerial robots, the speed of approach, direction of travel, and noise level on co-located humans, and autonomously develop 3D models of trust zones and safe zones for co-located aerial swarms.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been accepted for presentation at the Second International Symposium on Trustworthy Autonomous Systems (TAS '24), being held from September 16-18, 2024, at Austin, TX, USA. It consists of 10 pages, 9 figures, and 1 table"
    },
    {
        "paper id": "2409.01900",
        "abstract url": "https://arxiv.org/abs/2409.01900",
        "title": "Securing Federated Learning in Robot Swarms using Blockchain Technology",
        "rating": "-4",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "Federated Learning"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Federated learning is a new approach to distributed machine learning that offers potential advantages such as reducing communication requirements and distributing the costs of training algorithms. Therefore, it could hold great promise in swarm robotics applications. However, federated learning usually requires a centralized server for the aggregation of the models. In this paper, we present a proof-of-concept implementation of federated learning in a robot swarm that does not compromise decentralization. To do so, we use blockchain technology to enable our robot swarm to securely synchronize a shared model that is the aggregation of the individual models without relying on a central server. We then show that introducing a single malfunctioning robot can, however, heavily disrupt the training process. To prevent such situations, we devise protection mechanisms that are implemented through secure and tamper-proof blockchain smart contracts. Our experiments are conducted in ARGoS, a physics-based simulator for swarm robotics, using the Ethereum blockchain protocol which is executed by each simulated robot.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "To be published in the Proceedings of the 17th International Symposium on Distributed Autonomous Robotic Systems (DARS 2024)"
    },
    {
        "paper id": "2409.01812",
        "abstract url": "https://arxiv.org/abs/2409.01812",
        "title": "Optimal SSB Beam Planning and UAV Cell Selection for 5G Connectivity on Aerial Highways",
        "rating": "-5",
        "keywords": [
            [
                "3D"
            ],
            [
                "5G"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this article, we introduce a method to optimize 5G massive multiple-input multiple-output (mMIMO) connectivity for unmanned aerial vehicles (UAVs) on aerial highways through strategic cell association. UAVs operating in 3D space encounter distinct channel conditions compared to traditional ground user equipment (gUE); under the typical line of sight (LoS) condition, UAVs perceive strong reference signal received power (RSRP) from multiple cells within the network, resulting in a large set of suitable serving cell candidates and in low signal-to-interference-plus-noise ratio (SINR) due to high interference levels. Additionally, a downside of aerial highways is to pack possibly many UAVs along a small portion of space which, when taking into account typical LoS propagation conditions, results in high channel correlation and severely limits spatial multiplexing capabilities. In this paper, we propose a solution to both problems based on the suitable selection of serving cells based on a new metric which differs from the classical terrestrial approaches based on maximum RSRP. We then introduce an algorithm for optimal planning of synchronization signal block (SSB) beams for this set of cells, ensuring maximum coverage and effective management of UAVs cell associations. Simulation results demonstrate that our approach significantly improves the rates of UAVs on aerial highways, up to four times in achievable data rates, without impacting ground user performance.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01924",
        "abstract url": "https://arxiv.org/abs/2409.01924",
        "title": "Privacy-Preserving and Post-Quantum Counter Denial of Service Framework for Wireless Networks",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "IoT"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "As network services progress and mobile and IoT environments expand, numerous security concerns have surfaced for spectrum access systems. The omnipresent risk of Denial-of-Service (DoS) attacks and raising concerns about user privacy (e.g., location privacy, anonymity) are among such cyber threats. These security and privacy risks increase due to the threat of quantum computers that can compromise long-term security by circumventing conventional cryptosystems and increasing the cost of countermeasures. While some defense mechanisms exist against these threats in isolation, there is a significant gap in the state of the art on a holistic solution against DoS attacks with privacy and anonymity for spectrum management systems, especially when post-quantum (PQ) security is in mind. In this paper, we propose a new cybersecurity framework PACDoSQ, which is (to the best of our knowledge) the first to offer location privacy and anonymity for spectrum management with counter DoS and PQ security simultaneously. Our solution introduces the private spectrum bastion (database) concept to exploit existing architectural features of spectrum management systems and then synergizes them with multi-server private information retrieval and PQ-secure Tor to guarantee a location-private and anonymous acquisition of spectrum information together with hash-based client-server puzzles for counter DoS. We prove that PACDoSQ achieves its security objectives, and show its feasibility via a comprehensive performance evaluation.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted at IEEE Military Communications Conference, 28 October 1 November 2024, Washington, DC, USA"
    },
    {
        "paper id": "2409.01931",
        "abstract url": "https://arxiv.org/abs/2409.01931",
        "title": "On the design space between molecular mechanics and machine learning force fields",
        "rating": "-5.5",
        "keywords": [
            [
                "biomolecular"
            ],
            [
                "chemical"
            ],
            [
                "quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "A force field as accurate as quantum mechanics (QM) and as fast as molecular mechanics (MM), with which one can simulate a biomolecular system efficiently enough and meaningfully enough to get quantitative insights, is among the most ardent dreams of biophysicists -- a dream, nevertheless, not to be fulfilled any time soon. Machine learning force fields (MLFFs) represent a meaningful endeavor towards this direction, where differentiable neural functions are parametrized to fit ab initio energies, and furthermore forces through automatic differentiation. We argue that, as of now, the utility of the MLFF models is no longer bottlenecked by accuracy but primarily by their speed (as well as stability and generalizability), as many recent variants, on limited chemical spaces, have long surpassed the chemical accuracy of $1$ kcal/mol -- the empirical threshold beyond which realistic chemical predictions are possible -- though still magnitudes slower than MM. Hoping to kindle explorations and designs of faster, albeit perhaps slightly less accurate MLFFs, in this review, we focus our attention on the design space (the speed-accuracy tradeoff) between MM and ML force fields. After a brief review of the building blocks of force fields of either kind, we discuss the desired properties and challenges now faced by the force field development community, survey the efforts to make MM force fields more accurate and ML force fields faster, envision what the next generation of MLFF might look like.",
        "subjects": [
            "physics.chem-ph",
            "cs.AI",
            "cs.LG",
            "physics.bio-ph",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01953",
        "abstract url": "https://arxiv.org/abs/2409.01953",
        "title": "Learning Resilient Formation Control of Drones with Graph Attention Network",
        "rating": "-6",
        "keywords": [
            [
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "industrial"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "The rapid advancement of drone technology has significantly impacted various sectors, including search and rescue, environmental surveillance, and industrial inspection. Multidrone systems offer notable advantages such as enhanced efficiency, scalability, and redundancy over single-drone operations. Despite these benefits, ensuring resilient formation control in dynamic and adversarial environments, such as under communication loss or cyberattacks, remains a significant challenge. Classical approaches to resilient formation control, while effective in certain scenarios, often struggle with complex modeling and the curse of dimensionality, particularly as the number of agents increases. This paper proposes a novel, learning-based formation control for enhancing the adaptability and resilience of multidrone formations using graph attention networks (GATs). By leveraging GAT's dynamic capabilities to extract internode relationships based on the attention mechanism, this GAT-based formation controller significantly improves the robustness of drone formations against various threats, such as Denial of Service (DoS) attacks. Our approach not only improves formation performance in normal conditions but also ensures the resilience of multidrone systems in variable and adversarial environments. Extensive simulation results demonstrate the superior performance of our method over baseline formation controllers. Furthermore, the physical experiments validate the effectiveness of the trained control policy in real-world flights.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2409.01631",
        "abstract url": "https://arxiv.org/abs/2409.01631",
        "title": "Doppler Power Spectrum in Channels with von Mises-Fisher Distribution of Scatterers",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an analytical analysis of the Doppler spectrum in von Mises-Fisher (vMF) scattering channels. A closed-form expression for the Doppler spectrum is derived and used to investigate the impact of vMF scattering parameters, i.e., the mean direction and the degree of concentration of scatterers. The spectrum is observed to exhibit exponential behavior for the mobile antenna motion parallel to the mean direction of scatterers, while conforming to a Gaussian-like shape for the perpendicular motion. The validity of the obtained results is verified by comparison against the results of Monte Carlo simulations, where an exact match is observed.",
        "subjects": [
            "eess.SP",
            "stat.OT"
        ],
        "comment": "Submitted to IEEE Communications Letters (submitted on 2024-07-26)"
    },
    {
        "paper id": "2409.01675",
        "abstract url": "https://arxiv.org/abs/2409.01675",
        "title": "Intelligent Transaction Scheduling via Conflict Prediction in OLTP DBMS",
        "rating": "-10",
        "keywords": [],
        "abstract": "Current architectures for main-memory online transaction processing (OLTP) database management systems (DBMS) typically use random scheduling to assign transactions to threads. This approach achieves uniform load across threads but it ignores the likelihood of conflicts between transactions. If the DBMS could estimate the potential for transaction conflict and then intelligently schedule transactions to avoid conflicts, then the system could improve its performance. Such estimation of transaction conflict, however, is non-trivial for several reasons. First, conflicts occur under complex conditions that are far removed in time from the scheduling decision. Second, transactions must be represented in a compact and efficient manner to allow for fast conflict detection. Third, given some evidence of potential conflict, the DBMS must schedule transactions in such a way that minimizes this conflict. In this paper, we systematically explore the design decisions for solving these problems. We then empirically measure the performance impact of different representations on standard OLTP benchmarks. Our results show that intelligent scheduling using a history increases throughput by $\\sim$40\\% on 20-core machine.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2409.01681",
        "abstract url": "https://arxiv.org/abs/2409.01681",
        "title": "Static Nuel Games with Terminal Payoff",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study a variant of the Nuel game (a generalization of the duel) which is played in turns by $N$ players. In each turn a single player must fire at one of the other players and has a certain probability of hitting and killing his target. The players shoot in a fixed sequence and when a player is eliminated, the ``move'' passes to the next surviving player. The winner is the last surviving player. We prove that, for every $N\\geq2$, the Nuel has a stationary Nash equilibrium and provide algorithms for its computation.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01683",
        "abstract url": "https://arxiv.org/abs/2409.01683",
        "title": "Priority based inter-twin communication in vehicular digital twin networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the advancement and boom of autonomous vehicles, vehicular digital twins (VDTs) have become an emerging research area. VDT can solve the issues related to autonomous vehicles and provide improved and enhanced services to users. Recent studies have demonstrated the potential of using priorities in acquiring improved response time. However, since VDT is comprised of intra-twin and inter-twin communication, it leads to a reduced response time as traffic congestion grows, which causes issues in the form of accidents. It would be encouraging if priorities could be used in inter-twin communication of VDT for data sharing and processing tasks. Moreover, it would also be effective for managing the communication overhead on the digital twin layer of the cloud. This paper proposes a novel priority-based inter-twin communication in VDT to address this issue. We formulate the problem for priorities of digital twins and applications according to their categories. In addition, we describe the priority-based inter-twin communication in VDT in detail and algorithms for priority communication for intra-twin and inter-twin are designed, respectively. Finally, experiments on different priority tasks are conducted and compared with two existing algorithms, demonstrating our proposed algorithm's effectiveness and efficiency.",
        "subjects": [
            "cs.NI",
            "cs.DC"
        ],
        "comment": "This is an Accepted Manuscript of an article published by Taylor & Francis Group in the International Journal of Parallel, Emergent & Distributed Systems on 02 Sep 2024"
    },
    {
        "paper id": "2409.01692",
        "abstract url": "https://arxiv.org/abs/2409.01692",
        "title": "Record-biased permutations and their permuton limit",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this article, we study a non-uniform distribution on permutations biased by their number of records that we call \\emph{record-biased permutations}. We give several generative processes for record-biased permutations, explaining also how they can be used to devise efficient (linear) random samplers. For several classical permutation statistics, we obtain their expectation using the above generative processes, as well as their limit distributions in the regime that has a logarithmic number of records (as in the uniform case). Finally, increasing the bias to obtain a regime with an expected linear number of records, we establish the convergence of record-biased permutations to a deterministic permuton, which we fully characterize. This model was introduced in our earlier work [N. Auger, M. Bouvel, C. Nicaud, C. Pivoteau, \\emph{Analysis of Algorithms for Permutations Biased by Their Number of Records}, AofA 2016], in the context of realistic analysis of algorithms. We conduct here a more thorough study but with a theoretical perspective.",
        "subjects": [
            "math.PR",
            "cs.DM",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01694",
        "abstract url": "https://arxiv.org/abs/2409.01694",
        "title": "A novel and efficient parameter estimation of the Lognormal-Rician turbulence model based on k-Nearest Neighbor and data generation method",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we propose a novel and efficient parameter estimator based on $k$-Nearest Neighbor ($k$NN) and data generation method for the Lognormal-Rician turbulence channel. The Kolmogorov-Smirnov (KS) goodness-of-fit statistical tools are employed to investigate the validity of $k$NN approximation under different channel conditions and it is shown that the choice of $k$ plays a significant role in the approximation accuracy. We present several numerical results to illustrate that solving the constructed objective function can provide a reasonable estimate for the actual values. The accuracy of the proposed estimator is investigated in terms of the mean square error. The simulation results show that increasing the number of generation samples by two orders of magnitude does not lead to a significant improvement in estimation performance when solving the optimization problem by the gradient descent algorithm. However, the estimation performance under the genetic algorithm (GA) approximates to that of the saddlepoint approximation and expectation-maximization estimators. Therefore, combined with the GA, we demonstrate that the proposed estimator achieves the best tradeoff between the computation complexity and the accuracy.",
        "subjects": [
            "eess.SP",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01708",
        "abstract url": "https://arxiv.org/abs/2409.01708",
        "title": "Query complexity lower bounds for local list-decoding and hard-core predicates (even for small rate and huge lists)",
        "rating": "-10",
        "keywords": [],
        "abstract": "A binary code Enc$:\\{0,1\\}^k \\to \\{0,1\\}^n$ is $(0.5-\u03b5,L)$-list decodable if for all $w \\in \\{0,1\\}^n$, the set List$(w)$ of all messages $m \\in \\{0,1\\}^k$ such that the relative Hamming distance between Enc$(m)$ and $w$ is at most $0.5 -\u03b5$, has size at most $L$. Informally, a $q$-query local list-decoder for Enc is a randomized procedure Dec$:[k]\\times [L] \\to \\{0,1\\}$ that when given oracle access to a string $w$, makes at most $q$ oracle calls, and for every message $m \\in \\text{List}(w)$, with high probability, there exists $j \\in [L]$ such that for every $i \\in [k]$, with high probability, Dec$^w(i,j)=m_i$. We prove lower bounds on $q$, that apply even if $L$ is huge (say $L=2^{k^{0.9}}$) and the rate of Enc is small (meaning that $n \\ge 2^{k}$): 1. For $\u03b5\\geq 1/k^\u03bd$ for some universal constant $0< \u03bd< 1$, we prove a lower bound of $q=\u03a9(\\frac{\\log(1/\u03b4)}{\u03b5^2})$, where $\u03b4$ is the error probability of the local list-decoder. This bound is tight as there is a matching upper bound by Goldreich and Levin (STOC 1989) of $q=O(\\frac{\\log(1/\u03b4)}{\u03b5^2})$ for the Hadamard code (which has $n=2^k$). This bound extends an earlier work of Grinberg, Shaltiel and Viola (FOCS 2018) which only works if $n \\le 2^{k^\u03b3}$ for some universal constant $0<\u03b3<1$, and the number of coins tossed by Dec is small (and therefore does not apply to the Hadamard code, or other codes with low rate). 2. For smaller $\u03b5$, we prove a lower bound of roughly $q = \u03a9(\\frac{1}{\\sqrt\u03b5})$. To the best of our knowledge, this is the first lower bound on the number of queries of local list-decoders that gives $q \\ge k$ for small $\u03b5$. We also prove black-box limitations for improving some of the parameters of the Goldreich-Levin hard-core predicate construction.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01709",
        "abstract url": "https://arxiv.org/abs/2409.01709",
        "title": "Accented Character Entry Using Physical Keyboards in Virtual Reality",
        "rating": "-10",
        "keywords": [],
        "abstract": "Research on text entry in Virtual Reality (VR) has gained popularity but the efficient entry of accented characters, characters with diacritical marks, in VR remains underexplored. Entering accented characters is supported on most capacitive touch keyboards through a long press on a base character and a subsequent selection of the accented character. However, entering those characters on physical keyboards is still challenging, as they require a recall and an entry of respective numeric codes. To address this issue this paper investigates three techniques to support accented character entry on physical keyboards in VR. Specifically, we compare a context-aware numeric code technique that does not require users to recall a code, a key-press-only condition in which the accented characters are dynamically remapped to physical keys next to a base character, and a multimodal technique, in which eye gaze is used to select the accented version of a base character previously selected by key-press on the keyboard. The results from our user study (n=18) reveal that both the key-press-only and the multimodal technique outperform the baseline technique in terms of text entry speed.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01710",
        "abstract url": "https://arxiv.org/abs/2409.01710",
        "title": "Privacy-Preserving Multimedia Mobile Cloud Computing Using Protective Perturbation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mobile cloud computing has been adopted in many multimedia applications, where the resource-constrained mobile device sends multimedia data (e.g., images) to remote cloud servers to request computation-intensive multimedia services (e.g., image recognition). While significantly improving the performance of the mobile applications, the cloud-based mechanism often causes privacy concerns as the multimedia data and services are offloaded from the trusted user device to untrusted cloud servers. Several recent studies have proposed perturbation-based privacy preserving mechanisms, which obfuscate the offloaded multimedia data to eliminate privacy exposures without affecting the functionality of the remote multimedia services. However, the existing privacy protection approaches require the deployment of computation-intensive perturbation generation on the resource-constrained mobile devices. Also, the obfuscated images are typically not compliant with the standard image compression algorithms and suffer from significant bandwidth consumption. In this paper, we develop a novel privacy-preserving multimedia mobile cloud computing framework, namely $PMC^2$, to address the resource and bandwidth challenges. $PMC^2$ employs secure confidential computing in the cloud to deploy the perturbation generator, which addresses the resource challenge while maintaining the privacy. Furthermore, we develop a neural compressor specifically trained to compress the perturbed images in order to address the bandwidth challenge. We implement $PMC^2$ in an end-to-end mobile cloud computing system, based on which our evaluations demonstrate superior latency, power efficiency, and bandwidth consumption achieved by $PMC^2$ while maintaining high accuracy in the target multimedia service.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01727",
        "abstract url": "https://arxiv.org/abs/2409.01727",
        "title": "Level Planarity Is More Difficult Than We Thought",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider three simple quadratic time algorithms for the problem Level Planarity and give a level-planar instance that they either falsely report as negative or for which they output a drawing that is not level planar.",
        "subjects": [
            "cs.DM"
        ],
        "comment": "Poster presented at GD 2024"
    },
    {
        "paper id": "2409.01736",
        "abstract url": "https://arxiv.org/abs/2409.01736",
        "title": "SpannerLib: Embedding Declarative Information Extraction in an Imperative Workflow",
        "rating": "-10",
        "keywords": [],
        "abstract": "Document spanners have been proposed as a formal framework for declarative Information Extraction (IE) from text, following IE products from the industry and academia. Over the past decade, the framework has been studied thoroughly in terms of expressive power, complexity, and the ability to naturally combine text analysis with relational querying. This demonstration presents SpannerLib a library for embedding document spanners in Python code. SpannerLib facilitates the development of IE programs by providing an implementation of Spannerlog (Datalog-based documentspanners) that interacts with the Python code in two directions: rules can be embedded inside Python, and they can invoke custom Python code (e.g., calls to ML-based NLP models) via user-defined functions. The demonstration scenarios showcase IE programs, with increasing levels of complexity, within Jupyter Notebook.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "4 pages"
    },
    {
        "paper id": "2409.01760",
        "abstract url": "https://arxiv.org/abs/2409.01760",
        "title": "Design and Operation Principles of a Wave-Controlled Reconfigurable Intelligent Surface",
        "rating": "-10",
        "keywords": [],
        "abstract": "A Reflective Intelligent Surface (RIS) consists of many small reflective elements whose reflection properties can be adjusted to change the wireless propagation environment. Envisioned implementations require that each RIS element be connected to a controller, and as the number of RIS elements on a surface may be on the order of hundreds or more, the number of required electrical connectors creates a difficult wiring problem, especially at high frequencies where the physical space between the elements is limited. A potential solution to this problem was previously proposed by the authors in which \"biasing transmission lines\" carrying standing waves are sampled at each RIS location to produce the desired bias voltage for each RIS element. This solution has the potential to substantially reduce the complexity of the RIS control. This paper presents models for the RIS elements that account for mutual coupling and realistic varactor characteristics, as well as circuit models for sampling the transmission line to generate the RIS control signals. For the latter case, the paper investigates two techniques for conversion of the transmission line standing wave voltage to the varactor bias voltage, namely an envelope detector and a sample-and-hold circuit. The paper also develops a modal decomposition approach for generating standing waves that are able to generate beams and nulls in the resulting RIS radiation pattern that maximize either the Signal-to-Noise Ratio (SNR) or the Signal-to-Leakage-plus-Noise Ratio (SLNR). Extensive simulation results are provided for the two techniques, together with a discussion of computational complexity.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "20 pages, 25 figures, 2 tables"
    },
    {
        "paper id": "2409.01765",
        "abstract url": "https://arxiv.org/abs/2409.01765",
        "title": "Multi-Branch Attention Convolutional Neural Network for Online RIS Configuration with Discrete Responses: A Neuroevolution Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we consider the problem of jointly controlling the configuration of a Reconfigurable Intelligent Surface (RIS) with unit elements of discrete responses and a codebook-based transmit precoder in RIS-empowered Multiple-Input Single-Output (MISO) communication systems. The adjustable elements of the RIS and the precoding vector need to be jointly modified in real time to account for rapid changes in the wireless channels, making the application of complicated discrete optimization algorithms impractical. We present a novel Multi-Branch Attention Convolutional Neural Network (MBACNN) architecture for this design objective which is optimized using NeuroEvolution (NE), leveraging its capability to effectively tackle the non-differentiable problem arising from the discrete phase states of the RIS elements. The channel matrices of all involved links are first passed to separate self-attention layers to obtain initial embeddings, which are then concatenated and passed to a convolutional network for spatial feature extraction, before being fed to a per-element multi-layered perceptron for the final RIS phase configuration calculation. Our MBACNN architecture is then extended to multi-RIS-empowered MISO communication systems, and a novel NE-based optimization approach for the online distributed configuration of multiple RISs is presented. The superiority of the proposed single-RIS approach over both learning-based and classical discrete optimization benchmarks is showcased via extensive numerical evaluations over both stochastic and geometrical channel models. It is also demonstrated that the proposed distributed multi-RIS approach outperforms both distributed controllers with feedforward neural networks and fully centralized ones.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "13 pages, figures, under review in a journal"
    },
    {
        "paper id": "2409.01792",
        "abstract url": "https://arxiv.org/abs/2409.01792",
        "title": "Three-dimensional geometric resolution of the inverse kinematics of a 7 degree of freedom articulated arm",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work presents a three-dimensional geometric resolution method to calculate the complete inverse kinematics of a 7-degree-of-freedom articulated arm, including the hand itself. The method is classified as an analytical method with geometric solution, since it obtains a precise solution in a closed number of steps, converting the inverse kinematic problem into a three-dimensional geometric model. To simplify the problem, the kinematic decoupling method is used, so that the position of the wrist is calculated independently on one hand with information on the orientation of the hand, and the angles of the rest of the arm are calculated from the wrist.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "in Spanish language"
    },
    {
        "paper id": "2409.01804",
        "abstract url": "https://arxiv.org/abs/2409.01804",
        "title": "Strengthening Solidity Invariant Generation: From Post- to Pre-Deployment",
        "rating": "-10",
        "keywords": [],
        "abstract": "Invariants are essential for ensuring the security and correctness of Solidity smart contracts, particularly in the context of blockchain's immutability and decentralized execution. This paper introduces InvSol, a novel framework for pre-deployment invariant generation tailored specifically for Solidity smart contracts. Unlike existing solutions, namely InvCon, InvCon+, and Trace2Inv, that rely on post-deployment transaction histories on Ethereum mainnet, InvSol identifies invariants before deployment and offers comprehensive coverage of Solidity language constructs, including loops. Additionally, InvSol incorporates custom templates to effectively prevent critical issues such as reentrancy, out-of-gas errors, and exceptions during invariant generation. We rigorously evaluate InvSol using a benchmark set of smart contracts and compare its performance with state-of-the-art solutions. Our findings reveal that InvSol significantly outperforms these tools, demonstrating its effectiveness in handling new contracts with limited transaction histories. Notably, InvSol achieves a 15% improvement in identifying common vulnerabilities compared to InvCon+ and is able to address certain crucial vulnerabilities using specific invariant templates, better than Trace2Inv.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01809",
        "abstract url": "https://arxiv.org/abs/2409.01809",
        "title": "Hardware-Based Microgrid Coupled to Real-Time Simulated Power Grids for Evaluating New Control Strategies in Future Energy Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The design of new control strategies for future energy systems can neither be directly tested in real power grids nor be evaluated based on only current grid situations. In this regard, extensive tests are required in laboratory settings using real power system equipment. However, since it is impossible to replicate the entire grid section of interest, even in large-scale experiments, hardware setups must be supplemented by detailed simulations to reproduce the system under study fully. This paper presents a unique test environment in which a hardware-based microgrid environment is physically coupled with a large-scale real-time simulation framework. The setup combines the advantages of developing new solutions using hardware-based experiments and evaluating the impact on large-scale power systems using real-time simulations. In this paper, the interface between the microgrid-under-test environment and the real-time simulations is evaluated in terms of accuracy and communication delays. Furthermore, a test case is presented showing the approach's ability to test microgrid control strategies for supporting the grid. It is observed that the communication delays via the physical interface depend on the simulation sampling time and do not significantly affect the accuracy in the interaction between the hardware and the simulated grid.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "16 pages, 10 figures"
    },
    {
        "paper id": "2409.01836",
        "abstract url": "https://arxiv.org/abs/2409.01836",
        "title": "Reuse and Blend: Energy-Efficient Optical Neural Network Enabled by Weight Sharing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Optical neural networks (ONN) based on micro-ring resonators (MRR) have emerged as a promising alternative to significantly accelerating the massive matrix-vector multiplication (MVM) operations in artificial intelligence (AI) applications. However, the limited scale of MRR arrays presents a challenge for AI acceleration. The disparity between the small MRR arrays and the large weight matrices in AI necessitates extensive MRR writings, including reprogramming and calibration, resulting in considerable latency and energy overheads. To address this problem, we propose a novel design methodology to lessen the need for frequent weight reloading. Specifically, we propose a reuse and blend (R&B) architecture to support efficient layer-wise and block-wise weight sharing, which allows weights to be reused several times between layers/blocks. Experimental results demonstrate the R&B system can maintain comparable accuracy with 69% energy savings and 57% latency improvement. These results highlight the promise of the R&B to enable the efficient deployment of advanced deep learning models on photonic accelerators.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01841",
        "abstract url": "https://arxiv.org/abs/2409.01841",
        "title": "BinSub: The Simple Essence of Polymorphic Type Inference for Machine Code",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recovering high-level type information in binaries is a key task in reverse engineering and binary analysis. Binaries contain very little explicit type information. The structure of binary code is incredibly flexible allowing for ad-hoc subtyping and polymorphism. Prior work has shown that precise type inference on binary code requires expressive subtyping and polymorphism. Implementations of these type system features in a binary type inference algorithm have thus-far been too inefficient to achieve widespread adoption. Recent advances in traditional type inference have achieved simple and efficient principal type inference in an ML like language with subtyping and polymorphism through the framework of algebraic subtyping. BinSub, a new binary type inference algorithm, recognizes the connection between algebraic subtyping and the type system features required to analyze binaries effectively. Using this connection, BinSub achieves simple, precise, and efficient binary type inference. We show that BinSub maintains a similar precision to prior work, while achieving a 63x improvement in average runtime for 1568 functions. We also present a formalization of BinSub and show that BinSub's type system maintains the expressiveness of prior work.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "To appear in SAS 2024"
    },
    {
        "paper id": "2409.01850",
        "abstract url": "https://arxiv.org/abs/2409.01850",
        "title": "Phase Noise Characterization of Cr:ZnS Frequency Comb using Subspace Tracking",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a comprehensive phase noise characterization of a mid-IR Cr:ZnS frequency comb. Despite their emergence as a platform for high-resolution dual-comb spectroscopy, detailed investigations into the phase noise of Cr:ZnS combs have been lacking. To address this, we use a recently proposed phase noise measurement technique that employs multi-heterodyne detection and subspace tracking. This allows for the measurement of the common mode, repetition-rate and high-order phase noise terms, and their corresponding scaling as a function of a comb-line number, using a single measurement set-up. We demonstrate that the comb under test is dominated by the common mode phase noise, while all the other phase noise terms are below the measurement noise floor (~ -120 dB rad^2/Hz), and are thereby not identifiable.",
        "subjects": [
            "physics.optics",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01859",
        "abstract url": "https://arxiv.org/abs/2409.01859",
        "title": "COOCK project Smart Port 2025 D3.2: \"Variability in Twinning Architectures\"",
        "rating": "-10",
        "keywords": [],
        "abstract": "This document is a result of the COOCK project \"Smart Port 2025: improving and accelerating the operational efficiency of a harbour eco-system through the application of intelligent technologies\". The project is mainly aimed at SMEs, but also at large corporations. Together, they form the value-chain of the harbour. The digital maturity of these actors will be increased by model and data-driven digitization. The project brings together both technology users and providers/integrators. In this report, the broad spectrum of model and data-based digitization approaches is structured, under the unifying umbrella of \"Digital Twins\". During the (currently quite ad-hoc) digitization process and in particular, the creations of Digital Twins, a variety of choices have an impact on the ultimately realised system. This document identifies three stages during which this \"variability\" appears: the Problem Space Goal Construction Stage, the (Conceptual) Architecture Design Stage and the Deployment Stage. To illustrate the workflow, two simple use-cases are used: one of a ship moving in 1 dimension and, at a different scale and level of detail, a macroscopic model of the Port of Antwerp.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01887",
        "abstract url": "https://arxiv.org/abs/2409.01887",
        "title": "Detecting and Measuring Security Implications of Entangled Domain Verification in CDN",
        "rating": "-10",
        "keywords": [],
        "abstract": "Content Delivery Networks (CDNs) offer a protection layer for enhancing the security of websites. However, a significant security flaw named Absence of Domain Verification (DVA) has become emerging recently. Although this threat is recognized, the current practices and security flaws of domain verification strategies in CDNs have not been thoroughly investigated. In this paper, we present DVAHunter, an automated system for detecting DVA vulnerabilities that can lead to domain abuse in CDNs. Our evaluation of 45 major CDN providers reveals the prevalence of DVA: most (39/45) providers do not perform any verification, and even those that do remain exploitable. Additionally, we used DVAHunter to conduct a large-scale measurement of 89M subdomains from Tranco's Top 1M sites hosted on the 45 CDNs under evaluation. Our focus was on two primary DVA exploitation scenarios: covert communication and domain hijacking. We identified over 332K subdomains vulnerable to domain abuse. This tool provides deeper insights into DVA exploitation and allows us to propose viable mitigation practices for CDN providers. To date, we have received vulnerability confirmations from 12 providers; 6 (e.g., Edgio, Kuocai) have implemented fixes, and 1 (ChinaNetCenter) are actively working on solutions based on our recommendations.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2409.01907",
        "abstract url": "https://arxiv.org/abs/2409.01907",
        "title": "Focus Agent: LLM-Powered Virtual Focus Group",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the domain of Human-Computer Interaction, focus groups represent a widely utilised yet resource-intensive methodology, often demanding the expertise of skilled moderators and meticulous preparatory efforts. This study introduces the ``Focus Agent,'' a Large Language Model (LLM) powered framework that simulates both the focus group (for data collection) and acts as a moderator in a focus group setting with human participants. To assess the data quality derived from the Focus Agent, we ran five focus group sessions with a total of 23 human participants as well as deploying the Focus Agent to simulate these discussions with AI participants. Quantitative analysis indicates that Focus Agent can generate opinions similar to those of human participants. Furthermore, the research exposes some improvements associated with LLMs acting as moderators in focus group discussions that include human participants.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "8 pages, the 24th Intelligent Virtual Agent Conference"
    },
    {
        "paper id": "2409.01933",
        "abstract url": "https://arxiv.org/abs/2409.01933",
        "title": "Inverting the sound speed profile from multi-beam echo sounder data and historical measurements -- a simulation study",
        "rating": "-10",
        "keywords": [],
        "abstract": "The ocean's opacity poses challenges for security, as new technology, e.g. underwater drones, offers new opportunities for illegal activities, such as smuggling and terrorism. A network of unmanned surface vehicles (USV) and autonomous underwater vehicles (AUV) offers a potential underwater surveillance solution, but demands high autonomy and compact hardware. For improved situational awareness and efficient operation, sonar performance models may provide the network with sensor coverage maps, but this requires constantly updated environmental information, in particular the present sound speed profile (SSP). We propose the inversion of SSPs from multibeam echo sounder (MBES) data in an environment with known topography. The method exploits the two-way travel time from the MBES to the bottom, comparing the measurements to modelled travel time for a proposed SSP model. An acoustic raytracer models the travel time for the SSP model. The inversion problem is shown to be non-unique when basing the cost function on the two-way travel time alone. This is resolved by incorporating a Tikhonov-type regularization term for inclusion of a priori knowledge on the SSPs in addition to the travel time in the final cost function. Empirical orthogonal functions (EOFs) are derived from a historical SSP data set, and variance for the EOF coefficients are determined from the same data set. The EOF coefficient distributions are assumed Gaussian and used in the regularization term to limit the search space of the inversion algorithm to physically feasible SSPs. A neural network determines the regularization parameters. The method's validity and sensitivity to errors is assessed using synthetic sonar data for the Norwegian Trench. The method accurately recovers SSPs with average root mean square errors of 0.83 m/s. For comparison, the error obtained using state-of-the-art climatology (WOA) is 2.6 m/s.",
        "subjects": [
            "eess.SP",
            "math.NA"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2409.01947",
        "abstract url": "https://arxiv.org/abs/2409.01947",
        "title": "Evaluating the precision of the HTC VIVE Ultimate Tracker with robotic and human movements under varied environmental conditions",
        "rating": "-10",
        "keywords": [],
        "abstract": "The HTC VIVE Ultimate Tracker, utilizing inside-out tracking with internal stereo cameras providing 6 DoF tracking without external cameras, offers a cost-efficient and straightforward setup for motion tracking. Initially designed for the gaming and VR industry, we explored its application beyond VR, providing source code for data capturing in both C++ and Python without requiring a VR headset. This study is the first to evaluate the tracker's precision across various experimental scenarios. To assess the robustness of the tracking precision, we employed a robotic arm as a precise and repeatable source of motion. Using the OptiTrack system as a reference, we conducted tests under varying experimental conditions: lighting, movement velocity, environmental changes caused by displacing objects in the scene, and human movement in front of the trackers, as well as varying the displacement size relative to the calibration center. On average, the HTC VIVE Ultimate Tracker achieved a precision of 4.98 mm +/- 4 mm across various conditions. The most critical factors affecting accuracy were lighting conditions, movement velocity, and range of motion relative to the calibration center. For practical evaluation, we captured human movements with 5 trackers in realistic motion capture scenarios. Our findings indicate sufficient precision for capturing human movements, validated through two tasks: a low-dynamic pick-and-place task and high-dynamic fencing movements performed by an elite athlete. Even though its precision is lower than that of conventional fixed-camera-based motion capture systems and its performance is influenced by several factors, the HTC VIVE Ultimate Tracker demonstrates adequate accuracy for a variety of motion tracking applications. Its ability to capture human or object movements outside of VR or MOCAP environments makes it particularly versatile.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01963",
        "abstract url": "https://arxiv.org/abs/2409.01963",
        "title": "Achieving Maximin Share and EFX/EF1 Guarantees Simultaneously",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of computing \\emph{fair} divisions of a set of indivisible goods among agents with \\emph{additive} valuations. For the past many decades, the literature has explored various notions of fairness, that can be primarily seen as either having \\emph{envy-based} or \\emph{share-based} lens. For the discrete setting of resource-allocation problems, \\emph{envy-free up to any good} (EFX) and \\emph{maximin share} (MMS) are widely considered as the flag-bearers of fairness notions in the above two categories, thereby capturing different aspects of fairness herein. Due to lack of existence results of these notions and the fact that a good approximation of EFX or MMS does not imply particularly strong guarantees of the other, it becomes important to understand the compatibility of EFX and MMS allocations with one another. In this work, we identify a novel way to simultaneously achieve MMS guarantees with EFX/EF1 notions of fairness, while beating the best known approximation factors [Chaudhury et al., 2021, Amanatidis et al., 2020]. Our main contribution is to constructively prove the existence of (i) a partial allocation that is both $2/3$-MMS and EFX, and (ii) a complete allocation that is both $2/3$-MMS and EF1. Our algorithms run in pseudo-polynomial time if the approximation factor for MMS is relaxed to $2/3-\\varepsilon$ for any constant $\\varepsilon > 0$ and in polynomial time if, in addition, the EFX (or EF1) guarantee is relaxed to $(1-\u03b4)$-EFX (or $(1-\u03b4)$-EF1) for any constant $\u03b4>0$. In particular, we improve from the best approximation factor known prior to our work, which computes partial allocations that are $1/2$-MMS and EFX in pseudo-polynomial time [Chaudhury et al., 2021].",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01976",
        "abstract url": "https://arxiv.org/abs/2409.01976",
        "title": "Benchmarking ZK-Friendly Hash Functions and SNARK Proving Systems for EVM-compatible Blockchains",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the rapid development of Zero-Knowledge Proofs (ZKPs), particularly Succinct Non-Interactive Arguments of Knowledge (SNARKs), benchmarking various ZK tools has become a valuable task. ZK-friendly hash functions, as key algorithms in blockchain, have garnered significant attention. Therefore, comprehensive benchmarking and evaluations of these evolving algorithms in ZK circuits present both promising opportunities and challenges. Additionally, we focus on a popular ZKP application, privacy-preserving transaction protocols, aiming to leverage SNARKs' cost-efficiency through \"batch processing\" to address high on-chain costs and compliance issues. To this end, we benchmarked three SNARK proving systems and five ZK-friendly hash functions, including our self-developed circuit templates for Poseidon2, Neptune, and GMiMC, on the bn254 curve within the circom-snarkjs framework. We also introduced the role of \"sequencer\" in our SNARK-based privacy-preserving transaction scheme to enhance efficiency and enable flexible auditing. We conducted privacy and security analyses, as well as implementation and evaluation on Ethereum Virtual Machine (EVM)-compatible chains. The results indicate that Poseidon and Poseidon2 demonstrate superior memory usage and runtime during proof generation under Groth16. Moreover, compared to the baseline, Poseidon2 not only generates proofs faster but also reduces on-chain costs by 73% on EVM chains and nearly 26% on Hedera. Our work provides a benchmark for ZK-friendly hash functions and ZK tools, while also exploring cost efficiency and compliance in ZKP-based privacy-preserving transaction protocols.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01994",
        "abstract url": "https://arxiv.org/abs/2409.01994",
        "title": "BinPRE: Enhancing Field Inference in Binary Analysis Based Protocol Reverse Engineering",
        "rating": "-10",
        "keywords": [],
        "abstract": "Protocol reverse engineering (PRE) aims to infer the specification of network protocols when the source code is not available. Specifically, field inference is one crucial step in PRE to infer the field formats and semantics. To perform field inference, binary analysis based PRE techniques are one major approach category. However, such techniques face two key challenges - (1) the format inference is fragile when the logics of processing input messages may vary among different protocol implementations, and (2) the semantic inference is limited by inadequate and inaccurate inference rules. To tackle these challenges, we present BinPRE, a binary analysis based PRE tool. BinPRE incorporates (1) an instruction-based semantic similarity analysis strategy for format extraction; (2) a novel library composed of atomic semantic detectors for improving semantic inference adequacy; and (3) a cluster-and-refine paradigm to further improve semantic inference accuracy. We have evaluated BinPRE against five existing PRE tools, including Polyglot, AutoFormat, Tupni, BinaryInferno and DynPRE. The evaluation results on eight widely-used protocols show that BinPRE outperforms the prior PRE tools in both format and semantic inference. BinPRE achieves the perfection of 0.73 on format extraction and the F1-score of 0.74 (0.81) on semantic inference of types (functions), respectively. The field inference results of BinPRE have helped improve the effectiveness of protocol fuzzing by achieving 5-29% higher branch coverage, compared to those of the best prior PRE tool. BinPRE has also helped discover one new zero-day vulnerability, which otherwise cannot be found.",
        "subjects": [
            "cs.SE",
            "cs.CR"
        ],
        "comment": "Accepted by ACM Conference on Computer and Communications Security (CCS) 2024"
    },
    {
        "paper id": "2409.02036",
        "abstract url": "https://arxiv.org/abs/2409.02036",
        "title": "Towards Metrics for Evaluating Creativity in Visualisation Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Creativity in visualisation design is essential for designers and data scientists who need to present data in innovative ways. It is often achieved through sketching or drafting low-fidelity prototypes. However, judging this innovation is often difficult. A creative visualisation test would offer a structured approach to enhancing visual thinking and design skills, which are vital across many fields. Such a test can facilitate objective evaluation, skill identification, benchmarking, fostering innovation, and improving learning outcomes. In developing such a test, we propose focusing on four criteria: Quantity, Correctness, Novelty, and Feasibility. These criteria integrate into a test that is easy to administer. We name it the Rowen Test of Creativity in Visualisation Design; We introduce the test, scoring system and results from using eight visualisation experts.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02053",
        "abstract url": "https://arxiv.org/abs/2409.02053",
        "title": "Augmented Reality Assistive Technologies for Disabled Individuals",
        "rating": "-10",
        "keywords": [],
        "abstract": "Augmented Reality (AR) technologies hold immense potential for revolutionizing the way individuals with disabilities interact with the world. AR systems can provide real-time assistance and support by overlaying digital information over the physical environment based on the requirements of the use, hence addressing different types of disabilities. Through an in-depth analysis of four case studies, this paper aims to provide a comprehensive overview of the current-state-of-the-art in AR assistive technologies for individuals with disabilities, highlighting their potential to assist and transform their lives. The findings show the significance that AR has made to bridge the accessibility gap, while also discussing the challenges faced and ethical considerations associated with the implementation across the various cases. This is done through theory analysis, practical examples, and future projections that will motivate and seek to inspire further innovation in this very relevant area of exploration.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "18 pages, 12 figures, 5 tables"
    },
    {
        "paper id": "2409.02085",
        "abstract url": "https://arxiv.org/abs/2409.02085",
        "title": "EcoLife: Carbon-Aware Serverless Function Scheduling for Sustainable Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work introduces ECOLIFE, the first carbon-aware serverless function scheduler to co-optimize carbon footprint and performance. ECOLIFE builds on the key insight of intelligently exploiting multi-generation hardware to achieve high performance and lower carbon footprint. ECOLIFE designs multiple novel extensions to Particle Swarm Optimization (PSO) in the context of serverless execution environment to achieve high performance while effectively reducing the carbon footprint.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02088",
        "abstract url": "https://arxiv.org/abs/2409.02088",
        "title": "SELCC: Coherent Caching over Compute-Limited Disaggregated Memory",
        "rating": "-10",
        "keywords": [],
        "abstract": "Disaggregating memory from compute offers the opportunity to better utilize stranded memory in data centers. It is important to cache data in the compute nodes and maintain cache coherence across multiple compute nodes to save on round-trip communication cost between the disaggregated memory and the compute nodes. However, the limited computing power on the disaggregated memory servers makes it challenging to maintain cache coherence among multiple compute-side caches over disaggregated shared memory. This paper introduces SELCC; a Shared-Exclusive Latch Cache Coherence protocol that maintains cache coherence without imposing any computational burden on the remote memory side. SELCC builds on a one-sided shared-exclusive latch protocol by introducing lazy latch release and invalidation messages among the compute nodes so that it can guarantee both data access atomicity and cache coherence. SELCC minimizes communication round-trips by embedding the current cache copy holder IDs into RDMA latch words and prioritizes local concurrency control over global concurrency control. We instantiate the SELCC protocol onto compute-sided cache, forming an abstraction layer over disaggregated memory. This abstraction layer provides main-memory-like APIs to upper-level applications, and thus enabling existing data structures and algorithms to function over disaggregated memory with minimal code change. To demonstrate the usability of SELCC, we implement a B-tree and three transaction concurrency control algorithms over SELCC's APIs. Micro-benchmark results show that the SELCC protocol achieves better performance compared to RPC-based cache-coherence protocols. Additionally, YCSB and TPC-C benchmarks indicate that applications over SELCC can achieve comparable or superior performance against competitors over disaggregated memory.",
        "subjects": [
            "cs.DB",
            "cs.DC",
            "cs.ET"
        ],
        "comment": null
    }
]