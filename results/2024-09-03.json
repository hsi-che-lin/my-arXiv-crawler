[
    {
        "paper id": "2409.01821",
        "abstract url": "https://arxiv.org/abs/2409.01821",
        "title": "When Does Visual Prompting Outperform Linear Probing for Vision-Language Models? A Likelihood Perspective",
        "rating": "3",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "Vision-Language"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Adapting pre-trained models to new tasks can exhibit varying effectiveness across datasets. Visual prompting, a state-of-the-art parameter-efficient transfer learning method, can significantly improve the performance of out-of-distribution tasks. On the other hand, linear probing, a standard transfer learning method, can sometimes become the best approach. We propose a log-likelihood ratio (LLR) approach to analyze the comparative benefits of visual prompting and linear probing. By employing the LLR score alongside resource-efficient visual prompts approximations, our cost-effective measure attains up to a 100-fold reduction in run time compared to full training, while achieving prediction accuracies up to 91%. The source code is available at https://github.com/IBM/VP-LLR.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01883",
        "abstract url": "https://arxiv.org/abs/2409.01883",
        "title": "Boosting Vision-Language Models for Histopathology Classification: Predict all at once",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The development of vision-language models (VLMs) for histo-pathology has shown promising new usages and zero-shot performances. However, current approaches, which decompose large slides into smaller patches, focus solely on inductive classification, i.e., prediction for each patch is made independently of the other patches in the target test data. We extend the capability of these large models by introducing a transductive approach. By using text-based predictions and affinity relationships among patches, our approach leverages the strong zero-shot capabilities of these new VLMs without any additional labels. Our experiments cover four histopathology datasets and five different VLMs. Operating solely in the embedding space (i.e., in a black-box setting), our approach is highly efficient, processing $10^5$ patches in just a few seconds, and shows significant accuracy improvements over inductive zero-shot classification. Code available at https://github.com/FereshteShakeri/Histo-TransCLIP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02278",
        "abstract url": "https://arxiv.org/abs/2409.02278",
        "title": "Evaluation and Comparison of Visual Language Models for Transportation Engineering Problems",
        "rating": "2",
        "keywords": [
            [
                "Visual Language",
                "VLM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent developments in vision language models (VLM) have shown great potential for diverse applications related to image understanding. In this study, we have explored state-of-the-art VLM models for vision-based transportation engineering tasks such as image classification and object detection. The image classification task involves congestion detection and crack identification, whereas, for object detection, helmet violations were identified. We have applied open-source models such as CLIP, BLIP, OWL-ViT, Llava-Next, and closed-source GPT-4o to evaluate the performance of these state-of-the-art VLM models to harness the capabilities of language understanding for vision-based transportation tasks. These tasks were performed by applying zero-shot prompting to the VLM models, as zero-shot prompting involves performing tasks without any training on those tasks. It eliminates the need for annotated datasets or fine-tuning for specific tasks. Though these models gave comparative results with benchmark Convolutional Neural Networks (CNN) models in the image classification tasks, for object localization tasks, it still needs improvement. Therefore, this study provides a comprehensive evaluation of the state-of-the-art VLM models highlighting the advantages and limitations of the models, which can be taken as the baseline for future improvement and wide-scale implementation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02958",
        "abstract url": "https://arxiv.org/abs/2409.02958",
        "title": "Multi-Modal Adapter for Vision-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Large pre-trained vision-language models, such as CLIP, have demonstrated state-of-the-art performance across a wide range of image classification tasks, without requiring retraining. Few-shot CLIP is competitive with existing specialized architectures that were trained on the downstream tasks. Recent research demonstrates that the performance of CLIP can be further improved using lightweight adaptation approaches. However, previous methods adapt different modalities of the CLIP model individually, ignoring the interactions and relationships between visual and textual representations. In this work, we propose Multi-Modal Adapter, an approach for Multi-Modal adaptation of CLIP. Specifically, we add a trainable Multi-Head Attention layer that combines text and image features to produce an additive adaptation of both. Multi-Modal Adapter demonstrates improved generalizability, based on its performance on unseen classes compared to existing adaptation methods. We perform additional ablations and investigations to validate and interpret the proposed approach.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01658",
        "abstract url": "https://arxiv.org/abs/2409.01658",
        "title": "From Yes-Men to Truth-Tellers: Addressing Sycophancy in Large Language Models with Pinpoint Tuning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Large Language Models (LLMs) tend to prioritize adherence to user prompts over providing veracious responses, leading to the sycophancy issue. When challenged by users, LLMs tend to admit mistakes and provide inaccurate responses even if they initially provided the correct answer. Recent works propose to employ supervised fine-tuning (SFT) to mitigate the sycophancy issue, while it typically leads to the degeneration of LLMs' general capability. To address the challenge, we propose a novel supervised pinpoint tuning (SPT), where the region-of-interest modules are tuned for a given objective. Specifically, SPT first reveals and verifies a small percentage (<5%) of the basic modules, which significantly affect a particular behavior of LLMs. i.e., sycophancy. Subsequently, SPT merely fine-tunes these identified modules while freezing the rest. To verify the effectiveness of the proposed SPT, we conduct comprehensive experiments, demonstrating that SPT significantly mitigates the sycophancy issue of LLMs (even better than SFT). Moreover, SPT introduces limited or even no side effects on the general capability of LLMs. Our results shed light on how to precisely, effectively, and efficiently explain and improve the targeted ability of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ICML 2024"
    },
    {
        "paper id": "2409.01659",
        "abstract url": "https://arxiv.org/abs/2409.01659",
        "title": "Interpreting and Improving Large Language Models in Arithmetic Calculation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated remarkable potential across numerous applications and have shown an emergent ability to tackle complex reasoning tasks, such as mathematical computations. However, even for the simplest arithmetic calculations, the intrinsic mechanisms behind LLMs remain mysterious, making it challenging to ensure reliability. In this work, we delve into uncovering a specific mechanism by which LLMs execute calculations. Through comprehensive experiments, we find that LLMs frequently involve a small fraction (< 5%) of attention heads, which play a pivotal role in focusing on operands and operators during calculation processes. Subsequently, the information from these operands is processed through multi-layer perceptrons (MLPs), progressively leading to the final solution. These pivotal heads/MLPs, though identified on a specific dataset, exhibit transferability across different datasets and even distinct tasks. This insight prompted us to investigate the potential benefits of selectively fine-tuning these essential heads/MLPs to boost the LLMs' computational performance. We empirically find that such precise tuning can yield notable enhancements on mathematical prowess, without compromising the performance on non-mathematical tasks. Our work serves as a preliminary exploration into the arithmetic calculation abilities inherent in LLMs, laying a solid foundation to reveal more intricate mathematical tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by ICML 2024 (oral)"
    },
    {
        "paper id": "2409.01686",
        "abstract url": "https://arxiv.org/abs/2409.01686",
        "title": "Frequency-Spatial Entanglement Learning for Camouflaged Object Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Camouflaged object detection has attracted a lot of attention in computer vision. The main challenge lies in the high degree of similarity between camouflaged objects and their surroundings in the spatial domain, making identification difficult. Existing methods attempt to reduce the impact of pixel similarity by maximizing the distinguishing ability of spatial features with complicated design, but often ignore the sensitivity and locality of features in the spatial domain, leading to sub-optimal results. In this paper, we propose a new approach to address this issue by jointly exploring the representation in the frequency and spatial domains, introducing the Frequency-Spatial Entanglement Learning (FSEL) method. This method consists of a series of well-designed Entanglement Transformer Blocks (ETB) for representation learning, a Joint Domain Perception Module for semantic enhancement, and a Dual-domain Reverse Parser for feature integration in the frequency and spatial domains. Specifically, the ETB utilizes frequency self-attention to effectively characterize the relationship between different frequency bands, while the entanglement feed-forward network facilitates information interaction between features of different domains through entanglement learning. Our extensive experiments demonstrate the superiority of our FSEL over 21 state-of-the-art methods, through comprehensive quantitative and qualitative comparisons in three widely-used datasets. The source code is available at: https://github.com/CSYSI/FSEL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ECCV 2024"
    },
    {
        "paper id": "2409.01726",
        "abstract url": "https://arxiv.org/abs/2409.01726",
        "title": "Mahalanobis Distance-based Multi-view Optimal Transport for Multi-view Crowd Localization",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Multi-view crowd localization predicts the ground locations of all people in the scene. Typical methods usually estimate the crowd density maps on the ground plane first, and then obtain the crowd locations. However, the performance of existing methods is limited by the ambiguity of the density maps in crowded areas, where local peaks can be smoothed away. To mitigate the weakness of density map supervision, optimal transport-based point supervision methods have been proposed in the single-image crowd localization tasks, but have not been explored for multi-view crowd localization yet. Thus, in this paper, we propose a novel Mahalanobis distance-based multi-view optimal transport (M-MVOT) loss specifically designed for multi-view crowd localization. First, we replace the Euclidean-based transport cost with the Mahalanobis distance, which defines elliptical iso-contours in the cost function whose long-axis and short-axis directions are guided by the view ray direction. Second, the object-to-camera distance in each view is used to adjust the optimal transport cost of each location further, where the wrong predictions far away from the camera are more heavily penalized. Finally, we propose a strategy to consider all the input camera views in the model loss (M-MVOT) by computing the optimal transport cost for each ground-truth point based on its closest camera. Experiments demonstrate the advantage of the proposed method over density map-based or common Euclidean distance-based optimal transport loss on several multi-view crowd localization datasets. Project page: https://vcc.tech/research/2024/MVOT.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2409.01814",
        "abstract url": "https://arxiv.org/abs/2409.01814",
        "title": "Segmenting Object Affordances: Reproducibility and Sensitivity to Scale",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Visual affordance segmentation identifies image regions of an object an agent can interact with. Existing methods re-use and adapt learning-based architectures for semantic segmentation to the affordance segmentation task and evaluate on small-size datasets. However, experimental setups are often not reproducible, thus leading to unfair and inconsistent comparisons. In this work, we benchmark these methods under a reproducible setup on two single objects scenarios, tabletop without occlusions and hand-held containers, to facilitate future comparisons. We include a version of a recent architecture, Mask2Former, re-trained for affordance segmentation and show that this model is the best-performing on most testing sets of both scenarios. Our analysis shows that models are not robust to scale variations when object resolutions differ from those in the training set.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Paper accepted to Workshop on Assistive Computer Vision and Robotics (ACVR) in European Conference on Computer Vision (ECCV) 2024; 24 pages, 9 figures, 5 tables. Code and trained models are available at https://apicis.github.io/aff-seg/"
    },
    {
        "paper id": "2409.02241",
        "abstract url": "https://arxiv.org/abs/2409.02241",
        "title": "What makes a face looks like a hat: Decoupling low-level and high-level Visual Properties with Image Triplets",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "In visual decision making, high-level features, such as object categories, have a strong influence on choice. However, the impact of low-level features on behavior is less understood partly due to the high correlation between high- and low-level features in the stimuli presented (e.g., objects of the same category are more likely to share low-level features). To disentangle these effects, we propose a method that de-correlates low- and high-level visual properties in a novel set of stimuli. Our method uses two Convolutional Neural Networks (CNNs) as candidate models of the ventral visual stream: the CORnet-S that has high neural predictivity in high-level, IT-like responses and the VGG-16 that has high neural predictivity in low-level responses. Triplets (root, image1, image2) of stimuli are parametrized by the level of low- and high-level similarity of images extracted from the different layers. These stimuli are then used in a decision-making task where participants are tasked to choose the most similar-to-the-root image. We found that different networks show differing abilities to predict the effects of low-versus-high-level similarity: while CORnet-S outperforms VGG-16 in explaining human choices based on high-level similarity, VGG-16 outperforms CORnet-S in explaining human choices based on low-level similarity. Using Brain-Score, we observed that the behavioral prediction abilities of different layers of these networks qualitatively corresponded to their ability to explain neural activity at different levels of the visual hierarchy. In summary, our algorithm for stimulus set generation enables the study of how different representations in the visual stream affect high-level cognitive behaviors.",
        "subjects": [
            "q-bio.NC",
            "cs.CV"
        ],
        "comment": "Accepted at Workshop on Human-inspired Computer Vision @ ECCV2024"
    },
    {
        "paper id": "2409.03509",
        "abstract url": "https://arxiv.org/abs/2409.03509",
        "title": "Domain-Guided Weight Modulation for Semi-Supervised Domain Generalization",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Unarguably, deep learning models capable of generalizing to unseen domain data while leveraging a few labels are of great practical significance due to low developmental costs. In search of this endeavor, we study the challenging problem of semi-supervised domain generalization (SSDG), where the goal is to learn a domain-generalizable model while using only a small fraction of labeled data and a relatively large fraction of unlabeled data. Domain generalization (DG) methods show subpar performance under the SSDG setting, whereas semi-supervised learning (SSL) methods demonstrate relatively better performance, however, they are considerably poor compared to the fully-supervised DG methods. Towards handling this new, but challenging problem of SSDG, we propose a novel method that can facilitate the generation of accurate pseudo-labels under various domain shifts. This is accomplished by retaining the domain-level specialism in the classifier during training corresponding to each source domain. Specifically, we first create domain-level information vectors on the fly which are then utilized to learn a domain-aware mask for modulating the classifier's weights. We provide a mathematical interpretation for the effect of this modulation procedure on both pseudo-labeling and model training. Our method is plug-and-play and can be readily applied to different SSL baselines for SSDG. Extensive experiments on six challenging datasets in two different SSDG settings show that our method provides visible gains over the various strong SSL-based SSDG baselines.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at WACV25"
    },
    {
        "paper id": "2409.01609",
        "abstract url": "https://arxiv.org/abs/2409.01609",
        "title": "EDCSSM: Edge Detection with Convolutional State Space Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Edge detection in images is the foundation of many complex tasks in computer graphics. Due to the feature loss caused by multi-layer convolution and pooling architectures, learning-based edge detection models often produce thick edges and struggle to detect the edges of small objects in images. Inspired by state space models, this paper presents an edge detection algorithm which effectively addresses the aforementioned issues. The presented algorithm obtains state space variables of the image from dual-input channels with minimal down-sampling processes and utilizes these state variables for real-time learning and memorization of image text. Additionally, to achieve precise edges while filtering out false edges, a post-processing algorithm called wind erosion has been designed to handle the binary edge map. To further enhance the processing speed of the algorithm, we have designed parallel computing circuits for the most computationally intensive parts of presented algorithm, significantly improving computational speed and efficiency. Experimental results demonstrate that the proposed algorithm achieves precise thin edge localization and exhibits noise suppression capabilities across various types of images. With the parallel computing circuits, the algorithm to achieve processing speeds exceeds 30 FPS on 5K images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01610",
        "abstract url": "https://arxiv.org/abs/2409.01610",
        "title": "Decompose the model: Mechanistic interpretability in image models with Generalized Integrated Gradients (GIG)",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In the field of eXplainable AI (XAI) in language models, the progression from local explanations of individual decisions to global explanations with high-level concepts has laid the groundwork for mechanistic interpretability, which aims to decode the exact operations. However, this paradigm has not been adequately explored in image models, where existing methods have primarily focused on class-specific interpretations. This paper introduces a novel approach to systematically trace the entire pathway from input through all intermediate layers to the final output within the whole dataset. We utilize Pointwise Feature Vectors (PFVs) and Effective Receptive Fields (ERFs) to decompose model embeddings into interpretable Concept Vectors. Then, we calculate the relevance between concept vectors with our Generalized Integrated Gradients (GIG), enabling a comprehensive, dataset-wide analysis of model behavior. We validate our method of concept extraction and concept attribution in both qualitative and quantitative evaluations. Our approach advances the understanding of semantic significance within image models, offering a holistic view of their operational mechanics.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01618",
        "abstract url": "https://arxiv.org/abs/2409.01618",
        "title": "High-Precision UWB-Based Real-Time Locating System for Rodent Behavioral Studies in Naturalistic Habitats",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Rodent has proven to be the premier model for behavioral studies. Rats and mice have been raised and maintained in conventional cage environment for investigations. In contrast, the enhanced naturalistic habitat has been demonstrated to be a better setting, especially when behaviors and social interactions are desired. The habitat enables rodents to perform all natural activities with intrinsic phenotypes and importantly, interactions among individuals. The important elements of behavioral studies related to animals is to have precise tracking and collect accurate signals of multiple animals during interactions. Most of the existing approaches use video tracking and thus often face difficulties as rodents are nocturnal and often stay in tunnels underground. Here, we employed the ultra wideband technology to establish a novel tracking method for both overground and underground circumstances. UWB model DWM1001C was used with a custom-made device worn by the animal. A simplified habitat with a size of four-by-two feet was designed to demonstrate the performance of the system. The study evaluated the positioning system accuracy errors below one centimeter for LoS and less than ten centimeters for the NLoS. Generally, this work provides a more accurate and proven experiment to localize the moving object in the indoor building with concrete structures and signal processing data and introduces novel advancement techniques to the use of UWB.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2409.01627",
        "abstract url": "https://arxiv.org/abs/2409.01627",
        "title": "Dynamic Guidance Adversarial Distillation with Enhanced Teacher Knowledge",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of Adversarial Distillation (AD), strategic and precise knowledge transfer from an adversarially robust teacher model to a less robust student model is paramount. Our Dynamic Guidance Adversarial Distillation (DGAD) framework directly tackles the challenge of differential sample importance, with a keen focus on rectifying the teacher model's misclassifications. DGAD employs Misclassification-Aware Partitioning (MAP) to dynamically tailor the distillation focus, optimizing the learning process by steering towards the most reliable teacher predictions. Additionally, our Error-corrective Label Swapping (ELS) corrects misclassifications of the teacher on both clean and adversarially perturbed inputs, refining the quality of knowledge transfer. Further, Predictive Consistency Regularization (PCR) guarantees consistent performance of the student model across both clean and adversarial inputs, significantly enhancing its overall robustness. By integrating these methodologies, DGAD significantly improves upon the accuracy of clean data and fortifies the model's defenses against sophisticated adversarial threats. Our experimental validation on CIFAR10, CIFAR100, and Tiny ImageNet datasets, employing various model architectures, demonstrates the efficacy of DGAD, establishing it as a promising approach for enhancing both the robustness and accuracy of student models in adversarial settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01633",
        "abstract url": "https://arxiv.org/abs/2409.01633",
        "title": "Dreaming is All You Need",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In classification tasks, achieving a harmonious balance between exploration and precision is of paramount importance. To this end, this research introduces two novel deep learning models, SleepNet and DreamNet, to strike this balance. SleepNet seamlessly integrates supervised learning with unsupervised ``sleep\" stages using pre-trained encoder models. Dedicated neurons within SleepNet are embedded in these unsupervised features, forming intermittent ``sleep\" blocks that facilitate exploratory learning. Building upon the foundation of SleepNet, DreamNet employs full encoder-decoder frameworks to reconstruct the hidden states, mimicking the human \"dreaming\" process. This reconstruction process enables further exploration and refinement of the learned representations. Moreover, the principle ideas of our SleepNet and DreamNet are generic and can be applied to both computer vision and natural language processing downstream tasks. Through extensive empirical evaluations on diverse image and text datasets, SleepNet and DreanNet have demonstrated superior performance compared to state-of-the-art models, showcasing the strengths of unsupervised exploration and supervised precision afforded by our innovative approaches.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01666",
        "abstract url": "https://arxiv.org/abs/2409.01666",
        "title": "In Defense of RAG in the Era of Long-Context Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Overcoming the limited context limitations in early-generation LLMs, retrieval-augmented generation (RAG) has been a reliable solution for context-based answer generation in the past. Recently, the emergence of long-context LLMs allows the models to incorporate much longer text sequences, making RAG less attractive. Recent studies show that long-context LLMs significantly outperform RAG in long-context applications. Unlike the existing works favoring the long-context LLM over RAG, we argue that the extremely long context in LLMs suffers from a diminished focus on relevant information and leads to potential degradation in answer quality. This paper revisits the RAG in long-context answer generation. We propose an order-preserve retrieval-augmented generation (OP-RAG) mechanism, which significantly improves the performance of RAG for long-context question-answer applications. With OP-RAG, as the number of retrieved chunks increases, the answer quality initially rises, and then declines, forming an inverted U-shaped curve. There exist sweet points where OP-RAG could achieve higher answer quality with much less tokens than long-context LLM taking the whole context as input. Extensive experiments on public benchmark demonstrate the superiority of our OP-RAG.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01667",
        "abstract url": "https://arxiv.org/abs/2409.01667",
        "title": "VProChart: Answering Chart Question through Visual Perception Alignment Agent and Programmatic Solution Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Charts are widely used for data visualization across various fields, including education, research, and business. Chart Question Answering (CQA) is an emerging task focused on the automatic interpretation and reasoning of data presented in charts. However, chart images are inherently difficult to interpret, and chart-related questions often involve complex logical and numerical reasoning, which hinders the performance of existing models. This paper introduces VProChart, a novel framework designed to address these challenges in CQA by integrating a lightweight Visual Perception Alignment Agent (VPAgent) and a Programmatic Solution Reasoning approach. VPAgent aligns and models chart elements based on principles of human visual perception, enhancing the understanding of chart context. The Programmatic Solution Reasoning approach leverages large language models (LLMs) to transform natural language reasoning questions into structured solution programs, facilitating precise numerical and logical reasoning. Extensive experiments on benchmark datasets such as ChartQA and PlotQA demonstrate that VProChart significantly outperforms existing methods, highlighting its capability in understanding and reasoning with charts.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01672",
        "abstract url": "https://arxiv.org/abs/2409.01672",
        "title": "Enhancing Fine-Grained Visual Recognition in the Low-Data Regime Through Feature Magnitude Regularization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Training a fine-grained image recognition model with limited data presents a significant challenge, as the subtle differences between categories may not be easily discernible amidst distracting noise patterns. One commonly employed strategy is to leverage pretrained neural networks, which can generate effective feature representations for constructing an image classification model with a restricted dataset. However, these pretrained neural networks are typically trained for different tasks than the fine-grained visual recognition (FGVR) task at hand, which can lead to the extraction of less relevant features. Moreover, in the context of building FGVR models with limited data, these irrelevant features can dominate the training process, overshadowing more useful, generalizable discriminative features. Our research has identified a surprisingly simple solution to this challenge: we introduce a regularization technique to ensure that the magnitudes of the extracted features are evenly distributed. This regularization is achieved by maximizing the uniformity of feature magnitude distribution, measured through the entropy of the normalized features. The motivation behind this regularization is to remove bias in feature magnitudes from pretrained models, where some features may be more prominent and, consequently, more likely to be used for classification. Additionally, we have developed a dynamic weighting mechanism to adjust the strength of this regularization throughout the learning process. Despite its apparent simplicity, our approach has demonstrated significant performance improvements across various fine-grained visual recognition datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01679",
        "abstract url": "https://arxiv.org/abs/2409.01679",
        "title": "Adaptive Explicit Knowledge Transfer for Knowledge Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Logit-based knowledge distillation (KD) for classification is cost-efficient compared to feature-based KD but often subject to inferior performance. Recently, it was shown that the performance of logit-based KD can be improved by effectively delivering the probability distribution for the non-target classes from the teacher model, which is known as `implicit (dark) knowledge', to the student model. Through gradient analysis, we first show that this actually has an effect of adaptively controlling the learning of implicit knowledge. Then, we propose a new loss that enables the student to learn explicit knowledge (i.e., the teacher's confidence about the target class) along with implicit knowledge in an adaptive manner. Furthermore, we propose to separate the classification and distillation tasks for effective distillation and inter-class relationship modeling. Experimental results demonstrate that the proposed method, called adaptive explicit knowledge transfer (AEKT) method, achieves improved performance compared to the state-of-the-art KD methods on the CIFAR-100 and ImageNet datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "19 pages, 5 figures"
    },
    {
        "paper id": "2409.01728",
        "abstract url": "https://arxiv.org/abs/2409.01728",
        "title": "Shuffle Mamba: State Space Models with Random Shuffle for Multi-Modal Image Fusion",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal image fusion integrates complementary information from different modalities to produce enhanced and informative images. Although State-Space Models, such as Mamba, are proficient in long-range modeling with linear complexity, most Mamba-based approaches use fixed scanning strategies, which can introduce biased prior information. To mitigate this issue, we propose a novel Bayesian-inspired scanning strategy called Random Shuffle, supplemented by an theoretically-feasible inverse shuffle to maintain information coordination invariance, aiming to eliminate biases associated with fixed sequence scanning. Based on this transformation pair, we customized the Shuffle Mamba Framework, penetrating modality-aware information representation and cross-modality information interaction across spatial and channel axes to ensure robust interaction and an unbiased global receptive field for multi-modal image fusion. Furthermore, we develop a testing methodology based on Monte-Carlo averaging to ensure the model's output aligns more closely with expected results. Extensive experiments across multiple multi-modal image fusion tasks demonstrate the effectiveness of our proposed method, yielding excellent fusion quality over state-of-the-art alternatives. Code will be available upon acceptance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01749",
        "abstract url": "https://arxiv.org/abs/2409.01749",
        "title": "QPOPSS: Query and Parallelism Optimized Space-Saving for Finding Frequent Stream Elements",
        "rating": "1",
        "keywords": [
            [
                "memory-efficient"
            ]
        ],
        "abstract": "The frequent elements problem, a key component in demanding stream-data analytics, involves selecting elements whose occurrence exceeds a user-specified threshold. Fast, memory-efficient $\u03b5$-approximate synopsis algorithms select all frequent elements but may overestimate them depending on $\u03b5$ (user-defined parameter). Evolving applications demand performance only achievable by parallelization. However, algorithmic guarantees concerning concurrent updates and queries have been overlooked. We propose Query and Parallelism Optimized Space-Saving (QPOPSS), providing concurrency guarantees. The design includes an implementation of the \\emph{Space-Saving} algorithm supporting fast queries, implying minimal overlap with concurrent updates. QPOPSS integrates this with the distribution of work and fine-grained synchronization among threads, swiftly balancing high throughput, high accuracy, and low memory consumption. Our analysis, under various concurrency and data distribution conditions, shows space and approximation bounds. Our empirical evaluation relative to representative state-of-the-art methods reveals that QPOPSS's multi-threaded throughput scales linearly while maintaining the highest accuracy, with orders of magnitude smaller memory footprint.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01754",
        "abstract url": "https://arxiv.org/abs/2409.01754",
        "title": "Empirical evidence of Large Language Model's influence on human spoken communication",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) agents now interact with billions of humans in natural language, thanks to advances in Large Language Models (LLMs) like ChatGPT. This raises the question of whether AI has the potential to shape a fundamental aspect of human culture: the way we speak. Recent analyses revealed that scientific publications already exhibit evidence of AI-specific language. But this evidence is inconclusive, since scientists may simply be using AI to copy-edit their writing. To explore whether AI has influenced human spoken communication, we transcribed and analyzed about 280,000 English-language videos of presentations, talks, and speeches from more than 20,000 YouTube channels of academic institutions. We find a significant shift in the trend of word usage specific to words distinctively associated with ChatGPT following its release. These findings provide the first empirical evidence that humans increasingly imitate LLMs in their spoken language. Our results raise societal and policy-relevant concerns about the potential of AI to unintentionally reduce linguistic diversity, or to be deliberately misused for mass manipulation. They also highlight the need for further investigation into the feedback loops between machine behavior and human culture.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.CL",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01763",
        "abstract url": "https://arxiv.org/abs/2409.01763",
        "title": "FC-KAN: Function Combinations in Kolmogorov-Arnold Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we introduce FC-KAN, a Kolmogorov-Arnold Network (KAN) that leverages combinations of popular mathematical functions such as B-splines, wavelets, and radial basis functions on low-dimensional data through element-wise operations. We explore several methods for combining the outputs of these functions, including sum, element-wise product, the addition of sum and element-wise product, quadratic function representation, and concatenation. In our experiments, we compare FC-KAN with multi-layer perceptron network (MLP) and other existing KANs, such as BSRBF-KAN, EfficientKAN, FastKAN, and FasterKAN, on the MNIST and Fashion-MNIST datasets. A variant of FC-KAN, which uses a combination of outputs from B-splines and Difference of Gaussians (DoG) in the form of a quadratic function, outperformed all other models on the average of 5 independent training runs. We expect that FC-KAN can leverage function combinations to design future KANs. Our repository is publicly available at: https://github.com/hoangthangta/FC_KAN.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "9 pages, 1 figure"
    },
    {
        "paper id": "2409.01776",
        "abstract url": "https://arxiv.org/abs/2409.01776",
        "title": "Steered Response Power-Based Direction-of-Arrival Estimation Exploiting an Auxiliary Microphone",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Accurately estimating the direction-of-arrival (DOA) of a speech source using a compact microphone array (CMA) is often complicated by background noise and reverberation. A commonly used DOA estimation method is the steered response power with phase transform (SRP-PHAT) function, which has been shown to work reliably in moderate levels of noise and reverberation. Since for closely spaced microphones the spatial coherence of noise and reverberation may be high over an extended frequency range, this may negatively affect the SRP-PHAT spectra, resulting in DOA estimation errors. Assuming the availability of an auxiliary microphone at an unknown position which is spatially separated from the CMA, in this paper we propose to compute the SRP-PHAT spectra between the microphones of the CMA based on the SRP-PHAT spectra between the auxiliary microphone and the microphones of the CMA. For different levels of noise and reverberation, we show how far the auxiliary microphone needs to be spatially separated from the CMA for the auxiliary microphone-based SRP-PHAT spectra to be more reliable than the SRP-PHAT spectra without the auxiliary microphone. These findings are validated based on simulated microphone signals for several auxiliary microphone positions and two different noise and reverberation conditions.",
        "subjects": [
            "eess.AS",
            "cs.SD",
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures, conference: EUSIPCO 2024 in Lyon"
    },
    {
        "paper id": "2409.01780",
        "abstract url": "https://arxiv.org/abs/2409.01780",
        "title": "State-of-the-art Advances of Deep-learning Linguistic Steganalysis Research",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the evolution of generative linguistic steganography techniques, conventional steganalysis falls short in robustly quantifying the alterations induced by steganography, thereby complicating detection. Consequently, the research paradigm has pivoted towards deep-learning-based linguistic steganalysis. This study offers a comprehensive review of existing contributions and evaluates prevailing developmental trajectories. Specifically, we first provided a formalized exposition of the general formulas for linguistic steganalysis, while comparing the differences between this field and the domain of text classification. Subsequently, we classified the existing work into two levels based on vector space mapping and feature extraction models, thereby comparing the research motivations, model advantages, and other details. A comparative analysis of the experiments is conducted to assess the performances. Finally, the challenges faced by this field are discussed, and several directions for future development and key issues that urgently need to be addressed are proposed.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by 2023 International Conference on Data, Information and Computing Science"
    },
    {
        "paper id": "2409.01794",
        "abstract url": "https://arxiv.org/abs/2409.01794",
        "title": "Estimating Joint interventional distributions from marginal interventional data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In this paper we show how to exploit interventional data to acquire the joint conditional distribution of all the variables using the Maximum Entropy principle. To this end, we extend the Causal Maximum Entropy method to make use of interventional data in addition to observational data. Using Lagrange duality, we prove that the solution to the Causal Maximum Entropy problem with interventional constraints lies in the exponential family, as in the Maximum Entropy solution. Our method allows us to perform two tasks of interest when marginal interventional distributions are provided for any subset of the variables. First, we show how to perform causal feature selection from a mixture of observational and single-variable interventional data, and, second, how to infer joint interventional distributions. For the former task, we show on synthetically generated data, that our proposed method outperforms the state-of-the-art method on merging datasets, and yields comparable results to the KCI-test which requires access to joint observations of all variables.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Duality Principles for Modern Machine Learning workshop at ICML 2023, 2nd and 3rd author equal contribution"
    },
    {
        "paper id": "2409.01806",
        "abstract url": "https://arxiv.org/abs/2409.01806",
        "title": "LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI Planning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Effective planning is essential for the success of any task, from organizing a vacation to routing autonomous vehicles and developing corporate strategies. It involves setting goals, formulating plans, and allocating resources to achieve them. LLMs are particularly well-suited for automated planning due to their strong capabilities in commonsense reasoning. They can deduce a sequence of actions needed to achieve a goal from a given state and identify an effective course of action. However, it is frequently observed that plans generated through direct prompting often fail upon execution. Our survey aims to highlight the existing challenges in planning with language models, focusing on key areas such as embodied environments, optimal scheduling, competitive and cooperative games, task decomposition, reasoning, and planning. Through this study, we explore how LLMs transform AI planning and provide unique insights into the future of LM-assisted planning.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01808",
        "abstract url": "https://arxiv.org/abs/2409.01808",
        "title": "Dialogue You Can Trust: Human and AI Perspectives on Generated Conversations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "As dialogue systems and chatbots increasingly integrate into everyday interactions, the need for efficient and accurate evaluation methods becomes paramount. This study explores the comparative performance of human and AI assessments across a range of dialogue scenarios, focusing on seven key performance indicators (KPIs): Coherence, Innovation, Concreteness, Goal Contribution, Commonsense Contradiction, Incorrect Fact, and Redundancy. Utilizing the GPT-4o API, we generated a diverse dataset of conversations and conducted a two-part experimental analysis. In Experiment 1, we evaluated multi-party conversations on Coherence, Innovation, Concreteness, and Goal Contribution, revealing that GPT models align closely with human judgments. Notably, both human and AI evaluators exhibited a tendency towards binary judgment rather than linear scaling, highlighting a shared challenge in these assessments. Experiment 2 extended the work of Finch et al. (2023) by focusing on dyadic dialogues and assessing Commonsense Contradiction, Incorrect Fact, and Redundancy. The results indicate that while GPT-4o demonstrates strong performance in maintaining factual accuracy and commonsense reasoning, it still struggles with reducing redundancy and self-contradiction. Our findings underscore the potential of GPT models to closely replicate human evaluation in dialogue systems, while also pointing to areas for improvement. This research offers valuable insights for advancing the development and implementation of more refined dialogue evaluation methodologies, contributing to the evolution of more effective and human-like AI communication tools.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "17 pages, 15 figures, shorter version submitted to 22nd Annual Workshop of the Australasian Language Technology Association (ALTA'24)"
    },
    {
        "paper id": "2409.01835",
        "abstract url": "https://arxiv.org/abs/2409.01835",
        "title": "Towards Generative Class Prompt Learning for Fine-grained Visual Recognition",
        "rating": "1",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "diffusion",
                "text-to-image"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Although foundational vision-language models (VLMs) have proven to be very successful for various semantic discrimination tasks, they still struggle to perform faithfully for fine-grained categorization. Moreover, foundational models trained on one domain do not generalize well on a different domain without fine-tuning. We attribute these to the limitations of the VLM's semantic representations and attempt to improve their fine-grained visual awareness using generative modeling. Specifically, we propose two novel methods: Generative Class Prompt Learning (GCPL) and Contrastive Multi-class Prompt Learning (CoMPLe). Utilizing text-to-image diffusion models, GCPL significantly improves the visio-linguistic synergy in class embeddings by conditioning on few-shot exemplars with learnable class prompts. CoMPLe builds on this foundation by introducing a contrastive learning component that encourages inter-class separation during the generative optimization process. Our empirical results demonstrate that such a generative class prompt learning approach substantially outperform existing methods, offering a better alternative to few shot image recognition challenges. The source code will be made available at: https://github.com/soumitri2001/GCPL.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Accepted in BMVC 2024"
    },
    {
        "paper id": "2409.01854",
        "abstract url": "https://arxiv.org/abs/2409.01854",
        "title": "AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The relation extraction (RE) in complex scenarios faces challenges such as diverse relation types and ambiguous relations between entities within a single sentence, leading to the poor performance of pure \"text-in, text-out\" language models (LMs). To address these challenges, in this paper, we propose an agent-based RE framework, namely AgentRE, which fully leverages the potential of large language models (LLMs) including memory, retrieval and reflection, to achieve RE in complex scenarios. Specifically, three major modules are built in AgentRE serving as the tools to help the agent acquire and process various useful information, thereby obtaining improved RE performance. Our extensive experimental results upon two datasets in English and Chinese demonstrate our AgentRE's superior performance, especially in low-resource scenarios. Additionally, the trajectories generated by AgentRE can be refined to construct a high-quality training dataset incorporating different reasoning methods, which can be used to fine-tune smaller models. Code is available at https://github.com/Lightblues/AgentRE.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by CIKM 2024"
    },
    {
        "paper id": "2409.01871",
        "abstract url": "https://arxiv.org/abs/2409.01871",
        "title": "Real-Time Indoor Object Detection based on hybrid CNN-Transformer Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Real-time object detection in indoor settings is a challenging area of computer vision, faced with unique obstacles such as variable lighting and complex backgrounds. This field holds significant potential to revolutionize applications like augmented and mixed realities by enabling more seamless interactions between digital content and the physical world. However, the scarcity of research specifically fitted to the intricacies of indoor environments has highlighted a clear gap in the literature. To address this, our study delves into the evaluation of existing datasets and computational models, leading to the creation of a refined dataset. This new dataset is derived from OpenImages v7, focusing exclusively on 32 indoor categories selected for their relevance to real-world applications. Alongside this, we present an adaptation of a CNN detection model, incorporating an attention mechanism to enhance the model's ability to discern and prioritize critical features within cluttered indoor scenes. Our findings demonstrate that this approach is not just competitive with existing state-of-the-art models in accuracy and speed but also opens new avenues for research and application in the field of real-time indoor object detection.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01882",
        "abstract url": "https://arxiv.org/abs/2409.01882",
        "title": "Investigating Expert-in-the-Loop LLM Discourse Patterns for Ancient Intertextual Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study explores the potential of large language models (LLMs) for identifying and examining intertextual relationships within biblical, Koine Greek texts. By evaluating the performance of LLMs on various intertextuality scenarios the study demonstrates that these models can detect direct quotations, allusions, and echoes between texts. The LLM's ability to generate novel intertextual observations and connections highlights its potential to uncover new insights. However, the model also struggles with long query passages and the inclusion of false intertextual dependences, emphasizing the importance of expert evaluation. The expert-in-the-loop methodology presented offers a scalable approach for intertextual research into the complex web of intertextuality within and beyond the biblical corpus.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01890",
        "abstract url": "https://arxiv.org/abs/2409.01890",
        "title": "A Fresh Take on Stale Embeddings: Improving Dense Retriever Training with Corrector Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "In dense retrieval, deep encoders provide embeddings for both inputs and targets, and the softmax function is used to parameterize a distribution over a large number of candidate targets (e.g., textual passages for information retrieval). Significant challenges arise in training such encoders in the increasingly prevalent scenario of (1) a large number of targets, (2) a computationally expensive target encoder model, (3) cached target embeddings that are out-of-date due to ongoing training of target encoder parameters. This paper presents a simple and highly scalable response to these challenges by training a small parametric corrector network that adjusts stale cached target embeddings, enabling an accurate softmax approximation and thereby sampling of up-to-date high scoring \"hard negatives.\" We theoretically investigate the generalization properties of our proposed target corrector, relating the complexity of the network, staleness of cached representations, and the amount of training data. We present experimental results on large benchmark dense retrieval datasets as well as on QA with retrieval augmented language models. Our approach matches state-of-the-art results even when no target embedding updates are made during training beyond an initial cache from the unsupervised pre-trained model, providing a 4-80x reduction in re-embedding computational cost.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2409.01893",
        "abstract url": "https://arxiv.org/abs/2409.01893",
        "title": "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) with extended context windows have significantly improved tasks such as information extraction, question answering, and complex planning scenarios. In order to achieve success in long context tasks, a large amount of work has been done to enhance the long context capabilities of the model through synthetic data. Existing methods typically utilize the Self-Instruct framework to generate instruction tuning data for better long context capability improvement. However, our preliminary experiments indicate that less than 35% of generated samples are multi-hop, and more than 40% exhibit poor quality, limiting comprehensive understanding and further research. To improve the quality of synthetic data, we propose the Multi-agent Interactive Multi-hop Generation (MIMG) framework, incorporating a Quality Verification Agent, a Single-hop Question Generation Agent, a Multiple Question Sampling Strategy, and a Multi-hop Question Merger Agent. This framework improves the data quality, with the proportion of high-quality, multi-hop, and diverse data exceeding 85%. Furthermore, we systematically investigate strategies for document selection, question merging, and validation techniques through extensive experiments across various models. Our findings show that our synthetic high-quality long-context instruction data significantly enhances model performance, even surpassing models trained on larger amounts of human-annotated data. Our code is available at: https://github.com/WowCZ/LongMIT.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2409.02020",
        "abstract url": "https://arxiv.org/abs/2409.02020",
        "title": "Efficient Point Cloud Classification via Offline Distillation Framework and Negative-Weight Self-Distillation Technique",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement in point cloud processing technologies has significantly increased the demand for efficient and compact models that achieve high-accuracy classification. Knowledge distillation has emerged as a potent model compression technique. However, traditional KD often requires extensive computational resources for forward inference of large teacher models, thereby reducing training efficiency for student models and increasing resource demands. To address these challenges, we introduce an innovative offline recording strategy that avoids the simultaneous loading of both teacher and student models, thereby reducing hardware demands. This approach feeds a multitude of augmented samples into the teacher model, recording both the data augmentation parameters and the corresponding logit outputs. By applying shape-level augmentation operations such as random scaling and translation, while excluding point-level operations like random jittering, the size of the records is significantly reduced. Additionally, to mitigate the issue of small student model over-imitating the teacher model's outputs and converging to suboptimal solutions, we incorporate a negative-weight self-distillation strategy. Experimental results demonstrate that the proposed distillation strategy enables the student model to achieve performance comparable to state-of-the-art models while maintaining lower parameter count. This approach strikes an optimal balance between performance and complexity. This study highlights the potential of our method to optimize knowledge distillation for point cloud classification tasks, particularly in resource-constrained environments, providing a novel solution for efficient point cloud analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02026",
        "abstract url": "https://arxiv.org/abs/2409.02026",
        "title": "Foundations of Large Language Model Compression -- Part 1: Weight Quantization",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, compression of large language models (LLMs) has emerged as an important problem to allow language model deployment on resource-constrained devices, reduce computational costs, and mitigate the environmental footprint of large-scale AI infrastructure. In this paper, we present the foundations of LLM quantization from a convex optimization perspective and propose a quantization method that builds on these foundations and outperforms previous methods. Our quantization framework, CVXQ, scales to models containing hundreds of billions of weight parameters and provides users with the flexibility to compress models to any specified model size, post-training. A reference implementation of CVXQ can be obtained from https://github.com/seannz/cvxq.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2409.02041",
        "abstract url": "https://arxiv.org/abs/2409.02041",
        "title": "The USTC-NERCSLIP Systems for the CHiME-8 NOTSOFAR-1 Challenge",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This technical report outlines our submission system for the CHiME-8 NOTSOFAR-1 Challenge. The primary difficulty of this challenge is the dataset recorded across various conference rooms, which captures real-world complexities such as high overlap rates, background noises, a variable number of speakers, and natural conversation styles. To address these issues, we optimized the system in several aspects: For front-end speech signal processing, we introduced a data-driven joint training method for diarization and separation (JDS) to enhance audio quality. Additionally, we also integrated traditional guided source separation (GSS) for multi-channel track to provide complementary information for the JDS. For back-end speech recognition, we enhanced Whisper with WavLM, ConvNeXt, and Transformer innovations, applying multi-task training and Noise KLD augmentation, to significantly advance ASR robustness and accuracy. Our system attained a Time-Constrained minimum Permutation Word Error Rate (tcpWER) of 14.265% and 22.989% on the CHiME-8 NOTSOFAR-1 Dev-set-2 multi-channel and single-channel tracks, respectively.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02049",
        "abstract url": "https://arxiv.org/abs/2409.02049",
        "title": "Low-Resolution Face Recognition via Adaptable Instance-Relation Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Low-resolution face recognition is a challenging task due to the missing of informative details. Recent approaches based on knowledge distillation have proven that high-resolution clues can well guide low-resolution face recognition via proper knowledge transfer. However, due to the distribution difference between training and testing faces, the learned models often suffer from poor adaptability. To address that, we split the knowledge transfer process into distillation and adaptation steps, and propose an adaptable instance-relation distillation approach to facilitate low-resolution face recognition. In the approach, the student distills knowledge from high-resolution teacher in both instance level and relation level, providing sufficient cross-resolution knowledge transfer. Then, the learned student can be adaptable to recognize low-resolution faces with adaptive batch normalization in inference. In this manner, the capability of recovering missing details of familiar low-resolution faces can be effectively enhanced, leading to a better knowledge transfer. Extensive experiments on low-resolution face recognition clearly demonstrate the effectiveness and adaptability of our approach.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "comment": "Accepted by IJCNN 2024"
    },
    {
        "paper id": "2409.02050",
        "abstract url": "https://arxiv.org/abs/2409.02050",
        "title": "Enhancing Code-Switching Speech Recognition with LID-Based Collaborative Mixture of Experts Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Due to the inherent difficulty in modeling phonetic similarities across different languages, code-switching speech recognition presents a formidable challenge. This study proposes a Collaborative-MoE, a Mixture of Experts (MoE) model that leverages a collaborative mechanism among expert groups. Initially, a preceding routing network explicitly learns Language Identification (LID) tasks and selects experts based on acquired LID weights. This process ensures robust routing information to the MoE layer, mitigating interference from diverse language domains on expert network parameter updates. The LID weights are also employed to facilitate inter-group collaboration, enabling the integration of language-specific representations. Furthermore, within each language expert group, a gating network operates unsupervised to foster collaboration on attributes beyond language. Extensive experiments demonstrate the efficacy of our approach, achieving significant performance enhancements compared to alternative methods. Importantly, our method preserves the efficient inference capabilities characteristic of MoE models without necessitating additional pre-training.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by IEEE SLT 2024"
    },
    {
        "paper id": "2409.02060",
        "abstract url": "https://arxiv.org/abs/2409.02060",
        "title": "OLMoE: Open Mixture-of-Experts Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce OLMoE, a fully open, state-of-the-art language model leveraging sparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but uses only 1B per input token. We pretrain it on 5 trillion tokens and further adapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available models with similar active parameters, even surpassing larger ones like Llama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE training, analyze routing in our model showing high specialization, and open-source all aspects of our work: model weights, training data, code, and logs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "61 pages (24 main), 36 figures, 14 tables"
    },
    {
        "paper id": "2409.02076",
        "abstract url": "https://arxiv.org/abs/2409.02076",
        "title": "Spinning the Golden Thread: Benchmarking Long-Form Generation in Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The abilities of long-context language models (LMs) are often evaluated using the \"Needle-in-a-Haystack\" (NIAH) test, which comprises tasks designed to assess a model's ability to identify specific information (\"needle\") within large text sequences (\"haystack\"). While these benchmarks measure how well models understand long-context input sequences, they do not effectively gauge the quality of long-form text generation--a critical aspect for applications such as design proposals and creative writing. To address this gap, we have introduced a new long-form text evaluation benchmark, Spinning the Golden Thread (SGT), which tests models' ability to identify specific events within generated long text sequences. In this benchmark, we prompt long-context LMs to create long-form text that must include particular events or constraints and evaluate their ability to incorporate these elements. We evaluated ten long-context LMs across four distinct scenarios, three types of prompt instructions, and two different generation-length settings (16K and 32K). Although these models perform well on NIAH benchmarks, none demonstrated satisfactory performance on the Spinning the Golden Thread, raising concerns about their ability to generate coherent long-form text that follows instructions. Additionally, as the length of the generated text increases, all models exhibit a significant drop in performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02078",
        "abstract url": "https://arxiv.org/abs/2409.02078",
        "title": "Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for Political Text",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Social scientists quickly adopted large language models due to their ability to annotate documents without supervised training, an ability known as zero-shot learning. However, due to their compute demands, cost, and often proprietary nature, these models are often at odds with replication and open science standards. This paper introduces the Political DEBATE (DeBERTa Algorithm for Textual Entailment) language models for zero-shot and few-shot classification of political documents. These models are not only as good, or better than, state-of-the art large language models at zero and few-shot classification, but are orders of magnitude more efficient and completely open source. By training the models on a simple random sample of 10-25 documents, they can outperform supervised classifiers trained on hundreds or thousands of documents and state-of-the-art generative models with complex, engineered prompts. Additionally, we release the PolNLI dataset used to train these models -- a corpus of over 200,000 political documents with highly accurate labels across over 800 classification tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "26 pages, 5 figures"
    },
    {
        "paper id": "2409.02228",
        "abstract url": "https://arxiv.org/abs/2409.02228",
        "title": "Unforgettable Generalization in Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "When language models (LMs) are trained to forget (or \"unlearn'') a skill, how precisely does their behavior change? We study the behavior of transformer LMs in which tasks have been forgotten via fine-tuning on randomized labels. Such LMs learn to generate near-random predictions for individual examples in the \"training'' set used for forgetting. Across tasks, however, LMs exhibit extreme variability in whether LM predictions change on examples outside the training set. In some tasks (like entailment classification), forgetting generalizes robustly, and causes models to produce uninformative predictions on new task instances; in other tasks (like physical commonsense reasoning and scientific question answering) forgetting affects only the training examples, and models continue to perform the \"forgotten'' task accurately even for examples very similar to those that appeared in the training set. Dataset difficulty is not predictive of whether a behavior can be forgotten; instead, generalization in forgetting is (weakly) predicted by the confidence of LMs' initial task predictions and the variability of LM representations of training data, with low confidence and low variability both associated with greater generalization. Perhaps most surprisingly, random-label forgetting appears to be somewhat insensitive to the contents of the training set: for example, models trained on science questions with random labels continue to answer other science questions accurately, but begin to produce random labels on entailment classification tasks. Finally, we show that even generalizable forgetting is shallow: linear probes trained on LMs' representations can still perform tasks reliably after forgetting. Our results highlight the difficulty and unpredictability of performing targeted skill removal from models via fine-tuning.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "18 pages, 9 figures, published in First Conference on Language Modeling 2024"
    },
    {
        "paper id": "2409.02239",
        "abstract url": "https://arxiv.org/abs/2409.02239",
        "title": "Temporal Order Preserved Optimal Transport-based Cross-modal Knowledge Transfer Learning for ASR",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to an acoustic model has been shown to greatly improve the performance of automatic speech recognition (ASR). However, due to the heterogeneous feature distributions in cross-modalities, designing an effective model for feature alignment and knowledge transfer between linguistic and acoustic sequences remains a challenging task. Optimal transport (OT), which efficiently measures probability distribution discrepancies, holds great potential for aligning and transferring knowledge between acoustic and linguistic modalities. Nonetheless, the original OT treats acoustic and linguistic feature sequences as two unordered sets in alignment and neglects temporal order information during OT coupling estimation. Consequently, a time-consuming pretraining stage is required to learn a good alignment between the acoustic and linguistic representations. In this paper, we propose a Temporal Order Preserved OT (TOT)-based Cross-modal Alignment and Knowledge Transfer (CAKT) (TOT-CAKT) for ASR. In the TOT-CAKT, local neighboring frames of acoustic sequences are smoothly mapped to neighboring regions of linguistic sequences, preserving their temporal order relationship in feature alignment and matching. With the TOT-CAKT model framework, we conduct Mandarin ASR experiments with a pretrained Chinese PLM for linguistic knowledge transfer. Our results demonstrate that the proposed TOT-CAKT significantly improves ASR performance compared to several state-of-the-art models employing linguistic knowledge transfer, and addresses the weaknesses of the original OT-based method in sequential feature alignment for ASR.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "Accepted to IEEE SLT 2024"
    },
    {
        "paper id": "2409.02253",
        "abstract url": "https://arxiv.org/abs/2409.02253",
        "title": "How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model?",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large foundation models have revolutionized the field, yet challenges remain in optimizing multi-modal models for specialized visual tasks. We propose a novel, generalizable methodology to identify preferred image distributions for black-box Vision-Language Models (VLMs) by measuring output consistency across varied input prompts. Applying this to different rendering types of 3D objects, we demonstrate its efficacy across various domains requiring precise interpretation of complex structures, with a focus on Computer-Aided Design (CAD) as an exemplar field. We further refine VLM outputs using in-context learning with human feedback, significantly enhancing explanation quality. To address the lack of benchmarks in specialized domains, we introduce CAD-VQA, a new dataset for evaluating VLMs on CAD-related visual question answering tasks. Our evaluation of state-of-the-art VLMs on CAD-VQA establishes baseline performance levels, providing a framework for advancing VLM capabilities in complex visual reasoning tasks across various fields requiring expert-level visual interpretation. We release the dataset and evaluation codes at \\url{https://github.com/asgsaeid/cad_vqa}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02257",
        "abstract url": "https://arxiv.org/abs/2409.02257",
        "title": "MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Existing benchmarks for large language models (LLMs) increasingly struggle to differentiate between top-performing models, underscoring the need for more challenging evaluation frameworks. We introduce MMLU-Pro+, an enhanced benchmark building upon MMLU-Pro to assess shortcut learning and higher-order reasoning in LLMs. By incorporating questions with multiple correct answers across diverse domains, MMLU-Pro+ tests LLMs' ability to engage in complex reasoning and resist simplistic problem-solving strategies. Our results show that MMLU-Pro+ maintains MMLU-Pro's difficulty while providing a more rigorous test of model discrimination, particularly in multi-correct answer scenarios. We introduce novel metrics like shortcut selection ratio and correct pair identification ratio, offering deeper insights into model behavior and anchoring bias. Evaluations of five state-of-the-art LLMs reveal significant performance gaps, highlighting variations in reasoning abilities and bias susceptibility. We release the dataset and evaluation codes at \\url{https://github.com/asgsaeid/mmlu-pro-plus}.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02259",
        "abstract url": "https://arxiv.org/abs/2409.02259",
        "title": "Optimal L-Systems for Stochastic L-system Inference Problems",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents two novel theorems that address two open problems in stochastic Lindenmayer-system (L-system) inference, specifically focusing on the construction of an optimal stochastic L-system capable of generating a given sequence of strings. The first theorem delineates a method for crafting a stochastic L-system that maximizes the likelihood of producing a given sequence of words through a singular derivation. Furthermore, the second theorem determines the stochastic L-systems with the highest probability of producing a given sequence of words with multiple possible derivations. From these, we introduce an algorithm to infer an optimal stochastic L-system from a given sequence. This algorithm incorporates sophisticated optimization techniques, such as interior point methods, ensuring production of a stochastically optimal stochastic L-system suitable for generating the given sequence. This allows for the use of using stochastic L-systems as model for machine learning using only positive data for training.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CV",
            "cs.DS",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02266",
        "abstract url": "https://arxiv.org/abs/2409.02266",
        "title": "LSTMSE-Net: Long Short Term Speech Enhancement Network for Audio-visual Speech Enhancement",
        "rating": "1",
        "keywords": [
            [
                "Audio-visual"
            ],
            [
                "Speech Enhancement"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we propose long short term memory speech enhancement network (LSTMSE-Net), an audio-visual speech enhancement (AVSE) method. This innovative method leverages the complementary nature of visual and audio information to boost the quality of speech signals. Visual features are extracted with VisualFeatNet (VFN), and audio features are processed through an encoder and decoder. The system scales and concatenates visual and audio features, then processes them through a separator network for optimized speech enhancement. The architecture highlights advancements in leveraging multi-modal data and interpolation techniques for robust AVSE challenge systems. The performance of LSTMSE-Net surpasses that of the baseline model from the COG-MHEAR AVSE Challenge 2024 by a margin of 0.06 in scale-invariant signal-to-distortion ratio (SISDR), $0.03$ in short-time objective intelligibility (STOI), and $1.32$ in perceptual evaluation of speech quality (PESQ). The source code of the proposed LSTMSE-Net is available at \\url{https://github.com/mtanveer1/AVSEC-3-Challenge}.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "cs.MM",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02281",
        "abstract url": "https://arxiv.org/abs/2409.02281",
        "title": "K-Origins: Better Colour Quantification for Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "K-Origins is a neural network layer designed to improve image-based network performances when learning colour, or intensities, is beneficial. Over 250 encoder-decoder convolutional networks are trained and tested on 16-bit synthetic data, demonstrating that K-Origins improves semantic segmentation accuracy in two scenarios: object detection with low signal-to-noise ratios, and segmenting multiple objects that are identical in shape but vary in colour. K-Origins generates output features from the input features, $\\textbf{X}$, by the equation $\\textbf{Y}_k = \\textbf{X}-\\textbf{J}\\cdot w_k$ for each trainable parameter $w_k$, where $\\textbf{J}$ is a matrix of ones. Additionally, networks with varying receptive fields were trained to determine optimal network depths based on the dimensions of target classes, suggesting that receptive field lengths should exceed object sizes. By ensuring a sufficient receptive field length and incorporating K-Origins, we can achieve better semantic network performance.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "16 pages, 13 figures, 1 table"
    },
    {
        "paper id": "2409.02290",
        "abstract url": "https://arxiv.org/abs/2409.02290",
        "title": "Unsupervised Welding Defect Detection Using Audio And Video",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this work we explore the application of AI to robotic welding. Robotic welding is a widely used technology in many industries, but robots currently do not have the capability to detect welding defects which get introduced due to various reasons in the welding process. We describe how deep-learning methods can be applied to detect weld defects in real-time by recording the welding process with microphones and a camera. Our findings are based on a large database with more than 4000 welding samples we collected which covers different weld types, materials and various defect categories. All deep learning models are trained in an unsupervised fashion because the space of possible defects is large and the defects in our data may contain biases. We demonstrate that a reliable real-time detection of most categories of weld defects is feasible both from audio and video, with improvements achieved by combining both modalities. Specifically, the multi-modal approach achieves an average Area-under-ROC-Curve (AUC) of 0.92 over all eleven defect types in our data. We conclude the paper with an analysis of the results by defect type and a discussion of future work.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "eess.IV"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2409.02324",
        "abstract url": "https://arxiv.org/abs/2409.02324",
        "title": "Visual Servoing for Robotic On-Orbit Servicing: A Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "On-orbit servicing (OOS) activities will power the next big step for sustainable exploration and commercialization of space. Developing robotic capabilities for autonomous OOS operations is a priority for the space industry. Visual Servoing (VS) enables robots to achieve the precise manoeuvres needed for critical OOS missions by utilizing visual information for motion control. This article presents an overview of existing VS approaches for autonomous OOS operations with space manipulator systems (SMS). We divide the approaches according to their contribution to the typical phases of a robotic OOS mission: a) Recognition, b) Approach, and c) Contact. We also present a discussion on the reviewed VS approaches, identifying current trends. Finally, we highlight the challenges and areas for future research on VS techniques for robotic OOS.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "eess.SY"
        ],
        "comment": "Accepted for publication at the 2024 International Conference on Space Robotics (iSpaRo)"
    },
    {
        "paper id": "2409.02326",
        "abstract url": "https://arxiv.org/abs/2409.02326",
        "title": "Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent studies have been increasingly demonstrating that high-quality data is crucial for effective pretraining of language models. However, the precise definition of \"high-quality\" remains underexplored. Focusing on the code domain, we introduce Arctic-SnowCoder-1.3B, a data-efficient base code model pretrained on 555B tokens through three phases of progressively refined data: (1) general pretraining with 500B standard-quality code tokens, preprocessed through basic filtering, deduplication, and decontamination, (2) continued pretraining with 50B high-quality tokens, selected from phase one by a BERT-style quality annotator trained to distinguish good code from random data, using positive examples drawn from high-quality code files, along with instruction data from Magicoder and StarCoder2-Instruct, and (3) enhanced pretraining with 5B synthetic data created by Llama-3.1-70B using phase two data as seeds, adapting the Magicoder approach for pretraining. Despite being trained on a limited dataset, Arctic-SnowCoder achieves state-of-the-art performance on BigCodeBench, a coding benchmark focusing on practical and challenging programming tasks, compared to similarly sized models trained on no more than 1T tokens, outperforming Phi-1.5-1.3B by 36%. Across all evaluated benchmarks, Arctic-SnowCoder-1.3B beats StarCoderBase-3B pretrained on 1T tokens. Additionally, it matches the performance of leading small base code models trained on trillions of tokens. For example, Arctic-SnowCoder-1.3B surpasses StarCoder2-3B, pretrained on over 3.3T tokens, on HumanEval+, a benchmark that evaluates function-level code generation, and remains competitive on BigCodeBench. Our evaluation presents a comprehensive analysis justifying various design choices for Arctic-SnowCoder. Most importantly, we find that the key to high-quality data is its alignment with the distribution of downstream applications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02343",
        "abstract url": "https://arxiv.org/abs/2409.02343",
        "title": "NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "$k$-Nearest Neighbor search on dense vector embeddings ($k$-NN retrieval) from pre-trained embedding models is the predominant retrieval method for text and images, as well as Retrieval-Augmented Generation (RAG) pipelines. In practice, application developers often fine-tune the embeddings to improve their accuracy on the dataset and query workload in hand. Existing approaches either fine-tune the pre-trained model itself or, more efficiently, but at the cost of accuracy, train adaptor models to transform the output of the pre-trained model. We present NUDGE, a family of novel non-parametric embedding fine-tuning approaches that are significantly more accurate and efficient than both sets of existing approaches. NUDGE directly modifies the embeddings of data records to maximize the accuracy of $k$-NN retrieval. We present a thorough theoretical and experimental study of NUDGE's non-parametric approach. We show that even though the underlying problem is NP-Hard, constrained variations can be solved efficiently. These constraints additionally ensure that the changes to the embeddings are modest, avoiding large distortions to the semantics learned during pre-training. In experiments across five pre-trained models and nine standard text and image retrieval datasets, NUDGE runs in minutes and often improves NDCG@10 by more than 10% over existing fine-tuning methods. On average, NUDGE provides 3.3x and 4.3x higher increase in accuracy and runs 200x and 3x faster, respectively, over fine-tuning the pre-trained model and training adaptors.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02346",
        "abstract url": "https://arxiv.org/abs/2409.02346",
        "title": "Robust Federated Finetuning of Foundation Models via Alternating Minimization of LoRA",
        "rating": "1",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "federated learning"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has risen as an innovative training strategy that updates only a select few model parameters, significantly lowering both computational and memory demands. PEFT also helps to decrease data transfer in federated learning settings, where communication depends on the size of updates. In this work, we explore the constraints of previous studies that integrate a well-known PEFT method named LoRA with federated fine-tuning, then introduce RoLoRA, a robust federated fine-tuning framework that utilizes an alternating minimization approach for LoRA, providing greater robustness against decreasing fine-tuning parameters and increasing data heterogeneity. Our results indicate that RoLoRA not only presents the communication benefits but also substantially enhances the robustness and effectiveness in multiple federated fine-tuning scenarios.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "Presented at ES-FOMO-II@ICML2024"
    },
    {
        "paper id": "2409.02347",
        "abstract url": "https://arxiv.org/abs/2409.02347",
        "title": "Understanding the Role of Functional Diversity in Weight-Ensembling with Ingredient Selection and Multidimensional Scaling",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Weight-ensembles are formed when the parameters of multiple neural networks are directly averaged into a single model. They have demonstrated generalization capability in-distribution (ID) and out-of-distribution (OOD) which is not completely understood, though they are thought to successfully exploit functional diversity allotted by each distinct model. Given a collection of models, it is also unclear which combination leads to the optimal weight-ensemble; the SOTA is a linear-time ``greedy\" method. We introduce two novel weight-ensembling approaches to study the link between performance dynamics and the nature of how each method decides to use apply the functionally diverse components, akin to diversity-encouragement in the prediction-ensemble literature. We develop a visualization tool to explain how each algorithm explores various domains defined via pairwise-distances to further investigate selection and algorithms' convergence. Empirical analyses shed perspectives which reinforce how high-diversity enhances weight-ensembling while qualifying the extent to which diversity alone improves accuracy. We also demonstrate that sampling positionally distinct models can contribute just as meaningfully to improvements in a weight-ensemble.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Published at the ICML 2024 (Vienna, Austria) Workshop on Foundation Models in the Wild"
    },
    {
        "paper id": "2409.02361",
        "abstract url": "https://arxiv.org/abs/2409.02361",
        "title": "Diversify-verify-adapt: Efficient and Robust Retrieval-Augmented Ambiguous Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The retrieval augmented generation (RAG) framework addresses an ambiguity in user queries in QA systems by retrieving passages that cover all plausible interpretations and generating comprehensive responses based on the passages. However, our preliminary studies reveal that a single retrieval process often suffers from low quality results, as the retrieved passages frequently fail to capture all plausible interpretations. Although the iterative RAG approach has been proposed to address this problem, it comes at the cost of significantly reduced efficiency. To address these issues, we propose the diversify-verify-adapt (DIVA) framework. DIVA first diversifies the retrieved passages to encompass diverse interpretations. Subsequently, DIVA verifies the quality of the passages and adapts the most suitable approach tailored to their quality. This approach improves the QA systems accuracy and robustness by handling low quality retrieval issue in ambiguous questions, while enhancing efficiency.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02368",
        "abstract url": "https://arxiv.org/abs/2409.02368",
        "title": "Pluralistic Salient Object Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce pluralistic salient object detection (PSOD), a novel task aimed at generating multiple plausible salient segmentation results for a given input image. Unlike conventional SOD methods that produce a single segmentation mask for salient objects, this new setting recognizes the inherent complexity of real-world images, comprising multiple objects, and the ambiguity in defining salient objects due to different user intentions. To study this task, we present two new SOD datasets \"DUTS-MM\" and \"DUS-MQ\", along with newly designed evaluation metrics. DUTS-MM builds upon the DUTS dataset but enriches the ground-truth mask annotations from three aspects which 1) improves the mask quality especially for boundary and fine-grained structures; 2) alleviates the annotation inconsistency issue; and 3) provides multiple ground-truth masks for images with saliency ambiguity. DUTS-MQ consists of approximately 100K image-mask pairs with human-annotated preference scores, enabling the learning of real human preferences in measuring mask quality. Building upon these two datasets, we propose a simple yet effective pluralistic SOD baseline based on a Mixture-of-Experts (MOE) design. Equipped with two prediction heads, it simultaneously predicts multiple masks using different query prompts and predicts human preference scores for each mask candidate. Extensive experiments and analyses underscore the significance of our proposed datasets and affirm the effectiveness of our PSOD framework.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02370",
        "abstract url": "https://arxiv.org/abs/2409.02370",
        "title": "Do Large Language Models Possess Sensitive to Sentiment?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have recently displayed their extraordinary capabilities in language understanding. However, how to comprehensively assess the sentiment capabilities of LLMs continues to be a challenge. This paper investigates the ability of LLMs to detect and react to sentiment in text modal. As the integration of LLMs into diverse applications is on the rise, it becomes highly critical to comprehend their sensitivity to emotional tone, as it can influence the user experience and the efficacy of sentiment-driven tasks. We conduct a series of experiments to evaluate the performance of several prominent LLMs in identifying and responding appropriately to sentiments like positive, negative, and neutral emotions. The models' outputs are analyzed across various sentiment benchmarks, and their responses are compared with human evaluations. Our discoveries indicate that although LLMs show a basic sensitivity to sentiment, there are substantial variations in their accuracy and consistency, emphasizing the requirement for further enhancements in their training processes to better capture subtle emotional cues. Take an example in our findings, in some cases, the models might wrongly classify a strongly positive sentiment as neutral, or fail to recognize sarcasm or irony in the text. Such misclassifications highlight the complexity of sentiment analysis and the areas where the models need to be refined. Another aspect is that different LLMs might perform differently on the same set of data, depending on their architecture and training datasets. This variance calls for a more in-depth study of the factors that contribute to the performance differences and how they can be optimized.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "10 pages, 2 figures"
    },
    {
        "paper id": "2409.02371",
        "abstract url": "https://arxiv.org/abs/2409.02371",
        "title": "Unfolding Videos Dynamics via Taylor Expansion",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Taking inspiration from physical motion, we present a new self-supervised dynamics learning strategy for videos: Video Time-Differentiation for Instance Discrimination (ViDiDi). ViDiDi is a simple and data-efficient strategy, readily applicable to existing self-supervised video representation learning frameworks based on instance discrimination. At its core, ViDiDi observes different aspects of a video through various orders of temporal derivatives of its frame sequence. These derivatives, along with the original frames, support the Taylor series expansion of the underlying continuous dynamics at discrete times, where higher-order derivatives emphasize higher-order motion features. ViDiDi learns a single neural network that encodes a video and its temporal derivatives into consistent embeddings following a balanced alternating learning algorithm. By learning consistent representations for original frames and derivatives, the encoder is steered to emphasize motion features over static backgrounds and uncover the hidden dynamics in original frames. Hence, video representations are better separated by dynamic features. We integrate ViDiDi into existing instance discrimination frameworks (VICReg, BYOL, and SimCLR) for pretraining on UCF101 or Kinetics and test on standard benchmarks including video retrieval, action recognition, and action detection. The performances are enhanced by a significant margin without the need for large models or extensive datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02375",
        "abstract url": "https://arxiv.org/abs/2409.02375",
        "title": "How Privacy-Savvy Are Large Language Models? A Case Study on Compliance and Privacy Technical Review",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The recent advances in large language models (LLMs) have significantly expanded their applications across various fields such as language generation, summarization, and complex question answering. However, their application to privacy compliance and technical privacy reviews remains under-explored, raising critical concerns about their ability to adhere to global privacy standards and protect sensitive user data. This paper seeks to address this gap by providing a comprehensive case study evaluating LLMs' performance in privacy-related tasks such as privacy information extraction (PIE), legal and regulatory key point detection (KPD), and question answering (QA) with respect to privacy policies and data protection regulations. We introduce a Privacy Technical Review (PTR) framework, highlighting its role in mitigating privacy risks during the software development life-cycle. Through an empirical assessment, we investigate the capacity of several prominent LLMs, including BERT, GPT-3.5, GPT-4, and custom models, in executing privacy compliance checks and technical privacy reviews. Our experiments benchmark the models across multiple dimensions, focusing on their precision, recall, and F1-scores in extracting privacy-sensitive information and detecting key regulatory compliance points. While LLMs show promise in automating privacy reviews and identifying regulatory discrepancies, significant gaps persist in their ability to fully comply with evolving legal standards. We provide actionable recommendations for enhancing LLMs' capabilities in privacy compliance, emphasizing the need for robust model improvements and better integration with legal and regulatory requirements. This study underscores the growing importance of developing privacy-aware LLMs that can both support businesses in compliance efforts and safeguard user privacy rights.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2409.02384",
        "abstract url": "https://arxiv.org/abs/2409.02384",
        "title": "STAB: Speech Tokenizer Assessment Benchmark",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Representing speech as discrete tokens provides a framework for transforming speech into a format that closely resembles text, thus enabling the use of speech as an input to the widely successful large language models (LLMs). Currently, while several speech tokenizers have been proposed, there is ambiguity regarding the properties that are desired from a tokenizer for specific downstream tasks and its overall generalizability. Evaluating the performance of tokenizers across different downstream tasks is a computationally intensive effort that poses challenges for scalability. To circumvent this requirement, we present STAB (Speech Tokenizer Assessment Benchmark), a systematic evaluation framework designed to assess speech tokenizers comprehensively and shed light on their inherent characteristics. This framework provides a deeper understanding of the underlying mechanisms of speech tokenization, thereby offering a valuable resource for expediting the advancement of future tokenizer models and enabling comparative analysis using a standardized benchmark. We evaluate the STAB metrics and correlate this with downstream task performance across a range of speech tasks and tokenizer choices.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2409.02385",
        "abstract url": "https://arxiv.org/abs/2409.02385",
        "title": "Unified Framework with Consistency across Modalities for Human Activity Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recognizing human activities in videos is challenging due to the spatio-temporal complexity and context-dependence of human interactions. Prior studies often rely on single input modalities, such as RGB or skeletal data, limiting their ability to exploit the complementary advantages across modalities. Recent studies focus on combining these two modalities using simple feature fusion techniques. However, due to the inherent disparities in representation between these input modalities, designing a unified neural network architecture to effectively leverage their complementary information remains a significant challenge. To address this, we propose a comprehensive multimodal framework for robust video-based human activity recognition. Our key contribution is the introduction of a novel compositional query machine, called COMPUTER ($\\textbf{COMP}ositional h\\textbf{U}man-cen\\textbf{T}ric qu\\textbf{ER}y$ machine), a generic neural architecture that models the interactions between a human of interest and its surroundings in both space and time. Thanks to its versatile design, COMPUTER can be leveraged to distill distinctive representations for various input modalities. Additionally, we introduce a consistency loss that enforces agreement in prediction between modalities, exploiting the complementary information from multimodal inputs for robust human movement recognition. Through extensive experiments on action localization and group activity recognition tasks, our approach demonstrates superior performance when compared with state-of-the-art methods. Our code is available at: https://github.com/tranxuantuyen/COMPUTER.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to BMVC 2024"
    },
    {
        "paper id": "2409.02387",
        "abstract url": "https://arxiv.org/abs/2409.02387",
        "title": "Large Language Models and Cognitive Science: A Comprehensive Review of Similarities, Differences, and Challenges",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This comprehensive review explores the intersection of Large Language Models (LLMs) and cognitive science, examining similarities and differences between LLMs and human cognitive processes. We analyze methods for evaluating LLMs cognitive abilities and discuss their potential as cognitive models. The review covers applications of LLMs in various cognitive fields, highlighting insights gained for cognitive science research. We assess cognitive biases and limitations of LLMs, along with proposed methods for improving their performance. The integration of LLMs with cognitive architectures is examined, revealing promising avenues for enhancing artificial intelligence (AI) capabilities. Key challenges and future research directions are identified, emphasizing the need for continued refinement of LLMs to better align with human cognition. This review provides a balanced perspective on the current state and future potential of LLMs in advancing our understanding of both artificial and human intelligence.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "10 pages, 1 figure"
    },
    {
        "paper id": "2409.02406",
        "abstract url": "https://arxiv.org/abs/2409.02406",
        "title": "Hadamard Row-Wise Generation Algorithm",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce an efficient algorithm for generating specific Hadamard rows, addressing the memory demands of pre-computing the entire matrix. Leveraging Sylvester's recursive construction, our method generates the required $i$-th row on demand, significantly reducing computational resources. The algorithm uses the Kronecker product to construct the desired row from the binary representation of the index, without creating the full matrix. This approach is particularly useful for single-pixel imaging systems that need only one row at a time.",
        "subjects": [
            "cs.DS",
            "cs.CC",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02413",
        "abstract url": "https://arxiv.org/abs/2409.02413",
        "title": "Abstractive Text Summarization: State of the Art, Challenges, and Improvements",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Specifically focusing on the landscape of abstractive text summarization, as opposed to extractive techniques, this survey presents a comprehensive overview, delving into state-of-the-art techniques, prevailing challenges, and prospective research directions. We categorize the techniques into traditional sequence-to-sequence models, pre-trained large language models, reinforcement learning, hierarchical methods, and multi-modal summarization. Unlike prior works that did not examine complexities, scalability and comparisons of techniques in detail, this review takes a comprehensive approach encompassing state-of-the-art methods, challenges, solutions, comparisons, limitations and charts out future improvements - providing researchers an extensive overview to advance abstractive summarization research. We provide vital comparison tables across techniques categorized - offering insights into model complexity, scalability and appropriate applications. The paper highlights challenges such as inadequate meaning representation, factual consistency, controllable text summarization, cross-lingual summarization, and evaluation metrics, among others. Solutions leveraging knowledge incorporation and other innovative strategies are proposed to address these challenges. The paper concludes by highlighting emerging research areas like factual inconsistency, domain-specific, cross-lingual, multilingual, and long-document summarization, as well as handling noisy data. Our objective is to provide researchers and practitioners with a structured overview of the domain, enabling them to better understand the current landscape and identify potential areas for further research and improvement.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "9 Tables, 7 Figures"
    },
    {
        "paper id": "2409.02428",
        "abstract url": "https://arxiv.org/abs/2409.02428",
        "title": "Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Leveraging large language models (LLMs) for designing reward functions demonstrates significant potential. However, achieving effective design and improvement of reward functions in reinforcement learning (RL) tasks with complex custom environments and multiple requirements presents considerable challenges. In this paper, we enable LLMs to be effective white-box searchers, highlighting their advanced semantic understanding capabilities. Specifically, we generate reward components for each explicit user requirement and employ the reward critic to identify the correct code form. Then, LLMs assign weights to the reward components to balance their values and iteratively search and optimize these weights based on the context provided by the training log analyzer, while adaptively determining the search step size. We applied the framework to an underwater information collection RL task without direct human feedback or reward examples (zero-shot). The reward critic successfully correct the reward code with only one feedback for each requirement, effectively preventing irreparable errors that can occur when reward function feedback is provided in aggregate. The effective initialization of weights enables the acquisition of different reward functions within the Pareto solution set without weight search. Even in the case where a weight is 100 times off, fewer than four iterations are needed to obtain solutions that meet user requirements. The framework also works well with most prompts utilizing GPT-3.5 Turbo, since it does not require advanced numerical understanding or calculation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02438",
        "abstract url": "https://arxiv.org/abs/2409.02438",
        "title": "Non-target Divergence Hypothesis: Toward Understanding Domain Gaps in Cross-Modal Knowledge Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Compared to single-modal knowledge distillation, cross-modal knowledge distillation faces more severe challenges due to domain gaps between modalities. Although various methods have proposed various solutions to overcome these challenges, there is still limited research on how domain gaps affect cross-modal knowledge distillation. This paper provides an in-depth analysis and evaluation of this issue. We first introduce the Non-Target Divergence Hypothesis (NTDH) to reveal the impact of domain gaps on cross-modal knowledge distillation. Our key finding is that domain gaps between modalities lead to distribution differences in non-target classes, and the smaller these differences, the better the performance of cross-modal knowledge distillation. Subsequently, based on Vapnik-Chervonenkis (VC) theory, we derive the upper and lower bounds of the approximation error for cross-modal knowledge distillation, thereby theoretically validating the NTDH. Finally, experiments on five cross-modal datasets further confirm the validity, generalisability, and applicability of the NTDH.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02865",
        "abstract url": "https://arxiv.org/abs/2409.02865",
        "title": "Visually Grounded Speech Models for Low-resource Languages and Cognitive Modelling",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "This dissertation examines visually grounded speech (VGS) models that learn from unlabelled speech paired with images. It focuses on applications for low-resource languages and understanding human language acquisition. We introduce a task called visually prompted keyword localisation to detect and localise keywords in speech using images. We demonstrate the effectiveness of VGS models in few-shot learning scenarios for low-resource languages like Yoruba. Additionally, we examine the mutual exclusivity bias in VGS models. Our monolingual VGS model exhibits this bias, but we found that multilingualism does not affect the bias in this VGS model similarly to what is observed in children.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": "PhD Dissertation"
    },
    {
        "paper id": "2409.04464",
        "abstract url": "https://arxiv.org/abs/2409.04464",
        "title": "Leveraging Large Language Models for Solving Rare MIP Challenges",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Mixed Integer Programming (MIP) has been extensively applied in areas requiring mathematical solvers to address complex instances within tight time constraints. However, as the problem scale increases, the complexity of model formulation and finding feasible solutions escalates significantly. In contrast, the model-building cost for end-to-end models, such as large language models (LLMs), remains largely unaffected by problem scale due to their pattern recognition capabilities. While LLMs, like GPT-4, without fine-tuning, can handle some traditional medium-scale MIP problems, they struggle with uncommon or highly specialized MIP scenarios. Fine-tuning LLMs can yield some feasible solutions for medium-scale MIP instances, but these models typically fail to explore diverse solutions when constrained by a low and constant temperature, limiting their performance. In this paper, we propose and evaluate a recursively dynamic temperature method integrated with a chain-of-thought approach. Our findings show that starting with a high temperature and gradually lowering it leads to better feasible solutions compared to other dynamic temperature strategies. Additionally, by comparing results generated by the LLM with those from Gurobi, we demonstrate that the LLM can produce solutions that complement traditional solvers by accelerating the pruning process and improving overall efficiency.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01612",
        "abstract url": "https://arxiv.org/abs/2409.01612",
        "title": "Lexicographic optimization-based approaches to learning a representative model for multi-criteria sorting with non-monotonic criteria",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deriving a representative model using value function-based methods from the perspective of preference disaggregation has emerged as a prominent and growing topic in multi-criteria sorting (MCS) problems. A noteworthy observation is that many existing approaches to learning a representative model for MCS problems traditionally assume the monotonicity of criteria, which may not always align with the complexities found in real-world MCS scenarios. Consequently, this paper proposes some approaches to learning a representative model for MCS problems with non-monotonic criteria through the integration of the threshold-based value-driven sorting procedure. To do so, we first define some transformation functions to map the marginal values and category thresholds into a UTA-like functional space. Subsequently, we construct constraint sets to model non-monotonic criteria in MCS problems and develop optimization models to check and rectify the inconsistency of the decision maker's assignment example preference information. By simultaneously considering the complexity and discriminative power of the models, two distinct lexicographic optimization-based approaches are developed to derive a representative model for MCS problems with non-monotonic criteria. Eventually, we offer an illustrative example and conduct comprehensive simulation experiments to elaborate the feasibility and validity of the proposed approaches.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "45 pages, 12 figures"
    },
    {
        "paper id": "2409.01614",
        "abstract url": "https://arxiv.org/abs/2409.01614",
        "title": "On-chain Validation of Tracking Data Messages (TDM) Using Distributed Deep Learning on a Proof of Stake (PoS) Blockchain",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Trustless tracking of Resident Space Objects (RSOs) is crucial for Space Situational Awareness (SSA), especially during adverse situations. The importance of transparent SSA cannot be overstated, as it is vital for ensuring space safety and security. In an era where RSO location information can be easily manipulated, the risk of RSOs being used as weapons is a growing concern. The Tracking Data Message (TDM) is a standardized format for broadcasting RSO observations. However, the varying quality of observations from diverse sensors poses challenges to SSA reliability. While many countries operate space assets, relatively few have SSA capabilities, making it crucial to ensure the accuracy and reliability of the data. Current practices assume complete trust in the transmitting party, leaving SSA capabilities vulnerable to adversarial actions such as spoofing TDMs. This work introduces a trustless mechanism for TDM validation and verification using deep learning over blockchain. By leveraging the trustless nature of blockchain, our approach eliminates the need for a central authority, establishing consensus-based truth. We propose a state-of-the-art, transformer-based orbit propagator that outperforms traditional methods like SGP4, enabling cross-validation of multiple observations for a single RSO. This deep learning-based transformer model can be distributed over a blockchain, allowing interested parties to host a node that contains a part of the distributed deep learning model. Our system comprises decentralised observers and validators within a Proof of Stake (PoS) blockchain. Observers contribute TDM data along with a stake to ensure honesty, while validators run the propagation and validation algorithms. The system rewards observers for contributing verified TDMs and penalizes those submitting unverifiable data.",
        "subjects": [
            "cs.CR",
            "astro-ph.EP",
            "cs.LG"
        ],
        "comment": "Accepted for AMOS 2024"
    },
    {
        "paper id": "2409.01687",
        "abstract url": "https://arxiv.org/abs/2409.01687",
        "title": "A sparse PAC-Bayesian approach for high-dimensional quantile prediction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantile regression, a robust method for estimating conditional quantiles, has advanced significantly in fields such as econometrics, statistics, and machine learning. In high-dimensional settings, where the number of covariates exceeds sample size, penalized methods like lasso have been developed to address sparsity challenges. Bayesian methods, initially connected to quantile regression via the asymmetric Laplace likelihood, have also evolved, though issues with posterior variance have led to new approaches, including pseudo/score likelihoods. This paper presents a novel probabilistic machine learning approach for high-dimensional quantile prediction. It uses a pseudo-Bayesian framework with a scaled Student-t prior and Langevin Monte Carlo for efficient computation. The method demonstrates strong theoretical guarantees, through PAC-Bayes bounds, that establish non-asymptotic oracle inequalities, showing minimax-optimal prediction error and adaptability to unknown sparsity. Its effectiveness is validated through simulations and real-world data, where it performs competitively against established frequentist and Bayesian techniques.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01688",
        "abstract url": "https://arxiv.org/abs/2409.01688",
        "title": "Differentially Private Kernel Density Estimation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a refined differentially private (DP) data structure for kernel density estimation (KDE), offering not only improved privacy-utility tradeoff but also better efficiency over prior results. Specifically, we study the mathematical problem: given a similarity function $f$ (or DP KDE) and a private dataset $X \\subset \\mathbb{R}^d$, our goal is to preprocess $X$ so that for any query $y\\in\\mathbb{R}^d$, we approximate $\\sum_{x \\in X} f(x, y)$ in a differentially private fashion. The best previous algorithm for $f(x,y) =\\| x - y \\|_1$ is the node-contaminated balanced binary tree by [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. Their algorithm requires $O(nd)$ space and time for preprocessing with $n=|X|$. For any query point, the query time is $d \\log n$, with an error guarantee of $(1+\u03b1)$-approximation and $\u03b5^{-1} \u03b1^{-0.5} d^{1.5} R \\log^{1.5} n$. In this paper, we improve the best previous result [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024] in three aspects: - We reduce query time by a factor of $\u03b1^{-1} \\log n$. - We improve the approximation ratio from $\u03b1$ to 1. - We reduce the error dependence by a factor of $\u03b1^{-0.5}$. From a technical perspective, our method of constructing the search tree differs from previous work [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. In prior work, for each query, the answer is split into $\u03b1^{-1} \\log n$ numbers, each derived from the summation of $\\log n$ values in interval tree countings. In contrast, we construct the tree differently, splitting the answer into $\\log n$ numbers, where each is a smart combination of two distance values, two counting values, and $y$ itself. We believe our tree structure may be of independent interest.",
        "subjects": [
            "cs.DS",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01696",
        "abstract url": "https://arxiv.org/abs/2409.01696",
        "title": "On the Vulnerability of Skip Connections to Model Inversion Attacks",
        "rating": "0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Skip connections are fundamental architecture designs for modern deep neural networks (DNNs) such as CNNs and ViTs. While they help improve model performance significantly, we identify a vulnerability associated with skip connections to Model Inversion (MI) attacks, a type of privacy attack that aims to reconstruct private training data through abusive exploitation of a model. In this paper, as a pioneer work to understand how DNN architectures affect MI, we study the impact of skip connections on MI. We make the following discoveries: 1) Skip connections reinforce MI attacks and compromise data privacy. 2) Skip connections in the last stage are the most critical to attack. 3) RepVGG, an approach to remove skip connections in the inference-time architectures, could not mitigate the vulnerability to MI attacks. 4) Based on our findings, we propose MI-resilient architecture designs for the first time. Without bells and whistles, we show in extensive experiments that our MI-resilient architectures can outperform state-of-the-art (SOTA) defense methods in MI robustness. Furthermore, our MI-resilient architectures are complementary to existing MI defense methods. Our project is available at https://Pillowkoh.github.io/projects/RoLSS/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2409.01762",
        "abstract url": "https://arxiv.org/abs/2409.01762",
        "title": "Decoding finger velocity from cortical spike trains with recurrent spiking neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Invasive cortical brain-machine interfaces (BMIs) can significantly improve the life quality of motor-impaired patients. Nonetheless, externally mounted pedestals pose an infection risk, which calls for fully implanted systems. Such systems, however, must meet strict latency and energy constraints while providing reliable decoding performance. While recurrent spiking neural networks (RSNNs) are ideally suited for ultra-low-power, low-latency processing on neuromorphic hardware, it is unclear whether they meet the above requirements. To address this question, we trained RSNNs to decode finger velocity from cortical spike trains (CSTs) of two macaque monkeys. First, we found that a large RSNN model outperformed existing feedforward spiking neural networks (SNNs) and artificial neural networks (ANNs) in terms of their decoding accuracy. We next developed a tiny RSNN with a smaller memory footprint, low firing rates, and sparse connectivity. Despite its reduced computational requirements, the resulting model performed substantially better than existing SNN and ANN decoders. Our results thus demonstrate that RSNNs offer competitive CST decoding performance under tight resource constraints and are promising candidates for fully implanted ultra-low-power BMIs with the potential to revolutionize patient care.",
        "subjects": [
            "q-bio.NC",
            "cs.HC",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "5 pages, 2 figures. This work has been submitted to the IEEE BioCAS 2024 conference"
    },
    {
        "paper id": "2409.01771",
        "abstract url": "https://arxiv.org/abs/2409.01771",
        "title": "Adoption of smartphones among older adults and the role of perceived threat of cyberattacks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Adoption of smartphones by older adults (i.e., 65+ years old) is poorly understood, especially in relation to cybersecurity and cyberthreats. In this study, we focus on the perceived threat of cyberattacks as a potential barrier to smartphone adoption and use among older adults. The study also aims at investigating the differences between users and non-users of smartphones. We conducted a quantitative cross-sectional survey of older adults in Slovenia (N = 535). The results of covariance-based structural equation modeling indicate consistent support for the associations of intention to use (ItU) with perceived usefulness (PU), subjective norm (SN) and attitude toward use (AtU), the association between ease of use (EoU) and PU, the association between hedonic motivation (HM) and AtU, and the association between smartphone technology anxiety (STA) and fear of use (FoU). Even though the negative association between perceived threat (PT) and ItU was significant in the full sample, the non-user and the not aware subsamples, its role in adoption of smartphones among older adults remains puzzling. We uncovered significant positive associations between PT and AtU (except in the not aware subsample), and PT and PU which we could not fully explain in our study. The results of our study provide some insights on how campaigns promoting adoption of smartphones among older adults, workshops, training and informal teaching might be improved.",
        "subjects": [
            "cs.CY",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01793",
        "abstract url": "https://arxiv.org/abs/2409.01793",
        "title": "Task Weighting through Gradient Projection for Multitask Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In multitask learning, conflicts between task gradients are a frequent issue degrading a model's training performance. This is commonly addressed by using the Gradient Projection algorithm PCGrad that often leads to faster convergence and improved performance metrics. In this work, we present a method to adapt this algorithm to simultaneously also perform task prioritization. Our approach differs from traditional task weighting performed by scaling task losses in that our weighting scheme applies only in cases where tasks are in conflict, but lets the training proceed unhindered otherwise. We replace task weighting factors by a probability distribution that determines which task gradients get projected in conflict cases. Our experiments on the nuScenes, CIFAR-100, and CelebA datasets confirm that our approach is a practical method for task weighting. Paired with multiple different task weighting schemes, we observe a significant improvement in the performance metrics of most tasks compared to Gradient Projection with uniform projection probabilities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01815",
        "abstract url": "https://arxiv.org/abs/2409.01815",
        "title": "Learning State-Dependent Policy Parametrizations for Dynamic Technician Routing with Rework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Home repair and installation services require technicians to visit customers and resolve tasks of different complexity. Technicians often have heterogeneous skills and working experiences. The geographical spread of customers makes achieving only perfect matches between technician skills and task requirements impractical. Additionally, technicians are regularly absent due to sickness. With non-perfect assignments regarding task requirement and technician skill, some tasks may remain unresolved and require a revisit and rework. Companies seek to minimize customer inconvenience due to delay. We model the problem as a sequential decision process where, over a number of service days, customers request service while heterogeneously skilled technicians are routed to serve customers in the system. Each day, our policy iteratively builds tours by adding \"important\" customers. The importance bases on analytical considerations and is measured by respecting routing efficiency, urgency of service, and risk of rework in an integrated fashion. We propose a state-dependent balance of these factors via reinforcement learning. A comprehensive study shows that taking a few non-perfect assignments can be quite beneficial for the overall service quality. We further demonstrate the value provided by a state-dependent parametrization.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01823",
        "abstract url": "https://arxiv.org/abs/2409.01823",
        "title": "DAOs of Collective Intelligence? Unraveling the Complexity of Blockchain Governance in Decentralized Autonomous Organizations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Decentralized autonomous organizations (DAOs) have transformed organizational structures by shifting from traditional hierarchical control to decentralized approaches, leveraging blockchain and cryptoeconomics. Despite managing significant funds and building global networks, DAOs face challenges like declining participation, increasing centralization, and inabilities to adapt to changing environments, which stifle innovation. This paper explores DAOs as complex systems and applies complexity science to explain their inefficiencies. In particular, we discuss DAO challenges, their complex nature, and introduce the self-organization mechanisms of collective intelligence, digital democracy, and adaptation. By applying these mechansims to improve DAO design and construction, a practical design framework for DAOs is created. This contribution lays a foundation for future research at the intersection of complexity science and DAOs.",
        "subjects": [
            "cs.CY",
            "cs.ET",
            "physics.app-ph",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01829",
        "abstract url": "https://arxiv.org/abs/2409.01829",
        "title": "Deep non-parametric logistic model with case-control data and external summary information",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The case-control sampling design serves as a pivotal strategy in mitigating the imbalanced structure observed in binary data. We consider the estimation of a non-parametric logistic model with the case-control data supplemented by external summary information. The incorporation of external summary information ensures the identifiability of the model. We propose a two-step estimation procedure. In the first step, the external information is utilized to estimate the marginal case proportion. In the second step, the estimated proportion is used to construct a weighted objective function for parameter training. A deep neural network architecture is employed for functional approximation. We further derive the non-asymptotic error bound of the proposed estimator. Following this the convergence rate is obtained and is shown to reach the optimal speed of the non-parametric regression estimation. Simulation studies are conducted to evaluate the theoretical findings of the proposed method. A real data example is analyzed for illustration.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "26 pages, 2 figures, 3 tables"
    },
    {
        "paper id": "2409.01869",
        "abstract url": "https://arxiv.org/abs/2409.01869",
        "title": "Feature-Based Interpretable Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "For optimization models to be used in practice, it is crucial that users trust the results. A key factor in this aspect is the interpretability of the solution process. A previous framework for inherently interpretable optimization models used decision trees to map instances to solutions of the underlying optimization model. Based on this work, we investigate how we can use more general optimization rules to further increase interpretability and at the same time give more freedom to the decision maker. The proposed rules do not map to a concrete solution but to a set of solutions characterized by common features. To find such optimization rules, we present an exact methodology using mixed-integer programming formulations as well as heuristics. We also outline the challenges and opportunities that these methods present. In particular, we demonstrate the improvement in solution quality that our approach offers compared to existing frameworks for interpretable optimization and we discuss the relationship between interpretability and performance. These findings are supported by experiments using both synthetic and real-world data.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01872",
        "abstract url": "https://arxiv.org/abs/2409.01872",
        "title": "Latent Distillation for Continual Object Detection at the Edge",
        "rating": "0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "While numerous methods achieving remarkable performance exist in the Object Detection literature, addressing data distribution shifts remains challenging. Continual Learning (CL) offers solutions to this issue, enabling models to adapt to new data while maintaining performance on previous data. This is particularly pertinent for edge devices, common in dynamic environments like automotive and robotics. In this work, we address the memory and computation constraints of edge devices in the Continual Learning for Object Detection (CLOD) scenario. Specifically, (i) we investigate the suitability of an open-source, lightweight, and fast detector, namely NanoDet, for CLOD on edge devices, improving upon larger architectures used in the literature. Moreover, (ii) we propose a novel CL method, called Latent Distillation~(LD), that reduces the number of operations and the memory required by state-of-the-art CL approaches without significantly compromising detection performance. Our approach is validated using the well-known VOC and COCO benchmarks, reducing the distillation parameter overhead by 74\\% and the Floating Points Operations~(FLOPs) by 56\\% per model update compared to other distillation methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "ECCV workshops, Computational Aspects of Deep Learning (CADL) 2024"
    },
    {
        "paper id": "2409.01880",
        "abstract url": "https://arxiv.org/abs/2409.01880",
        "title": "Preserving the Ephemeral: Instagram Story Archiving with the Tidal Tales Plugin",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "We introduce the Tidal Tales Plugin, a Firefox extension for efficiently collecting and archiving of Instagram stories, addressing the challenges of ephemeral data in social media research. It enables an automated collection of story metadata and media files without risking account bans. It contributes to Web Science by facilitating expansive, long-term studies with enhanced data access and integrity.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01908",
        "abstract url": "https://arxiv.org/abs/2409.01908",
        "title": "Bayesian CART models for aggregate claim modeling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes three types of Bayesian CART (or BCART) models for aggregate claim amount, namely, frequency-severity models, sequential models and joint models. We propose a general framework for the BCART models applicable to data with multivariate responses, which is particularly useful for the joint BCART models with a bivariate response: the number of claims and aggregate claim amount. To facilitate frequency-severity modeling, we investigate BCART models for the right-skewed and heavy-tailed claim severity data by using various distributions. We discover that the Weibull distribution is superior to gamma and lognormal distributions, due to its ability to capture different tail characteristics in tree models. Additionally, we find that sequential BCART models and joint BCART models, which incorporate dependence between the number of claims and average severity, are beneficial and thus preferable to the frequency-severity BCART models in which independence is assumed. The effectiveness of these models' performance is illustrated by carefully designed simulations and real insurance data.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "q-fin.ST",
            "stat.AP",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01909",
        "abstract url": "https://arxiv.org/abs/2409.01909",
        "title": "LUK: Empowering Log Understanding with Expert Knowledge from Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Logs play a critical role in providing essential information for system monitoring and troubleshooting. Recently, with the success of pre-trained language models (PLMs) and large language models (LLMs) in natural language processing (NLP), smaller PLMs (such as BERT) and LLMs (like ChatGPT) have become the current mainstream approaches for log analysis. While LLMs possess rich knowledge, their high computational costs and unstable performance make LLMs impractical for analyzing logs directly. In contrast, smaller PLMs can be fine-tuned for specific tasks even with limited computational resources, making them more practical. However, these smaller PLMs face challenges in understanding logs comprehensively due to their limited expert knowledge. To better utilize the knowledge embedded within LLMs for log understanding, this paper introduces a novel knowledge enhancement framework, called LUK, which acquires expert knowledge from LLMs to empower log understanding on a smaller PLM. Specifically, we design a multi-expert collaboration framework based on LLMs consisting of different roles to acquire expert knowledge. In addition, we propose two novel pre-training tasks to enhance the log pre-training with expert knowledge. LUK achieves state-of-the-art results on different log analysis tasks and extensive experiments demonstrate expert knowledge from LLMs can be utilized more effectively to understand logs.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2409.01927",
        "abstract url": "https://arxiv.org/abs/2409.01927",
        "title": "From Grounding to Planning: Benchmarking Bottlenecks in Web Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "General web-based agents are increasingly essential for interacting with complex web environments, yet their performance in real-world web applications remains poor, yielding extremely low accuracy even with state-of-the-art frontier models. We observe that these agents can be decomposed into two primary components: Planning and Grounding. Yet, most existing research treats these agents as black boxes, focusing on end-to-end evaluations which hinder meaningful improvements. We sharpen the distinction between the planning and grounding components and conduct a novel analysis by refining experiments on the Mind2Web dataset. Our work proposes a new benchmark for each of the components separately, identifying the bottlenecks and pain points that limit agent performance. Contrary to prevalent assumptions, our findings suggest that grounding is not a significant bottleneck and can be effectively addressed with current techniques. Instead, the primary challenge lies in the planning component, which is the main source of performance degradation. Through this analysis, we offer new insights and demonstrate practical suggestions for improving the capabilities of web agents, paving the way for more reliable agents.",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01930",
        "abstract url": "https://arxiv.org/abs/2409.01930",
        "title": "Efficient LLM Context Distillation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper specifically investigates context distillation a method that extends the utility of task-specific examples by internalizing them, thus augmenting the example set accessible for model inference.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01958",
        "abstract url": "https://arxiv.org/abs/2409.01958",
        "title": "Private Electronic Payments with Self-Custody and Zero-Knowledge Verified Reissuance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This article builds upon the protocol for digital transfers described by Goodell, Toliver, and Nakib, which combines privacy by design for consumers with strong compliance enforcement for recipients of payments and self-validating assets that carry their own verifiable provenance information. We extend the protocol to allow for the verification that reissued assets were created in accordance with rules prohibiting the creation of new assets by anyone but the issuer, without exposing information about the circumstances in which the assets were created that could be used to identify the payer. The modified protocol combines an audit log with zero-knowledge proofs, so that a consumer spending an asset can demonstrate that there exists a valid entry on the audit log that is associated with the asset, without specifying which entry it is. This property is important as a means to allow money to be reissued within the system without the involvement of system operators within the zone of control of the original issuer. Additionally, we identify a key property of privacy-respecting electronic payments, wherein the payer is not required to retain secrets arising from one transaction until the following transaction, and argue that this property is essential to framing security requirements for storage of digital assets and the risk of blackmail or coercion as a way to exfiltrate information about payment history. We claim that the design of our protocol strongly protects the anonymity of payers with respect to their payment transactions, while preventing the creation of assets by any party other than the original issuer without destroying assets of equal value.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "19 pages, 3 figures"
    },
    {
        "paper id": "2409.01968",
        "abstract url": "https://arxiv.org/abs/2409.01968",
        "title": "Learning Machines: In Search of a Concept Oriented Language",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "What is the next step after the data/digital revolution? What do we need the most to reach this aim? How machines can memorize, learn or discover? What should they be able to do to be qualified as \"intelligent\"? These questions relate to the next generation \"intelligent\" machines. Probably, these machines should be able to handle knowledge discovery, decision-making and concepts. In this paper, we will take into account some historical contributions and discuss these different questions through an analogy to human intelligence. Also, a general framework for a concept oriented language will be proposed.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 8 figures"
    },
    {
        "paper id": "2409.01980",
        "abstract url": "https://arxiv.org/abs/2409.01980",
        "title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems. Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities. The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field. This survey focuses on the problem of anomaly and OOD detection under the context of LLMs. We propose a new taxonomy to categorize existing approaches into three classes based on the role played by LLMs. Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field. We also provide an up-to-date reading list of relevant papers.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "under review"
    },
    {
        "paper id": "2409.01984",
        "abstract url": "https://arxiv.org/abs/2409.01984",
        "title": "Observing Context Improves Disparity Estimation when Race is Unobserved",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "In many domains, it is difficult to obtain the race data that is required to estimate racial disparity. To address this problem, practitioners have adopted the use of proxy methods which predict race using non-protected covariates. However, these proxies often yield biased estimates, especially for minority groups, limiting their real-world utility. In this paper, we introduce two new contextual proxy models that advance existing methods by incorporating contextual features in order to improve race estimates. We show that these algorithms demonstrate significant performance improvements in estimating disparities on real-world home loan and voter data. We establish that achieving unbiased disparity estimates with contextual proxies relies on mean-consistency, a calibration-like condition.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01985",
        "abstract url": "https://arxiv.org/abs/2409.01985",
        "title": "UNSURE: Unknown Noise level Stein's Unbiased Risk Estimator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, many self-supervised learning methods for image reconstruction have been proposed that can learn from noisy data alone, bypassing the need for ground-truth references. Most existing methods cluster around two classes: i) Noise2Self and similar cross-validation methods that require very mild knowledge about the noise distribution, and ii) Stein's Unbiased Risk Estimator (SURE) and similar approaches that assume full knowledge of the distribution. The first class of methods is often suboptimal compared to supervised learning, and the second class is often impractical, as the noise level is generally unknown in real-world applications. In this paper, we provide a theoretical framework that characterizes this expressivity-robustness trade-off and propose a new approach based on SURE, but unlike the standard SURE, does not require knowledge about the noise level. Throughout a series of experiments, we show that the proposed estimator outperforms other existing self-supervised methods on various imaging inverse problems.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01990",
        "abstract url": "https://arxiv.org/abs/2409.01990",
        "title": "Contemporary Model Compression on Large Language Models Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have revolutionized natural language processing by achieving state-of-the-art results across a variety of tasks. However, the computational demands of LLM inference, including high memory consumption and slow processing speeds, pose significant challenges for real-world applications, particularly on resource-constrained devices. Efficient inference is crucial for scaling the deployment of LLMs to a broader range of platforms, including mobile and edge devices. This survey explores contemporary techniques in model compression that address these challenges by reducing the size and computational requirements of LLMs while maintaining their performance. We focus on model-level compression methods, including quantization, knowledge distillation, and pruning, as well as system-level optimizations like KV cache efficient design. Each of these methodologies offers a unique approach to optimizing LLMs, from reducing numerical precision to transferring knowledge between models and structurally simplifying neural networks. Additionally, we discuss emerging trends in system-level design that further enhance the efficiency of LLM inference. This survey aims to provide a comprehensive overview of current advancements in model compression and their potential to make LLMs more accessible and practical for diverse applications.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02017",
        "abstract url": "https://arxiv.org/abs/2409.02017",
        "title": "AI Governance in Higher Education: Case Studies of Guidance at Big Ten Universities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Generative AI has drawn significant attention from stakeholders in higher education. As it introduces new opportunities for personalized learning and tutoring support, it simultaneously poses challenges to academic integrity and leads to ethical issues. Consequently, governing responsible AI usage within higher education institutions (HEIs) becomes increasingly important. Leading universities have already published guidelines on Generative AI, with most attempting to embrace this technology responsibly. This study provides a new perspective by focusing on strategies for responsible AI governance as demonstrated in these guidelines. Through a case study of 14 prestigious universities in the United States, we identified the multi-unit governance of AI, the role-specific governance of AI, and the academic characteristics of AI governance from their AI guidelines. The strengths and potential limitations of these strategies and characteristics are discussed. The findings offer practical implications for guiding responsible AI usage in HEIs and beyond.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02052",
        "abstract url": "https://arxiv.org/abs/2409.02052",
        "title": "Robust Fourier Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fourier embedding has shown great promise in removing spectral bias during neural network training. However, it can still suffer from high generalization errors, especially when the labels or measurements are noisy. We demonstrate that introducing a simple diagonal layer after the Fourier embedding layer makes the network more robust to measurement noise, effectively prompting it to learn sparse Fourier features. We provide theoretical justifications for this Fourier feature learning, leveraging recent developments in diagonal networks and implicit regularization in neural networks. Under certain conditions, our proposed approach can also learn functions that are noisy mixtures of nonlinear functions of Fourier features. Numerical experiments validate the effectiveness of our proposed architecture, supporting our theory.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "31 pages, 9 figures"
    },
    {
        "paper id": "2409.02066",
        "abstract url": "https://arxiv.org/abs/2409.02066",
        "title": "Robust Clustering on High-Dimensional Data with Stochastic Quantization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses the limitations of traditional vector quantization (clustering) algorithms, particularly K-Means and its variant K-Means++, and explores the Stochastic Quantization (SQ) algorithm as a scalable alternative for high-dimensional unsupervised and semi-supervised learning problems. Some traditional clustering algorithms suffer from inefficient memory utilization during computation, necessitating the loading of all data samples into memory, which becomes impractical for large-scale datasets. While variants such as Mini-Batch K-Means partially mitigate this issue by reducing memory usage, they lack robust theoretical convergence guarantees due to the non-convex nature of clustering problems. In contrast, the Stochastic Quantization algorithm provides strong theoretical convergence guarantees, making it a robust alternative for clustering tasks. We demonstrate the computational efficiency and rapid convergence of the algorithm on an image classification problem with partially labeled data, comparing model accuracy across various ratios of labeled to unlabeled data. To address the challenge of high dimensionality, we trained Triplet Network to encode images into low-dimensional representations in a latent space, which serve as a basis for comparing the efficiency of both the Stochastic Quantization algorithm and traditional quantization algorithms. Furthermore, we enhance the algorithm's convergence speed by introducing modifications with an adaptive learning rate.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "20 pages, 5 figures, to be published in the International Scientific Technical Journal \"Problems of Control and Informatics\""
    },
    {
        "paper id": "2409.02077",
        "abstract url": "https://arxiv.org/abs/2409.02077",
        "title": "FastEnsemble: A new scalable ensemble clustering method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Many community detection algorithms are stochastic in nature, and their output can vary based on different input parameters and random seeds. Consensus clustering methods, such as FastConsensus and ECG, combine clusterings from multiple runs of the same clustering algorithm, in order to improve stability and accuracy. In this study we present a new consensus clustering method, FastEnsemble, and show that it provides advantages over both FastConsensus and ECG. Furthermore, FastEnsemble is designed for use with any clustering method, and we show results using \\ourmethod with Leiden optimizing modularity or the Constant Potts model. FastEnsemble is available in Github at https://github.com/ytabatabaee/fast-ensemble",
        "subjects": [
            "cs.SI"
        ],
        "comment": "12 pages, 5 figures, submitted to a conference"
    },
    {
        "paper id": "2409.02079",
        "abstract url": "https://arxiv.org/abs/2409.02079",
        "title": "Synthetic Data Generation and Automated Multidimensional Data Labeling for AI/ML in General and Circular Coordinates",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Insufficient amounts of available training data is a critical challenge for both development and deployment of artificial intelligence and machine learning (AI/ML) models. This paper proposes a unified approach to both synthetic data generation (SDG) and automated data labeling (ADL) with a unified SDG-ADL algorithm. SDG-ADL uses multidimensional (n-D) representations of data visualized losslessly with General Line Coordinates (GLCs), relying on reversible GLC properties to visualize n-D data in multiple GLCs. This paper demonstrates use of the new Circular Coordinates in Static and Dynamic forms, used with Parallel Coordinates and Shifted Paired Coordinates, since each GLC exemplifies unique data properties, such as interattribute n-D distributions and outlier detection. The approach is interactively implemented in computer software with the Dynamic Coordinates Visualization system (DCVis). Results with real data are demonstrated in case studies, evaluating impact on classifiers.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 17 figures, 11 tables"
    },
    {
        "paper id": "2409.02100",
        "abstract url": "https://arxiv.org/abs/2409.02100",
        "title": "On a heuristic approach to the description of consciousness as a hypercomplex system state and the possibility of machine consciousness (German edition)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This article presents a heuristic view that shows that the inner states of consciousness experienced by every human being have a physical but imaginary hypercomplex basis. The hypercomplex description is necessary because certain processes of consciousness cannot be physically measured in principle, but nevertheless exist. Based on theoretical considerations, it could be possible - as a result of mathematical investigations into a so-called bicomplex algebra - to generate and use hypercomplex system states on machines in a targeted manner. The hypothesis of the existence of hypercomplex system states on machines is already supported by the surprising performance of highly complex AI systems. However, this has yet to be proven. In particular, there is a lack of experimental data that distinguishes such systems from other systems, which is why this question will be addressed in later articles. This paper describes the developed bicomplex algebra and possible applications of these findings to generate hypercomplex energy states on machines. In the literature, such system states are often referred to as machine consciousness. The article uses mathematical considerations to explain how artificial consciousness could be generated and what advantages this would have for such AI systems.",
        "subjects": [
            "cs.AI",
            "math.AC",
            "physics.app-ph"
        ],
        "comment": "7 pages, in German language. 1 figure"
    },
    {
        "paper id": "2409.02101",
        "abstract url": "https://arxiv.org/abs/2409.02101",
        "title": "Towards Real-World Adverse Weather Image Restoration: Enhancing Clearness and Semantics with Vision-Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This paper addresses the limitations of adverse weather image restoration approaches trained on synthetic data when applied to real-world scenarios. We formulate a semi-supervised learning framework employing vision-language models to enhance restoration performance across diverse adverse weather conditions in real-world settings. Our approach involves assessing image clearness and providing semantics using vision-language models on real data, serving as supervision signals for training restoration models. For clearness enhancement, we use real-world data, utilizing a dual-step strategy with pseudo-labels assessed by vision-language models and weather prompt learning. For semantic enhancement, we integrate real-world data by adjusting weather conditions in vision-language model descriptions while preserving semantic meaning. Additionally, we introduce an effective training strategy to bootstrap restoration performance. Our approach achieves superior results in real-world adverse weather image restoration, demonstrated through qualitative and quantitative comparisons with state-of-the-art works.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2409.02150",
        "abstract url": "https://arxiv.org/abs/2409.02150",
        "title": "Hazardous Asteroids Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hazardous asteroid has been one of the concerns for humankind as fallen asteroid on earth could cost a huge impact on the society.Monitoring these objects could help predict future impact events, but such efforts are hindered by the large numbers of objects that pass in the Earth's vicinity. The aim of this project is to use machine learning and deep learning to accurately classify hazardous asteroids. A total of ten methods which consist of five machine learning algorithms and five deep learning models are trained and evaluated to find the suitable model that solves the issue. We experiment on two datasets, one from Kaggle and one we extracted from a web service called NeoWS which is a RESTful web service from NASA that provides information about near earth asteroids, it updates every day. In overall, the model is tested on two datasets with different features to find the most accurate model to perform the classification.",
        "subjects": [
            "astro-ph.EP",
            "cs.LG"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.02152",
        "abstract url": "https://arxiv.org/abs/2409.02152",
        "title": "Fair Railway Network Design",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.SI"
            ]
        ],
        "abstract": "When designing a public transportation network in a country, one may want to minimise the sum of travel duration of all inhabitants. This corresponds to a purely utilitarian view and does not involve any fairness consideration, as the resulting network will typically benefit the capital city and/or large central cities while leaving some peripheral cities behind. On the other hand, a more egalitarian view will allow some people to travel between peripheral cities without having to go through a central city. We define a model, propose algorithms for computing solution networks, and report on experiments based on real data.",
        "subjects": [
            "cs.SI",
            "cs.AI"
        ],
        "comment": "32 pages, 18 figures"
    },
    {
        "paper id": "2409.02154",
        "abstract url": "https://arxiv.org/abs/2409.02154",
        "title": "COmoving Computer Acceleration (COCA): $N$-body simulations in an emulated frame of reference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "$N$-body simulations are computationally expensive, so machine-learning (ML)-based emulation techniques have emerged as a way to increase their speed. Although fast, surrogate models have limited trustworthiness due to potentially substantial emulation errors that current approaches cannot correct for. To alleviate this problem, we introduce COmoving Computer Acceleration (COCA), a hybrid framework interfacing ML with an $N$-body simulator. The correct physical equations of motion are solved in an emulated frame of reference, so that any emulation error is corrected by design. This approach corresponds to solving for the perturbation of particle trajectories around the machine-learnt solution, which is computationally cheaper than obtaining the full solution, yet is guaranteed to converge to the truth as one increases the number of force evaluations. Although applicable to any ML algorithm and $N$-body simulator, this approach is assessed in the particular case of particle-mesh cosmological simulations in a frame of reference predicted by a convolutional neural network, where the time dependence is encoded as an additional input parameter to the network. COCA efficiently reduces emulation errors in particle trajectories, requiring far fewer force evaluations than running the corresponding simulation without ML. We obtain accurate final density and velocity fields for a reduced computational budget. We demonstrate that this method shows robustness when applied to examples outside the range of the training data. When compared to the direct emulation of the Lagrangian displacement field using the same training resources, COCA's ability to correct emulation errors results in more accurate predictions. COCA makes $N$-body simulations cheaper by skipping unnecessary force evaluations, while still solving the correct equations of motion and correcting for emulation errors made by ML.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.CO",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "23 pages, 13 figures"
    },
    {
        "paper id": "2409.02219",
        "abstract url": "https://arxiv.org/abs/2409.02219",
        "title": "A+AI: Threats to Society, Remedies, and Governance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "This document focuses on the threats, especially near-term threats, that Artificial Intelligence (AI) brings to society. Most of the threats discussed here can result from any algorithmic process, not just AI; in addition, defining AI is notoriously difficult. For both reasons, it is important to think of \"A+AI\": Algorithms and Artificial Intelligence. In addition to the threats, this paper discusses countermeasures to them, and it includes a table showing which countermeasures are likely to mitigate which threats. Thoughtful governance could manage the risks without seriously impeding progress; in fact, chances are it would accelerate progress by reducing the social chaos that would otherwise be likely. The paper lists specific actions government should take as soon as possible, namely: * Require all social media platforms accessible in the U.S. to offer users verification that their accounts are owned by citizens, and to display every account's verification status * Establish regulations to require that all products created or significantly modified with A+AI be clearly labeled as such; to restrict use of generative AI to create likenesses of persons; and to require creators of generative AI software to disclose materials used to train their software and to compensate the creators of any copyrighted material used * Fund a crash project of research on mitigating the threats * Fund educational campaigns to raise awareness of the threats",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2409.02246",
        "abstract url": "https://arxiv.org/abs/2409.02246",
        "title": "Multi-Agent Reinforcement Learning for Joint Police Patrol and Dispatch",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Police patrol units need to split their time between performing preventive patrol and being dispatched to serve emergency incidents. In the existing literature, patrol and dispatch decisions are often studied separately. We consider joint optimization of these two decisions to improve police operations efficiency and reduce response time to emergency calls. Methodology/results: We propose a novel method for jointly optimizing multi-agent patrol and dispatch to learn policies yielding rapid response times. Our method treats each patroller as an independent Q-learner (agent) with a shared deep Q-network that represents the state-action values. The dispatching decisions are chosen using mixed-integer programming and value function approximation from combinatorial action spaces. We demonstrate that this heterogeneous multi-agent reinforcement learning approach is capable of learning joint policies that outperform those optimized for patrol or dispatch alone. Managerial Implications: Policies jointly optimized for patrol and dispatch can lead to more effective service while targeting demonstrably flexible objectives, such as those encouraging efficiency and equity in response.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02291",
        "abstract url": "https://arxiv.org/abs/2409.02291",
        "title": "Initial Development and Evaluation of the Creative Artificial Intelligence through Recurring Developments and Determinations (CAIRDD) System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Computer system creativity is a key step on the pathway to artificial general intelligence (AGI). It is elusive, however, due to the fact that human creativity is not fully understood and, thus, it is difficult to develop this capability in software. Large language models (LLMs) provide a facsimile of creativity and the appearance of sentience, while not actually being either creative or sentient. While LLMs have created bona fide new content, in some cases - such as with harmful hallucinations - inadvertently, their deliberate creativity is seen by some to not match that of humans. In response to this challenge, this paper proposes a technique for enhancing LLM output creativity via an iterative process of concept injection and refinement. Initial work on the development of the Creative Artificial Intelligence through Recurring Developments and Determinations (CAIRDD) system is presented and the efficacy of key system components is evaluated.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02304",
        "abstract url": "https://arxiv.org/abs/2409.02304",
        "title": "Wikipedia in Wartime: Experiences of Wikipedians Maintaining Articles About the Russia-Ukraine War",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "How do Wikipedians maintain an accurate encyclopedia during an ongoing geopolitical conflict where state actors might seek to spread disinformation or conduct an information operation? In the context of the Russia-Ukraine War, this question becomes more pressing, given the Russian government's extensive history of orchestrating information campaigns. We conducted an interview study with 13 expert Wikipedians involved in the Russo-Ukrainian War topic area on the English-language edition of Wikipedia. While our participants did not perceive there to be clear evidence of a state-backed information operation, they agreed that war-related articles experienced high levels of disruptive editing from both Russia-aligned and Ukraine-aligned accounts. The English-language edition of Wikipedia had existing policies and processes at its disposal to counter such disruption. State-backed or not, the disruptive activity created time-intensive maintenance work for our participants. Finally, participants considered English-language Wikipedia to be more resilient than social media in preventing the spread of false information online. We conclude by discussing sociotechnical implications for Wikipedia and social platforms.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02313",
        "abstract url": "https://arxiv.org/abs/2409.02313",
        "title": "On the Benefits of Memory for Modeling Time-Dependent PDEs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Data-driven techniques have emerged as a promising alternative to traditional numerical methods for solving partial differential equations (PDEs). These techniques frequently offer a better trade-off between computational cost and accuracy for many PDE families of interest. For time-dependent PDEs, existing methodologies typically treat PDEs as Markovian systems, i.e., the evolution of the system only depends on the ``current state'', and not the past states. However, distortion of the input signals -- e.g., due to discretization or low-pass filtering -- can render the evolution of the distorted signals non-Markovian. In this work, motivated by the Mori-Zwanzig theory of model reduction, we investigate the impact of architectures with memory for modeling PDEs: that is, when past states are explicitly used to predict the future. We introduce Memory Neural Operator (MemNO), a network based on the recent SSM architectures and Fourier Neural Operator (FNO). We empirically demonstrate on a variety of PDE families of interest that when the input is given on a low-resolution grid, MemNO significantly outperforms the baselines without memory, achieving more than 6 times less error on unseen PDEs. Via a combination of theory and experiments, we show that the effect of memory is particularly significant when the solution of the PDE has high frequency Fourier components (e.g., low-viscosity fluid dynamics), and it also increases robustness to observation noise.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02327",
        "abstract url": "https://arxiv.org/abs/2409.02327",
        "title": "Generative Principal Component Regression via Variational Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The ability to manipulate complex systems, such as the brain, to modify specific outcomes has far-reaching implications, particularly in the treatment of psychiatric disorders. One approach to designing appropriate manipulations is to target key features of predictive models. While generative latent variable models, such as probabilistic principal component analysis (PPCA), is a powerful tool for identifying targets, they struggle incorporating information relevant to low-variance outcomes into the latent space. When stimulation targets are designed on the latent space in such a scenario, the intervention can be suboptimal with minimal efficacy. To address this problem, we develop a novel objective based on supervised variational autoencoders (SVAEs) that enforces such information is represented in the latent space. The novel objective can be used with linear models, such as PPCA, which we refer to as generative principal component regression (gPCR). We show in simulations that gPCR dramatically improves target selection in manipulation as compared to standard PCR and SVAEs. As part of these simulations, we develop a metric for detecting when relevant information is not properly incorporated into the loadings. We then show in two neural datasets related to stress and social behavior in which gPCR dramatically outperforms PCR in predictive performance and that SVAEs exhibit low incorporation of relevant information into the loadings. Overall, this work suggests that our method significantly improves target selection for manipulation using latent variable models over competitor inference schemes.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02332",
        "abstract url": "https://arxiv.org/abs/2409.02332",
        "title": "Double Machine Learning at Scale to Predict Causal Impact of Customer Actions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causal Impact (CI) of customer actions are broadly used across the industry to inform both short- and long-term investment decisions of various types. In this paper, we apply the double machine learning (DML) methodology to estimate the CI values across 100s of customer actions of business interest and 100s of millions of customers. We operationalize DML through a causal ML library based on Spark with a flexible, JSON-driven model configuration approach to estimate CI at scale (i.e., across hundred of actions and millions of customers). We outline the DML methodology and implementation, and associated benefits over the traditional potential outcomes based CI model. We show population-level as well as customer-level CI values along with confidence intervals. The validation metrics show a 2.2% gain over the baseline methods and a 2.5X gain in the computational time. Our contribution is to advance the scalable application of CI, while also providing an interface that allows faster experimentation, cross-platform support, ability to onboard new use cases, and improves accessibility of underlying code for partner teams.",
        "subjects": [
            "cs.LG",
            "econ.EM",
            "stat.AP",
            "stat.ME"
        ],
        "comment": "16 pages, 11 figures. Accepted at the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2023, Turin, Italy"
    },
    {
        "paper id": "2409.02342",
        "abstract url": "https://arxiv.org/abs/2409.02342",
        "title": "Optimal sampling for least-squares approximation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Least-squares approximation is one of the most important methods for recovering an unknown function from data. While in many applications the data is fixed, in many others there is substantial freedom to choose where to sample. In this paper, we review recent progress on optimal sampling for (weighted) least-squares approximation in arbitrary linear spaces. We introduce the Christoffel function as a key quantity in the analysis of (weighted) least-squares approximation from random samples, then show how it can be used to construct sampling strategies that possess near-optimal sample complexity: namely, the number of samples scales log-linearly in $n$, the dimension of the approximation space. We discuss a series of variations, extensions and further topics, and throughout highlight connections to approximation theory, machine learning, information-based complexity and numerical linear algebra. Finally, motivated by various contemporary applications, we consider a generalization of the classical setting where the samples need not be pointwise samples of a scalar-valued function, and the approximation space need not be linear. We show that even in this significantly more general setting suitable generalizations of the Christoffel function still determine the sample complexity. This provides a unified procedure for designing improved sampling strategies for general recovery problems. This article is largely self-contained, and intended to be accessible to nonspecialists.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02388",
        "abstract url": "https://arxiv.org/abs/2409.02388",
        "title": "Gaussian Rate-Distortion-Perception Coding and Entropy-Constrained Scalar Quantization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper investigates the best known bounds on the quadratic Gaussian distortion-rate-perception function with limited common randomness for the Kullback-Leibler divergence-based perception measure, as well as their counterparts for the squared Wasserstein-2 distance-based perception measure, recently established by Xie et al. These bounds are shown to be nondegenerate in the sense that they cannot be deduced from each other via a refined version of Talagrand's transportation inequality. On the other hand, an improved lower bound is established when the perception measure is given by the squared Wasserstein-2 distance. In addition, it is revealed by exploiting the connection between rate-distortion-perception coding and entropy-constrained scalar quantization that all the aforementioned bounds are generally not tight in the weak perception constraint regime.",
        "subjects": [
            "cs.IT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02391",
        "abstract url": "https://arxiv.org/abs/2409.02391",
        "title": "Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper derives 'scaling laws' -- empirical relationships between the amount of training compute used for a Large Language Model (LLM) and its performance -- for economic outcomes. In a preregistered experiment, 300 professional translators completed 1800 tasks with access to one of thirteen LLMs with differing model training compute sizes (or a control). Our results show that model scaling substantially raises productivity: for every 10x increase in model compute, translators completed tasks 12.3% quicker, received 0.18 s.d. higher grades, and earned 16.1% more per minute (including bonus payments). Further, the gains from model scaling are much higher for lower-skilled workers who gain a 4x larger improvement in task completion speed. These results imply further frontier model scaling -- which is currently estimated at 4x increase per year -- may have significant economic implications.",
        "subjects": [
            "econ.GN",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02404",
        "abstract url": "https://arxiv.org/abs/2409.02404",
        "title": "Learning Privacy-Preserving Student Networks via Discriminative-Generative Distillation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "While deep models have proved successful in learning rich knowledge from massive well-annotated data, they may pose a privacy leakage risk in practical deployment. It is necessary to find an effective trade-off between high utility and strong privacy. In this work, we propose a discriminative-generative distillation approach to learn privacy-preserving deep models. Our key idea is taking models as bridge to distill knowledge from private data and then transfer it to learn a student network via two streams. First, discriminative stream trains a baseline classifier on private data and an ensemble of teachers on multiple disjoint private subsets, respectively. Then, generative stream takes the classifier as a fixed discriminator and trains a generator in a data-free manner. After that, the generator is used to generate massive synthetic data which are further applied to train a variational autoencoder (VAE). Among these synthetic data, a few of them are fed into the teacher ensemble to query labels via differentially private aggregation, while most of them are embedded to the trained VAE for reconstructing synthetic data. Finally, a semi-supervised student learning is performed to simultaneously handle two tasks: knowledge transfer from the teachers with distillation on few privately labeled synthetic data, and knowledge enhancement with tangent-normal adversarial regularization on many triples of reconstructed synthetic data. In this way, our approach can control query cost over private data and mitigate accuracy degradation in a unified manner, leading to a privacy-preserving student model. Extensive experiments and analysis clearly show the effectiveness of the proposed approach.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": "This paper is accepted by IEEE Transactions on Image Processing (TIP)"
    },
    {
        "paper id": "2409.02410",
        "abstract url": "https://arxiv.org/abs/2409.02410",
        "title": "Adaptive Class Emergence Training: Enhancing Neural Network Stability and Generalization through Progressive Target Evolution",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in artificial intelligence, particularly deep neural networks, have pushed the boundaries of what is achievable in complex tasks. Traditional methods for training neural networks in classification problems often rely on static target outputs, such as one-hot encoded vectors, which can lead to unstable optimization and difficulties in handling non-linearities within data. In this paper, we propose a novel training methodology that progressively evolves the target outputs from a null vector to one-hot encoded vectors throughout the training process. This gradual transition allows the network to adapt more smoothly to the increasing complexity of the classification task, maintaining an equilibrium state that reduces the risk of overfitting and enhances generalization. Our approach, inspired by concepts from structural equilibrium in finite element analysis, has been validated through extensive experiments on both synthetic and real-world datasets. The results demonstrate that our method achieves faster convergence, improved accuracy, and better generalization, especially in scenarios with high data complexity and noise. This progressive training framework offers a robust alternative to classical methods, opening new perspectives for more efficient and stable neural network training.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "15 pages, 9 figures, 2 tables"
    },
    {
        "paper id": "2409.02416",
        "abstract url": "https://arxiv.org/abs/2409.02416",
        "title": "Relative-Translation Invariant Wasserstein Distance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a new family of distances, relative-translation invariant Wasserstein distances ($RW_p$), for measuring the similarity of two probability distributions under distribution shift. Generalizing it from the classical optimal transport model, we show that $RW_p$ distances are also real distance metrics defined on the quotient set $\\mathcal{P}_p(\\mathbb{R}^n)/\\sim$ and invariant to distribution translations. When $p=2$, the $RW_2$ distance enjoys more exciting properties, including decomposability of the optimal transport model, translation-invariance of the $RW_2$ distance, and a Pythagorean relationship between $RW_2$ and the classical quadratic Wasserstein distance ($W_2$). Based on these properties, we show that a distribution shift, measured by $W_2$ distance, can be explained in the bias-variance perspective. In addition, we propose a variant of the Sinkhorn algorithm, named $RW_2$ Sinkhorn algorithm, for efficiently calculating $RW_2$ distance, coupling solutions, as well as $W_2$ distance. We also provide the analysis of numerical stability and time complexity for the proposed algorithm. Finally, we validate the $RW_2$ distance metric and the algorithm performance with three experiments. We conduct one numerical validation for the $RW_2$ Sinkhorn algorithm and show two real-world applications demonstrating the effectiveness of using $RW_2$ under distribution shift: digits recognition and similar thunderstorm detection. The experimental results report that our proposed algorithm significantly improves the computational efficiency of Sinkhorn in certain practical applications, and the $RW_2$ distance is robust to distribution translations compared with baselines.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02423",
        "abstract url": "https://arxiv.org/abs/2409.02423",
        "title": "Accelerating Large Language Model Training with Hybrid GPU-based Compression",
        "rating": "0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "3D"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Data Parallelism (DP), Tensor Parallelism (TP), and Pipeline Parallelism (PP) are the three strategies widely adopted to enable fast and efficient Large Language Model (LLM) training. However, these approaches rely on data-intensive communication routines to collect, aggregate, and re-distribute gradients, activations, and other important model information, which pose significant overhead. Co-designed with GPU-based compression libraries, MPI libraries have been proven to reduce message size significantly, and leverage interconnect bandwidth, thus increasing training efficiency while maintaining acceptable accuracy. In this work, we investigate the efficacy of compression-assisted MPI collectives under the context of distributed LLM training using 3D parallelism and ZeRO optimizations. We scaled up to 192 V100 GPUs on the Lassen supercomputer. First, we enabled a na\u00efve compression scheme across all collectives and observed a 22.5\\% increase in TFLOPS per GPU and a 23.6\\% increase in samples per second for GPT-NeoX-20B training. Nonetheless, such a strategy ignores the sparsity discrepancy among messages communicated in each parallelism degree, thus introducing more errors and causing degradation in training loss. Therefore, we incorporated hybrid compression settings toward each parallel dimension and adjusted the compression intensity accordingly. Given their low-rank structure (arXiv:2301.02654), we apply aggressive compression on gradients when performing DP All-reduce. We adopt milder compression to preserve precision while communicating activations, optimizer states, and model parameters in TP and PP. Using the adjusted hybrid compression scheme, we demonstrate a 17.3\\% increase in TFLOPS per GPU and a 12.7\\% increase in samples per second while reaching baseline loss convergence.",
        "subjects": [
            "cs.DC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02431",
        "abstract url": "https://arxiv.org/abs/2409.02431",
        "title": "Adversarial Learning for Neural PDE Solvers with Sparse Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural network solvers for partial differential equations (PDEs) have made significant progress, yet they continue to face challenges related to data scarcity and model robustness. Traditional data augmentation methods, which leverage symmetry or invariance, impose strong assumptions on physical systems that often do not hold in dynamic and complex real-world applications. To address this research gap, this study introduces a universal learning strategy for neural network PDEs, named Systematic Model Augmentation for Robust Training (SMART). By focusing on challenging and improving the model's weaknesses, SMART reduces generalization error during training under data-scarce conditions, leading to significant improvements in prediction accuracy across various PDE scenarios. The effectiveness of the proposed method is demonstrated through both theoretical analysis and extensive experimentation. The code will be available.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02960",
        "abstract url": "https://arxiv.org/abs/2409.02960",
        "title": "Managing multiple agents by automatically adjusting incentives",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the coming years, AI agents will be used for making more complex decisions, including in situations involving many different groups of people. One big challenge is that AI agent tends to act in its own interest, unlike humans who often think about what will be the best for everyone in the long run. In this paper, we explore a method to get self-interested agents to work towards goals that benefit society as a whole. We propose a method to add a manager agent to mediate agent interactions by assigning incentives to certain actions. We tested our method with a supply-chain management problem and showed that this framework (1) increases the raw reward by 22.2%, (2) increases the agents' reward by 23.8%, and (3) increases the manager's reward by 20.1%.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2409.02963",
        "abstract url": "https://arxiv.org/abs/2409.02963",
        "title": "Fair Minimum Representation Clustering via Integer Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Clustering is an unsupervised learning task that aims to partition data into a set of clusters. In many applications, these clusters correspond to real-world constructs (e.g., electoral districts, playlists, TV channels) whose benefit can only be attained by groups when they reach a minimum level of representation (e.g., 50\\% to elect their desired candidate). In this paper, we study the k-means and k-medians clustering problems with the additional constraint that each group (e.g., demographic group) must have a minimum level of representation in at least a given number of clusters. We formulate the problem through a mixed-integer optimization framework and present an alternating minimization algorithm, called MiniReL, that directly incorporates the fairness constraints. While incorporating the fairness criteria leads to an NP-Hard assignment problem within the algorithm, we provide computational approaches that make the algorithm practical even for large datasets. Numerical results show that the approach is able to create fairer clusters with practically no increase in the clustering cost across standard benchmark datasets.",
        "subjects": [
            "math.OC",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2302.03151"
    },
    {
        "paper id": "2409.04465",
        "abstract url": "https://arxiv.org/abs/2409.04465",
        "title": "Here's Charlie! Realising the Semantic Web vision of Agents in the age of LLMs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents our research towards a near-term future in which legal entities, such as individuals and organisations can entrust semi-autonomous AI-driven agents to carry out online interactions on their behalf. The author's research concerns the development of semi-autonomous Web agents, which consult users if and only if the system does not have sufficient context or confidence to proceed working autonomously. This creates a user-agent dialogue that allows the user to teach the agent about the information sources they trust, their data-sharing preferences, and their decision-making preferences. Ultimately, this enables the user to maximise control over their data and decisions while retaining the convenience of using agents, including those driven by LLMs. In view of developing near-term solutions, the research seeks to answer the question: \"How do we build a trustworthy and reliable network of semi-autonomous agents which represent individuals and organisations on the Web?\". After identifying key requirements, the paper presents a demo for a sample use case of a generic personal assistant. This is implemented using (Notation3) rules to enforce safety guarantees around belief, data sharing and data usage and LLMs to allow natural language interaction with users and serendipitous dialogues between software agents.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "The 23rd International Semantic Web Conference, November 11--15, 2024, Hanover, MD - Posters and Demos track"
    },
    {
        "paper id": "2409.04467",
        "abstract url": "https://arxiv.org/abs/2409.04467",
        "title": "State and Action Factorization in Power Grids",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The increase of renewable energy generation towards the zero-emission target is making the problem of controlling power grids more and more challenging. The recent series of competitions Learning To Run a Power Network (L2RPN) have encouraged the use of Reinforcement Learning (RL) for the assistance of human dispatchers in operating power grids. All the solutions proposed so far severely restrict the action space and are based on a single agent acting on the entire grid or multiple independent agents acting at the substations level. In this work, we propose a domain-agnostic algorithm that estimates correlations between state and action components entirely based on data. Highly correlated state-action pairs are grouped together to create simpler, possibly independent subproblems that can lead to distinct learning processes with less computational and data requirements. The algorithm is validated on a power grid benchmark obtained with the Grid2Op simulator that has been used throughout the aforementioned competitions, showing that our algorithm is in line with domain-expert analysis. Based on these results, we lay a theoretically-grounded foundation for using distributed reinforcement learning in order to improve the existing solutions.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04469",
        "abstract url": "https://arxiv.org/abs/2409.04469",
        "title": "Intensional FOL: Many-Sorted Extension",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The concepts used in IFOL have associated to them a list of sorted attributes, and the sorts are the intensional concepts as well. The requirement to extend the unsorted IFOL (Intensional FOL) to many-sorted IFOL is mainly based on the fact that a natural language is implicitly many-sorted and that we intend to use IFOL to support applications that use natural languages. Thus, the proposed version of many-sorted IFOL is just the completion of this conceptual feature of the IFOL.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2409.01652",
        "abstract url": "https://arxiv.org/abs/2409.01652",
        "title": "ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "3D",
                "RGB-D"
            ],
            [
                "robot",
                "Robotic Manipulation"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Representing robotic manipulation tasks as constraints that associate the robot and the environment is a promising way to encode desired robot behaviors. However, it remains unclear how to formulate the constraints such that they are 1) versatile to diverse tasks, 2) free of manual labeling, and 3) optimizable by off-the-shelf solvers to produce robot actions in real-time. In this work, we introduce Relational Keypoint Constraints (ReKep), a visually-grounded representation for constraints in robotic manipulation. Specifically, ReKep is expressed as Python functions mapping a set of 3D keypoints in the environment to a numerical cost. We demonstrate that by representing a manipulation task as a sequence of Relational Keypoint Constraints, we can employ a hierarchical optimization procedure to solve for robot actions (represented by a sequence of end-effector poses in SE(3)) with a perception-action loop at a real-time frequency. Furthermore, in order to circumvent the need for manual specification of ReKep for each new task, we devise an automated procedure that leverages large vision models and vision-language models to produce ReKep from free-form language instructions and RGB-D observations. We present system implementations on a wheeled single-arm platform and a stationary dual-arm platform that can perform a large variety of manipulation tasks, featuring multi-stage, in-the-wild, bimanual, and reactive behaviors, all without task-specific data or environment models. Website at https://rekep-robot.github.io.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01662",
        "abstract url": "https://arxiv.org/abs/2409.01662",
        "title": "Efficiently Expanding Receptive Fields: Local Split Attention and Parallel Aggregation for Enhanced Large-scale Point Cloud Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Expanding the receptive field in a deep learning model for large-scale 3D point cloud segmentation is an effective technique for capturing rich contextual information, which consequently enhances the network's ability to learn meaningful features. However, this often leads to increased computational complexity and risk of overfitting, challenging the efficiency and effectiveness of the learning paradigm. To address these limitations, we propose the Local Split Attention Pooling (LSAP) mechanism to effectively expand the receptive field through a series of local split operations, thus facilitating the acquisition of broader contextual knowledge. Concurrently, it optimizes the computational workload associated with attention-pooling layers to ensure a more streamlined processing workflow. Based on LSAP, a Parallel Aggregation Enhancement (PAE) module is introduced to enable parallel processing of data using both 2D and 3D neighboring information to further enhance contextual representations within the network. In light of the aforementioned designs, we put forth a novel framework, designated as LSNet, for large-scale point cloud semantic segmentation. Extensive evaluations demonstrated the efficacy of seamlessly integrating the proposed PAE module into existing frameworks, yielding significant improvements in mean intersection over union (mIoU) metrics, with a notable increase of up to 11%. Furthermore, LSNet demonstrated superior performance compared to state-of-the-art semantic segmentation networks on three benchmark datasets, including S3DIS, Toronto3D, and SensatUrban. It is noteworthy that our method achieved a substantial speedup of approximately 38.8% compared to those employing similar-sized receptive fields, which serves to highlight both its computational efficiency and practical utility in real-world large-scale scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01691",
        "abstract url": "https://arxiv.org/abs/2409.01691",
        "title": "When 3D Partial Points Meets SAM: Tooth Point Cloud Segmentation with Sparse Labels",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Tooth point cloud segmentation is a fundamental task in many orthodontic applications. Current research mainly focuses on fully supervised learning which demands expensive and tedious manual point-wise annotation. Although recent weakly-supervised alternatives are proposed to use weak labels for 3D segmentation and achieve promising results, they tend to fail when the labels are extremely sparse. Inspired by the powerful promptable segmentation capability of the Segment Anything Model (SAM), we propose a framework named SAMTooth that leverages such capacity to complement the extremely sparse supervision. To automatically generate appropriate point prompts for SAM, we propose a novel Confidence-aware Prompt Generation strategy, where coarse category predictions are aggregated with confidence-aware filtering. Furthermore, to fully exploit the structural and shape clues in SAM's outputs for assisting the 3D feature learning, we advance a Mask-guided Representation Learning that re-projects the generated tooth masks of SAM into 3D space and constrains these points of different teeth to possess distinguished representations. To demonstrate the effectiveness of the framework, we conduct experiments on the public dataset and surprisingly find with only 0.1\\% annotations (one point per tooth), our method can surpass recent weakly supervised methods by a large margin, and the performance is even comparable to the recent fully-supervised methods, showcasing the significant potential of applying SAM to 3D perception tasks with sparse labels. Code is available at https://github.com/CUHK-AIM-Group/SAMTooth.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To appear at MICCAI24"
    },
    {
        "paper id": "2409.01761",
        "abstract url": "https://arxiv.org/abs/2409.01761",
        "title": "PRoGS: Progressive Rendering of Gaussian Splats",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Over the past year, 3D Gaussian Splatting (3DGS) has received significant attention for its ability to represent 3D scenes in a perceptually accurate manner. However, it can require a substantial amount of storage since each splat's individual data must be stored. While compression techniques offer a potential solution by reducing the memory footprint, they still necessitate retrieving the entire scene before any part of it can be rendered. In this work, we introduce a novel approach for progressively rendering such scenes, aiming to display visible content that closely approximates the final scene as early as possible without loading the entire scene into memory. This approach benefits both on-device rendering applications limited by memory constraints and streaming applications where minimal bandwidth usage is preferred. To achieve this, we approximate the contribution of each Gaussian to the final scene and construct an order of prioritization on their inclusion in the rendering process. Additionally, we demonstrate that our approach can be combined with existing compression methods to progressively render (and stream) 3DGS scenes, optimizing bandwidth usage by focusing on the most important splats within a scene. Overall, our work establishes a foundation for making remotely hosted 3DGS content more quickly accessible to end-users in over-the-top consumption scenarios, with our results showing significant improvements in quality across all metrics compared to existing methods.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01781",
        "abstract url": "https://arxiv.org/abs/2409.01781",
        "title": "Dual Advancement of Representation Learning and Clustering for Sparse and Noisy Images",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Sparse and noisy images (SNIs), like those in spatial gene expression data, pose significant challenges for effective representation learning and clustering, which are essential for thorough data analysis and interpretation. In response to these challenges, we propose Dual Advancement of Representation Learning and Clustering (DARLC), an innovative framework that leverages contrastive learning to enhance the representations derived from masked image modeling. Simultaneously, DARLC integrates cluster assignments in a cohesive, end-to-end approach. This integrated clustering strategy addresses the \"class collision problem\" inherent in contrastive learning, thus improving the quality of the resulting representations. To generate more plausible positive views for contrastive learning, we employ a graph attention network-based technique that produces denoised images as augmented data. As such, our framework offers a comprehensive approach that improves the learning of representations by enhancing their local perceptibility, distinctiveness, and the understanding of relational semantics. Furthermore, we utilize a Student's t mixture model to achieve more robust and adaptable clustering of SNIs. Extensive experiments, conducted across 12 different types of datasets consisting of SNIs, demonstrate that DARLC surpasses the state-of-the-art methods in both image clustering and generating image representations that accurately capture gene interactions. Code is available at https://github.com/zipging/DARLC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01782",
        "abstract url": "https://arxiv.org/abs/2409.01782",
        "title": "UWStereo: A Large Synthetic Dataset for Underwater Stereo Matching",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite recent advances in stereo matching, the extension to intricate underwater settings remains unexplored, primarily owing to: 1) the reduced visibility, low contrast, and other adverse effects of underwater images; 2) the difficulty in obtaining ground truth data for training deep learning models, i.e. simultaneously capturing an image and estimating its corresponding pixel-wise depth information in underwater environments. To enable further advance in underwater stereo matching, we introduce a large synthetic dataset called UWStereo. Our dataset includes 29,568 synthetic stereo image pairs with dense and accurate disparity annotations for left view. We design four distinct underwater scenes filled with diverse objects such as corals, ships and robots. We also induce additional variations in camera model, lighting, and environmental effects. In comparison with existing underwater datasets, UWStereo is superior in terms of scale, variation, annotation, and photo-realistic image quality. To substantiate the efficacy of the UWStereo dataset, we undertake a comprehensive evaluation compared with nine state-of-the-art algorithms as benchmarks. The results indicate that current models still struggle to generalize to new domains. Hence, we design a new strategy that learns to reconstruct cross domain masked images before stereo matching training and integrate a cross view attention enhancement module that aggregates long-range content information to enhance the generalization ability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12pages"
    },
    {
        "paper id": "2409.01787",
        "abstract url": "https://arxiv.org/abs/2409.01787",
        "title": "LLM-GAN: Construct Generative Adversarial Network Through Large Language Models For Explainable Fake News Detection",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Explainable fake news detection predicts the authenticity of news items with annotated explanations. Today, Large Language Models (LLMs) are known for their powerful natural language understanding and explanation generation abilities. However, presenting LLMs for explainable fake news detection remains two main challenges. Firstly, fake news appears reasonable and could easily mislead LLMs, leaving them unable to understand the complex news-faking process. Secondly, utilizing LLMs for this task would generate both correct and incorrect explanations, which necessitates abundant labor in the loop. In this paper, we propose LLM-GAN, a novel framework that utilizes prompting mechanisms to enable an LLM to become Generator and Detector and for realistic fake news generation and detection. Our results demonstrate LLM-GAN's effectiveness in both prediction performance and explanation quality. We further showcase the integration of LLM-GAN to a cloud-native AI platform to provide better fake news detection service in the cloud.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01807",
        "abstract url": "https://arxiv.org/abs/2409.01807",
        "title": "EPRecon: An Efficient Framework for Real-Time Panoptic 3D Reconstruction from Monocular Video",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "voxel",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Panoptic 3D reconstruction from a monocular video is a fundamental perceptual task in robotic scene understanding. However, existing efforts suffer from inefficiency in terms of inference speed and accuracy, limiting their practical applicability. We present EPRecon, an efficient real-time panoptic 3D reconstruction framework. Current volumetric-based reconstruction methods usually utilize multi-view depth map fusion to obtain scene depth priors, which is time-consuming and poses challenges to real-time scene reconstruction. To end this, we propose a lightweight module to directly estimate scene depth priors in a 3D volume for reconstruction quality improvement by generating occupancy probabilities of all voxels. In addition, to infer richer panoptic features from occupied voxels, EPRecon extracts panoptic features from both voxel features and corresponding image features, obtaining more detailed and comprehensive instance-level semantic information and achieving more accurate segmentation results. Experimental results on the ScanNetV2 dataset demonstrate the superiority of EPRecon over current state-of-the-art methods in terms of both panoptic 3D reconstruction quality and real-time inference. Code is available at https://github.com/zhen6618/EPRecon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01813",
        "abstract url": "https://arxiv.org/abs/2409.01813",
        "title": "Reassessing Noise Augmentation Methods in the Context of Adversarial Speech",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this study, we investigate if noise-augmented training can concurrently improve adversarial robustness in automatic speech recognition (ASR) systems. We conduct a comparative analysis of the adversarial robustness of four different state-of-the-art ASR architectures, where each of the ASR architectures is trained under three different augmentation conditions: one subject to background noise, speed variations, and reverberations, another subject to speed variations only, and a third without any form of data augmentation. The results demonstrate that noise augmentation not only improves model performance on noisy speech but also the model's robustness to adversarial attacks.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01879",
        "abstract url": "https://arxiv.org/abs/2409.01879",
        "title": "SPiKE: 3D Human Pose from Point Cloud Sequences",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Human Pose Estimation (HPE) is the task of locating keypoints of the human body in 3D space from 2D or 3D representations such as RGB images, depth maps or point clouds. Current HPE methods from depth and point clouds predominantly rely on single-frame estimation and do not exploit temporal information from sequences. This paper presents SPiKE, a novel approach to 3D HPE using point cloud sequences. Unlike existing methods that process frames of a sequence independently, SPiKE leverages temporal context by adopting a Transformer architecture to encode spatio-temporal relationships between points across the sequence. By partitioning the point cloud into local volumes and using spatial feature extraction via point spatial convolution, SPiKE ensures efficient processing by the Transformer while preserving spatial integrity per timestamp. Experiments on the ITOP benchmark for 3D HPE show that SPiKE reaches 89.19% mAP, achieving state-of-the-art performance with significantly lower inference times. Extensive ablations further validate the effectiveness of sequence exploitation and our algorithmic choices. Code and models are available at: https://github.com/iballester/SPiKE",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 4 figures"
    },
    {
        "paper id": "2409.01935",
        "abstract url": "https://arxiv.org/abs/2409.01935",
        "title": "Map-Assisted Remote-Sensing Image Compression at Extremely Low Bitrates",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Remote-sensing (RS) image compression at extremely low bitrates has always been a challenging task in practical scenarios like edge device storage and narrow bandwidth transmission. Generative models including VAEs and GANs have been explored to compress RS images into extremely low-bitrate streams. However, these generative models struggle to reconstruct visually plausible images due to the highly ill-posed nature of extremely low-bitrate image compression. To this end, we propose an image compression framework that utilizes a pre-trained diffusion model with powerful natural image priors to achieve high-realism reconstructions. However, diffusion models tend to hallucinate small structures and textures due to the significant information loss at limited bitrates. Thus, we introduce vector maps as semantic and structural guidance and propose a novel image compression approach named Map-Assisted Generative Compression (MAGC). MAGC employs a two-stage pipeline to compress and decompress RS images at extremely low bitrates. The first stage maps an image into a latent representation, which is then further compressed in a VAE architecture to save bitrates and serves as implicit guidance in the subsequent diffusion process. The second stage conducts a conditional diffusion model to generate a visually pleasing and semantically accurate result using implicit guidance and explicit semantic guidance. Quantitative and qualitative comparisons show that our method outperforms standard codecs and other learning-based methods in terms of perceptual quality and semantic accuracy. The dataset and code will be publicly available at https://github.com/WHUyyx/MAGC.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01936",
        "abstract url": "https://arxiv.org/abs/2409.01936",
        "title": "Optimizing CLIP Models for Image Retrieval with Maintained Joint-Embedding Alignment",
        "rating": "0",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Contrastive Language and Image Pairing (CLIP), a transformative method in multimedia retrieval, typically trains two neural networks concurrently to generate joint embeddings for text and image pairs. However, when applied directly, these models often struggle to differentiate between visually distinct images that have similar captions, resulting in suboptimal performance for image-based similarity searches. This paper addresses the challenge of optimizing CLIP models for various image-based similarity search scenarios, while maintaining their effectiveness in text-based search tasks such as text-to-image retrieval and zero-shot classification. We propose and evaluate two novel methods aimed at refining the retrieval capabilities of CLIP without compromising the alignment between text and image embeddings. The first method involves a sequential fine-tuning process: initially optimizing the image encoder for more precise image retrieval and subsequently realigning the text encoder to these optimized image embeddings. The second approach integrates pseudo-captions during the retrieval-optimization phase to foster direct alignment within the embedding space. Through comprehensive experiments, we demonstrate that these methods enhance CLIP's performance on various benchmarks, including image retrieval, k-NN classification, and zero-shot text-based classification, while maintaining robustness in text-to-image retrieval. Our optimized models permit maintaining a single embedding per image, significantly simplifying the infrastructure needed for large-scale multi-modal similarity search systems.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01944",
        "abstract url": "https://arxiv.org/abs/2409.01944",
        "title": "FuzzCoder: Byte-level Fuzzing Test via Large Language Model",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Fuzzing is an important dynamic program analysis technique designed for finding vulnerabilities in complex software. Fuzzing involves presenting a target program with crafted malicious input to cause crashes, buffer overflows, memory errors, and exceptions. Crafting malicious inputs in an efficient manner is a difficult open problem and the best approaches often apply uniform random mutations to pre-existing valid inputs. In this work, we propose to adopt fine-tuned large language models (FuzzCoder) to learn patterns in the input files from successful attacks to guide future fuzzing explorations. Specifically, we develop a framework to leverage the code LLMs to guide the mutation process of inputs in fuzzing. The mutation process is formulated as the sequence-to-sequence modeling, where LLM receives a sequence of bytes and then outputs the mutated byte sequence. FuzzCoder is fine-tuned on the created instruction dataset (Fuzz-Instruct), where the successful fuzzing history is collected from the heuristic fuzzing tool. FuzzCoder can predict mutation locations and strategies locations in input files to trigger abnormal behaviors of the program. Experimental results show that FuzzCoder based on AFL (American Fuzzy Lop) gain significant improvements in terms of effective proportion of mutation (EPM) and number of crashes (NC) for various input formats including ELF, JPG, MP3, and XML.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2409.01966",
        "abstract url": "https://arxiv.org/abs/2409.01966",
        "title": "MetaFood3D: Large 3D Food Object Dataset with Nutrition Values",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "RGB-D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Food computing is both important and challenging in computer vision (CV). It significantly contributes to the development of CV algorithms due to its frequent presence in datasets across various applications, ranging from classification and instance segmentation to 3D reconstruction. The polymorphic shapes and textures of food, coupled with high variation in forms and vast multimodal information, including language descriptions and nutritional data, make food computing a complex and demanding task for modern CV algorithms. 3D food modeling is a new frontier for addressing food-related problems, due to its inherent capability to deal with random camera views and its straightforward representation for calculating food portion size. However, the primary hurdle in the development of algorithms for food object analysis is the lack of nutrition values in existing 3D datasets. Moreover, in the broader field of 3D research, there is a critical need for domain-specific test datasets. To bridge the gap between general 3D vision and food computing research, we propose MetaFood3D. This dataset consists of 637 meticulously labeled 3D food objects across 108 categories, featuring detailed nutrition information, weight, and food codes linked to a comprehensive nutrition database. The dataset emphasizes intra-class diversity and includes rich modalities such as textured mesh files, RGB-D videos, and segmentation masks. Experimental results demonstrate our dataset's significant potential for improving algorithm performance, highlight the challenging gap between video captures and 3D scanned data, and show the strength of the MetaFood3D dataset in high-quality data generation, simulation, and augmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Dataset is coming soon"
    },
    {
        "paper id": "2409.01971",
        "abstract url": "https://arxiv.org/abs/2409.01971",
        "title": "Snapshot: Towards Application-centered Models for Pedestrian Trajectory Prediction in Urban Traffic Environments",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "Trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper explores pedestrian trajectory prediction in urban traffic while focusing on both model accuracy and real-world applicability. While promising approaches exist, they are often not publicly available, revolve around pedestrian datasets excluding traffic-related information, or resemble architectures that are either not real-time capable or robust. To address these limitations, we first introduce a dedicated benchmark based on Argoverse 2, specifically targeting pedestrians in urban settings. Following this, we present Snapshot, a modular, feed-forward neural network that outperforms the current state of the art while utilizing significantly less information. Despite its agent-centric encoding scheme, Snapshot demonstrates scalability, real-time performance, and robustness to varying motion histories. Moreover, by integrating Snapshot into a modular autonomous driving software stack, we showcase its real-world applicability",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 Pages, 9 Figures"
    },
    {
        "paper id": "2409.01998",
        "abstract url": "https://arxiv.org/abs/2409.01998",
        "title": "SA-MLP: Enhancing Point Cloud Classification with Efficient Addition and Shift Operations in MLP Architectures",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This study addresses the computational inefficiencies in point cloud classification by introducing novel MLP-based architectures inspired by recent advances in CNN optimization. Traditional neural networks heavily rely on multiplication operations, which are computationally expensive. To tackle this, we propose Add-MLP and Shift-MLP, which replace multiplications with addition and shift operations, respectively, significantly enhancing computational efficiency. Building on this, we introduce SA-MLP, a hybrid model that intermixes alternately distributed shift and adder layers to replace MLP layers, maintaining the original number of layers without freezing shift layer weights. This design contrasts with the ShiftAddNet model from previous literature, which replaces convolutional layers with shift and adder layers, leading to a doubling of the number of layers and limited representational capacity due to frozen shift weights. Moreover, SA-MLP optimizes learning by setting distinct learning rates and optimizers specifically for the adder and shift layers, fully leveraging their complementary strengths. Extensive experiments demonstrate that while Add-MLP and Shift-MLP achieve competitive performance, SA-MLP significantly surpasses the multiplication-based baseline MLP model and achieves performance comparable to state-of-the-art MLP-based models. This study offers an efficient and effective solution for point cloud classification, balancing performance with computational efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02007",
        "abstract url": "https://arxiv.org/abs/2409.02007",
        "title": "PMT-MAE: Dual-Branch Self-Supervised Learning with Distillation for Efficient Point Cloud Classification",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Advances in self-supervised learning are essential for enhancing feature extraction and understanding in point cloud processing. This paper introduces PMT-MAE (Point MLP-Transformer Masked Autoencoder), a novel self-supervised learning framework for point cloud classification. PMT-MAE features a dual-branch architecture that integrates Transformer and MLP components to capture rich features. The Transformer branch leverages global self-attention for intricate feature interactions, while the parallel MLP branch processes tokens through shared fully connected layers, offering a complementary feature transformation pathway. A fusion mechanism then combines these features, enhancing the model's capacity to learn comprehensive 3D representations. Guided by the sophisticated teacher model Point-M2AE, PMT-MAE employs a distillation strategy that includes feature distillation during pre-training and logit distillation during fine-tuning, ensuring effective knowledge transfer. On the ModelNet40 classification task, achieving an accuracy of 93.6\\% without employing voting strategy, PMT-MAE surpasses the baseline Point-MAE (93.2\\%) and the teacher Point-M2AE (93.4\\%), underscoring its ability to learn discriminative 3D point cloud representations. Additionally, this framework demonstrates high efficiency, requiring only 40 epochs for both pre-training and fine-tuning. PMT-MAE's effectiveness and efficiency render it well-suited for scenarios with limited computational resources, positioning it as a promising solution for practical point cloud analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02084",
        "abstract url": "https://arxiv.org/abs/2409.02084",
        "title": "GraspSplats: Efficient Manipulation with 3D Feature Splatting",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "3D",
                "depth",
                "NeRF"
            ],
            [
                "robot"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The ability for robots to perform efficient and zero-shot grasping of object parts is crucial for practical applications and is becoming prevalent with recent advances in Vision-Language Models (VLMs). To bridge the 2D-to-3D gap for representations to support such a capability, existing methods rely on neural fields (NeRFs) via differentiable rendering or point-based projection methods. However, we demonstrate that NeRFs are inappropriate for scene changes due to their implicitness and point-based methods are inaccurate for part localization without rendering-based optimization. To amend these issues, we propose GraspSplats. Using depth supervision and a novel reference feature computation method, GraspSplats generates high-quality scene representations in under 60 seconds. We further validate the advantages of Gaussian-based representation by showing that the explicit and optimized geometry in GraspSplats is sufficient to natively support (1) real-time grasp sampling and (2) dynamic and articulated object manipulation with point trackers. With extensive experiments on a Franka robot, we demonstrate that GraspSplats significantly outperforms existing methods under diverse task settings. In particular, GraspSplats outperforms NeRF-based methods like F3RM and LERF-TOGO, and 2D detection methods.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project webpage: https://graspsplats.github.io/"
    },
    {
        "paper id": "2409.02097",
        "abstract url": "https://arxiv.org/abs/2409.02097",
        "title": "LinFusion: 1 GPU, 1 Minute, 16K Image",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Modern diffusion models, particularly those utilizing a Transformer-based UNet for denoising, rely heavily on self-attention operations to manage complex spatial relationships, thus achieving impressive generation performance. However, this existing paradigm faces significant challenges in generating high-resolution visual content due to its quadratic time and memory complexity with respect to the number of spatial tokens. To address this limitation, we aim at a novel linear attention mechanism as an alternative in this paper. Specifically, we begin our exploration from recently introduced models with linear complexity, e.g., Mamba2, RWKV6, Gated Linear Attention, etc, and identify two key features-attention normalization and non-causal inference-that enhance high-resolution visual generation performance. Building on these insights, we introduce a generalized linear attention paradigm, which serves as a low-rank approximation of a wide spectrum of popular linear token mixers. To save the training cost and better leverage pre-trained models, we initialize our models and distill the knowledge from pre-trained StableDiffusion (SD). We find that the distilled model, termed LinFusion, achieves performance on par with or superior to the original SD after only modest training, while significantly reducing time and memory complexity. Extensive experiments on SD-v1.5, SD-v2.1, and SD-XL demonstrate that LinFusion delivers satisfactory zero-shot cross-resolution generation performance, generating high-resolution images like 16K resolution. Moreover, it is highly compatible with pre-trained SD components, such as ControlNet and IP-Adapter, requiring no adaptation efforts. Codes are available at https://github.com/Huage001/LinFusion.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Work in Progress. Codes are available at https://github.com/Huage001/LinFusion"
    },
    {
        "paper id": "2409.02108",
        "abstract url": "https://arxiv.org/abs/2409.02108",
        "title": "Unveiling Deep Shadows: A Survey on Image and Video Shadow Detection, Removal, and Generation in the Era of Deep Learning",
        "rating": "0",
        "keywords": [
            [
                "video editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Shadows are formed when light encounters obstacles, leading to areas of diminished illumination. In computer vision, shadow detection, removal, and generation are crucial for enhancing scene understanding, refining image quality, ensuring visual consistency in video editing, and improving virtual environments. This paper presents a comprehensive survey of shadow detection, removal, and generation in images and videos within the deep learning landscape over the past decade, covering tasks, deep models, datasets, and evaluation metrics. Our key contributions include a comprehensive survey of shadow analysis, standardization of experimental comparisons, exploration of the relationships among model size, speed, and performance, a cross-dataset generalization study, identification of open issues and future directions, and provision of publicly available resources to support further research.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.MM"
        ],
        "comment": "Publicly available results, trained models, and evaluation metrics at https://github.com/xw-hu/Unveiling-Deep-Shadows"
    },
    {
        "paper id": "2409.02243",
        "abstract url": "https://arxiv.org/abs/2409.02243",
        "title": "A Novel Audio-Visual Information Fusion System for Mental Disorders Detection",
        "rating": "0",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "healthcare",
                "diagnosis",
                "fMRI",
                "EEG",
                "facial",
                "physiological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Mental disorders are among the foremost contributors to the global healthcare challenge. Research indicates that timely diagnosis and intervention are vital in treating various mental disorders. However, the early somatization symptoms of certain mental disorders may not be immediately evident, often resulting in their oversight and misdiagnosis. Additionally, the traditional diagnosis methods incur high time and cost. Deep learning methods based on fMRI and EEG have improved the efficiency of the mental disorder detection process. However, the cost of the equipment and trained staff are generally huge. Moreover, most systems are only trained for a specific mental disorder and are not general-purpose. Recently, physiological studies have shown that there are some speech and facial-related symptoms in a few mental disorders (e.g., depression and ADHD). In this paper, we focus on the emotional expression features of mental disorders and introduce a multimodal mental disorder diagnosis system based on audio-visual information input. Our proposed system is based on spatial-temporal attention networks and innovative uses a less computationally intensive pre-train audio recognition network to fine-tune the video recognition module for better results. We also apply the unified system for multiple mental disorders (ADHD and depression) for the first time. The proposed system achieves over 80\\% accuracy on the real multimodal ADHD dataset and achieves state-of-the-art results on the depression dataset AVEC 2014.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "27th International Conference on Information (FUSION)"
    },
    {
        "paper id": "2409.02251",
        "abstract url": "https://arxiv.org/abs/2409.02251",
        "title": "NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Backdoor attacks pose a significant threat when using third-party data for deep learning development. In these attacks, data can be manipulated to cause a trained model to behave improperly when a specific trigger pattern is applied, providing the adversary with unauthorized advantages. While most existing works focus on designing trigger patterns in both visible and invisible to poison the victim class, they typically result in a single targeted class upon the success of the backdoor attack, meaning that the victim class can only be converted to another class based on the adversary predefined value. In this paper, we address this issue by introducing a novel sample-specific multi-targeted backdoor attack, namely NoiseAttack. Specifically, we adopt White Gaussian Noise (WGN) with various Power Spectral Densities (PSD) as our underlying triggers, coupled with a unique training strategy to execute the backdoor attack. This work is the first of its kind to launch a vision backdoor attack with the intent to generate multiple targeted classes with minimal input configuration. Furthermore, our extensive experimental results demonstrate that NoiseAttack can achieve a high attack success rate against popular network architectures and datasets, as well as bypass state-of-the-art backdoor detection methods. Our source code and experiments are available at https://github.com/SiSL-URI/NoiseAttack/tree/main.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02302",
        "abstract url": "https://arxiv.org/abs/2409.02302",
        "title": "Speech Foundation Model Ensembles for the Controlled Singing Voice Deepfake Detection (CtrSVDD) Challenge 2024",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This work details our approach to achieving a leading system with a 1.79% pooled equal error rate (EER) on the evaluation set of the Controlled Singing Voice Deepfake Detection (CtrSVDD). The rapid advancement of generative AI models presents significant challenges for detecting AI-generated deepfake singing voices, attracting increased research attention. The Singing Voice Deepfake Detection (SVDD) Challenge 2024 aims to address this complex task. In this work, we explore the ensemble methods, utilizing speech foundation models to develop robust singing voice anti-spoofing systems. We also introduce a novel Squeeze-and-Excitation Aggregation (SEA) method, which efficiently and effectively integrates representation features from the speech foundation models, surpassing the performance of our other individual systems. Evaluation results confirm the efficacy of our approach in detecting deepfake singing voices. The codes can be accessed at https://github.com/Anmol2059/SVDD2024.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": "Accepted to the IEEE Spoken Language Technology Workshop (SLT) 2024. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.02310",
        "abstract url": "https://arxiv.org/abs/2409.02310",
        "title": "Geometry-aware Feature Matching for Large-Scale Structure from Motion",
        "rating": "0",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Establishing consistent and dense correspondences across multiple images is crucial for Structure from Motion (SfM) systems. Significant view changes, such as air-to-ground with very sparse view overlap, pose an even greater challenge to the correspondence solvers. We present a novel optimization-based approach that significantly enhances existing feature matching methods by introducing geometry cues in addition to color cues. This helps fill gaps when there is less overlap in large-scale scenarios. Our method formulates geometric verification as an optimization problem, guiding feature matching within detector-free methods and using sparse correspondences from detector-based methods as anchor points. By enforcing geometric constraints via the Sampson Distance, our approach ensures that the denser correspondences from detector-free methods are geometrically consistent and more accurate. This hybrid strategy significantly improves correspondence density and accuracy, mitigates multi-view inconsistencies, and leads to notable advancements in camera pose accuracy and point cloud density. It outperforms state-of-the-art feature matching methods on benchmark datasets and enables feature matching in challenging extreme large-scale settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02374",
        "abstract url": "https://arxiv.org/abs/2409.02374",
        "title": "Exploring Low-Dimensional Subspaces in Diffusion Models for Controllable Image Editing",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Image Editing",
                "text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, diffusion models have emerged as a powerful class of generative models. Despite their success, there is still limited understanding of their semantic spaces. This makes it challenging to achieve precise and disentangled image generation without additional training, especially in an unsupervised way. In this work, we improve the understanding of their semantic spaces from intriguing observations: among a certain range of noise levels, (1) the learned posterior mean predictor (PMP) in the diffusion model is locally linear, and (2) the singular vectors of its Jacobian lie in low-dimensional semantic subspaces. We provide a solid theoretical basis to justify the linearity and low-rankness in the PMP. These insights allow us to propose an unsupervised, single-step, training-free LOw-rank COntrollable image editing (LOCO Edit) method for precise local editing in diffusion models. LOCO Edit identified editing directions with nice properties: homogeneity, transferability, composability, and linearity. These properties of LOCO Edit benefit greatly from the low-dimensional semantic subspace. Our method can further be extended to unsupervised or text-supervised editing in various text-to-image diffusion models (T-LOCO Edit). Finally, extensive empirical experiments demonstrate the effectiveness and efficiency of LOCO Edit. The codes will be released at https://github.com/ChicyChen/LOCO-Edit.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02376",
        "abstract url": "https://arxiv.org/abs/2409.02376",
        "title": "Coral Model Generation from Single Images for Virtual Reality Applications",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "With the rapid development of VR technology, the demand for high-quality 3D models is increasing. Traditional methods struggle with efficiency and quality in large-scale customization. This paper introduces a deep-learning framework that generates high-precision 3D coral models from a single image. Using the Coral dataset, the framework extracts geometric and texture features, performs 3D reconstruction, and optimizes design and material blending. Advanced optimization and polygon count control ensure shape accuracy, detail retention, and flexible output for various complexities, catering to high-quality rendering and real-time interaction needs.The project incorporates Explainable AI (XAI) to transform AI-generated models into interactive \"artworks,\" best viewed in VR and XR. This enhances model interpretability and human-machine collaboration. Real-time feedback in VR interactions displays information like coral species and habitat, enriching user experience. The generated models surpass traditional methods in detail, visual quality, and efficiency. This research offers an intelligent approach to 3D content creation for VR, lowering production barriers, and promoting widespread VR applications. Additionally, integrating XAI provides new insights into AI-generated visual content and advances research in 3D vision interpretability.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.HC",
            "cs.MM"
        ],
        "comment": "In Proceedings of Explainable AI for the Arts Workshop 2024 (XAIxArts 2024) arXiv:2406.14485"
    },
    {
        "paper id": "2409.02393",
        "abstract url": "https://arxiv.org/abs/2409.02393",
        "title": "Determination of language families using deep learning",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "We use a c-GAN (convolutional generative adversarial) neural network to analyze transliterated text fragments of extant, dead comprehensible, and one dead non-deciphered (Cypro-Minoan) language to establish linguistic affinities. The paper is agnostic with respect to translation and/or deciphering. However, there is hope that the proposed approach can be useful for decipherment with more sophisticated neural network techniques.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "First draft. Comments are welcome"
    },
    {
        "paper id": "2409.02426",
        "abstract url": "https://arxiv.org/abs/2409.02426",
        "title": "Diffusion Models Learn Low-Dimensional Distributions via Subspace Clustering",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "image editing"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recent empirical studies have demonstrated that diffusion models can effectively learn the image distribution and generate new samples. Remarkably, these models can achieve this even with a small number of training samples despite a large image dimension, circumventing the curse of dimensionality. In this work, we provide theoretical insights into this phenomenon by leveraging key empirical observations: (i) the low intrinsic dimensionality of image data, (ii) a union of manifold structure of image data, and (iii) the low-rank property of the denoising autoencoder in trained diffusion models. These observations motivate us to assume the underlying data distribution of image data as a mixture of low-rank Gaussians and to parameterize the denoising autoencoder as a low-rank model according to the score function of the assumed distribution. With these setups, we rigorously show that optimizing the training loss of diffusion models is equivalent to solving the canonical subspace clustering problem over the training samples. Based on this equivalence, we further show that the minimal number of samples required to learn the underlying distribution scales linearly with the intrinsic dimensions under the above data and model assumptions. This insight sheds light on why diffusion models can break the curse of dimensionality and exhibit the phase transition in learning distributions. Moreover, we empirically establish a correspondence between the subspaces and the semantic representations of image data, facilitating image editing. We validate these results with corroborated experimental results on both simulated distributions and image datasets.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "39 pages, 9 figures"
    },
    {
        "paper id": "2409.02429",
        "abstract url": "https://arxiv.org/abs/2409.02429",
        "title": "Training-free Color-Style Disentanglement for Constrained Text-to-Image Synthesis",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We consider the problem of independently, in a disentangled fashion, controlling the outputs of text-to-image diffusion models with color and style attributes of a user-supplied reference image. We present the first training-free, test-time-only method to disentangle and condition text-to-image models on color and style attributes from reference image. To realize this, we propose two key innovations. Our first contribution is to transform the latent codes at inference time using feature transformations that make the covariance matrix of current generation follow that of the reference image, helping meaningfully transfer color. Next, we observe that there exists a natural disentanglement between color and style in the LAB image space, which we exploit to transform the self-attention feature maps of the image being generated with respect to those of the reference computed from its L channel. Both these operations happen purely at test time and can be done independently or merged. This results in a flexible method where color and style information can come from the same reference image or two different sources, and a new generation can seamlessly fuse them in either scenario.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 17 figures"
    },
    {
        "paper id": "2409.02729",
        "abstract url": "https://arxiv.org/abs/2409.02729",
        "title": "MedUnA: Language guided Unsupervised Adaptation of Vision-Language Models for Medical Image Classification",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "BioBERT",
                "Medical",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In medical image classification, supervised learning is challenging due to the lack of labeled medical images. Contrary to the traditional \\textit{modus operandi} of pre-training followed by fine-tuning, this work leverages the visual-textual alignment within Vision-Language models (\\texttt{VLMs}) to facilitate the unsupervised learning. Specifically, we propose \\underline{Med}ical \\underline{Un}supervised \\underline{A}daptation (\\texttt{MedUnA}), constituting two-stage training: Adapter Pre-training, and Unsupervised Learning. In the first stage, we use descriptions generated by a Large Language Model (\\texttt{LLM}) corresponding to class labels, which are passed through the text encoder \\texttt{BioBERT}. The resulting text embeddings are then aligned with the class labels by training a lightweight \\texttt{adapter}. We choose \\texttt{\\texttt{LLMs}} because of their capability to generate detailed, contextually relevant descriptions to obtain enhanced text embeddings. In the second stage, the trained \\texttt{adapter} is integrated with the visual encoder of \\texttt{MedCLIP}. This stage employs a contrastive entropy-based loss and prompt tuning to align visual embeddings. We incorporate self-entropy minimization into the overall training objective to ensure more confident embeddings, which are crucial for effective unsupervised learning and alignment. We evaluate the performance of \\texttt{MedUnA} on three different kinds of data modalities - chest X-rays, eye fundus and skin lesion images. The results demonstrate significant accuracy gain on average compared to the baselines across different datasets, highlighting the efficacy of our approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01607",
        "abstract url": "https://arxiv.org/abs/2409.01607",
        "title": "Data-driven topology design based on principal component analysis for 3D structural design problems",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Topology optimization is a structural design methodology widely utilized to address engineering challenges. However, sensitivity-based topology optimization methods struggle to solve optimization problems characterized by strong non-linearity. Leveraging the sensitivity-free nature and high capacity of deep generative models, data-driven topology design (DDTD) methodology is considered an effective solution to this problem. Despite this, the training effectiveness of deep generative models diminishes when input size exceeds a threshold while maintaining high degrees of freedom is crucial for accurately characterizing complex structures. To resolve the conflict between the both, we propose DDTD based on principal component analysis (PCA). Its core idea is to replace the direct training of deep generative models with material distributions by using a principal component score matrix obtained from PCA computation and to obtain the generated material distributions with new features through the restoration process. We apply the proposed PCA-based DDTD to the problem of minimizing the maximum stress in 3D structural mechanics and demonstrate it can effectively address the current challenges faced by DDTD that fail to handle 3D structural design problems. Various experiments are conducted to demonstrate the effectiveness and practicability of the proposed PCA-based DDTD.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "19 pages, 18 figures"
    },
    {
        "paper id": "2409.01656",
        "abstract url": "https://arxiv.org/abs/2409.01656",
        "title": "Graphons of Line Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A graphon is the limit of a converging graph sequence. Graphons of dense graphs are useful as they can act as a blueprint and generate graphs of arbitrary size with similar properties. But for sparse graphs this is not the case. Sparse graphs converge to the zero graphon, making the generated graphs empty or edgeless. Thus, the classical graphon definition fails for sparse graphs. Several methods have been proposed to overcome this limitation and to understand sparse graphs more deeply. However, the fragile nature of sparse graphs makes these methods mathematically complex. In this paper we show a simple method that can shed light on a certain subset of sparse graphs. The method involves mapping the original graphs to their line graphs. Line graphs map edges to vertices and connects edges when edges in the original graph share a vertex. We show that graphs satisfying a particular property, which we call the square-degree property are sparse, but give rise to dense line graphs. In particular, star graphs satisfy the square-degree property resulting in dense line graphs and non-zero graphons of line graphs. Similarly, superlinear preferential attachment graphs give rise to dense line graphs almost surely. In contrast, dense graphs, including Erdos-Renyi graphs make the line graphs sparse, resulting in the zero graphon.",
        "subjects": [
            "stat.ML",
            "cs.DM",
            "cs.LG",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01668",
        "abstract url": "https://arxiv.org/abs/2409.01668",
        "title": "Pureformer-VC: Non-parallel One-Shot Voice Conversion with Pure Transformer Blocks and Triplet Discriminative Training",
        "rating": "-0.5",
        "keywords": [
            [
                "Voice Conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "One-shot voice conversion(VC) aims to change the timbre of any source speech to match that of the target speaker with only one speech sample. Existing style transfer-based VC methods relied on speech representation disentanglement and suffered from accurately and independently encoding each speech component and recomposing back to converted speech effectively. To tackle this, we proposed Pureformer-VC, which utilizes Conformer blocks to build a disentangled encoder, and Zipformer blocks to build a style transfer decoder as the generator. In the decoder, we used effective styleformer blocks to integrate speaker characteristics effectively into the generated speech. The models used the generative VAE loss for encoding components and triplet loss for unsupervised discriminative training. We applied the styleformer method to Zipformer's shared weights for style transfer. The experimental results show that the proposed model achieves comparable subjective scores and exhibits improvements in objective metrics compared to existing methods in a one-shot voice conversion scenario.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "submmited to ICASSP 2025"
    },
    {
        "paper id": "2409.01690",
        "abstract url": "https://arxiv.org/abs/2409.01690",
        "title": "Taming CLIP for Fine-grained and Structured Visual Understanding of Museum Exhibits",
        "rating": "-0.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.CV",
                "cs.CL"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "CLIP is a powerful and widely used tool for understanding images in the context of natural language descriptions to perform nuanced tasks. However, it does not offer application-specific fine-grained and structured understanding, due to its generic nature. In this work, we aim to adapt CLIP for fine-grained and structured -- in the form of tabular data -- visual understanding of museum exhibits. To facilitate such understanding we (a) collect, curate, and benchmark a dataset of 200K+ image-table pairs, and (b) develop a method that allows predicting tabular outputs for input images. Our dataset is the first of its kind in the public domain. At the same time, the proposed method is novel in leveraging CLIP's powerful representations for fine-grained and tabular understanding. The proposed method (MUZE) learns to map CLIP's image embeddings to the tabular structure by means of a proposed transformer-based parsing network (parseNet). More specifically, parseNet enables prediction of missing attribute values while integrating context from known attribute-value pairs for an input image. We show that this leads to significant improvement in accuracy. Through exhaustive experiments, we show the effectiveness of the proposed method on fine-grained and structured understanding of museum exhibits, by achieving encouraging results in a newly established benchmark. Our dataset and source-code can be found at: https://github.com/insait-institute/MUZE",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Accepted to ECCV 2024"
    },
    {
        "paper id": "2409.01713",
        "abstract url": "https://arxiv.org/abs/2409.01713",
        "title": "Interpreting Outliers in Time Series Data through Decoding Autoencoder",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Outlier detection is a crucial analytical tool in various fields. In critical systems like manufacturing, malfunctioning outlier detection can be costly and safety-critical. Therefore, there is a significant need for explainable artificial intelligence (XAI) when deploying opaque models in such environments. This study focuses on manufacturing time series data from a German automotive supply industry. We utilize autoencoders to compress the entire time series and then apply anomaly detection techniques to its latent features. For outlier interpretation, we (i) adopt widely used XAI techniques to the autoencoder's encoder. Additionally, (ii) we propose AEE, Aggregated Explanatory Ensemble, a novel approach that fuses explanations of multiple XAI techniques into a single, more expressive interpretation. For evaluation of explanations, (iii) we propose a technique to measure the quality of encoder explanations quantitatively. Furthermore, we qualitatively assess the effectiveness of outlier explanations with domain expertise.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "14 pages, 8 figures, accepted at TempXAI @ ECML-PKDD"
    },
    {
        "paper id": "2409.01730",
        "abstract url": "https://arxiv.org/abs/2409.01730",
        "title": "Federated Prediction-Powered Inference from Decentralized Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In various domains, the increasing application of machine learning allows researchers to access inexpensive predictive data, which can be utilized as auxiliary data for statistical inference. Although such data are often unreliable compared to gold-standard datasets, Prediction-Powered Inference (PPI) has been proposed to ensure statistical validity despite the unreliability. However, the challenge of `data silos' arises when the private gold-standard datasets are non-shareable for model training, leading to less accurate predictive models and invalid inferences. In this paper, we introduces the Federated Prediction-Powered Inference (Fed-PPI) framework, which addresses this challenge by enabling decentralized experimental data to contribute to statistically valid conclusions without sharing private information. The Fed-PPI framework involves training local models on private data, aggregating them through Federated Learning (FL), and deriving confidence intervals using PPI computation. The proposed framework is evaluated through experiments, demonstrating its effectiveness in producing valid confidence intervals.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01832",
        "abstract url": "https://arxiv.org/abs/2409.01832",
        "title": "Beyond Unconstrained Features: Neural Collapse for Shallow Neural Networks with General Data",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural collapse (NC) is a phenomenon that emerges at the terminal phase of the training (TPT) of deep neural networks (DNNs). The features of the data in the same class collapse to their respective sample means and the sample means exhibit a simplex equiangular tight frame (ETF). In the past few years, there has been a surge of works that focus on explaining why the NC occurs and how it affects generalization. Since the DNNs are notoriously difficult to analyze, most works mainly focus on the unconstrained feature model (UFM). While the UFM explains the NC to some extent, it fails to provide a complete picture of how the network architecture and the dataset affect NC. In this work, we focus on shallow ReLU neural networks and try to understand how the width, depth, data dimension, and statistical property of the training dataset influence the neural collapse. We provide a complete characterization of when the NC occurs for two or three-layer neural networks. For two-layer ReLU neural networks, a sufficient condition on when the global minimizer of the regularized empirical risk function exhibits the NC configuration depends on the data dimension, sample size, and the signal-to-noise ratio in the data instead of the network width. For three-layer neural networks, we show that the NC occurs as long as the first layer is sufficiently wide. Regarding the connection between NC and generalization, we show the generalization heavily depends on the SNR (signal-to-noise ratio) in the data: even if the NC occurs, the generalization can still be bad provided that the SNR in the data is too low. Our results significantly extend the state-of-the-art theoretical analysis of the N C under the UFM by characterizing the emergence of the N C under shallow nonlinear networks and showing how it depends on data properties and network architecture.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01952",
        "abstract url": "https://arxiv.org/abs/2409.01952",
        "title": "Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) have long been recognized as vulnerable to backdoor attacks. By providing poisoned training data in the fine-tuning process, the attacker can implant a backdoor into the victim model. This enables input samples meeting specific textual trigger patterns to be classified as target labels of the attacker's choice. While such black-box attacks have been well explored in both computer vision and natural language processing (NLP), backdoor attacks relying on white-box attack philosophy have hardly been thoroughly investigated. In this paper, we take the first step to introduce a new type of backdoor attack that conceals itself within the underlying model architecture. Specifically, we propose to design separate backdoor modules consisting of two functions: trigger detection and noise injection. The add-on modules of model architecture layers can detect the presence of input trigger tokens and modify layer weights using Gaussian noise to disturb the feature distribution of the baseline model. We conduct extensive experiments to evaluate our attack methods using two model architecture settings on five different large language datasets. We demonstrate that the training-free architectural backdoor on a large language model poses a genuine threat. Unlike the-state-of-art work, it can survive the rigorous fine-tuning and retraining process, as well as evade output probability-based defense methods (i.e. BDDR). All the code and data is available https://github.com/SiSL-URI/Arch_Backdoor_LLM.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01989",
        "abstract url": "https://arxiv.org/abs/2409.01989",
        "title": "Improving Electrolyte Performance for Target Cathode Loading Using Interpretable Data-Driven Approach",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Higher loading of active electrode materials is desired in batteries, especially those based on conversion reactions, for enhanced energy density and cost efficiency. However, increasing active material loading in electrodes can cause significant performance depreciation due to internal resistance, shuttling, and parasitic side reactions, which can be alleviated to a certain extent by a compatible design of electrolytes. In this work, a data-driven approach is leveraged to find a high-performing electrolyte formulation for a novel interhalogen battery custom to the target cathode loading. An electrolyte design consisting of 4 solvents and 4 salts is experimentally devised for a novel interhalogen battery based on a multi-electron redox reaction. The experimental dataset with variable electrolyte compositions and active cathode loading, is used to train a graph-based deep learning model mapping changing variables in the battery's material design to its specific capacity. The trained model is used to further optimize the electrolyte formulation compositions for enhancing the battery capacity at a target cathode loading by a two-fold approach: large-scale screening and interpreting electrolyte design principles for different cathode loadings. The data-driven approach is demonstrated to bring about an additional 20% increment in the specific capacity of the battery over capacities obtained from the experimental optimization.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cond-mat.mtrl-sci"
        ],
        "comment": "34 Pages, 5 Figures, 2 Tables"
    },
    {
        "paper id": "2409.01992",
        "abstract url": "https://arxiv.org/abs/2409.01992",
        "title": "QueryCheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Query-based systems (QBSs) are one of the key approaches for sharing data. QBSs allow analysts to request aggregate information from a private protected dataset. Attacks are a crucial part of ensuring QBSs are truly privacy-preserving. The development and testing of attacks is however very labor-intensive and unable to cope with the increasing complexity of systems. Automated approaches have been shown to be promising but are currently extremely computationally intensive, limiting their applicability in practice. We here propose QueryCheetah, a fast and effective method for automated discovery of privacy attacks against QBSs. We instantiate QueryCheetah on attribute inference attacks and show it to discover stronger attacks than previous methods while being 18 times faster than the state-of-the-art automated approach. We then show how QueryCheetah allows system developers to thoroughly evaluate the privacy risk, including for various attacker strengths and target individuals. We finally show how QueryCheetah can be used out-of-the-box to find attacks in larger syntaxes and workarounds around ad-hoc defenses.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "This is an extended version of the ACM CCS paper which includes appendices"
    },
    {
        "paper id": "2409.02006",
        "abstract url": "https://arxiv.org/abs/2409.02006",
        "title": "Robust Fitting on a Gate Quantum Computer",
        "rating": "-0.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Gate quantum computers generate significant interest due to their potential to solve certain difficult problems such as prime factorization in polynomial time. Computer vision researchers have long been attracted to the power of quantum computers. Robust fitting, which is fundamentally important to many computer vision pipelines, has recently been shown to be amenable to gate quantum computing. The previous proposed solution was to compute Boolean influence as a measure of outlyingness using the Bernstein-Vazirani quantum circuit. However, the method assumed a quantum implementation of an $\\ell_\\infty$ feasibility test, which has not been demonstrated. In this paper, we take a big stride towards quantum robust fitting: we propose a quantum circuit to solve the $\\ell_\\infty$ feasibility test in the 1D case, which allows to demonstrate for the first time quantum robust fitting on a real gate quantum computer, the IonQ Aria. We also show how 1D Boolean influences can be accumulated to compute Boolean influences for higher-dimensional non-linear models, which we experimentally validate on real benchmark datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by the European Conference on Computer Vision 2024 (ECCV2024) as Oral. The paper is written for a computer vision audience who generally has minimal quantum physics background"
    },
    {
        "paper id": "2409.02064",
        "abstract url": "https://arxiv.org/abs/2409.02064",
        "title": "Personalized Federated Learning via Active Sampling",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Consider a collection of data generators which could represent, e.g., humans equipped with a smart-phone or wearables. We want to train a personalized (or tailored) model for each data generator even if they provide only small local datasets. The available local datasets might fail to provide sufficient statistical power to train high-dimensional models (such as deep neural networks) effectively. One possible solution is to identify similar data generators and pool their local datasets to obtain a sufficiently large training set. This paper proposes a novel method for sequentially identifying similar (or relevant) data generators. Our method is similar in spirit to active sampling methods but does not require exchange of raw data. Indeed, our method evaluates the relevance of a data generator by evaluating the effect of a gradient step using its local dataset. This evaluation can be performed in a privacy-friendly fashion without sharing raw data. We extend this method to non-parametric models by a suitable generalization of the gradient step to update a hypothesis using the local dataset provided by a data generator.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02074",
        "abstract url": "https://arxiv.org/abs/2409.02074",
        "title": "RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Malicious shell commands are linchpins to many cyber-attacks, but may not be easy to understand by security analysts due to complicated and often disguised code structures. Advances in large language models (LLMs) have unlocked the possibility of generating understandable explanations for shell commands. However, existing general-purpose LLMs suffer from a lack of expert knowledge and a tendency to hallucinate in the task of shell command explanation. In this paper, we present Raconteur, a knowledgeable, expressive and portable shell command explainer powered by LLM. Raconteur is infused with professional knowledge to provide comprehensive explanations on shell commands, including not only what the command does (i.e., behavior) but also why the command does it (i.e., purpose). To shed light on the high-level intent of the command, we also translate the natural-language-based explanation into standard technique & tactic defined by MITRE ATT&CK, the worldwide knowledge base of cybersecurity. To enable Raconteur to explain unseen private commands, we further develop a documentation retriever to obtain relevant information from complementary documentations to assist the explanation process. We have created a large-scale dataset for training and conducted extensive experiments to evaluate the capability of Raconteur in shell command explanation. The experiments verify that Raconteur is able to provide high-quality explanations and in-depth insight of the intent of the command.",
        "subjects": [
            "cs.CR",
            "cs.HC",
            "cs.LG",
            "cs.SE"
        ],
        "comment": "Accepted by NDSS Symposium 2025. Please cite this paper as \"Jiangyi Deng, Xinfeng Li, Yanjiao Chen, Yijie Bai, Haiqin Weng, Yan Liu, Tao Wei, Wenyuan Xu. RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer. In the 32nd Annual Network and Distributed System Security Symposium (NDSS 2025).\""
    },
    {
        "paper id": "2409.02189",
        "abstract url": "https://arxiv.org/abs/2409.02189",
        "title": "Collaboratively Learning Federated Models from Noisy Decentralized Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) has emerged as a prominent method for collaboratively training machine learning models using local data from edge devices, all while keeping data decentralized. However, accounting for the quality of data contributed by local clients remains a critical challenge in FL, as local data are often susceptible to corruption by various forms of noise and perturbations, which compromise the aggregation process and lead to a subpar global model. In this work, we focus on addressing the problem of noisy data in the input space, an under-explored area compared to the label noise. We propose a comprehensive assessment of client input in the gradient space, inspired by the distinct disparity observed between the density of gradient norm distributions of models trained on noisy and clean input data. Based on this observation, we introduce a straightforward yet effective approach to identify clients with low-quality data at the initial stage of FL. Furthermore, we propose a noise-aware FL aggregation method, namely Federated Noise-Sifting (FedNS), which can be used as a plug-in approach in conjunction with widely used FL strategies. Our extensive evaluation on diverse benchmark datasets under different federated settings demonstrates the efficacy of FedNS. Our method effortlessly integrates with existing FL strategies, enhancing the global model's performance by up to 13.68% in IID and 15.85% in non-IID settings when learning from noisy decentralized data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02363",
        "abstract url": "https://arxiv.org/abs/2409.02363",
        "title": "Optimal Neural Network Approximation for High-Dimensional Continuous Functions",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, the authors of Shen Yang Zhang (JMLR, 2022) developed a neural network with width $36d(2d + 1)$ and depth $11$, which utilizes a special activation function called the elementary universal activation function, to achieve the super approximation property for functions in $C([a,b]^d)$. That is, the constructed network only requires a fixed number of neurons to approximate a $d$-variate continuous function on a $d$-dimensional hypercube with arbitrary accuracy. Their network uses $\\mathcal{O}(d^2)$ fixed neurons. One natural question to address is whether we can reduce the number of these neurons in such a network. By leveraging a variant of the Kolmogorov Superposition Theorem, our analysis shows that there is a neural network generated by the elementary universal activation function with only $366d +365$ fixed, intrinsic (non-repeated) neurons that attains this super approximation property. Furthermore, we present a family of continuous functions that requires at least width $d$, and therefore at least $d$ intrinsic neurons, to achieve arbitrary accuracy in its approximation. This shows that the requirement of $\\mathcal{O}(d)$ intrinsic neurons is optimal in the sense that it grows linearly with the input dimension $d$, unlike some approximation methods where parameters may grow exponentially with $d$.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02392",
        "abstract url": "https://arxiv.org/abs/2409.02392",
        "title": "Building Math Agents with Multi-Turn Iterative Preference Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent studies have shown that large language models' (LLMs) mathematical problem-solving capabilities can be enhanced by integrating external tools, such as code interpreters, and employing multi-turn Chain-of-Thought (CoT) reasoning. While current methods focus on synthetic data generation and Supervised Fine-Tuning (SFT), this paper studies the complementary direct preference learning approach to further improve model performance. However, existing direct preference learning algorithms are originally designed for the single-turn chat task, and do not fully address the complexities of multi-turn reasoning and external tool integration required for tool-integrated mathematical reasoning tasks. To fill in this gap, we introduce a multi-turn direct preference learning framework, tailored for this context, that leverages feedback from code interpreters and optimizes trajectory-level preferences. This framework includes multi-turn DPO and multi-turn KTO as specific implementations. The effectiveness of our framework is validated through training of various language models using an augmented prompt set from the GSM8K and MATH datasets. Our results demonstrate substantial improvements: a supervised fine-tuned Gemma-1.1-it-7B model's performance increased from 77.5% to 83.9% on GSM8K and from 46.1% to 51.2% on MATH. Similarly, a Gemma-2-it-9B model improved from 84.1% to 86.3% on GSM8K and from 51.0% to 54.5% on MATH.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "A multi-turn direct preference learning framework for tool-integrated reasoning tasks"
    },
    {
        "paper id": "2409.02430",
        "abstract url": "https://arxiv.org/abs/2409.02430",
        "title": "Transfer-based Adversarial Poisoning Attacks for Online (MIMO-)Deep Receviers",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, the design of wireless receivers using deep neural networks (DNNs), known as deep receivers, has attracted extensive attention for ensuring reliable communication in complex channel environments. To adapt quickly to dynamic channels, online learning has been adopted to update the weights of deep receivers with over-the-air data (e.g., pilots). However, the fragility of neural models and the openness of wireless channels expose these systems to malicious attacks. To this end, understanding these attack methods is essential for robust receiver design. In this paper, we propose a transfer-based adversarial poisoning attack method for online receivers.Without knowledge of the attack target, adversarial perturbations are injected to the pilots, poisoning the online deep receiver and impairing its ability to adapt to dynamic channels and nonlinear effects. In particular, our attack method targets Deep Soft Interference Cancellation (DeepSIC)[1] using online meta-learning. As a classical model-driven deep receiver, DeepSIC incorporates wireless domain knowledge into its architecture. This integration allows it to adapt efficiently to time-varying channels with only a small number of pilots, achieving optimal performance in a multi-input and multi-output (MIMO) scenario.The deep receiver in this scenario has a number of applications in the field of wireless communication, which motivates our study of the attack methods targeting it.Specifically, we demonstrate the effectiveness of our attack in simulations on synthetic linear, synthetic nonlinear, static, and COST 2100 channels. Simulation results indicate that the proposed poisoning attack significantly reduces the performance of online receivers in rapidly changing scenarios.",
        "subjects": [
            "eess.SP",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "15 pages, 14 figures"
    },
    {
        "paper id": "2409.02965",
        "abstract url": "https://arxiv.org/abs/2409.02965",
        "title": "Do We Trust What They Say or What They Do? A Multimodal User Embedding Provides Personalized Explanations",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "With the rapid development of social media, the importance of analyzing social network user data has also been put on the agenda. User representation learning in social media is a critical area of research, based on which we can conduct personalized content delivery, or detect malicious actors. Being more complicated than many other types of data, social network user data has inherent multimodal nature. Various multimodal approaches have been proposed to harness both text (i.e. post content) and relation (i.e. inter-user interaction) information to learn user embeddings of higher quality. The advent of Graph Neural Network models enables more end-to-end integration of user text embeddings and user interaction graphs in social networks. However, most of those approaches do not adequately elucidate which aspects of the data - text or graph structure information - are more helpful for predicting each specific user under a particular task, putting some burden on personalized downstream analysis and untrustworthy information filtering. We propose a simple yet effective framework called Contribution-Aware Multimodal User Embedding (CAMUE) for social networks. We have demonstrated with empirical evidence, that our approach can provide personalized explainable predictions, automatically mitigating the impact of unreliable information. We also conducted case studies to show how reasonable our results are. We observe that for most users, graph structure information is more trustworthy than text information, but there are some reasonable cases where text helps more. Our work paves the way for more explainable, reliable, and effective social media user embedding which allows for better personalized content delivery.",
        "subjects": [
            "cs.SI",
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03793",
        "abstract url": "https://arxiv.org/abs/2409.03793",
        "title": "Safeguarding AI Agents: Developing and Analyzing Safety Architectures",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "AI agents, specifically powered by large language models, have demonstrated exceptional capabilities in various applications where precision and efficacy are necessary. However, these agents come with inherent risks, including the potential for unsafe or biased actions, vulnerability to adversarial attacks, lack of transparency, and tendency to generate hallucinations. As AI agents become more prevalent in critical sectors of the industry, the implementation of effective safety protocols becomes increasingly important. This paper addresses the critical need for safety measures in AI systems, especially ones that collaborate with human teams. We propose and evaluate three frameworks to enhance safety protocols in AI agent systems: an LLM-powered input-output filter, a safety agent integrated within the system, and a hierarchical delegation-based system with embedded safety checks. Our methodology involves implementing these frameworks and testing them against a set of unsafe agentic use cases, providing a comprehensive evaluation of their effectiveness in mitigating risks associated with AI agent deployment. We conclude that these frameworks can significantly strengthen the safety and security of AI agent systems, minimizing potential harmful actions or outputs. Our work contributes to the ongoing effort to create safe and reliable AI applications, particularly in automated operations, and provides a foundation for developing robust guardrails to ensure the responsible use of AI agents in real-world applications.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01608",
        "abstract url": "https://arxiv.org/abs/2409.01608",
        "title": "LiDAR-Aided Millimeter-Wave Range Extension using a Passive Mirror Reflector",
        "rating": "-1",
        "keywords": [
            [
                "LiDAR"
            ]
        ],
        "abstract": "Passive reflectors mitigate millimeter-wave (mmwave) link blockages by extending coverage to non-line-ofsight (NLoS) regions. However, their deployment often leads to irregular reflected beam patterns and coverage gaps. This results in rapid channel fluctuations and potential outages. In this paper, we propose two LiDAR-aided link enhancement techniques to address these challenges. Leveraging user position information, we introduce a location-dependent link control strategy and a user selection technique to improve NLoS link reliability and coverage. Experimental results validate the efficacy of the proposed techniques in reducing outages and enhancing NLoS signal strength.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01617",
        "abstract url": "https://arxiv.org/abs/2409.01617",
        "title": "High Precision Positioning System",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "SAPPO is a high-precision, low-cost and highly scalable indoor localization system. The system is designed using modified HC-SR04 ultrasound transducers as a base to be used as distance meters between beacons and mobile robots. Additionally, it has a very unusual arrangement of its elements, such that the beacons and the array of transmitters of the mobile robot are located in very close planes, in a horizontal emission arrangement, parallel to the ground, achieving a range per transducer of almost 12 meters. SAPPO represents a significant leap forward in ultrasound localization systems, in terms of reducing the density of beacons while maintaining average precision in the millimeter range.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "in Spanish language"
    },
    {
        "paper id": "2409.01622",
        "abstract url": "https://arxiv.org/abs/2409.01622",
        "title": "T1-contrast Enhanced MRI Generation from Multi-parametric MRI for Glioma Patients with Latent Tumor Conditioning",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "Tumor"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Objective: Gadolinium-based contrast agents (GBCAs) are commonly used in MRI scans of patients with gliomas to enhance brain tumor characterization using T1-weighted (T1W) MRI. However, there is growing concern about GBCA toxicity. This study develops a deep-learning framework to generate T1-postcontrast (T1C) from pre-contrast multiparametric MRI. Approach: We propose the tumor-aware vision transformer (TA-ViT) model that predicts high-quality T1C images. The predicted tumor region is significantly improved (P < .001) by conditioning the transformer layers from predicted segmentation maps through adaptive layer norm zero mechanism. The predicted segmentation maps were generated with the multi-parametric residual (MPR) ViT model and transformed into a latent space to produce compressed, feature-rich representations. The TA-ViT model predicted T1C MRI images of 501 glioma cases. Selected patients were split into training (N=400), validation (N=50), and test (N=51) sets. Main Results: Both qualitative and quantitative results demonstrate that the TA-ViT model performs superior against the benchmark MRP-ViT model. Our method produces synthetic T1C MRI with high soft tissue contrast and more accurately reconstructs both the tumor and whole brain volumes. The synthesized T1C images achieved remarkable improvements in both tumor and healthy tissue regions compared to the MRP-ViT model. For healthy tissue and tumor regions, the results were as follows: NMSE: 8.53 +/- 4.61E-4; PSNR: 31.2 +/- 2.2; NCC: 0.908 +/- .041 and NMSE: 1.22 +/- 1.27E-4, PSNR: 41.3 +/- 4.7, and NCC: 0.879 +/- 0.042, respectively. Significance: The proposed method generates synthetic T1C images that closely resemble real T1C images. Future development and application of this approach may enable contrast-agent-free MRI for brain tumor patients, eliminating the risk of GBCA toxicity and simplifying the MRI scan protocol.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2407.02616"
    },
    {
        "paper id": "2409.01647",
        "abstract url": "https://arxiv.org/abs/2409.01647",
        "title": "Correlation Properties in Channels with von Mises-Fisher Distribution of Scatterers",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "This letter presents simple analytical expressions for the spatial and temporal correlation functions in channels with von Mises-Fisher (vMF) scattering. In contrast to previous results, the expressions presented here are exact and based only on elementary functions, clearly revealing the impact of the underlying parameters. The derived results are validated by a comparison against numerical integration result, where an exact match is observed. To demonstrate their utility, the presented results are used to analyze spatial correlation across different antenna array geometries and to investigate temporal correlation of a fluctuating radar signal from a moving target.",
        "subjects": [
            "eess.SP",
            "stat.OT"
        ],
        "comment": "Submitted to IEEE Wireless Communications Letters (submitted on 2024-05-14; revised and resubmitted on 2024-08-26)"
    },
    {
        "paper id": "2409.01661",
        "abstract url": "https://arxiv.org/abs/2409.01661",
        "title": "$S^2$NeRF: Privacy-preserving Training Framework for NeRF",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "attack"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRF) have revolutionized 3D computer vision and graphics, facilitating novel view synthesis and influencing sectors like extended reality and e-commerce. However, NeRF's dependence on extensive data collection, including sensitive scene image data, introduces significant privacy risks when users upload this data for model training. To address this concern, we first propose SplitNeRF, a training framework that incorporates split learning (SL) techniques to enable privacy-preserving collaborative model training between clients and servers without sharing local data. Despite its benefits, we identify vulnerabilities in SplitNeRF by developing two attack methods, Surrogate Model Attack and Scene-aided Surrogate Model Attack, which exploit the shared gradient data and a few leaked scene images to reconstruct private scene information. To counter these threats, we introduce $S^2$NeRF, secure SplitNeRF that integrates effective defense mechanisms. By introducing decaying noise related to the gradient norm into the shared gradient information, $S^2$NeRF preserves privacy while maintaining a high utility of the NeRF model. Our extensive evaluations across multiple datasets demonstrate the effectiveness of $S^2$NeRF against privacy breaches, confirming its viability for secure NeRF training in sensitive applications.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "To appear in the ACM Conference on Computer and Communications Security (CCS'24), October 14-18, 2024, Salt Lake City, UT, USA"
    },
    {
        "paper id": "2409.01704",
        "abstract url": "https://arxiv.org/abs/2409.01704",
        "title": "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Traditional OCR systems (OCR-1.0) are increasingly unable to meet people's usage due to the growing demand for intelligent processing of man-made optical characters. In this paper, we collectively refer to all artificial optical signals (e.g., plain texts, math/molecular formulas, tables, charts, sheet music, and even geometric shapes) as \"characters\" and propose the General OCR Theory along with an excellent model, namely GOT, to promote the arrival of OCR-2.0. The GOT, with 580M parameters, is a unified, elegant, and end-to-end model, consisting of a high-compression encoder and a long-contexts decoder. As an OCR-2.0 model, GOT can handle all the above \"characters\" under various OCR tasks. On the input side, the model supports commonly used scene- and document-style images in slice and whole-page styles. On the output side, GOT can generate plain or formatted results (markdown/tikz/smiles/kern) via an easy prompt. Besides, the model enjoys interactive OCR features, i.e., region-level recognition guided by coordinates or colors. Furthermore, we also adapt dynamic resolution and multi-page OCR technologies to GOT for better practicality. In experiments, we provide sufficient results to prove the superiority of our model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01723",
        "abstract url": "https://arxiv.org/abs/2409.01723",
        "title": "Holes in Convex and Simple Drawings",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Gons and holes in point sets have been extensively studied in the literature. For simple drawings of the complete graph a generalization of the Erd\u0151s--Szekeres theorem is known and empty triangles have been investigated. We introduce a notion of $k$-holes for simple drawings and study their existence with respect to the convexity hierarchy. We present a family of simple drawings without 4-holes and prove a generalization of Gerken's empty hexagon theorem for convex drawings. A crucial intermediate step will be the structural investigation of pseudolinear subdrawings in convex~drawings.",
        "subjects": [
            "cs.CG",
            "cs.DM",
            "math.GT"
        ],
        "comment": "This article appears in the proceedings of GD2024"
    },
    {
        "paper id": "2409.01732",
        "abstract url": "https://arxiv.org/abs/2409.01732",
        "title": "Intersection Graphs with and without Product Structure",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "A graph class $\\mathcal{G}$ admits product structure if there exists a constant $k$ such that every $G \\in \\mathcal{G}$ is a subgraph of $H \\boxtimes P$ for a path $P$ and some graph $H$ of treewidth $k$. Famously, the class of planar graphs, as well as many beyond-planar graph classes are known to admit product structure. However, we have only few tools to prove the absence of product structure, and hence know of only a few interesting examples of classes. Motivated by the transition between product structure and no product structure, we investigate subclasses of intersection graphs in the plane (e.g., disk intersection graphs) and present necessary and sufficient conditions for these to admit product structure. Specifically, for a set $S \\subset \\mathbb{R}^2$ (e.g., a disk) and a real number $\u03b1\\in [0,1]$, we consider intersection graphs of $\u03b1$-free homothetic copies of $S$. That is, each vertex $v$ is a homothetic copy of $S$ of which at least an $\u03b1$-portion is not covered by other vertices, and there is an edge between $u$ and $v$ if and only if $u \\cap v \\neq \\emptyset$. For $\u03b1= 1$ we have contact graphs, which are in most cases planar, and hence admit product structure. For $\u03b1= 0$ we have (among others) all complete graphs, and hence no product structure. In general, there is a threshold value $\u03b1^*(S) \\in [0,1]$ such that $\u03b1$-free homothetic copies of $S$ admit product structure for all $\u03b1> \u03b1^*(S)$ and do not admit product structure for all $\u03b1< \u03b1^*(S)$. We show for a large family of sets $S$, including all triangles and all trapezoids, that it holds $\u03b1^*(S) = 1$, i.e., we have no product structure, except for the contact graphs (when $\u03b1= 1$). For other sets $S$, including regular $n$-gons for infinitely many values of $n$, we show that $0 < \u03b1^*(S) < 1$ by proving upper and lower bounds.",
        "subjects": [
            "math.CO",
            "cs.CG",
            "cs.DM"
        ],
        "comment": "An extended abstract of this paper appears in the proceedings of the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024)"
    },
    {
        "paper id": "2409.01733",
        "abstract url": "https://arxiv.org/abs/2409.01733",
        "title": "Improving the Crossing Lemma by Characterizing Dense 2-Planar and 3-Planar Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "The classical Crossing Lemma by Ajtai et al.~and Leighton from 1982 gave an important lower bound of $c \\frac{m^3}{n^2}$ for the number of crossings in any drawing of a given graph of $n$ vertices and $m$ edges. The original value was $c= 1/100$, which then has gradually been improved. Here, the bounds for the density of $k$-planar graphs played a central role. Our new insight is that for $k=2,3$ the $k$-planar graphs have substantially fewer edges if specific local configurations that occur in drawings of $k$-planar graphs of maximum density are forbidden. Therefore, we are able to derive better bounds for the crossing number $\\text{cr}(G)$ of a given graph $G$. In particular, we achieve a bound of $\\text{cr}(G) \\ge \\frac{37}{9}m-\\frac{155}{9}(n-2)$ for the range of $5n < m \\le 6n$, while our second bound $\\text{cr}(G) \\ge 5m - \\frac{203}{9}(n-2)$ is even stronger for larger $m>6n$. For $m > 6.77n$, we finally apply the standard probabilistic proof from the BOOK and obtain an improved constant of $c>1/27.48$ in the Crossing Lemma. Note that the previous constant was $1/29$. Although this improvement is not too impressive, we consider our technique as an important new tool, which might be helpful in various other applications.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01788",
        "abstract url": "https://arxiv.org/abs/2409.01788",
        "title": "DogeFuzz: A Simple Yet Efficient Grey-box Fuzzer for Ethereum Smart Contracts",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Ethereum is a distributed, peer-to-peer blockchain infrastructure that has attracted billions of dollars. Perhaps due to its success, Ethereum has become a target for various kinds of attacks, motivating researchers to explore different techniques to identify vulnerabilities in EVM bytecode (the language of the Ethereum Virtual Machine), including formal verification, symbolic execution, and fuzz testing. Although recent studies empirically compare smart contract fuzzers, there is a lack of literature investigating how simpler greybox fuzzers compare to more advanced ones. To fill this gap, in this paper, we present DogeFuzz, an extensible infrastructure for fuzzing Ethereum smart contracts, currently supporting black-box fuzzing and two grey-box fuzzing strategies: coverage-guided grey-box fuzzing (DogeFuzz-G) and directed grey-box fuzzing (DogeFuzz-DG). We conduct a series of experiments using benchmarks already available in the literature and compare the DogeFuzz strategies with state-of-the-art fuzzers for smart contracts. Surprisingly, although DogeFuzz does not leverage advanced techniques for improving input generation (such as symbolic execution or machine learning), DogeFuzz outperforms sFuzz and ILF, two state-of-the-art fuzzers. Nonetheless, the Smartian fuzzer shows higher code coverage and bug-finding capabilities than DogeFuzz.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": "16 pages,published in SBSEG 2024 conference"
    },
    {
        "paper id": "2409.01790",
        "abstract url": "https://arxiv.org/abs/2409.01790",
        "title": "Training on the Benchmark Is Not All You Need",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The success of Large Language Models (LLMs) relies heavily on the huge amount of pre-training data learned in the pre-training phase. The opacity of the pre-training process and the training data causes the results of many benchmark tests to become unreliable. If any model has been trained on a benchmark test set, it can seriously hinder the health of the field. In order to automate and efficiently test the capabilities of large language models, numerous mainstream benchmarks adopt a multiple-choice format. As the swapping of the contents of multiple-choice options does not affect the meaning of the question itself, we propose a simple and effective data leakage detection method based on this property. Specifically, we shuffle the contents of the options in the data to generate the corresponding derived data sets, and then detect data leakage based on the model's log probability distribution over the derived data sets. If there is a maximum and outlier in the set of log probabilities, it indicates that the data is leaked. Our method is able to work under black-box conditions without access to model training data or weights, effectively identifying data leakage from benchmark test sets in model pre-training data, including both normal scenarios and complex scenarios where options may have been shuffled intentionally or unintentionally. Through experiments based on two LLMs and benchmark designs, we demonstrate the effectiveness of our method. In addition, we evaluate the degree of data leakage of 31 mainstream open-source LLMs on four benchmark datasets and give a ranking of the leaked LLMs for each benchmark, and we find that the Qwen family of LLMs has the highest degree of data leakage.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01824",
        "abstract url": "https://arxiv.org/abs/2409.01824",
        "title": "DarthShader: Fuzzing WebGPU Shader Translators & Compilers",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "A recent trend towards running more demanding web applications, such as video games or client-side LLMs, in the browser has led to the adoption of the WebGPU standard that provides a cross-platform API exposing the GPU to websites. This opens up a new attack surface: Untrusted web content is passed through to the GPU stack, which traditionally has been optimized for performance instead of security. Worsening the problem, most of WebGPU cannot be run in the tightly sandboxed process that manages other web content, which eases the attacker's path to compromising the client machine. Contrasting its importance, WebGPU shader processing has received surprisingly little attention from the automated testing community. Part of the reason is that shader translators expect highly structured and statically typed input, which renders typical fuzzing mutations ineffective. Complicating testing further, shader translation consists of a complex multi-step compilation pipeline, each stage presenting unique requirements and challenges. In this paper, we propose DarthShader, the first language fuzzer that combines mutators based on an intermediate representation with those using a more traditional abstract syntax tree. The key idea is that the individual stages of the shader compilation pipeline are susceptible to different classes of faults, requiring entirely different mutation strategies for thorough testing. By fuzzing the full pipeline, we ensure that we maintain a realistic attacker model. In an empirical evaluation, we show that our method outperforms the state-of-the-art fuzzers regarding code coverage. Furthermore, an extensive ablation study validates our key design. DarthShader found a total of 39 software faults in all modern browsers -- Chrome, Firefox, and Safari -- that prior work missed. For 15 of them, the Chrome team assigned a CVE, acknowledging the impact of our results.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01825",
        "abstract url": "https://arxiv.org/abs/2409.01825",
        "title": "AstroMAE: Redshift Prediction Using a Masked Autoencoder with a Novel Fine-Tuning Architecture",
        "rating": "-1",
        "keywords": [
            [
                "astronomy"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Redshift prediction is a fundamental task in astronomy, essential for understanding the expansion of the universe and determining the distances of astronomical objects. Accurate redshift prediction plays a crucial role in advancing our knowledge of the cosmos. Machine learning (ML) methods, renowned for their precision and speed, offer promising solutions for this complex task. However, traditional ML algorithms heavily depend on labeled data and task-specific feature extraction. To overcome these limitations, we introduce AstroMAE, an innovative approach that pretrains a vision transformer encoder using a masked autoencoder method on Sloan Digital Sky Survey (SDSS) images. This technique enables the encoder to capture the global patterns within the data without relying on labels. To the best of our knowledge, AstroMAE represents the first application of a masked autoencoder to astronomical data. By ignoring labels during the pretraining phase, the encoder gathers a general understanding of the data. The pretrained encoder is subsequently fine-tuned within a specialized architecture tailored for redshift prediction. We evaluate our model against various vision transformer architectures and CNN-based models, demonstrating the superior performance of AstroMAEs pretrained model and fine-tuning architecture.",
        "subjects": [
            "cs.CV",
            "astro-ph.GA",
            "astro-ph.IM",
            "cs.CE",
            "cs.LG"
        ],
        "comment": "This paper has been accepted to 2024 IEEE 20th International Conference on e-Science"
    },
    {
        "paper id": "2409.01856",
        "abstract url": "https://arxiv.org/abs/2409.01856",
        "title": "Explicit Second-order LiDAR Bundle Adjustment Algorithm Using Mean Squared Group Metric",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Bundle Adjustment (BA) algorithm is a widely used nonlinear optimization technique in the backend of Simultaneous Localization and Mapping (SLAM) systems. By leveraging the co-view relationships of landmarks from multiple perspectives, it constructs a joint estimation model for both poses and landmarks, enabling the system to generate refined maps and reduce front-end localization errors. However, applying BA to LiDAR data presents unique challenges due to the large volume of 3D points typically present in point clouds, making robust and accurate model solving more complex. In this work, we propose a novel mean square group metric (MSGM). This metric applies mean square transformation to uniformly process the measurement of plane landmarks from a single perspective. The transformed metric ensures scale interpretability while avoiding the time-consuming point-by-point calculations. By integrating a robust kernel function, the metrics involved in the BA model are reweighted, enhancing the robustness of the solution process. On the basis of the proposed robust LiDAR BA model, we derived an explicit second-order estimator (RSO-BA). This estimator employs analytical formulas for Hessian and gradient calculations, ensuring the precision of the BA solution. We evaluated the proposed RSO-BA estimator against existing implicit second-order and explicit approximate second-order estimators using the publicly available datasets. The experimental results demonstrate that the RSO-BA estimator outperforms its counterparts regarding registration accuracy and robustness, particularly in large-scale or complex unstructured environments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01864",
        "abstract url": "https://arxiv.org/abs/2409.01864",
        "title": "The Role of Large Language Models in Musicology: Are We Ready to Trust the Machines?",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this work, we explore the use and reliability of Large Language Models (LLMs) in musicology. From a discussion with experts and students, we assess the current acceptance and concerns regarding this, nowadays ubiquitous, technology. We aim to go one step further, proposing a semi-automatic method to create an initial benchmark using retrieval-augmented generation models and multiple-choice question generation, validated by human experts. Our evaluation on 400 human-validated questions shows that current vanilla LLMs are less reliable than retrieval augmented generation from music dictionaries. This paper suggests that the potential of LLMs in musicology requires musicology driven research that can specialized LLMs by including accurate and reliable domain knowledge.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CL",
            "cs.DL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01889",
        "abstract url": "https://arxiv.org/abs/2409.01889",
        "title": "Weakly Leveled Planarity with Bounded Span",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This paper studies planar drawings of graphs in which each vertex is represented as a point along a sequence of horizontal lines, called levels, and each edge is either a horizontal segment or a strictly $y$-monotone curve. A graph is $s$-span weakly leveled planar if it admits such a drawing where the edges have span at most $s$; the span of an edge is the number of levels it touches minus one. We investigate the problem of computing $s$-span weakly leveled planar drawings from both the computational and the combinatorial perspectives. We prove the problem to be para-NP-hard with respect to its natural parameter $s$ and investigate its complexity with respect to widely used structural parameters. We show the existence of a polynomial-size kernel with respect to vertex cover number and prove that the problem is FPT when parameterized by treedepth. We also present upper and lower bounds on the span for various graph classes. Notably, we show that cycle trees, a family of $2$-outerplanar graphs generalizing Halin graphs, are $\u0398(\\log n)$-span weakly leveled planar and $4$-span weakly leveled planar when $3$-connected. As a byproduct of these combinatorial results, we obtain improved bounds on the edge-length ratio of the graph families under consideration.",
        "subjects": [
            "cs.CG",
            "cs.DS"
        ],
        "comment": "Appears in the Proceedings of the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024)"
    },
    {
        "paper id": "2409.01928",
        "abstract url": "https://arxiv.org/abs/2409.01928",
        "title": "Comprehensive Equity Index (CEI): Definition and Application to Bias Evaluation in Biometrics",
        "rating": "-1",
        "keywords": [
            [
                "Biometrics"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We present a novel metric designed, among other applications, to quantify biased behaviors of machine learning models. As its core, the metric consists of a new similarity metric between score distributions that balances both their general shapes and tails' probabilities. In that sense, our proposed metric may be useful in many application areas. Here we focus on and apply it to the operational evaluation of face recognition systems, with special attention to quantifying demographic biases; an application where our metric is especially useful. The topic of demographic bias and fairness in biometric recognition systems has gained major attention in recent years. The usage of these systems has spread in society, raising concerns about the extent to which these systems treat different population groups. A relevant step to prevent and mitigate demographic biases is first to detect and quantify them. Traditionally, two approaches have been studied to quantify differences between population groups in machine learning literature: 1) measuring differences in error rates, and 2) measuring differences in recognition score distributions. Our proposed Comprehensive Equity Index (CEI) trade-offs both approaches combining both errors from distribution tails and general distribution shapes. This new metric is well suited to real-world scenarios, as measured on NIST FRVT evaluations, involving high-performance systems and realistic face databases including a wide range of covariates and demographic groups. We first show the limitations of existing metrics to correctly assess the presence of biases in realistic setups and then propose our new metric to tackle these limitations. We tested the proposed metric with two state-of-the-art models and four widely used databases, showing its capacity to overcome the main flaws of previous bias metrics.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted paper for the 27th International Conference on Pattern Recognition (ICPR) 2024"
    },
    {
        "paper id": "2409.01941",
        "abstract url": "https://arxiv.org/abs/2409.01941",
        "title": "Towards Leveraging Large Language Models for Automated Medical Q&A Evaluation",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper explores the potential of using Large Language Models (LLMs) to automate the evaluation of responses in medical Question and Answer (Q\\&A) systems, a crucial form of Natural Language Processing. Traditionally, human evaluation has been indispensable for assessing the quality of these responses. However, manual evaluation by medical professionals is time-consuming and costly. Our study examines whether LLMs can reliably replicate human evaluations by using questions derived from patient data, thereby saving valuable time for medical experts. While the findings suggest promising results, further research is needed to address more specific or complex questions that were beyond the scope of this initial investigation.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "10 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2409.01955",
        "abstract url": "https://arxiv.org/abs/2409.01955",
        "title": "Adaptive Stochastic Predictive Control from Noisy Data: A Sampling-based Approach",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "In this work, an adaptive predictive control scheme for linear systems with unknown parameters and bounded additive disturbances is proposed. In contrast to related adaptive control approaches that robustly consider the parametric uncertainty, the proposed method handles all uncertainties stochastically by employing an online adaptive sampling-based approximation of chance constraints. The approach requires initial data in the form of a short input-output trajectory and distributional knowledge of the disturbances. This prior knowledge is used to construct an initial set of data-consistent system parameters and a distribution that allows for sample generation. As new data stream in online, the set of consistent system parameters is adapted by exploiting set membership identification. Consequently, chance constraints are deterministically approximated using a probabilistic scaling approach by sampling from the set of system parameters. In combination with a robust constraint on the first predicted step, recursive feasibility of the proposed predictive controller and closed-loop constraint satisfaction are guaranteed. A numerical example demonstrates the efficacy of the proposed method.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted for presentation at the 63rd IEEE Conference on Decision and Control (CDC2024)"
    },
    {
        "paper id": "2409.01965",
        "abstract url": "https://arxiv.org/abs/2409.01965",
        "title": "Exploiting Six-Dimensional Movable Antenna (6DMA) for Wireless Sensing",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Six-dimensional movable antenna (6DMA) is an emerging technology that is able to fully exploit the spatial variation of wireless channels by controlling the 3D positions and 3D rotations of distributed antennas/antenna surfaces at the transmitter/receiver. In this letter, we apply 6DMA at the base station (BS) to enhance its wireless sensing performance over a given set of regions. To this end, we first divide each region into a number of equal-size subregions and select one typical target location within each subregion. Then, we derive an expression for the Cramer-Rao bound (CRB) for estimating the directions of arrival (DoAs) from these typical target locations in all regions, which sheds light on the sensing performance of 6DMA enhanced systems in terms of a power gain and a geometric gain. Next, we minimize the CRB for DoA estimation via jointly optimizing the positions and rotations of all 6DMAs at the BS, subject to practical movement constraints, and propose an efficient algorithm to solve the resulting non-convex optimization problem sub-optimally. Finally, simulation results demonstrate the significant improvement in DoA estimation accuracy achieved by the proposed 6DMA sensing scheme as compared to various benchmark schemes, for both isotropic and directive antenna radiation patterns.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "5 figures"
    },
    {
        "paper id": "2409.01975",
        "abstract url": "https://arxiv.org/abs/2409.01975",
        "title": "1DCNNTrans: BISINDO Sign Language Interpreters in Improving the Inclusiveness of Public Services",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Indonesia ranks fourth globally in the number of deaf cases. Individuals with hearing impairments often find communication challenging, necessitating the use of sign language. However, there are limited public services that offer such inclusivity. On the other hand, advancements in artificial intelligence (AI) present promising solutions to overcome communication barriers faced by the deaf. This study aims to explore the application of AI in developing models for a simplified sign language translation app and dictionary, designed for integration into public service facilities, to facilitate communication for individuals with hearing impairments, thereby enhancing inclusivity in public services. The researchers compared the performance of LSTM and 1D CNN + Transformer (1DCNNTrans) models for sign language recognition. Through rigorous testing and validation, it was found that the LSTM model achieved an accuracy of 94.67%, while the 1DCNNTrans model achieved an accuracy of 96.12%. Model performance evaluation indicated that although the LSTM exhibited lower inference latency, it showed weaknesses in classifying classes with similar keypoints. In contrast, the 1DCNNTrans model demonstrated greater stability and higher F1 scores for classes with varying levels of complexity compared to the LSTM model. Both models showed excellent performance, exceeding 90% validation accuracy and demonstrating rapid classification of 50 sign language gestures.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.01988",
        "abstract url": "https://arxiv.org/abs/2409.01988",
        "title": "Compressed learning based onboard semantic compression for remote sensing platforms",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Earth observation (EO) plays a crucial role in creating and sustaining a resilient and prosperous society that has far reaching consequences for all life and the planet itself. Remote sensing platforms like satellites, airborne platforms, and more recently dones and UAVs are used for EO. They collect large amounts of data and this needs to be downlinked to Earth for further processing and analysis. Bottleneck for such high throughput acquisition is the downlink bandwidth. Data-centric solutions to image compression is required to address this deluge. In this work, semantic compression is studied through a compressed learning framework that utilizes only fast and sparse matrix-vector multiplication to encode the data. Camera noise and a communication channel are the considered sources of distortion. The complete semantic communication pipeline then consists of a learned low-complexity compression matrix that acts on the noisy camera output to generate onboard a vector of observations that is downlinked through a communication channel, processed through an unrolled network and then fed to a deep learning model performing the necessary downstream tasks; image classification is studied. Distortions are compensated by unrolling layers of NA-ALISTA with a wavelet sparsity prior. Decoding is thus a plug-n-play approach designed according to the camera/environment information and downstream task. The deep learning model for the downstream task is jointly fine-tuned with the compression matrix and the unrolled network through the loss function in an end-to-end fashion. It is shown that addition of a recovery loss along with the task dependent losses improves the downstream performance in noisy settings at low compression ratios.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01995",
        "abstract url": "https://arxiv.org/abs/2409.01995",
        "title": "vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders",
        "rating": "-1",
        "keywords": [
            [
                "Voice Conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We propose a new speech discrete token vocoder, vec2wav 2.0, which advances voice conversion (VC). We use discrete tokens from speech self-supervised models as the content features of source speech, and treat VC as a prompted vocoding task. To amend the loss of speaker timbre in the content tokens, vec2wav 2.0 utilizes the WavLM features to provide strong timbre-dependent information. A novel adaptive Snake activation function is proposed to better incorporate timbre into the waveform reconstruction process. In this way, vec2wav 2.0 learns to alter the speaker timbre appropriately given different reference prompts. Also, no supervised data is required for vec2wav 2.0 to be effectively trained. Experimental results demonstrate that vec2wav 2.0 outperforms all other baselines to a considerable margin in terms of audio quality and speaker similarity in any-to-any VC. Ablation studies verify the effects made by the proposed techniques. Moreover, vec2wav 2.0 achieves competitive cross-lingual VC even only trained on monolingual corpus. Thus, vec2wav 2.0 shows timbre can potentially be manipulated only by speech token vocoders, pushing the frontiers of VC and speech synthesis.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2409.02011",
        "abstract url": "https://arxiv.org/abs/2409.02011",
        "title": "Deep learning for objective estimation of Parkinsonian tremor severity",
        "rating": "-1",
        "keywords": [
            [
                "disease",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate assessment of Parkinsonian tremor is vital for monitoring disease progression and evaluating treatment efficacy. We introduce a pixel-based deep learning model designed to analyse postural tremor in Parkinson's disease (PD) from video data, overcoming the limitations of traditional pose estimation techniques. Trained on 2,742 assessments from five specialised movement disorder centres across two continents, the model demonstrated robust concordance with clinical evaluations. It effectively predicted treatment effects for levodopa and deep brain stimulation (DBS), detected lateral asymmetry of symptoms, and differentiated between different tremor severities. Feature space analysis revealed a non-linear, structured distribution of tremor severity, with low-severity scores occupying a larger portion of the feature space. The model also effectively identified outlier videos, suggesting its potential for adaptive learning and quality control in clinical settings. Our approach offers a scalable and objective method for tremor scoring, with potential integration into other MDS-UPDRS motor assessments, including bradykinesia and gait. The system's adaptability and performance underscore its promise for high-frequency, longitudinal monitoring of PD symptoms, complementing clinical expertise and enhancing decision-making in patient management. Future work will extend this pixel-based methodology to other cardinal symptoms of PD, aiming to develop a comprehensive, multi-symptom model for automated Parkinson's disease severity assessment.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02018",
        "abstract url": "https://arxiv.org/abs/2409.02018",
        "title": "TransDAE: Dual Attention Mechanism in a Hierarchical Transformer for Efficient Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare",
                "diagnosis",
                "disease",
                "organ"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In healthcare, medical image segmentation is crucial for accurate disease diagnosis and the development of effective treatment strategies. Early detection can significantly aid in managing diseases and potentially prevent their progression. Machine learning, particularly deep convolutional neural networks, has emerged as a promising approach to addressing segmentation challenges. Traditional methods like U-Net use encoding blocks for local representation modeling and decoding blocks to uncover semantic relationships. However, these models often struggle with multi-scale objects exhibiting significant variations in texture and shape, and they frequently fail to capture long-range dependencies in the input data. Transformers designed for sequence-to-sequence predictions have been proposed as alternatives, utilizing global self-attention mechanisms. Yet, they can sometimes lack precise localization due to insufficient granular details. To overcome these limitations, we introduce TransDAE: a novel approach that reimagines the self-attention mechanism to include both spatial and channel-wise associations across the entire feature space, while maintaining computational efficiency. Additionally, TransDAE enhances the skip connection pathway with an inter-scale interaction module, promoting feature reuse and improving localization accuracy. Remarkably, TransDAE outperforms existing state-of-the-art methods on the Synaps multi-organ dataset, even without relying on pre-trained weights.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02035",
        "abstract url": "https://arxiv.org/abs/2409.02035",
        "title": "A Modern Take on Visual Relationship Reasoning for Grasp Planning",
        "rating": "-1",
        "keywords": [
            [
                "robotic manipulation"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Interacting with real-world cluttered scenes pose several challenges to robotic agents that need to understand complex spatial dependencies among the observed objects to determine optimal pick sequences or efficient object retrieval strategies. Existing solutions typically manage simplified scenarios and focus on predicting pairwise object relationships following an initial object detection phase, but often overlook the global context or struggle with handling redundant and missing object relations. In this work, we present a modern take on visual relational reasoning for grasp planning. We introduce D3GD, a novel testbed that includes bin picking scenes with up to 35 objects from 97 distinct categories. Additionally, we propose D3G, a new end-to-end transformer-based dependency graph generation model that simultaneously detects objects and produces an adjacency matrix representing their spatial relationships. Recognizing the limitations of standard metrics, we employ the Average Precision of Relationships for the first time to evaluate model performance, conducting an extensive experimental benchmark. The obtained results establish our approach as the new state-of-the-art for this task, laying the foundation for future research in robotic manipulation. We publicly release the code and dataset at https://paolotron.github.io/d3g.github.io.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02038",
        "abstract url": "https://arxiv.org/abs/2409.02038",
        "title": "BEAVER: An Enterprise Benchmark for Text-to-SQL",
        "rating": "-1",
        "keywords": [
            [
                "SQL"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Existing text-to-SQL benchmarks have largely been constructed using publicly available tables from the web with human-generated tests containing question and SQL statement pairs. They typically show very good results and lead people to think that LLMs are effective at text-to-SQL tasks. In this paper, we apply off-the-shelf LLMs to a benchmark containing enterprise data warehouse data. In this environment, LLMs perform poorly, even when standard prompt engineering and RAG techniques are utilized. As we will show, the reasons for poor performance are largely due to three characteristics: (1) public LLMs cannot train on enterprise data warehouses because they are largely in the \"dark web\", (2) schemas of enterprise tables are more complex than the schemas in public data, which leads the SQL-generation task innately harder, and (3) business-oriented questions are often more complex, requiring joins over multiple tables and aggregations. As a result, we propose a new dataset BEAVER, sourced from real enterprise data warehouses together with natural language queries and their correct SQL statements which we collected from actual user history. We evaluated this dataset using recent LLMs and demonstrated their poor performance on this task. We hope this dataset will facilitate future researchers building more sophisticated text-to-SQL systems which can do better on this important class of data.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02046",
        "abstract url": "https://arxiv.org/abs/2409.02046",
        "title": "Human-AI Collaborative Multi-modal Multi-rater Learning for Endometriosis Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "surgery",
                "Diagnosis",
                "MRI",
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Endometriosis, affecting about 10\\% of individuals assigned female at birth, is challenging to diagnose and manage. Diagnosis typically involves the identification of various signs of the disease using either laparoscopic surgery or the analysis of T1/T2 MRI images, with the latter being quicker and cheaper but less accurate. A key diagnostic sign of endometriosis is the obliteration of the Pouch of Douglas (POD). However, even experienced clinicians struggle with accurately classifying POD obliteration from MRI images, which complicates the training of reliable AI models. In this paper, we introduce the \\underline{H}uman-\\underline{AI} \\underline{Co}llaborative \\underline{M}ulti-modal \\underline{M}ulti-rater Learning (HAICOMM) methodology to address the challenge above. HAICOMM is the first method that explores three important aspects of this problem: 1) multi-rater learning to extract a cleaner label from the multiple ``noisy'' labels available per training sample; 2) multi-modal learning to leverage the presence of T1/T2 MRI images for training and testing; and 3) human-AI collaboration to build a system that leverages the predictions from clinicians and the AI model to provide more accurate classification than standalone clinicians and AI models. Presenting results on the multi-rater T1/T2 MRI endometriosis dataset that we collected to validate our methodology, the proposed HAICOMM model outperforms an ensemble of clinicians, noisy-label learning models, and multi-rater learning methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02056",
        "abstract url": "https://arxiv.org/abs/2409.02056",
        "title": "F2former: When Fractional Fourier Meets Deep Wiener Deconvolution and Selective Frequency Transformer for Image Deblurring",
        "rating": "-1",
        "keywords": [
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent progress in image deblurring techniques focuses mainly on operating in both frequency and spatial domains using the Fourier transform (FT) properties. However, their performance is limited due to the dependency of FT on stationary signals and its lack of capability to extract spatial-frequency properties. In this paper, we propose a novel approach based on the Fractional Fourier Transform (FRFT), a unified spatial-frequency representation leveraging both spatial and frequency components simultaneously, making it ideal for processing non-stationary signals like images. Specifically, we introduce a Fractional Fourier Transformer (F2former), where we combine the classical fractional Fourier based Wiener deconvolution (F2WD) as well as a multi-branch encoder-decoder transformer based on a new fractional frequency aware transformer block (F2TB). We design F2TB consisting of a fractional frequency aware self-attention (F2SA) to estimate element-wise product attention based on important frequency components and a novel feed-forward network based on frequency division multiplexing (FM-FFN) to refine high and low frequency features separately for efficient latent clear image restoration. Experimental results for the cases of both motion deblurring as well as defocus deblurring show that the performance of our proposed method is superior to other state-of-the-art (SOTA) approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "20 pages, 21 figures"
    },
    {
        "paper id": "2409.02081",
        "abstract url": "https://arxiv.org/abs/2409.02081",
        "title": "Physical Rule-Guided Convolutional Neural Network",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The black-box nature of Convolutional Neural Networks (CNNs) and their reliance on large datasets limit their use in complex domains with limited labeled data. Physics-Guided Neural Networks (PGNNs) have emerged to address these limitations by integrating scientific principles and real-world knowledge, enhancing model interpretability and efficiency. This paper proposes a novel Physics-Guided CNN (PGCNN) architecture that incorporates dynamic, trainable, and automated LLM-generated, widely recognized rules integrated into the model as custom layers to address challenges like limited data and low confidence scores. The PGCNN is evaluated on multiple datasets, demonstrating superior performance compared to a baseline CNN model. Key improvements include a significant reduction in false positives and enhanced confidence scores for true detection. The results highlight the potential of PGCNNs to improve CNN performance for broader application areas.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02094",
        "abstract url": "https://arxiv.org/abs/2409.02094",
        "title": "Software Verification with CPAchecker 3.0: Tutorial and User Guide (Extended Version)",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This tutorial provides an introduction to CPAchecker for users. CPAchecker is a flexible and configurable framework for software verification and testing. The framework provides many abstract domains, such as BDDs, explicit values, intervals, memory graphs, and predicates, and many program-analysis and model-checking algorithms, such as abstract interpretation, bounded model checking, Impact, interpolation-based model checking, k -induction, PDR, predicate abstraction, and symbolic execution. This tutorial presents basic use cases for CPAchecker in formal software verification, focusing on its main verification techniques with their strengths and weaknesses. It also shows further use cases of CPAchecker for test-case generation and witness-based result validation. The envisioned readers are assumed to possess a background in automatic formal verification and program analysis, but prior knowledge of CPAchecker is not required. This tutorial and user guide is based on CPAchecker in version 3.0. This user guide's latest version and other documentation are available at https://cpachecker.sosy-lab.org/doc.php.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": "39 pages, 17 figures, 6 tables"
    },
    {
        "paper id": "2409.02095",
        "abstract url": "https://arxiv.org/abs/2409.02095",
        "title": "DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Despite significant advancements in monocular depth estimation for static images, estimating video depth in the open world remains challenging, since open-world videos are extremely diverse in content, motion, camera movement, and length. We present DepthCrafter, an innovative method for generating temporally consistent long depth sequences with intricate details for open-world videos, without requiring any supplementary information such as camera poses or optical flow. DepthCrafter achieves generalization ability to open-world videos by training a video-to-depth model from a pre-trained image-to-video diffusion model, through our meticulously designed three-stage training strategy with the compiled paired video-depth datasets. Our training approach enables the model to generate depth sequences with variable lengths at one time, up to 110 frames, and harvest both precise depth details and rich content diversity from realistic and synthetic datasets. We also propose an inference strategy that processes extremely long videos through segment-wise estimation and seamless stitching. Comprehensive evaluations on multiple datasets reveal that DepthCrafter achieves state-of-the-art performance in open-world video depth estimation under zero-shot settings. Furthermore, DepthCrafter facilitates various downstream applications, including depth-based visual effects and conditional video generation.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "comment": "Project webpage: https://depthcrafter.github.io"
    },
    {
        "paper id": "2409.02098",
        "abstract url": "https://arxiv.org/abs/2409.02098",
        "title": "CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through Corpus Retrieval and Augmentation",
        "rating": "-1",
        "keywords": [
            [
                "biology"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Building high-quality datasets for specialized tasks is a time-consuming and resource-intensive process that often requires specialized domain knowledge. We propose Corpus Retrieval and Augmentation for Fine-Tuning (CRAFT), a method for generating synthetic datasets, given a small number of user-written few-shots that demonstrate the task to be performed. Given the few-shot examples, we use large-scale public web-crawled corpora and similarity-based document retrieval to find other relevant human-written documents. Lastly, instruction-tuned large language models (LLMs) augment the retrieved documents into custom-formatted task samples, which then can be used for fine-tuning. We demonstrate that CRAFT can efficiently generate large-scale task-specific training datasets for four diverse tasks: biology question-answering (QA), medicine QA and commonsense QA as well as summarization. Our experiments show that CRAFT-based models outperform or achieve comparable performance to general LLMs for QA tasks, while CRAFT-based summarization models outperform models trained on human-curated data by 46 preference points.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02104",
        "abstract url": "https://arxiv.org/abs/2409.02104",
        "title": "DynOMo: Online Point Tracking by Dynamic Online Monocular Gaussian Reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian splatting"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reconstructing scenes and tracking motion are two sides of the same coin. Tracking points allow for geometric reconstruction [14], while geometric reconstruction of (dynamic) scenes allows for 3D tracking of points over time [24, 39]. The latter was recently also exploited for 2D point tracking to overcome occlusion ambiguities by lifting tracking directly into 3D [38]. However, above approaches either require offline processing or multi-view camera setups both unrealistic for real-world applications like robot navigation or mixed reality. We target the challenge of online 2D and 3D point tracking from unposed monocular camera input introducing Dynamic Online Monocular Reconstruction (DynOMo). We leverage 3D Gaussian splatting to reconstruct dynamic scenes in an online fashion. Our approach extends 3D Gaussians to capture new content and object motions while estimating camera movements from a single RGB frame. DynOMo stands out by enabling emergence of point trajectories through robust image feature reconstruction and a novel similarity-enhanced regularization term, without requiring any correspondence-level supervision. It sets the first baseline for online point tracking with monocular unposed cameras, achieving performance on par with existing methods. We aim to inspire the community to advance online point tracking and reconstruction, expanding the applicability to diverse real-world scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02146",
        "abstract url": "https://arxiv.org/abs/2409.02146",
        "title": "Brain-Inspired Online Adaptation for Remote Sensing with Spiking Neural Network",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing",
                "UAV"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "On-device computing, or edge computing, is becoming increasingly important for remote sensing, particularly in applications like deep network-based perception on on-orbit satellites and unmanned aerial vehicles (UAVs). In these scenarios, two brain-like capabilities are crucial for remote sensing models: (1) high energy efficiency, allowing the model to operate on edge devices with limited computing resources, and (2) online adaptation, enabling the model to quickly adapt to environmental variations, weather changes, and sensor drift. This work addresses these needs by proposing an online adaptation framework based on spiking neural networks (SNNs) for remote sensing. Starting with a pretrained SNN model, we design an efficient, unsupervised online adaptation algorithm, which adopts an approximation of the BPTT algorithm and only involves forward-in-time computation that significantly reduces the computational complexity of SNN adaptation learning. Besides, we propose an adaptive activation scaling scheme to boost online SNN adaptation performance, particularly in low time-steps. Furthermore, for the more challenging remote sensing detection task, we propose a confidence-based instance weighting scheme, which substantially improves adaptation performance in the detection task. To our knowledge, this work is the first to address the online adaptation of SNNs. Extensive experiments on seven benchmark datasets across classification, segmentation, and detection tasks demonstrate that our proposed method significantly outperforms existing domain adaptation and domain generalization approaches under varying weather conditions. The proposed method enables energy-efficient and fast online adaptation on edge devices, and has much potential in applications such as remote perception on on-orbit satellites and UAV.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02208",
        "abstract url": "https://arxiv.org/abs/2409.02208",
        "title": "Accelerating Graph Neural Networks with a Novel Matrix Compression Format",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ]
        ],
        "abstract": "The inference and training stages of Graph Neural Networks (GNNs) are often dominated by the time required to compute a long sequence of matrix multiplications between the sparse graph adjacency matrix and its embedding. To accelerate these stages, we first propose the Compressed Binary Matrix (CBM) storage format to succinctly represent the binary adjacency matrix of an unweighted graph. Then, we show how to generalize this representation to normalized adjacency matrices of unweighted graphs which arise in the context of GNNs. Finally, we develop efficient matrix multiplication kernels based on this compressed representation. The matrix multiplication kernels proposed in this work never require more scalar operations than classic sparse matrix multiplication algorithms. Experimental evaluation shows that the matrix multiplication strategies proposed outperform the current state-of-the-art implementations provided by Intel MKL, achieving speedups close to 5$\\times$. Furthermore, our optimized matrix-multiplication strategies accelerated the inference time of a GNN by up to $3\\times$.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02217",
        "abstract url": "https://arxiv.org/abs/2409.02217",
        "title": "Quantifying Liveness and Safety of Avalanche's Snowball",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "This work examines the resilience properties of the Snowball and Avalanche protocols that underlie the popular Avalanche blockchain. We experimentally quantify the resilience of Snowball using a simulation implemented in Rust, where the adversary strategically rebalances the network to delay termination. We show that in a network of $n$ nodes of equal stake, the adversary is able to break liveness when controlling $\u03a9(\\sqrt{n})$ nodes. Specifically, for $n = 2000$, a simple adversary controlling $5.2\\%$ of stake can successfully attack liveness. When the adversary is given additional information about the state of the network (without any communication or other advantages), the stake needed for a successful attack is as little as $2.8\\%$. We show that the adversary can break safety in time exponentially dependent on their stake, and inversely linearly related to the size of the network, e.g. in 265 rounds in expectation when the adversary controls $25\\%$ of a network of 3000. We conclude that Snowball and Avalanche are akin to Byzantine reliable broadcast protocols as opposed to consensus.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02224",
        "abstract url": "https://arxiv.org/abs/2409.02224",
        "title": "EgoPressure: A Dataset for Hand Pressure and Pose Estimation in Egocentric Vision",
        "rating": "-1",
        "keywords": [
            [
                "RGBD",
                "depth"
            ],
            [
                "robotics",
                "robotic manipulation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Estimating touch contact and pressure in egocentric vision is a central task for downstream applications in Augmented Reality, Virtual Reality, as well as many robotic applications, because it provides precise physical insights into hand-object interaction and object manipulation. However, existing contact pressure datasets lack egocentric views and hand poses, which are essential for accurate estimation during in-situ operation, both for AR/VR interaction and robotic manipulation. In this paper, we introduce EgoPressure,a novel dataset of touch contact and pressure interaction from an egocentric perspective, complemented with hand pose meshes and fine-grained pressure intensities for each contact. The hand poses in our dataset are optimized using our proposed multi-view sequence-based method that processes footage from our capture rig of 8 accurately calibrated RGBD cameras. EgoPressure comprises 5.0 hours of touch contact and pressure interaction from 21 participants captured by a moving egocentric camera and 7 stationary Kinect cameras, which provided RGB images and depth maps at 30 Hz. In addition, we provide baselines for estimating pressure with different modalities, which will enable future developments and benchmarking on the dataset. Overall, we demonstrate that pressure and hand poses are complementary, which supports our intention to better facilitate the physical understanding of hand-object interactions in AR/VR and robotics research.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02244",
        "abstract url": "https://arxiv.org/abs/2409.02244",
        "title": "Therapy as an NLP Task: Psychologists' Comparison of LLMs and Human Peers in CBT",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Wider access to therapeutic care is one of the biggest challenges in mental health treatment. Due to institutional barriers, some people seeking mental health support have turned to large language models (LLMs) for personalized therapy, even though these models are largely unsanctioned and untested. We investigate the potential and limitations of using LLMs as providers of evidence-based therapy by using mixed methods clinical metrics. Using HELPERT, a prompt run on a large language model using the same process and training as a comparative group of peer counselors, we replicated publicly accessible mental health conversations rooted in Cognitive Behavioral Therapy (CBT) to compare session dynamics and counselor's CBT-based behaviors between original peer support sessions and their reconstructed HELPERT sessions. Two licensed, CBT-trained clinical psychologists evaluated the sessions using the Cognitive Therapy Rating Scale and provided qualitative feedback. Our findings show that the peer sessions are characterized by empathy, small talk, therapeutic alliance, and shared experiences but often exhibit therapist drift. Conversely, HELPERT reconstructed sessions exhibit minimal therapist drift and higher adherence to CBT methods but display a lack of collaboration, empathy, and cultural understanding. Through CTRS ratings and psychologists' feedback, we highlight the importance of human-AI collaboration for scalable mental health. Our work outlines the ethical implication of imparting human-like subjective qualities to LLMs in therapeutic settings, particularly the risk of deceptive empathy, which may lead to unrealistic patient expectations and potential harm.",
        "subjects": [
            "cs.HC",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02261",
        "abstract url": "https://arxiv.org/abs/2409.02261",
        "title": "Action-Based ADHD Diagnosis in Video",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Diagnosis"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Attention Deficit Hyperactivity Disorder (ADHD) causes significant impairment in various domains. Early diagnosis of ADHD and treatment could significantly improve the quality of life and functioning. Recently, machine learning methods have improved the accuracy and efficiency of the ADHD diagnosis process. However, the cost of the equipment and trained staff required by the existing methods are generally huge. Therefore, we introduce the video-based frame-level action recognition network to ADHD diagnosis for the first time. We also record a real multi-modal ADHD dataset and extract three action classes from the video modality for ADHD diagnosis. The whole process data have been reported to CNTW-NHS Foundation Trust, which would be reviewed by medical consultants/professionals and will be made public in due course.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "31st European Symposium on Artificial Neural Networks"
    },
    {
        "paper id": "2409.02273",
        "abstract url": "https://arxiv.org/abs/2409.02273",
        "title": "SlipNet: Slip Cost Map for Autonomous Navigation on Heterogeneous Deformable Terrains",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "Autonomous space rovers face significant challenges when navigating deformable and heterogeneous terrains during space exploration. The variability in terrain types, influenced by different soil properties, often results in severe wheel slip, compromising navigation efficiency and potentially leading to entrapment. This paper proposes SlipNet, an approach for predicting slip in segmented regions of heterogeneous deformable terrain surfaces to enhance navigation algorithms. Unlike previous methods, SlipNet does not depend on prior terrain classification, reducing prediction errors and misclassifications through dynamic terrain segmentation and slip assignment during deployment while maintaining a history of terrain classes. This adaptive reclassification mechanism has improved prediction performance. Extensive simulation results demonstrate that our model (DeepLab v3+ + SlipNet) achieves better slip prediction performance than the TerrainNet, with a lower mean absolute error (MAE) in five terrain sample tests.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02274",
        "abstract url": "https://arxiv.org/abs/2409.02274",
        "title": "ADHD diagnosis based on action characteristics recorded in videos using machine learning",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Demand for ADHD diagnosis and treatment is increasing significantly and the existing services are unable to meet the demand in a timely manner. In this work, we introduce a novel action recognition method for ADHD diagnosis by identifying and analysing raw video recordings. Our main contributions include 1) designing and implementing a test focusing on the attention and hyperactivity/impulsivity of participants, recorded through three cameras; 2) implementing a novel machine learning ADHD diagnosis system based on action recognition neural networks for the first time; 3) proposing classification criteria to provide diagnosis results and analysis of ADHD action characteristics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Neuroscience Applied"
    },
    {
        "paper id": "2409.02284",
        "abstract url": "https://arxiv.org/abs/2409.02284",
        "title": "Biochemical Prostate Cancer Recurrence Prediction: Thinking Fast & Slow",
        "rating": "-1",
        "keywords": [
            [
                "Biochemical",
                "surgery",
                "Cancer"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Time to biochemical recurrence in prostate cancer is essential for prognostic monitoring of the progression of patients after prostatectomy, which assesses the efficacy of the surgery. In this work, we proposed to leverage multiple instance learning through a two-stage ``thinking fast \\& slow'' strategy for the time to recurrence (TTR) prediction. The first (``thinking fast'') stage finds the most relevant WSI area for biochemical recurrence and the second (``thinking slow'') stage leverages higher resolution patches to predict TTR. Our approach reveals a mean C-index ($Ci$) of 0.733 ($\u03b8=0.059$) on our internal validation and $Ci=0.603$ on the LEOPARD challenge validation set. Post hoc attention visualization shows that the most attentive area contributes to the TTR prediction.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 3 figures, methodology paper for LEOPRARD Challenge"
    },
    {
        "paper id": "2409.02305",
        "abstract url": "https://arxiv.org/abs/2409.02305",
        "title": "Kinesthetic Teaching in Robotics: a Mixed Reality Approach",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "robot"
            ]
        ],
        "abstract": "As collaborative robots become more common in manufacturing scenarios and adopted in hybrid human-robot teams, we should develop new interaction and communication strategies to ensure smooth collaboration between agents. In this paper, we propose a novel communicative interface that uses Mixed Reality as a medium to perform Kinesthetic Teaching (KT) on any robotic platform. We evaluate our proposed approach in a user study involving multiple subjects and two different robots, comparing traditional physical KT with holographic-based KT through user experience questionnaires and task-related metrics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been published in the Proceedings of the 2024 IEEE International Conference on Human and Robot Interactive Communication (RO-MAN), Pasadena, CA, USA, August 2024"
    },
    {
        "paper id": "2409.02312",
        "abstract url": "https://arxiv.org/abs/2409.02312",
        "title": "Investigating Mixed Reality for Communication Between Humans and Mobile Manipulators",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This article investigates mixed reality (MR) to enhance human-robot collaboration (HRC). The proposed solution adopts MR as a communication layer to convey a mobile manipulator's intentions and upcoming actions to the humans with whom it interacts, thus improving their collaboration. A user study involving 20 participants demonstrated the effectiveness of this MR-focused approach in facilitating collaborative tasks, with a positive effect on overall collaboration performances and human satisfaction.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been published in the Proceedings of the 2024 IEEE International Conference on Human and Robot Interactive Communication (RO-MAN), Pasadena, CA, USA, August 2024"
    },
    {
        "paper id": "2409.02335",
        "abstract url": "https://arxiv.org/abs/2409.02335",
        "title": "What Do You See in Common? Learning Hierarchical Prototypes over Tree-of-Life to Discover Evolutionary Traits",
        "rating": "-1",
        "keywords": [
            [
                "biology"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A grand challenge in biology is to discover evolutionary traits - features of organisms common to a group of species with a shared ancestor in the tree of life (also referred to as phylogenetic tree). With the growing availability of image repositories in biology, there is a tremendous opportunity to discover evolutionary traits directly from images in the form of a hierarchy of prototypes. However, current prototype-based methods are mostly designed to operate over a flat structure of classes and face several challenges in discovering hierarchical prototypes, including the issue of learning over-specific features at internal nodes. To overcome these challenges, we introduce the framework of Hierarchy aligned Commonality through Prototypical Networks (HComP-Net). We empirically show that HComP-Net learns prototypes that are accurate, semantically consistent, and generalizable to unseen species in comparison to baselines on birds, butterflies, and fishes datasets. The code and datasets are available at https://github.com/Imageomics/HComPNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "34 pages, 27 figures"
    },
    {
        "paper id": "2409.02337",
        "abstract url": "https://arxiv.org/abs/2409.02337",
        "title": "Coaching a Robotic Sonographer: Learning Robotic Ultrasound with Sparse Expert's Feedback",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Ultrasound is widely employed for clinical intervention and diagnosis, due to its advantages of offering non-invasive, radiation-free, and real-time imaging. However, the accessibility of this dexterous procedure is limited due to the substantial training and expertise required of operators. The robotic ultrasound (RUS) offers a viable solution to address this limitation; nonetheless, achieving human-level proficiency remains challenging. Learning from demonstrations (LfD) methods have been explored in RUS, which learns the policy prior from a dataset of offline demonstrations to encode the mental model of the expert sonographer. However, active engagement of experts, i.e. Coaching, during the training of RUS has not been explored thus far. Coaching is known for enhancing efficiency and performance in human training. This paper proposes a coaching framework for RUS to amplify its performance. The framework combines DRL (self-supervised practice) with sparse expert's feedback through coaching. The DRL employs an off-policy Soft Actor-Critic (SAC) network, with a reward based on image quality rating. The coaching by experts is modeled as a Partially Observable Markov Decision Process (POMDP), which updates the policy parameters based on the correction by the expert. The validation study on phantoms showed that coaching increases the learning rate by $25\\%$ and the number of high-quality image acquisition by $74.5\\%$.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted in IEEE Transactions on Medical Robotics and Bionics (TMRB) 2024"
    },
    {
        "paper id": "2409.02348",
        "abstract url": "https://arxiv.org/abs/2409.02348",
        "title": "Image Registration with Averaging Network and Edge-Based Loss for Low-SNR Cardiac MRI",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "clinical",
                "Cardiac"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: To perform image registration and averaging of multiple free-breathing single-shot cardiac images, where the individual images may have a low signal-to-noise ratio (SNR). Methods: To address low SNR encountered in single-shot imaging, especially at low field strengths, we propose a fast deep learning (DL)-based image registration method, called Averaging Morph with Edge Detection (AiM-ED). AiM-ED jointly registers multiple noisy source images to a noisy target image and utilizes a noise-robust pre-trained edge detector to define the training loss. We validate AiM-ED using synthetic late gadolinium enhanced (LGE) imaging data from the MR extended cardiac-torso (MRXCAT) phantom and retrospectively undersampled single-shot data from healthy subjects (24 slices) and patients (5 slices) under various levels of added noise. Additionally, we demonstrate the clinical feasibility of AiM-ED by applying it to prospectively undersampled data from patients (6 slices) scanned at a 0.55T scanner. Results: Compared to a traditional energy-minimization-based image registration method and DL-based VoxelMorph, images registered using AiM-ED exhibit higher values of recovery SNR and three perceptual image quality metrics. An ablation study shows the benefit of both jointly processing multiple source images and using an edge map in AiM-ED. Conclusion: For single-shot LGE imaging, AiM-ED outperforms existing image registration methods in terms of image quality. With fast inference, minimal training data requirements, and robust performance at various noise levels, AiM-ED has the potential to benefit single-shot CMR applications.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02389",
        "abstract url": "https://arxiv.org/abs/2409.02389",
        "title": "Multi-modal Situated Reasoning in 3D Scenes",
        "rating": "-1",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "3D",
                "point cloud"
            ],
            [
                "Navigation"
            ],
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Situation awareness is essential for understanding and reasoning about 3D scenes in embodied AI agents. However, existing datasets and benchmarks for situated understanding are limited in data modality, diversity, scale, and task scope. To address these limitations, we propose Multi-modal Situated Question Answering (MSQA), a large-scale multi-modal situated reasoning dataset, scalably collected leveraging 3D scene graphs and vision-language models (VLMs) across a diverse range of real-world 3D scenes. MSQA includes 251K situated question-answering pairs across 9 distinct question categories, covering complex scenarios within 3D scenes. We introduce a novel interleaved multi-modal input setting in our benchmark to provide text, image, and point cloud for situation and question description, resolving ambiguity in previous single-modality convention (e.g., text). Additionally, we devise the Multi-modal Situated Next-step Navigation (MSNN) benchmark to evaluate models' situated reasoning for navigation. Comprehensive evaluations on MSQA and MSNN highlight the limitations of existing vision-language models and underscore the importance of handling multi-modal interleaved inputs and situation modeling. Experiments on data scaling and cross-domain transfer further demonstrate the efficacy of leveraging MSQA as a pre-training dataset for developing more powerful situated reasoning models.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Project page: https://msr3d.github.io/"
    },
    {
        "paper id": "2409.02390",
        "abstract url": "https://arxiv.org/abs/2409.02390",
        "title": "Neural Dynamics Model of Visual Decision-Making: Learning from Human Experts",
        "rating": "-1",
        "keywords": [
            [
                "biological",
                "MRI"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Uncovering the fundamental neural correlates of biological intelligence, developing mathematical models, and conducting computational simulations are critical for advancing new paradigms in artificial intelligence (AI). In this study, we implemented a comprehensive visual decision-making model that spans from visual input to behavioral output, using a neural dynamics modeling approach. Drawing inspiration from the key components of the dorsal visual pathway in primates, our model not only aligns closely with human behavior but also reflects neural activities in primates, and achieving accuracy comparable to convolutional neural networks (CNNs). Moreover, magnetic resonance imaging (MRI) identified key neuroimaging features such as structural connections and functional connectivity that are associated with performance in perceptual decision-making tasks. A neuroimaging-informed fine-tuning approach was introduced and applied to the model, leading to performance improvements that paralleled the behavioral variations observed among subjects. Compared to classical deep learning models, our model more accurately replicates the behavioral performance of biological intelligence, relying on the structural characteristics of biological neural networks rather than extensive training data, and demonstrating enhanced resilience to perturbation.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.CV",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02415",
        "abstract url": "https://arxiv.org/abs/2409.02415",
        "title": "Local map Construction Methods with SD map: A Novel Survey",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, significant academic advancements have been made in the field of autonomous vehicles, with Local maps emerging as a crucial component of autonomous driving technology. Local maps not only provide intricate details of road networks but also serve as fundamental inputs for critical tasks such as vehicle localization, navigation, and decision-making. Given the characteristics of SD map (Standard Definition Map), which include low cost, ease of acquisition, and high versatility, perception methods that integrate SD map as prior information have demonstrated significant potential in the field of Local map perception. The purpose of this paper is to provide researchers with a comprehensive overview and summary of the latest advancements in the integration of SD map as prior information for Local map perception methods. This review begins by introducing the task definition and general pipeline of local map perception methods that incorporate SD maps as prior information, along with relevant public datasets. And then it focuses on the representation and encoding methods of multi-source information, as well as the methods for fusing multi-source information. In response to this burgeoning trend, this article presents a comprehensive and meticulous overview of the diverse research efforts in this particular field. Finally, the article addresses pertinent issues and future challenges with the aim of guiding researchers in understanding the current trends and methodologies prevalent in the field.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 11 figures"
    },
    {
        "paper id": "2409.02418",
        "abstract url": "https://arxiv.org/abs/2409.02418",
        "title": "MOSMOS: Multi-organ segmentation facilitated by medical report supervision",
        "rating": "-1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "3D"
            ],
            [
                "medical",
                "organ"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Owing to a large amount of multi-modal data in modern medical systems, such as medical images and reports, Medical Vision-Language Pre-training (Med-VLP) has demonstrated incredible achievements in coarse-grained downstream tasks (i.e., medical classification, retrieval, and visual question answering). However, the problem of transferring knowledge learned from Med-VLP to fine-grained multi-organ segmentation tasks has barely been investigated. Multi-organ segmentation is challenging mainly due to the lack of large-scale fully annotated datasets and the wide variation in the shape and size of the same organ between individuals with different diseases. In this paper, we propose a novel pre-training & fine-tuning framework for Multi-Organ Segmentation by harnessing Medical repOrt Supervision (MOSMOS). Specifically, we first introduce global contrastive learning to maximally align the medical image-report pairs in the pre-training stage. To remedy the granularity discrepancy, we further leverage multi-label recognition to implicitly learn the semantic correspondence between image pixels and organ tags. More importantly, our pre-trained models can be transferred to any segmentation model by introducing the pixel-tag attention maps. Different network settings, i.e., 2D U-Net and 3D UNETR, are utilized to validate the generalization. We have extensively evaluated our approach using different diseases and modalities on BTCV, AMOS, MMWHS, and BRATS datasets. Experimental results in various settings demonstrate the effectiveness of our framework. This framework can serve as the foundation to facilitate future research on automatic annotation tasks under the supervision of medical reports.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 7 figures"
    },
    {
        "paper id": "2409.02421",
        "abstract url": "https://arxiv.org/abs/2409.02421",
        "title": "MusicMamba: A Dual-Feature Modeling Approach for Generating Chinese Traditional Music with Modal Precision",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In recent years, deep learning has significantly advanced the MIDI domain, solidifying music generation as a key application of artificial intelligence. However, existing research primarily focuses on Western music and encounters challenges in generating melodies for Chinese traditional music, especially in capturing modal characteristics and emotional expression. To address these issues, we propose a new architecture, the Dual-Feature Modeling Module, which integrates the long-range dependency modeling of the Mamba Block with the global structure capturing capabilities of the Transformer Block. Additionally, we introduce the Bidirectional Mamba Fusion Layer, which integrates local details and global structures through bidirectional scanning, enhancing the modeling of complex sequences. Building on this architecture, we propose the REMI-M representation, which more accurately captures and generates modal information in melodies. To support this research, we developed FolkDB, a high-quality Chinese traditional music dataset encompassing various styles and totaling over 11 hours of music. Experimental results demonstrate that the proposed architecture excels in generating melodies with Chinese traditional music characteristics, offering a new and effective solution for music generation.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02434",
        "abstract url": "https://arxiv.org/abs/2409.02434",
        "title": "Context-Aware Agent-based Model for Smart Long Distance Transport System",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Long-distance transport plays a vital role in the economic growth of countries. However, there is a lack of systems being developed for monitoring and support of long-route vehicles (LRV). Sustainable and context-aware transport systems with modern technologies are needed. We model for long-distance vehicle transportation monitoring and support systems in a multi-agent environment. Our model incorporates the distance vehicle transport mechanism through agent-based modeling (ABM). This model constitutes the design protocol of ABM called Overview, Design, and Details (ODD). This model constitutes that every category of agents is offering information as a service. Hence, a federation of services through protocol for the communication between sensors and software components is desired. Such integration of services supports monitoring and tracking of vehicles on the route. The model simulations provide useful results for the integration of services based on smart objects.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02437",
        "abstract url": "https://arxiv.org/abs/2409.02437",
        "title": "Fuzzy Logic Control for Indoor Navigation of Mobile Robots",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "Navigation"
            ]
        ],
        "abstract": "Autonomous mobile robots have many applications in indoor unstructured environment, wherein optimal movement of the robot is needed. The robot therefore needs to navigate in unknown and dynamic environments. This paper presents an implementation of fuzzy logic controller for navigation of mobile robot in an unknown dynamically cluttered environment. Fuzzy logic controller is used here as it is capable of making inferences even under uncertainties. It helps in rule generation and decision making process in order to reach the goal position under various situations. Sensor readings from the robot and the desired direction of motion are inputs to the fuzz logic controllers and the acceleration of the respective wheels are the output of the controller. Hence, the mobile robot avoids obstacles and reaches the goal position. Keywords: Fuzzy Logic Controller, Membership Functions, Takagi-Sugeno-Kang FIS, Centroid Defuzzification",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02444",
        "abstract url": "https://arxiv.org/abs/2409.02444",
        "title": "USV-AUV Collaboration Framework for Underwater Tasks under Extreme Sea Conditions",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Autonomous underwater vehicles (AUVs) are valuable for ocean exploration due to their flexibility and ability to carry communication and detection units. Nevertheless, AUVs alone often face challenges in harsh and extreme sea conditions. This study introduces a unmanned surface vehicle (USV)-AUV collaboration framework, which includes high-precision multi-AUV positioning using USV path planning via Fisher information matrix optimization and reinforcement learning for multi-AUV cooperative tasks. Applied to a multi-AUV underwater data collection task scenario, extensive simulations validate the framework's feasibility and superior performance, highlighting exceptional coordination and robustness under extreme sea conditions. The simulation code will be made available as open-source to foster future research in this area.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03713",
        "abstract url": "https://arxiv.org/abs/2409.03713",
        "title": "Clustering of Indonesian and Western Gamelan Orchestras through Machine Learning of Performance Parameters",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.LG",
                "cs.SD"
            ]
        ],
        "abstract": "Indonesian and Western gamelan ensembles are investigated with respect to performance differences. Thereby, the often exotistic history of this music in the West might be reflected in contemporary tonal system, articulation, or large-scale form differences. Analyzing recordings of four Western and five Indonesian orchestras with respect to tonal systems and timbre features and using self-organizing Kohonen map (SOM) as a machine learning algorithm, a clear clustering between Indonesian and Western ensembles appears using certain psychoacoustic features. These point to a reduced articulation and large-scale form variability of Western ensembles compared to Indonesian ones. The SOM also clusters the ensembles with respect to their tonal systems, but no clusters between Indonesian and Western ensembles can be found in this respect. Therefore, a clear analogy between lower articulatory variability and large-scale form variation and a more exostistic, mediative and calm performance expectation and reception of gamelan in the West therefore appears.",
        "subjects": [
            "cs.SD",
            "cs.LG"
        ],
        "comment": "5 figures, 4 tables"
    },
    {
        "paper id": "2409.03715",
        "abstract url": "https://arxiv.org/abs/2409.03715",
        "title": "Applications and Advances of Artificial Intelligence in Music Generation:A Review",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In recent years, artificial intelligence (AI) has made significant progress in the field of music generation, driving innovation in music creation and applications. This paper provides a systematic review of the latest research advancements in AI music generation, covering key technologies, models, datasets, evaluation methods, and their practical applications across various fields. The main contributions of this review include: (1) presenting a comprehensive summary framework that systematically categorizes and compares different technological approaches, including symbolic generation, audio generation, and hybrid models, helping readers better understand the full spectrum of technologies in the field; (2) offering an extensive survey of current literature, covering emerging topics such as multimodal datasets and emotion expression evaluation, providing a broad reference for related research; (3) conducting a detailed analysis of the practical impact of AI music generation in various application domains, particularly in real-time interaction and interdisciplinary applications, offering new perspectives and insights; (4) summarizing the existing challenges and limitations of music quality evaluation methods and proposing potential future research directions, aiming to promote the standardization and broader adoption of evaluation techniques. Through these innovative summaries and analyses, this paper serves as a comprehensive reference tool for researchers and practitioners in AI music generation, while also outlining future directions for the field.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03794",
        "abstract url": "https://arxiv.org/abs/2409.03794",
        "title": "Evaluating Machine Learning-based Skin Cancer Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "Cancer",
                "skin lesions",
                "lesion"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This study evaluates the reliability of two deep learning models for skin cancer detection, focusing on their explainability and fairness. Using the HAM10000 dataset of dermatoscopic images, the research assesses two convolutional neural network architectures: a MobileNet-based model and a custom CNN model. Both models are evaluated for their ability to classify skin lesions into seven categories and to distinguish between dangerous and benign lesions. Explainability is assessed using Saliency Maps and Integrated Gradients, with results interpreted by a dermatologist. The study finds that both models generally highlight relevant features for most lesion types, although they struggle with certain classes like seborrheic keratoses and vascular lesions. Fairness is evaluated using the Equalized Odds metric across sex and skin tone groups. While both models demonstrate fairness across sex groups, they show significant disparities in false positive and false negative rates between light and dark skin tones. A Calibrated Equalized Odds postprocessing strategy is applied to mitigate these disparities, resulting in improved fairness, particularly in reducing false negative rate differences. The study concludes that while the models show promise in explainability, further development is needed to ensure fairness across different skin tones. These findings underscore the importance of rigorous evaluation of AI models in medical applications, particularly in diverse population groups.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.01626",
        "abstract url": "https://arxiv.org/abs/2409.01626",
        "title": "AQ-PINNs: Attention-Enhanced Quantum Physics-Informed Neural Networks for Carbon-Efficient Climate Modeling",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum",
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The growing computational demands of artificial intelligence (AI) in addressing climate change raise significant concerns about inefficiencies and environmental impact, as highlighted by the Jevons paradox. We propose an attention-enhanced quantum physics-informed neural networks model (AQ-PINNs) to tackle these challenges. This approach integrates quantum computing techniques into physics-informed neural networks (PINNs) for climate modeling, aiming to enhance predictive accuracy in fluid dynamics governed by the Navier-Stokes equations while reducing the computational burden and carbon footprint. By harnessing variational quantum multi-head self-attention mechanisms, our AQ-PINNs achieve a 51.51% reduction in model parameters compared to classical multi-head self-attention methods while maintaining comparable convergence and loss. It also employs quantum tensor networks to enhance representational capacity, which can lead to more efficient gradient computations and reduced susceptibility to barren plateaus. Our AQ-PINNs represent a crucial step towards more sustainable and effective climate modeling solutions.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.01630",
        "abstract url": "https://arxiv.org/abs/2409.01630",
        "title": "SafeEmbodAI: a Safety Framework for Mobile Robots in Embodied AI Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Embodied AI systems, including AI-powered robots that autonomously interact with the physical world, stand to be significantly advanced by Large Language Models (LLMs), which enable robots to better understand complex language commands and perform advanced tasks with enhanced comprehension and adaptability, highlighting their potential to improve embodied AI capabilities. However, this advancement also introduces safety challenges, particularly in robotic navigation tasks. Improper safety management can lead to failures in complex environments and make the system vulnerable to malicious command injections, resulting in unsafe behaviours such as detours or collisions. To address these issues, we propose \\textit{SafeEmbodAI}, a safety framework for integrating mobile robots into embodied AI systems. \\textit{SafeEmbodAI} incorporates secure prompting, state management, and safety validation mechanisms to secure and assist LLMs in reasoning through multi-modal data and validating responses. We designed a metric to evaluate mission-oriented exploration, and evaluations in simulated environments demonstrate that our framework effectively mitigates threats from malicious commands and improves performance in various environment settings, ensuring the safety of embodied AI systems. Notably, In complex environments with mixed obstacles, our method demonstrates a significant performance increase of 267\\% compared to the baseline in attack scenarios, highlighting its robustness in challenging conditions.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01635",
        "abstract url": "https://arxiv.org/abs/2409.01635",
        "title": "PMLBmini: A Tabular Classification Benchmark Suite for Data-Scarce Applications",
        "rating": "-1.5",
        "keywords": [
            [
                "Tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In practice, we are often faced with small-sized tabular data. However, current tabular benchmarks are not geared towards data-scarce applications, making it very difficult to derive meaningful conclusions from empirical comparisons. We introduce PMLBmini, a tabular benchmark suite of 44 binary classification datasets with sample sizes $\\leq$ 500. We use our suite to thoroughly evaluate current automated machine learning (AutoML) frameworks, off-the-shelf tabular deep neural networks, as well as classical linear models in the low-data regime. Our analysis reveals that state-of-the-art AutoML and deep learning approaches often fail to appreciably outperform even a simple logistic regression baseline, but we also identify scenarios where AutoML and deep learning methods are indeed reasonable to apply. Our benchmark suite, available on https://github.com/RicardoKnauer/TabMini , allows researchers and practitioners to analyze their own methods and challenge their data efficiency.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "AutoML 2024 Workshop Track"
    },
    {
        "paper id": "2409.01641",
        "abstract url": "https://arxiv.org/abs/2409.01641",
        "title": "Unveiling Advanced Frequency Disentanglement Paradigm for Low-Light Image Enhancement",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Previous low-light image enhancement (LLIE) approaches, while employing frequency decomposition techniques to address the intertwined challenges of low frequency (e.g., illumination recovery) and high frequency (e.g., noise reduction), primarily focused on the development of dedicated and complex networks to achieve improved performance. In contrast, we reveal that an advanced disentanglement paradigm is sufficient to consistently enhance state-of-the-art methods with minimal computational overhead. Leveraging the image Laplace decomposition scheme, we propose a novel low-frequency consistency method, facilitating improved frequency disentanglement optimization. Our method, seamlessly integrating with various models such as CNNs, Transformers, and flow-based and diffusion models, demonstrates remarkable adaptability. Noteworthy improvements are showcased across five popular benchmarks, with up to 7.68dB gains on PSNR achieved for six state-of-the-art models. Impressively, our approach maintains efficiency with only 88K extra parameters, setting a new standard in the challenging realm of low-light image enhancement.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV 2024, Github \\url{https://github.com/redrock303/ADF-LLIE}"
    },
    {
        "paper id": "2409.01712",
        "abstract url": "https://arxiv.org/abs/2409.01712",
        "title": "Toward Capturing Genetic Epistasis From Multivariate Genome-Wide Association Studies Using Mixed-Precision Kernel Ridge Regression",
        "rating": "-1.5",
        "keywords": [
            [
                "BioBank"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We exploit the widening margin in tensor-core performance between [FP64/FP32/FP16/INT8,FP64/FP32/FP16/FP8/INT8] on NVIDIA [Ampere,Hopper] GPUs to boost the performance of output accuracy-preserving mixed-precision computation of Genome-Wide Association Studies (GWAS) of 305K patients from the UK BioBank, the largest-ever GWAS cohort studied for genetic epistasis using a multivariate approach. Tile-centric adaptive-precision linear algebraic techniques motivated by reducing data motion gain enhanced significance with low-precision GPU arithmetic. At the core of Kernel Ridge Regression (KRR) techniques for GWAS lie compute-bound cubic-complexity matrix operations that inhibit scaling to aspirational dimensions of the population, genotypes, and phenotypes. We accelerate KRR matrix generation by redesigning the computation for Euclidean distances to engage INT8 tensor cores while exploiting symmetry.We accelerate solution of the regularized KRR systems by deploying a new four-precision Cholesky-based solver, which, at 1.805 mixed-precision ExaOp/s on a nearly full Alps system, outperforms the state-of-the-art CPU-only REGENIE GWAS software by five orders of magnitude.",
        "subjects": [
            "q-bio.GN",
            "cs.AR",
            "cs.LG",
            "cs.MS",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01899",
        "abstract url": "https://arxiv.org/abs/2409.01899",
        "title": "PINNIES: An Efficient Physics-Informed Neural Network Framework to Integral Operator Problems",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces an efficient tensor-vector product technique for the rapid and accurate approximation of integral operators within physics-informed deep learning frameworks. Our approach leverages neural network architectures to evaluate problem dynamics at specific points, while employing Gaussian quadrature formulas to approximate the integral components, even in the presence of infinite domains or singularities. We demonstrate the applicability of this method to both Fredholm and Volterra integral operators, as well as to optimal control problems involving continuous time. Additionally, we outline how this approach can be extended to approximate fractional derivatives and integrals and propose a fast matrix-vector product algorithm for efficiently computing the fractional Caputo derivative. In the numerical section, we conduct comprehensive experiments on forward and inverse problems. For forward problems, we evaluate the performance of our method on over 50 diverse mathematical problems, including multi-dimensional integral equations, systems of integral equations, partial and fractional integro-differential equations, and various optimal control problems in delay, fractional, multi-dimensional, and nonlinear configurations. For inverse problems, we test our approach on several integral equations and fractional integro-differential problems. Finally, we introduce the pinnies Python package to facilitate the implementation and usability of the proposed method.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": "The PiNNIEs python package is available at https://github.com/alirezaafzalaghaei/pinnies"
    },
    {
        "paper id": "2409.01914",
        "abstract url": "https://arxiv.org/abs/2409.01914",
        "title": "GradINN: Gradient Informed Neural Network",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We propose Gradient Informed Neural Networks (GradINNs), a methodology inspired by Physics Informed Neural Networks (PINNs) that can be used to efficiently approximate a wide range of physical systems for which the underlying governing equations are completely unknown or cannot be defined, a condition that is often met in complex engineering problems. GradINNs leverage prior beliefs about a system's gradient to constrain the predicted function's gradient across all input dimensions. This is achieved using two neural networks: one modeling the target function and an auxiliary network expressing prior beliefs, e.g., smoothness. A customized loss function enables training the first network while enforcing gradient constraints derived from the auxiliary network. We demonstrate the advantages of GradINNs, particularly in low-data regimes, on diverse problems spanning non time-dependent systems (Friedman function, Stokes Flow) and time-dependent systems (Lotka-Volterra, Burger's equation). Experimental results showcase strong performance compared to standard neural networks and PINN-like approaches across all tested scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01932",
        "abstract url": "https://arxiv.org/abs/2409.01932",
        "title": "Modeling IoT Traffic Patterns: Insights from a Statistical Analysis of an MTC Dataset",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Internet-of-Things (IoT) is rapidly expanding, connecting numerous devices and becoming integral to our daily lives. As this occurs, ensuring efficient traffic management becomes crucial. Effective IoT traffic management requires modeling and predicting intrincate machine-type communication (MTC) dynamics, for which machine-learning (ML) techniques are certainly appealing. However, obtaining comprehensive and high-quality datasets, along with accessible platforms for reproducing ML-based predictions, continues to impede the research progress. In this paper, we aim to fill this gap by characterizing the Smart Campus MTC dataset provided by the University of Oulu. Specifically, we perform a comprehensive statistical analysis of the MTC traffic utilizing goodness-of-fit tests, including well-established tests such as Kolmogorov-Smirnov, Anderson-Darling, chi-squared, and root mean square error. The analysis centers on examining and evaluating three models that accurately represent the two most significant MTC traffic types: periodic updating and event-driven, which are also identified from the dataset. The results demonstrate that the models accurately characterize the traffic patterns. The Poisson point process model exhibits the best fit for event-driven patterns with errors below 11%, while the quasi-periodic model fits accurately the periodic updating traffic with errors below 7%.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": "SSRN:4655476"
    },
    {
        "paper id": "2409.01977",
        "abstract url": "https://arxiv.org/abs/2409.01977",
        "title": "Counterfactual Fairness by Combining Factual and Counterfactual Predictions",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In high-stake domains such as healthcare and hiring, the role of machine learning (ML) in decision-making raises significant fairness concerns. This work focuses on Counterfactual Fairness (CF), which posits that an ML model's outcome on any individual should remain unchanged if they had belonged to a different demographic group. Previous works have proposed methods that guarantee CF. Notwithstanding, their effects on the model's predictive performance remains largely unclear. To fill in this gap, we provide a theoretical study on the inherent trade-off between CF and predictive performance in a model-agnostic manner. We first propose a simple but effective method to cast an optimal but potentially unfair predictor into a fair one without losing the optimality. By analyzing its excess risk in order to achieve CF, we quantify this inherent trade-off. Further analysis on our method's performance with access to only incomplete causal knowledge is also conducted. Built upon it, we propose a performant algorithm that can be applied in such scenarios. Experiments on both synthetic and semi-synthetic datasets demonstrate the validity of our analysis and methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01978",
        "abstract url": "https://arxiv.org/abs/2409.01978",
        "title": "Application of Langevin Dynamics to Advance the Quantum Natural Gradient Optimization Algorithm",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A Quantum Natural Gradient (QNG) algorithm for optimization of variational quantum circuits has been proposed recently. In this study, we employ the Langevin equation with a QNG stochastic force to demonstrate that its discrete-time solution gives a generalized form of the above-specified algorithm, which we call Momentum-QNG. Similar to other optimization algorithms with the momentum term, such as the Stochastic Gradient Descent with momentum, RMSProp with momentum and Adam, Momentum-QNG is more effective to escape local minima and plateaus in the variational parameter space and, therefore, achieves a better convergence behavior compared to the basic QNG. Our open-source code is available at https://github.com/borbysh/Momentum-QNG",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.02002",
        "abstract url": "https://arxiv.org/abs/2409.02002",
        "title": "The overlooked need for Ethics in Complexity Science: Why it matters",
        "rating": "-1.5",
        "keywords": [
            [
                "biotechnology"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Complexity science, despite its broad scope and potential impact, has not kept pace with fields like artificial intelligence, biotechnology and social sciences in addressing ethical concerns. The field lacks a comprehensive ethical framework, leaving us, as a community, vulnerable to ethical challenges and dilemmas. Other areas have gone through similar experiences and created, with discussions and working groups, their guides, policies and recommendations. Therefore, here we highlight the critical absence of formal guidelines, dedicated ethical committees, and widespread discussions on ethics within the complexity science community. Drawing on insights from the disciplines mentioned earlier, we propose a roadmap to enhance ethical awareness and action. Our recommendations include (i) initiating supportive mechanisms to develop ethical guidelines specific to complex systems research, (ii) creating open-access resources, and (iii) fostering inclusive dialogues to ensure that complexity science can responsibly tackle societal challenges and achieve a more inclusive environment. By initiating this dialogue, we aim to encourage a necessary shift in how ethics is integrated into complexity research, positioning the field to address contemporary challenges more effectively.",
        "subjects": [
            "physics.soc-ph",
            "cs.CY"
        ],
        "comment": "7 pages, 2 figures, 1 Annexus, 1 table"
    },
    {
        "paper id": "2409.02008",
        "abstract url": "https://arxiv.org/abs/2409.02008",
        "title": "When Digital Twin Meets 6G: Concepts, Obstacles, and Research Prospects",
        "rating": "-1.5",
        "keywords": [
            [
                "6G"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The convergence of digital twin technology and the emerging 6G network presents both challenges and numerous research opportunities. This article explores the potential synergies between digital twin and 6G, highlighting the key challenges and proposing fundamental principles for their integration. We discuss the unique requirements and capabilities of digital twin in the context of 6G networks, such as sustainable deployment, real-time synchronization, seamless migration, predictive analytic, and closed-loop control. Furthermore, we identify research opportunities for leveraging digital twin and artificial intelligence to enhance various aspects of 6G, including network optimization, resource allocation, security, and intelligent service provisioning. This article aims to stimulate further research and innovation at the intersection of digital twin and 6G, paving the way for transformative applications and services in the future.",
        "subjects": [
            "cs.NI",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2409.02069",
        "abstract url": "https://arxiv.org/abs/2409.02069",
        "title": "A Deployed Online Reinforcement Learning Algorithm In An Oral Health Clinical Trial",
        "rating": "-1.5",
        "keywords": [
            [
                "Health",
                "disease",
                "Clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Dental disease is a prevalent chronic condition associated with substantial financial burden, personal suffering, and increased risk of systemic diseases. Despite widespread recommendations for twice-daily tooth brushing, adherence to recommended oral self-care behaviors remains sub-optimal due to factors such as forgetfulness and disengagement. To address this, we developed Oralytics, a mHealth intervention system designed to complement clinician-delivered preventative care for marginalized individuals at risk for dental disease. Oralytics incorporates an online reinforcement learning algorithm to determine optimal times to deliver intervention prompts that encourage oral self-care behaviors. We have deployed Oralytics in a registered clinical trial. The deployment required careful design to manage challenges specific to the clinical trials setting in the U.S. In this paper, we (1) highlight key design decisions of the RL algorithm that address these challenges and (2) conduct a re-sampling analysis to evaluate algorithm design decisions. A second phase (randomized control trial) of Oralytics is planned to start in spring 2025.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02145",
        "abstract url": "https://arxiv.org/abs/2409.02145",
        "title": "A Multimodal Object-level Contrast Learning Method for Cancer Survival Risk Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "Survival",
                "Cancer",
                "clinical",
                "pathological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Computer-aided cancer survival risk prediction plays an important role in the timely treatment of patients. This is a challenging weakly supervised ordinal regression task associated with multiple clinical factors involved such as pathological images, genomic data and etc. In this paper, we propose a new training method, multimodal object-level contrast learning, for cancer survival risk prediction. First, we construct contrast learning pairs based on the survival risk relationship among the samples in the training sample set. Then we introduce the object-level contrast learning method to train the survival risk predictor. We further extend it to the multimodal scenario by applying cross-modal constrast. Considering the heterogeneity of pathological images and genomics data, we construct a multimodal survival risk predictor employing attention-based and self-normalizing based nerural network respectively. Finally, the survival risk predictor trained by our proposed method outperforms state-of-the-art methods on two public multimodal cancer datasets for survival risk prediction.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02149",
        "abstract url": "https://arxiv.org/abs/2409.02149",
        "title": "Uncertainty Quantification Using Ensemble Learning and Monte Carlo Sampling for Performance Prediction and Monitoring in Cell Culture Processes",
        "rating": "-1.5",
        "keywords": [
            [
                "Biopharmaceutical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Biopharmaceutical products, particularly monoclonal antibodies (mAbs), have gained prominence in the pharmaceutical market due to their high specificity and efficacy. As these products are projected to constitute a substantial portion of global pharmaceutical sales, the application of machine learning models in mAb development and manufacturing is gaining momentum. This paper addresses the critical need for uncertainty quantification in machine learning predictions, particularly in scenarios with limited training data. Leveraging ensemble learning and Monte Carlo simulations, our proposed method generates additional input samples to enhance the robustness of the model in small training datasets. We evaluate the efficacy of our approach through two case studies: predicting antibody concentrations in advance and real-time monitoring of glucose concentrations during bioreactor runs using Raman spectra data. Our findings demonstrate the effectiveness of the proposed method in estimating the uncertainty levels associated with process performance predictions and facilitating real-time decision-making in biopharmaceutical manufacturing. This contribution not only introduces a novel approach for uncertainty quantification but also provides insights into overcoming challenges posed by small training datasets in bioprocess development. The evaluation demonstrates the effectiveness of our method in addressing key challenges related to uncertainty estimation within upstream cell cultivation, illustrating its potential impact on enhancing process control and product quality in the dynamic field of biopharmaceuticals.",
        "subjects": [
            "q-bio.QM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02231",
        "abstract url": "https://arxiv.org/abs/2409.02231",
        "title": "SmileyLlama: Modifying Large Language Models for Directed Chemical Space Exploration",
        "rating": "-1.5",
        "keywords": [
            [
                "chemistry",
                "Chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Here we show that a Large Language Model (LLM) can serve as a foundation model for a Chemical Language Model (CLM) which performs at or above the level of CLMs trained solely on chemical SMILES string data. Using supervised fine-tuning (SFT) and direct preference optimization (DPO) on the open-source Llama LLM, we demonstrate that we can train an LLM to respond to prompts such as generating molecules with properties of interest to drug development. This overall framework allows an LLM to not just be a chatbot client for chemistry and materials tasks, but can be adapted to speak more directly as a CLM which can generate molecules with user-specified properties.",
        "subjects": [
            "physics.chem-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02245",
        "abstract url": "https://arxiv.org/abs/2409.02245",
        "title": "FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Voice Conversion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Diffusion-based voice conversion (VC) techniques such as VoiceGrad have attracted interest because of their high VC performance in terms of speech quality and speaker similarity. However, a notable limitation is the slow inference caused by the multi-step reverse diffusion. Therefore, we propose FastVoiceGrad, a novel one-step diffusion-based VC that reduces the number of iterations from dozens to one while inheriting the high VC performance of the multi-step diffusion-based VC. We obtain the model using adversarial conditional diffusion distillation (ACDD), leveraging the ability of generative adversarial networks and diffusion models while reconsidering the initial states in sampling. Evaluations of one-shot any-to-any VC demonstrate that FastVoiceGrad achieves VC performance superior to or comparable to that of previous multi-step diffusion-based VC while enhancing the inference speed. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastvoicegrad/.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "eess.AS",
            "stat.ML"
        ],
        "comment": "Accepted to Interspeech 2024. Project page: https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastvoicegrad/"
    },
    {
        "paper id": "2409.02270",
        "abstract url": "https://arxiv.org/abs/2409.02270",
        "title": "Reinforcement Learning-enabled Satellite Constellation Reconfiguration and Retasking for Mission-Critical Applications",
        "rating": "-1.5",
        "keywords": [
            [
                "Satellite"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The development of satellite constellation applications is rapidly advancing due to increasing user demands, reduced operational costs, and technological advancements. However, a significant gap in the existing literature concerns reconfiguration and retasking issues within satellite constellations, which is the primary focus of our research. In this work, we critically assess the impact of satellite failures on constellation performance and the associated task requirements. To facilitate this analysis, we introduce a system modeling approach for GPS satellite constellations, enabling an investigation into performance dynamics and task distribution strategies, particularly in scenarios where satellite failures occur during mission-critical operations. Additionally, we introduce reinforcement learning (RL) techniques, specifically Q-learning, Policy Gradient, Deep Q-Network (DQN), and Proximal Policy Optimization (PPO), for managing satellite constellations, addressing the challenges posed by reconfiguration and retasking following satellite failures. Our results demonstrate that DQN and PPO achieve effective outcomes in terms of average rewards, task completion rates, and response times.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SY"
        ],
        "comment": "Accepted for publication in the IEEE Military Communications Conference (IEEE MILCOM 2024)"
    },
    {
        "paper id": "2409.02339",
        "abstract url": "https://arxiv.org/abs/2409.02339",
        "title": "Data-driven 2D stationary quantum droplets and wave propagations in the amended GP equation with two potentials via deep neural networks learning",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum",
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we develop a systematic deep learning approach to solve two-dimensional (2D) stationary quantum droplets (QDs) and investigate their wave propagation in the 2D amended Gross-Pitaevskii equation with Lee-Huang-Yang correction and two kinds of potentials. Firstly, we use the initial-value iterative neural network (IINN) algorithm for 2D stationary quantum droplets of stationary equations. Then the learned stationary QDs are used as the initial value conditions for physics-informed neural networks (PINNs) to explore their evolutions in the some space-time region. Especially, we consider two types of potentials, one is the 2D quadruple-well Gaussian potential and the other is the PT-symmetric HO-Gaussian potential, which lead to spontaneous symmetry breaking and the generation of multi-component QDs. The used deep learning method can also be applied to study wave propagations of other nonlinear physical models.",
        "subjects": [
            "cs.LG",
            "math-ph",
            "nlin.PS",
            "physics.comp-ph",
            "physics.optics"
        ],
        "comment": "17 pages, 12 figures (Proc. R. Soc. A, accepted for publication). arXiv admin note: text overlap with arXiv:2409.01124"
    },
    {
        "paper id": "2409.02349",
        "abstract url": "https://arxiv.org/abs/2409.02349",
        "title": "Machine Learning Applications to Computational Plasma Physics and Reduced-Order Plasma Modeling: A Perspective",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) provides a broad spectrum of tools and architectures that enable the transformation of data from simulations and experiments into useful and explainable science, thereby augmenting domain knowledge. Furthermore, ML-enhanced numerical modelling can revamp scientific computing for real-world complex engineering systems, creating unique opportunities to examine the operation of the technologies in detail and automate their optimization and control. In recent years, ML applications have seen significant growth across various scientific domains, particularly in fluid mechanics, where ML has shown great promise in enhancing computational modeling of fluid flows. In contrast, ML applications in numerical plasma physics research remain relatively limited in scope and extent. Despite this, the close relationship between fluid mechanics and plasma physics presents a valuable opportunity to create a roadmap for transferring ML advances in fluid flow modeling to computational plasma physics. This Perspective aims to outline such a roadmap. We begin by discussing some general fundamental aspects of ML, including the various categories of ML algorithms and the different types of problems that can be solved with the help of ML. With regard to each problem type, we then present specific examples from the use of ML in computational fluid dynamics, reviewing several insightful prior efforts. We also review recent ML applications in plasma physics for each problem type. The paper discusses promising future directions and development pathways for ML in plasma modelling within the different application areas. Additionally, we point out prominent challenges that must be addressed to realize ML's full potential in computational plasma physics, including the need for cost-effective high-fidelity simulation tools for extensive data generation.",
        "subjects": [
            "physics.plasm-ph",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": "42 pages, 20 figures"
    },
    {
        "paper id": "2409.02425",
        "abstract url": "https://arxiv.org/abs/2409.02425",
        "title": "Deep Adaptive Interest Network: Personalized Recommendation with Context-Aware Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In personalized recommendation systems, accurately capturing users' evolving interests and combining them with contextual information is a critical research area. This paper proposes a novel model called the Deep Adaptive Interest Network (DAIN), which dynamically models users' interests while incorporating context-aware learning mechanisms to achieve precise and adaptive personalized recommendations. DAIN leverages deep learning techniques to build an adaptive interest network structure that can capture users' interest changes in real-time while further optimizing recommendation results by integrating contextual information. Experiments conducted on several public datasets demonstrate that DAIN excels in both recommendation performance and computational efficiency. This research not only provides a new solution for personalized recommendation systems but also offers fresh insights into the application of context-aware learning in recommendation systems.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01628",
        "abstract url": "https://arxiv.org/abs/2409.01628",
        "title": "CTG-KrEW: Generating Synthetic Structured Contextually Correlated Content by Conditional Tabular GAN with K-Means Clustering and Efficient Word Embedding",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Tabular"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Conditional Tabular Generative Adversarial Networks (CTGAN) and their various derivatives are attractive for their ability to efficiently and flexibly create synthetic tabular data, showcasing strong performance and adaptability. However, there are certain critical limitations to such models. The first is their inability to preserve the semantic integrity of contextually correlated words or phrases. For instance, skillset in freelancer profiles is one such attribute where individual skills are semantically interconnected and indicative of specific domain interests or qualifications. The second challenge of traditional approaches is that, when applied to generate contextually correlated tabular content, besides generating semantically shallow content, they consume huge memory resources and CPU time during the training stage. To address these problems, we introduce a novel framework, CTGKrEW (Conditional Tabular GAN with KMeans Clustering and Word Embedding), which is adept at generating realistic synthetic tabular data where attributes are collections of semantically and contextually coherent words. CTGKrEW is trained and evaluated using a dataset from Upwork, a realworld freelancing platform. Comprehensive experiments were conducted to analyze the variability, contextual similarity, frequency distribution, and associativity of the generated data, along with testing the framework's system feasibility. CTGKrEW also takes around 99\\% less CPU time and 33\\% less memory footprints than the conventional approach. Furthermore, we developed KrEW, a web application to facilitate the generation of realistic data containing skill-related information. This application, available at https://riyasamanta.github.io/krew.html, is freely accessible to both the general public and the research community.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01648",
        "abstract url": "https://arxiv.org/abs/2409.01648",
        "title": "Computing Range Consistent Answers to Aggregation Queries via Rewriting",
        "rating": "-2",
        "keywords": [
            [
                "SQL"
            ]
        ],
        "abstract": "We consider the problem of answering conjunctive queries with aggregation on database instances that may violate primary key constraints. In SQL, these queries follow the SELECT-FROM-WHERE-GROUP BY format, where the WHERE-clause involves a conjunction of equalities, and the SELECT-clause can incorporate aggregate operators like MAX, MIN, SUM, AVG, or COUNT. Repairs of a database instance are defined as inclusion-maximal subsets that satisfy all primary keys. For a given query, our primary objective is to identify repairs that yield the lowest aggregated value among all possible repairs. We particularly investigate queries for which this lowest aggregated value can be determined through a rewriting in first-order logic with aggregate operators.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01701",
        "abstract url": "https://arxiv.org/abs/2409.01701",
        "title": "Low Layer Functional Split Management in 5G and Beyond: Architecture and Self-adaptation",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Radio Access Network (RAN) disaggregation is emerging as a key trend in beyond 5G, as it offers new opportunities for more flexible deployments and intelligent network management. A relevant problem in disaggregated RAN is the functional split selection, which dynamically decides which baseband (BB) functions of a base station are kept close to the radio units and which ones are centralized. In this context, this paper firstly presents an architectural framework for supporting this concept relying on the O-RAN architecture. Then, the paper analyzes how the functional split can be optimized to adapt to the different load conditions while minimizing energy costs.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": "2024 19th International Symposium on Wireless Communication Systems (ISWCS)"
    },
    {
        "paper id": "2409.01707",
        "abstract url": "https://arxiv.org/abs/2409.01707",
        "title": "Quantum Byzantine Agreement Against Full-information Adversary",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We exhibit that, when given a classical Byzantine agreement protocol designed in the private-channel model, it is feasible to construct a quantum agreement protocol that can effectively handle a full-information adversary. Notably, both protocols have equivalent levels of resilience, round complexity, and communication complexity. In the classical private-channel scenario, participating players are limited to exchanging classical bits, with the adversary lacking knowledge of the exchanged messages. In contrast, in the quantum full-information setting, participating players can exchange qubits, while the adversary possesses comprehensive and accurate visibility into the system's state and messages. By showcasing the reduction from quantum to classical frameworks, this paper demonstrates the strength and flexibility of quantum protocols in addressing security challenges posed by adversaries with increased visibility. It underscores the potential of leveraging quantum principles to improve security measures without compromising on efficiency or resilience. By applying our reduction, we demonstrate quantum advantages in the round complexity of asynchronous Byzantine agreement protocols in the full-information model. It is well known that in the full-information model, any classical protocol requires $\u03a9(n)$ rounds to solve Byzantine agreement with probability one even against Fail-stop adversary when resilience $t=\u0398(n)$. We show that quantum protocols can achieve $O(1)$ rounds (i) with resilience $t<n/2$ against a Fail-stop adversary, and (ii) with resilience $t<n/(3+\u03b5)$ against a Byzantine adversary for any constant $\u03b5>0$, therefore surpassing the classical lower bound.",
        "subjects": [
            "quant-ph",
            "cs.DC"
        ],
        "comment": "26 pages. This is the extended version of the paper presented at DISC2024. It includes extra results in Appendix D that were not included in the conference submission due to page constraints"
    },
    {
        "paper id": "2409.01722",
        "abstract url": "https://arxiv.org/abs/2409.01722",
        "title": "ACCESS-FL: Agile Communication and Computation for Efficient Secure Aggregation in Stable Federated Learning Networks",
        "rating": "-2",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "Federated Learning (FL) is a promising distributed learning framework designed for privacy-aware applications. FL trains models on client devices without sharing the client's data and generates a global model on a server by aggregating model updates. Traditional FL approaches risk exposing sensitive client data when plain model updates are transmitted to the server, making them vulnerable to security threats such as model inversion attacks where the server can infer the client's original training data from monitoring the changes of the trained model in different rounds. Google's Secure Aggregation (SecAgg) protocol addresses this threat by employing a double-masking technique, secret sharing, and cryptography computations in honest-but-curious and adversarial scenarios with client dropouts. However, in scenarios without the presence of an active adversary, the computational and communication cost of SecAgg significantly increases by growing the number of clients. To address this issue, in this paper, we propose ACCESS-FL, a communication-and-computation-efficient secure aggregation method designed for honest-but-curious scenarios in stable FL networks with a limited rate of client dropout. ACCESS-FL reduces the computation/communication cost to a constant level (independent of the network size) by generating shared secrets between only two clients and eliminating the need for double masking, secret sharing, and cryptography computations. To evaluate the performance of ACCESS-FL, we conduct experiments using the MNIST, FMNIST, and CIFAR datasets to verify the performance of our proposed method. The evaluation results demonstrate that our proposed method significantly reduces computation and communication overhead compared to state-of-the-art methods, SecAgg and SecAgg+.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01725",
        "abstract url": "https://arxiv.org/abs/2409.01725",
        "title": "4D-CAT: Synthesis of 4D Coronary Artery Trees from Systole and Diastole",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "medical",
                "diagnosis",
                "CT",
                "cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The three-dimensional vascular model reconstructed from CT images is widely used in medical diagnosis. At different phases, the beating of the heart can cause deformation of vessels, resulting in different vascular imaging states and false positive diagnostic results. The 4D model can simulate a complete cardiac cycle. Due to the dose limitation of contrast agent injection in patients, it is valuable to synthesize a 4D coronary artery trees through finite phases imaging. In this paper, we propose a method for generating a 4D coronary artery trees, which maps the systole to the diastole through deformation field prediction, interpolates on the timeline, and the motion trajectory of points are obtained. Specifically, the centerline is used to represent vessels and to infer deformation fields using cube-based sorting and neural networks. Adjacent vessel points are aggregated and interpolated based on the deformation field of the centerline point to obtain displacement vectors of different phases. Finally, the proposed method is validated through experiments to achieve the registration of non-rigid vascular points and the generation of 4D coronary trees.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01764",
        "abstract url": "https://arxiv.org/abs/2409.01764",
        "title": "Gradient events: improved acquisition of visual information in event cameras",
        "rating": "-2",
        "keywords": [
            [
                "event cameras"
            ],
            [
                "bio-inspired"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The current event cameras are bio-inspired sensors that respond to brightness changes in the scene asynchronously and independently for every pixel, and transmit these changes as ternary event streams. Event cameras have several benefits over conventional digital cameras, such as significantly higher temporal resolution and pixel bandwidth resulting in reduced motion blur, and very high dynamic range. However, they also introduce challenges such as the difficulty of applying existing computer vision algorithms to the output event streams, and the flood of uninformative events in the presence of oscillating light sources. Here we propose a new type of event, the gradient event, which benefits from the same properties as a conventional brightness event, but which is by design much less sensitive to oscillating light sources, and which enables considerably better grayscale frame reconstruction. We show that the gradient event -based video reconstruction outperforms existing state-of-the-art brightness event -based methods by a significant margin, when evaluated on publicly available event-to-video datasets. Our results show how gradient information can be used to significantly improve the acquisition of visual information by an event camera.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 6 figures. This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement no 101016734"
    },
    {
        "paper id": "2409.01855",
        "abstract url": "https://arxiv.org/abs/2409.01855",
        "title": "Graph-based Modeling and Simulation of Emergency Services Communication Systems",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "attack"
            ]
        ],
        "abstract": "Emergency Services Communication Systems (ESCS) are evolving into Internet Protocol based communication networks, promising enhancements to their function, availability, and resilience. This increase in complexity and cyber-attack surface demands better understanding of these systems' breakdown dynamics under extreme circumstances. Existing ESCS research largely overlooks simulation and the little work that exists focuses primarily on cybersecurity threats and neglects critical factors such as non-stationarity of call arrivals. This paper introduces a robust, adaptable graph-based simulation framework and essential mathematical models for ESCS simulation. The framework uses a representation of ESCSes where each vertex is a communicating finite-state machine that exchanges messages along edges and whose behavior is governed by a discrete event queuing model. Call arrival burstiness and its connection to emergency incidents is modeled through a cluster point process. Model applicability is demonstrated through simulations of the Seattle Police Department ESCS. Ongoing work is developing GPU implementation and exploring use in cybersecurity tabletop exercises.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2409.01867",
        "abstract url": "https://arxiv.org/abs/2409.01867",
        "title": "ASD-Chat: An Innovative Dialogue Intervention System for Children with Autism based on LLM and VB-MAPP",
        "rating": "-2",
        "keywords": [
            [
                "medical",
                "healthcare",
                "diagnosis",
                "clinical"
            ]
        ],
        "abstract": "Early diagnosis and professional intervention can help children with autism spectrum disorder (ASD) return to normal life. However, the scarcity and imbalance of professional medical resources currently prevent many autistic children from receiving the necessary diagnosis and intervention. Therefore, numerous paradigms have been proposed that use computer technology to assist or independently conduct ASD interventions, with the aim of alleviating the aforementioned problem. However, these paradigms often lack a foundation in clinical intervention methods and suffer from a lack of personalization. Addressing these concerns, we propose ASD-Chat, a social intervention system based on VB-MAPP (Verbal Behavior Milestones Assessment and Placement Program) and powered by ChatGPT as the backbone for dialogue generation. Specifically, we designed intervention paradigms and prompts based on the clinical intervention method VB-MAPP and utilized ChatGPT's generative capabilities to facilitate social dialogue interventions. Experimental results demonstrate that our proposed system achieves competitive intervention effects to those of professional interventionists, making it a promising tool for long-term interventions in real healthcare scenario in the future.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01885",
        "abstract url": "https://arxiv.org/abs/2409.01885",
        "title": "Activity-Guided Industrial Anomalous Sound Detection against Interferences",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "Industrial"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We address a practical scenario of anomaly detection for industrial sound data, where the sound of a target machine is corrupted by background noise and interference from neighboring machines. Overcoming this challenge is difficult since the interference is often virtually indistinguishable from the target machine without additional information. To address the issue, we propose SSAD, a framework of source separation (SS) followed by anomaly detection (AD), which leverages machine activity information, often readily available in practical settings. SSAD consists of two components: (i) activity-informed SS, enabling effective source separation even given interference with similar timbre, and (ii) two-step masking, robustifying anomaly detection by emphasizing anomalies aligned with the machine activity. Our experiments demonstrate that SSAD achieves comparable accuracy to a baseline with full access to clean signals, while SSAD is provided only a corrupted signal and activity information. In addition, thanks to the activity-informed SS and AD with the two-step masking, SSAD outperforms standard approaches, particularly in cases with interference. It highlights the practical efficacy of SSAD in addressing the complexities of anomaly detection in industrial sound data.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Thsis is an extended version of https://ieeexplore.ieee.org/document/10095113"
    },
    {
        "paper id": "2409.01896",
        "abstract url": "https://arxiv.org/abs/2409.01896",
        "title": "Mixed Regular and Impulsive Sampled-data LQR",
        "rating": "-2",
        "keywords": [
            [
                "MRI"
            ]
        ],
        "abstract": "We investigate the benefits of combining regular and impulsive inputs for the control of sampled-data linear time-invariant systems. We first observe that adding an impulsive term to a regular, zero-order-hold controller may help enlarging the set of sampling periods under which controllability is preserved by sampling. In this context, we provide a tailored Hautus-like necessary and sufficient condition under which controllability of the mixed regular, impulsive (MRI) sampled-data model is preserved. We then focus on LQR optimal control. After having presented the optimal controllers for the sampled-data LQR control in the MRI setting, we consider the scenario where an impulsive disturbance affects the dynamics and is known ahead of time. The solution to the so-called preview LQR is presented exploiting both regular and impulsive input components. Numerical examples, that include an insulin infusion benchmark, illustrate that leveraging both future disturbance information and MRI controls may lead to significant performance improvements.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01901",
        "abstract url": "https://arxiv.org/abs/2409.01901",
        "title": "3D-LEX v1.0: 3D Lexicons for American Sign Language and Sign Language of the Netherlands",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Sign Language",
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "In this work, we present an efficient approach for capturing sign language in 3D, introduce the 3D-LEX v1.0 dataset, and detail a method for semi-automatic annotation of phonetic properties. Our procedure integrates three motion capture techniques encompassing high-resolution 3D poses, 3D handshapes, and depth-aware facial features, and attains an average sampling rate of one sign every 10 seconds. This includes the time for presenting a sign example, performing and recording the sign, and archiving the capture. The 3D-LEX dataset includes 1,000 signs from American Sign Language and an additional 1,000 signs from the Sign Language of the Netherlands. We showcase the dataset utility by presenting a simple method for generating handshape annotations directly from 3D-LEX. We produce handshape labels for 1,000 signs from American Sign Language and evaluate the labels in a sign recognition task. The labels enhance gloss recognition accuracy by 5% over using no handshape annotations, and by 1% over expert annotations. Our motion capture data supports in-depth analysis of sign features and facilitates the generation of 2D projections from any viewpoint. The 3D-LEX collection has been aligned with existing sign language benchmarks and linguistic resources, to support studies in 3D-aware sign language processing.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01915",
        "abstract url": "https://arxiv.org/abs/2409.01915",
        "title": "Integration of Augmented Reality and Mobile Robot Indoor SLAM for Enhanced Spatial Awareness",
        "rating": "-2",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "This research explores the integration of indoor Simultaneous Localization and Mapping (SLAM) with Augmented Reality (AR) to enhance situational awareness, improving safety in hazardous or emergency situations. The main contribution of this work is to enable mobile robots to provide real-time spatial perception to users who are not co-located with the robot. This is a comprehensive approach, including selecting suitable sensors for indoor SLAM, designing and building a platform, developing methods to display maps on AR devices, implementing this into software on an AR device, and improving the robustness of communication and localization between the robot and AR device in real-world testing. By taking this approach and analyzing each component of the integrated system, this paper highlights numerous areas for future research that can further advance the integration of SLAM and AR technologies. These advancements aim to significantly improve safety and efficiency during rescue operations.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2409.01957",
        "abstract url": "https://arxiv.org/abs/2409.01957",
        "title": "Power Control and Random Serving Mode Allocation for CJT-NCJT Hybrid Mode Enabled Cell-Free Massive MIMO With Limited Fronthauls",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "With a great potential of improving the service fairness and quality for user equipments (UEs), cell-free massive multiple-input multiple-output (mMIMO) has been regarded as an emerging candidate for 6G network architectures. Under ideal assumptions, the coherent joint transmission (CJT) serving mode has been considered as an optimal option for cell-free mMIMO systems, since it can achieve coherent cooperation gain among the access points. However, when considering the limited fronthaul constraint in practice, the non-coherent joint transmission (NCJT) serving mode is likely to outperform CJT, since the former requires much lower fronthaul resources. In other words, the performance excellence and worseness of single serving mode (CJT or NCJT) depends on the fronthaul capacity, and any single transmission mode cannot perfectly adapt the capacity limited fronthaul. To explore the performance potential of the cell-free mMIMO system with limited fronthauls by harnessing the merits of CJT and NCJT, we propose a CJT-NCJT hybrid serving mode framework, in which UEs are allocated to operate on CJT or NCJT serving mode. To improve the sum-rate of the system with low complexity, we first propose a probability-based random serving mode allocation scheme. With a given serving mode, a successive convex approximation-based power allocation algorithm is proposed to maximize the system's sum-rate. Simulation results demonstrate the superiority of the proposed scheme.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 2 figures, accepted by GLOBECOM 2024"
    },
    {
        "paper id": "2409.01969",
        "abstract url": "https://arxiv.org/abs/2409.01969",
        "title": "Connectivity structure and dynamics of nonlinear recurrent neural networks",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "We develop a theory to analyze how structure in connectivity shapes the high-dimensional, internally generated activity of nonlinear recurrent neural networks. Using two complementary methods -- a path-integral calculation of fluctuations around the saddle point, and a recently introduced two-site cavity approach -- we derive analytic expressions that characterize important features of collective activity, including its dimensionality and temporal correlations. To model structure in the coupling matrices of real neural circuits, such as synaptic connectomes obtained through electron microscopy, we introduce the random-mode model, which parameterizes a coupling matrix using random input and output modes and a specified spectrum. This model enables systematic study of the effects of low-dimensional structure in connectivity on neural activity. These effects manifest in features of collective activity, that we calculate, and can be undetectable when analyzing only single-neuron activities. We derive a relation between the effective rank of the coupling matrix and the dimension of activity. By extending the random-mode model, we compare the effects of single-neuron heterogeneity and low-dimensional connectivity. We also investigate the impact of structured overlaps between input and output modes, a feature of biological coupling matrices. Our theory provides tools to relate neural-network architecture and collective dynamics in artificial and biological systems.",
        "subjects": [
            "q-bio.NC",
            "cond-mat.dis-nn",
            "cs.NE"
        ],
        "comment": "35 pages, 11 figures"
    },
    {
        "paper id": "2409.02010",
        "abstract url": "https://arxiv.org/abs/2409.02010",
        "title": "Ternary Tree Fermion-to-Qubit Mapping with Hamiltonian Aware Optimization",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "This paper introduces the Hamiltonian-Aware Ternary Tree (HATT) framework to compile optimized Fermion-to-qubit mapping for specific Fermionic Hamiltonians. In the simulation of Fermionic quantum systems, efficient Fermion-to-qubit mapping plays a critical role in transforming the Fermionic system into a qubit system. HATT utilizes ternary tree mapping and a bottom-up construction procedure to generate Hamiltonian aware Fermion-to-qubit mapping to reduce the Pauli weight of the qubit Hamiltonian, resulting in lower quantum simulation circuit overhead. Additionally, our optimizations retain the important vacuum state preservation property in our Fermion-to-qubit mapping and reduce the complexity of our algorithm from $O(N^4)$ to $O(N^3)$. Evaluations and simulations of various Fermionic systems demonstrate a significant reduction in both Pauli weight and circuit complexity, alongside excellent scalability to larger systems. Experiments on the Ionq quantum computer also show the advantages of our approach in noise resistance in quantum simulations.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02044",
        "abstract url": "https://arxiv.org/abs/2409.02044",
        "title": "FedMinds: Privacy-Preserving Personalized Brain Visual Decoding",
        "rating": "-2",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "fMRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Exploring the mysteries of the human brain is a long-term research topic in neuroscience. With the help of deep learning, decoding visual information from human brain activity fMRI has achieved promising performance. However, these decoding models require centralized storage of fMRI data to conduct training, leading to potential privacy security issues. In this paper, we focus on privacy preservation in multi-individual brain visual decoding. To this end, we introduce a novel framework called FedMinds, which utilizes federated learning to protect individuals' privacy during model training. In addition, we deploy individual adapters for each subject, thus allowing personalized visual decoding. We conduct experiments on the authoritative NSD datasets to evaluate the performance of the proposed framework. The results demonstrate that our framework achieves high-precision visual decoding along with privacy protection.",
        "subjects": [
            "q-bio.NC",
            "cs.CV",
            "cs.DC",
            "eess.IV"
        ],
        "comment": "5 pages, Accepted by JCRAI 2024"
    },
    {
        "paper id": "2409.02045",
        "abstract url": "https://arxiv.org/abs/2409.02045",
        "title": "AllWeatherNet:Unified Image enhancement for autonomous driving under adverse weather and lowlight-conditions",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "Image enhancement"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Adverse conditions like snow, rain, nighttime, and fog, pose challenges for autonomous driving perception systems. Existing methods have limited effectiveness in improving essential computer vision tasks, such as semantic segmentation, and often focus on only one specific condition, such as removing rain or translating nighttime images into daytime ones. To address these limitations, we propose a method to improve the visual quality and clarity degraded by such adverse conditions. Our method, AllWeather-Net, utilizes a novel hierarchical architecture to enhance images across all adverse conditions. This architecture incorporates information at three semantic levels: scene, object, and texture, by discriminating patches at each level. Furthermore, we introduce a Scaled Illumination-aware Attention Mechanism (SIAM) that guides the learning towards road elements critical for autonomous driving perception. SIAM exhibits robustness, remaining unaffected by changes in weather conditions or environmental scenes. AllWeather-Net effectively transforms images into normal weather and daytime scenes, demonstrating superior image enhancement results and subsequently enhancing the performance of semantic segmentation, with up to a 5.3% improvement in mIoU in the trained domain. We also show our model's generalization ability by applying it to unseen domains without re-training, achieving up to 3.9% mIoU improvement. Code can be accessed at: https://github.com/Jumponthemoon/AllWeatherNet.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02048",
        "abstract url": "https://arxiv.org/abs/2409.02048",
        "title": "ViewCrafter: Taming Video Diffusion Models for High-fidelity Novel View Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite recent advancements in neural 3D reconstruction, the dependence on dense multi-view captures restricts their broader applicability. In this work, we propose \\textbf{ViewCrafter}, a novel method for synthesizing high-fidelity novel views of generic scenes from single or sparse images with the prior of video diffusion model. Our method takes advantage of the powerful generation capabilities of video diffusion model and the coarse 3D clues offered by point-based representation to generate high-quality video frames with precise camera pose control. To further enlarge the generation range of novel views, we tailored an iterative view synthesis strategy together with a camera trajectory planning algorithm to progressively extend the 3D clues and the areas covered by the novel views. With ViewCrafter, we can facilitate various applications, such as immersive experiences with real-time rendering by efficiently optimizing a 3D-GS representation using the reconstructed 3D points and the generated novel views, and scene-level text-to-3D generation for more imaginative content creation. Extensive experiments on diverse datasets demonstrate the strong generalization capability and superior performance of our method in synthesizing high-fidelity and consistent novel views.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://drexubery.github.io/ViewCrafter/"
    },
    {
        "paper id": "2409.02055",
        "abstract url": "https://arxiv.org/abs/2409.02055",
        "title": "Wireless Mobile Distributed-MIMO for 6G",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "The paper proposes a new architecture for Distributed MIMO (D-MIMO) in which the base station (BS) jointly transmits with wireless mobile nodes to serve users (UEs) within a cell for 6G communication systems. The novelty of the architecture lies in the wireless mobile nodes participating in joint D-MIMO transmission with the BS (referred to as D-MIMO nodes), which are themselves users on the network. The D-MIMO nodes establish wireless connections with the BS, are generally near the BS, and ideally benefit from higher SNR links and better connections with edge-located UEs. These D-MIMO nodes can be existing handset UEs, Unmanned Aerial Vehicles (UAVs), or Vehicular UEs. Since the D-MIMO nodes are users sharing the access channel, the proposed architecture operates in two phases. First, the BS communicates with the D-MIMO nodes to forward data for the joint transmission, and then the BS and D-MIMO nodes jointly serve the UEs through coherent D-MIMO operation. Capacity analysis of this architecture is studied based on realistic 3GPP channel models, and the paper demonstrates that despite the two-phase operation, the proposed architecture enhances the system's capacity compared to the baseline where the BS communicates directly with the UEs.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02155",
        "abstract url": "https://arxiv.org/abs/2409.02155",
        "title": "Target Detection in Sea Clutter with Application to Spaceborne SAR Imaging",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "In this paper, the challenging task of target detection in sea clutter is addressed. We analyze the statistical properties of the signals which have been received from the scene and based on that, we model the amplitude of the signals that have been reflected from the sea clutter according to several well-known probability distributions. Next, by exploiting the Kullback-Leibler (KL) divergence metric as a goodness-of-fit test, we will demonstrate that among the proposed probability distributions, the Weibull distribution can model the statistical properties of the sea clutter with higher accuracy. Subsequently, we utilize the aforementioned information to design an adaptive threshold based on the Constant False Alarm Rate (CFAR) algorithm to detect the energy of the targets which have been buried in the sea clutter. Thorough analysis of the experimental data gathered from the Canadian RADARSAT-1 satellite demonstrates the overall effectiveness of the proposed method.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2008.07457"
    },
    {
        "paper id": "2409.02193",
        "abstract url": "https://arxiv.org/abs/2409.02193",
        "title": "Effective Distance of Higher Dimensional HGPs and Weight-Reduced Quantum LDPC Codes",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum error correction plays a prominent role in the realization of quantum computation, and quantum low-density parity-check (qLDPC) codes are believed to be practically useful stabilizer codes. While qLDPC codes are defined to have constant weight parity-checks, the weight of these parity checks could be large constants that make implementing these codes challenging. Large constants can also result in long syndrome extraction times and bad error propagation that can impact error correction performance. Hastings recently introduced weight reduction techniques for qLDPC codes that reduce the weight of the parity checks as well as the maximum number of checks that acts on any data qubit. However, the fault tolerance of these techniques remains an open question. In this paper, we analyze the effective distance of the weight-reduced code when single-ancilla syndrome extraction circuits are considered for error correction. We prove that there exists single-ancilla syndrome extraction circuits that largely preserve the effective distance of the weight-reduced qLDPC codes. In addition, we also show that the distance balancing technique introduced by Evra et al. preserves effective distance. As a corollary, our result shows that higher-dimensional hypergraph product (HGP) codes, also known as homological product codes corresponding to the product of 1-complexes, have no troublesome hook errors when using any single-ancilla syndrome extraction circuit.",
        "subjects": [
            "quant-ph",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02212",
        "abstract url": "https://arxiv.org/abs/2409.02212",
        "title": "LSTM-QGAN: Scalable NISQ Generative Adversarial Network",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Current quantum generative adversarial networks (QGANs) still struggle with practical-sized data. First, many QGANs use principal component analysis (PCA) for dimension reduction, which, as our studies reveal, can diminish the QGAN's effectiveness. Second, methods that segment inputs into smaller patches processed by multiple generators face scalability issues. In this work, we propose LSTM-QGAN, a QGAN architecture that eliminates PCA preprocessing and integrates quantum long short-term memory (QLSTM) to ensure scalable performance. Our experiments show that LSTM-QGAN significantly enhances both performance and scalability over state-of-the-art QGAN models, with visual data improvements, reduced Frechet Inception Distance scores, and reductions of 5x in qubit counts, 5x in single-qubit gates, and 12x in two-qubit gates.",
        "subjects": [
            "quant-ph",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02218",
        "abstract url": "https://arxiv.org/abs/2409.02218",
        "title": "Early Design Exploration of Aerospace Systems Using Assume-Guarantee Contracts",
        "rating": "-2",
        "keywords": [
            [
                "thermal"
            ]
        ],
        "abstract": "We present a compositional approach to early modeling and analysis of complex aerospace systems based on assume-guarantee contracts. Components in a system are abstracted into assume-guarantee specifications. Performing algebraic contract operations with Pacti allows us to relate local component specifications to that of the system. Applications to two aerospace case studies (the design of spacecraft to satisfy a rendezvous mission and the design of the thermal management system of a prototypical aircraft) show that this methodology provides engineers with an agile, early analysis and exploration process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "32 pages"
    },
    {
        "paper id": "2409.02247",
        "abstract url": "https://arxiv.org/abs/2409.02247",
        "title": "Personalized and uncertainty-aware coronary hemodynamics simulations: From Bayesian estimation to improved multi-fidelity uncertainty quantification",
        "rating": "-2",
        "keywords": [
            [
                "biomechanical",
                "CT",
                "disease",
                "clinical",
                "cardiac"
            ]
        ],
        "abstract": "Simulations of coronary hemodynamics have improved non-invasive clinical risk stratification and treatment outcomes for coronary artery disease, compared to relying on anatomical imaging alone. However, simulations typically use empirical approaches to distribute total coronary flow amongst the arteries in the coronary tree. This ignores patient variability, the presence of disease, and other clinical factors. Further, uncertainty in the clinical data often remains unaccounted for in the modeling pipeline. We present an end-to-end uncertainty-aware pipeline to (1) personalize coronary flow simulations by incorporating branch-specific coronary flows as well as cardiac function; and (2) predict clinical and biomechanical quantities of interest with improved precision, while accounting for uncertainty in the clinical data. We assimilate patient-specific measurements of myocardial blood flow from CT myocardial perfusion imaging to estimate branch-specific coronary flows. We use adaptive Markov Chain Monte Carlo sampling to estimate the joint posterior distributions of model parameters with simulated noise in the clinical data. Additionally, we determine the posterior predictive distribution for relevant quantities of interest using a new approach combining multi-fidelity Monte Carlo estimation with non-linear, data-driven dimensionality reduction. Our framework recapitulates clinically measured cardiac function as well as branch-specific coronary flows under measurement uncertainty. We substantially shrink the confidence intervals for estimated quantities of interest compared to single-fidelity and state-of-the-art multi-fidelity Monte Carlo methods. This is especially true for quantities that showed limited correlation between the low- and high-fidelity model predictions. Moreover, the proposed estimators are significantly cheaper to compute for a specified confidence level or variance.",
        "subjects": [
            "physics.flu-dyn",
            "cs.CE",
            "math.ST",
            "physics.comp-ph",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02262",
        "abstract url": "https://arxiv.org/abs/2409.02262",
        "title": "Thermal Inverse design for resistive micro-heaters",
        "rating": "-2",
        "keywords": [
            [
                "Thermal"
            ]
        ],
        "abstract": "This paper proposes an inverse design scheme for resistive heaters. By adjusting the spatial distribution of a binary electrical resistivity map, the scheme enables objective-driven optimization of heaters to achieve pre-defined steady-state temperature profiles. The approach can be fully automated and is computationally efficient since it does not entail extensive iterative simulations of the entire heater structure. The design scheme offers a powerful solution for resistive heater device engineering in applications spanning electronics, photonics, and microelectromechanical systems.",
        "subjects": [
            "physics.app-ph",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02309",
        "abstract url": "https://arxiv.org/abs/2409.02309",
        "title": "QID$^2$: An Image-Conditioned Diffusion Model for Q-space Up-sampling of DWI Data",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "GAN"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We propose an image-conditioned diffusion model to estimate high angular resolution diffusion weighted imaging (DWI) from a low angular resolution acquisition. Our model, which we call QID$^2$, takes as input a set of low angular resolution DWI data and uses this information to estimate the DWI data associated with a target gradient direction. We leverage a U-Net architecture with cross-attention to preserve the positional information of the reference images, further guiding the target image generation. We train and evaluate QID$^2$ on single-shell DWI samples curated from the Human Connectome Project (HCP) dataset. Specifically, we sub-sample the HCP gradient directions to produce low angular resolution DWI data and train QID$^2$ to reconstruct the missing high angular resolution samples. We compare QID$^2$ with two state-of-the-art GAN models. Our results demonstrate that QID$^2$ not only achieves higher-quality generated images, but it consistently outperforms the GAN models in downstream tensor estimation across multiple metrics. Taken together, this study highlights the potential of diffusion models, and QID$^2$ in particular, for q-space up-sampling, thus offering a promising toolkit for clinical and research applications.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted at MICCAI 2024 International Workshop on Computational Diffusion MRI. Zijian Chen and Jueqi Wang contributed equally to this work"
    },
    {
        "paper id": "2409.02345",
        "abstract url": "https://arxiv.org/abs/2409.02345",
        "title": "Combined Plant and Control Co-design via Solutions of Hamilton-Jacobi-Bellman Equation Based on Physics-informed Learning",
        "rating": "-2",
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "This paper addresses integrated design of engineering systems, where physical structure of the plant and controller design are optimized simultaneously. To cope with uncertainties due to noises acting on the dynamics and modeling errors, an Uncertain Control Co-design (UCCD) problem formulation is proposed. Existing UCCD methods usually rely on uncertainty propagation analyses using Monte Calro methods for open-loop solutions of optimal control, which suffer from stringent trade-offs among accuracy, time horizon, and computational time. The proposed method utilizes closed-loop solutions characterized by the Hamilton-Jacobi-Bellman equation, a Partial Differential Equation (PDE) defined on the state space. A solution algorithm for the proposed UCCD formulation is developed based on PDE solutions of Physics-informed Neural Networks (PINNs). Numerical examples of regulator design problems are provided, and it is shown that simultaneous update of PINN weights and the design parameters effectively works for solving UCCD problems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02382",
        "abstract url": "https://arxiv.org/abs/2409.02382",
        "title": "GGS: Generalizable Gaussian Splatting for Lane Switching in Autonomous Driving",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "depth"
            ],
            [
                "diffusion"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose GGS, a Generalizable Gaussian Splatting method for Autonomous Driving which can achieve realistic rendering under large viewpoint changes. Previous generalizable 3D gaussian splatting methods are limited to rendering novel views that are very close to the original pair of images, which cannot handle large differences in viewpoint. Especially in autonomous driving scenarios, images are typically collected from a single lane. The limited training perspective makes rendering images of a different lane very challenging. To further improve the rendering capability of GGS under large viewpoint changes, we introduces a novel virtual lane generation module into GSS method to enables high-quality lane switching even without a multi-lane dataset. Besides, we design a diffusion loss to supervise the generation of virtual lane image to further address the problem of lack of data in the virtual lanes. Finally, we also propose a depth refinement module to optimize depth estimation in the GSS model. Extensive validation of our method, compared to existing approaches, demonstrates state-of-the-art performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02732",
        "abstract url": "https://arxiv.org/abs/2409.02732",
        "title": "Approximating mutual information of high-dimensional variables using learned representations",
        "rating": "-2",
        "keywords": [
            [
                "biology"
            ]
        ],
        "abstract": "Mutual information (MI) is a general measure of statistical dependence with widespread application across the sciences. However, estimating MI between multi-dimensional variables is challenging because the number of samples necessary to converge to an accurate estimate scales unfavorably with dimensionality. In practice, existing techniques can reliably estimate MI in up to tens of dimensions, but fail in higher dimensions, where sufficient sample sizes are infeasible. Here, we explore the idea that underlying low-dimensional structure in high-dimensional data can be exploited to faithfully approximate MI in high-dimensional settings with realistic sample sizes. We develop a method that we call latent MI (LMI) approximation, which applies a nonparametric MI estimator to low-dimensional representations learned by a simple, theoretically-motivated model architecture. Using several benchmarks, we show that unlike existing techniques, LMI can approximate MI well for variables with $> 10^3$ dimensions if their dependence structure has low intrinsic dimensionality. Finally, we showcase LMI on two open problems in biology. First, we approximate MI between protein language model (pLM) representations of interacting proteins, and find that pLMs encode non-trivial information about protein-protein interactions. Second, we quantify cell fate information contained in single-cell RNA-seq (scRNA-seq) measurements of hematopoietic stem cells, and find a sharp transition during neutrophil differentiation when fate information captured by scRNA-seq increases dramatically.",
        "subjects": [
            "q-bio.QM",
            "cs.IT",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02961",
        "abstract url": "https://arxiv.org/abs/2409.02961",
        "title": "Enhancing Alzheimer's Disease Prediction: A Novel Approach to Leveraging GAN-Augmented Data for Improved CNN Model Accuracy",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "diagnosis",
                "MRI",
                "Disease",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Alzheimer's Disease (AD) is a neurodegenerative disease affecting millions of individuals across the globe. As the prevalence of this disease continues to rise, early diagnosis is crucial to improve clinical outcomes. Neural networks, specifically Convolutional Neural Networks (CNNs), are promising tools for diagnosing individuals with Alzheimer's. However, neural networks such as ANNs and CNNs typically yield lower validation accuracies when fed lower quantities of data. Hence, Generative Adversarial Networks (GANs) can be utilized to synthesize data to augment these existing MRI datasets, potentially yielding higher validation accuracies. In this study, we use this principle while examining a novel application of the SSMI metric in selecting high-quality synthetic data generated by our GAN to compare its accuracies with shuffled data generated by our GAN. We observed that incorporating GANs with an SSMI metric returned the highest accuracies when compared to a traditional dataset.",
        "subjects": [
            "eess.IV",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03501",
        "abstract url": "https://arxiv.org/abs/2409.03501",
        "title": "Towards Data-Centric Face Anti-Spoofing: Improving Cross-domain Generalization via Physics-based Data Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "Attack"
            ],
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Face Anti-Spoofing (FAS) research is challenged by the cross-domain problem, where there is a domain gap between the training and testing data. While recent FAS works are mainly model-centric, focusing on developing domain generalization algorithms for improving cross-domain performance, data-centric research for face anti-spoofing, improving generalization from data quality and quantity, is largely ignored. Therefore, our work starts with data-centric FAS by conducting a comprehensive investigation from the data perspective for improving cross-domain generalization of FAS models. More specifically, at first, based on physical procedures of capturing and recapturing, we propose task-specific FAS data augmentation (FAS-Aug), which increases data diversity by synthesizing data of artifacts, such as printing noise, color distortion, moir\u00e9 pattern, \\textit{etc}. Our experiments show that using our FAS augmentation can surpass traditional image augmentation in training FAS models to achieve better cross-domain performance. Nevertheless, we observe that models may rely on the augmented artifacts, which are not environment-invariant, and using FAS-Aug may have a negative effect. As such, we propose Spoofing Attack Risk Equalization (SARE) to prevent models from relying on certain types of artifacts and improve the generalization performance. Last but not least, our proposed FAS-Aug and SARE with recent Vision Transformer backbones can achieve state-of-the-art performance on the FAS cross-domain generalization protocols. The implementation is available at https://github.com/RizhaoCai/FAS_Aug.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by International Journal of Computer Vision (IJCV) in Sept 2024"
    },
    {
        "paper id": "2409.04468",
        "abstract url": "https://arxiv.org/abs/2409.04468",
        "title": "Controlled fluid transport by the collective motion of microrotors",
        "rating": "-2",
        "keywords": [
            [
                "biomedical",
                "surgery"
            ]
        ],
        "abstract": "Torque-driven microscale swimming robots, or microrotors, hold significant potential in biomedical applications such as targeted drug delivery, minimally invasive surgery, and micromanipulation. This paper addresses the challenge of controlling the transport of fluid volumes using the flow fields generated by interacting groups of microrotors. Our approach uses polynomial chaos expansions to model the time evolution of fluid particle distributions and formulate an optimal control problem, which we solve numerically. We implement this framework in simulation to achieve the controlled transport of an initial fluid particle distribution to a target destination while minimizing undesirable effects such as stretching and mixing. We consider the case where translational velocities of the rotors are directly controlled, as well as the case where only torques are controlled and the rotors move in response to the collective flow fields they generate. We analyze the solution of this optimal control problem by computing the Lagrangian coherent structures of the associated flow field, which reveal the formation of transport barriers that efficiently guide particles toward their target. This analysis provides insights into the underlying mechanisms of controlled transport.",
        "subjects": [
            "math.OC",
            "eess.SY",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01676",
        "abstract url": "https://arxiv.org/abs/2409.01676",
        "title": "Classifier-Free Diffusion-Based Weakly-Supervised Approach for Health Indicator Derivation in Rotating Machines: Advancing Early Fault Detection and Condition Monitoring",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Health"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deriving health indicators of rotating machines is crucial for their maintenance. However, this process is challenging for the prevalent adopted intelligent methods since they may take the whole data distributions, not only introducing noise interference but also lacking the explainability. To address these issues, we propose a diffusion-based weakly-supervised approach for deriving health indicators of rotating machines, enabling early fault detection and continuous monitoring of condition evolution. This approach relies on a classifier-free diffusion model trained using healthy samples and a few anomalies. This model generates healthy samples. and by comparing the differences between the original samples and the generated ones in the envelope spectrum, we construct an anomaly map that clearly identifies faults. Health indicators are then derived, which can explain the fault types and mitigate noise interference. Comparative studies on two cases demonstrate that the proposed method offers superior health monitoring effectiveness and robustness compared to baseline models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01685",
        "abstract url": "https://arxiv.org/abs/2409.01685",
        "title": "Optimizing Mortality Prediction for ICU Heart Failure Patients: Leveraging XGBoost and Advanced Machine Learning with the MIMIC-III Database",
        "rating": "-2.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Heart failure affects millions of people worldwide, significantly reducing quality of life and leading to high mortality rates. Despite extensive research, the relationship between heart failure and mortality rates among ICU patients is not fully understood, indicating the need for more accurate prediction models. This study analyzed data from 1,177 patients over 18 years old from the MIMIC-III database, identified using ICD-9 codes. Preprocessing steps included handling missing data, removing duplicates, treating skewness, and using oversampling techniques to address data imbalances. Through rigorous feature selection using Variance Inflation Factor (VIF), expert clinical input, and ablation studies, 46 key features were identified to enhance model performance. Our analysis compared several machine learning models, including Logistic Regression, Support Vector Machine (SVM), Random Forest, LightGBM, and XGBoost. XGBoost emerged as the superior model, achieving a test AUC-ROC of 0.9228 (95\\% CI 0.8748 - 0.9613), significantly outperforming our previous work (AUC-ROC of 0.8766) and the best results reported in existing literature (AUC-ROC of 0.824). The improved model's success is attributed to advanced feature selection methods, robust preprocessing techniques, and comprehensive hyperparameter optimization through Grid-Search. SHAP analysis and feature importance evaluations based on XGBoost highlighted key variables like leucocyte count and RDW, providing valuable insights into the clinical factors influencing mortality risk. This framework offers significant support for clinicians, enabling them to identify high-risk ICU heart failure patients and improve patient outcomes through timely and informed interventions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01731",
        "abstract url": "https://arxiv.org/abs/2409.01731",
        "title": "Stacked ensemble\\-based mutagenicity prediction model using multiple modalities with graph attention network",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "biologists",
                "cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mutagenicity is a concern due to its association with genetic mutations which can result in a variety of negative consequences, including the development of cancer. Earlier identification of mutagenic compounds in the drug development process is therefore crucial for preventing the progression of unsafe candidates and reducing development costs. While computational techniques, especially machine learning models have become increasingly prevalent for this endpoint, they rely on a single modality. In this work, we introduce a novel stacked ensemble based mutagenicity prediction model which incorporate multiple modalities such as simplified molecular input line entry system (SMILES) and molecular graph. These modalities capture diverse information about molecules such as substructural, physicochemical, geometrical and topological. To derive substructural, geometrical and physicochemical information, we use SMILES, while topological information is extracted through a graph attention network (GAT) via molecular graph. Our model uses a stacked ensemble of machine learning classifiers to make predictions using these multiple features. We employ the explainable artificial intelligence (XAI) technique SHAP (Shapley Additive Explanations) to determine the significance of each classifier and the most relevant features in the prediction. We demonstrate that our method surpasses SOTA methods on two standard datasets across various metrics. Notably, we achieve an area under the curve of 95.21\\% on the Hansen benchmark dataset, affirming the efficacy of our method in predicting mutagenicity. We believe that this research will captivate the interest of both clinicians and computational biologists engaged in translational research.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submitted to a journal"
    },
    {
        "paper id": "2409.01903",
        "abstract url": "https://arxiv.org/abs/2409.01903",
        "title": "A randomized simulation trial evaluating ABiMed, a clinical decision support system for medication reviews and polypharmacy management",
        "rating": "-2.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Background: Medication review is a structured interview of the patient, performed by the pharmacist and aimed at optimizing drug treatments. In practice, medication review is a long and cognitively-demanding task that requires specific knowledge. Clinical practice guidelines have been proposed, but their application is tedious. Methods: We designed ABiMed, a clinical decision support system for medication reviews, based on the implementation of the STOPP/START v2 guidelines and on the visual presentation of aggregated drug knowledge using tables, graphs and flower glyphs. We evaluated ABiMed with 39 community pharmacists during a randomized simulation trial, each pharmacist performing a medication review for two fictitious patients without ABiMed, and two others with ABiMed. We recorded the problems identified by the pharmacists, the interventions proposed, the response time, the perceived usability and the comments. Pharmacists' medication reviews were compared to an expert-designed gold standard. Results: With ABiMed, pharmacists found 1.6 times more relevant drug-related problems during the medication review (p=1.1e-12) and proposed better interventions (p=9.8e-9), without needing more time (p=0.56). The System Usability Scale score is 82.7, which is ranked \"excellent\". In their comments, pharmacists appreciated the visual aspect of ABiMed and its ability to compare the current treatment with the proposed one. A multifactor analysis showed no difference in the support offered by ABiMed according to the pharmacist's age or sex, in terms of percentage of problems identified or quality of the proposed interventions. Conclusions: The use of an intelligent and visual clinical decision support system can help pharmacists when they perform medication reviews. Our main perspective is the validation of the system in clinical conditions.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.01974",
        "abstract url": "https://arxiv.org/abs/2409.01974",
        "title": "Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents",
        "rating": "-2.5",
        "keywords": [
            [
                "robot",
                "navigation"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In nature, active inference agents must learn how observations of the world represent the state of the agent. In engineering, the physics behind sensors is often known reasonably accurately and measurement functions can be incorporated into generative models. When a measurement function is non-linear, the transformed variable is typically approximated with a Gaussian distribution to ensure tractable inference. We show that Gaussian approximations that are sensitive to the curvature of the measurement function, such as a second-order Taylor approximation, produce a state-dependent ambiguity term. This induces a preference over states, based on how accurately the state can be inferred from the observation. We demonstrate this preference with a robot navigation experiment where agents plan trajectories.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.RO",
            "stat.ML"
        ],
        "comment": "13 pages, 3 figures. Accepted to the International Workshop on Active Inference 2024"
    },
    {
        "paper id": "2409.02148",
        "abstract url": "https://arxiv.org/abs/2409.02148",
        "title": "Optimal Power Grid Operations with Foundation Models",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The energy transition, crucial for tackling the climate crisis, demands integrating numerous distributed, renewable energy sources into existing grids. Along with climate change and consumer behavioral changes, this leads to changes and variability in generation and load patterns, introducing significant complexity and uncertainty into grid planning and operations. While the industry has already started to exploit AI to overcome computational challenges of established grid simulation tools, we propose the use of AI Foundation Models (FMs) and advances in Graph Neural Networks to efficiently exploit poorly available grid data for different downstream tasks, enhancing grid operations. For capturing the grid's underlying physics, we believe that building a self-supervised model learning the power flow dynamics is a critical first step towards developing an FM for the power grid. We show how this approach may close the gap between the industry needs and current grid analysis capabilities, to bring the industry closer to optimal grid operation and planning.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02303",
        "abstract url": "https://arxiv.org/abs/2409.02303",
        "title": "A Lesion-aware Edge-based Graph Neural Network for Predicting Language Ability in Patients with Post-stroke Aphasia",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "fMRI",
                "Lesion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a lesion-aware graph neural network (LEGNet) to predict language ability from resting-state fMRI (rs-fMRI) connectivity in patients with post-stroke aphasia. Our model integrates three components: an edge-based learning module that encodes functional connectivity between brain regions, a lesion encoding module, and a subgraph learning module that leverages functional similarities for prediction. We use synthetic data derived from the Human Connectome Project (HCP) for hyperparameter tuning and model pretraining. We then evaluate the performance using repeated 10-fold cross-validation on an in-house neuroimaging dataset of post-stroke aphasia. Our results demonstrate that LEGNet outperforms baseline deep learning methods in predicting language ability. LEGNet also exhibits superior generalization ability when tested on a second in-house dataset that was acquired under a slightly different neuroimaging protocol. Taken together, the results of this study highlight the potential of LEGNet in effectively learning the relationships between rs-fMRI connectivity and language ability in a patient cohort with brain lesions for improved post-stroke aphasia evaluation.",
        "subjects": [
            "cs.LG",
            "eess.SP",
            "q-bio.NC"
        ],
        "comment": "Accepted at MICCAI 2024 International Workshop on Machine Learning in Clinical Neuroimaging (MLCN)"
    },
    {
        "paper id": "2409.02957",
        "abstract url": "https://arxiv.org/abs/2409.02957",
        "title": "Comparison of Epilepsy Induced by Ischemic Hypoxic Brain Injury and Hypoglycemic Brain Injury using Multilevel Fusion of Data Features",
        "rating": "-2.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "medical",
                "health",
                "EEG",
                "disease",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The study aims to investigate the similarities and differences in the brain damage caused by Hypoxia-Ischemia (HI), Hypoglycemia, and Epilepsy. Hypoglycemia poses a significant challenge in improving glycemic regulation for insulin-treated patients, while HI brain disease in neonates is associated with low oxygen levels. The study examines the possibility of using a combination of medical data and Electroencephalography (EEG) measurements to predict outcomes over a two-year period. The study employs a multilevel fusion of data features to enhance the accuracy of the predictions. Therefore this paper suggests a hybridized classification model for Hypoxia-Ischemia and Hypoglycemia, Epilepsy brain injury (HCM-BI). A Support Vector Machine is applied with clinical details to define the Hypoxia-Ischemia outcomes of each infant. The newborn babies are assessed every two years again to know the neural development results. A selection of four attributes is derived from the Electroencephalography records, and SVM does not get conclusions regarding the classification of diseases. The final feature extraction of the EEG signal is optimized by the Bayesian Neural Network (BNN) to get the clear health condition of Hypoglycemia and Epilepsy patients. Through monitoring and assessing physical effects resulting from Electroencephalography, The Bayesian Neural Network (BNN) is used to extract the test samples with the most log data and to report hypoglycemia and epilepsy Keywords- Hypoxia-Ischemia , Hypoglycemia , Epilepsy , Multilevel Fusion of Data Features , Bayesian Neural Network (BNN) , Support Vector Machine (SVM)",
        "subjects": [
            "cs.LG",
            "eess.SP",
            "q-bio.NC"
        ],
        "comment": "16 Pages, 12 Figures, 2 Tables"
    },
    {
        "paper id": "2409.01650",
        "abstract url": "https://arxiv.org/abs/2409.01650",
        "title": "Exact computation of Transfer Entropy with Path Weight Sampling",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Information processing in networks entails a dynamical transfer of information between stochastic variables. Transfer entropy is widely used for quantification of the directional transfer of information between input and output trajectories. However, currently there is no exact technique to quantify transfer entropy given the dynamical model of a general network. Here we introduce an exact computational algorithm, Transfer Entropy-Path Weight Sampling (TE-PWS), to quantify transfer entropy and its variants in an arbitrary network in the presence of multiple hidden variables, nonlinearity, transient conditions, and feedback. TE-PWS extends a recently introduced algorithm Path Weight Sampling (PWS) and uses techniques from the statistical physics of polymers and trajectory sampling. We apply TE-PWS to linear and nonlinear systems to reveal how transfer entropy can overcome naive applications of data processing inequalities in presence of feedback.",
        "subjects": [
            "q-bio.MN",
            "cond-mat.soft",
            "cond-mat.stat-mech",
            "cs.IT",
            "physics.bio-ph"
        ],
        "comment": "12 pages, 4 figures"
    },
    {
        "paper id": "2409.01695",
        "abstract url": "https://arxiv.org/abs/2409.01695",
        "title": "USTC-KXDIGIT System Description for ASVspoof5 Challenge",
        "rating": "-3",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "attacks"
            ],
            [
                "voice conversion"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper describes the USTC-KXDIGIT system submitted to the ASVspoof5 Challenge for Track 1 (speech deepfake detection) and Track 2 (spoofing-robust automatic speaker verification, SASV). Track 1 showcases a diverse range of technical qualities from potential processing algorithms and includes both open and closed conditions. For these conditions, our system consists of a cascade of a frontend feature extractor and a back-end classifier. We focus on extensive embedding engineering and enhancing the generalization of the back-end classifier model. Specifically, the embedding engineering is based on hand-crafted features and speech representations from a self-supervised model, used for closed and open conditions, respectively. To detect spoof attacks under various adversarial conditions, we trained multiple systems on an augmented training set. Additionally, we used voice conversion technology to synthesize fake audio from genuine audio in the training set to enrich the synthesis algorithms. To leverage the complementary information learned by different model architectures, we employed activation ensemble and fused scores from different systems to obtain the final decision score for spoof detection. During the evaluation phase, the proposed methods achieved 0.3948 minDCF and 14.33% EER in the close condition, and 0.0750 minDCF and 2.59% EER in the open condition, demonstrating the robustness of our submitted systems under adversarial conditions. In Track 2, we continued using the CM system from Track 1 and fused it with a CNN-based ASV system. This approach achieved 0.2814 min-aDCF in the closed condition and 0.0756 min-aDCF in the open condition, showcasing superior performance in the SASV system.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "ASVspoof5 workshop paper"
    },
    {
        "paper id": "2409.01706",
        "abstract url": "https://arxiv.org/abs/2409.01706",
        "title": "Classically estimating observables of noiseless quantum circuits",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "We present a classical algorithm for estimating expectation values of arbitrary observables on most quantum circuits across all circuit architectures and depths, including those with all-to-all connectivity. We prove that for any architecture where each circuit layer is equipped with a measure invariant under single-qubit rotations, our algorithm achieves a small error $\\varepsilon$ on all circuits except for a small fraction $\u03b4$. The computational time is polynomial in qubit count and circuit depth for any small constant $\\varepsilon, \u03b4$, and quasi-polynomial for inverse-polynomially small $\\varepsilon, \u03b4$. For non-classically-simulable input states or observables, the expectation values can be estimated by augmenting our algorithm with classical shadows of the relevant state or observable. Our approach leverages a Pauli-path method under Heisenberg evolution. While prior works are limited to noisy quantum circuits, we establish classical simulability in noiseless regimes. Given that most quantum circuits in an architecture exhibit chaotic and locally scrambling behavior, our work demonstrates that estimating observables of such quantum dynamics is classically tractable across all geometries.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "math-ph"
        ],
        "comment": "Main text: 8 pages, 3 figures. Appendices: 25 pages, 1 figure"
    },
    {
        "paper id": "2409.01797",
        "abstract url": "https://arxiv.org/abs/2409.01797",
        "title": "Frugal RIS-aided 3D Localization with CFO under LoS and NLoS Conditions",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "In this paper, we investigate 3-D localization and frequency synchronization with multiple reconfigurable intelligent surfaces (RISs) in the presence of carrier frequency offset (CFO) for a stationary user equipment (UE). In line with the 6G goals of sustainability and efficiency, we focus on a frugal communication scenario with minimal spatial and spectral resources (i.e., narrowband single-input single-ouput system), considering both the presence and blockage of the line-of-sight (LoS) path between the base station (BS) and the UE. We design a generalized likelihood ratio test (GLRT)-based LoS detector, channel parameter estimation and localization algorithms, with varying complexity. To verify the efficiency of our estimators, we compare the root mean-squared error (RMSE) to the Cram\u00e9r- Rao bound (CRB) of the unknown parameters. We also evaluate the sensitivity of our algorithms to the presence of uncontrolled multi-path components (MPC) and various levels of CFO. Simulation results showcase the effectiveness of the proposed algorithms under minimal hardware and spectral requirements, and a wide range of operating conditions, thereby confirming the viability of RIS-aided frugal localization in 6G scenarios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 11 figures"
    },
    {
        "paper id": "2409.01803",
        "abstract url": "https://arxiv.org/abs/2409.01803",
        "title": "Performance Level Evaluation Model based on ELM",
        "rating": "-3",
        "keywords": [
            [
                "flight"
            ],
            [
                "physiological"
            ]
        ],
        "abstract": "Human factor evaluation is crucial in designing civil aircraft cockpits. This process relies on the physiological and cognitive characteristics of the flight crew to ensure that the cockpit design aligns with their capabilities and enhances flight safety. Modern physiological data acquisition and analysis technology, developed to replace traditional subjective human evaluation, has become an effective method for verifying and evaluating cockpit human factors design. Given the high-dimensional and complex nature of pilot physiological signals, these uncertainties significantly impact pilot performance. This paper proposes a pilot performance evaluation model based on an Extreme Learning Machine (ELM) to predict flight performance through pilots' physiological signals and further explores the quantitative relationship between human factors and civil aviation safety.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "6 pages, 7 figures"
    },
    {
        "paper id": "2409.01816",
        "abstract url": "https://arxiv.org/abs/2409.01816",
        "title": "GeoBEV: Learning Geometric BEV Representation for Multi-view 3D Object Detection",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "LiDAR"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Bird's-Eye-View (BEV) representation has emerged as a mainstream paradigm for multi-view 3D object detection, demonstrating impressive perceptual capabilities. However, existing methods overlook the geometric quality of BEV representation, leaving it in a low-resolution state and failing to restore the authentic geometric information of the scene. In this paper, we identify the reasons why previous approaches are constrained by low BEV representation resolution and propose Radial-Cartesian BEV Sampling (RC-Sampling), enabling efficient generation of high-resolution dense BEV representations without the need for complex operators. Additionally, we design a novel In-Box Label to substitute the traditional depth label generated from the LiDAR points. This label reflects the actual geometric structure of objects rather than just their surfaces, injecting real-world geometric information into the BEV representation. Furthermore, in conjunction with the In-Box Label, a Centroid-Aware Inner Loss (CAI Loss) is developed to capture the fine-grained inner geometric structure of objects. Finally, we integrate the aforementioned modules into a novel multi-view 3D object detection framework, dubbed GeoBEV. Extensive experiments on the nuScenes dataset exhibit that GeoBEV achieves state-of-the-art performance, highlighting its effectiveness.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01876",
        "abstract url": "https://arxiv.org/abs/2409.01876",
        "title": "CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention",
        "rating": "-3",
        "keywords": [
            [
                "Avatar"
            ],
            [
                "Diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion-based video generation technology has advanced significantly, catalyzing a proliferation of research in human animation. However, the majority of these studies are confined to same-modality driving settings, with cross-modality human body animation remaining relatively underexplored. In this paper, we introduce, an end-to-end audio-driven human animation framework that ensures hand integrity, identity consistency, and natural motion. The key design of CyberHost is the Region Codebook Attention mechanism, which improves the generation quality of facial and hand animations by integrating fine-grained local features with learned motion pattern priors. Furthermore, we have developed a suite of human-prior-guided training strategies, including body movement map, hand clarity score, pose-aligned reference feature, and local enhancement supervision, to improve synthesis results. To our knowledge, CyberHost is the first end-to-end audio-driven human diffusion model capable of facilitating zero-shot video generation within the scope of human body. Extensive experiments demonstrate that CyberHost surpasses previous works in both quantitative and qualitative aspects.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Homepage: https://cyberhost.github.io/"
    },
    {
        "paper id": "2409.01881",
        "abstract url": "https://arxiv.org/abs/2409.01881",
        "title": "The Impact of Run-Time Variability on Side-Channel Attacks Targeting FPGAs",
        "rating": "-3",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "FPGAs"
            ]
        ],
        "abstract": "To defeat side-channel attacks, many recent countermeasures work by enforcing random run-time variability to the target computing platform in terms of clock jitters, frequency and voltage scaling, and phase shift, also combining the contributions from different actuators to maximize the side-channel resistance of the target. However, the robustness of such solutions seems strongly influenced by several hyper-parameters for which an in-depth analysis is still missing. This work proposes a fine-grained dynamic voltage and frequency scaling actuator to investigate the effectiveness of recent desynchronization countermeasures with the goal of highlighting the link between the enforced run-time variability and the vulnerability to side-channel attacks of cryptographic implementations targeting FPGAs. The analysis of the results collected from real hardware allowed for a comprehensive understanding of the protection offered by run-time variability countermeasures against side-channel attacks.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "comment": "Accepted for lecture presentation at 2024 31st IEEE International Conference on Electronics, Circuits and Systems (ICECS), Nancy, France, Nov. 18-20, 2024"
    },
    {
        "paper id": "2409.01942",
        "abstract url": "https://arxiv.org/abs/2409.01942",
        "title": "Quantum Algorithms for One-Sided Crossing Minimization",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "We present singly-exponential quantum algorithms for the One-Sided Crossing Minimization (OSCM) problem. Given an $n$-vertex bipartite graph $G=(U,V,E\\subseteq U \\times V)$, a $2$-level drawing $(\u03c0_U,\u03c0_V)$ of $G$ is described by a linear ordering $\u03c0_U: U \\leftrightarrow \\{1,\\dots,|U|\\}$ of $U$ and linear ordering $\u03c0_V: V \\leftrightarrow \\{1,\\dots,|V|\\}$ of $V$. For a fixed linear ordering $\u03c0_U$ of $U$, the OSCM problem seeks to find a linear ordering $\u03c0_V$ of $V$ that yields a $2$-level drawing $(\u03c0_U,\u03c0_V)$ of $G$ with the minimum number of edge crossings. We show that OSCM can be viewed as a set problem over $V$ amenable for exact algorithms with a quantum speedup with respect to their classical counterparts. First, we exploit the quantum dynamic programming framework of Ambainis et al. [Quantum Speedups for Exponential-Time Dynamic Programming Algorithms. SODA 2019] to devise a QRAM-based algorithm that solves OSCM in $O^*(1.728^n)$ time and space. Second, we use quantum divide and conquer to obtain an algorithm that solves OSCM without using QRAM in $O^*(2^n)$ time and polynomial space.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "comment": "This is the long version of a paper to appear at the 32nd International Symposium on Graph Drawing and Network Visualization (GD '24)"
    },
    {
        "paper id": "2409.02070",
        "abstract url": "https://arxiv.org/abs/2409.02070",
        "title": "Explicit Differentiable Slicing and Global Deformation for Cardiac Mesh Reconstruction",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "graph"
            ],
            [
                "biophysics",
                "medical",
                "health",
                "MRI",
                "CT",
                "Cardiac"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Mesh reconstruction of the cardiac anatomy from medical images is useful for shape and motion measurements and biophysics simulations to facilitate the assessment of cardiac function and health. However, 3D medical images are often acquired as 2D slices that are sparsely sampled and noisy, and mesh reconstruction on such data is a challenging task. Traditional voxel-based approaches rely on pre- and post-processing that compromises image fidelity, while mesh-level deep learning approaches require mesh annotations that are difficult to get. Therefore, direct cross-domain supervision from 2D images to meshes is a key technique for advancing 3D learning in medical imaging, but it has not been well-developed. While there have been attempts to approximate the optimized meshes' slicing, few existing methods directly use 2D slices to supervise mesh reconstruction in a differentiable manner. Here, we propose a novel explicit differentiable voxelization and slicing (DVS) algorithm that allows gradient backpropagation to a mesh from its slices, facilitating refined mesh optimization directly supervised by the losses defined on 2D images. Further, we propose an innovative framework for extracting patient-specific left ventricle (LV) meshes from medical images by coupling DVS with a graph harmonic deformation (GHD) mesh morphing descriptor of cardiac shape that naturally preserves mesh quality and smoothness during optimization. Experimental results demonstrate that our method achieves state-of-the-art performance in cardiac mesh reconstruction tasks from CT and MRI, with an overall Dice score of 90% on multi-datasets, outperforming existing approaches. The proposed method can further quantify clinically useful parameters such as ejection fraction and global myocardial strains, closely matching the ground truth and surpassing the traditional voxel-based approach in sparse images.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02292",
        "abstract url": "https://arxiv.org/abs/2409.02292",
        "title": "RAMBO: Leaking Secrets from Air-Gap Computers by Spelling Covert Radio Signals from Computer RAM",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "biometric"
            ]
        ],
        "abstract": "Air-gapped systems are physically separated from external networks, including the Internet. This isolation is achieved by keeping the air-gap computers disconnected from wired or wireless networks, preventing direct or remote communication with other devices or networks. Air-gap measures may be used in sensitive environments where security and isolation are critical to prevent private and confidential information leakage. In this paper, we present an attack allowing adversaries to leak information from air-gapped computers. We show that malware on a compromised computer can generate radio signals from memory buses (RAM). Using software-generated radio signals, malware can encode sensitive information such as files, images, keylogging, biometric information, and encryption keys. With software-defined radio (SDR) hardware, and a simple off-the-shelf antenna, an attacker can intercept transmitted raw radio signals from a distance. The signals can then be decoded and translated back into binary information. We discuss the design and implementation and present related work and evaluation results. This paper presents fast modification methods to leak data from air-gapped computers at 1000 bits per second. Finally, we propose countermeasures to mitigate this out-of-band air-gap threat.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Version of this work accepted to Nordic Conference on Secure IT Systems, 2023"
    },
    {
        "paper id": "2409.02334",
        "abstract url": "https://arxiv.org/abs/2409.02334",
        "title": "YoloTag: Vision-based Robust UAV Navigation with Fiducial Markers",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot",
                "Navigation"
            ],
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "By harnessing fiducial markers as visual landmarks in the environment, Unmanned Aerial Vehicles (UAVs) can rapidly build precise maps and navigate spaces safely and efficiently, unlocking their potential for fluent collaboration and coexistence with humans. Existing fiducial marker methods rely on handcrafted feature extraction, which sacrifices accuracy. On the other hand, deep learning pipelines for marker detection fail to meet real-time runtime constraints crucial for navigation applications. In this work, we propose YoloTag \\textemdash a real-time fiducial marker-based localization system. YoloTag uses a lightweight YOLO v8 object detector to accurately detect fiducial markers in images while meeting the runtime constraints needed for navigation. The detected markers are then used by an efficient perspective-n-point algorithm to estimate UAV states. However, this localization system introduces noise, causing instability in trajectory tracking. To suppress noise, we design a higher-order Butterworth filter that effectively eliminates noise through frequency domain analysis. We evaluate our algorithm through real-robot experiments in an indoor environment, comparing the trajectory tracking performance of our method against other approaches in terms of several distance metrics.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01642",
        "abstract url": "https://arxiv.org/abs/2409.01642",
        "title": "Acoustic Levitation for Environmental Remediation: An Effective Approach for Containment and Forecasting of Oil Spills",
        "rating": "-4",
        "keywords": [
            [
                "chemical"
            ],
            [
                "Forecasting"
            ]
        ],
        "abstract": "The ocean ecology is badly impacted by large-scale oil spills, plastic waste, and chemical pollution, which destroy ecosystems and endanger marine life. Acknowledging the detrimental effects of oil spills on ecosystems, our research aims to establish the foundation for creative methods to lessen their impact. With an emphasis on the containment and prediction of oil spills, this research investigates the potential of acoustic levitation as a cutting-edge technique for environmental cleanup. Effectively separating and eliminating pollutants without causing additional ecological harm is a major issue for traditional oil spill cleanup techniques. Acoustic levitation provides a non-invasive, accurate, and effective alternative by using sound waves to precisely and subtly separate oil droplets from water in controlled environments. This proposed approach can reduce the negative effects on the environment and increase the efficacy of cleanup efforts. The findings have been examined and assessed by proof of concept experiments with oil droplets, identifying the relationship between the intensity of ultrasonic pressure and the proportion of oil droplets collected.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01646",
        "abstract url": "https://arxiv.org/abs/2409.01646",
        "title": "BEVNav: Robot Autonomous Navigation Via Spatial-Temporal Contrastive Learning in Bird's-Eye View",
        "rating": "-4",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "Robot",
                "Navigation"
            ],
            [
                "Bird's-Eye View",
                "BEV"
            ]
        ],
        "abstract": "Goal-driven mobile robot navigation in map-less environments requires effective state representations for reliable decision-making. Inspired by the favorable properties of Bird's-Eye View (BEV) in point clouds for visual perception, this paper introduces a novel navigation approach named BEVNav. It employs deep reinforcement learning to learn BEV representations and enhance decision-making reliability. First, we propose a self-supervised spatial-temporal contrastive learning approach to learn BEV representations. Spatially, two randomly augmented views from a point cloud predict each other, enhancing spatial features. Temporally, we combine the current observation with consecutive frames' actions to predict future features, establishing the relationship between observation transitions and actions to capture temporal cues. Then, incorporating this spatial-temporal contrastive learning in the Soft Actor-Critic reinforcement learning framework, our BEVNav offers a superior navigation policy. Extensive experiments demonstrate BEVNav's robustness in environments with dense pedestrians, outperforming state-of-the-art methods across multiple benchmarks. \\rev{The code will be made publicly available at https://github.com/LanrenzzzZ/BEVNav.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01768",
        "abstract url": "https://arxiv.org/abs/2409.01768",
        "title": "Mapping Safe Zones for Co-located Human-UAV Interaction",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "UAV",
                "drone"
            ]
        ],
        "abstract": "Recent advances in robotics bring us closer to the reality of living, co-habiting, and sharing personal spaces with robots. However, it is not clear how close a co-located robot can be to a human in a shared environment without making the human uncomfortable or anxious. This research aims to map safe and comfortable zones for co-located aerial robots. The objective is to identify the distances at which a drone causes discomfort to a co-located human and to create a map showing no-fly, moderate-fly, and safe-fly zones. We recruited a total of 18 participants and conducted two indoor laboratory experiments, one with a single drone and the other set with two drones. Our results show that multiple drones cause more discomfort when close to a co-located human than a single drone. We observed that distances below 200 cm caused discomfort, the moderate fly zone was 200 - 300 cm, and the safe-fly zone was any distance greater than 300 cm in single drone experiments. The safe zones were pushed further away by 100 cm for the multiple drone experiments. In this paper, we present the preliminary findings on safe-fly zones for multiple drones. Further work would investigate the impact of a higher number of aerial robots, the speed of approach, direction of travel, and noise level on co-located humans, and autonomously develop 3D models of trust zones and safe zones for co-located aerial swarms.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been accepted for presentation at the Second International Symposium on Trustworthy Autonomous Systems (TAS '24), being held from September 16-18, 2024, at Austin, TX, USA. It consists of 10 pages, 9 figures, and 1 table"
    },
    {
        "paper id": "2409.01900",
        "abstract url": "https://arxiv.org/abs/2409.01900",
        "title": "Securing Federated Learning in Robot Swarms using Blockchain Technology",
        "rating": "-4",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "Federated Learning"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Federated learning is a new approach to distributed machine learning that offers potential advantages such as reducing communication requirements and distributing the costs of training algorithms. Therefore, it could hold great promise in swarm robotics applications. However, federated learning usually requires a centralized server for the aggregation of the models. In this paper, we present a proof-of-concept implementation of federated learning in a robot swarm that does not compromise decentralization. To do so, we use blockchain technology to enable our robot swarm to securely synchronize a shared model that is the aggregation of the individual models without relying on a central server. We then show that introducing a single malfunctioning robot can, however, heavily disrupt the training process. To prevent such situations, we devise protection mechanisms that are implemented through secure and tamper-proof blockchain smart contracts. Our experiments are conducted in ARGoS, a physics-based simulator for swarm robotics, using the Ethereum blockchain protocol which is executed by each simulated robot.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "To be published in the Proceedings of the 17th International Symposium on Distributed Autonomous Robotic Systems (DARS 2024)"
    },
    {
        "paper id": "2409.02322",
        "abstract url": "https://arxiv.org/abs/2409.02322",
        "title": "TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model",
        "rating": "-4",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "model editing"
            ],
            [
                "anomaly detection"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "With recent advances in building foundation models for texts and video data, there is a surge of interest in foundation models for time series. A family of models have been developed, utilizing a temporal auto-regressive generative Transformer architecture, whose effectiveness has been proven in Large Language Models. While the empirical results are promising, almost all existing time series foundation models have only been tested on well-curated ``benchmark'' datasets very similar to texts. However, real-world time series exhibit unique challenges, such as variable channel sizes across domains, missing values, and varying signal sampling intervals due to the multi-resolution nature of real-world data. Additionally, the uni-directional nature of temporally auto-regressive decoding limits the incorporation of domain knowledge, such as physical laws expressed as partial differential equations (PDEs). To address these challenges, we introduce the Time Diffusion Transformer (TimeDiT), a general foundation model for time series that employs a denoising diffusion paradigm instead of temporal auto-regressive generation. TimeDiT leverages the Transformer architecture to capture temporal dependencies and employs diffusion processes to generate high-quality candidate samples without imposing stringent assumptions on the target distribution via novel masking schemes and a channel alignment strategy. Furthermore, we propose a finetuning-free model editing strategy that allows the seamless integration of external knowledge during the sampling process without updating any model parameters. Extensive experiments conducted on a varity of tasks such as forecasting, imputation, and anomaly detection, demonstrate the effectiveness of TimeDiT.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "23 Pages, 6 Figures, 11 Tables. First present at ICML 2024 Workshop on Foundation Models in the Wild"
    },
    {
        "paper id": "2409.02383",
        "abstract url": "https://arxiv.org/abs/2409.02383",
        "title": "Reinforcement Learning for Wheeled Mobility on Vertically Challenging Terrain",
        "rating": "-4",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "navigation"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Off-road navigation on vertically challenging terrain, involving steep slopes and rugged boulders, presents significant challenges for wheeled robots both at the planning level to achieve smooth collision-free trajectories and at the control level to avoid rolling over or getting stuck. Considering the complex model of wheel-terrain interactions, we develop an end-to-end Reinforcement Learning (RL) system for an autonomous vehicle to learn wheeled mobility through simulated trial-and-error experiences. Using a custom-designed simulator built on the Chrono multi-physics engine, our approach leverages Proximal Policy Optimization (PPO) and a terrain difficulty curriculum to refine a policy based on a reward function to encourage progress towards the goal and penalize excessive roll and pitch angles, which circumvents the need of complex and expensive kinodynamic modeling, planning, and control. Additionally, we present experimental results in the simulator and deploy our approach on a physical Verti-4-Wheeler (V4W) platform, demonstrating that RL can equip conventional wheeled robots with previously unrealized potential of navigating vertically challenging terrain.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02395",
        "abstract url": "https://arxiv.org/abs/2409.02395",
        "title": "Deep Brain Ultrasound Ablation Thermal Dose Modeling with in Vivo Experimental Validation",
        "rating": "-4",
        "keywords": [
            [
                "bioheat",
                "tumor"
            ],
            [
                "Thermal"
            ]
        ],
        "abstract": "Intracorporeal needle-based therapeutic ultrasound (NBTU) is a minimally invasive option for intervening in malignant brain tumors, commonly used in thermal ablation procedures. This technique is suitable for both primary and metastatic cancers, utilizing a high-frequency alternating electric field (up to 10 MHz) to excite a piezoelectric transducer. The resulting rapid deformation of the transducer produces an acoustic wave that propagates through tissue, leading to localized high-temperature heating at the target tumor site and inducing rapid cell death. To optimize the design of NBTU transducers for thermal dose delivery during treatment, numerical modeling of the acoustic pressure field generated by the deforming piezoelectric transducer is frequently employed. The bioheat transfer process generated by the input pressure field is used to track the thermal propagation of the applicator over time. Magnetic resonance thermal imaging (MRTI) can be used to experimentally validate these models. Validation results using MRTI demonstrated the feasibility of this model, showing a consistent thermal propagation pattern. However, a thermal damage isodose map is more advantageous for evaluating therapeutic efficacy. To achieve a more accurate simulation based on the actual brain tissue environment, a new finite element method (FEM) simulation with enhanced damage evaluation capabilities was conducted. The results showed that the highest temperature and ablated volume differed between experimental and simulation results by 2.1884\u00b0C (3.71%) and 0.0631 cm$^3$ (5.74%), respectively. The lowest Pearson correlation coefficient (PCC) for peak temperature was 0.7117, and the lowest Dice coefficient for the ablated area was 0.7021, indicating a good agreement in accuracy between simulation and experiment.",
        "subjects": [
            "physics.med-ph",
            "cs.RO"
        ],
        "comment": "9 pages, 9 figures, 7 tables"
    },
    {
        "paper id": "2409.01812",
        "abstract url": "https://arxiv.org/abs/2409.01812",
        "title": "Optimal SSB Beam Planning and UAV Cell Selection for 5G Connectivity on Aerial Highways",
        "rating": "-5",
        "keywords": [
            [
                "3D"
            ],
            [
                "5G"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this article, we introduce a method to optimize 5G massive multiple-input multiple-output (mMIMO) connectivity for unmanned aerial vehicles (UAVs) on aerial highways through strategic cell association. UAVs operating in 3D space encounter distinct channel conditions compared to traditional ground user equipment (gUE); under the typical line of sight (LoS) condition, UAVs perceive strong reference signal received power (RSRP) from multiple cells within the network, resulting in a large set of suitable serving cell candidates and in low signal-to-interference-plus-noise ratio (SINR) due to high interference levels. Additionally, a downside of aerial highways is to pack possibly many UAVs along a small portion of space which, when taking into account typical LoS propagation conditions, results in high channel correlation and severely limits spatial multiplexing capabilities. In this paper, we propose a solution to both problems based on the suitable selection of serving cells based on a new metric which differs from the classical terrestrial approaches based on maximum RSRP. We then introduce an algorithm for optimal planning of synchronization signal block (SSB) beams for this set of cells, ensuring maximum coverage and effective management of UAVs cell associations. Simulation results demonstrate that our approach significantly improves the rates of UAVs on aerial highways, up to four times in achievable data rates, without impacting ground user performance.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01924",
        "abstract url": "https://arxiv.org/abs/2409.01924",
        "title": "Privacy-Preserving and Post-Quantum Counter Denial of Service Framework for Wireless Networks",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "IoT"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "As network services progress and mobile and IoT environments expand, numerous security concerns have surfaced for spectrum access systems. The omnipresent risk of Denial-of-Service (DoS) attacks and raising concerns about user privacy (e.g., location privacy, anonymity) are among such cyber threats. These security and privacy risks increase due to the threat of quantum computers that can compromise long-term security by circumventing conventional cryptosystems and increasing the cost of countermeasures. While some defense mechanisms exist against these threats in isolation, there is a significant gap in the state of the art on a holistic solution against DoS attacks with privacy and anonymity for spectrum management systems, especially when post-quantum (PQ) security is in mind. In this paper, we propose a new cybersecurity framework PACDoSQ, which is (to the best of our knowledge) the first to offer location privacy and anonymity for spectrum management with counter DoS and PQ security simultaneously. Our solution introduces the private spectrum bastion (database) concept to exploit existing architectural features of spectrum management systems and then synergizes them with multi-server private information retrieval and PQ-secure Tor to guarantee a location-private and anonymous acquisition of spectrum information together with hash-based client-server puzzles for counter DoS. We prove that PACDoSQ achieves its security objectives, and show its feasibility via a comprehensive performance evaluation.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted at IEEE Military Communications Conference, 28 October 1 November 2024, Washington, DC, USA"
    },
    {
        "paper id": "2409.01931",
        "abstract url": "https://arxiv.org/abs/2409.01931",
        "title": "On the design space between molecular mechanics and machine learning force fields",
        "rating": "-5.5",
        "keywords": [
            [
                "biomolecular"
            ],
            [
                "chemical"
            ],
            [
                "quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "A force field as accurate as quantum mechanics (QM) and as fast as molecular mechanics (MM), with which one can simulate a biomolecular system efficiently enough and meaningfully enough to get quantitative insights, is among the most ardent dreams of biophysicists -- a dream, nevertheless, not to be fulfilled any time soon. Machine learning force fields (MLFFs) represent a meaningful endeavor towards this direction, where differentiable neural functions are parametrized to fit ab initio energies, and furthermore forces through automatic differentiation. We argue that, as of now, the utility of the MLFF models is no longer bottlenecked by accuracy but primarily by their speed (as well as stability and generalizability), as many recent variants, on limited chemical spaces, have long surpassed the chemical accuracy of $1$ kcal/mol -- the empirical threshold beyond which realistic chemical predictions are possible -- though still magnitudes slower than MM. Hoping to kindle explorations and designs of faster, albeit perhaps slightly less accurate MLFFs, in this review, we focus our attention on the design space (the speed-accuracy tradeoff) between MM and ML force fields. After a brief review of the building blocks of force fields of either kind, we discuss the desired properties and challenges now faced by the force field development community, survey the efforts to make MM force fields more accurate and ML force fields faster, envision what the next generation of MLFF might look like.",
        "subjects": [
            "physics.chem-ph",
            "cs.AI",
            "cs.LG",
            "physics.bio-ph",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01953",
        "abstract url": "https://arxiv.org/abs/2409.01953",
        "title": "Learning Resilient Formation Control of Drones with Graph Attention Network",
        "rating": "-6",
        "keywords": [
            [
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "industrial"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "The rapid advancement of drone technology has significantly impacted various sectors, including search and rescue, environmental surveillance, and industrial inspection. Multidrone systems offer notable advantages such as enhanced efficiency, scalability, and redundancy over single-drone operations. Despite these benefits, ensuring resilient formation control in dynamic and adversarial environments, such as under communication loss or cyberattacks, remains a significant challenge. Classical approaches to resilient formation control, while effective in certain scenarios, often struggle with complex modeling and the curse of dimensionality, particularly as the number of agents increases. This paper proposes a novel, learning-based formation control for enhancing the adaptability and resilience of multidrone formations using graph attention networks (GATs). By leveraging GAT's dynamic capabilities to extract internode relationships based on the attention mechanism, this GAT-based formation controller significantly improves the robustness of drone formations against various threats, such as Denial of Service (DoS) attacks. Our approach not only improves formation performance in normal conditions but also ensures the resilience of multidrone systems in variable and adversarial environments. Extensive simulation results demonstrate the superior performance of our method over baseline formation controllers. Furthermore, the physical experiments validate the effectiveness of the trained control policy in real-world flights.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2409.01631",
        "abstract url": "https://arxiv.org/abs/2409.01631",
        "title": "Doppler Power Spectrum in Channels with von Mises-Fisher Distribution of Scatterers",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an analytical analysis of the Doppler spectrum in von Mises-Fisher (vMF) scattering channels. A closed-form expression for the Doppler spectrum is derived and used to investigate the impact of vMF scattering parameters, i.e., the mean direction and the degree of concentration of scatterers. The spectrum is observed to exhibit exponential behavior for the mobile antenna motion parallel to the mean direction of scatterers, while conforming to a Gaussian-like shape for the perpendicular motion. The validity of the obtained results is verified by comparison against the results of Monte Carlo simulations, where an exact match is observed.",
        "subjects": [
            "eess.SP",
            "stat.OT"
        ],
        "comment": "Submitted to IEEE Communications Letters (submitted on 2024-07-26)"
    },
    {
        "paper id": "2409.01675",
        "abstract url": "https://arxiv.org/abs/2409.01675",
        "title": "Intelligent Transaction Scheduling via Conflict Prediction in OLTP DBMS",
        "rating": "-10",
        "keywords": [],
        "abstract": "Current architectures for main-memory online transaction processing (OLTP) database management systems (DBMS) typically use random scheduling to assign transactions to threads. This approach achieves uniform load across threads but it ignores the likelihood of conflicts between transactions. If the DBMS could estimate the potential for transaction conflict and then intelligently schedule transactions to avoid conflicts, then the system could improve its performance. Such estimation of transaction conflict, however, is non-trivial for several reasons. First, conflicts occur under complex conditions that are far removed in time from the scheduling decision. Second, transactions must be represented in a compact and efficient manner to allow for fast conflict detection. Third, given some evidence of potential conflict, the DBMS must schedule transactions in such a way that minimizes this conflict. In this paper, we systematically explore the design decisions for solving these problems. We then empirically measure the performance impact of different representations on standard OLTP benchmarks. Our results show that intelligent scheduling using a history increases throughput by $\\sim$40\\% on 20-core machine.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2409.01681",
        "abstract url": "https://arxiv.org/abs/2409.01681",
        "title": "Static Nuel Games with Terminal Payoff",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study a variant of the Nuel game (a generalization of the duel) which is played in turns by $N$ players. In each turn a single player must fire at one of the other players and has a certain probability of hitting and killing his target. The players shoot in a fixed sequence and when a player is eliminated, the ``move'' passes to the next surviving player. The winner is the last surviving player. We prove that, for every $N\\geq2$, the Nuel has a stationary Nash equilibrium and provide algorithms for its computation.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01683",
        "abstract url": "https://arxiv.org/abs/2409.01683",
        "title": "Priority based inter-twin communication in vehicular digital twin networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the advancement and boom of autonomous vehicles, vehicular digital twins (VDTs) have become an emerging research area. VDT can solve the issues related to autonomous vehicles and provide improved and enhanced services to users. Recent studies have demonstrated the potential of using priorities in acquiring improved response time. However, since VDT is comprised of intra-twin and inter-twin communication, it leads to a reduced response time as traffic congestion grows, which causes issues in the form of accidents. It would be encouraging if priorities could be used in inter-twin communication of VDT for data sharing and processing tasks. Moreover, it would also be effective for managing the communication overhead on the digital twin layer of the cloud. This paper proposes a novel priority-based inter-twin communication in VDT to address this issue. We formulate the problem for priorities of digital twins and applications according to their categories. In addition, we describe the priority-based inter-twin communication in VDT in detail and algorithms for priority communication for intra-twin and inter-twin are designed, respectively. Finally, experiments on different priority tasks are conducted and compared with two existing algorithms, demonstrating our proposed algorithm's effectiveness and efficiency.",
        "subjects": [
            "cs.NI",
            "cs.DC"
        ],
        "comment": "This is an Accepted Manuscript of an article published by Taylor & Francis Group in the International Journal of Parallel, Emergent & Distributed Systems on 02 Sep 2024"
    },
    {
        "paper id": "2409.01692",
        "abstract url": "https://arxiv.org/abs/2409.01692",
        "title": "Record-biased permutations and their permuton limit",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this article, we study a non-uniform distribution on permutations biased by their number of records that we call \\emph{record-biased permutations}. We give several generative processes for record-biased permutations, explaining also how they can be used to devise efficient (linear) random samplers. For several classical permutation statistics, we obtain their expectation using the above generative processes, as well as their limit distributions in the regime that has a logarithmic number of records (as in the uniform case). Finally, increasing the bias to obtain a regime with an expected linear number of records, we establish the convergence of record-biased permutations to a deterministic permuton, which we fully characterize. This model was introduced in our earlier work [N. Auger, M. Bouvel, C. Nicaud, C. Pivoteau, \\emph{Analysis of Algorithms for Permutations Biased by Their Number of Records}, AofA 2016], in the context of realistic analysis of algorithms. We conduct here a more thorough study but with a theoretical perspective.",
        "subjects": [
            "math.PR",
            "cs.DM",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01694",
        "abstract url": "https://arxiv.org/abs/2409.01694",
        "title": "A novel and efficient parameter estimation of the Lognormal-Rician turbulence model based on k-Nearest Neighbor and data generation method",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we propose a novel and efficient parameter estimator based on $k$-Nearest Neighbor ($k$NN) and data generation method for the Lognormal-Rician turbulence channel. The Kolmogorov-Smirnov (KS) goodness-of-fit statistical tools are employed to investigate the validity of $k$NN approximation under different channel conditions and it is shown that the choice of $k$ plays a significant role in the approximation accuracy. We present several numerical results to illustrate that solving the constructed objective function can provide a reasonable estimate for the actual values. The accuracy of the proposed estimator is investigated in terms of the mean square error. The simulation results show that increasing the number of generation samples by two orders of magnitude does not lead to a significant improvement in estimation performance when solving the optimization problem by the gradient descent algorithm. However, the estimation performance under the genetic algorithm (GA) approximates to that of the saddlepoint approximation and expectation-maximization estimators. Therefore, combined with the GA, we demonstrate that the proposed estimator achieves the best tradeoff between the computation complexity and the accuracy.",
        "subjects": [
            "eess.SP",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01708",
        "abstract url": "https://arxiv.org/abs/2409.01708",
        "title": "Query complexity lower bounds for local list-decoding and hard-core predicates (even for small rate and huge lists)",
        "rating": "-10",
        "keywords": [],
        "abstract": "A binary code Enc$:\\{0,1\\}^k \\to \\{0,1\\}^n$ is $(0.5-\u03b5,L)$-list decodable if for all $w \\in \\{0,1\\}^n$, the set List$(w)$ of all messages $m \\in \\{0,1\\}^k$ such that the relative Hamming distance between Enc$(m)$ and $w$ is at most $0.5 -\u03b5$, has size at most $L$. Informally, a $q$-query local list-decoder for Enc is a randomized procedure Dec$:[k]\\times [L] \\to \\{0,1\\}$ that when given oracle access to a string $w$, makes at most $q$ oracle calls, and for every message $m \\in \\text{List}(w)$, with high probability, there exists $j \\in [L]$ such that for every $i \\in [k]$, with high probability, Dec$^w(i,j)=m_i$. We prove lower bounds on $q$, that apply even if $L$ is huge (say $L=2^{k^{0.9}}$) and the rate of Enc is small (meaning that $n \\ge 2^{k}$): 1. For $\u03b5\\geq 1/k^\u03bd$ for some universal constant $0< \u03bd< 1$, we prove a lower bound of $q=\u03a9(\\frac{\\log(1/\u03b4)}{\u03b5^2})$, where $\u03b4$ is the error probability of the local list-decoder. This bound is tight as there is a matching upper bound by Goldreich and Levin (STOC 1989) of $q=O(\\frac{\\log(1/\u03b4)}{\u03b5^2})$ for the Hadamard code (which has $n=2^k$). This bound extends an earlier work of Grinberg, Shaltiel and Viola (FOCS 2018) which only works if $n \\le 2^{k^\u03b3}$ for some universal constant $0<\u03b3<1$, and the number of coins tossed by Dec is small (and therefore does not apply to the Hadamard code, or other codes with low rate). 2. For smaller $\u03b5$, we prove a lower bound of roughly $q = \u03a9(\\frac{1}{\\sqrt\u03b5})$. To the best of our knowledge, this is the first lower bound on the number of queries of local list-decoders that gives $q \\ge k$ for small $\u03b5$. We also prove black-box limitations for improving some of the parameters of the Goldreich-Levin hard-core predicate construction.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01709",
        "abstract url": "https://arxiv.org/abs/2409.01709",
        "title": "Accented Character Entry Using Physical Keyboards in Virtual Reality",
        "rating": "-10",
        "keywords": [],
        "abstract": "Research on text entry in Virtual Reality (VR) has gained popularity but the efficient entry of accented characters, characters with diacritical marks, in VR remains underexplored. Entering accented characters is supported on most capacitive touch keyboards through a long press on a base character and a subsequent selection of the accented character. However, entering those characters on physical keyboards is still challenging, as they require a recall and an entry of respective numeric codes. To address this issue this paper investigates three techniques to support accented character entry on physical keyboards in VR. Specifically, we compare a context-aware numeric code technique that does not require users to recall a code, a key-press-only condition in which the accented characters are dynamically remapped to physical keys next to a base character, and a multimodal technique, in which eye gaze is used to select the accented version of a base character previously selected by key-press on the keyboard. The results from our user study (n=18) reveal that both the key-press-only and the multimodal technique outperform the baseline technique in terms of text entry speed.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01710",
        "abstract url": "https://arxiv.org/abs/2409.01710",
        "title": "Privacy-Preserving Multimedia Mobile Cloud Computing Using Protective Perturbation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mobile cloud computing has been adopted in many multimedia applications, where the resource-constrained mobile device sends multimedia data (e.g., images) to remote cloud servers to request computation-intensive multimedia services (e.g., image recognition). While significantly improving the performance of the mobile applications, the cloud-based mechanism often causes privacy concerns as the multimedia data and services are offloaded from the trusted user device to untrusted cloud servers. Several recent studies have proposed perturbation-based privacy preserving mechanisms, which obfuscate the offloaded multimedia data to eliminate privacy exposures without affecting the functionality of the remote multimedia services. However, the existing privacy protection approaches require the deployment of computation-intensive perturbation generation on the resource-constrained mobile devices. Also, the obfuscated images are typically not compliant with the standard image compression algorithms and suffer from significant bandwidth consumption. In this paper, we develop a novel privacy-preserving multimedia mobile cloud computing framework, namely $PMC^2$, to address the resource and bandwidth challenges. $PMC^2$ employs secure confidential computing in the cloud to deploy the perturbation generator, which addresses the resource challenge while maintaining the privacy. Furthermore, we develop a neural compressor specifically trained to compress the perturbed images in order to address the bandwidth challenge. We implement $PMC^2$ in an end-to-end mobile cloud computing system, based on which our evaluations demonstrate superior latency, power efficiency, and bandwidth consumption achieved by $PMC^2$ while maintaining high accuracy in the target multimedia service.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01727",
        "abstract url": "https://arxiv.org/abs/2409.01727",
        "title": "Level Planarity Is More Difficult Than We Thought",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider three simple quadratic time algorithms for the problem Level Planarity and give a level-planar instance that they either falsely report as negative or for which they output a drawing that is not level planar.",
        "subjects": [
            "cs.DM"
        ],
        "comment": "Poster presented at GD 2024"
    },
    {
        "paper id": "2409.01736",
        "abstract url": "https://arxiv.org/abs/2409.01736",
        "title": "SpannerLib: Embedding Declarative Information Extraction in an Imperative Workflow",
        "rating": "-10",
        "keywords": [],
        "abstract": "Document spanners have been proposed as a formal framework for declarative Information Extraction (IE) from text, following IE products from the industry and academia. Over the past decade, the framework has been studied thoroughly in terms of expressive power, complexity, and the ability to naturally combine text analysis with relational querying. This demonstration presents SpannerLib a library for embedding document spanners in Python code. SpannerLib facilitates the development of IE programs by providing an implementation of Spannerlog (Datalog-based documentspanners) that interacts with the Python code in two directions: rules can be embedded inside Python, and they can invoke custom Python code (e.g., calls to ML-based NLP models) via user-defined functions. The demonstration scenarios showcase IE programs, with increasing levels of complexity, within Jupyter Notebook.",
        "subjects": [
            "cs.DB",
            "cs.IR"
        ],
        "comment": "4 pages"
    },
    {
        "paper id": "2409.01760",
        "abstract url": "https://arxiv.org/abs/2409.01760",
        "title": "Design and Operation Principles of a Wave-Controlled Reconfigurable Intelligent Surface",
        "rating": "-10",
        "keywords": [],
        "abstract": "A Reflective Intelligent Surface (RIS) consists of many small reflective elements whose reflection properties can be adjusted to change the wireless propagation environment. Envisioned implementations require that each RIS element be connected to a controller, and as the number of RIS elements on a surface may be on the order of hundreds or more, the number of required electrical connectors creates a difficult wiring problem, especially at high frequencies where the physical space between the elements is limited. A potential solution to this problem was previously proposed by the authors in which \"biasing transmission lines\" carrying standing waves are sampled at each RIS location to produce the desired bias voltage for each RIS element. This solution has the potential to substantially reduce the complexity of the RIS control. This paper presents models for the RIS elements that account for mutual coupling and realistic varactor characteristics, as well as circuit models for sampling the transmission line to generate the RIS control signals. For the latter case, the paper investigates two techniques for conversion of the transmission line standing wave voltage to the varactor bias voltage, namely an envelope detector and a sample-and-hold circuit. The paper also develops a modal decomposition approach for generating standing waves that are able to generate beams and nulls in the resulting RIS radiation pattern that maximize either the Signal-to-Noise Ratio (SNR) or the Signal-to-Leakage-plus-Noise Ratio (SLNR). Extensive simulation results are provided for the two techniques, together with a discussion of computational complexity.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "20 pages, 25 figures, 2 tables"
    },
    {
        "paper id": "2409.01765",
        "abstract url": "https://arxiv.org/abs/2409.01765",
        "title": "Multi-Branch Attention Convolutional Neural Network for Online RIS Configuration with Discrete Responses: A Neuroevolution Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we consider the problem of jointly controlling the configuration of a Reconfigurable Intelligent Surface (RIS) with unit elements of discrete responses and a codebook-based transmit precoder in RIS-empowered Multiple-Input Single-Output (MISO) communication systems. The adjustable elements of the RIS and the precoding vector need to be jointly modified in real time to account for rapid changes in the wireless channels, making the application of complicated discrete optimization algorithms impractical. We present a novel Multi-Branch Attention Convolutional Neural Network (MBACNN) architecture for this design objective which is optimized using NeuroEvolution (NE), leveraging its capability to effectively tackle the non-differentiable problem arising from the discrete phase states of the RIS elements. The channel matrices of all involved links are first passed to separate self-attention layers to obtain initial embeddings, which are then concatenated and passed to a convolutional network for spatial feature extraction, before being fed to a per-element multi-layered perceptron for the final RIS phase configuration calculation. Our MBACNN architecture is then extended to multi-RIS-empowered MISO communication systems, and a novel NE-based optimization approach for the online distributed configuration of multiple RISs is presented. The superiority of the proposed single-RIS approach over both learning-based and classical discrete optimization benchmarks is showcased via extensive numerical evaluations over both stochastic and geometrical channel models. It is also demonstrated that the proposed distributed multi-RIS approach outperforms both distributed controllers with feedforward neural networks and fully centralized ones.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "13 pages, figures, under review in a journal"
    },
    {
        "paper id": "2409.01792",
        "abstract url": "https://arxiv.org/abs/2409.01792",
        "title": "Three-dimensional geometric resolution of the inverse kinematics of a 7 degree of freedom articulated arm",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work presents a three-dimensional geometric resolution method to calculate the complete inverse kinematics of a 7-degree-of-freedom articulated arm, including the hand itself. The method is classified as an analytical method with geometric solution, since it obtains a precise solution in a closed number of steps, converting the inverse kinematic problem into a three-dimensional geometric model. To simplify the problem, the kinematic decoupling method is used, so that the position of the wrist is calculated independently on one hand with information on the orientation of the hand, and the angles of the rest of the arm are calculated from the wrist.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "in Spanish language"
    },
    {
        "paper id": "2409.01804",
        "abstract url": "https://arxiv.org/abs/2409.01804",
        "title": "Strengthening Solidity Invariant Generation: From Post- to Pre-Deployment",
        "rating": "-10",
        "keywords": [],
        "abstract": "Invariants are essential for ensuring the security and correctness of Solidity smart contracts, particularly in the context of blockchain's immutability and decentralized execution. This paper introduces InvSol, a novel framework for pre-deployment invariant generation tailored specifically for Solidity smart contracts. Unlike existing solutions, namely InvCon, InvCon+, and Trace2Inv, that rely on post-deployment transaction histories on Ethereum mainnet, InvSol identifies invariants before deployment and offers comprehensive coverage of Solidity language constructs, including loops. Additionally, InvSol incorporates custom templates to effectively prevent critical issues such as reentrancy, out-of-gas errors, and exceptions during invariant generation. We rigorously evaluate InvSol using a benchmark set of smart contracts and compare its performance with state-of-the-art solutions. Our findings reveal that InvSol significantly outperforms these tools, demonstrating its effectiveness in handling new contracts with limited transaction histories. Notably, InvSol achieves a 15% improvement in identifying common vulnerabilities compared to InvCon+ and is able to address certain crucial vulnerabilities using specific invariant templates, better than Trace2Inv.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01809",
        "abstract url": "https://arxiv.org/abs/2409.01809",
        "title": "Hardware-Based Microgrid Coupled to Real-Time Simulated Power Grids for Evaluating New Control Strategies in Future Energy Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The design of new control strategies for future energy systems can neither be directly tested in real power grids nor be evaluated based on only current grid situations. In this regard, extensive tests are required in laboratory settings using real power system equipment. However, since it is impossible to replicate the entire grid section of interest, even in large-scale experiments, hardware setups must be supplemented by detailed simulations to reproduce the system under study fully. This paper presents a unique test environment in which a hardware-based microgrid environment is physically coupled with a large-scale real-time simulation framework. The setup combines the advantages of developing new solutions using hardware-based experiments and evaluating the impact on large-scale power systems using real-time simulations. In this paper, the interface between the microgrid-under-test environment and the real-time simulations is evaluated in terms of accuracy and communication delays. Furthermore, a test case is presented showing the approach's ability to test microgrid control strategies for supporting the grid. It is observed that the communication delays via the physical interface depend on the simulation sampling time and do not significantly affect the accuracy in the interaction between the hardware and the simulated grid.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "16 pages, 10 figures"
    },
    {
        "paper id": "2409.01836",
        "abstract url": "https://arxiv.org/abs/2409.01836",
        "title": "Reuse and Blend: Energy-Efficient Optical Neural Network Enabled by Weight Sharing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Optical neural networks (ONN) based on micro-ring resonators (MRR) have emerged as a promising alternative to significantly accelerating the massive matrix-vector multiplication (MVM) operations in artificial intelligence (AI) applications. However, the limited scale of MRR arrays presents a challenge for AI acceleration. The disparity between the small MRR arrays and the large weight matrices in AI necessitates extensive MRR writings, including reprogramming and calibration, resulting in considerable latency and energy overheads. To address this problem, we propose a novel design methodology to lessen the need for frequent weight reloading. Specifically, we propose a reuse and blend (R&B) architecture to support efficient layer-wise and block-wise weight sharing, which allows weights to be reused several times between layers/blocks. Experimental results demonstrate the R&B system can maintain comparable accuracy with 69% energy savings and 57% latency improvement. These results highlight the promise of the R&B to enable the efficient deployment of advanced deep learning models on photonic accelerators.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01841",
        "abstract url": "https://arxiv.org/abs/2409.01841",
        "title": "BinSub: The Simple Essence of Polymorphic Type Inference for Machine Code",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recovering high-level type information in binaries is a key task in reverse engineering and binary analysis. Binaries contain very little explicit type information. The structure of binary code is incredibly flexible allowing for ad-hoc subtyping and polymorphism. Prior work has shown that precise type inference on binary code requires expressive subtyping and polymorphism. Implementations of these type system features in a binary type inference algorithm have thus-far been too inefficient to achieve widespread adoption. Recent advances in traditional type inference have achieved simple and efficient principal type inference in an ML like language with subtyping and polymorphism through the framework of algebraic subtyping. BinSub, a new binary type inference algorithm, recognizes the connection between algebraic subtyping and the type system features required to analyze binaries effectively. Using this connection, BinSub achieves simple, precise, and efficient binary type inference. We show that BinSub maintains a similar precision to prior work, while achieving a 63x improvement in average runtime for 1568 functions. We also present a formalization of BinSub and show that BinSub's type system maintains the expressiveness of prior work.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "To appear in SAS 2024"
    },
    {
        "paper id": "2409.01850",
        "abstract url": "https://arxiv.org/abs/2409.01850",
        "title": "Phase Noise Characterization of Cr:ZnS Frequency Comb using Subspace Tracking",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a comprehensive phase noise characterization of a mid-IR Cr:ZnS frequency comb. Despite their emergence as a platform for high-resolution dual-comb spectroscopy, detailed investigations into the phase noise of Cr:ZnS combs have been lacking. To address this, we use a recently proposed phase noise measurement technique that employs multi-heterodyne detection and subspace tracking. This allows for the measurement of the common mode, repetition-rate and high-order phase noise terms, and their corresponding scaling as a function of a comb-line number, using a single measurement set-up. We demonstrate that the comb under test is dominated by the common mode phase noise, while all the other phase noise terms are below the measurement noise floor (~ -120 dB rad^2/Hz), and are thereby not identifiable.",
        "subjects": [
            "physics.optics",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01859",
        "abstract url": "https://arxiv.org/abs/2409.01859",
        "title": "COOCK project Smart Port 2025 D3.2: \"Variability in Twinning Architectures\"",
        "rating": "-10",
        "keywords": [],
        "abstract": "This document is a result of the COOCK project \"Smart Port 2025: improving and accelerating the operational efficiency of a harbour eco-system through the application of intelligent technologies\". The project is mainly aimed at SMEs, but also at large corporations. Together, they form the value-chain of the harbour. The digital maturity of these actors will be increased by model and data-driven digitization. The project brings together both technology users and providers/integrators. In this report, the broad spectrum of model and data-based digitization approaches is structured, under the unifying umbrella of \"Digital Twins\". During the (currently quite ad-hoc) digitization process and in particular, the creations of Digital Twins, a variety of choices have an impact on the ultimately realised system. This document identifies three stages during which this \"variability\" appears: the Problem Space Goal Construction Stage, the (Conceptual) Architecture Design Stage and the Deployment Stage. To illustrate the workflow, two simple use-cases are used: one of a ship moving in 1 dimension and, at a different scale and level of detail, a macroscopic model of the Port of Antwerp.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01887",
        "abstract url": "https://arxiv.org/abs/2409.01887",
        "title": "Detecting and Measuring Security Implications of Entangled Domain Verification in CDN",
        "rating": "-10",
        "keywords": [],
        "abstract": "Content Delivery Networks (CDNs) offer a protection layer for enhancing the security of websites. However, a significant security flaw named Absence of Domain Verification (DVA) has become emerging recently. Although this threat is recognized, the current practices and security flaws of domain verification strategies in CDNs have not been thoroughly investigated. In this paper, we present DVAHunter, an automated system for detecting DVA vulnerabilities that can lead to domain abuse in CDNs. Our evaluation of 45 major CDN providers reveals the prevalence of DVA: most (39/45) providers do not perform any verification, and even those that do remain exploitable. Additionally, we used DVAHunter to conduct a large-scale measurement of 89M subdomains from Tranco's Top 1M sites hosted on the 45 CDNs under evaluation. Our focus was on two primary DVA exploitation scenarios: covert communication and domain hijacking. We identified over 332K subdomains vulnerable to domain abuse. This tool provides deeper insights into DVA exploitation and allows us to propose viable mitigation practices for CDN providers. To date, we have received vulnerability confirmations from 12 providers; 6 (e.g., Edgio, Kuocai) have implemented fixes, and 1 (ChinaNetCenter) are actively working on solutions based on our recommendations.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2409.01907",
        "abstract url": "https://arxiv.org/abs/2409.01907",
        "title": "Focus Agent: LLM-Powered Virtual Focus Group",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the domain of Human-Computer Interaction, focus groups represent a widely utilised yet resource-intensive methodology, often demanding the expertise of skilled moderators and meticulous preparatory efforts. This study introduces the ``Focus Agent,'' a Large Language Model (LLM) powered framework that simulates both the focus group (for data collection) and acts as a moderator in a focus group setting with human participants. To assess the data quality derived from the Focus Agent, we ran five focus group sessions with a total of 23 human participants as well as deploying the Focus Agent to simulate these discussions with AI participants. Quantitative analysis indicates that Focus Agent can generate opinions similar to those of human participants. Furthermore, the research exposes some improvements associated with LLMs acting as moderators in focus group discussions that include human participants.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "8 pages, the 24th Intelligent Virtual Agent Conference"
    },
    {
        "paper id": "2409.01933",
        "abstract url": "https://arxiv.org/abs/2409.01933",
        "title": "Inverting the sound speed profile from multi-beam echo sounder data and historical measurements -- a simulation study",
        "rating": "-10",
        "keywords": [],
        "abstract": "The ocean's opacity poses challenges for security, as new technology, e.g. underwater drones, offers new opportunities for illegal activities, such as smuggling and terrorism. A network of unmanned surface vehicles (USV) and autonomous underwater vehicles (AUV) offers a potential underwater surveillance solution, but demands high autonomy and compact hardware. For improved situational awareness and efficient operation, sonar performance models may provide the network with sensor coverage maps, but this requires constantly updated environmental information, in particular the present sound speed profile (SSP). We propose the inversion of SSPs from multibeam echo sounder (MBES) data in an environment with known topography. The method exploits the two-way travel time from the MBES to the bottom, comparing the measurements to modelled travel time for a proposed SSP model. An acoustic raytracer models the travel time for the SSP model. The inversion problem is shown to be non-unique when basing the cost function on the two-way travel time alone. This is resolved by incorporating a Tikhonov-type regularization term for inclusion of a priori knowledge on the SSPs in addition to the travel time in the final cost function. Empirical orthogonal functions (EOFs) are derived from a historical SSP data set, and variance for the EOF coefficients are determined from the same data set. The EOF coefficient distributions are assumed Gaussian and used in the regularization term to limit the search space of the inversion algorithm to physically feasible SSPs. A neural network determines the regularization parameters. The method's validity and sensitivity to errors is assessed using synthetic sonar data for the Norwegian Trench. The method accurately recovers SSPs with average root mean square errors of 0.83 m/s. For comparison, the error obtained using state-of-the-art climatology (WOA) is 2.6 m/s.",
        "subjects": [
            "eess.SP",
            "math.NA"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2409.01947",
        "abstract url": "https://arxiv.org/abs/2409.01947",
        "title": "Evaluating the precision of the HTC VIVE Ultimate Tracker with robotic and human movements under varied environmental conditions",
        "rating": "-10",
        "keywords": [],
        "abstract": "The HTC VIVE Ultimate Tracker, utilizing inside-out tracking with internal stereo cameras providing 6 DoF tracking without external cameras, offers a cost-efficient and straightforward setup for motion tracking. Initially designed for the gaming and VR industry, we explored its application beyond VR, providing source code for data capturing in both C++ and Python without requiring a VR headset. This study is the first to evaluate the tracker's precision across various experimental scenarios. To assess the robustness of the tracking precision, we employed a robotic arm as a precise and repeatable source of motion. Using the OptiTrack system as a reference, we conducted tests under varying experimental conditions: lighting, movement velocity, environmental changes caused by displacing objects in the scene, and human movement in front of the trackers, as well as varying the displacement size relative to the calibration center. On average, the HTC VIVE Ultimate Tracker achieved a precision of 4.98 mm +/- 4 mm across various conditions. The most critical factors affecting accuracy were lighting conditions, movement velocity, and range of motion relative to the calibration center. For practical evaluation, we captured human movements with 5 trackers in realistic motion capture scenarios. Our findings indicate sufficient precision for capturing human movements, validated through two tasks: a low-dynamic pick-and-place task and high-dynamic fencing movements performed by an elite athlete. Even though its precision is lower than that of conventional fixed-camera-based motion capture systems and its performance is influenced by several factors, the HTC VIVE Ultimate Tracker demonstrates adequate accuracy for a variety of motion tracking applications. Its ability to capture human or object movements outside of VR or MOCAP environments makes it particularly versatile.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01963",
        "abstract url": "https://arxiv.org/abs/2409.01963",
        "title": "Achieving Maximin Share and EFX/EF1 Guarantees Simultaneously",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of computing \\emph{fair} divisions of a set of indivisible goods among agents with \\emph{additive} valuations. For the past many decades, the literature has explored various notions of fairness, that can be primarily seen as either having \\emph{envy-based} or \\emph{share-based} lens. For the discrete setting of resource-allocation problems, \\emph{envy-free up to any good} (EFX) and \\emph{maximin share} (MMS) are widely considered as the flag-bearers of fairness notions in the above two categories, thereby capturing different aspects of fairness herein. Due to lack of existence results of these notions and the fact that a good approximation of EFX or MMS does not imply particularly strong guarantees of the other, it becomes important to understand the compatibility of EFX and MMS allocations with one another. In this work, we identify a novel way to simultaneously achieve MMS guarantees with EFX/EF1 notions of fairness, while beating the best known approximation factors [Chaudhury et al., 2021, Amanatidis et al., 2020]. Our main contribution is to constructively prove the existence of (i) a partial allocation that is both $2/3$-MMS and EFX, and (ii) a complete allocation that is both $2/3$-MMS and EF1. Our algorithms run in pseudo-polynomial time if the approximation factor for MMS is relaxed to $2/3-\\varepsilon$ for any constant $\\varepsilon > 0$ and in polynomial time if, in addition, the EFX (or EF1) guarantee is relaxed to $(1-\u03b4)$-EFX (or $(1-\u03b4)$-EF1) for any constant $\u03b4>0$. In particular, we improve from the best approximation factor known prior to our work, which computes partial allocations that are $1/2$-MMS and EFX in pseudo-polynomial time [Chaudhury et al., 2021].",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01976",
        "abstract url": "https://arxiv.org/abs/2409.01976",
        "title": "Benchmarking ZK-Friendly Hash Functions and SNARK Proving Systems for EVM-compatible Blockchains",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the rapid development of Zero-Knowledge Proofs (ZKPs), particularly Succinct Non-Interactive Arguments of Knowledge (SNARKs), benchmarking various ZK tools has become a valuable task. ZK-friendly hash functions, as key algorithms in blockchain, have garnered significant attention. Therefore, comprehensive benchmarking and evaluations of these evolving algorithms in ZK circuits present both promising opportunities and challenges. Additionally, we focus on a popular ZKP application, privacy-preserving transaction protocols, aiming to leverage SNARKs' cost-efficiency through \"batch processing\" to address high on-chain costs and compliance issues. To this end, we benchmarked three SNARK proving systems and five ZK-friendly hash functions, including our self-developed circuit templates for Poseidon2, Neptune, and GMiMC, on the bn254 curve within the circom-snarkjs framework. We also introduced the role of \"sequencer\" in our SNARK-based privacy-preserving transaction scheme to enhance efficiency and enable flexible auditing. We conducted privacy and security analyses, as well as implementation and evaluation on Ethereum Virtual Machine (EVM)-compatible chains. The results indicate that Poseidon and Poseidon2 demonstrate superior memory usage and runtime during proof generation under Groth16. Moreover, compared to the baseline, Poseidon2 not only generates proofs faster but also reduces on-chain costs by 73% on EVM chains and nearly 26% on Hedera. Our work provides a benchmark for ZK-friendly hash functions and ZK tools, while also exploring cost efficiency and compliance in ZKP-based privacy-preserving transaction protocols.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.01994",
        "abstract url": "https://arxiv.org/abs/2409.01994",
        "title": "BinPRE: Enhancing Field Inference in Binary Analysis Based Protocol Reverse Engineering",
        "rating": "-10",
        "keywords": [],
        "abstract": "Protocol reverse engineering (PRE) aims to infer the specification of network protocols when the source code is not available. Specifically, field inference is one crucial step in PRE to infer the field formats and semantics. To perform field inference, binary analysis based PRE techniques are one major approach category. However, such techniques face two key challenges - (1) the format inference is fragile when the logics of processing input messages may vary among different protocol implementations, and (2) the semantic inference is limited by inadequate and inaccurate inference rules. To tackle these challenges, we present BinPRE, a binary analysis based PRE tool. BinPRE incorporates (1) an instruction-based semantic similarity analysis strategy for format extraction; (2) a novel library composed of atomic semantic detectors for improving semantic inference adequacy; and (3) a cluster-and-refine paradigm to further improve semantic inference accuracy. We have evaluated BinPRE against five existing PRE tools, including Polyglot, AutoFormat, Tupni, BinaryInferno and DynPRE. The evaluation results on eight widely-used protocols show that BinPRE outperforms the prior PRE tools in both format and semantic inference. BinPRE achieves the perfection of 0.73 on format extraction and the F1-score of 0.74 (0.81) on semantic inference of types (functions), respectively. The field inference results of BinPRE have helped improve the effectiveness of protocol fuzzing by achieving 5-29% higher branch coverage, compared to those of the best prior PRE tool. BinPRE has also helped discover one new zero-day vulnerability, which otherwise cannot be found.",
        "subjects": [
            "cs.SE",
            "cs.CR"
        ],
        "comment": "Accepted by ACM Conference on Computer and Communications Security (CCS) 2024"
    },
    {
        "paper id": "2409.02036",
        "abstract url": "https://arxiv.org/abs/2409.02036",
        "title": "Towards Metrics for Evaluating Creativity in Visualisation Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Creativity in visualisation design is essential for designers and data scientists who need to present data in innovative ways. It is often achieved through sketching or drafting low-fidelity prototypes. However, judging this innovation is often difficult. A creative visualisation test would offer a structured approach to enhancing visual thinking and design skills, which are vital across many fields. Such a test can facilitate objective evaluation, skill identification, benchmarking, fostering innovation, and improving learning outcomes. In developing such a test, we propose focusing on four criteria: Quantity, Correctness, Novelty, and Feasibility. These criteria integrate into a test that is easy to administer. We name it the Rowen Test of Creativity in Visualisation Design; We introduce the test, scoring system and results from using eight visualisation experts.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02053",
        "abstract url": "https://arxiv.org/abs/2409.02053",
        "title": "Augmented Reality Assistive Technologies for Disabled Individuals",
        "rating": "-10",
        "keywords": [],
        "abstract": "Augmented Reality (AR) technologies hold immense potential for revolutionizing the way individuals with disabilities interact with the world. AR systems can provide real-time assistance and support by overlaying digital information over the physical environment based on the requirements of the use, hence addressing different types of disabilities. Through an in-depth analysis of four case studies, this paper aims to provide a comprehensive overview of the current-state-of-the-art in AR assistive technologies for individuals with disabilities, highlighting their potential to assist and transform their lives. The findings show the significance that AR has made to bridge the accessibility gap, while also discussing the challenges faced and ethical considerations associated with the implementation across the various cases. This is done through theory analysis, practical examples, and future projections that will motivate and seek to inspire further innovation in this very relevant area of exploration.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "18 pages, 12 figures, 5 tables"
    },
    {
        "paper id": "2409.02085",
        "abstract url": "https://arxiv.org/abs/2409.02085",
        "title": "EcoLife: Carbon-Aware Serverless Function Scheduling for Sustainable Computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work introduces ECOLIFE, the first carbon-aware serverless function scheduler to co-optimize carbon footprint and performance. ECOLIFE builds on the key insight of intelligently exploiting multi-generation hardware to achieve high performance and lower carbon footprint. ECOLIFE designs multiple novel extensions to Particle Swarm Optimization (PSO) in the context of serverless execution environment to achieve high performance while effectively reducing the carbon footprint.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02088",
        "abstract url": "https://arxiv.org/abs/2409.02088",
        "title": "SELCC: Coherent Caching over Compute-Limited Disaggregated Memory",
        "rating": "-10",
        "keywords": [],
        "abstract": "Disaggregating memory from compute offers the opportunity to better utilize stranded memory in data centers. It is important to cache data in the compute nodes and maintain cache coherence across multiple compute nodes to save on round-trip communication cost between the disaggregated memory and the compute nodes. However, the limited computing power on the disaggregated memory servers makes it challenging to maintain cache coherence among multiple compute-side caches over disaggregated shared memory. This paper introduces SELCC; a Shared-Exclusive Latch Cache Coherence protocol that maintains cache coherence without imposing any computational burden on the remote memory side. SELCC builds on a one-sided shared-exclusive latch protocol by introducing lazy latch release and invalidation messages among the compute nodes so that it can guarantee both data access atomicity and cache coherence. SELCC minimizes communication round-trips by embedding the current cache copy holder IDs into RDMA latch words and prioritizes local concurrency control over global concurrency control. We instantiate the SELCC protocol onto compute-sided cache, forming an abstraction layer over disaggregated memory. This abstraction layer provides main-memory-like APIs to upper-level applications, and thus enabling existing data structures and algorithms to function over disaggregated memory with minimal code change. To demonstrate the usability of SELCC, we implement a B-tree and three transaction concurrency control algorithms over SELCC's APIs. Micro-benchmark results show that the SELCC protocol achieves better performance compared to RPC-based cache-coherence protocols. Additionally, YCSB and TPC-C benchmarks indicate that applications over SELCC can achieve comparable or superior performance against competitors over disaggregated memory.",
        "subjects": [
            "cs.DB",
            "cs.DC",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02206",
        "abstract url": "https://arxiv.org/abs/2409.02206",
        "title": "Directed Hypercube Routing, a Generalized Lehman-Ron Theorem, and Monotonicity Testing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Motivated by applications to monotonicity testing, Lehman and Ron (JCTA, 2001) proved the existence of a collection of vertex disjoint paths between comparable sub-level sets in the directed hypercube. The main technical contribution of this paper is a new proof method that yields a generalization to their theorem: we prove the existence of two edge-disjoint collections of vertex disjoint paths. Our main conceptual contribution are conjectures on directed hypercube flows with simultaneous vertex and edge capacities of which our generalized Lehman-Ron theorem is a special case. We show that these conjectures imply directed isoperimetric theorems, and in particular, the robust directed Talagrand inequality due to Khot, Minzer, and Safra (SIAM J. on Comp, 2018). These isoperimetric inequalities, that relate the directed surface area (of a set in the hypercube) to its distance to monotonicity, have been crucial in obtaining the best monotonicity testers for Boolean functions. We believe our conjectures pave the way towards combinatorial proofs of these directed isoperimetry theorems.",
        "subjects": [
            "cs.DM",
            "cs.DS",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02214",
        "abstract url": "https://arxiv.org/abs/2409.02214",
        "title": "Checkpoint and Restart: An Energy Consumption Characterization in Clusters",
        "rating": "-10",
        "keywords": [],
        "abstract": "The fault tolerance method currently used in High Performance Computing (HPC) is the rollback-recovery method by using checkpoints. This, like any other fault tolerance method, adds an additional energy consumption to that of the execution of the application. The objective of this work is to determine the factors that affect the energy consumption of the computing nodes on homogeneous cluster, when performing checkpoint and restart operations, on SPMD (Single Program Multiple Data) applications. We have focused on the energetic study of compute nodes, contemplating different configurations of hardware and software parameters. We studied the effect of performance states (states P) and power states (states C) of processors, application problem size, checkpoint software (DMTCP) and distributed file system (NFS) configuration. The results analysis allowed to identify opportunities to reduce the energy consumption of checkpoint and restart operations.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "15 pages, 20 figures"
    },
    {
        "paper id": "2409.02222",
        "abstract url": "https://arxiv.org/abs/2409.02222",
        "title": "A Digital signature scheme based on Module-LWE and Module-SIS",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present an improved version of the digital signature scheme proposed by Sharafi and Daghigh based on Module-LWE and Module-SIS problems. Our proposed signature scheme has a notably higher security level and smaller decoding failure probability, than the ones in the Sharaf-Daghigh scheme, at the expense of enlarging the module of the underlying basic ring.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02227",
        "abstract url": "https://arxiv.org/abs/2409.02227",
        "title": "Global Optimizations & Lightweight Dynamic Logic for Concurrency",
        "rating": "-10",
        "keywords": [],
        "abstract": "Modern accelerators like GPUs are increasingly executing independent operations concurrently to improve the device's compute utilization. However, effectively harnessing it on GPUs for important primitives such as general matrix multiplications (GEMMs) remains challenging. Although modern GPUs have significant hardware and software support for GEMMs, their kernel implementations and optimizations typically assume each kernel executes in isolation and can utilize all GPU resources. This approach is highly efficient when kernels execute in isolation, but causes significant resource contention and slowdowns when kernels execute concurrently. Moreover, current approaches often only statically expose and control parallelism within an application, without considering runtime information such as varying input size and concurrent applications -- often exacerbating contention. These issues limit performance benefits from concurrently executing independent operations. Accordingly, we propose GOLDYLOC, which considers the global resources across all concurrent operations to identify performant GEMM kernels, which we call globally optimized (GO)-Kernels. Moreover, GOLDYLOC introduces a lightweight dynamic logic which considers the dynamic execution environment for available parallelism and input sizes to execute performant combinations of concurrent GEMMs on the GPU. Overall, GOLDYLOC improves performance of concurrent GEMMs on a real GPU by up to 2$\\times$ (18% geomean per workload) and provides up to 2.5$\\times$ (43% geomean per workload) speedups over sequential execution.",
        "subjects": [
            "cs.AR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02237",
        "abstract url": "https://arxiv.org/abs/2409.02237",
        "title": "Open6G OTIC: A Blueprint for Programmable O-RAN and 3GPP Testing Infrastructure",
        "rating": "-10",
        "keywords": [],
        "abstract": "Softwarized and programmable Radio Access Networks (RANs) come with virtualized and disaggregated components, increasing the supply chain robustness and the flexibility and dynamism of the network deployments. This is a key tenet of Open RAN, with open interfaces across disaggregated components specified by the O-RAN ALLIANCE. It is mandatory, however, to validate that all components are compliant with the specifications and can successfully interoperate, without performance gaps with traditional, monolithic appliances. Open Testing & Integration Centers (OTICs) are entities that can verify such interoperability and adherence to the standard through rigorous testing. However, how to design, instrument, and deploy an OTIC which can offer testing for multiple tenants, heterogeneous devices, and is ready to support automated testing is still an open challenge. In this paper, we introduce a blueprint for a programmable OTIC testing infrastructure, based on the design and deployment of the Open6G OTIC at Northeastern University, Boston, and provide insights on technical challenges and solutions for O-RAN testing at scale.",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": "Presented at IEEE VTC Fall RitiRAN Workshop, 5 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2409.02272",
        "abstract url": "https://arxiv.org/abs/2409.02272",
        "title": "Discrete-Time Maximum Likelihood Neural Distribution Steering",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper studies the problem of steering the distribution of a discrete-time dynamical system from an initial distribution to a target distribution in finite time. The formulation is fully nonlinear, allowing the use of general control policies, parametrized by neural networks. Although similar solutions have been explored in the continuous-time context, extending these techniques to systems with discrete dynamics is not trivial. The proposed algorithm results in a regularized maximum likelihood optimization problem, which is solved using machine learning techniques. After presenting the algorithm, we provide several numerical examples that illustrate the capabilities of the proposed method. We start from a simple problem that admits a solution through semidefinite programming, serving as a benchmark for the proposed approach. Then, we employ the framework in more general problems that cannot be solved using existing techniques, such as problems with non-Gaussian boundary distributions and non-linear dynamics.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted for publication in CDC 2024"
    },
    {
        "paper id": "2409.02276",
        "abstract url": "https://arxiv.org/abs/2409.02276",
        "title": "Optimizing Multi-User Uplink Cooperative Rate-Splitting Multiple Access: Efficient User Pairing and Resource Allocation",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates joint user pairing, power and time slot duration allocation in the uplink multiple-input single-output (MISO) multi-user cooperative rate-splitting multiple access (C-RSMA) networks in half-duplex (HD) mode. We assume two types of users: cell-center users (CCU) and cell-edge users (CEU); first, we propose a user pairing scheme utilizing a semi-orthogonal user selection (SUS) and a matching-game (MG)-based approach where the SUS algorithm is used to select CCU in each pair which assists in reducing inter-pair interference (IPI). Afterward, the CEU in each pair is selected by considering the highest channel gain between CCU and CEU. After pairing is performed, the communication takes place in two phases: in the first phase, in a given pair, CEUs broadcast their signal, which is received by the base station (BS) and CCUs. In the second phase, in a given pair, the CCU decodes the signal from its paired CEU, superimposes its own signal, and transmits it to the BS. We formulate a joint optimization problem in order to maximize the sum rate subject to the constraints of the power budget of the user equipment (UE) and Quality of Service (QoS) requirements at each UE. Since the formulated optimization problem is non-convex, we adopt a bi-level optimization to make the problem tractable. We decompose the original problem into two sub-problems: the user pairing sub-problem and the resource allocation sub-problem where user pairing sub-problem is independent of resource allocation sub-problem and once pairs are identified, resource allocation sub-problem is solved for a given pair. Resource allocation sub-problem is solved by invoking a successive convex approximation (SCA)-based approach. Simulation results demonstrate that the proposed SUS-MG-based algorithm with SCA outperforms other conventional schemes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02289",
        "abstract url": "https://arxiv.org/abs/2409.02289",
        "title": "Query answering in lattice-based description logic",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, the description logic LE-$\\mathcal{ALC}$ was introduced for reasoning in the semantic environment of the enriched formal contexts, and a tableaux algorithm was developed for checking the consistency of ABoxes in this logic \\cite{van2023non}. In this paper, we study the ontology-mediated query answering in LE-$\\mathcal{ALC}$. In particular, we show that several different types of queries can be answered efficiently for LE-$\\mathcal{ALC}$ knowledge bases with acyclic TBoxes using our tableaux algorithm directly or by extending it with some additional rules.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02294",
        "abstract url": "https://arxiv.org/abs/2409.02294",
        "title": "Accelerating Fortran Codes: A Method for Integrating Coarray Fortran with CUDA Fortran and OpenMP",
        "rating": "-10",
        "keywords": [],
        "abstract": "Fortran's prominence in scientific computing requires strategies to ensure both that legacy codes are efficient on high-performance computing systems, and that the language remains attractive for the development of new high-performance codes. Coarray Fortran (CAF), part of the Fortran 2008 standard introduced for parallel programming, facilitates distributed memory parallelism with a syntax familiar to Fortran programmers, simplifying the transition from single-processor to multi-processor coding. This research focuses on innovating and refining a parallel programming methodology that fuses the strengths of Intel Coarray Fortran, Nvidia CUDA Fortran, and OpenMP for distributed memory parallelism, high-speed GPU acceleration and shared memory parallelism respectively. We consider the management of pageable and pinned memory, CPU-GPU affinity in NUMA multiprocessors, and robust compiler interfacing with speed optimisation. We demonstrate our method through its application to a parallelised Poisson solver and compare the methodology, implementation, and scaling performance to that of the Message Passing Interface (MPI), finding CAF offers similar speeds with easier implementation. For new codes, this approach offers a faster route to optimised parallel computing. For legacy codes, it eases the transition to parallel computing, allowing their transformation into scalable, high-performance computing applications without the need for extensive re-design or additional syntax.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.SR",
            "cs.DC",
            "cs.PL"
        ],
        "comment": "Accepted to the Journal of Parallel and Distributed Computing"
    },
    {
        "paper id": "2409.02300",
        "abstract url": "https://arxiv.org/abs/2409.02300",
        "title": "TreeTOp: Topology Optimization using Constructive Solid Geometry Trees",
        "rating": "-10",
        "keywords": [],
        "abstract": "Feature-mapping methods for topology optimization (FMTO) facilitate direct geometry extraction by leveraging high-level geometric descriptions of the designs. However, FMTO often relies solely on Boolean unions, which can restrict the design space. This work proposes an FMTO framework leveraging an expanded set of Boolean operations, namely, union, intersection, and subtraction. The optimization process entails determining the primitives and the optimal Boolean operation tree. In particular, the framework leverages a recently proposed unified Boolean operation approach. This approach presents a continuous and differentiable function that interpolates the Boolean operations, enabling gradient-based optimization. The proposed methodology is agnostic to the specific primitive parametrization and is showcased through various numerical examples.",
        "subjects": [
            "cs.CE",
            "math.NA"
        ],
        "comment": "Submitted to Structural and Multidisciplinary Optimization"
    },
    {
        "paper id": "2409.02336",
        "abstract url": "https://arxiv.org/abs/2409.02336",
        "title": "Comparative Analysis of Learning-Based Methods for Transient Stability Assessment",
        "rating": "-10",
        "keywords": [],
        "abstract": "Transient stability and critical clearing time (CCT) are important concepts in power system protection and control. This paper explores and compares various learning-based methods for predicting CCT under uncertainties arising from renewable generation, loads, and contingencies. Specially, we introduce new definitions of transient stability (B-stablilty) and CCT from an engineering perspective. For training the models, only the initial values of system variables and contingency cases are used as features, enabling the provision of protection information based on these initial values. To enhance efficiency, a hybrid feature selection strategy combining the maximal information coefficient (MIC) and Spearman's Correlation Coefficient (SCC) is employed to reduce the feature dimension. The performance of different learning-based models is evaluated on a WSCC 9-bus system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted for presentation at the 56th North American Power Symposium (NAPS)"
    },
    {
        "paper id": "2409.02350",
        "abstract url": "https://arxiv.org/abs/2409.02350",
        "title": "Neighbourhood conditions for network stability with link uncertainty",
        "rating": "-10",
        "keywords": [],
        "abstract": "The main result relates to structured robust stability analysis of an input-output model for networks with link uncertainty. It constitutes a collection of integral quadratic constraints, which together imply robust stability of the uncertain networked dynamics. Each condition is decentralized in the sense that it depends on model data pertaining to the neighbourhood of a specific agent. By contrast, pre-existing conditions for the network model are link-wise decentralized, with each involving conservatively more localized problem data. A numerical example is presented to illustrate the advantage of the new broader neighbourhood conditions.",
        "subjects": [
            "eess.SY",
            "math.DS"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2403.14931"
    },
    {
        "paper id": "2409.02352",
        "abstract url": "https://arxiv.org/abs/2409.02352",
        "title": "Upstream Allocation of Bidirectional Load Demand by Power Packetization",
        "rating": "-10",
        "keywords": [],
        "abstract": "The power packet dispatching system has been studied for power management with strict tie to an accompanying information system through power packetization. In the system, integrated units of transfer of power and information, called power packets, are delivered through a network of apparatuses called power packet routers. This paper proposes upstream allocation of a bidirectional load demand represented by a sequence of power packets to power sources. We first develop a scheme of power packet routing for upstream allocation of load demand with full integration of power and information transfer. The routing scheme is then proved to enable packetized management of bidirectional load demand, which is of practical importance for applicability to, e.g., electric drives in motoring and regenerating operations. We present a way of packetizing the bidirectional load demand and realizing the power and information flow under the upstream allocation scheme. The viability of the proposed methods is demonstrated through experiments.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.02358",
        "abstract url": "https://arxiv.org/abs/2409.02358",
        "title": "Teen Talk: The Good, the Bad, and the Neutral of Adolescent Social Media Use",
        "rating": "-10",
        "keywords": [],
        "abstract": "The debate on whether social media has a net positive or negative effect on youth is ongoing. Therefore, we conducted a thematic analysis on 2,061 posts made by 1,038 adolescents aged 15-17 on an online peer-support platform to investigate the ways in which these teens discussed popular social media platforms in their posts and to identify differences in their experiences across platforms. Our findings revealed four main emergent themes for the ways in which social media was discussed: 1) Sharing negative experiences or outcomes of social media use (58%, n = 1,095), 2) Attempts to connect with others (45%, n = 922), 3) Highlighting the positive side of social media use (20%, n = 409), and 4) Seeking information (20%, n = 491). Overall, while sharing about negative experiences was more prominent, teens also discussed balanced perspectives of connection-seeking, positive experiences, and information support on social media that should not be discounted. Moreover, we found statistical significance for how these experiences differed across social media platforms. For instance, teens were most likely to seek romantic relationships on Snapchat and self-promote on YouTube. Meanwhile, Instagram was mentioned most frequently for body shaming, and Facebook was the most commonly discussed platform for privacy violations (mostly from parents). The key takeaway from our study is that the benefits and drawbacks of teens' social media usage can co-exist and net effects (positive or negative) can vary across different teens across various contexts. As such, we advocate for mitigating the negative experiences and outcomes of social media use as voiced by teens, to improve, rather than limit or restrict, their overall social media experience. We do this by taking an affordance perspective that aims to promote the digital well-being and online safety of youth \"by design.\"",
        "subjects": [
            "cs.HC"
        ],
        "comment": "36 pages"
    },
    {
        "paper id": "2409.02364",
        "abstract url": "https://arxiv.org/abs/2409.02364",
        "title": "Examining Caregiving Roles to Differentiate the Effects of Using a Mobile App for Community Oversight for Privacy and Security",
        "rating": "-10",
        "keywords": [],
        "abstract": "We conducted a 4-week field study with 101 smartphone users who self-organized into 22 small groups of family, friends, and neighbors to use ``CO-oPS,'' a mobile app for co-managing mobile privacy and security. We differentiated between those who provided oversight (i.e., caregivers) and those who did not (i.e., caregivees) to examine differential effects on their experiences and behaviors while using CO-oPS. Caregivers reported higher power use, community trust, belonging, collective efficacy, and self-efficacy than caregivees. Both groups' self-efficacy and collective efficacy for mobile privacy and security increased after using CO-oPS. However, this increase was significantly stronger for caregivees. Our research demonstrates how community-based approaches can benefit people who need additional help managing their digital privacy and security. We provide recommendations to support community-based oversight for managing privacy and security within communities of different roles and skills.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02366",
        "abstract url": "https://arxiv.org/abs/2409.02366",
        "title": "The Hidden Costs of Automation: An Empirical Study on GitHub Actions Workflow Maintenance",
        "rating": "-10",
        "keywords": [],
        "abstract": "GitHub Actions (GA) is an orchestration platform that streamlines the automatic execution of software engineering tasks such as building, testing, and deployment. Although GA workflows are the primary means for automation, according to our experience and observations, human intervention is necessary to correct defects, update dependencies, or refactor existing workflow files. In fact, previous research has shown that software artifacts similar to workflows, such as build files and bots, can introduce additional maintenance tasks in software projects. This suggests that workflow files, which are also used to automate repetitive tasks in professional software production, may generate extra workload for developers. However, the nature of such effort has not been well studied. This paper presents a large-scale empirical investigation towards characterizing the maintenance of GA workflows by studying the evolution of workflow files in almost 200 mature GitHub projects across ten programming languages. Our findings largely confirm the results of previous studies on the maintenance of similar artifacts, while also revealing GA-specific insights such as bug fixing and CI/CD improvement being among the major drivers of GA maintenance. A direct implication is that practitioners should be aware of proper resource planning and allocation for maintaining GA workflows, thus exposing the ``hidden costs of automation.'' Our findings also call for identifying and documenting best practices for such maintenance, and for enhanced tool features supporting dependency tracking and better error reporting of workflow specifications.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02381",
        "abstract url": "https://arxiv.org/abs/2409.02381",
        "title": "FlexBSO: Flexible Block Storage Offload for Datacenters",
        "rating": "-10",
        "keywords": [],
        "abstract": "Efficient virtualization of CPU and memory is standardized and mature. Capabilities such as Intel VT-x [3] have been added by manufacturers for efficient hypervisor support. In contrast, virtualization of a block device and its presentation to the virtual machines on the host can be done in multiple ways. Indeed, hyperscalers develop in-house solutions to improve performance and cost-efficiency of their storage solutions for datacenters. Unfortunately, these storage solutions are based on specialized hardware and software which are not publicly available. The traditional solution is to expose virtual block device to the VM through a paravirtualized driver like virtio [2]. virtio provides significantly better performance than real block device driver emulation because of host OS and guest OS cooperation. The IO requests are then fulfilled by the host OS either with a local block device such as an SSD drive or with some form of disaggregated storage over the network like NVMe-oF or iSCSI. There are three main problems to the traditional solution. 1) Cost. IO operations consume host CPU cycles due to host OS involvement. These CPU cycles are doing useless work from the application point of view. 2) Inflexibility. Any change of the virtualized storage stack requires host OS and/or guest OS cooperation and cannot be done silently in production. 3) Performance. IO operations are causing recurring VM EXITs to do the transition from non-root mode to root mode on the host CPU. This results into excessive IO performance impact. We propose FlexBSO, a hardware-assisted solution, which solves all the mentioned issues. Our prototype is based on the publicly available Bluefield-2 SmartNIC with NVIDIA SNAP support, hence can be deployed without any obstacles.",
        "subjects": [
            "cs.NI",
            "cs.OS"
        ],
        "comment": "4 pages, 6 figures"
    },
    {
        "paper id": "2409.02386",
        "abstract url": "https://arxiv.org/abs/2409.02386",
        "title": "Dissecting Payload-based Transaction Phishing on Ethereum",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, a more advanced form of phishing has arisen on Ethereum, surpassing early-stage, simple transaction phishing. This new form, which we refer to as payload-based transaction phishing (PTXPHISH), manipulates smart contract interactions through the execution of malicious payloads to deceive users. PTXPHISH has rapidly emerged as a significant threat, leading to incidents that caused losses exceeding \\$70 million in 2023 reports. Despite its substantial impact, no previous studies have systematically explored PTXPHISH In this paper, we present the first comprehensive study of the PTXPHISH on Ethereum. Firstly, we conduct a long-term data collection and put considerable effort into establishing the first ground-truth PTXPHISH dataset, consisting of 5,000 phishing transactions. Based on the dataset, we dissect PTXPHISH, categorizing phishing tactics into four primary categories and eleven sub-categories. Secondly, we propose a rule-based multi-dimensional detection approach to identify PTXPHISH, achieving over 99% accuracy in the ground-truth dataset. Finally, we conducted a large-scale detection spanning 300 days and discovered a total of 130,637 phishing transactions on Ethereum, resulting in losses exceeding $341.9 million. Our in-depth analysis of these phishing transactions yielded valuable and insightful findings. Furthermore, our work has made significant contributions to mitigating real-world threats. We have reported 1,726 phishing addresses to the community, accounting for 42.7% of total community contributions during the same period. Additionally, we have sent 2,539 on-chain alert messages, assisting 1,980 victims. This research serves as a valuable reference in combating the emerging PTXPHISH and safeguarding users' assets.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02396",
        "abstract url": "https://arxiv.org/abs/2409.02396",
        "title": "A Dynamic Resource Scheduling Algorithm Based on Traffic Prediction for Coexistence of eMBB and Random Arrival URLLC",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we propose a joint design for the coexistence of enhanced mobile broadband (eMBB) and ultra-reliable and random low-latency communication (URLLC) with different transmission time intervals (TTI): an eMBB scheduler operating at the beginning of each eMBB TTI to decide the coding redundancy of eMBB code blocks, and a URLLC scheduler at the beginning of each mini-slot to perform immediate preemption to ensure that the randomly arriving URLLC traffic is allocated with enough radio resource and the eMBB traffic keeps acceptable one-shot transmission successful probability and throughput. The framework for schedulers under hybrid-TTI is developed and a method to configure eMBB code block based on URLLC traffic arrival prediction is implemented. Simulations show that our work improves the throughput of eMBB traffic without sacrificing the reliablity while supporting randomly arriving URLLC traffic.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02398",
        "abstract url": "https://arxiv.org/abs/2409.02398",
        "title": "Sharing Analysis in the Pawns Compiler",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pawns is a programming language under development that supports algebraic data types, polymorphism, higher order functions and \"pure\" declarative programming. It also supports impure imperative features including destructive update of shared data structures via pointers, allowing significantly increased efficiency for some operations. A novelty of Pawns is that all impure \"effects\" must be made obvious in the source code and they can be safely encapsulated in pure functions in a way that is checked by the compiler. Execution of a pure function can perform destructive updates on data structures that are local to or eventually returned from the function without risking modification of the data structures passed to the function. This paper describes the sharing analysis which allows impurity to be encapsulated. Aspects of the analysis are similar to other published work, but in addition it handles explicit pointers and destructive update, higher order functions including closures and pre- and post-conditions concerning sharing for functions.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "This is a revision of a previously published version"
    },
    {
        "paper id": "2409.02408",
        "abstract url": "https://arxiv.org/abs/2409.02408",
        "title": "Force-Limited Control of Wave Energy Converters using a Describing Function Linearization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Actuator saturation is a common nonlinearity. In wave energy conversion, force saturation conveniently limits drivetrain size and cost with minimal impact on energy generation. However, such nonlinear dynamics typically demand numerical simulation, which increases computational cost and diminishes intuition. This paper instead uses describing functions to approximate a force saturation nonlinearity as a linear impedance mismatch. In the frequency domain, the impact of controller impedance mismatch (such as force limit, finite bandwidth, or parameter error) on electrical power production is shown analytically and graphically for a generic nondimensionalized single degree of freedom wave energy converter in regular waves. Results are visualized with Smith charts. Notably, systems with a specific ratio of reactive to real mechanical impedance are least sensitive to force limits, a criteria which conflicts with resonance and bandwidth considerations. The describing function method shows promise to enable future studies such as large-scale design optimization and co-design.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages, 7 figures. For code, see https://github.com/symbiotic-engineering/IFAC_CAMS_2024/ . To be presented at IFAC CAMS 2024 conference and to appear in IFAC-PapersOnLine"
    },
    {
        "paper id": "2409.02424",
        "abstract url": "https://arxiv.org/abs/2409.02424",
        "title": "Enhancing Information Freshness: An AoI Optimized Markov Decision Process Dedicated In the Underwater Task",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ocean exploration utilizing autonomous underwater vehicles (AUVs) via reinforcement learning (RL) has emerged as a significant research focus. However, underwater tasks have mostly failed due to the observation delay caused by acoustic communication in the Internet of underwater things. In this study, we present an AoI optimized Markov decision process (AoI-MDP) to improve the performance of underwater tasks. Specifically, AoI-MDP models observation delay as signal delay through statistical signal processing, and includes this delay as a new component in the state space. Additionally, we introduce wait time in the action space, and integrate AoI with reward functions to achieve joint optimization of information freshness and decision-making for AUVs leveraging RL for training. Finally, we apply this approach to the multi-AUV data collection task scenario as an example. Simulation results highlight the feasibility of AoI-MDP, which effectively minimizes AoI while showcasing superior performance in the task. To accelerate relevant research in this field, the code for simulation will be released as open-source in the future.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02432",
        "abstract url": "https://arxiv.org/abs/2409.02432",
        "title": "Preliminary Insights on Industry Practices for Addressing Fairness Debt",
        "rating": "-10",
        "keywords": [],
        "abstract": "Context: This study explores how software professionals identify and address biases in AI systems within the software industry, focusing on practical knowledge and real-world applications. Goal: We aimed to understand the strategies employed by practitioners to manage bias and their implications for fairness debt. Method: We used a qualitative research method, gathering insights from industry professionals through interviews and employing thematic analysis to explore the collected data. Findings: Professionals identify biases through discrepancies in model outputs, demographic inconsistencies, and issues with training data. They address these biases using strategies such as enhanced data management, model adjustments, crisis management, improving team diversity, and ethical analysis. Conclusion: Our paper presents initial evidence on addressing fairness debt and provides a foundation for developing structured guidelines to manage fairness-related issues in AI systems.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02433",
        "abstract url": "https://arxiv.org/abs/2409.02433",
        "title": "From Literature to Practice: Exploring Fairness Testing Tools for the Software Industry Adoption",
        "rating": "-10",
        "keywords": [],
        "abstract": "In today's world, we need to ensure that AI systems are fair and unbiased. Our study looked at tools designed to test the fairness of software to see if they are practical and easy for software developers to use. We found that while some tools are cost-effective and compatible with various programming environments, many are hard to use and lack detailed instructions. They also tend to focus on specific types of data, which limits their usefulness in real-world situations. Overall, current fairness testing tools need significant improvements to better support software developers in creating fair and equitable technology. We suggest that new tools should be user-friendly, well-documented, and flexible enough to handle different kinds of data, helping developers identify and fix biases early in the development process. This will lead to more trustworthy and fair software for everyone.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02436",
        "abstract url": "https://arxiv.org/abs/2409.02436",
        "title": "Occlusion-Based Cooperative Transport for Concave Objects with a Swarm of Miniature Mobile Robots",
        "rating": "-10",
        "keywords": [],
        "abstract": "An occlusion based strategy for collective transport of a concave object using a swarm of mobile robots has been proposed in this paper. We aim to overcome the challenges of transporting concave objects using decentralized approach. The interesting aspect of this task is that the agents have no prior knowledge about the geometry of the object and do not explicitly communicate with each other. The concept is to eliminate the concavity of the object by filling a number of robots in its cavity and then carry out an occlusion based transport strategy on the newly formed convex object or \"pseudo object\". We divide our work into two parts: concavity filling of various concave objects and occlusion based collective transport of convex objects.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02443",
        "abstract url": "https://arxiv.org/abs/2409.02443",
        "title": "Exploring the applicability of Large Language Models to citation context analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Unlike traditional citation analysis -- which assumes that all citations in a paper are equivalent -- citation context analysis considers the contextual information of individual citations. However, citation context analysis requires creating large amounts of data through annotation, which hinders the widespread use of this methodology. This study explored the applicability of Large Language Models (LLMs) -- particularly ChatGPT -- to citation context analysis by comparing LLMs and human annotation results. The results show that the LLMs annotation is as good as or better than the human annotation in terms of consistency but poor in terms of predictive performance. Thus, having LLMs immediately replace human annotators in citation context analysis is inappropriate. However, the annotation results obtained by LLMs can be used as reference information when narrowing the annotation results obtained by multiple human annotators to one, or LLMs can be used as one of the annotators when it is difficult to prepare sufficient human annotators. This study provides basic findings important for the future development of citation context analyses.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    }
]