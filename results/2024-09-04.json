[
    {
        "paper id": "2409.02882",
        "abstract url": "https://arxiv.org/abs/2409.02882",
        "title": "Benchmarking Spurious Bias in Few-Shot Image Classifiers",
        "rating": "2.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Few-shot image classifiers are designed to recognize and classify new data with minimal supervision and limited data but often show reliance on spurious correlations between classes and spurious attributes, known as spurious bias. Spurious correlations commonly hold in certain samples and few-shot classifiers can suffer from spurious bias induced from them. There is an absence of an automatic benchmarking system to assess the robustness of few-shot classifiers against spurious bias. In this paper, we propose a systematic and rigorous benchmark framework, termed FewSTAB, to fairly demonstrate and quantify varied degrees of robustness of few-shot classifiers to spurious bias. FewSTAB creates few-shot evaluation tasks with biased attributes so that using them for predictions can demonstrate poor performance. To construct these tasks, we propose attribute-based sample selection strategies based on a pre-trained vision-language model, eliminating the need for manual dataset curation. This allows FewSTAB to automatically benchmark spurious bias using any existing test data. FewSTAB offers evaluation results in a new dimension along with a new design guideline for building robust classifiers. Moreover, it can benchmark spurious bias in varied degrees and enable designs for varied degrees of robustness. Its effectiveness is demonstrated through experiments on ten few-shot learning methods across three datasets. We hope our framework can inspire new designs of robust few-shot classifiers. Our code is available at https://github.com/gtzheng/FewSTAB.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted to ECCV 2024"
    },
    {
        "paper id": "2409.02451",
        "abstract url": "https://arxiv.org/abs/2409.02451",
        "title": "Fast, High-Quality and Parameter-Efficient Articulatory Synthesis using Differentiable DSP",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Articulatory trajectories like electromagnetic articulography (EMA) provide a low-dimensional representation of the vocal tract filter and have been used as natural, grounded features for speech synthesis. Differentiable digital signal processing (DDSP) is a parameter-efficient framework for audio synthesis. Therefore, integrating low-dimensional EMA features with DDSP can significantly enhance the computational efficiency of speech synthesis. In this paper, we propose a fast, high-quality, and parameter-efficient DDSP articulatory vocoder that can synthesize speech from EMA, F0, and loudness. We incorporate several techniques to solve the harmonics / noise imbalance problem, and add a multi-resolution adversarial loss for better synthesis quality. Our model achieves a transcription word error rate (WER) of 6.67% and a mean opinion score (MOS) of 3.74, with an improvement of 1.63% and 0.16 compared to the state-of-the-art (SOTA) baseline. Our DDSP vocoder is 4.9x faster than the baseline on CPU during inference, and can generate speech of comparable quality with only 0.4M parameters, in contrast to the 9M parameters required by the SOTA.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": "accepted for Spoken Language Technology Workshop 2024"
    },
    {
        "paper id": "2409.02565",
        "abstract url": "https://arxiv.org/abs/2409.02565",
        "title": "Efficient Extraction of Noise-Robust Discrete Units from Self-Supervised Speech Models",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Continuous speech can be converted into a discrete sequence by deriving discrete units from the hidden features of self-supervised learned (SSL) speech models. Although SSL models are becoming larger and trained on more data, they are often sensitive to real-life distortions like additive noise or reverberation, which translates to a shift in discrete units. We propose a parameter-efficient approach to generate noise-robust discrete units from pre-trained SSL models by training a small encoder-decoder model, with or without adapters, to simultaneously denoise and discretise the hidden features of the SSL model. The model learns to generate a clean discrete sequence for a noisy utterance, conditioned on the SSL features. The proposed denoiser outperforms several pre-training methods on the tasks of noisy discretisation and noisy speech recognition, and can be finetuned to the target environment with a few recordings of unlabeled target data.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Accepted at SLT2024"
    },
    {
        "paper id": "2409.02976",
        "abstract url": "https://arxiv.org/abs/2409.02976",
        "title": "Hallucination Detection in LLMs: Fast and Memory-Efficient Finetuned Models",
        "rating": "2",
        "keywords": [
            [
                "Memory-Efficient"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Uncertainty estimation is a necessary component when implementing AI in high-risk settings, such as autonomous cars, medicine, or insurances. Large Language Models (LLMs) have seen a surge in popularity in recent years, but they are subject to hallucinations, which may cause serious harm in high-risk settings. Despite their success, LLMs are expensive to train and run: they need a large amount of computations and memory, preventing the use of ensembling methods in practice. In this work, we present a novel method that allows for fast and memory-friendly training of LLM ensembles. We show that the resulting ensembles can detect hallucinations and are a viable approach in practice as only one GPU is needed for training and inference.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "5 pages, 3 figures"
    },
    {
        "paper id": "2409.02449",
        "abstract url": "https://arxiv.org/abs/2409.02449",
        "title": "What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "This paper explores the pitfalls in evaluating multilingual automatic speech recognition (ASR) models, with a particular focus on Indic language scripts. We investigate the text normalization routine employed by leading ASR models, including OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer, and their unintended consequences on performance metrics. Our research reveals that current text normalization practices, while aiming to standardize ASR outputs for fair comparison, by removing inconsistencies such as variations in spelling, punctuation, and special characters, are fundamentally flawed when applied to Indic scripts. Through empirical analysis using text similarity scores and in-depth linguistic examination, we demonstrate that these flaws lead to artificially inflated performance metrics for Indic languages. We conclude by proposing a shift towards developing normalization routines that leverage native linguistic expertise, ensuring more robust and accurate evaluations of multilingual ASR models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "Sumbitted to EMNLP 2024"
    },
    {
        "paper id": "2409.03043",
        "abstract url": "https://arxiv.org/abs/2409.03043",
        "title": "Can Your Generative Model Detect Out-of-Distribution Covariate Shift?",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Detecting Out-of-Distribution~(OOD) sensory data and covariate distribution shift aims to identify new test examples with different high-level image statistics to the captured, normal and In-Distribution (ID) set. Existing OOD detection literature largely focuses on semantic shift with little-to-no consensus over covariate shift. Generative models capture the ID data in an unsupervised manner, enabling them to effectively identify samples that deviate significantly from this learned distribution, irrespective of the downstream task. In this work, we elucidate the ability of generative models to detect and quantify domain-specific covariate shift through extensive analyses that involves a variety of models. To this end, we conjecture that it is sufficient to detect most occurring sensory faults (anomalies and deviations in global signals statistics) by solely modeling high-frequency signal-dependent and independent details. We propose a novel method, CovariateFlow, for OOD detection, specifically tailored to covariate heteroscedastic high-frequency image-components using conditional Normalizing Flows (cNFs). Our results on CIFAR10 vs. CIFAR10-C and ImageNet200 vs. ImageNet200-C demonstrate the effectiveness of the method by accurately detecting OOD covariate shift. This work contributes to enhancing the fidelity of imaging systems and aiding machine learning models in OOD detection in the presence of covariate shift.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2409.03059",
        "abstract url": "https://arxiv.org/abs/2409.03059",
        "title": "Quantification of stylistic differences in human- and ASR-produced transcripts of African American English",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "Common measures of accuracy used to assess the performance of automatic speech recognition (ASR) systems, as well as human transcribers, conflate multiple sources of error. Stylistic differences, such as verbatim vs non-verbatim, can play a significant role in ASR performance evaluation when differences exist between training and test datasets. The problem is compounded for speech from underrepresented varieties, where the speech to orthography mapping is not as standardized. We categorize the kinds of stylistic differences between 6 transcription versions, 4 human- and 2 ASR-produced, of 10 hours of African American English (AAE) speech. Focusing on verbatim features and AAE morphosyntactic features, we investigate the interactions of these categories with how well transcripts can be compared via word error rate (WER). The results, and overall analysis, help clarify how ASR outputs are a function of the decisions made by the training data's human transcribers.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Published in Interspeech 2024 Proceedings, 5 pages excluding references, 5 figures"
    },
    {
        "paper id": "2409.02448",
        "abstract url": "https://arxiv.org/abs/2409.02448",
        "title": "Detecting Korean Food Using Image using Hierarchical Model",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "A solution was made available for Korean Food lovers who have dietary restrictions to identify the Korean food before consuming. Just by uploading a clear photo of the dish, people can get to know what they are eating. Image processing techniques together with machine learning helped to come up with this solution.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02465",
        "abstract url": "https://arxiv.org/abs/2409.02465",
        "title": "DetectiveQA: Evaluating Long-Context Reasoning on Detective Novels",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the rapid advancement of Large Language Models (LLMs), long-context information understanding and processing have become a hot topic in academia and industry. However, benchmarks for evaluating the ability of LLMs to handle long-context information do not seem to have kept pace with the development of LLMs. Despite the emergence of various long-context evaluation benchmarks, the types of capability assessed are still limited, without new capability dimensions. In this paper, we introduce DetectiveQA, a narrative reasoning benchmark featured with an average context length of over 100K tokens. DetectiveQA focuses on evaluating the long-context reasoning ability of LLMs, which not only requires a full understanding of context but also requires extracting important evidences from the context and reasoning according to extracted evidences to answer the given questions. This is a new dimension of capability evaluation, which is more in line with the current intelligence level of LLMs. We use detective novels as data sources, which naturally have various reasoning elements. Finally, we manually annotated 600 questions in Chinese and then also provided an English edition of the context information and questions. We evaluate many long-context LLMs on DetectiveQA, including commercial and open-sourced models, and the results indicate that existing long-context LLMs still require significant advancements to effectively process true long-context dependency questions.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02466",
        "abstract url": "https://arxiv.org/abs/2409.02466",
        "title": "CUEMPATHY: A Counseling Speech Dataset for Psychotherapy Research",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Psychotherapy or counseling is typically conducted through spoken conversation between a therapist and a client. Analyzing the speech characteristics of psychotherapeutic interactions can help understand the factors associated with effective psychotherapy. This paper introduces CUEMPATHY, a large-scale speech dataset collected from actual counseling sessions. The dataset consists of 156 counseling sessions involving 39 therapist-client dyads. The process of speech data collection, subjective ratings (one observer and two client ratings), and transcription are described. An automatic speech and text processing system is developed to locate the time stamps of speaker turns in each session. Examining the relationships among the three subjective ratings suggests that observer and client ratings have no significant correlation, while the client-rated measures are significantly correlated. The intensity similarity between the therapist and the client, measured by the averaged absolute difference of speaker-turn-level intensities, is associated with the psychotherapy outcomes. Recent studies on the acoustic and linguistic characteristics of the CUEMPATHY are introduced.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Accepted by ISCSLP 2022"
    },
    {
        "paper id": "2409.02474",
        "abstract url": "https://arxiv.org/abs/2409.02474",
        "title": "A Comparative Study on Large Language Models for Log Parsing",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Background: Log messages provide valuable information about the status of software systems. This information is provided in an unstructured fashion and automated approaches are applied to extract relevant parameters. To ease this process, log parsing can be applied, which transforms log messages into structured log templates. Recent advances in language models have led to several studies that apply ChatGPT to the task of log parsing with promising results. However, the performance of other state-of-the-art large language models (LLMs) on the log parsing task remains unclear. Aims: In this study, we investigate the current capability of state-of-the-art LLMs to perform log parsing. Method: We select six recent LLMs, including both paid proprietary (GPT-3.5, Claude 2.1) and four free-to-use open models, and compare their performance on system logs obtained from a selection of mature open-source projects. We design two different prompting approaches and apply the LLMs on 1, 354 log templates across 16 different projects. We evaluate their effectiveness, in the number of correctly identified templates, and the syntactic similarity between the generated templates and the ground truth. Results: We found that free-to-use models are able to compete with paid models, with CodeLlama extracting 10% more log templates correctly than GPT-3.5. Moreover, we provide qualitative insights into the usability of language models (e.g., how easy it is to use their responses). Conclusions: Our results reveal that some of the smaller, free-to-use LLMs can considerably assist log parsing compared to their paid proprietary competitors, especially code-specialized models.",
        "subjects": [
            "cs.SE",
            "cs.CL"
        ],
        "comment": "Accepted for publication in the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM '24)"
    },
    {
        "paper id": "2409.02490",
        "abstract url": "https://arxiv.org/abs/2409.02490",
        "title": "TP-GMOT: Tracking Generic Multiple Object by Textual Prompt with Motion-Appearance Cost (MAC) SORT",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "While Multi-Object Tracking (MOT) has made substantial advancements, it is limited by heavy reliance on prior knowledge and limited to predefined categories. In contrast, Generic Multiple Object Tracking (GMOT), tracking multiple objects with similar appearance, requires less prior information about the targets but faces challenges with variants like viewpoint, lighting, occlusion, and resolution. Our contributions commence with the introduction of the \\textbf{\\text{Refer-GMOT dataset}} a collection of videos, each accompanied by fine-grained textual descriptions of their attributes. Subsequently, we introduce a novel text prompt-based open-vocabulary GMOT framework, called \\textbf{\\text{TP-GMOT}}, which can track never-seen object categories with zero training examples. Within \\text{TP-GMOT} framework, we introduce two novel components: (i) {\\textbf{\\text{TP-OD}}, an object detection by a textual prompt}, for accurately detecting unseen objects with specific characteristics. (ii) Motion-Appearance Cost SORT \\textbf{\\text{MAC-SORT}}, a novel object association approach that adeptly integrates motion and appearance-based matching strategies to tackle the complex task of tracking multiple generic objects with high similarity. Our contributions are benchmarked on the \\text{Refer-GMOT} dataset for GMOT task. Additionally, to assess the generalizability of the proposed \\text{TP-GMOT} framework and the effectiveness of \\text{MAC-SORT} tracker, we conduct ablation studies on the DanceTrack and MOT20 datasets for the MOT task. Our dataset, code, and models will be publicly available at: https://fsoft-aic.github.io/TP-GMOT",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02519",
        "abstract url": "https://arxiv.org/abs/2409.02519",
        "title": "Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts",
        "rating": "1",
        "keywords": [
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "We propose misogyny detection as an Argumentative Reasoning task and we investigate the capacity of large language models (LLMs) to understand the implicit reasoning used to convey misogyny in both Italian and English. The central aim is to generate the missing reasoning link between a message and the implied meanings encoding the misogyny. Our study uses argumentation theory as a foundation to form a collection of prompts in both zero-shot and few-shot settings. These prompts integrate different techniques, including chain-of-thought reasoning and augmented knowledge. Our findings show that LLMs fall short on reasoning capabilities about misogynistic comments and that they mostly rely on their implicit knowledge derived from internalized common stereotypes about women to generate implied assumptions, rather than on inductive reasoning.",
        "subjects": [
            "cs.CL",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02555",
        "abstract url": "https://arxiv.org/abs/2409.02555",
        "title": "Low-Resolution Object Recognition with Cross-Resolution Relational Contrastive Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recognizing objects in low-resolution images is a challenging task due to the lack of informative details. Recent studies have shown that knowledge distillation approaches can effectively transfer knowledge from a high-resolution teacher model to a low-resolution student model by aligning cross-resolution representations. However, these approaches still face limitations in adapting to the situation where the recognized objects exhibit significant representation discrepancies between training and testing images. In this study, we propose a cross-resolution relational contrastive distillation approach to facilitate low-resolution object recognition. Our approach enables the student model to mimic the behavior of a well-trained teacher model which delivers high accuracy in identifying high-resolution objects. To extract sufficient knowledge, the student learning is supervised with contrastive relational distillation loss, which preserves the similarities in various relational structures in contrastive representation space. In this manner, the capability of recovering missing details of familiar low-resolution objects can be effectively enhanced, leading to a better knowledge transfer. Extensive experiments on low-resolution object classification and low-resolution face recognition clearly demonstrate the effectiveness and adaptability of our approach.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "comment": "This paper is accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)"
    },
    {
        "paper id": "2409.02567",
        "abstract url": "https://arxiv.org/abs/2409.02567",
        "title": "Evaluation Study on SAM 2 for Class-agnostic Instance-level Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Segment Anything Model (SAM) has demonstrated powerful zero-shot segmentation performance in natural scenes. The recently released Segment Anything Model 2 (SAM2) has further heightened researchers' expectations towards image segmentation capabilities. To evaluate the performance of SAM2 on class-agnostic instance-level segmentation tasks, we adopt different prompt strategies for SAM2 to cope with instance-level tasks for three relevant scenarios: Salient Instance Segmentation (SIS), Camouflaged Instance Segmentation (CIS), and Shadow Instance Detection (SID). In addition, to further explore the effectiveness of SAM2 in segmenting granular object structures, we also conduct detailed tests on the high-resolution Dichotomous Image Segmentation (DIS) benchmark to assess the fine-grained segmentation capability. Qualitative and quantitative experimental results indicate that the performance of SAM2 varies significantly across different scenarios. Besides, SAM2 is not particularly sensitive to segmenting high-resolution fine details. We hope this technique report can drive the emergence of SAM2-based adapters, aiming to enhance the performance ceiling of large vision models on class-agnostic instance segmentation tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02569",
        "abstract url": "https://arxiv.org/abs/2409.02569",
        "title": "More is More: Addition Bias in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we investigate the presence of additive bias in Large Language Models (LLMs), drawing a parallel to the cognitive bias observed in humans where individuals tend to favor additive over subtractive changes. Using a series of controlled experiments, we tested various LLMs, including GPT-3.5 Turbo, Claude 3.5 Sonnet, Mistral, Math$\u03a3$tral, and Llama 3.1, on tasks designed to measure their propensity for additive versus subtractive modifications. Our findings demonstrate a significant preference for additive changes across all tested models. For example, in a palindrome creation task, Llama 3.1 favored adding letters 97.85% of the time over removing them. Similarly, in a Lego tower balancing task, GPT-3.5 Turbo chose to add a brick 76.38% of the time rather than remove one. In a text summarization task, Mistral 7B produced longer summaries in 59.40% to 75.10% of cases when asked to improve its own or others' writing. These results indicate that, similar to humans, LLMs exhibit a marked additive bias, which might have implications when LLMs are used on a large scale. Addittive bias might increase resource use and environmental impact, leading to higher economic costs due to overconsumption and waste. This bias should be considered in the development and application of LLMs to ensure balanced and efficient problem-solving approaches.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.HC"
        ],
        "comment": "25 pages, 8 figures"
    },
    {
        "paper id": "2409.02596",
        "abstract url": "https://arxiv.org/abs/2409.02596",
        "title": "An Analysis of Linear Complexity Attention Substitutes with BEST-RQ",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Self-Supervised Learning (SSL) has proven to be effective in various domains, including speech processing. However, SSL is computationally and memory expensive. This is in part due the quadratic complexity of multi-head self-attention (MHSA). Alternatives for MHSA have been proposed and used in the speech domain, but have yet to be investigated properly in an SSL setting. In this work, we study the effects of replacing MHSA with recent state-of-the-art alternatives that have linear complexity, namely, HyperMixing, Fastformer, SummaryMixing, and Mamba. We evaluate these methods by looking at the speed, the amount of VRAM consumed, and the performance on the SSL MP3S benchmark. Results show that these linear alternatives maintain competitive performance compared to MHSA while, on average, decreasing VRAM consumption by around 20% to 60% and increasing speed from 7% to 65% for input sequences ranging from 20 to 80 seconds.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted in the IEEE Soken Language Technology Workshop 2024"
    },
    {
        "paper id": "2409.02615",
        "abstract url": "https://arxiv.org/abs/2409.02615",
        "title": "USEF-TSE: Universal Speaker Embedding Free Target Speaker Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Target speaker extraction aims to isolate the voice of a specific speaker from mixed speech. Traditionally, this process has relied on extracting a speaker embedding from a reference speech, necessitating a speaker recognition model. However, identifying an appropriate speaker recognition model can be challenging, and using the target speaker embedding as reference information may not be optimal for target speaker extraction tasks. This paper introduces a Universal Speaker Embedding-Free Target Speaker Extraction (USEF-TSE) framework that operates without relying on speaker embeddings. USEF-TSE utilizes a multi-head cross-attention mechanism as a frame-level target speaker feature extractor. This innovative approach allows mainstream speaker extraction solutions to bypass the dependency on speaker recognition models and to fully leverage the information available in the enrollment speech, including speaker characteristics and contextual details. Additionally, USEF-TSE can seamlessly integrate with any time-domain or time-frequency domain speech separation model to achieve effective speaker extraction. Experimental results show that our proposed method achieves state-of-the-art (SOTA) performance in terms of Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) on the WSJ0-2mix, WHAM!, and WHAMR! datasets, which are standard benchmarks for monaural anechoic, noisy and noisy-reverberant two-speaker speech separation and speaker extraction.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "13 pages, 6 figures"
    },
    {
        "paper id": "2409.02617",
        "abstract url": "https://arxiv.org/abs/2409.02617",
        "title": "PUB: Plot Understanding Benchmark and Dataset for Evaluating Large Language Models on Synthetic Visual Data Interpretation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The ability of large language models (LLMs) to interpret visual representations of data is crucial for advancing their application in data analysis and decision-making processes. This paper presents a novel synthetic dataset designed to evaluate the proficiency of LLMs in interpreting various forms of data visualizations, including plots like time series, histograms, violins, boxplots, and clusters. Our dataset is generated using controlled parameters to ensure comprehensive coverage of potential real-world scenarios. We employ multimodal text prompts with questions related to visual data in images to benchmark several state-of-the-art models like ChatGPT or Gemini, assessing their understanding and interpretative accuracy. To ensure data integrity, our benchmark dataset is generated automatically, making it entirely new and free from prior exposure to the models being tested. This strategy allows us to evaluate the models' ability to truly interpret and understand the data, eliminating possibility of pre-learned responses, and allowing for an unbiased evaluation of the models' capabilities. We also introduce quantitative metrics to assess the performance of the models, providing a robust and comprehensive evaluation tool. Benchmarking several state-of-the-art LLMs with this dataset reveals varying degrees of success, highlighting specific strengths and weaknesses in interpreting diverse types of visual data. The results provide valuable insights into the current capabilities of LLMs and identify key areas for improvement. This work establishes a foundational benchmark for future research and development aimed at enhancing the visual interpretative abilities of language models. In the future, improved LLMs with robust visual interpretation skills can significantly aid in automated data analysis, scientific research, educational tools, and business intelligence applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02645",
        "abstract url": "https://arxiv.org/abs/2409.02645",
        "title": "A Survey on Emergent Language",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of 181 scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps.",
        "subjects": [
            "cs.MA",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02667",
        "abstract url": "https://arxiv.org/abs/2409.02667",
        "title": "Creating Domain-Specific Translation Memories for Machine Translation Fine-tuning: The TRENCARD Bilingual Cardiology Corpus",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This article investigates how translation memories (TM) can be created by translators or other language professionals in order to compile domain-specific parallel corpora , which can then be used in different scenarios, such as machine translation training and fine-tuning, TM leveraging, and/or large language model fine-tuning. The article introduces a semi-automatic TM preparation methodology leveraging primarily translation tools used by translators in favor of data quality and control by the translators. This semi-automatic methodology is then used to build a cardiology-based Turkish -> English corpus from bilingual abstracts of Turkish cardiology journals. The resulting corpus called TRENCARD Corpus has approximately 800,000 source words and 50,000 sentences. Using this methodology, translators can build their custom TMs in a reasonable time and use them in their bilingual data requiring tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02683",
        "abstract url": "https://arxiv.org/abs/2409.02683",
        "title": "Rethinking HTG Evaluation: Bridging Generation and Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The evaluation of generative models for natural image tasks has been extensively studied. Similar protocols and metrics are used in cases with unique particularities, such as Handwriting Generation, even if they might not be completely appropriate. In this work, we introduce three measures tailored for HTG evaluation, $ \\text{HTG}_{\\text{HTR}} $, $ \\text{HTG}_{\\text{style}} $, and $ \\text{HTG}_{\\text{OOV}} $, and argue that they are more expedient to evaluate the quality of generated handwritten images. The metrics rely on the recognition error/accuracy of Handwriting Text Recognition and Writer Identification models and emphasize writing style, textual content, and diversity as the main aspects that adhere to the content of handwritten images. We conduct comprehensive experiments on the IAM handwriting database, showcasing that widely used metrics such as FID fail to properly quantify the diversity and the practical utility of generated handwriting samples. Our findings show that our metrics are richer in information and underscore the necessity of standardized evaluation protocols in HTG. The proposed metrics provide a more robust and informative protocol for assessing HTG quality, contributing to improved performance in HTR. Code for the evaluation protocol is available at: https://github.com/koninik/HTG_evaluation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02690",
        "abstract url": "https://arxiv.org/abs/2409.02690",
        "title": "Detecting Calls to Action in Multimodal Content: Analysis of the 2021 German Federal Election Campaign on Instagram",
        "rating": "1",
        "keywords": [
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "This study investigates the automated classification of Calls to Action (CTAs) within the 2021 German Instagram election campaign to advance the understanding of mobilization in social media contexts. We analyzed over 2,208 Instagram stories and 712 posts using fine-tuned BERT models and OpenAI's GPT-4 models. The fine-tuned BERT model incorporating synthetic training data achieved a macro F1 score of 0.93, demonstrating a robust classification performance. Our analysis revealed that 49.58% of Instagram posts and 10.64% of stories contained CTAs, highlighting significant differences in mobilization strategies between these content types. Additionally, we found that FDP and the Greens had the highest prevalence of CTAs in posts, whereas CDU and CSU led in story CTAs.",
        "subjects": [
            "cs.SI",
            "cs.CL"
        ],
        "comment": "Accepted Archival Paper for the CPSS Workshop at KONVENS 2024. Camera Ready Submission"
    },
    {
        "paper id": "2409.02699",
        "abstract url": "https://arxiv.org/abs/2409.02699",
        "title": "CLDA: Collaborative Learning for Enhanced Unsupervised Domain Adaptation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised Domain Adaptation (UDA) endeavors to bridge the gap between a model trained on a labeled source domain and its deployment in an unlabeled target domain. However, current high-performance models demand significant resources, resulting in prohibitive deployment costs and highlighting the need for small yet effective models. For UDA of lightweight models, Knowledge Distillation (KD) in a Teacher-Student framework can be a common approach, but we find that domain shift in UDA leads to a significant increase in non-salient parameters in the teacher model, degrading model's generalization ability and transferring misleading information to the student model. Interestingly, we observed that this phenomenon occurs considerably less in the student model. Driven by this insight, we introduce Collaborative Learning, a method that updates the teacher's non-salient parameters using the student model and at the same time enhance the student's performance using the updated teacher model. Experiments across various tasks and datasets show consistent performance improvements for both student and teacher models. For example, in semantic segmentation, CLDA achieves an improvement of +0.7% mIoU for teacher and +1.4% mIoU for student compared to the baseline model in the GTA to Cityscapes. In the Synthia to Cityscapes, it achieves an improvement of +0.8% mIoU for teacher and +2.0% mIoU for student.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02712",
        "abstract url": "https://arxiv.org/abs/2409.02712",
        "title": "A Data Selection Approach for Enhancing Low Resource Machine Translation Using Cross-Lingual Sentence Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Machine translation in low-resource language pairs faces significant challenges due to the scarcity of parallel corpora and linguistic resources. This study focuses on the case of English-Marathi language pairs, where existing datasets are notably noisy, impeding the performance of machine translation models. To mitigate the impact of data quality issues, we propose a data filtering approach based on cross-lingual sentence representations. Our methodology leverages a multilingual SBERT model to filter out problematic translations in the training data. Specifically, we employ an IndicSBERT similarity model to assess the semantic equivalence between original and translated sentences, allowing us to retain linguistically correct translations while discarding instances with substantial deviations. The results demonstrate a significant improvement in translation quality over the baseline post-filtering with IndicSBERT. This illustrates how cross-lingual sentence representations can reduce errors in machine translation scenarios with limited resources. By integrating multilingual sentence BERT models into the translation pipeline, this research contributes to advancing machine translation techniques in low-resource environments. The proposed method not only addresses the challenges in English-Marathi language pairs but also provides a valuable framework for enhancing translation quality in other low-resource language translation tasks.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted at I2CT 2024"
    },
    {
        "paper id": "2409.02727",
        "abstract url": "https://arxiv.org/abs/2409.02727",
        "title": "Pooling And Attention: What Are Effective Designs For LLM-Based Embedding Models?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The significant advancements of Large Language Models (LLMs) in generative tasks have led to a growing body of work exploring LLM-based embedding models. While these models, employing different pooling and attention strategies, have achieved state-of-the-art performance on public embedding benchmarks, questions still arise about what constitutes an effective design for LLM-based embedding models. However, these models are often trained on different datasets, using different LLM base models or training settings. Moreover, evaluations on public embedding benchmarks often fail to report statistical significance, making it difficult to determine which designs truly contribute to final performance. This complicates the process for practitioners seeking optimal training recipes for LLM-based embedding models. In this study, we conduct a large-scale experiment by training a series of LLM-based embedding models using the same training data and base model but differing in their pooling and attention strategies. The results show that there is no one-size-fits-all solution: while bidirectional attention and an additional trainable pooling layer outperform in text similarity and information retrieval tasks, they do not significantly surpass simpler designs like EOS-last token pooling and default causal attention in clustering and classification tasks. Furthermore, we propose a new pooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs of all hidden layers, rather than just the last layer, using a cross-attention network. This method proves to be statistically superior in text similarity and retrieval tasks compared to existing pooling methods. Overall, this paper sheds light on effective training strategies for LLM-based embedding models.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": "https://github.com/yixuantt/PoolingAndAttn"
    },
    {
        "paper id": "2409.02743",
        "abstract url": "https://arxiv.org/abs/2409.02743",
        "title": "Efficient Image Compression Using Advanced State Space Models",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Transformers have led to learning-based image compression methods that outperform traditional approaches. However, these methods often suffer from high complexity, limiting their practical application. To address this, various strategies such as knowledge distillation and lightweight architectures have been explored, aiming to enhance efficiency without significantly sacrificing performance. This paper proposes a State Space Model-based Image Compression (SSMIC) architecture. This novel architecture balances performance and computational efficiency, making it suitable for real-world applications. Experimental evaluations confirm the effectiveness of our model in achieving a superior BD-rate while significantly reducing computational complexity and latency compared to competitive learning-based image compression methods.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Accepted at IEEE MMSP conference 2024 held on October 2-4 2024 at Purdue University in West Lafayette IN US"
    },
    {
        "paper id": "2409.02751",
        "abstract url": "https://arxiv.org/abs/2409.02751",
        "title": "A Comparative Study of Pre-training and Self-training",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Pre-training and self-training are two approaches to semi-supervised learning. The comparison between pre-training and self-training has been explored. However, the previous works led to confusing findings: self-training outperforms pre-training experienced on some tasks in computer vision, and contrarily, pre-training outperforms self-training experienced on some tasks in natural language processing, under certain conditions of incomparable settings. We propose, comparatively and exhaustively, an ensemble method to empirical study all feasible training paradigms combining pre-training, self-training, and fine-tuning within consistent foundational settings comparable to data augmentation. We conduct experiments on six datasets, four data augmentation, and imbalanced data for sentiment analysis and natural language inference tasks. Our findings confirm that the pre-training and fine-tuning paradigm yields the best overall performances. Moreover, self-training offers no additional benefits when combined with semi-supervised pre-training.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "19 pages, 2 figures, 9 tables"
    },
    {
        "paper id": "2409.02795",
        "abstract url": "https://arxiv.org/abs/2409.02795",
        "title": "Towards a Unified View of Preference Learning for Large Language Models: A Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to efficiently enhance the LLM's performance. While effective, research in this area spans multiple domains, and the methods involved are relatively complex to understand. The relationships between different methods have been under-explored, limiting the development of the preference alignment. In light of this, we break down the existing popular alignment strategies into different components and provide a unified framework to study the current alignment strategies, thereby establishing connections among them. In this survey, we decompose all the strategies in preference learning into four components: model, data, feedback, and algorithm. This unified view offers an in-depth understanding of existing alignment algorithms and also opens up possibilities to synergize the strengths of different strategies. Furthermore, we present detailed working examples of prevalent existing algorithms to facilitate a comprehensive understanding for the readers. Finally, based on our unified perspective, we explore the challenges and future research directions for aligning large language models with human preferences.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "23 pages, 6 figures"
    },
    {
        "paper id": "2409.02800",
        "abstract url": "https://arxiv.org/abs/2409.02800",
        "title": "Effects of Recording Condition and Number of Monitored Days on Discriminative Power of the Daily Phonotrauma Index",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Objective: The Daily Phonotrauma Index (DPI) can quantify pathophysiological mechanisms associated with daily voice use in individuals with phonotraumatic vocal hyperfunction (PVH). Since DPI was developed based on week-long ambulatory voice monitoring, this study investigated if DPI can achieve comparable performance using (1) short laboratory speech tasks and (2) fewer than seven days of ambulatory data. Method: An ambulatory voice monitoring system recorded the vocal function/behavior of 134 females with PVH and vocally healthy matched controls in two different conditions. In the lab, the participants read the first paragraph of the Rainbow Passage and produced spontaneous speech (in-lab data). They were then monitored for seven days (in-field data). Separate DPI models were trained from in-lab and in-field data using the standard deviation of the difference between the magnitude of the first two harmonics (H1-H2) and the skewness of neck-surface acceleration magnitude. First, 10-fold cross-validation evaluated classification performance of in-lab and in-field DPIs. Second, the effect of the number of ambulatory monitoring days on the accuracy of in-field DPI classification was quantified. Results: The average in-lab DPI accuracy computed from the Rainbow passage and spontaneous speech were, respectively, 57.9% and 48.9%, which are close to chance performance. The average classification accuracy of in-field DPI was significantly higher with a very large effect size (73.4%, Cohens D = 1.8). Second, the average in-field DPI accuracy increased from 66.5% for one day to 75.0% for seven days, with the gain of including an additional day on accuracy dropping below 1 percentage point after 4 days.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "The paper is submitted to JSLHR"
    },
    {
        "paper id": "2409.02809",
        "abstract url": "https://arxiv.org/abs/2409.02809",
        "title": "Experimental Framework for Generating Reliable Ground Truth for Laryngeal Spatial Segmentation Tasks",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Objective: The validity of objective measures derived from high-speed videoendoscopy (HSV) depends, among other factors, on the validity of spatial segmentation. Evaluation of the validity of spatial segmentation requires the existence of reliable ground truths. This study presents a framework for creating reliable ground truth with sub-pixel resolution and then evaluates its performance. Method: The proposed framework is a three-stage process. First, three laryngeal imaging experts performed the spatial segmentation task. Second, regions with high discrepancies between experts were determined and then overlaid onto the segmentation outcomes of each expert. The marked HSV frames from each expert were randomly assigned to the two remaining experts, and they were tasked to make proper adjustments and modifications to the initial segmentation within disparity regions. Third, the outcomes of this reconciliation phase were analyzed again and regions with continued high discrepancies were identified and adjusted based on the consensus among the three experts. This three-stage framework was tested using a custom graphical user interface that allowed precise piece-wise linear segmentation of the vocal fold edges. Inter-rate reliability of segmentation was evaluated using 12 HSV recordings. 10% of the frames from each HSV file were randomly selected to assess the intra-rater reliability. Result and conclusion: The reliability of spatial segmentation progressively improved as it went through the three stages of the framework. The proposed framework generated highly reliable and valid ground truths for evaluating the validity of automated spatial segmentation methods.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02813",
        "abstract url": "https://arxiv.org/abs/2409.02813",
        "title": "MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces MMMU-Pro, a robust version of the Massive Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark. MMMU-Pro rigorously assesses multimodal models' true understanding and reasoning capabilities through a three-step process based on MMMU: (1) filtering out questions answerable by text-only models, (2) augmenting candidate options, and (3) introducing a vision-only input setting where questions are embedded within images. This setting challenges AI to truly \"see\" and \"read\" simultaneously, testing a fundamental human cognitive skill of seamlessly integrating visual and textual information. Results show that model performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8% to 26.9% across models. We explore the impact of OCR prompts and Chain of Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT generally improves performance. MMMU-Pro provides a more rigorous evaluation tool, closely mimicking real-world scenarios and offering valuable directions for future research in multimodal AI.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02834",
        "abstract url": "https://arxiv.org/abs/2409.02834",
        "title": "CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have obtained promising results in mathematical reasoning, which is a foundational skill for human intelligence. Most previous studies focus on improving and measuring the performance of LLMs based on textual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few researchers have released English multimodal math datasets (e.g., MATHVISTA and MATH-V) to evaluate the effectiveness of large multimodal models (LMMs). In this paper, we release a Chinese multimodal math (CMM-Math) dataset, including benchmark and training parts, to evaluate and enhance the mathematical reasoning of LMMs. CMM-Math contains over 28,000 high-quality samples, featuring a variety of problem types (e.g., multiple-choice, fill-in-the-blank, and so on) with detailed solutions across 12 grade levels from elementary to high school in China. Specifically, the visual context may be present in the questions or opinions, which makes this dataset more challenging. Through comprehensive analysis, we discover that state-of-the-art LMMs on the CMM-Math dataset face challenges, emphasizing the necessity for further improvements in LMM development. We also propose a Multimodal Mathematical LMM (Math-LMM) to handle the problems with mixed input of multiple images and text segments. We train our model using three stages, including foundational pre-training, foundational fine-tuning, and mathematical fine-tuning. The extensive experiments indicate that our model effectively improves math reasoning performance by comparing it with the SOTA LMMs over three multimodal mathematical datasets.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02836",
        "abstract url": "https://arxiv.org/abs/2409.02836",
        "title": "Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This study performs analysis of Predictive statements, Hope speech, and Regret Detection behaviors within cryptocurrency-related discussions, leveraging advanced natural language processing techniques. We introduce a novel classification scheme named \"Prediction statements,\" categorizing comments into Predictive Incremental, Predictive Decremental, Predictive Neutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large language model, we explore sentiment dynamics across five prominent cryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis reveals distinct patterns in predictive sentiments, with Matic demonstrating a notably higher propensity for optimistic predictions. Additionally, we investigate hope and regret sentiments, uncovering nuanced interplay between these emotions and predictive behaviors. Despite encountering limitations related to data volume and resource availability, our study reports valuable discoveries concerning investor behavior and sentiment trends within the cryptocurrency market, informing strategic decision-making and future research endeavors.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02838",
        "abstract url": "https://arxiv.org/abs/2409.02838",
        "title": "iConFormer: Dynamic Parameter-Efficient Tuning with Input-Conditioned Adaptation",
        "rating": "1",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "efficient fine-tuning"
            ],
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Transfer learning based on full fine-tuning (FFT) of the pre-trained encoder and task-specific decoder becomes increasingly complex as deep models grow exponentially. Parameter efficient fine-tuning (PEFT) approaches using adapters consisting of small learnable layers have emerged as an alternative to FFT, achieving comparable performance while maintaining high training efficiency. However, the inflexibility of the adapter with respect to input instances limits its capability of learning task-specific information in diverse downstream tasks. In this paper, we propose a novel PEFT approach, input-Conditioned transFormer, termed iConFormer, that leverages a dynamic adapter conditioned on the input instances. To secure flexible learning ability on input instances in various downstream tasks, we introduce an input-Conditioned Network (iCoN) in the dynamic adapter that enables instance-level feature transformation. To be specific, iCoN generates channel-wise convolutional kernels for each feature and transform it using adaptive convolution process to effectively capture task-specific and fine-grained details tailor to downstream tasks. Experimental results demonstrate that by tuning just 1.6% to 2.8% of the Transformer backbone parameters, iConFormer achieves performance comparable to FFT in monocular depth estimation and semantic segmentation, while outperforming it in image classification and instance segmentation. Also, the proposed method consistently outperforms recent PEFT methods for all the tasks mentioned above.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02840",
        "abstract url": "https://arxiv.org/abs/2409.02840",
        "title": "R2GQA: Retriever-Reader-Generator Question Answering System to Support Students Understanding Legal Regulations in Higher Education",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In this article, we propose the R2GQA system, a Retriever-Reader-Generator Question Answering system, consisting of three main components: Document Retriever, Machine Reader, and Answer Generator. The Retriever module employs advanced information retrieval techniques to extract the context of articles from a dataset of legal regulation documents. The Machine Reader module utilizes state-of-the-art natural language understanding algorithms to comprehend the retrieved documents and extract answers. Finally, the Generator module synthesizes the extracted answers into concise and informative responses to questions of students regarding legal regulations. Furthermore, we built the ViRHE4QA dataset in the domain of university training regulations, comprising 9,758 question-answer pairs with a rigorous construction process. This is the first Vietnamese dataset in the higher regulations domain with various types of answers, both extractive and abstractive. In addition, the R2GQA system is the first system to offer abstractive answers in Vietnamese. This paper discusses the design and implementation of each module within the R2GQA system on the ViRHE4QA dataset, highlighting their functionalities and interactions. Furthermore, we present experimental results demonstrating the effectiveness and utility of the proposed system in supporting the comprehension of students of legal regulations in higher education settings. In general, the R2GQA system and the ViRHE4QA dataset promise to contribute significantly to related research and help students navigate complex legal documents and regulations, empowering them to make informed decisions and adhere to institutional policies effectively. Our dataset is available for research purposes.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02841",
        "abstract url": "https://arxiv.org/abs/2409.02841",
        "title": "Historical German Text Normalization Using Type- and Token-Based Language Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Historic variations of spelling poses a challenge for full-text search or natural language processing on historical digitized texts. To minimize the gap between the historic orthography and contemporary spelling, usually an automatic orthographic normalization of the historical source material is pursued. This report proposes a normalization system for German literary texts from c. 1700-1900, trained on a parallel corpus. The proposed system makes use of a machine learning approach using Transformer language models, combining an encoder-decoder model to normalize individual word types, and a pre-trained causal language model to adjust these normalizations within their context. An extensive evaluation shows that the proposed system provides state-of-the-art accuracy, comparable with a much larger fully end-to-end sentence-based normalization system, fine-tuning a pre-trained Transformer large language model. However, the normalization of historical text remains a challenge due to difficulties for models to generalize, and the lack of extensive high-quality parallel data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "27 pages, 3 figures"
    },
    {
        "paper id": "2409.02866",
        "abstract url": "https://arxiv.org/abs/2409.02866",
        "title": "Hybrid-Segmentor: A Hybrid Approach to Automated Fine-Grained Crack Segmentation in Civil Infrastructure",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Detecting and segmenting cracks in infrastructure, such as roads and buildings, is crucial for safety and cost-effective maintenance. In spite of the potential of deep learning, there are challenges in achieving precise results and handling diverse crack types. With the proposed dataset and model, we aim to enhance crack detection and infrastructure maintenance. We introduce Hybrid-Segmentor, an encoder-decoder based approach that is capable of extracting both fine-grained local and global crack features. This allows the model to improve its generalization capabilities in distinguish various type of shapes, surfaces and sizes of cracks. To keep the computational performances low for practical purposes, while maintaining the high the generalization capabilities of the model, we incorporate a self-attention model at the encoder level, while reducing the complexity of the decoder component. The proposed model outperforms existing benchmark models across 5 quantitative metrics (accuracy 0.971, precision 0.804, recall 0.744, F1-score 0.770, and IoU score 0.630), achieving state-of-the-art status.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": "25 pages, 6 figures"
    },
    {
        "paper id": "2409.02877",
        "abstract url": "https://arxiv.org/abs/2409.02877",
        "title": "Configurable Foundation Models: Building LLMs from a Modular Perspective",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Advancements in LLMs have recently unveiled challenges tied to computational efficiency and continual scalability due to their requirements of huge parameters, making the applications and evolution of these models on devices with limited computation resources and scenarios requiring various abilities increasingly cumbersome. Inspired by modularity within the human brain, there is a growing tendency to decompose LLMs into numerous functional modules, allowing for inference with part of modules and dynamic assembly of modules to tackle complex tasks, such as mixture-of-experts. To highlight the inherent efficiency and composability of the modular approach, we coin the term brick to represent each functional module, designating the modularized structure as configurable foundation models. In this paper, we offer a comprehensive overview and investigation of the construction, utilization, and limitation of configurable foundation models. We first formalize modules into emergent bricks - functional neuron partitions that emerge during the pre-training phase, and customized bricks - bricks constructed via additional post-training to improve the capabilities and knowledge of LLMs. Based on diverse functional bricks, we further present four brick-oriented operations: retrieval and routing, merging, updating, and growing. These operations allow for dynamic configuration of LLMs based on instructions to handle complex tasks. To verify our perspective, we conduct an empirical analysis on widely-used LLMs. We find that the FFN layers follow modular patterns with functional specialization of neurons and functional neuron partitions. Finally, we highlight several open issues and directions for future research. Overall, this paper aims to offer a fresh modular perspective on existing LLM research and inspire the future creation of more efficient and scalable foundational models.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02889",
        "abstract url": "https://arxiv.org/abs/2409.02889",
        "title": "LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Expanding the long-context capabilities of Multi-modal Large Language Models~(MLLMs) is crucial for video understanding, high-resolution image understanding, and multi-modal agents. This involves a series of systematic optimizations, including model architecture, data construction and training strategy, particularly addressing challenges such as \\textit{degraded performance with more images} and \\textit{high computational costs}. In this paper, we adapt the model architecture to a hybrid of Mamba and Transformer blocks, approach data construction with both temporal and spatial dependencies among multiple images and employ a progressive training strategy. The released model \\textbf{LongLLaVA}~(\\textbf{Long}-Context \\textbf{L}arge \\textbf{L}anguage \\textbf{a}nd \\textbf{V}ision \\textbf{A}ssistant) is the first hybrid MLLM, which achieved a better balance between efficiency and effectiveness. LongLLaVA not only achieves competitive results across various benchmarks, but also maintains high throughput and low memory consumption. Especially, it could process nearly a thousand images on a single A100 80GB GPU, showing promising application prospects for a wide range of tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.MM"
        ],
        "comment": "19 pages, 7 figures, 6 tables"
    },
    {
        "paper id": "2409.02897",
        "abstract url": "https://arxiv.org/abs/2409.02897",
        "title": "LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Though current long-context large language models (LLMs) have demonstrated impressive capacities in answering user questions based on extensive text, the lack of citations in their responses makes user verification difficult, leading to concerns about their trustworthiness due to their potential hallucinations. In this work, we aim to enable long-context LLMs to generate responses with fine-grained sentence-level citations, improving their faithfulness and verifiability. We first introduce LongBench-Cite, an automated benchmark for assessing current LLMs' performance in Long-Context Question Answering with Citations (LQAC), revealing considerable room for improvement. To this end, we propose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs to automatically generate long-context QA instances with precise sentence-level citations, and leverage this pipeline to construct LongCite-45k, a large-scale SFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the LongCite-45k dataset, successfully enabling their generation of accurate responses and fine-grained sentence-level citations in a single output. The evaluation results on LongBench-Cite show that our trained models achieve state-of-the-art citation quality, surpassing advanced proprietary models including GPT-4o.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02910",
        "abstract url": "https://arxiv.org/abs/2409.02910",
        "title": "SITAR: Semi-supervised Image Transformer for Action Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recognizing actions from a limited set of labeled videos remains a challenge as annotating visual data is not only tedious but also can be expensive due to classified nature. Moreover, handling spatio-temporal data using deep $3$D transformers for this can introduce significant computational complexity. In this paper, our objective is to address video action recognition in a semi-supervised setting by leveraging only a handful of labeled videos along with a collection of unlabeled videos in a compute efficient manner. Specifically, we rearrange multiple frames from the input videos in row-column form to construct super images. Subsequently, we capitalize on the vast pool of unlabeled samples and employ contrastive learning on the encoded super images. Our proposed approach employs two pathways to generate representations for temporally augmented super images originating from the same video. Specifically, we utilize a 2D image-transformer to generate representations and apply a contrastive loss function to minimize the similarity between representations from different videos while maximizing the representations of identical videos. Our method demonstrates superior performance compared to existing state-of-the-art approaches for semi-supervised action recognition across various benchmark datasets, all while significantly reducing computational costs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at ICPR 2024"
    },
    {
        "paper id": "2409.02914",
        "abstract url": "https://arxiv.org/abs/2409.02914",
        "title": "Can LVLMs Obtain a Driver's License? A Benchmark Towards Reliable AGI for Autonomous Driving",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large Vision-Language Models (LVLMs) have recently garnered significant attention, with many efforts aimed at harnessing their general knowledge to enhance the interpretability and robustness of autonomous driving models. However, LVLMs typically rely on large, general-purpose datasets and lack the specialized expertise required for professional and safe driving. Existing vision-language driving datasets focus primarily on scene understanding and decision-making, without providing explicit guidance on traffic rules and driving skills, which are critical aspects directly related to driving safety. To bridge this gap, we propose IDKB, a large-scale dataset containing over one million data items collected from various countries, including driving handbooks, theory test data, and simulated road test data. Much like the process of obtaining a driver's license, IDKB encompasses nearly all the explicit knowledge needed for driving from theory to practice. In particular, we conducted comprehensive tests on 15 LVLMs using IDKB to assess their reliability in the context of autonomous driving and provided extensive analysis. We also fine-tuned popular models, achieving notable performance improvements, which further validate the significance of our dataset. The project page can be found at: \\url{https://4dvlab.github.io/project_page/idkb.html}",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02979",
        "abstract url": "https://arxiv.org/abs/2409.02979",
        "title": "Vec2Face: Scaling Face Dataset Generation with Loosely Constrained Vectors",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper studies how to synthesize face images of non-existent persons, to create a dataset that allows effective training of face recognition (FR) models. Two important goals are (1) the ability to generate a large number of distinct identities (inter-class separation) with (2) a wide variation in appearance of each identity (intra-class variation). However, existing works 1) are typically limited in how many well-separated identities can be generated and 2) either neglect or use a separate editing model for attribute augmentation. We propose Vec2Face, a holistic model that uses only a sampled vector as input and can flexibly generate and control face images and their attributes. Composed of a feature masked autoencoder and a decoder, Vec2Face is supervised by face image reconstruction and can be conveniently used in inference. Using vectors with low similarity among themselves as inputs, Vec2Face generates well-separated identities. Randomly perturbing an input identity vector within a small range allows Vec2Face to generate faces of the same identity with robust variation in face attributes. It is also possible to generate images with designated attributes by adjusting vector values with a gradient descent method. Vec2Face has efficiently synthesized as many as 300K identities with 15 million total images, whereas 60K is the largest number of identities created in the previous works. FR models trained with the generated HSFace datasets, from 10k to 300k identities, achieve state-of-the-art accuracy, from 92% to 93.52%, on five real-world test sets. For the first time, our model created using a synthetic training set achieves higher accuracy than the model created using a same-scale training set of real face images (on the CALFW test set).",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03012",
        "abstract url": "https://arxiv.org/abs/2409.03012",
        "title": "Design and Evaluation of Camera-Centric Mobile Crowdsourcing Applications",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The data that underlies automated methods in computer vision and machine learning, such as image retrieval and fine-grained recognition, often comes from crowdsourcing. In contexts that rely on the intrinsic motivation of users, we seek to understand how the application design affects a user's willingness to contribute and the quantity and quality of the data they capture. In this project, we designed three versions of a camera-based mobile crowdsourcing application, which varied in the amount of labeling effort requested of the user and conducted a user study to evaluate the trade-off between the level of user-contributed information requested and the quantity and quality of labeled images collected. The results suggest that higher levels of user labeling do not lead to reduced contribution. Users collected and annotated the most images using the application version with the highest requested level of labeling with no decrease in user satisfaction. In preliminary experiments, the additional labeled data supported increased performance on an image retrieval task.",
        "subjects": [
            "cs.HC",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03021",
        "abstract url": "https://arxiv.org/abs/2409.03021",
        "title": "CLUE: Concept-Level Uncertainty Estimation for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in various natural language generation (NLG) tasks. Previous studies suggest that LLMs' generation process involves uncertainty. However, existing approaches to uncertainty estimation mainly focus on sequence-level uncertainty, overlooking individual pieces of information within sequences. These methods fall short in separately assessing the uncertainty of each component in a sequence. In response, we propose a novel framework for Concept-Level Uncertainty Estimation (CLUE) for LLMs. We leverage LLMs to convert output sequences into concept-level representations, breaking down sequences into individual concepts and measuring the uncertainty of each concept separately. We conduct experiments to demonstrate that CLUE can provide more interpretable uncertainty estimation results compared with sentence-level uncertainty, and could be a useful tool for various tasks such as hallucination detection and story generation.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03025",
        "abstract url": "https://arxiv.org/abs/2409.03025",
        "title": "No Detail Left Behind: Revisiting Self-Retrieval for Fine-Grained Image Captioning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image captioning systems are unable to generate fine-grained captions as they are trained on data that is either noisy (alt-text) or generic (human annotations). This is further exacerbated by maximum likelihood training that encourages generation of frequently occurring phrases. Previous works have tried to address this limitation by fine-tuning captioners with a self-retrieval (SR) reward. However, we find that SR fine-tuning has a tendency to reduce caption faithfulness and even hallucinate. In this work, we circumvent this bottleneck by improving the MLE initialization of the captioning system and designing a curriculum for the SR fine-tuning process. To this extent, we present (1) Visual Caption Boosting, a novel framework to instill fine-grainedness in generic image captioning datasets while remaining anchored in human annotations; and (2) BagCurri, a carefully designed training curriculum that more optimally leverages the contrastive nature of the self-retrieval reward. Jointly, they enable the captioner to describe fine-grained aspects in the image while preserving faithfulness to ground-truth captions. Our approach outperforms previous work by +8.9% on SR against 99 random distractors (RD100) (Dessi et al., 2023); and +7.6% on ImageCoDe. Additionally, existing metrics to evaluate captioning systems fail to reward diversity or evaluate a model's fine-grained understanding ability. Our third contribution addresses this by proposing self-retrieval from the lens of evaluation. We introduce TrueMatch, a benchmark comprising bags of highly similar images that uses SR to assess the captioner's ability to capture subtle visual distinctions. We evaluate and compare several state-of-the-art open-source MLLMs on TrueMatch, and find that our SR approach outperforms them all by a significant margin (e.g. +4.8% - 7.1% over Cambrian) while having 1-2 orders of magnitude fewer parameters.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03115",
        "abstract url": "https://arxiv.org/abs/2409.03115",
        "title": "Probing self-attention in self-supervised speech models for cross-linguistic differences",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Speech models have gained traction thanks to increase in accuracy from novel transformer architectures. While this impressive increase in performance across automatic speech recognition (ASR) benchmarks is noteworthy, there is still much that is unknown about the use of attention mechanisms for speech-related tasks. For example, while it is assumed that these models are learning language-independent (i.e., universal) speech representations, there has not yet been an in-depth exploration of what it would mean for the models to be language-independent. In the current paper, we explore this question within the realm of self-attention mechanisms of one small self-supervised speech transformer model (TERA). We find that even with a small model, the attention heads learned are diverse ranging from almost entirely diagonal to almost entirely global regardless of the training language. We highlight some notable differences in attention patterns between Turkish and English and demonstrate that the models do learn important phonological information during pretraining. We also present a head ablation study which shows that models across languages primarily rely on diagonal heads to classify phonemes.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "10 pages, 18 figures"
    },
    {
        "paper id": "2409.03161",
        "abstract url": "https://arxiv.org/abs/2409.03161",
        "title": "MaterialBENCH: Evaluating College-Level Materials Science Problem-Solving Abilities of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "A college-level benchmark dataset for large language models (LLMs) in the materials science field, MaterialBENCH, is constructed. This dataset consists of problem-answer pairs, based on university textbooks. There are two types of problems: one is the free-response answer type, and the other is the multiple-choice type. Multiple-choice problems are constructed by adding three incorrect answers as choices to a correct answer, so that LLMs can choose one of the four as a response. Most of the problems for free-response answer and multiple-choice types overlap except for the format of the answers. We also conduct experiments using the MaterialBENCH on LLMs, including ChatGPT-3.5, ChatGPT-4, Bard (at the time of the experiments), and GPT-3.5 and GPT-4 with the OpenAI API. The differences and similarities in the performance of LLMs measured by the MaterialBENCH are analyzed and discussed. Performance differences between the free-response type and multiple-choice type in the same models and the influence of using system massages on multiple-choice problems are also studied. We anticipate that MaterialBENCH will encourage further developments of LLMs in reasoning abilities to solve more complicated problems and eventually contribute to materials research and discovery.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03171",
        "abstract url": "https://arxiv.org/abs/2409.03171",
        "title": "MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented Generation Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper we present a multi-adapter retrieval augmented generation system (MARAGS) for Meta's Comprehensive RAG (CRAG) competition for KDD CUP 2024. CRAG is a question answering dataset contains 3 different subtasks aimed at realistic question and answering RAG related tasks, with a diverse set of question topics, question types, time dynamic answers, and questions featuring entities of varying popularity. Our system follows a standard setup for web based RAG, which uses processed web pages to provide context for an LLM to produce generations, while also querying API endpoints for additional information. MARAGS also utilizes multiple different adapters to solve the various requirements for these tasks with a standard cross-encoder model for ranking candidate passages relevant for answering the question. Our system achieved 2nd place for Task 1 as well as 3rd place on Task 2.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to CRAG KDD Cup 24 Workshop"
    },
    {
        "paper id": "2409.03192",
        "abstract url": "https://arxiv.org/abs/2409.03192",
        "title": "PEPL: Precision-Enhanced Pseudo-Labeling for Fine-Grained Image Classification in Semi-Supervised Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fine-grained image classification has witnessed significant advancements with the advent of deep learning and computer vision technologies. However, the scarcity of detailed annotations remains a major challenge, especially in scenarios where obtaining high-quality labeled data is costly or time-consuming. To address this limitation, we introduce Precision-Enhanced Pseudo-Labeling(PEPL) approach specifically designed for fine-grained image classification within a semi-supervised learning framework. Our method leverages the abundance of unlabeled data by generating high-quality pseudo-labels that are progressively refined through two key phases: initial pseudo-label generation and semantic-mixed pseudo-label generation. These phases utilize Class Activation Maps (CAMs) to accurately estimate the semantic content and generate refined labels that capture the essential details necessary for fine-grained classification. By focusing on semantic-level information, our approach effectively addresses the limitations of standard data augmentation and image-mixing techniques in preserving critical fine-grained features. We achieve state-of-the-art performance on benchmark datasets, demonstrating significant improvements over existing semi-supervised strategies, with notable boosts in accuracy and robustness.Our code has been open sourced at https://github.com/TianSuya/SemiFG.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2409.03206",
        "abstract url": "https://arxiv.org/abs/2409.03206",
        "title": "TC-LLaVA: Rethinking the Transfer from Image to Video Understanding with Temporal Considerations",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have significantly improved performance across various image-language applications. Recently, there has been a growing interest in adapting image pre-trained MLLMs for video-related tasks. However, most efforts concentrate on enhancing the vision encoder and projector components, while the core part, Large Language Models (LLMs), remains comparatively under-explored. In this paper, we propose two strategies to enhance the model's capability in video understanding tasks by improving inter-layer attention computation in LLMs. Specifically, the first approach focuses on the enhancement of Rotary Position Embedding (RoPE) with Temporal-Aware Dual RoPE, which introduces temporal position information to strengthen the MLLM's temporal modeling capabilities while preserving the relative position relationships of both visual and text tokens. The second approach involves enhancing the Attention Mask with the Frame-wise Block Causal Attention Mask, a simple yet effective method that broadens visual token interactions within and across video frames while maintaining the causal inference mechanism. Based on these proposed methods, we adapt LLaVA for video understanding tasks, naming it Temporal-Considered LLaVA (TC-LLaVA). Our TC-LLaVA achieves new state-of-the-art performance across various video understanding benchmarks with only supervised fine-tuning (SFT) on video-related datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03212",
        "abstract url": "https://arxiv.org/abs/2409.03212",
        "title": "Bi-capacity Choquet Integral for Sensor Fusion with Label Uncertainty",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Sensor fusion combines data from multiple sensor sources to improve reliability, robustness, and accuracy of data interpretation. The Fuzzy Integral (FI), in particular, the Choquet integral (ChI), is often used as a powerful nonlinear aggregator for fusion across multiple sensors. However, existing supervised ChI learning algorithms typically require precise training labels for each input data point, which can be difficult or impossible to obtain. Additionally, prior work on ChI fusion is often based only on the normalized fuzzy measures, which bounds the fuzzy measure values between [0, 1]. This can be limiting in cases where the underlying scales of input data sources are bipolar (i.e., between [-1, 1]). To address these challenges, this paper proposes a novel Choquet integral-based fusion framework, named Bi-MIChI (pronounced \"bi-mi-kee\"), which uses bi-capacities to represent the interactions between pairs of subsets of the input sensor sources on a bi-polar scale. This allows for extended non-linear interactions between the sensor sources and can lead to interesting fusion results. Bi-MIChI also addresses label uncertainty through Multiple Instance Learning, where training labels are applied to \"bags\" (sets) of data instead of per-instance. Our proposed Bi-MIChI framework shows effective classification and detection performance on both synthetic and real-world experiments for sensor fusion with label uncertainty. We also provide detailed analyses on the behavior of the fuzzy measures to demonstrate our fusion process.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "10 pages, 7 figures, 7 tables; Accepted to 2024 FUZZ-IEEE and presented at 2024 IEEE WCCI; Code available at https://github.com/hvak/Bi-MIChI"
    },
    {
        "paper id": "2409.03215",
        "abstract url": "https://arxiv.org/abs/2409.03215",
        "title": "xLAM: A Family of Large Action Models to Empower AI Agent Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Autonomous agents powered by large language models (LLMs) have attracted significant research interest. However, the open-source community faces many challenges in developing specialized models for agent tasks, driven by the scarcity of high-quality agent datasets and the absence of standard protocols in this area. We introduce and publicly release xLAM, a series of large action models designed for AI agent tasks. The xLAM series includes five models with both dense and mixture-of-expert architectures, ranging from 1B to 8x22B parameters, trained using a scalable, flexible pipeline that unifies, augments, and synthesizes diverse datasets to enhance AI agents' generalizability and performance across varied environments. Our experimental results demonstrate that xLAM consistently delivers exceptional performance across multiple agent ability benchmarks, notably securing the 1st position on the Berkeley Function-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other models in terms of tool use. By releasing the xLAM series, we aim to advance the performance of open-source LLMs for autonomous AI agents, potentially accelerating progress and democratizing access to high-performance models for agent tasks. Models are available at https://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Technical report for the Salesforce xLAM model series"
    },
    {
        "paper id": "2409.03797",
        "abstract url": "https://arxiv.org/abs/2409.03797",
        "title": "NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API Calls",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Autonomous agent applications powered by large language models (LLMs) have recently risen to prominence as effective tools for addressing complex real-world tasks. At their core, agentic workflows rely on LLMs to plan and execute the use of tools and external Application Programming Interfaces (APIs) in sequence to arrive at the answer to a user's request. Various benchmarks and leaderboards have emerged to evaluate an LLM's capabilities for tool and API use; however, most of these evaluations only track single or multiple isolated API calling capabilities. In this paper, we present NESTFUL, a benchmark to evaluate LLMs on nested sequences of API calls, i.e., sequences where the output of one API call is passed as input to a subsequent call. NESTFUL has a total of 300 human annotated samples divided into two types - executable and non-executable. The executable samples are curated manually by crawling Rapid-APIs whereas the non-executable samples are hand picked by human annotators from data synthetically generated using an LLM. We evaluate state-of-the-art LLMs with function calling abilities on NESTFUL. Our results show that most models do not perform well on nested APIs in NESTFUL as compared to their performance on the simpler problem settings available in existing benchmarks.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02446",
        "abstract url": "https://arxiv.org/abs/2409.02446",
        "title": "ForeCal: Random Forest-based Calibration for DNNs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep neural network(DNN) based classifiers do extremely well in discriminating between observations, resulting in higher ROC AUC and accuracy metrics, but their outputs are often miscalibrated with respect to true event likelihoods. Post-hoc calibration algorithms are often used to calibrate the outputs of these classifiers. Methods like Isotonic regression, Platt scaling, and Temperature scaling have been shown to be effective in some cases but are limited by their parametric assumptions and/or their inability to capture complex non-linear relationships. We propose ForeCal - a novel post-hoc calibration algorithm based on Random forests. ForeCal exploits two unique properties of Random forests: the ability to enforce weak monotonicity and range-preservation. It is more powerful in achieving calibration than current state-of-the-art methods, is non-parametric, and can incorporate exogenous information as features to learn a better calibration function. Through experiments on 43 diverse datasets from the UCI ML repository, we show that ForeCal outperforms existing methods in terms of Expected Calibration Error(ECE) with minimal impact on the discriminative power of the base DNN as measured by AUC.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02471",
        "abstract url": "https://arxiv.org/abs/2409.02471",
        "title": "Demographic parity in regression and classification within the unawareness framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "This paper explores the theoretical foundations of fair regression under the constraint of demographic parity within the unawareness framework, where disparate treatment is prohibited, extending existing results where such treatment is permitted. Specifically, we aim to characterize the optimal fair regression function when minimizing the quadratic loss. Our results reveal that this function is given by the solution to a barycenter problem with optimal transport costs. Additionally, we study the connection between optimal fair cost-sensitive classification, and optimal fair regression. We demonstrate that nestedness of the decision sets of the classifiers is both necessary and sufficient to establish a form of equivalence between classification and regression. Under this nestedness assumption, the optimal classifiers can be derived by applying thresholds to the optimal fair regression function; conversely, the optimal fair regression function is characterized by the family of cost-sensitive classifiers.",
        "subjects": [
            "stat.ML",
            "cs.CY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02525",
        "abstract url": "https://arxiv.org/abs/2409.02525",
        "title": "A Topic-wise Exploration of the Telegram Group-verse",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Although currently one of the most popular instant messaging apps worldwide, Telegram has been largely understudied in the past years. In this paper, we aim to address this gap by presenting an analysis of publicly accessible groups covering discussions encompassing different topics, as diverse as Education, Erotic, Politics, and Cryptocurrencies. We engineer and offer an open-source tool to automate the collection of messages from Telegram groups, a non-straightforward problem. We use it to collect more than 50 million messages from 669 groups. Here, we present a first-of-its-kind, per-topic analysis, contrasting the characteristics of the messages sent on the platform from different angles -- the language, the presence of bots, the type and volume of shared media content. Our results confirm some anecdotal evidence, e.g., clues that Telegram is used to share possibly illicit content, and unveil some unexpected findings, e.g., the different sharing patterns of video and stickers in groups of different topics. While preliminary, we hope that our work paves the road for several avenues of future research on the understudied Telegram platform.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02543",
        "abstract url": "https://arxiv.org/abs/2409.02543",
        "title": "StyleTokenizer: Defining Image Style by a Single Instance for Controlling Diffusion Models",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Despite the burst of innovative methods for controlling the diffusion process, effectively controlling image styles in text-to-image generation remains a challenging task. Many adapter-based methods impose image representation conditions on the denoising process to accomplish image control. However these conditions are not aligned with the word embedding space, leading to interference between image and text control conditions and the potential loss of semantic information from the text prompt. Addressing this issue involves two key challenges. Firstly, how to inject the style representation without compromising the effectiveness of text representation in control. Secondly, how to obtain the accurate style representation from a single reference image. To tackle these challenges, we introduce StyleTokenizer, a zero-shot style control image generation method that aligns style representation with text representation using a style tokenizer. This alignment effectively minimizes the impact on the effectiveness of text prompts. Furthermore, we collect a well-labeled style dataset named Style30k to train a style feature extractor capable of accurately representing style while excluding other content information. Experimental results demonstrate that our method fully grasps the style characteristics of the reference image, generating appealing images that are consistent with both the target image style and text prompt. The code and dataset are available at https://github.com/alipay/style-tokenizer.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV2024"
    },
    {
        "paper id": "2409.02549",
        "abstract url": "https://arxiv.org/abs/2409.02549",
        "title": "A Sequential Decision-Making Model for Perimeter Identification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Perimeter identification involves ascertaining the boundaries of a designated area or zone, requiring traffic flow monitoring, control, or optimization. Various methodologies and technologies exist for accurately defining these perimeters; however, they often necessitate specialized equipment, precise mapping, or comprehensive data for effective problem delineation. In this study, we propose a sequential decision-making framework for perimeter search, designed to operate efficiently in real-time and require only publicly accessible information. We conceptualize the perimeter search as a game between a playing agent and an artificial environment, where the agent's objective is to identify the optimal perimeter by sequentially improving the current perimeter. We detail the model for the game and discuss its adaptability in determining the definition of an optimal perimeter. Ultimately, we showcase the model's efficacy through a real-world scenario, highlighting the identification of corresponding optimal perimeters.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02572",
        "abstract url": "https://arxiv.org/abs/2409.02572",
        "title": "Advancing Cyber Incident Timeline Analysis Through Rule Based AI and Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Timeline Analysis (TA) is a key part of Timeline Forensics (TF) in Digital Forensics (DF), focusing primarily on examining and analysing temporal digital artefacts such as timestamps, derived from event logs, file metadata, and other related data to correlate events resulting from cyber incidents and reconstruct their chronological timeline. Traditional tools often struggle to efficiently process the vast volume and variety of data acquired during DF investigations and Incident Response (IR) processes. This paper presents a novel framework, GenDFIR, that combines Rule-Based Artificial Intelligence (R-BAI) algorithms with Large Language Models (LLMs) to advance and automate the TA process. Our approach consists of two main stages (1) We use R-BAI to identify and select anomalous digital artefacts based on predefined rules. (2) The selected artefacts are then converted into embeddings for processing by an LLM with the help of a Retrieval-Augmented Generation (RAG) agent. The LLM consequently leverages its capabilities to perform automated TA on the artefacts and predict potential incident scenarios. To validate our framework, we evaluate GenDFIR performance, efficiency, and reliability using various metrics across synthetic cyber incident simulation scenarios. This paper presents a proof of concept, where the findings demonstrate the significant potential of integrating R-BAI and LLMs for TA. This novel approach highlights the power of Generative AI (GenAI), specifically LLMs, and opens new avenues for advanced threat detection and incident reconstruction, representing a significant step forward in the field.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.ET",
            "cs.LG"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2409.02601",
        "abstract url": "https://arxiv.org/abs/2409.02601",
        "title": "ChatGPT vs Social Surveys: Probing the Objective and Subjective Human Society",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The extent to which Large Language Models (LLMs) can simulate the data-generating process for social surveys remains unclear. Current research has not thoroughly assessed potential biases in the sociodemographic population represented within the language model's framework. Additionally, the subjective worlds of LLMs often show inconsistencies in how closely their responses match those of groups of human respondents. In this paper, we used ChatGPT-3.5 to simulate the sampling process and generated six socioeconomic characteristics from the 2020 US population. We also analyzed responses to questions about income inequality and gender roles to explore GPT's subjective attitudes. By using repeated random sampling, we created a sampling distribution to identify the parameters of the GPT-generated population and compared these with Census data. Our findings show some alignment in gender and age means with the actual 2020 US population, but we also found mismatches in the distributions of racial and educational groups. Furthermore, there were significant differences between the distribution of GPT's responses and human self-reported attitudes. While the overall point estimates of GPT's income attitudinal responses seem to align with the mean of the population occasionally, their response distributions follow a normal distribution that diverges from human responses. In terms of gender relations, GPT's answers tend to cluster in the most frequently answered category, demonstrating a deterministic pattern. We conclude by emphasizing the distinct design philosophies of LLMs and social surveys: LLMs aim to predict the most suitable answers, while social surveys seek to reveal the heterogeneity among social groups.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02628",
        "abstract url": "https://arxiv.org/abs/2409.02628",
        "title": "(Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Epistemic uncertainty is crucial for safety-critical applications and out-of-distribution detection tasks. Yet, we uncover a paradoxical phenomenon in deep learning models: an epistemic uncertainty collapse as model complexity increases, challenging the assumption that larger models invariably offer better uncertainty quantification. We propose that this stems from implicit ensembling within large models. To support this hypothesis, we demonstrate epistemic uncertainty collapse empirically across various architectures, from explicit ensembles of ensembles and simple MLPs to state-of-the-art vision models, including ResNets and Vision Transformers -- for the latter, we examine implicit ensemble extraction and decompose larger models into diverse sub-models, recovering epistemic uncertainty. We provide theoretical justification for these phenomena and explore their implications for uncertainty estimation.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2409.02632",
        "abstract url": "https://arxiv.org/abs/2409.02632",
        "title": "Evaluating Environments Using Exploratory Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Exploration is a key part of many video games. We investigate the using an exploratory agent to provide feedback on the design of procedurally generated game levels, 5 engaging levels and 5 unengaging levels. We expand upon a framework introduced in previous research which models motivations for exploration and introduce a fitness function for evaluating an environment's potential for exploration. Our study showed that our exploratory agent can clearly distinguish between engaging and unengaging levels. The findings suggest that our agent has the potential to serve as an effective tool for assessing procedurally generated levels, in terms of exploration. This work contributes to the growing field of AI-driven game design by offering new insights into how game environments can be evaluated and optimised for player exploration.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": "9 Pages, 9 figures, 2 tables, work in progress"
    },
    {
        "paper id": "2409.02659",
        "abstract url": "https://arxiv.org/abs/2409.02659",
        "title": "Dynamics of drug trafficking: Results from a simple compartmental model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "In this work we propose a simple model for the emergence of drug dealers. For this purpose, we built a compartmental model considering four subpopulations, namely susceptibles, passive supporters, drug dealers and arrested drug dealers. The target is to study the influence of the passive supporters on the long-time prevalence of drug dealers. Passive supporters are people who are passively consenting to the drug trafficking cause. First we consider the model on a fully-connected newtork, in such a way that we can write a rate equation for each subpopulation. Our analytical and numerical results show that the emergence of drug dealers is a consequence of the rapid increase number of passive supporters. Such increase is associated with a nonequilibrium active-absorbing phase transition. After that, we consider the model on a two-dimensional square lattice, in order to compare the results in the presence of a simple social network with the previous results. The Monte Carlo simulation results suggest a similar behavior in comparison with the fully-connected network case, but the location of the critical point of the transition is distinct, due to the neighbors' correlations introduced by the presence of the lattice.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": "17 pages, 6 figures, to appear in IJMPC"
    },
    {
        "paper id": "2409.02668",
        "abstract url": "https://arxiv.org/abs/2409.02668",
        "title": "Introduction to Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This book introduces the mathematical foundations and techniques that lead to the development and analysis of many of the algorithms that are used in machine learning. It starts with an introductory chapter that describes notation used throughout the book and serve at a reminder of basic concepts in calculus, linear algebra and probability and also introduces some measure theoretic terminology, which can be used as a reading guide for the sections that use these tools. The introductory chapters also provide background material on matrix analysis and optimization. The latter chapter provides theoretical support to many algorithms that are used in the book, including stochastic gradient descent, proximal methods, etc. After discussing basic concepts for statistical prediction, the book includes an introduction to reproducing kernel theory and Hilbert space techniques, which are used in many places, before addressing the description of various algorithms for supervised statistical learning, including linear methods, support vector machines, decision trees, boosting, or neural networks. The subject then switches to generative methods, starting with a chapter that presents sampling methods and an introduction to the theory of Markov chains. The following chapter describe the theory of graphical models, an introduction to variational methods for models with latent variables, and to deep-learning based generative models. The next chapters focus on unsupervised learning methods, for clustering, factor analysis and manifold learning. The final chapter of the book is theory-oriented and discusses concentration inequalities and generalization bounds.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "textbook"
    },
    {
        "paper id": "2409.02684",
        "abstract url": "https://arxiv.org/abs/2409.02684",
        "title": "Neural timescales from a computational perspective",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Timescales of neural activity are diverse across and within brain areas, and experimental observations suggest that neural timescales reflect information in dynamic environments. However, these observations do not specify how neural timescales are shaped, nor whether particular timescales are necessary for neural computations and brain function. Here, we take a complementary perspective and synthesize three directions where computational methods can distill the broad set of empirical observations into quantitative and testable theories: We review (i) how data analysis methods allow us to capture different timescales of neural dynamics across different recording modalities, (ii) how computational models provide a mechanistic explanation for the emergence of diverse timescales, and (iii) how task-optimized models in machine learning uncover the functional relevance of neural timescales. This integrative computational approach, combined with empirical findings, would provide a more holistic understanding of how neural timescales capture the relationship between brain structure, dynamics, and behavior.",
        "subjects": [
            "q-bio.NC",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "18 pages, 4 figures, 2 boxes"
    },
    {
        "paper id": "2409.02685",
        "abstract url": "https://arxiv.org/abs/2409.02685",
        "title": "RouterRetriever: Exploring the Benefits of Routing over Multiple Expert Embedding Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Information retrieval methods often rely on a single embedding model trained on large, general-domain datasets like MSMARCO. While this approach can produce a retriever with reasonable overall performance, models trained on domain-specific data often yield better results within their respective domains. While prior work in information retrieval has tackled this through multi-task training, the topic of combining multiple domain-specific expert retrievers remains unexplored, despite its popularity in language model generation. In this work, we introduce RouterRetriever, a retrieval model that leverages multiple domain-specific experts along with a routing mechanism to select the most appropriate expert for each query. It is lightweight and allows easy addition or removal of experts without additional training. Evaluation on the BEIR benchmark demonstrates that RouterRetriever outperforms both MSMARCO-trained (+2.1 absolute nDCG@10) and multi-task trained (+3.2) models. This is achieved by employing our routing mechanism, which surpasses other routing techniques (+1.8 on average) commonly used in language modeling. Furthermore, the benefit generalizes well to other datasets, even in the absence of a specific expert on the dataset. To our knowledge, RouterRetriever is the first work to demonstrate the advantages of using multiple domain-specific expert embedding models with effective routing over a single, general-purpose embedding model in retrieval tasks.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02691",
        "abstract url": "https://arxiv.org/abs/2409.02691",
        "title": "LLM-Assisted Visual Analytics: Opportunities and Challenges",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We explore the integration of large language models (LLMs) into visual analytics (VA) systems to transform their capabilities through intuitive natural language interactions. We survey current research directions in this emerging field, examining how LLMs are integrated into data management, language interaction, visualisation generation, and language generation processes. We highlight the new possibilities that LLMs bring to VA, especially how they can change VA processes beyond the usual use cases. We especially highlight building new visualisation-language models, allowing access of a breadth of domain knowledge, multimodal interaction, and opportunities with guidance. Finally, we carefully consider the prominent challenges of using current LLMs in VA tasks. Our discussions in this paper aim to guide future researchers working on LLM-assisted VA systems and help them navigate common obstacles when developing these systems.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "Accepted at EG UK Computer Graphics & Visual Computing 2024"
    },
    {
        "paper id": "2409.02693",
        "abstract url": "https://arxiv.org/abs/2409.02693",
        "title": "The Role of Artificial Intelligence and Machine Learning in Software Testing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) have significantly impacted various industries, including software development. Software testing, a crucial part of the software development lifecycle (SDLC), ensures the quality and reliability of software products. Traditionally, software testing has been a labor-intensive process requiring significant manual effort. However, the advent of AI and ML has transformed this landscape by introducing automation and intelligent decision-making capabilities. AI and ML technologies enhance the efficiency and effectiveness of software testing by automating complex tasks such as test case generation, test execution, and result analysis. These technologies reduce the time required for testing and improve the accuracy of defect detection, ultimately leading to higher quality software. AI can predict potential areas of failure by analyzing historical data and identifying patterns, which allows for more targeted and efficient testing. This paper explores the role of AI and ML in software testing by reviewing existing literature, analyzing current tools and techniques, and presenting case studies that demonstrate the practical benefits of these technologies. The literature review provides a comprehensive overview of the advancements in AI and ML applications in software testing, highlighting key methodologies and findings from various studies. The analysis of current tools showcases the capabilities of popular AI-driven testing tools such as Eggplant AI, Test.ai, Selenium, Appvance, Applitools Eyes, Katalon Studio, and Tricentis Tosca, each offering unique features and advantages. Case studies included in this paper illustrate real-world applications of AI and ML in software testing, showing significant improvements in testing efficiency, accuracy, and overall software quality.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02697",
        "abstract url": "https://arxiv.org/abs/2409.02697",
        "title": "Decision Transformer for Enhancing Neural Local Search on the Job Shop Scheduling Problem",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The job shop scheduling problem (JSSP) and its solution algorithms have been of enduring interest in both academia and industry for decades. In recent years, machine learning (ML) is playing an increasingly important role in advancing existing and building new heuristic solutions for the JSSP, aiming to find better solutions in shorter computation times. In this paper we build on top of a state-of-the-art deep reinforcement learning (DRL) agent, called Neural Local Search (NLS), which can efficiently and effectively control a large local neighborhood search on the JSSP. In particular, we develop a method for training the decision transformer (DT) algorithm on search trajectories taken by a trained NLS agent to further improve upon the learned decision-making sequences. Our experiments show that the DT successfully learns local search strategies that are different and, in many cases, more effective than those of the NLS agent itself. In terms of the tradeoff between solution quality and acceptable computational time needed for the search, the DT is particularly superior in application scenarios where longer computational times are acceptable. In this case, it makes up for the longer inference times required per search step, which are caused by the larger neural network architecture, through better quality decisions per step. Thereby, the DT achieves state-of-the-art results for solving the JSSP with ML-enhanced search.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "currently under review for IEEE Transactions on Cybernetics"
    },
    {
        "paper id": "2409.02708",
        "abstract url": "https://arxiv.org/abs/2409.02708",
        "title": "Few-shot Multi-Task Learning of Linear Invariant Features with Meta Subspace Pursuit",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data scarcity poses a serious threat to modern machine learning and artificial intelligence, as their practical success typically relies on the availability of big datasets. One effective strategy to mitigate the issue of insufficient data is to first harness information from other data sources possessing certain similarities in the study design stage, and then employ the multi-task or meta learning framework in the analysis stage. In this paper, we focus on multi-task (or multi-source) linear models whose coefficients across tasks share an invariant low-rank component, a popular structural assumption considered in the recent multi-task or meta learning literature. Under this assumption, we propose a new algorithm, called Meta Subspace Pursuit (abbreviated as Meta-SP), that provably learns this invariant subspace shared by different tasks. Under this stylized setup for multi-task or meta learning, we establish both the algorithmic and statistical guarantees of the proposed method. Extensive numerical experiments are conducted, comparing Meta-SP against several competing methods, including popular, off-the-shelf model-agnostic meta learning algorithms such as ANIL. These experiments demonstrate that Meta-SP achieves superior performance over the competing methods in various aspects.",
        "subjects": [
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02711",
        "abstract url": "https://arxiv.org/abs/2409.02711",
        "title": "Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for PostNL",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The developments in the field of generative AI has brought a lot of opportunities for companies, for instance to improve efficiency in customer service and automating tasks. PostNL, the biggest parcel and E-commerce corporation of the Netherlands wants to use generative AI to enhance the communication around track and trace of parcels. During the internship a Minimal Viable Product (MVP) is created to showcase the value of using generative AI technologies, to enhance parcel tracking, analyzing the parcel's journey and being able to communicate about it in an easy to understand manner. The primary goal was to develop an in-house LLM-based system, reducing dependency on external platforms and establishing the feasibility of a dedicated generative AI team within the company. This multi-agent LLM based system aimed to construct parcel journey stories and identify logistical disruptions with heightened efficiency and accuracy. The research involved deploying a sophisticated AI-driven communication system, employing Retrieval-Augmented Generation (RAG) for enhanced response precision, and optimizing large language models (LLMs) tailored to domain specific tasks. The MVP successfully implemented a multi-agent open-source LLM system, called SuperTracy. SuperTracy is capable of autonomously managing a broad spectrum of user inquiries and improving internal knowledge handling. Results and evaluation demonstrated technological innovation and feasibility, notably in communication about the track and trace of a parcel, which exceeded initial expectations. These advancements highlight the potential of AI-driven solutions in logistics, suggesting many opportunities for further refinement and broader implementation within PostNL operational framework.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02740",
        "abstract url": "https://arxiv.org/abs/2409.02740",
        "title": "Convolutional Neural Networks for Automated Cellular Automaton Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The emergent dynamics in spacetime diagrams of cellular automata (CAs) is often organised by means of a number of behavioural classes. Whilst classification of elementary CAs is feasible and well-studied, non-elementary CAs are generally too diverse and numerous to exhaustively classify manually. In this chapter we treat the spacetime diagram as a digital image, and implement simple computer vision techniques to perform an automated classification of elementary cellular automata into the five Li-Packard classes. In particular, we present a supervised learning task to a convolutional neural network, in such a way that it may be generalised to non-elementary CAs. If we want to do so, we must divert the algorithm's focus away from the underlying 'microscopic' local updates. We first show that previously developed deep learning approaches have in fact been trained to identify the local update rule, rather than directly focus on the mesoscopic patterns that are associated with the particular behavioural classes. By means of a well-argued neural network design, as well as a number of data augmentation techniques, we then present a convolutional neural network that performs nearly perfectly at identifying the behavioural class, without necessarily first identifying the underlying microscopic dynamics.",
        "subjects": [
            "nlin.CG",
            "cs.LG"
        ],
        "comment": "19 pages, 12 figures, book chapter"
    },
    {
        "paper id": "2409.02747",
        "abstract url": "https://arxiv.org/abs/2409.02747",
        "title": "Tractable Offline Learning of Regular Decision Processes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This work studies offline Reinforcement Learning (RL) in a class of non-Markovian environments called Regular Decision Processes (RDPs). In RDPs, the unknown dependency of future observations and rewards from the past interactions can be captured by some hidden finite-state automaton. For this reason, many RDP algorithms first reconstruct this unknown dependency using automata learning techniques. In this paper, we show that it is possible to overcome two strong limitations of previous offline RL algorithms for RDPs, notably RegORL. This can be accomplished via the introduction of two original techniques: the development of a new pseudometric based on formal languages, which removes a problematic dependency on $L_\\infty^\\mathsf{p}$-distinguishability parameters, and the adoption of Count-Min-Sketch (CMS), instead of naive counting. The former reduces the number of samples required in environments that are characterized by a low complexity in language-theoretic terms. The latter alleviates the memory requirements for long planning horizons. We derive the PAC sample complexity bounds associated to each of these techniques, and we validate the approach experimentally.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.FL"
        ],
        "comment": "To appear in EWRL 2024"
    },
    {
        "paper id": "2409.02760",
        "abstract url": "https://arxiv.org/abs/2409.02760",
        "title": "An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces a novel incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting (MCS) problems, enabling decision makers to progressively provide assignment example preference information. Specifically, we first construct a max-margin optimization-based model to model potentially non-monotonic preferences and inconsistent assignment example preference information in each iteration of the incremental preference elicitation process. Using the optimal objective function value of the max-margin optimization-based model, we devise information amount measurement methods and question selection strategies to pinpoint the most informative alternative in each iteration within the framework of uncertainty sampling in active learning. Once the termination criterion is satisfied, the sorting result for non-reference alternatives can be determined through the use of two optimization models, i.e., the max-margin optimization-based model and the complexity controlling optimization model. Subsequently, two incremental preference elicitation-based algorithms are developed to learn potentially non-monotonic preferences, considering different termination criteria. Ultimately, we apply the proposed approach to a credit rating problem to elucidate the detailed implementation steps, and perform computational experiments on both artificial and real-world data sets to compare the proposed question selection strategies with several benchmark strategies.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "37 pages, 22 figures"
    },
    {
        "paper id": "2409.02772",
        "abstract url": "https://arxiv.org/abs/2409.02772",
        "title": "Unifying Causal Representation Learning with the Invariance Principle",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causal representation learning aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. The folklore is that these different settings are important, as they are often linked to different rungs of Pearl's causal hierarchy, although not all neatly fit. Our main contribution is to show that many existing causal representation learning approaches methodologically align the representation to known data symmetries. Identification of the variables is guided by equivalence classes across different data pockets that are not necessarily causal. This result suggests important implications, allowing us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariances relevant to our application. It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causality assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "36 pages"
    },
    {
        "paper id": "2409.02778",
        "abstract url": "https://arxiv.org/abs/2409.02778",
        "title": "Regularized Multi-output Gaussian Convolution Process with Domain Adaptation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multi-output Gaussian process (MGP) has been attracting increasing attention as a transfer learning method to model multiple outputs. Despite its high flexibility and generality, MGP still faces two critical challenges when applied to transfer learning. The first one is negative transfer, which occurs when there exists no shared information among the outputs. The second challenge is the input domain inconsistency, which is commonly studied in transfer learning yet not explored in MGP. In this paper, we propose a regularized MGP modeling framework with domain adaptation to overcome these challenges. More specifically, a sparse covariance matrix of MGP is proposed by using convolution process, where penalization terms are added to adaptively select the most informative outputs for knowledge transfer. To deal with the domain inconsistency, a domain adaptation method is proposed by marginalizing inconsistent features and expanding missing features to align the input domains among different outputs. Statistical properties of the proposed method are provided to guarantee the performance practically and asymptotically. The proposed framework outperforms state-of-the-art benchmarks in comprehensive simulation studies and one real case study of a ceramic manufacturing process. The results demonstrate the effectiveness of our method in dealing with both the negative transfer and the domain inconsistency.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02808",
        "abstract url": "https://arxiv.org/abs/2409.02808",
        "title": "Towards Edge-Based Data Lake Architecture for Intelligent Transportation System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rapid urbanization growth has underscored the need for innovative solutions to enhance transportation efficiency and safety. Intelligent Transportation Systems (ITS) have emerged as a promising solution in this context. However, analyzing and processing the massive and intricate data generated by ITS presents significant challenges for traditional data processing systems. This work proposes an Edge-based Data Lake Architecture to integrate and analyze the complex data from ITS efficiently. The architecture offers scalability, fault tolerance, and performance, improving decision-making and enhancing innovative services for a more intelligent transportation ecosystem. We demonstrate the effectiveness of the architecture through an analysis of three different use cases: (i) Vehicular Sensor Network, (ii) Mobile Network, and (iii) Driver Identification applications.",
        "subjects": [
            "cs.DB",
            "cs.AI",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02810",
        "abstract url": "https://arxiv.org/abs/2409.02810",
        "title": "A hybrid FEM-PINN method for time-dependent partial differential equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this work, we present a hybrid numerical method for solving evolution partial differential equations (PDEs) by merging the time finite element method with deep neural networks. In contrast to the conventional deep learning-based formulation where the neural network is defined on a spatiotemporal domain, our methodology utilizes finite element basis functions in the time direction where the space-dependent coefficients are defined as the output of a neural network. We then apply the Galerkin or collocation projection in the time direction to obtain a system of PDEs for the space-dependent coefficients which is approximated in the framework of PINN. The advantages of such a hybrid formulation are twofold: statistical errors are avoided for the integral in the time direction, and the neural network's output can be regarded as a set of reduced spatial basis functions. To further alleviate the difficulties from high dimensionality and low regularity, we have developed an adaptive sampling strategy that refines the training set. More specifically, we use an explicit density model to approximate the distribution induced by the PDE residual and then augment the training set with new time-dependent random samples given by the learned density model. The effectiveness and efficiency of our proposed method have been demonstrated through a series of numerical experiments.",
        "subjects": [
            "math.NA",
            "cs.AI"
        ],
        "comment": "25pages"
    },
    {
        "paper id": "2409.02817",
        "abstract url": "https://arxiv.org/abs/2409.02817",
        "title": "Obsidian: Cooperative State-Space Exploration for Performant Inference on Secure ML Accelerators",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Trusted execution environments (TEEs) for machine learning accelerators are indispensable in secure and efficient ML inference. Optimizing workloads through state-space exploration for the accelerator architectures improves performance and energy consumption. However, such explorations are expensive and slow due to the large search space. Current research has to use fast analytical models that forego critical hardware details and cross-layer opportunities unique to the hardware security primitives. While cycle-accurate models can theoretically reach better designs, their high runtime cost restricts them to a smaller state space. We present Obsidian, an optimization framework for finding the optimal mapping from ML kernels to a secure ML accelerator. Obsidian addresses the above challenge by exploring the state space using analytical and cycle-accurate models cooperatively. The two main exploration components include: (1) A secure accelerator analytical model, that includes the effect of secure hardware while traversing the large mapping state space and produce the best m model mappings; (2) A compiler profiling step on a cycle-accurate model, that captures runtime bottlenecks to further improve execution runtime, energy and resource utilization and find the optimal model mapping. We compare our results to a baseline secure accelerator, comprising of the state-of-the-art security schemes obtained from guardnn [ 33 ] and sesame [11]. The analytical model reduces the inference latency by 20.5% for a cloud and 8.4% for an edge deployment with an energy improvement of 24% and 19% respectively. The cycle-accurate model, further reduces the latency by 9.1% for a cloud and 12.2% for an edge with an energy improvement of 13.8% and 13.1%.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02839",
        "abstract url": "https://arxiv.org/abs/2409.02839",
        "title": "J\u00e4ger: Automated Telephone Call Traceback",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Unsolicited telephone calls that facilitate fraud or unlawful telemarketing continue to overwhelm network users and the regulators who prosecute them. The first step in prosecuting phone abuse is traceback -- identifying the call originator. This fundamental investigative task currently requires hours of manual effort per call. In this paper, we introduce J\u00e4ger, a distributed secure call traceback system. J\u00e4ger can trace a call in a few seconds, even with partial deployment, while cryptographically preserving the privacy of call parties, carrier trade secrets like peers and call volume, and limiting the threat of bulk analysis. We establish definitions and requirements of secure traceback, then develop a suite of protocols that meet these requirements using witness encryption, oblivious pseudorandom functions, and group signatures. We prove these protocols secure in the universal composibility framework. We then demonstrate that J\u00e4ger has low compute and bandwidth costs per call, and these costs scale linearly with call volume. J\u00e4ger provides an efficient, secure, privacy-preserving system to revolutionize telephone abuse investigation with minimal costs to operators.",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.NI"
        ],
        "comment": "In Proceedings of the 2024 ACM SIGSAC Conference on Computer and Communications Security (CCS '24), October 14---18, 2024, Salt Lake City, UT, USA. ACM, New York, NY, USA, 24 pages"
    },
    {
        "paper id": "2409.02850",
        "abstract url": "https://arxiv.org/abs/2409.02850",
        "title": "Oops, I Sampled it Again: Reinterpreting Confidence Intervals in Few-Shot Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The predominant method for computing confidence intervals (CI) in few-shot learning (FSL) is based on sampling the tasks with replacement, i.e.\\ allowing the same samples to appear in multiple tasks. This makes the CI misleading in that it takes into account the randomness of the sampler but not the data itself. To quantify the extent of this problem, we conduct a comparative analysis between CIs computed with and without replacement. These reveal a notable underestimation by the predominant method. This observation calls for a reevaluation of how we interpret confidence intervals and the resulting conclusions in FSL comparative studies. Our research demonstrates that the use of paired tests can partially address this issue. Additionally, we explore methods to further reduce the (size of the) CI by strategically sampling tasks of a specific size. We also introduce a new optimized benchmark, which can be accessed at https://github.com/RafLaf/FSL-benchmark-again",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02867",
        "abstract url": "https://arxiv.org/abs/2409.02867",
        "title": "The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition",
        "rating": "0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Over the recent years, the advancements in deep face recognition have fueled an increasing demand for large and diverse datasets. Nevertheless, the authentic data acquired to create those datasets is typically sourced from the web, which, in many cases, can lead to significant privacy issues due to the lack of explicit user consent. Furthermore, obtaining a demographically balanced, large dataset is even more difficult because of the natural imbalance in the distribution of images from different demographic groups. In this paper, we investigate the impact of demographically balanced authentic and synthetic data, both individually and in combination, on the accuracy and fairness of face recognition models. Initially, several generative methods were used to balance the demographic representations of the corresponding synthetic datasets. Then a state-of-the-art face encoder was trained and evaluated using (combinations of) synthetic and authentic images. Our findings emphasized two main points: (i) the increased effectiveness of training data generated by diffusion-based models in enhancing accuracy, whether used alone or combined with subsets of authentic data, and (ii) the minimal impact of incorporating balanced data from pre-trained generative methods on fairness (in nearly all tested scenarios using combined datasets, fairness scores remained either unchanged or worsened, even when compared to unbalanced authentic datasets). Source code and data are available at \\url{https://cutt.ly/AeQy1K5G} for reproducibility.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at Synthetic Data for Computer Vision Workshop - Side Event at ECCV 2024"
    },
    {
        "paper id": "2409.02969",
        "abstract url": "https://arxiv.org/abs/2409.02969",
        "title": "LibMOON: A Gradient-based MultiObjective OptimizatioN Library in PyTorch",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multiobjective optimization problems (MOPs) are prevalent in machine learning, with applications in multi-task learning, learning under fairness or robustness constraints, etc. Instead of reducing multiple objective functions into a scalar objective, MOPs aim to optimize for the so-called Pareto optimality or Pareto set learning, which involves optimizing more than one objective function simultaneously, over models with millions of parameters. Existing benchmark libraries for MOPs mainly focus on evolutionary algorithms, most of which are zeroth-order methods that do not effectively utilize higher-order information from objectives and cannot scale to large-scale models with millions of parameters. In light of the above gap, this paper introduces LibMOON, the first multiobjective optimization library that supports state-of-the-art gradient-based methods, provides a fair benchmark, and is open-sourced for the community.",
        "subjects": [
            "cs.MS",
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02971",
        "abstract url": "https://arxiv.org/abs/2409.02971",
        "title": "Meal-taking activity monitoring in the elderly based on sensor data: Comparison of unsupervised classification methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In an era marked by a demographic change towards an older population, there is an urgent need to improve nutritional monitoring in view of the increase in frailty. This research aims to enhance the identification of meal-taking activities by combining K-Means, GMM, and DBSCAN techniques. Using the Davies-Bouldin Index (DBI) for the optimal meal taking activity clustering, the results show that K-Means seems to be the best solution, thanks to its unrivalled efficiency in data demarcation, compared with the capabilities of GMM and DBSCAN. Although capable of identifying complex patterns and outliers, the latter methods are limited by their operational complexities and dependence on precise parameter configurations. In this paper, we have processed data from 4 houses equipped with sensors. The findings indicate that applying the K-Means method results in high performance, evidenced by a particularly low Davies-Bouldin Index (DBI), illustrating optimal cluster separation and cohesion. Calculating the average duration of each activity using the GMM algorithm allows distinguishing various categories of meal-taking activities. Alternatively, this can correspond to different times of the day fitting to each meal-taking activity. Using K-Means, GMM, and DBSCAN clustering algorithms, the study demonstrates an effective strategy for thoroughly understanding the data. This approach facilitates the comparison and selection of the most suitable method for optimal meal-taking activity clustering.",
        "subjects": [
            "cs.LG",
            "eess.SP",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02977",
        "abstract url": "https://arxiv.org/abs/2409.02977",
        "title": "Large Language Model-Based Agents for Software Engineering: A Survey",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The recent advance in Large Language Models (LLMs) has shaped a new paradigm of AI agents, i.e., LLM-based agents. Compared to standalone LLMs, LLM-based agents substantially extend the versatility and expertise of LLMs by enhancing LLMs with the capabilities of perceiving and utilizing external resources and tools. To date, LLM-based agents have been applied and shown remarkable effectiveness in Software Engineering (SE). The synergy between multiple agents and human interaction brings further promise in tackling complex real-world SE problems. In this work, we present a comprehensive and systematic survey on LLM-based agents for SE. We collect 106 papers and categorize them from two perspectives, i.e., the SE and agent perspectives. In addition, we discuss open challenges and future directions in this critical domain. The repository of this survey is at https://github.com/FudanSELab/Agent4SE-Paper-List.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03044",
        "abstract url": "https://arxiv.org/abs/2409.03044",
        "title": "A Large-Scale Survey of Password Entry Practices on Non-Desktop Devices",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Password managers encourage users to generate passwords to improve their security. However, research has shown that users avoid generating passwords, often giving the rationale that it is difficult to enter generated passwords on devices without a password manager. In this paper, we conduct a survey ($n=999$) of individuals from the US, UK, and Europe, exploring the range of devices on which they enter passwords and the challenges associated with password entry on those devices. We find that password entry on devices without password managers is a common occurrence and comes with significant usability challenges. These usability challenges lead users to weaken their passwords to increase the ease of entry. We conclude this paper with a discussion of how future research could address these challenges and encourage users to adopt generated passwords.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": "12 pages, 4 figures, 8 tables"
    },
    {
        "paper id": "2409.03052",
        "abstract url": "https://arxiv.org/abs/2409.03052",
        "title": "An Introduction to Centralized Training for Decentralized Execution in Cooperative Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multi-agent reinforcement learning (MARL) has exploded in popularity in recent years. Many approaches have been developed but they can be divided into three main types: centralized training and execution (CTE), centralized training for decentralized execution (CTDE), and Decentralized training and execution (DTE). CTDE methods are the most common as they can use centralized information during training but execute in a decentralized manner -- using only information available to that agent during execution. CTDE is the only paradigm that requires a separate training phase where any available information (e.g., other agent policies, underlying states) can be used. As a result, they can be more scalable than CTE methods, do not require communication during execution, and can often perform well. CTDE fits most naturally with the cooperative case, but can be potentially applied in competitive or mixed settings depending on what information is assumed to be observed. This text is an introduction to CTDE in cooperative MARL. It is meant to explain the setting, basic concepts, and common methods. It does not cover all work in CTDE MARL as the subarea is quite extensive. I have included work that I believe is important for understanding the main concepts in the subarea and apologize to those that I have omitted.",
        "subjects": [
            "cs.LG",
            "cs.MA"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2405.06161"
    },
    {
        "paper id": "2409.03060",
        "abstract url": "https://arxiv.org/abs/2409.03060",
        "title": "Better Verified Explanations with Applications to Incorrectness and Out-of-Distribution Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Building on VeriX (Verified eXplainability, arXiv:2212.01051), a system for producing optimal verified explanations for machine learning model outputs, we present VeriX+, which significantly improves both the size and the generation time of verified explanations. We introduce a bound propagation-based sensitivity technique to improve the size, and a binary search-based traversal with confidence ranking for improving time -- the two techniques are orthogonal and can be used independently or together. We also show how to adapt the QuickXplain (Junker 2004) algorithm to our setting to provide a trade-off between size and time. Experimental evaluations on standard benchmarks demonstrate significant improvements on both metrics, e.g., a size reduction of 38% on the GTSRB dataset and a time reduction of 90% on MNIST. We also explore applications of our verified explanations and show that explanation size is a useful proxy for both incorrectness detection and out-of-distribution detection.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03067",
        "abstract url": "https://arxiv.org/abs/2409.03067",
        "title": "A Comparative Study of Offline Models and Online LLMs in Fake News Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Fake news detection remains a critical challenge in today's rapidly evolving digital landscape, where misinformation can spread faster than ever before. Traditional fake news detection models often rely on static datasets and auxiliary information, such as metadata or social media interactions, which limits their adaptability to real-time scenarios. Recent advancements in Large Language Models (LLMs) have demonstrated significant potential in addressing these challenges due to their extensive pre-trained knowledge and ability to analyze textual content without relying on auxiliary data. However, many of these LLM-based approaches are still rooted in static datasets, with limited exploration into their real-time processing capabilities. This paper presents a systematic evaluation of both traditional offline models and state-of-the-art LLMs for real-time fake news detection. We demonstrate the limitations of existing offline models, including their inability to adapt to dynamic misinformation patterns. Furthermore, we show that newer LLM models with online capabilities, such as GPT-4, Claude, and Gemini, are better suited for detecting emerging fake news in real-time contexts. Our findings emphasize the importance of transitioning from offline to online LLM models for real-time fake news detection. Additionally, the public accessibility of LLMs enhances their scalability and democratizes the tools needed to combat misinformation. By leveraging real-time data, our work marks a significant step toward more adaptive, effective, and scalable fake news detection systems.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03077",
        "abstract url": "https://arxiv.org/abs/2409.03077",
        "title": "Backdoor defense, learnability and obfuscation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a formal notion of defendability against backdoors using a game between an attacker and a defender. In this game, the attacker modifies a function to behave differently on a particular input known as the \"trigger\", while behaving the same almost everywhere else. The defender then attempts to detect the trigger at evaluation time. If the defender succeeds with high enough probability, then the function class is said to be defendable. The key constraint on the attacker that makes defense possible is that the attacker's strategy must work for a randomly-chosen trigger. Our definition is simple and does not explicitly mention learning, yet we demonstrate that it is closely connected to learnability. In the computationally unbounded setting, we use a voting algorithm of Hanneke et al. (2022) to show that defendability is essentially determined by the VC dimension of the function class, in much the same way as PAC learnability. In the computationally bounded setting, we use a similar argument to show that efficient PAC learnability implies efficient defendability, but not conversely. On the other hand, we use indistinguishability obfuscation to show that the class of polynomial size circuits is not efficiently defendable. Finally, we present polynomial size decision trees as a natural example for which defense is strictly easier than learning. Thus, we identify efficient defendability as a notable intermediate concept in between efficient learnability and obfuscation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": "29 pages"
    },
    {
        "paper id": "2409.03103",
        "abstract url": "https://arxiv.org/abs/2409.03103",
        "title": "Leveraging Interpretability in the Transformer to Automate the Proactive Scaling of Cloud Resources",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modern web services adopt cloud-native principles to leverage the advantages of microservices. To consistently guarantee high Quality of Service (QoS) according to Service Level Agreements (SLAs), ensure satisfactory user experiences, and minimize operational costs, each microservice must be provisioned with the right amount of resources. However, accurately provisioning microservices with adequate resources is complex and depends on many factors, including workload intensity and the complex interconnections between microservices. To address this challenge, we develop a model that captures the relationship between an end-to-end latency, requests at the front-end level, and resource utilization. We then use the developed model to predict the end-to-end latency. Our solution leverages the Temporal Fusion Transformer (TFT), an attention-based architecture equipped with interpretability features. When the prediction results indicate SLA non-compliance, we use the feature importance provided by the TFT as covariates in Kernel Ridge Regression (KRR), with the response variable being the desired latency, to learn the parameters associated with the feature importance. These learned parameters reflect the adjustments required to the features to ensure SLA compliance. We demonstrate the merit of our approach with a microservice-based application and provide a roadmap to deployment.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "14 pages, 5 figures"
    },
    {
        "paper id": "2409.03127",
        "abstract url": "https://arxiv.org/abs/2409.03127",
        "title": "Fast algorithms to improve fair information access in networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "When information spreads across a network via pairwise sharing, large disparities in information access can arise from the network's structural heterogeneity. Algorithms to improve the fairness of information access seek to maximize the minimum access of a node to information by sequentially selecting new nodes to seed with the spreading information. However, existing algorithms are computationally expensive. Here, we develop and evaluate a set of 10 new scalable algorithms to improve information access in social networks; in order to compare them to the existing state-of-the-art, we introduce both a new performance metric and a new benchmark corpus of networks. Additionally, we investigate the degree to which algorithm performance on minimizing information access gaps can be predicted ahead of time from features of a network's structure. We find that while no algorithm is strictly superior to all others across networks, our new scalable algorithms are competitive with the state-of-the-art and orders of magnitude faster. We introduce a meta-learner approach that learns which of the fast algorithms is best for a specific network and is on average only 20% less effective than the state-of-the-art performance on held-out data, while about 75-130 times faster. Furthermore, on about 20% of networks the meta-learner's performance exceeds the state-of-the-art.",
        "subjects": [
            "cs.SI",
            "cs.CY",
            "physics.soc-ph"
        ],
        "comment": "9 pages, 9 figures, and 3 appendices containing 12 algorithms, 1 table, and 9 additional figures"
    },
    {
        "paper id": "2409.03129",
        "abstract url": "https://arxiv.org/abs/2409.03129",
        "title": "Subsidy design for better social outcomes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Overcoming the impact of selfish behavior of rational players in multiagent systems is a fundamental problem in game theory. Without any intervention from a central agent, strategic users take actions in order to maximize their personal utility, which can lead to extremely inefficient overall system performance, often indicated by a high Price of Anarchy. Recent work (Lin et al. 2021) investigated and formalized yet another undesirable behavior of rational agents, that of avoiding freely available information about the game for selfish reasons, leading to worse social outcomes. A central planner can significantly mitigate these issues by injecting a subsidy to reduce certain costs associated with the system and obtain net gains in the system performance. Crucially, the planner needs to determine how to allocate this subsidy effectively. We formally show that designing subsidies that perfectly optimize the social good, in terms of minimizing the Price of Anarchy or preventing the information avoidance behavior, is computationally hard under standard complexity theoretic assumptions. On the positive side, we show that we can learn provably good values of subsidy in repeated games coming from the same domain. This data-driven subsidy design approach avoids solving computationally hard problems for unseen games by learning over polynomially many games. We also show that optimal subsidy can be learned with no-regret given an online sequence of games, under mild assumptions on the cost matrix. Our study focuses on two distinct games: a Bayesian extension of the well-studied fair cost-sharing game, and a component maintenance game with engineering applications.",
        "subjects": [
            "cs.GT",
            "cs.LG"
        ],
        "comment": "30 pages, 3 figures, 5 tables"
    },
    {
        "paper id": "2409.03137",
        "abstract url": "https://arxiv.org/abs/2409.03137",
        "title": "The AdEMAMix Optimizer: Better, Faster, Older",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Momentum based optimizers are central to a wide range of machine learning applications. These typically rely on an Exponential Moving Average (EMA) of gradients, which decays exponentially the present contribution of older gradients. This accounts for gradients being local linear approximations which lose their relevance as the iterate moves along the loss landscape. This work questions the use of a single EMA to accumulate past gradients and empirically demonstrates how this choice can be sub-optimal: a single EMA cannot simultaneously give a high weight to the immediate past, and a non-negligible weight to older gradients. Building on this observation, we propose AdEMAMix, a simple modification of the Adam optimizer with a mixture of two EMAs to better take advantage of past gradients. Our experiments on language modeling and image classification show -- quite surprisingly -- that gradients can stay relevant for tens of thousands of steps. They help to converge faster, and often to lower minima: e.g., a $1.3$B parameter AdEMAMix LLM trained on $101$B tokens performs comparably to an AdamW model trained on $197$B tokens ($+95\\%$). Moreover, our method significantly slows-down model forgetting during training. Our work motivates further exploration of different types of functions to leverage past gradients, beyond EMAs.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "38 pages, 27 figures"
    },
    {
        "paper id": "2409.03142",
        "abstract url": "https://arxiv.org/abs/2409.03142",
        "title": "Causal Temporal Representation Learning with Nonstationary Sparse Transition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causal Temporal Representation Learning (Ctrl) methods aim to identify the temporal causal dynamics of complex nonstationary temporal sequences. Despite the success of existing Ctrl methods, they require either directly observing the domain variables or assuming a Markov prior on them. Such requirements limit the application of these methods in real-world scenarios when we do not have such prior knowledge of the domain variables. To address this problem, this work adopts a sparse transition assumption, aligned with intuitive human understanding, and presents identifiability results from a theoretical perspective. In particular, we explore under what conditions on the significance of the variability of the transitions we can build a model to identify the distribution shifts. Based on the theoretical result, we introduce a novel framework, Causal Temporal Representation Learning with Nonstationary Sparse Transition (CtrlNS), designed to leverage the constraints on transition sparsity and conditional independence to reliably identify both distribution shifts and latent factors. Our experimental evaluations on synthetic and real-world datasets demonstrate significant improvements over existing baselines, highlighting the effectiveness of our approach.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03149",
        "abstract url": "https://arxiv.org/abs/2409.03149",
        "title": "Non-stationary and Sparsely-correlated Multi-output Gaussian Process with Spike-and-Slab Prior",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multi-output Gaussian process (MGP) is commonly used as a transfer learning method to leverage information among multiple outputs. A key advantage of MGP is providing uncertainty quantification for prediction, which is highly important for subsequent decision-making tasks. However, traditional MGP may not be sufficiently flexible to handle multivariate data with dynamic characteristics, particularly when dealing with complex temporal correlations. Additionally, since some outputs may lack correlation, transferring information among them may lead to negative transfer. To address these issues, this study proposes a non-stationary MGP model that can capture both the dynamic and sparse correlation among outputs. Specifically, the covariance functions of MGP are constructed using convolutions of time-varying kernel functions. Then a dynamic spike-and-slab prior is placed on correlation parameters to automatically decide which sources are informative to the target output in the training process. An expectation-maximization (EM) algorithm is proposed for efficient model fitting. Both numerical studies and a real case demonstrate its efficacy in capturing dynamic and sparse correlation structure and mitigating negative transfer for high-dimensional time-series data. Finally, a mountain-car reinforcement learning case highlights its potential application in decision making problems.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.MA",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03151",
        "abstract url": "https://arxiv.org/abs/2409.03151",
        "title": "Standing on the shoulders of giants",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Although fundamental to the advancement of Machine Learning, the classic evaluation metrics extracted from the confusion matrix, such as precision and F1, are limited. Such metrics only offer a quantitative view of the models' performance, without considering the complexity of the data or the quality of the hit. To overcome these limitations, recent research has introduced the use of psychometric metrics such as Item Response Theory (IRT), which allows an assessment at the level of latent characteristics of instances. This work investigates how IRT concepts can enrich a confusion matrix in order to identify which model is the most appropriate among options with similar performance. In the study carried out, IRT does not replace, but complements classical metrics by offering a new layer of evaluation and observation of the fine behavior of models in specific instances. It was also observed that there is 97% confidence that the score from the IRT has different contributions from 66% of the classical metrics analyzed.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "15 pages, 8 figures, 3 tables, submitted for the BRACIS'24 conference"
    },
    {
        "paper id": "2409.03164",
        "abstract url": "https://arxiv.org/abs/2409.03164",
        "title": "A Scalable Matrix Visualization for Understanding Tree Ensemble Classifiers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The high performance of tree ensemble classifiers benefits from a large set of rules, which, in turn, makes the models hard to understand. To improve interpretability, existing methods extract a subset of rules for approximation using model reduction techniques. However, by focusing on the reduced rule set, these methods often lose fidelity and ignore anomalous rules that, despite their infrequency, play crucial roles in real-world applications. This paper introduces a scalable visual analysis method to explain tree ensemble classifiers that contain tens of thousands of rules. The key idea is to address the issue of losing fidelity by adaptively organizing the rules as a hierarchy rather than reducing them. To ensure the inclusion of anomalous rules, we develop an anomaly-biased model reduction method to prioritize these rules at each hierarchical level. Synergized with this hierarchical organization of rules, we develop a matrix-based hierarchical visualization to support exploration at different levels of detail. Our quantitative experiments and case studies demonstrate how our method fosters a deeper understanding of both common and anomalous rules, thereby enhancing interpretability without sacrificing comprehensiveness.",
        "subjects": [
            "cs.LG",
            "cs.GR"
        ],
        "comment": "15 pages, 10 figures"
    },
    {
        "paper id": "2409.03167",
        "abstract url": "https://arxiv.org/abs/2409.03167",
        "title": "InfraLib: Enabling Reinforcement Learning and Decision Making for Large Scale Infrastructure Management",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Efficient management of infrastructure systems is crucial for economic stability, sustainability, and public safety. However, infrastructure management is challenging due to the vast scale of systems, stochastic deterioration of components, partial observability, and resource constraints. While data-driven approaches like reinforcement learning (RL) offer a promising avenue for optimizing management policies, their application to infrastructure has been limited by the lack of suitable simulation environments. We introduce InfraLib, a comprehensive framework for modeling and analyzing infrastructure management problems. InfraLib employs a hierarchical, stochastic approach to realistically model infrastructure systems and their deterioration. It supports practical functionality such as modeling component unavailability, cyclical budgets, and catastrophic failures. To facilitate research, InfraLib provides tools for expert data collection, simulation-driven analysis, and visualization. We demonstrate InfraLib's capabilities through case studies on a real-world road network and a synthetic benchmark with 100,000 components.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03187",
        "abstract url": "https://arxiv.org/abs/2409.03187",
        "title": "How noise affects memory in linear recurrent networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The effects of noise on memory in a linear recurrent network are theoretically investigated. Memory is characterized by its ability to store previous inputs in its instantaneous state of network, which receives a correlated or uncorrelated noise. Two major properties are revealed: First, the memory reduced by noise is uniquely determined by the noise's power spectral density (PSD). Second, the memory will not decrease regardless of noise intensity if the PSD is in a certain class of distribution (including power law). The results are verified using the human brain signals, showing good agreement.",
        "subjects": [
            "cs.NE",
            "cond-mat.dis-nn",
            "cs.LG",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03204",
        "abstract url": "https://arxiv.org/abs/2409.03204",
        "title": "Pricing American Options using Machine Learning Algorithms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study investigates the application of machine learning algorithms, particularly in the context of pricing American options using Monte Carlo simulations. Traditional models, such as the Black-Scholes-Merton framework, often fail to adequately address the complexities of American options, which include the ability for early exercise and non-linear payoff structures. By leveraging Monte Carlo methods in conjunction Least Square Method machine learning was used. This research aims to improve the accuracy and efficiency of option pricing. The study evaluates several machine learning models, including neural networks and decision trees, highlighting their potential to outperform traditional approaches. The results from applying machine learning algorithm in LSM indicate that integrating machine learning with Monte Carlo simulations can enhance pricing accuracy and provide more robust predictions, offering significant insights into quantitative finance by merging classical financial theories with modern computational techniques. The dataset was split into features and the target variable representing bid prices, with an 80-20 train-validation split. LSTM and GRU models were constructed using TensorFlow's Keras API, each with four hidden layers of 200 neurons and an output layer for bid price prediction, optimized with the Adam optimizer and MSE loss function. The GRU model outperformed the LSTM model across all evaluated metrics, demonstrating lower mean absolute error, mean squared error, and root mean squared error, along with greater stability and efficiency in training.",
        "subjects": [
            "cs.LG",
            "q-fin.CP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03218",
        "abstract url": "https://arxiv.org/abs/2409.03218",
        "title": "Application Research On Real-Time Perception Of Device Performance Status",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In order to accurately identify the performance status of mobile devices and finely adjust the user experience, a real-time performance perception evaluation method based on TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) combined with entropy weighting method and time series model construction was studied. After collecting the performance characteristics of various mobile devices, the device performance profile was fitted by using PCA (principal component analysis) dimensionality reduction and feature engineering methods such as descriptive time series analysis. The ability of performance features and profiles to describe the real-time performance status of devices was understood and studied by applying the TOPSIS method and multi-level weighting processing. A time series model was constructed for the feature set under objective weighting, and multiple sensitivity (real-time, short-term, long-term) performance status perception results were provided to obtain real-time performance evaluation data and long-term stable performance prediction data. Finally, by configuring dynamic AB experiments and overlaying fine-grained power reduction strategies, the usability of the method was verified, and the accuracy of device performance status identification and prediction was compared with the performance of the profile features including dimensionality reduction time series modeling, TOPSIS method and entropy weighting method, subjective weighting, HMA method. The results show that accurate real-time performance perception results can greatly enhance business value, and this research has application effectiveness and certain forward-looking significance.",
        "subjects": [
            "cs.PF",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03219",
        "abstract url": "https://arxiv.org/abs/2409.03219",
        "title": "Content Moderation by LLM: From Accuracy to Legitimacy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "One trending application of LLM (large language model) is to use it for content moderation in online platforms. Most current studies on this application have focused on the metric of accuracy - the extent to which LLM makes correct decisions about content. This article argues that accuracy is insufficient and misleading, because it fails to grasp the distinction between easy cases and hard cases as well as the inevitable trade-offs in achieving higher accuracy. Closer examination reveals that content moderation is a constitutive part of platform governance, the key of which is to gain and enhance legitimacy. Instead of making moderation decisions correct, the chief goal of LLM is to make them legitimate. In this regard, this article proposes a paradigm shift from the single benchmark of accuracy towards a legitimacy-based framework of evaluating the performance of LLM moderators. The framework suggests that for easy cases, the key is to ensure accuracy, speed and transparency, while for hard cases, what matters is reasoned justification and user participation. Examined under this framework, LLM's real potential in moderation is not accuracy improvement. Rather, LLM can better contribute in four other aspects: to conduct screening of hard cases from easy cases, to provide quality explanations for moderation decisions, to assist human reviewers in getting more contextual information, and to facilitate user participation in a more interactive way. Using normative theories from law and social sciences to critically assess the new technological application, this article seeks to redefine LLM's role in content moderation and redirect relevant research in this field.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.ET",
            "cs.HC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03220",
        "abstract url": "https://arxiv.org/abs/2409.03220",
        "title": "FairQuant: Certifying and Quantifying Fairness of Deep Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a method for formally certifying and quantifying individual fairness of deep neural networks (DNN). Individual fairness guarantees that any two individuals who are identical except for a legally protected attribute (e.g., gender or race) receive the same treatment. While there are existing techniques that provide such a guarantee, they tend to suffer from lack of scalability or accuracy as the size and input dimension of the DNN increase. Our method overcomes this limitation by applying abstraction to a symbolic interval based analysis of the DNN followed by iterative refinement guided by the fairness property. Furthermore, our method lifts the symbolic interval based analysis from conventional qualitative certification to quantitative certification, by computing the percentage of individuals whose classification outputs are provably fair, instead of merely deciding if the DNN is fair. We have implemented our method and evaluated it on deep neural networks trained on four popular fairness research datasets. The experimental results show that our method is not only more accurate than state-of-the-art techniques but also several orders-of-magnitude faster.",
        "subjects": [
            "cs.LG",
            "cs.SE"
        ],
        "comment": "To Appear In Proceedings of the 47th IEEE/ACM International Conference on Software Engineering (ICSE 2025)"
    },
    {
        "paper id": "2409.03710",
        "abstract url": "https://arxiv.org/abs/2409.03710",
        "title": "Inverse decision-making using neural amortized Bayesian actors",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian observer and actor models have provided normative explanations for many behavioral phenomena in perception, sensorimotor control, and other areas of cognitive science and neuroscience. They attribute behavioral variability and biases to different interpretable entities such as perceptual and motor uncertainty, prior beliefs, and behavioral costs. However, when extending these models to more complex tasks with continuous actions, solving the Bayesian decision-making problem is often analytically intractable. Moreover, inverting such models to perform inference over their parameters given behavioral data is computationally even more difficult. Therefore, researchers typically constrain their models to easily tractable components, such as Gaussian distributions or quadratic cost functions, or resort to numerical methods. To overcome these limitations, we amortize the Bayesian actor using a neural network trained on a wide range of different parameter settings in an unsupervised fashion. Using the pre-trained neural network enables performing gradient-based Bayesian inference of the Bayesian actor model's parameters. We show on synthetic data that the inferred posterior distributions are in close alignment with those obtained using analytical solutions where they exist. Where no analytical solution is available, we recover posterior distributions close to the ground truth. We then show that identifiability problems between priors and costs can arise in more complex cost functions. Finally, we apply our method to empirical data and show that it explains systematic individual differences of behavioral patterns.",
        "subjects": [
            "cs.LG",
            "q-bio.NC",
            "stat.ML"
        ],
        "comment": "19 pages, 7 figures"
    },
    {
        "paper id": "2409.03801",
        "abstract url": "https://arxiv.org/abs/2409.03801",
        "title": "Resultant: Incremental Effectiveness on Likelihood for Unsupervised Out-of-Distribution Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Unsupervised out-of-distribution (U-OOD) detection is to identify OOD data samples with a detector trained solely on unlabeled in-distribution (ID) data. The likelihood function estimated by a deep generative model (DGM) could be a natural detector, but its performance is limited in some popular \"hard\" benchmarks, such as FashionMNIST (ID) vs. MNIST (OOD). Recent studies have developed various detectors based on DGMs to move beyond likelihood. However, despite their success on \"hard\" benchmarks, most of them struggle to consistently surpass or match the performance of likelihood on some \"non-hard\" cases, such as SVHN (ID) vs. CIFAR10 (OOD) where likelihood could be a nearly perfect detector. Therefore, we appeal for more attention to incremental effectiveness on likelihood, i.e., whether a method could always surpass or at least match the performance of likelihood in U-OOD detection. We first investigate the likelihood of variational DGMs and find its detection performance could be improved in two directions: i) alleviating latent distribution mismatch, and ii) calibrating the dataset entropy-mutual integration. Then, we apply two techniques for each direction, specifically post-hoc prior and dataset entropy-mutual calibration. The final method, named Resultant, combines these two directions for better incremental effectiveness compared to either technique alone. Experimental results demonstrate that the Resultant could be a new state-of-the-art U-OOD detector while maintaining incremental effectiveness on likelihood in a wide range of tasks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02481",
        "abstract url": "https://arxiv.org/abs/2409.02481",
        "title": "Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Effective question classification is crucial for AI-driven educational tools, enabling adaptive learning systems to categorize questions by skill area, difficulty level, and competence. This classification not only supports educational diagnostics and analytics but also enhances complex tasks like information retrieval and question answering by associating questions with relevant categories. Traditional methods, often based on word embeddings and conventional classifiers, struggle to capture the nuanced relationships in natural language, leading to suboptimal performance. To address this, we propose a novel approach leveraging graph convolutional networks (GCNs), named Phrase Question-Graph Convolutional Network (PQ-GCN) to better model the inherent structure of questions. By representing questions as graphs -- where nodes signify words or phrases and edges denote syntactic or semantic relationships -- our method allows GCNs to learn from the interconnected nature of language more effectively. Additionally, we explore the incorporation of phrase-based features to enhance classification accuracy, especially in low-resource settings. Our findings demonstrate that GCNs, augmented with these features, offer a promising solution for more accurate and context-aware question classification, bridging the gap between graph neural network research and practical educational applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02482",
        "abstract url": "https://arxiv.org/abs/2409.02482",
        "title": "Volumetric Surfaces: Representing Fuzzy Geometries with Multiple Meshes",
        "rating": "0",
        "keywords": [
            [
                "SDF"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "High-quality real-time view synthesis methods are based on volume rendering, splatting, or surface rendering. While surface-based methods generally are the fastest, they cannot faithfully model fuzzy geometry like hair. In turn, alpha-blending techniques excel at representing fuzzy materials but require an unbounded number of samples per ray (P1). Further overheads are induced by empty space skipping in volume rendering (P2) and sorting input primitives in splatting (P3). These problems are exacerbated on low-performance graphics hardware, e.g. on mobile devices. We present a novel representation for real-time view synthesis where the (P1) number of sampling locations is small and bounded, (P2) sampling locations are efficiently found via rasterization, and (P3) rendering is sorting-free. We achieve this by representing objects as semi-transparent multi-layer meshes, rendered in fixed layer order from outermost to innermost. We model mesh layers as SDF shells with optimal spacing learned during training. After baking, we fit UV textures to the corresponding meshes. We show that our method can represent challenging fuzzy objects while achieving higher frame rates than volume-based and splatting-based methods on low-end and mobile devices.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02494",
        "abstract url": "https://arxiv.org/abs/2409.02494",
        "title": "Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth Estimation",
        "rating": "0",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Monocular depth estimation aims to infer a dense depth map from a single image, which is a fundamental and prevalent task in computer vision. Many previous works have shown impressive depth estimation results through carefully designed network structures, but they usually ignore the planar information and therefore perform poorly in low-texture areas of indoor scenes. In this paper, we propose Plane2Depth, which adaptively utilizes plane information to improve depth prediction within a hierarchical framework. Specifically, in the proposed plane guided depth generator (PGDG), we design a set of plane queries as prototypes to softly model planes in the scene and predict per-pixel plane coefficients. Then the predicted plane coefficients can be converted into metric depth values with the pinhole camera model. In the proposed adaptive plane query aggregation (APGA) module, we introduce a novel feature interaction approach to improve the aggregation of multi-scale plane features in a top-down manner. Extensive experiments show that our method can achieve outstanding performance, especially in low-texture or repetitive areas. Furthermore, under the same backbone network, our method outperforms the state-of-the-art methods on the NYU-Depth-v2 dataset, achieves competitive results with state-of-the-art methods KITTI dataset and can be generalized to unseen scenes effectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 12 figures, 8 tables"
    },
    {
        "paper id": "2409.02497",
        "abstract url": "https://arxiv.org/abs/2409.02497",
        "title": "A Learnable Color Correction Matrix for RAW Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "Autonomous driving"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Autonomous driving algorithms usually employ sRGB images as model input due to their compatibility with the human visual system. However, visually pleasing sRGB images are possibly sub-optimal for downstream tasks when compared to RAW images. The availability of RAW images is constrained by the difficulties in collecting real-world driving data and the associated challenges of annotation. To address this limitation and support research in RAW-domain driving perception, we design a novel and ultra-lightweight RAW reconstruction method. The proposed model introduces a learnable color correction matrix (CCM), which uses only a single convolutional layer to approximate the complex inverse image signal processor (ISP). Experimental results demonstrate that simulated RAW (simRAW) images generated by our method provide performance improvements equivalent to those produced by more complex inverse ISP methods when pretraining RAW-domain object detectors, which highlights the effectiveness and practicality of our approach.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted by BMVC2024"
    },
    {
        "paper id": "2409.02508",
        "abstract url": "https://arxiv.org/abs/2409.02508",
        "title": "TLD: A Vehicle Tail Light signal Dataset and Benchmark",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "Vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding other drivers' intentions is crucial for safe driving. The role of taillights in conveying these intentions is underemphasized in current autonomous driving systems. Accurately identifying taillight signals is essential for predicting vehicle behavior and preventing collisions. Open-source taillight datasets are scarce, often small and inconsistently annotated. To address this gap, we introduce a new large-scale taillight dataset called TLD. Sourced globally, our dataset covers diverse traffic scenarios. To our knowledge, TLD is the first dataset to separately annotate brake lights and turn signals in real driving scenarios. We collected 17.78 hours of driving videos from the internet. This dataset consists of 152k labeled image frames sampled at a rate of 2 Hz, along with 1.5 million unlabeled frames interspersed throughout. Additionally, we have developed a two-stage vehicle light detection model consisting of two primary modules: a vehicle detector and a taillight classifier. Initially, YOLOv10 and DeepSORT captured consecutive vehicle images over time. Subsequently, the two classifiers work simultaneously to determine the states of the brake lights and turn signals. A post-processing procedure is then used to eliminate noise caused by misidentifications and provide the taillight states of the vehicle within a given time frame. Our method shows exceptional performance on our dataset, establishing a benchmark for vehicle taillight detection. The dataset is available at https://huggingface.co/datasets/ChaiJohn/TLD/tree/main",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02513",
        "abstract url": "https://arxiv.org/abs/2409.02513",
        "title": "SG-MIM: Structured Knowledge Guided Efficient Pre-training for Dense Prediction",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Masked Image Modeling (MIM) techniques have redefined the landscape of computer vision, enabling pre-trained models to achieve exceptional performance across a broad spectrum of tasks. Despite their success, the full potential of MIM-based methods in dense prediction tasks, particularly in depth estimation, remains untapped. Existing MIM approaches primarily rely on single-image inputs, which makes it challenging to capture the crucial structured information, leading to suboptimal performance in tasks requiring fine-grained feature representation. To address these limitations, we propose SG-MIM, a novel Structured knowledge Guided Masked Image Modeling framework designed to enhance dense prediction tasks by utilizing structured knowledge alongside images. SG-MIM employs a lightweight relational guidance framework, allowing it to guide structured knowledge individually at the feature level rather than naively combining at the pixel level within the same architecture, as is common in traditional multi-modal pre-training methods. This approach enables the model to efficiently capture essential information while minimizing discrepancies between pre-training and downstream tasks. Furthermore, SG-MIM employs a selective masking strategy to incorporate structured knowledge, maximizing the synergy between general representation learning and structured knowledge-specific learning. Our method requires no additional annotations, making it a versatile and efficient solution for a wide range of applications. Our evaluations on the KITTI, NYU-v2, and ADE20k datasets demonstrate SG-MIM's superiority in monocular depth estimation and semantic segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02529",
        "abstract url": "https://arxiv.org/abs/2409.02529",
        "title": "Sample what you cant compress",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "GAN"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "For learned image representations, basic autoencoders often produce blurry results. Reconstruction quality can be improved by incorporating additional penalties such as adversarial (GAN) and perceptual losses. Arguably, these approaches lack a principled interpretation. Concurrently, in generative settings diffusion has demonstrated a remarkable ability to create crisp, high quality results and has solid theoretical underpinnings (from variational inference to direct study as the Fisher Divergence). Our work combines autoencoder representation learning with diffusion and is, to our knowledge, the first to demonstrate the efficacy of jointly learning a continuous encoder and decoder under a diffusion-based loss. We demonstrate that this approach yields better reconstruction quality as compared to GAN-based autoencoders while being easier to tune. We also show that the resulting representation is easier to model with a latent diffusion model as compared to the representation obtained from a state-of-the-art GAN-based loss. Since our decoder is stochastic, it can generate details not encoded in the otherwise deterministic latent representation; we therefore name our approach \"Sample what you can't compress\", or SWYCC for short.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02545",
        "abstract url": "https://arxiv.org/abs/2409.02545",
        "title": "UniTT-Stereo: Unified Training of Transformer for Enhanced Stereo Matching",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unlike other vision tasks where Transformer-based approaches are becoming increasingly common, stereo depth estimation is still dominated by convolution-based approaches. This is mainly due to the limited availability of real-world ground truth for stereo matching, which is a limiting factor in improving the performance of Transformer-based stereo approaches. In this paper, we propose UniTT-Stereo, a method to maximize the potential of Transformer-based stereo architectures by unifying self-supervised learning used for pre-training with stereo matching framework based on supervised learning. To be specific, we explore the effectiveness of reconstructing features of masked portions in an input image and at the same time predicting corresponding points in another image from the perspective of locality inductive bias, which is crucial in training models with limited training data. Moreover, to address these challenging tasks of reconstruction-and-prediction, we present a new strategy to vary a masking ratio when training the stereo model with stereo-tailored losses. State-of-the-art performance of UniTT-Stereo is validated on various benchmarks such as ETH3D, KITTI 2012, and KITTI 2015 datasets. Lastly, to investigate the advantages of the proposed approach, we provide a frequency analysis of feature maps and the analysis of locality inductive bias based on attention maps.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02574",
        "abstract url": "https://arxiv.org/abs/2409.02574",
        "title": "Solving Video Inverse Problems Using Image Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "inpainting",
                "super-resolution"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, diffusion model-based inverse problem solvers (DIS) have emerged as state-of-the-art approaches for addressing inverse problems, including image super-resolution, deblurring, inpainting, etc. However, their application to video inverse problems arising from spatio-temporal degradation remains largely unexplored due to the challenges in training video diffusion models. To address this issue, here we introduce an innovative video inverse solver that leverages only image diffusion models. Specifically, by drawing inspiration from the success of the recent decomposed diffusion sampler (DDS), our method treats the time dimension of a video as the batch dimension of image diffusion models and solves spatio-temporal optimization problems within denoised spatio-temporal batches derived from each image diffusion model. Moreover, we introduce a batch-consistent diffusion sampling strategy that encourages consistency across batches by synchronizing the stochastic noise components in image diffusion models. Our approach synergistically combines batch-consistent sampling with simultaneous optimization of denoised spatio-temporal batches at each reverse diffusion step, resulting in a novel and efficient diffusion sampling strategy for video inverse problems. Experimental results demonstrate that our method effectively addresses various spatio-temporal degradations in video inverse problems, achieving state-of-the-art reconstructions. Project page: https://solving-video-inverse.github.io/main/",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "22 pages, 16 figures"
    },
    {
        "paper id": "2409.02611",
        "abstract url": "https://arxiv.org/abs/2409.02611",
        "title": "GoT-CQA: Graph-of-Thought Guided Compositional Reasoning for Chart Question Answering",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Chart Question Answering (CQA) aims at answering questions based on the visual chart content, which plays an important role in chart sumarization, business data analysis, and data report generation. CQA is a challenging multi-modal task because of the strong context dependence and complex reasoning requirement. The former refers to answering this question strictly based on the analysis of the visual content or internal data of the given chart, while the latter emphasizes the various logical and numerical reasoning involved in answer prediction process. In this paper, we pay more attention on the complex reasoning in CQA task, and propose a novel Graph-of-Thought (GoT) guided compositional reasoning model called GoT-CQA to overcome this problem. At first, we transform the chart-oriented question into a directed acyclic GoT composed of multiple operator nodes, including localization, numerical and logical operator. It intuitively reflects the human brain's solution process to this question. After that, we design an efficient auto-compositional reasoning framework guided by the GoT, to excute the multi-step reasoning operations in various types of questions. Comprehensive experiments on ChartQA and PlotQA-D datasets show that GoT-CQA achieves outstanding performance, especially in complex human-written and reasoning questions, comparing with the latest popular baselines.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02629",
        "abstract url": "https://arxiv.org/abs/2409.02629",
        "title": "AdvSecureNet: A Python Toolkit for Adversarial Machine Learning",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Machine learning models are vulnerable to adversarial attacks. Several tools have been developed to research these vulnerabilities, but they often lack comprehensive features and flexibility. We introduce AdvSecureNet, a PyTorch based toolkit for adversarial machine learning that is the first to natively support multi-GPU setups for attacks, defenses, and evaluation. It is the first toolkit that supports both CLI and API interfaces and external YAML configuration files to enhance versatility and reproducibility. The toolkit includes multiple attacks, defenses and evaluation metrics. Rigiorous software engineering practices are followed to ensure high code quality and maintainability. The project is available as an open-source project on GitHub at https://github.com/melihcatal/advsecurenet and installable via PyPI.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02647",
        "abstract url": "https://arxiv.org/abs/2409.02647",
        "title": "Learning-Based Error Detection System for Advanced Vehicle Instrument Cluster Rendering",
        "rating": "0",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The automotive industry is currently expanding digital display options with every new model that comes onto the market. This entails not just an expansion in dimensions, resolution, and customization choices, but also the capability to employ novel display effects like overlays while assembling the content of the display cluster. Unfortunately, this raises the need for appropriate monitoring systems that can detect rendering errors and apply appropriate countermeasures when required. Classical solutions such as Cyclic Redundancy Checks (CRC) will soon be no longer viable as any sort of alpha blending, warping of scaling of content can cause unwanted CRC violations. Therefore, we propose a novel monitoring approach to verify correctness of displayed content using telltales (e.g. warning signs) as example. It uses a learning-based approach to separate \"good\" telltales, i.e. those that a human driver will understand correctly, and \"corrupted\" telltales, i.e. those that will not be visible or perceived correctly. As a result, it possesses inherent resilience against individual pixel errors and implicitly supports changing backgrounds, overlay or scaling effects. This is underlined by our experimental study where all \"corrupted\" test patterns were correctly classified, while no false alarms were triggered.",
        "subjects": [
            "cs.CV",
            "cs.HC",
            "cs.LG",
            "cs.RO",
            "eess.IV"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2409.02649",
        "abstract url": "https://arxiv.org/abs/2409.02649",
        "title": "OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents the experiments and results for the CheckThat! Lab at CLEF 2024 Task 6: Robustness of Credibility Assessment with Adversarial Examples (InCrediblAE). The primary objective of this task was to generate adversarial examples in five problem domains in order to evaluate the robustness of widely used text classification methods (fine-tuned BERT, BiLSTM, and RoBERTa) when applied to credibility assessment issues. This study explores the application of ensemble learning to enhance adversarial attacks on natural language processing (NLP) models. We systematically tested and refined several adversarial attack methods, including BERT-Attack, Genetic algorithms, TextFooler, and CLARE, on five datasets across various misinformation tasks. By developing modified versions of BERT-Attack and hybrid methods, we achieved significant improvements in attack effectiveness. Our results demonstrate the potential of modification and combining multiple methods to create more sophisticated and effective adversarial attack strategies, contributing to the development of more robust and secure systems.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "CLEF 2024 - Conference and Labs of the Evaluation Forum"
    },
    {
        "paper id": "2409.02657",
        "abstract url": "https://arxiv.org/abs/2409.02657",
        "title": "PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "While previous audio-driven talking head generation (THG) methods generate head poses from driving audio, the generated poses or lips cannot match the audio well or are not editable. In this study, we propose \\textbf{PoseTalk}, a THG system that can freely generate lip-synchronized talking head videos with free head poses conditioned on text prompts and audio. The core insight of our method is using head pose to connect visual, linguistic, and audio signals. First, we propose to generate poses from both audio and text prompts, where the audio offers short-term variations and rhythm correspondence of the head movements and the text prompts describe the long-term semantics of head motions. To achieve this goal, we devise a Pose Latent Diffusion (PLD) model to generate motion latent from text prompts and audio cues in a pose latent space. Second, we observe a loss-imbalance problem: the loss for the lip region contributes less than 4\\% of the total reconstruction loss caused by both pose and lip, making optimization lean towards head movements rather than lip shapes. To address this issue, we propose a refinement-based learning strategy to synthesize natural talking videos using two cascaded networks, i.e., CoarseNet, and RefineNet. The CoarseNet estimates coarse motions to produce animated images in novel poses and the RefineNet focuses on learning finer lip motions by progressively estimating lip motions from low-to-high resolutions, yielding improved lip-synchronization performance. Experiments demonstrate our pose prediction strategy achieves better pose diversity and realness compared to text-only or audio-only, and our video generator model outperforms state-of-the-art methods in synthesizing talking videos with natural head motions. Project: https://junleen.github.io/projects/posetalk.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "7+5 pages, 15 figures"
    },
    {
        "paper id": "2409.02686",
        "abstract url": "https://arxiv.org/abs/2409.02686",
        "title": "Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs",
        "rating": "0",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable efficiency in tackling various tasks based on human instructions, but recent studies reveal that these models often fail to achieve satisfactory results on questions involving reasoning, such as mathematics or physics questions. This phenomenon is usually attributed to the uncertainty regarding whether these models could genuinely comprehend the knowledge embedded in the text or merely learn to replicate the token distribution without a true understanding of the content. In this paper, we delve into this problem and aim to enhance the reasoning capabilities of LLMs. First, we investigate if the model has genuine reasoning capabilities by visualizing the text generation process at the attention and representation level. Then, we formulate the reasoning process of LLMs into a causal framework, which provides a formal explanation of the problems we observe in the visualization. Finally, building upon this causal framework, we propose Deconfounded Causal Adaptation (DCA), a novel parameter-efficient fine-tuning (PEFT) method to enhance the model's reasoning capabilities by encouraging the model to extract the general problem-solving skills and apply these skills to different questions. Experiments show that our method outperforms the baseline consistently across multiple benchmarks, and with only 1.2M tunable parameters, we achieve better or comparable results to other fine-tuning methods. This demonstrates the effectiveness and efficiency of our method in improving the overall accuracy and reliability of LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02792",
        "abstract url": "https://arxiv.org/abs/2409.02792",
        "title": "UnLearning from Experience to Avoid Spurious Correlations",
        "rating": "0",
        "keywords": [
            [
                "UnLearning"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "While deep neural networks can achieve state-of-the-art performance in many tasks, these models are more fragile than they appear. They are prone to learning spurious correlations in their training data, leading to surprising failure cases. In this paper, we propose a new approach that addresses the issue of spurious correlations: UnLearning from Experience (ULE). Our method is based on using two classification models trained in parallel: student and teacher models. Both models receive the same batches of training data. The student model is trained with no constraints and pursues the spurious correlations in the data. The teacher model is trained to solve the same classification problem while avoiding the mistakes of the student model. As training is done in parallel, the better the student model learns the spurious correlations, the more robust the teacher model becomes. The teacher model uses the gradient of the student's output with respect to its input to unlearn mistakes made by the student. We show that our method is effective on the Waterbirds, CelebA, Spawrious and UrbanCars datasets.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2409.02846",
        "abstract url": "https://arxiv.org/abs/2409.02846",
        "title": "MaDis-Stereo: Enhanced Stereo Matching via Distilled Masked Image Modeling",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In stereo matching, CNNs have traditionally served as the predominant architectures. Although Transformer-based stereo models have been studied recently, their performance still lags behind CNN-based stereo models due to the inherent data scarcity issue in the stereo matching task. In this paper, we propose Masked Image Modeling Distilled Stereo matching model, termed MaDis-Stereo, that enhances locality inductive bias by leveraging Masked Image Modeling (MIM) in training Transformer-based stereo model. Given randomly masked stereo images as inputs, our method attempts to conduct both image reconstruction and depth prediction tasks. While this strategy is beneficial to resolving the data scarcity issue, the dual challenge of reconstructing masked tokens and subsequently performing stereo matching poses significant challenges, particularly in terms of training stability. To address this, we propose to use an auxiliary network (teacher), updated via Exponential Moving Average (EMA), along with the original stereo model (student), where teacher predictions serve as pseudo supervisory signals to effectively distill knowledge into the student model. State-of-the-arts performance is achieved with the proposed method on several stereo matching such as ETH3D and KITTI 2015. Additionally, to demonstrate that our model effectively leverages locality inductive bias, we provide the attention distance measurement.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02908",
        "abstract url": "https://arxiv.org/abs/2409.02908",
        "title": "Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Masked diffusion models (MDMs) have emerged as a popular research topic for generative modeling of discrete data, thanks to their superior performance over other discrete diffusion models, and are rivaling the auto-regressive models (ARMs) for language modeling tasks. The recent effort in simplifying the masked diffusion framework further leads to alignment with continuous-space diffusion models and more principled training and sampling recipes. In this paper, however, we reveal that both training and sampling of MDMs are theoretically free from the time variable, arguably the key signature of diffusion models, and are instead equivalent to masked models. The connection on the sampling aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we show that the FHS is theoretically equivalent to MDMs' original generation process while significantly alleviating the time-consuming categorical sampling and achieving a 20$\\times$ speedup. In addition, our investigation challenges previous claims that MDMs can surpass ARMs in generative perplexity. We identify, for the first time, an underlying numerical issue, even with the 32-bit floating-point precision, which results in inaccurate categorical sampling. We show that the numerical issue lowers the effective temperature both theoretically and empirically, leading to unfair assessments of MDMs' generation results in the previous literature.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "40 pages"
    },
    {
        "paper id": "2409.02919",
        "abstract url": "https://arxiv.org/abs/2409.02919",
        "title": "HiPrompt: Tuning-free Higher-Resolution Generation with Hierarchical MLLM Prompts",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The potential for higher-resolution image generation using pretrained diffusion models is immense, yet these models often struggle with issues of object repetition and structural artifacts especially when scaling to 4K resolution and higher. We figure out that the problem is caused by that, a single prompt for the generation of multiple scales provides insufficient efficacy. In response, we propose HiPrompt, a new tuning-free solution that tackles the above problems by introducing hierarchical prompts. The hierarchical prompts offer both global and local guidance. Specifically, the global guidance comes from the user input that describes the overall content, while the local guidance utilizes patch-wise descriptions from MLLMs to elaborately guide the regional structure and texture generation. Furthermore, during the inverse denoising process, the generated noise is decomposed into low- and high-frequency spatial components. These components are conditioned on multiple prompt levels, including detailed patch-wise descriptions and broader image-level prompts, facilitating prompt-guided denoising under hierarchical semantic guidance. It further allows the generation to focus more on local spatial regions and ensures the generated images maintain coherent local and global semantics, structures, and textures with high definition. Extensive experiments demonstrate that HiPrompt outperforms state-of-the-art works in higher-resolution image generation, significantly reducing object repetition and enhancing structural quality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "https://liuxinyv.github.io/HiPrompt/"
    },
    {
        "paper id": "2409.03022",
        "abstract url": "https://arxiv.org/abs/2409.03022",
        "title": "Boundless: Generating Photorealistic Synthetic Data for Object Detection in Urban Streetscapes",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce Boundless, a photo-realistic synthetic data generation system for enabling highly accurate object detection in dense urban streetscapes. Boundless can replace massive real-world data collection and manual ground-truth object annotation (labeling) with an automated and configurable process. Boundless is based on the Unreal Engine 5 (UE5) City Sample project with improvements enabling accurate collection of 3D bounding boxes across different lighting and scene variability conditions. We evaluate the performance of object detection models trained on the dataset generated by Boundless when used for inference on a real-world dataset acquired from medium-altitude cameras. We compare the performance of the Boundless-trained model against the CARLA-trained model and observe an improvement of 7.8 mAP. The results we achieved support the premise that synthetic data generation is a credible methodology for training/fine-tuning scalable object detection models for urban scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03034",
        "abstract url": "https://arxiv.org/abs/2409.03034",
        "title": "MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We propose a novel framework for representing neural fields on triangle meshes that is multi-resolution across both spatial and frequency domains. Inspired by the Neural Fourier Filter Bank (NFFB), our architecture decomposes the spatial and frequency domains by associating finer spatial resolution levels with higher frequency bands, while coarser resolutions are mapped to lower frequencies. To achieve geometry-aware spatial decomposition we leverage multiple DiffusionNet components, each associated with a different spatial resolution level. Subsequently, we apply a Fourier feature mapping to encourage finer resolution levels to be associated with higher frequencies. The final signal is composed in a wavelet-inspired manner using a sine-activated MLP, aggregating higher-frequency signals on top of lower-frequency ones. Our architecture attains high accuracy in learning complex neural fields and is robust to discontinuities, exponential scale variations of the target field, and mesh modification. We demonstrate the effectiveness of our approach through its application to diverse neural fields, such as synthetic RGB functions, UV texture coordinates, and vertex normals, illustrating different challenges. To validate our method, we compare its performance against two alternatives, showcasing the advantages of our multi-resolution architecture.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03106",
        "abstract url": "https://arxiv.org/abs/2409.03106",
        "title": "Spatial Diffusion for Cell Layout Generation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generative models, such as GANs and diffusion models, have been used to augment training sets and boost performances in different tasks. We focus on generative models for cell detection instead, i.e., locating and classifying cells in given pathology images. One important information that has been largely overlooked is the spatial patterns of the cells. In this paper, we propose a spatial-pattern-guided generative model for cell layout generation. Specifically, a novel diffusion model guided by spatial features and generates realistic cell layouts has been proposed. We explore different density models as spatial features for the diffusion model. In downstream tasks, we show that the generated cell layouts can be used to guide the generation of high-quality pathology images. Augmenting with these images can significantly boost the performance of SOTA cell detection methods. The code is available at https://github.com/superlc1995/Diffusion-cell.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 4 figures, accepted by MICCAI 2024"
    },
    {
        "paper id": "2409.03131",
        "abstract url": "https://arxiv.org/abs/2409.03131",
        "title": "Well, that escalated quickly: The Single-Turn Crescendo Attack (STCA)",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper explores a novel approach to adversarial attacks on large language models (LLM): the Single-Turn Crescendo Attack (STCA). The STCA builds upon the multi-turn crescendo attack established by Mark Russinovich, Ahmed Salem, Ronen Eldan. Traditional multi-turn adversarial strategies gradually escalate the context to elicit harmful or controversial responses from LLMs. However, this paper introduces a more efficient method where the escalation is condensed into a single interaction. By carefully crafting the prompt to simulate an extended dialogue, the attack bypasses typical content moderation systems, leading to the generation of responses that would normally be filtered out. I demonstrate this technique through a few case studies. The results highlight vulnerabilities in current LLMs and underscore the need for more robust safeguards. This work contributes to the broader discourse on responsible AI (RAI) safety and adversarial testing, providing insights and practical examples for researchers and developers. This method is unexplored in the literature, making it a novel contribution to the field.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03143",
        "abstract url": "https://arxiv.org/abs/2409.03143",
        "title": "Large \u00c9tendue 3D Holographic Display with Content-adpative Dynamic Fourier Modulation",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Emerging holographic display technology offers unique capabilities for next-generation virtual reality systems. Current holographic near-eye displays, however, only support a small \u00e9tendue, which results in a direct tradeoff between achievable field of view and eyebox size. \u00c9tendue expansion has recently been explored, but existing approaches are either fundamentally limited in the image quality that can be achieved or they require extremely high-speed spatial light modulators. We describe a new \u00e9tendue expansion approach that combines multiple coherent sources with content-adaptive amplitude modulation of the hologram spectrum in the Fourier plane. To generate time-multiplexed phase and amplitude patterns for our spatial light modulators, we devise a pupil-aware gradient-descent-based computer-generated holography algorithm that is supervised by a large-baseline target light field. Compared with relevant baseline approaches, our method demonstrates significant improvements in image quality and \u00e9tendue in simulation and with an experimental holographic display prototype.",
        "subjects": [
            "cs.GR",
            "eess.IV",
            "physics.optics"
        ],
        "comment": "12 pages, 7 figures, to be published in SIGGRAPH Asia 2024. Project website: https://bchao1.github.io/holo_dfm/"
    },
    {
        "paper id": "2409.03155",
        "abstract url": "https://arxiv.org/abs/2409.03155",
        "title": "Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) may suffer from hallucinations in real-world applications due to the lack of relevant knowledge. In contrast, knowledge graphs encompass extensive, multi-relational structures that store a vast array of symbolic facts. Consequently, integrating LLMs with knowledge graphs has been extensively explored, with Knowledge Graph Question Answering (KGQA) serving as a critical touchstone for the integration. This task requires LLMs to answer natural language questions by retrieving relevant triples from knowledge graphs. However, existing methods face two significant challenges: \\textit{excessively long reasoning paths distracting from the answer generation}, and \\textit{false-positive relations hindering the path refinement}. In this paper, we propose an iterative interactive KGQA framework that leverages the interactive learning capabilities of LLMs to perform reasoning and Debating over Graphs (DoG). Specifically, DoG employs a subgraph-focusing mechanism, allowing LLMs to perform answer trying after each reasoning step, thereby mitigating the impact of lengthy reasoning paths. On the other hand, DoG utilizes a multi-role debate team to gradually simplify complex questions, reducing the influence of false-positive relations. This debate mechanism ensures the reliability of the reasoning process. Experimental results on five public datasets demonstrate the effectiveness and superiority of our architecture. Notably, DoG outperforms the state-of-the-art method ToG by 23.7\\% and 9.1\\% in accuracy on WebQuestions and GrailQA, respectively. Furthermore, the integration experiments with various LLMs on the mentioned datasets highlight the flexibility of DoG. Code is available at \\url{https://github.com/reml-group/DoG}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2409.03166",
        "abstract url": "https://arxiv.org/abs/2409.03166",
        "title": "Continual Skill and Task Learning via Dialogue",
        "rating": "0",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Continual and interactive robot learning is a challenging problem as the robot is present with human users who expect the robot to learn novel skills to solve novel tasks perpetually with sample efficiency. In this work we present a framework for robots to query and learn visuo-motor robot skills and task relevant information via natural language dialog interactions with human users. Previous approaches either focus on improving the performance of instruction following agents, or passively learn novel skills or concepts. Instead, we used dialog combined with a language-skill grounding embedding to query or confirm skills and/or tasks requested by a user. To achieve this goal, we developed and integrated three different components for our agent. Firstly, we propose a novel visual-motor control policy ACT with Low Rank Adaptation (ACT-LoRA), which enables the existing SoTA ACT model to perform few-shot continual learning. Secondly, we develop an alignment model that projects demonstrations across skill embodiments into a shared embedding allowing us to know when to ask questions and/or demonstrations from users. Finally, we integrated an existing LLM to interact with a human user to perform grounded interactive continual skill learning to solve a task. Our ACT-LoRA model learns novel fine-tuned skills with a 100% accuracy when trained with only five demonstrations for a novel skill while still maintaining a 74.75% accuracy on pre-trained skills in the RLBench dataset where other models fall significantly short. We also performed a human-subjects study with 8 subjects to demonstrate the continual learning capabilities of our combined framework. We achieve a success rate of 75% in the task of sandwich making with the real robot learning from participant data demonstrating that robots can learn novel skills or task knowledge from dialogue with non-expert users using our approach.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03183",
        "abstract url": "https://arxiv.org/abs/2409.03183",
        "title": "Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Neural networks (NN) classification models for Natural Language Processing (NLP) are vulnerable to the Universal Adversarial Triggers (UAT) attack that triggers a model to produce a specific prediction for any input. DARCY borrows the \"honeypot\" concept to bait multiple trapdoors, effectively detecting the adversarial examples generated by UAT. Unfortunately, we find a new UAT generation method, called IndisUAT, which produces triggers (i.e., tokens) and uses them to craft adversarial examples whose feature distribution is indistinguishable from that of the benign examples in a randomly-chosen category at the detection layer of DARCY. The produced adversarial examples incur the maximal loss of predicting results in the DARCY-protected models. Meanwhile, the produced triggers are effective in black-box models for text generation, text inference, and reading comprehension. Finally, the evaluation results under NN models for NLP tasks indicate that the IndisUAT method can effectively circumvent DARCY and penetrate other defenses. For example, IndisUAT can reduce the true positive rate of DARCY's detection by at least 40.8% and 90.6%, and drop the accuracy by at least 33.3% and 51.6% in the RNN and CNN models, respectively. IndisUAT reduces the accuracy of the BERT's adversarial defense model by at least 34.0%, and makes the GPT-2 language model spew racist outputs even when conditioned on non-racial context.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "13 pages, 5 figures"
    },
    {
        "paper id": "2409.03198",
        "abstract url": "https://arxiv.org/abs/2409.03198",
        "title": "RoomDiffusion: A Specialized Diffusion Model in the Interior Design Industry",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in text-to-image diffusion models have significantly transformed visual content generation, yet their application in specialized fields such as interior design remains underexplored. In this paper, we present RoomDiffusion, a pioneering diffusion model meticulously tailored for the interior design industry. To begin with, we build from scratch a whole data pipeline to update and evaluate data for iterative model optimization. Subsequently, techniques such as multiaspect training, multi-stage fine-tune and model fusion are applied to enhance both the visual appeal and precision of the generated results. Lastly, leveraging the latent consistency Distillation method, we distill and expedite the model for optimal efficiency. Unlike existing models optimized for general scenarios, RoomDiffusion addresses specific challenges in interior design, such as lack of fashion, high furniture duplication rate, and inaccurate style. Through our holistic human evaluation protocol with more than 20 professional human evaluators, RoomDiffusion demonstrates industry-leading performance in terms of aesthetics, accuracy, and efficiency, surpassing all existing open source models such as stable diffusion and SDXL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03203",
        "abstract url": "https://arxiv.org/abs/2409.03203",
        "title": "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Sentiment classification (SC) often suffers from low-resource challenges such as domain-specific contexts, imbalanced label distributions, and few-shot scenarios. The potential of the diffusion language model (LM) for textual data augmentation (DA) remains unexplored, moreover, textual DA methods struggle to balance the diversity and consistency of new samples. Most DA methods either perform logical modifications or rephrase less important tokens in the original sequence with the language model. In the context of SC, strong emotional tokens could act critically on the sentiment of the whole sequence. Therefore, contrary to rephrasing less important context, we propose DiffusionCLS to leverage a diffusion LM to capture in-domain knowledge and generate pseudo samples by reconstructing strong label-related tokens. This approach ensures a balance between consistency and diversity, avoiding the introduction of noise and augmenting crucial features of datasets. DiffusionCLS also comprises a Noise-Resistant Training objective to help the model generalize. Experiments demonstrate the effectiveness of our method in various low-resource scenarios including domain-specific and domain-general problems. Ablation studies confirm the effectiveness of our framework's modules, and visualization studies highlight optimal deployment conditions, reinforcing our conclusions.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03209",
        "abstract url": "https://arxiv.org/abs/2409.03209",
        "title": "iSeg: An Iterative Refinement-based Framework for Training-free Segmentation",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Stable diffusion has demonstrated strong image synthesis ability to given text descriptions, suggesting it to contain strong semantic clue for grouping objects. Inspired by this, researchers have explored employing stable diffusion for trainingfree segmentation. Most existing approaches either simply employ cross-attention map or refine it by self-attention map, to generate segmentation masks. We believe that iterative refinement with self-attention map would lead to better results. However, we mpirically demonstrate that such a refinement is sub-optimal likely due to the self-attention map containing irrelevant global information which hampers accurately refining cross-attention map with multiple iterations. To address this, we propose an iterative refinement framework for training-free segmentation, named iSeg, having an entropy-reduced self-attention module which utilizes a gradient descent scheme to reduce the entropy of self-attention map, thereby suppressing the weak responses corresponding to irrelevant global information. Leveraging the entropy-reduced self-attention module, our iSeg stably improves refined crossattention map with iterative refinement. Further, we design a category-enhanced cross-attention module to generate accurate cross-attention map, providing a better initial input for iterative refinement. Extensive experiments across different datasets and diverse segmentation tasks reveal the merits of proposed contributions, leading to promising performance on diverse segmentation tasks. For unsupervised semantic segmentation on Cityscapes, our iSeg achieves an absolute gain of 3.8% in terms of mIoU compared to the best existing training-free approach in literature. Moreover, our proposed iSeg can support segmentation with different kind of images and interactions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://linsun449.github.io/iSeg/ Code: https://github.com/linsun449/iseg.code"
    },
    {
        "paper id": "2409.02485",
        "abstract url": "https://arxiv.org/abs/2409.02485",
        "title": "Adversarial Attacks on Machine Learning-Aided Visualizations",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Research in ML4VIS investigates how to use machine learning (ML) techniques to generate visualizations, and the field is rapidly growing with high societal impact. However, as with any computational pipeline that employs ML processes, ML4VIS approaches are susceptible to a range of ML-specific adversarial attacks. These attacks can manipulate visualization generations, causing analysts to be tricked and their judgments to be impaired. Due to a lack of synthesis from both visualization and ML perspectives, this security aspect is largely overlooked by the current ML4VIS literature. To bridge this gap, we investigate the potential vulnerabilities of ML-aided visualizations from adversarial attacks using a holistic lens of both visualization and ML perspectives. We first identify the attack surface (i.e., attack entry points) that is unique in ML-aided visualizations. We then exemplify five different adversarial attacks. These examples highlight the range of possible attacks when considering the attack surface and multiple different adversary capabilities. Our results show that adversaries can induce various attacks, such as creating arbitrary and deceptive visualizations, by systematically identifying input attributes that are influential in ML inferences. Based on our observations of the attack surface characteristics and the attack examples, we underline the importance of comprehensive studies of security issues and defense mechanisms as a call of urgency for the ML4VIS community.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.HC",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "This is the author's version of the article that has been accepted by the Journal of Visualization"
    },
    {
        "paper id": "2409.02495",
        "abstract url": "https://arxiv.org/abs/2409.02495",
        "title": "CoAst: Validation-Free Contribution Assessment for Federated Learning based on Cross-Round Valuation",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the federated learning (FL) process, since the data held by each participant is different, it is necessary to figure out which participant has a higher contribution to the model performance. Effective contribution assessment can help motivate data owners to participate in the FL training. Research works in this field can be divided into two directions based on whether a validation dataset is required. Validation-based methods need to use representative validation data to measure the model accuracy, which is difficult to obtain in practical FL scenarios. Existing validation-free methods assess the contribution based on the parameters and gradients of local models and the global model in a single training round, which is easily compromised by the stochasticity of model training. In this work, we propose CoAst, a practical method to assess the FL participants' contribution without access to any validation data. The core idea of CoAst involves two aspects: one is to only count the most important part of model parameters through a weights quantization, and the other is a cross-round valuation based on the similarity between the current local parameters and the global parameter updates in several subsequent communication rounds. Extensive experiments show that CoAst has comparable assessment reliability to existing validation-based methods and outperforms existing validation-free methods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02512",
        "abstract url": "https://arxiv.org/abs/2409.02512",
        "title": "Continual Diffuser (CoD): Mastering Continual Offline Reinforcement Learning with Experience Rehearsal",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Artificial neural networks, especially recent diffusion-based models, have shown remarkable superiority in gaming, control, and QA systems, where the training tasks' datasets are usually static. However, in real-world applications, such as robotic control of reinforcement learning (RL), the tasks are changing, and new tasks arise in a sequential order. This situation poses the new challenge of plasticity-stability trade-off for training an agent who can adapt to task changes and retain acquired knowledge. In view of this, we propose a rehearsal-based continual diffusion model, called Continual Diffuser (CoD), to endow the diffuser with the capabilities of quick adaptation (plasticity) and lasting retention (stability). Specifically, we first construct an offline benchmark that contains 90 tasks from multiple domains. Then, we train the CoD on each task with sequential modeling and conditional generation for making decisions. Next, we preserve a small portion of previous datasets as the rehearsal buffer and replay it to retain the acquired knowledge. Extensive experiments on a series of tasks show CoD can achieve a promising plasticity-stability trade-off and outperform existing diffusion-based methods and other representative baselines on most tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02561",
        "abstract url": "https://arxiv.org/abs/2409.02561",
        "title": "Vision-Language Navigation with Continual Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "3D"
            ],
            [
                "Navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Vision-language navigation (VLN) is a critical domain within embedded intelligence, requiring agents to navigate 3D environments based on natural language instructions. Traditional VLN research has focused on improving environmental understanding and decision accuracy. However, these approaches often exhibit a significant performance gap when agents are deployed in novel environments, mainly due to the limited diversity of training data. Expanding datasets to cover a broader range of environments is impractical and costly. We propose the Vision-Language Navigation with Continual Learning (VLNCL) paradigm to address this challenge. In this paradigm, agents incrementally learn new environments while retaining previously acquired knowledge. VLNCL enables agents to maintain an environmental memory and extract relevant knowledge, allowing rapid adaptation to new environments while preserving existing information. We introduce a novel dual-loop scenario replay method (Dual-SR) inspired by brain memory replay mechanisms integrated with VLN agents. This method facilitates consolidating past experiences and enhances generalization across new tasks. By utilizing a multi-scenario memory buffer, the agent efficiently organizes and replays task memories, thereby bolstering its ability to adapt quickly to new environments and mitigating catastrophic forgetting. Our work pioneers continual learning in VLN agents, introducing a novel experimental setup and evaluation metrics. We demonstrate the effectiveness of our approach through extensive evaluations and establish a benchmark for the VLNCL paradigm. Comparative experiments with existing continual learning and VLN methods show significant improvements, achieving state-of-the-art performance in continual learning ability and highlighting the potential of our approach in enabling rapid adaptation while preserving prior knowledge.",
        "subjects": [
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02599",
        "abstract url": "https://arxiv.org/abs/2409.02599",
        "title": "A Fashion Item Recommendation Model in Hyperbolic Space",
        "rating": "-0.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "In this work, we propose a fashion item recommendation model that incorporates hyperbolic geometry into user and item representations. Using hyperbolic space, our model aims to capture implicit hierarchies among items based on their visual data and users' purchase history. During training, we apply a multi-task learning framework that considers both hyperbolic and Euclidean distances in the loss function. Our experiments on three data sets show that our model performs better than previous models trained in Euclidean space only, confirming the effectiveness of our model. Our ablation studies show that multi-task learning plays a key role, and removing the Euclidean loss substantially deteriorates the model performance.",
        "subjects": [
            "cs.IR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "This work was presented at the CVFAD Workshop at CVPR 2024"
    },
    {
        "paper id": "2409.02604",
        "abstract url": "https://arxiv.org/abs/2409.02604",
        "title": "Hypothesizing Missing Causal Variables with LLMs",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Scientific discovery is a catalyst for human intellectual advances, driven by the cycle of hypothesis generation, experimental design, data evaluation, and iterative assumption refinement. This process, while crucial, is expensive and heavily dependent on the domain knowledge of scientists to generate hypotheses and navigate the scientific cycle. Central to this is causality, the ability to establish the relationship between the cause and the effect. Motivated by the scientific discovery process, in this work, we formulate a novel task where the input is a partial causal graph with missing variables, and the output is a hypothesis about the missing variables to complete the partial graph. We design a benchmark with varying difficulty levels and knowledge assumptions about the causal graph. With the growing interest in using Large Language Models (LLMs) to assist in scientific discovery, we benchmark open-source and closed models on our testbed. We show the strong ability of LLMs to hypothesize the mediation variables between a cause and its effect. In contrast, they underperform in hypothesizing the cause and effect variables themselves. We also observe surprising results where some of the open-source models outperform the closed GPT-4 model.",
        "subjects": [
            "cs.LG",
            "stat.ME"
        ],
        "comment": "Code - https://github.com/ivaxi0s/hypothesizing-causal-variable-llm"
    },
    {
        "paper id": "2409.02669",
        "abstract url": "https://arxiv.org/abs/2409.02669",
        "title": "Causality-Aware Transformer Networks for Robotic Navigation",
        "rating": "-0.5",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in machine learning algorithms have garnered growing interest in developing versatile Embodied AI systems. However, current research in this domain reveals opportunities for improvement. First, the direct adoption of RNNs and Transformers often overlooks the specific differences between Embodied AI and traditional sequential data modelling, potentially limiting its performance in Embodied AI tasks. Second, the reliance on task-specific configurations, such as pre-trained modules and dataset-specific logic, compromises the generalizability of these methods. We address these constraints by initially exploring the unique differences between Embodied AI tasks and other sequential data tasks through the lens of Causality, presenting a causal framework to elucidate the inadequacies of conventional sequential methods for Embodied AI. By leveraging this causal perspective, we propose Causality-Aware Transformer (CAT) Networks for Navigation, featuring a Causal Understanding Module to enhance the models's Environmental Understanding capability. Meanwhile, our method is devoid of task-specific inductive biases and can be trained in an End-to-End manner, which enhances the method's generalizability across various contexts. Empirical evaluations demonstrate that our methodology consistently surpasses benchmark performances across a spectrum of settings, tasks and simulation environments. Extensive ablation studies reveal that the performance gains can be attributed to the Causal Understanding Module, which demonstrates effectiveness and efficiency in both Reinforcement Learning and Supervised Learning settings.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02672",
        "abstract url": "https://arxiv.org/abs/2409.02672",
        "title": "Independence Constrained Disentangled Representation Learning from Epistemological Perspective",
        "rating": "-0.5",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Disentangled Representation Learning aims to improve the explainability of deep learning methods by training a data encoder that identifies semantically meaningful latent variables in the data generation process. Nevertheless, there is no consensus regarding a universally accepted definition for the objective of disentangled representation learning. In particular, there is a considerable amount of discourse regarding whether should the latent variables be mutually independent or not. In this paper, we first investigate these arguments on the interrelationships between latent variables by establishing a conceptual bridge between Epistemology and Disentangled Representation Learning. Then, inspired by these interdisciplinary concepts, we introduce a two-level latent space framework to provide a general solution to the prior arguments on this issue. Finally, we propose a novel method for disentangled representation learning by employing an integration of mutual information constraint and independence constraint within the Generative Adversarial Network (GAN) framework. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches in both quantitative and qualitative evaluations. The method exhibits strong performance across multiple commonly used metrics and demonstrates a great capability in disentangling various semantic factors, leading to an improved quality of controllable generation, which consequently benefits the explainability of the algorithm.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02728",
        "abstract url": "https://arxiv.org/abs/2409.02728",
        "title": "Task-Oriented Communication for Graph Data: A Graph Information Bottleneck Approach",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph data, essential in fields like knowledge representation and social networks, often involves large networks with many nodes and edges. Transmitting these graphs can be highly inefficient due to their size and redundancy for specific tasks. This paper introduces a method to extract a smaller, task-focused subgraph that maintains key information while reducing communication overhead. Our approach utilizes graph neural networks (GNNs) and the graph information bottleneck (GIB) principle to create a compact, informative, and robust graph representation suitable for transmission. The challenge lies in the irregular structure of graph data, making GIB optimization complex. We address this by deriving a tractable variational upper bound for the objective function. Additionally, we propose the VQ-GIB mechanism, integrating vector quantization (VQ) to convert subgraph representations into a discrete codebook sequence, compatible with existing digital communication systems. Our experiments show that this GIB-based method significantly lowers communication costs while preserving essential task-related information. The approach demonstrates robust performance across various communication channels, suitable for both continuous and discrete systems.",
        "subjects": [
            "cs.LG",
            "cs.SI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02825",
        "abstract url": "https://arxiv.org/abs/2409.02825",
        "title": "Deep Learning Meets Satellite Images -- An Evaluation on Handcrafted and Learning-based Features for Multi-date Satellite Stereo Images",
        "rating": "-0.5",
        "keywords": [
            [
                "Satellite"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "A critical step in the digital surface models(DSM) generation is feature matching. Off-track (or multi-date) satellite stereo images, in particular, can challenge the performance of feature matching due to spectral distortions between images, long baseline, and wide intersection angles. Feature matching methods have evolved over the years from handcrafted methods (e.g., SIFT) to learning-based methods (e.g., SuperPoint and SuperGlue). In this paper, we compare the performance of different features, also known as feature extraction and matching methods, applied to satellite imagery. A wide range of stereo pairs(~500) covering two separate study sites are used. SIFT, as a widely used classic feature extraction and matching algorithm, is compared with seven deep-learning matching methods: SuperGlue, LightGlue, LoFTR, ASpanFormer, DKM, GIM-LightGlue, and GIM-DKM. Results demonstrate that traditional matching methods are still competitive in this age of deep learning, although for particular scenarios learning-based methods are very promising.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV2024 Workshop - TradiCV"
    },
    {
        "paper id": "2409.02869",
        "abstract url": "https://arxiv.org/abs/2409.02869",
        "title": "Look Into the LITE in Deep Learning for Time Series Classification",
        "rating": "-0.5",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning models have been shown to be a powerful solution for Time Series Classification (TSC). State-of-the-art architectures, while producing promising results on the UCR and the UEA archives , present a high number of trainable parameters. This can lead to long training with high CO2 emission, power consumption and possible increase in the number of FLoating-point Operation Per Second (FLOPS). In this paper, we present a new architecture for TSC, the Light Inception with boosTing tEchnique (LITE) with only 2.34% of the number of parameters of the state-of-the-art InceptionTime model, while preserving performance. This architecture, with only 9, 814 trainable parameters due to the usage of DepthWise Separable Convolutions (DWSC), is boosted by three techniques: multiplexing, custom filters, and dilated convolution. The LITE architecture, trained on the UCR, is 2.78 times faster than InceptionTime and consumes 2.79 times less CO2 and power. To evaluate the performance of the proposed architecture on multivariate time series data, we adapt LITE to handle multivariate time series, we call this version LITEMV. To bring theory into application, we also conducted experiments using LITEMV on multivariate time series representing human rehabilitation movements, showing that LITEMV not only is the most efficient model but also the best performing for this application on the Kimore dataset, a skeleton based human rehabilitation exercises dataset. Moreover, to address the interpretability of LITEMV, we present a study using Class Activation Maps to understand the classification decision taken by the model during evaluation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02871",
        "abstract url": "https://arxiv.org/abs/2409.02871",
        "title": "Hybrid Imitation-Learning Motion Planner for Urban Driving",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "With the release of open source datasets such as nuPlan and Argoverse, the research around learning-based planners has spread a lot in the last years. Existing systems have shown excellent capabilities in imitating the human driver behaviour, but they struggle to guarantee safe closed-loop driving. Conversely, optimization-based planners offer greater security in short-term planning scenarios. To confront this challenge, in this paper we propose a novel hybrid motion planner that integrates both learning-based and optimization-based techniques. Initially, a multilayer perceptron (MLP) generates a human-like trajectory, which is then refined by an optimization-based component. This component not only minimizes tracking errors but also computes a trajectory that is both kinematically feasible and collision-free with obstacles and road boundaries. Our model effectively balances safety and human-likeness, mitigating the trade-off inherent in these objectives. We validate our approach through simulation experiments and further demonstrate its efficacy by deploying it in real-world self-driving vehicles.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02901",
        "abstract url": "https://arxiv.org/abs/2409.02901",
        "title": "Topological Methods in Machine Learning: A Tutorial for Practitioners",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Topological Machine Learning (TML) is an emerging field that leverages techniques from algebraic topology to analyze complex data structures in ways that traditional machine learning methods may not capture. This tutorial provides a comprehensive introduction to two key TML techniques, persistent homology and the Mapper algorithm, with an emphasis on practical applications. Persistent homology captures multi-scale topological features such as clusters, loops, and voids, while the Mapper algorithm creates an interpretable graph summarizing high-dimensional data. To enhance accessibility, we adopt a data-centric approach, enabling readers to gain hands-on experience applying these techniques to relevant tasks. We provide step-by-step explanations, implementations, hands-on examples, and case studies to demonstrate how these tools can be applied to real-world problems. The goal is to equip researchers and practitioners with the knowledge and resources to incorporate TML into their work, revealing insights often hidden from conventional machine learning methods. The tutorial code is available at https://github.com/cakcora/TopologyForML",
        "subjects": [
            "cs.LG",
            "cs.CG",
            "math.AT"
        ],
        "comment": "54 pages, 35 figures"
    },
    {
        "paper id": "2409.03024",
        "abstract url": "https://arxiv.org/abs/2409.03024",
        "title": "NUMOSIM: A Synthetic Mobility Dataset with Anomaly Detection Benchmarks",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Collecting real-world mobility data is challenging. It is often fraught with privacy concerns, logistical difficulties, and inherent biases. Moreover, accurately annotating anomalies in large-scale data is nearly impossible, as it demands meticulous effort to distinguish subtle and complex patterns. These challenges significantly impede progress in geospatial anomaly detection research by restricting access to reliable data and complicating the rigorous evaluation, comparison, and benchmarking of methodologies. To address these limitations, we introduce a synthetic mobility dataset, NUMOSIM, that provides a controlled, ethical, and diverse environment for benchmarking anomaly detection techniques. NUMOSIM simulates a wide array of realistic mobility scenarios, encompassing both typical and anomalous behaviours, generated through advanced deep learning models trained on real mobility data. This approach allows NUMOSIM to accurately replicate the complexities of real-world movement patterns while strategically injecting anomalies to challenge and evaluate detection algorithms based on how effectively they capture the interplay between demographic, geospatial, and temporal factors. Our goal is to advance geospatial mobility analysis by offering a realistic benchmark for improving anomaly detection and mobility modeling techniques. To support this, we provide open access to the NUMOSIM dataset, along with comprehensive documentation, evaluation metrics, and benchmark results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03062",
        "abstract url": "https://arxiv.org/abs/2409.03062",
        "title": "MobileUNETR: A Lightweight End-To-End Hybrid Vision Transformer For Efficient Medical Image Segmentation",
        "rating": "-0.5",
        "keywords": [
            [
                "Medical",
                "cancer",
                "lesion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Skin cancer segmentation poses a significant challenge in medical image analysis. Numerous existing solutions, predominantly CNN-based, face issues related to a lack of global contextual understanding. Alternatively, some approaches resort to large-scale Transformer models to bridge the global contextual gaps, but at the expense of model size and computational complexity. Finally many Transformer based approaches rely primarily on CNN based decoders overlooking the benefits of Transformer based decoding models. Recognizing these limitations, we address the need efficient lightweight solutions by introducing MobileUNETR, which aims to overcome the performance constraints associated with both CNNs and Transformers while minimizing model size, presenting a promising stride towards efficient image segmentation. MobileUNETR has 3 main features. 1) MobileUNETR comprises of a lightweight hybrid CNN-Transformer encoder to help balance local and global contextual feature extraction in an efficient manner; 2) A novel hybrid decoder that simultaneously utilizes low-level and global features at different resolutions within the decoding stage for accurate mask generation; 3) surpassing large and complex architectures, MobileUNETR achieves superior performance with 3 million parameters and a computational complexity of 1.3 GFLOP resulting in 10x and 23x reduction in parameters and FLOPS, respectively. Extensive experiments have been conducted to validate the effectiveness of our proposed method on four publicly available skin lesion segmentation datasets, including ISIC 2016, ISIC 2017, ISIC 2018, and PH2 datasets. The code will be publicly available at: https://github.com/OSUPCVLab/MobileUNETR.git",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted at ECCV 2024 - BioImage Computing Workshop (Oral)"
    },
    {
        "paper id": "2409.03107",
        "abstract url": "https://arxiv.org/abs/2409.03107",
        "title": "RoboKoop: Efficient Control Conditioned Representations from Visual Input in Robotics using Koopman Operator",
        "rating": "-0.5",
        "keywords": [
            [
                "Robotics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Developing agents that can perform complex control tasks from high-dimensional observations is a core ability of autonomous agents that requires underlying robust task control policies and adapting the underlying visual representations to the task. Most existing policies need a lot of training samples and treat this problem from the lens of two-stage learning with a controller learned on top of pre-trained vision models. We approach this problem from the lens of Koopman theory and learn visual representations from robotic agents conditioned on specific downstream tasks in the context of learning stabilizing control for the agent. We introduce a Contrastive Spectral Koopman Embedding network that allows us to learn efficient linearized visual representations from the agent's visual data in a high dimensional latent space and utilizes reinforcement learning to perform off-policy control on top of the extracted representations with a linear controller. Our method enhances stability and control in gradient dynamics over time, significantly outperforming existing approaches by improving efficiency and accuracy in learning task policies over extended horizons.",
        "subjects": [
            "cs.RO",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Accepted to the $8^{th}$ Conference on Robot Learning (CoRL 2024)"
    },
    {
        "paper id": "2409.03111",
        "abstract url": "https://arxiv.org/abs/2409.03111",
        "title": "What is Normal? A Big Data Observational Science Model of Anonymized Internet Traffic",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Understanding what is normal is a key aspect of protecting a domain. Other domains invest heavily in observational science to develop models of normal behavior to better detect anomalies. Recent advances in high performance graph libraries, such as the GraphBLAS, coupled with supercomputers enables processing of the trillions of observations required. We leverage this approach to synthesize low-parameter observational models of anonymized Internet traffic with a high regard for privacy.",
        "subjects": [
            "cs.NI",
            "cs.CR",
            "cs.CY",
            "cs.SI"
        ],
        "comment": "Accepted to IEEE HPEC, 7 pages, 6 figures, 1 table, 41 references"
    },
    {
        "paper id": "2409.03237",
        "abstract url": "https://arxiv.org/abs/2409.03237",
        "title": "Robust Q-Learning under Corrupted Rewards",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, there has been a surge of interest in analyzing the non-asymptotic behavior of model-free reinforcement learning algorithms. However, the performance of such algorithms in non-ideal environments, such as in the presence of corrupted rewards, is poorly understood. Motivated by this gap, we investigate the robustness of the celebrated Q-learning algorithm to a strong-contamination attack model, where an adversary can arbitrarily perturb a small fraction of the observed rewards. We start by proving that such an attack can cause the vanilla Q-learning algorithm to incur arbitrarily large errors. We then develop a novel robust synchronous Q-learning algorithm that uses historical reward data to construct robust empirical Bellman operators at each time step. Finally, we prove a finite-time convergence rate for our algorithm that matches known state-of-the-art bounds (in the absence of attacks) up to a small inevitable $O(\\varepsilon)$ error term that scales with the adversarial corruption fraction $\\varepsilon$. Notably, our results continue to hold even when the true reward distributions have infinite support, provided they admit bounded second moments.",
        "subjects": [
            "cs.LG",
            "eess.SY",
            "math.OC",
            "stat.ML"
        ],
        "comment": "Accepted to the Decision and Control Conference (CDC) 2024"
    },
    {
        "paper id": "2409.03795",
        "abstract url": "https://arxiv.org/abs/2409.03795",
        "title": "Security Implications and Mitigation Strategies in MPLS Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multiprotocol Label Switching (MPLS) is a high-performance telecommunications technology that directs data from one network node to another based on short path labels rather than long network addresses. Its efficiency and scalability have made it a popular choice for large-scale and enterprise networks. However, as MPLS networks grow and evolve, they encounter various security challenges. This paper explores the security implications associated with MPLS networks, including risks such as label spoofing, traffic interception, and denial of service attacks. Additionally, it evaluates advanced mitigation strategies to address these vulnerabilities, leveraging mathematical models and security protocols to enhance MPLS network resilience. By integrating theoretical analysis with practical solutions, this paper aims to provide a comprehensive understanding of MPLS security and propose effective methods for safeguarding network infrastructure.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03796",
        "abstract url": "https://arxiv.org/abs/2409.03796",
        "title": "Protecting Activity Sensing Data Privacy Using Hierarchical Information Dissociation",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Smartphones and wearable devices have been integrated into our daily lives, offering personalized services. However, many apps become overprivileged as their collected sensing data contains unnecessary sensitive information. For example, mobile sensing data could reveal private attributes (e.g., gender and age) and unintended sensitive features (e.g., hand gestures when entering passwords). To prevent sensitive information leakage, existing methods must obtain private labels and users need to specify privacy policies. However, they only achieve limited control over information disclosure. In this work, we present Hippo to dissociate hierarchical information including private metadata and multi-grained activity information from the sensing data. Hippo achieves fine-grained control over the disclosure of sensitive information without requiring private labels. Specifically, we design a latent guidance-based diffusion model, which generates multi-grained versions of raw sensor data conditioned on hierarchical latent activity features. Hippo enables users to control the disclosure of sensitive information in sensing data, ensuring their privacy while preserving the necessary features to meet the utility requirements of applications. Hippo is the first unified model that achieves two goals: perturbing the sensitive attributes and controlling the disclosure of sensitive information in mobile sensing data. Extensive experiments show that Hippo can anonymize personal attributes and transform activity information at various resolutions across different types of sensing data.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02453",
        "abstract url": "https://arxiv.org/abs/2409.02453",
        "title": "FrameCorr: Adaptive, Autoencoder-based Neural Compression for Video Reconstruction in Resource and Timing Constrained Network Settings",
        "rating": "-1",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Despite the growing adoption of video processing via Internet of Things (IoT) devices due to their cost-effectiveness, transmitting captured data to nearby servers poses challenges due to varying timing constraints and scarcity of network bandwidth. Existing video compression methods face difficulties in recovering compressed data when incomplete data is provided. Here, we introduce \\emph{\\project}, a deep-learning based solution that utilizes previously received data to predict the missing segments of a frame, enabling the reconstruction of a frame from partially received data.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.ET",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02455",
        "abstract url": "https://arxiv.org/abs/2409.02455",
        "title": "An Effective Tag Assignment Approach for Billboard Advertisement",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Billboard Advertisement has gained popularity due to its significant outrage in return on investment. To make this advertisement approach more effective, the relevant information about the product needs to be reached to the relevant set of people. This can be achieved if the relevant set of tags can be mapped to the correct slots. Formally, we call this problem the Tag Assignment Problem in Billboard Advertisement. Given trajectory, billboard database, and a set of selected billboard slots and tags, this problem asks to output a mapping of selected tags to the selected slots so that the influence is maximized. We model this as a variant of traditional bipartite matching called One-To-Many Bipartite Matching (OMBM). Unlike traditional bipartite matching, a tag can be assigned to only one slot; in the OMBM, a tag can be assigned to multiple slots while the vice versa can not happen. We propose an iterative solution approach that incrementally allocates the tags to the slots. The proposed methodology has been explained with an illustrated example. A complexity analysis of the proposed solution approach has also been conducted. The experimental results on real-world trajectory and billboard datasets prove our claim on the effectiveness and efficiency of the proposed solution.",
        "subjects": [
            "cs.DS",
            "cs.IR"
        ],
        "comment": "This Paper has been accepted at The 25th International Web Information Systems Engineering Conference (WISE-2024)"
    },
    {
        "paper id": "2409.02457",
        "abstract url": "https://arxiv.org/abs/2409.02457",
        "title": "On Oriented Diameter of Power Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "In this paper, we study the oriented diameter of power graphs of groups. We show that a $2$-edge connected power graph of a finite group has oriented diameter at most $4$. We prove that the power graph of a cyclic group of order $n$ has oriented diameter $2$ for all $n\\neq 2,4,6$. Until our work, to the best of our knowledge, no infinite family of graphs with oriented diameter 2 had been identified except for subclasses of complete graphs. Finally, we give a complete characterization of the oriented diameter of the power graphs of nilpotent groups. This, in turn, gives an algorithm for computing the oriented diameter of the power graph of a given nilpotent group that runs in time polynomial in the size of the group.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "24 pages"
    },
    {
        "paper id": "2409.02486",
        "abstract url": "https://arxiv.org/abs/2409.02486",
        "title": "Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization",
        "rating": "-1",
        "keywords": [
            [
                "RGB-D",
                "Depth"
            ],
            [
                "navigation"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Indoor robots rely on depth to perform tasks like navigation or obstacle detection, and single-image depth estimation is widely used to assist perception. Most indoor single-image depth prediction focuses less on model generalizability to unseen datasets, concerned with in-the-wild robustness for system deployment. This work leverages gradient-based meta-learning to gain higher generalizability on zero-shot cross-dataset inference. Unlike the most-studied meta-learning of image classification associated with explicit class labels, no explicit task boundaries exist for continuous depth values tied to highly varying indoor environments regarding object arrangement and scene composition. We propose fine-grained task that treats each RGB-D mini-batch as a task in our meta-learning formulation. We first show that our method on limited data induces a much better prior (max 27.8% in RMSE). Then, finetuning on meta-learned initialization consistently outperforms baselines without the meta approach. Aiming at generalization, we propose zero-shot cross-dataset protocols and validate higher generalizability induced by our meta-initialization, as a simple and useful plugin to many existing depth estimation methods. The work at the intersection of depth and meta-learning potentially drives both research to step closer to practical robotic and machine perception usage.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "IROS 2024. The version supersedes 2305.07269. arXiv admin note: text overlap with arXiv:2305.07269"
    },
    {
        "paper id": "2409.02489",
        "abstract url": "https://arxiv.org/abs/2409.02489",
        "title": "NeuroSpex: Neuro-Guided Speaker Extraction with Cross-Modal Attention",
        "rating": "-1",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In the study of auditory attention, it has been revealed that there exists a robust correlation between attended speech and elicited neural responses, measurable through electroencephalography (EEG). Therefore, it is possible to use the attention information available within EEG signals to guide the extraction of the target speaker in a cocktail party computationally. In this paper, we present a neuro-guided speaker extraction model, i.e. NeuroSpex, using the EEG response of the listener as the sole auxiliary reference cue to extract attended speech from monaural speech mixtures. We propose a novel EEG signal encoder that captures the attention information. Additionally, we propose a cross-attention (CA) mechanism to enhance the speech feature representations, generating a speaker extraction mask. Experimental results on a publicly available dataset demonstrate that our proposed model outperforms two baseline models across various evaluation metrics.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02502",
        "abstract url": "https://arxiv.org/abs/2409.02502",
        "title": "Dispelling Four Challenges in Inertial Motion Tracking with One Recurrent Inertial Graph-based Estimator (RING)",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "In this paper, we extend the Recurrent Inertial Graph-based Estimator (RING), a novel neural-network-based solution for Inertial Motion Tracking (IMT), to generalize across a large range of sampling rates, and we demonstrate that it can overcome four real-world challenges: inhomogeneous magnetic fields, sensor-to-segment misalignment, sparse sensor setups, and nonrigid sensor attachment. RING can estimate the rotational state of a three-segment kinematic chain with double hinge joints from inertial data, and achieves an experimental mean-absolute-(tracking)-error of 8.10 +/- 1.19 degrees if all four challenges are present simultaneously. The network is trained on simulated data yet evaluated on experimental data, highlighting its remarkable ability to zero-shot generalize from simulation to experiment. We conduct an ablation study to analyze the impact of each of the four challenges on RING's performance, we showcase its robustness to varying sampling rates, and we demonstrate that RING is capable of real-time operation. This research not only advances IMT technology by making it more accessible and versatile but also enhances its potential for new application domains including non-expert use of sparse IMT with nonrigid sensor attachments in unconstrained environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to 12th IFAC Symposium on Biological and Medical Systems"
    },
    {
        "paper id": "2409.02503",
        "abstract url": "https://arxiv.org/abs/2409.02503",
        "title": "eRSS-RAMP: A Rule-Adherence Motion Planner Based on Extended Responsibility-Sensitive Safety for Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ]
        ],
        "abstract": "Driving safety and responsibility determination are indispensable pieces of the puzzle for autonomous driving. They are also deeply related to the allocation of right-of-way and the determination of accident liability. Therefore, Intel/Mobileye designed the responsibility-sensitive safety (RSS) framework to further enhance the safety regulation of autonomous driving, which mathematically defines rules for autonomous vehicles (AVs) behaviors in various traffic scenarios. However, the RSS framework's rules are relatively rudimentary in certain scenarios characterized by interaction uncertainty, especially those requiring collaborative driving during emergency collision avoidance. Besides, the integration of the RSS framework with motion planning is rarely discussed in current studies. Therefore, we proposed a rule-adherence motion planner (RAMP) based on the extended RSS (eRSS) regulation for non-connected and connected AVs in merging and emergency-avoiding scenarios. The simulation results indicate that the proposed method can achieve faster and safer lane merging performance (53.0% shorter merging length and a 73.5% decrease in merging time), and allows for more stable steering maneuvers in emergency collision avoidance, resulting in smoother paths for ego vehicle and surrounding vehicles.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "12 pages, 19 figures, submitted to an IEEE journal"
    },
    {
        "paper id": "2409.02517",
        "abstract url": "https://arxiv.org/abs/2409.02517",
        "title": "Training Universal Vocoders with Feature Smoothing-Based Augmentation Methods for High-Quality TTS Systems",
        "rating": "-1",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "While universal vocoders have achieved proficient waveform generation across diverse voices, their integration into text-to-speech (TTS) tasks often results in degraded synthetic quality. To address this challenge, we present a novel augmentation technique for training universal vocoders. Our training scheme randomly applies linear smoothing filters to input acoustic features, facilitating vocoder generalization across a wide range of smoothings. It significantly mitigates the training-inference mismatch, enhancing the naturalness of synthetic output even when the acoustic model produces overly smoothed features. Notably, our method is applicable to any vocoder without requiring architectural modifications or dependencies on specific acoustic models. The experimental results validate the superiority of our vocoder over conventional methods, achieving 11.99% and 12.05% improvements in mean opinion scores when integrated with Tacotron 2 and FastSpeech 2 TTS acoustic models, respectively.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "4 pages, 4 figures, for demo samples, see https://sytronik.github.io/demos/voc_smth_aug/"
    },
    {
        "paper id": "2409.02531",
        "abstract url": "https://arxiv.org/abs/2409.02531",
        "title": "Modular pipeline for small bodies gravity field modeling: an efficient representation of variable density spherical harmonics coefficients",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "Proximity operations to small bodies, such as asteroids and comets, demand high levels of autonomy to achieve cost-effective, safe, and reliable Guidance, Navigation and Control (GNC) solutions. Enabling autonomous GNC capabilities in the vicinity of these targets is thus vital for future space applications. However, the highly non-linear and uncertain environment characterizing their vicinity poses unique challenges that need to be assessed to grant robustness against unknown shapes and gravity fields. In this paper, a pipeline designed to generate variable density gravity field models is proposed, allowing the generation of a coherent set of scenarios that can be used for design, validation, and testing of GNC algorithms. The proposed approach consists in processing a polyhedral shape model of the body with a given density distribution to compute the coefficients of the spherical harmonics expansion associated with the gravity field. To validate the approach, several comparison are conducted against analytical solutions, literature results, and higher fidelity models, across a diverse set of targets with varying morphological and physical properties. Simulation results demonstrate the effectiveness of the methodology, showing good performances in terms of modeling accuracy and computational efficiency. This research presents a faster and more robust framework for generating environmental models to be used in simulation and hardware-in-the-loop testing of onboard GNC algorithms.",
        "subjects": [
            "cs.RO",
            "astro-ph.IM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02548",
        "abstract url": "https://arxiv.org/abs/2409.02548",
        "title": "A Joint Time and Energy-Efficient Federated Learning-based Computation Offloading Method for Mobile Edge Computing",
        "rating": "-1",
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "Computation offloading at lower time and lower energy consumption is crucial for resource limited mobile devices. This paper proposes an offloading decision-making model using federated learning. Based on the task type and the user input, the proposed decision-making model predicts whether the task is computationally intensive or not. If the predicted result is computationally intensive, then based on the network parameters the proposed decision-making model predicts whether to offload or locally execute the task. According to the predicted result the task is either locally executed or offloaded to the edge server. The proposed method is implemented in a real-time environment, and the experimental results show that the proposed method has achieved above 90% prediction accuracy in offloading decision-making. The experimental results also present that the proposed offloading method reduces the response time and energy consumption of the user device by ~11-31% for computationally intensive tasks. A partial computation offloading method for federated learning is also proposed and implemented in this paper, where the devices which are unable to analyse the huge number of data samples, offload a part of their local datasets to the edge server. For secure data transmission, cryptography is used. The experimental results present that using encryption and decryption the total time is increased by only 0.05-0.16%. The results also present that the proposed partial computation offloading method for federated learning has achieved a prediction accuracy of above 98% for the global model.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02556",
        "abstract url": "https://arxiv.org/abs/2409.02556",
        "title": "Want a Ride? Attitudes Towards Autonomous Driving and Behavior in Autonomous Vehicles",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ]
        ],
        "abstract": "Research conducted previously has focused on either attitudes toward or behaviors associated with autonomous driving. In this paper, we bridge these two dimensions by exploring how attitudes towards autonomous driving influence behavior in an autonomous car. We conducted a field experiment with twelve participants engaged in non-driving related tasks. Our findings indicate that attitudes towards autonomous driving do not affect participants' driving interventions in vehicle control and eye glance behavior. Therefore, studies on autonomous driving technology lacking field tests might be unreliable for assessing the potential behaviors, attitudes, and acceptance of autonomous vehicles.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2409.02562",
        "abstract url": "https://arxiv.org/abs/2409.02562",
        "title": "Interacting Multiple Model-based Joint Homography Matrix and Multiple Object State Estimation",
        "rating": "-1",
        "keywords": [
            [
                "BIoU"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "A novel MOT algorithm, IMM Joint Homography State Estimation (IMM-JHSE), is proposed. By jointly modelling the camera projection matrix as part of track state vectors, IMM-JHSE removes the explicit influence of camera motion compensation techniques on predicted track position states, which was prevalent in previous approaches. Expanding upon this, static and dynamic camera motion models are combined through the use of an IMM filter. A simple bounding box motion model is used to predict bounding box positions to incorporate image plane information. In addition to applying an IMM to camera motion, a non-standard IMM approach is applied where bounding-box-based BIoU scores are mixed with ground-plane-based Mahalanobis distances in an IMM-like fashion to perform association only. Finally, IMM-JHSE makes use of dynamic process and measurement noise estimation techniques. IMM-JHSE improves upon related techniques on the DanceTrack and KITTI-car datasets, increasing HOTA by 2.64 and 2.11, respectively, while offering competitive performance on the MOT17, MOT20 and KITTI-pedestrian datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Preprint submitted to Information Fusion"
    },
    {
        "paper id": "2409.02564",
        "abstract url": "https://arxiv.org/abs/2409.02564",
        "title": "Learnable Wireless Digital Twins: Reconstructing Electromagnetic Field with Neural Representations",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Fully harvesting the gain of multiple-input and multiple-output (MIMO) requires accurate channel information. However, conventional channel acquisition methods mainly rely on pilot training signals, resulting in significant training overheads (time, energy, spectrum). Digital twin-aided communications have been proposed in [1] to reduce or eliminate this overhead by approximating the real world with a digital replica. However, how to implement a digital twin-aided communication system brings new challenges. In particular, how to model the 3D environment and the associated EM properties, as well as how to update the environment dynamics in a coherent manner. To address these challenges, motivated by the latest advancements in computer vision, 3D reconstruction and neural radiance field, we propose an end-to-end deep learning framework for future generation wireless systems that can reconstruct the 3D EM field covered by a wireless access point, based on widely available crowd-sourced world-locked wireless samples between the access point and the devices. This visionary framework is grounded in classical EM theory and employs deep learning models to learn the EM properties and interaction behaviors of the objects in the environment. Simulation results demonstrate that the proposed learnable digital twin can implicitly learn the EM properties of the objects, accurately predict wireless channels, and generalize to changes in the environment, highlighting the prospect of this novel direction for future generation wireless platforms.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02571",
        "abstract url": "https://arxiv.org/abs/2409.02571",
        "title": "iRangeGraph: Improvising Range-dedicated Graphs for Range-filtering Nearest Neighbor Search",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "Range-filtering approximate nearest neighbor (RFANN) search is attracting increasing attention in academia and industry. Given a set of data objects, each being a pair of a high-dimensional vector and a numeric value, an RFANN query with a vector and a numeric range as parameters returns the data object whose numeric value is in the query range and whose vector is nearest to the query vector. To process this query, a recent study proposes to build $O(n^2)$ dedicated graph-based indexes for all possible query ranges to enable efficient processing on a database of $n$ objects. As storing all these indexes is prohibitively expensive, the study constructs compressed indexes instead, which reduces the memory consumption considerably. However, this incurs suboptimal performance because the compression is lossy. In this study, instead of materializing a compressed index for every possible query range in preparation for querying, we materialize graph-based indexes, called elemental graphs, for a moderate number of ranges. We then provide an effective and efficient algorithm that during querying can construct an index for any query range using the elemental graphs. We prove that the time needed to construct such an index is low. We also cover an experimental study on real-world datasets that provides evidence that the materialized elemental graphs only consume moderate space and that the proposed method is capable of superior and stable query performance across different query workloads.",
        "subjects": [
            "cs.DB",
            "cs.DS",
            "cs.IR"
        ],
        "comment": "The paper has been accepted by SIGMOD 2025"
    },
    {
        "paper id": "2409.02581",
        "abstract url": "https://arxiv.org/abs/2409.02581",
        "title": "Object Gaussian for Monocular 6D Pose Estimation from Sparse Views",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "6D",
                "depth"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Monocular object pose estimation, as a pivotal task in computer vision and robotics, heavily depends on accurate 2D-3D correspondences, which often demand costly CAD models that may not be readily available. Object 3D reconstruction methods offer an alternative, among which recent advancements in 3D Gaussian Splatting (3DGS) afford a compelling potential. Yet its performance still suffers and tends to overfit with fewer input views. Embracing this challenge, we introduce SGPose, a novel framework for sparse view object pose estimation using Gaussian-based methods. Given as few as ten views, SGPose generates a geometric-aware representation by starting with a random cuboid initialization, eschewing reliance on Structure-from-Motion (SfM) pipeline-derived geometry as required by traditional 3DGS methods. SGPose removes the dependence on CAD models by regressing dense 2D-3D correspondences between images and the reconstructed model from sparse input and random initialization, while the geometric-consistent depth supervision and online synthetic view warping are key to the success. Experiments on typical benchmarks, especially on the Occlusion LM-O dataset, demonstrate that SGPose outperforms existing methods even under sparse view constraints, under-scoring its potential in real-world applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02584",
        "abstract url": "https://arxiv.org/abs/2409.02584",
        "title": "BMI Prediction from Handwritten English Characters Using a Convolutional Neural Network",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "A person's Body Mass Index, or BMI, is the most widely used parameter for assessing their health. BMI is a crucial predictor of potential diseases that may arise at higher body fat levels because it is correlated with body fat. Conversely, a community's or an individual's nutritional status can be determined using the BMI. Although deep learning models are used in several studies to estimate BMI from face photos and other data, no previous research established a clear connection between deep learning techniques for handwriting analysis and BMI prediction. This article addresses this research gap with a deep learning approach to estimating BMI from handwritten characters by developing a convolutional neural network (CNN). A dataset containing samples from 48 people in lowercase English scripts is successfully captured for the BMI prediction task. The proposed CNN-based approach reports a commendable accuracy of 99.92%. Performance comparison with other popular CNN architectures reveals that AlexNet and InceptionV3 achieve the second and third-best performance, with the accuracy of 99.69% and 99.53%, respectively.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02634",
        "abstract url": "https://arxiv.org/abs/2409.02634",
        "title": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency",
        "rating": "-1",
        "keywords": [
            [
                "Avatar"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the introduction of diffusion-based video generation techniques, audio-conditioned human video generation has recently achieved significant breakthroughs in both the naturalness of motion and the synthesis of portrait details. Due to the limited control of audio signals in driving human motion, existing methods often add auxiliary spatial signals to stabilize movements, which may compromise the naturalness and freedom of motion. In this paper, we propose an end-to-end audio-only conditioned video diffusion model named Loopy. Specifically, we designed an inter- and intra-clip temporal module and an audio-to-latents module, enabling the model to leverage long-term motion information from the data to learn natural motion patterns and improving audio-portrait movement correlation. This method removes the need for manually specified spatial motion templates used in existing methods to constrain motion during inference. Extensive experiments show that Loopy outperforms recent audio-driven portrait diffusion models, delivering more lifelike and high-quality results across various scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Homepage: https://loopyavatar.github.io/"
    },
    {
        "paper id": "2409.02648",
        "abstract url": "https://arxiv.org/abs/2409.02648",
        "title": "Creating a Microstructure Latent Space with Rich Material Information for Multiphase Alloy Design",
        "rating": "-1",
        "keywords": [
            [
                "Alloy"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The intricate microstructure serves as the cornerstone for the composition/processing-structure-property (CPSP) connection in multiphase alloys. Traditional alloy design methods often overlook microstructural details, which diminishes the reliability and effectiveness of the outcomes. This study introduces an improved alloy design algorithm that integrates authentic microstructural information to establish precise CPSP relationships. The approach utilizes a deep-learning framework based on a variational autoencoder to map real microstructural data to a latent space, enabling the prediction of composition, processing steps, and material properties from the latent space vector. By integrating this deep learning model with a specific sampling strategy in the latent space, a novel, microstructure-centered algorithm for multiphase alloy design is developed. This algorithm is demonstrated through the design of a unified dual-phase steel, and the results are assessed at three performance levels. Moreover, an exploration into the latent vector space of the model highlights its seamless interpolation ability and its rich material information content. Notably, the current configuration of the latent space is particularly advantageous for alloy design, offering an exhaustive representation of microstructure, composition, processing, and property variations essential for multiphase alloys.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02650",
        "abstract url": "https://arxiv.org/abs/2409.02650",
        "title": "SoK: Bitcoin Layer Two (L2)",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "We present the first Systematization of Knowledge (SoK) on constructing Layer Two (L2) solutions for Bitcoin. We carefully examine a representative subset of ongoing Bitcoin L2 solutions (40 out of 335 extensively investigated cases) and provide a concise yet impactful identification of six classic design patterns through two approaches (i.e., modifying transactions \\& creating proofs). Notably, we are the first to incorporate the inscription technology (emerged in mid-2023), along with a series of related innovations. We further establish a reference framework that serves as a baseline criterion ideally suited for evaluating the security aspects of Bitcoin L2 solutions, and which can also be extended to broader L2 applications. We apply this framework to evaluate each of the projects we investigated. We find that the inscription-based approaches introduce new functionality (i.e., programability) to Bitcoin systems, whereas existing proof-based solutions primarily address scalability challenges. Our security analysis reveals new attack vectors targeting data/state (availability, verification), assets (withdrawal, recovery), and users (disputes, censorship).",
        "subjects": [
            "cs.CR",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02653",
        "abstract url": "https://arxiv.org/abs/2409.02653",
        "title": "Skip-and-Play: Depth-Driven Pose-Preserved Image Generation for Any Objects",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The emergence of diffusion models has enabled the generation of diverse high-quality images solely from text, prompting subsequent efforts to enhance the controllability of these models. Despite the improvement in controllability, pose control remains limited to specific objects (e.g., humans) or poses (e.g., frontal view) due to the fact that pose is generally controlled via camera parameters (e.g., rotation angle) or keypoints (e.g., eyes, nose). Specifically, camera parameters-conditional pose control models generate unrealistic images depending on the object, owing to the small size of 3D datasets for training. Also, keypoint-based approaches encounter challenges in acquiring reliable keypoints for various objects (e.g., church) or poses (e.g., back view). To address these limitations, we propose depth-based pose control, as depth maps are easily obtainable from a single depth estimation model regardless of objects and poses, unlike camera parameters and keypoints. However, depth-based pose control confronts issues of shape dependency, as depth maps influence not only the pose but also the shape of the generated images. To tackle this issue, we propose Skip-and-Play (SnP), designed via analysis of the impact of three components of depth-conditional ControlNet on the pose and the shape of the generated images. To be specific, based on the analysis, we selectively skip parts of the components to mitigate shape dependency on the depth map while preserving the pose. Through various experiments, we demonstrate the superiority of SnP over baselines and showcase the ability of SnP to generate images of diverse objects and poses. Remarkably, SnP exhibits the ability to generate images even when the objects in the condition (e.g., a horse) and the prompt (e.g., a hedgehog) differ from each other.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02664",
        "abstract url": "https://arxiv.org/abs/2409.02664",
        "title": "Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection",
        "rating": "-1",
        "keywords": [
            [
                "Visual-Language",
                "VLMs"
            ],
            [
                "Deepfake"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The proliferation of deepfake faces poses huge potential negative impacts on our daily lives. Despite substantial advancements in deepfake detection over these years, the generalizability of existing methods against forgeries from unseen datasets or created by emerging generative models remains constrained. In this paper, inspired by the zero-shot advantages of Vision-Language Models (VLMs), we propose a novel approach that repurposes a well-trained VLM for general deepfake detection. Motivated by the model reprogramming paradigm that manipulates the model prediction via data perturbations, our method can reprogram a pretrained VLM model (e.g., CLIP) solely based on manipulating its input without tuning the inner parameters. Furthermore, we insert a pseudo-word guided by facial identity into the text prompt. Extensive experiments on several popular benchmarks demonstrate that (1) the cross-dataset and cross-manipulation performances of deepfake detection can be significantly and consistently improved (e.g., over 88% AUC in cross-dataset setting from FF++ to WildDeepfake) using a pre-trained CLIP model with our proposed reprogramming method; (2) our superior performances are at less cost of trainable parameters, making it a promising approach for real-world applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02675",
        "abstract url": "https://arxiv.org/abs/2409.02675",
        "title": "Multi-Head Attention Residual Unfolded Network for Model-Based Pansharpening",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The objective of pansharpening and hypersharpening is to accurately combine a high-resolution panchromatic (PAN) image with a low-resolution multispectral (MS) or hyperspectral (HS) image, respectively. Unfolding fusion methods integrate the powerful representation capabilities of deep learning with the robustness of model-based approaches. These techniques involve unrolling the steps of the optimization scheme derived from the minimization of an energy into a deep learning framework, resulting in efficient and highly interpretable architectures. In this paper, we propose a model-based deep unfolded method for satellite image fusion. Our approach is based on a variational formulation that incorporates the classic observation model for MS/HS data, a high-frequency injection constraint based on the PAN image, and an arbitrary convex prior. For the unfolding stage, we introduce upsampling and downsampling layers that use geometric information encoded in the PAN image through residual networks. The backbone of our method is a multi-head attention residual network (MARNet), which replaces the proximity operator in the optimization scheme and combines multiple head attentions with residual learning to exploit image self-similarities via nonlocal operators defined in terms of patches. Additionally, we incorporate a post-processing module based on the MARNet architecture to further enhance the quality of the fused images. Experimental results on PRISMA, Quickbird, and WorldView2 datasets demonstrate the superior performance of our method and its ability to generalize across different sensor configurations and varying spatial and spectral resolutions. The source code will be available at https://github.com/TAMI-UIB/MARNet.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02725",
        "abstract url": "https://arxiv.org/abs/2409.02725",
        "title": "Pre-training data selection for biomedical domain adaptation using journal impact metrics",
        "rating": "-1",
        "keywords": [
            [
                "biomedical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Domain adaptation is a widely used method in natural language processing (NLP) to improve the performance of a language model within a specific domain. This method is particularly common in the biomedical domain, which sees regular publication of numerous scientific articles. PubMed, a significant corpus of text, is frequently used in the biomedical domain. The primary objective of this study is to explore whether refining a pre-training dataset using specific quality metrics for scientific papers can enhance the performance of the resulting model. To accomplish this, we employ two straightforward journal impact metrics and conduct experiments by continually pre-training BERT on various subsets of the complete PubMed training set, we then evaluate the resulting models on biomedical language understanding tasks from the BLURB benchmark. Our results show that pruning using journal impact metrics is not efficient. But we also show that pre-training using fewer abstracts (but with the same number of training steps) does not necessarily decrease the resulting model's performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02733",
        "abstract url": "https://arxiv.org/abs/2409.02733",
        "title": "Characterization of Circular-arc Graphs: III. Chordal Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "We identify all minimal chordal graphs that are not circular-arc graphs, thereby resolving one of ``the main open problems'' concerning the structures of circular-arc graphs as posed by Dur{\u00e1}n, Grippo, and Safe in 2011. The problem had been attempted even earlier, and previous efforts have yielded partial results, particularly for claw-free graphs and graphs with an independence number of at most four. The answers turn out to have very simple structures: all the nontrivial ones belong to a single family. Our findings are based on a structural study of McConnell's flipping, which transforms circular-arc graphs into interval graphs with certain representation patterns.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02753",
        "abstract url": "https://arxiv.org/abs/2409.02753",
        "title": "Does the Vulnerability Threaten Our Projects? Automated Vulnerable API Detection for Third-Party Libraries",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Developers usually use TPLs to facilitate the development of the projects to avoid reinventing the wheels, however, the vulnerable TPLs indeed cause severe security threats. The majority of existing research only considered whether projects used vulnerable TPLs but neglected whether the vulnerable code of the TPLs was indeed used by the projects, which inevitably results in false positives and further requires additional patching efforts and maintenance costs. To address this, we propose VAScanner, which can effectively identify vulnerable root methods causing vulnerabilities in TPLs and further identify all vulnerable APIs of TPLs used by Java projects. Specifically, we first collect the initial patch methods from the patch commits and extract accurate patch methods by employing a patch-unrelated sifting mechanism, then we further identify the vulnerable root methods for each vulnerability by employing an augmentation mechanism. Based on them, we leverage backward call graph analysis to identify all vulnerable APIs for each vulnerable TPL version and construct a database consisting of 90,749 (2,410,779 with library versions) vulnerable APIs with 1.45% false positive proportion with a 95% CI of [1.31%, 1.59%] from 362 TPLs with 14,775 versions. Our experiments show VAScanner eliminates 5.78% false positives and 2.16% false negatives owing to the proposed sifting and augmentation mechanisms. Besides, it outperforms the state-of-the-art method-level tool in analyzing direct dependencies, Eclipse Steady, achieving more effective detection of vulnerable APIs. Furthermore, in a large-scale analysis of 3,147 projects using vulnerable TPLs, we find only 21.51% of projects (with 1.83% false positive proportion and a 95% CI of [0.71%, 4.61%]) were threatened through vulnerable APIs by vulnerable TPLs, demonstrating that VAScanner can potentially reduce false positives significantly.",
        "subjects": [
            "cs.SE",
            "cs.CR"
        ],
        "comment": "15 pages, 4 figures"
    },
    {
        "paper id": "2409.02770",
        "abstract url": "https://arxiv.org/abs/2409.02770",
        "title": "Validation of musculoskeletal segmentation model with uncertainty estimation for bone and muscle assessment in hip-to-knee clinical CT images",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "CT",
                "disease",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Deep learning-based image segmentation has allowed for the fully automated, accurate, and rapid analysis of musculoskeletal (MSK) structures from medical images. However, current approaches were either applied only to 2D cross-sectional images, addressed few structures, or were validated on small datasets, which limit the application in large-scale databases. This study aimed to validate an improved deep learning model for volumetric MSK segmentation of the hip and thigh with uncertainty estimation from clinical computed tomography (CT) images. Databases of CT images from multiple manufacturers/scanners, disease status, and patient positioning were used. The segmentation accuracy, and accuracy in estimating the structures volume and density, i.e., mean HU, were evaluated. An approach for segmentation failure detection based on predictive uncertainty was also investigated. The model has shown an overall improvement with respect to all segmentation accuracy and structure volume/density evaluation metrics. The predictive uncertainty yielded large areas under the receiver operating characteristic (AUROC) curves (AUROCs>=.95) in detecting inaccurate and failed segmentations. The high segmentation and muscle volume/density estimation accuracy, along with the high accuracy in failure detection based on the predictive uncertainty, exhibited the model's reliability for analyzing individual MSK structures in large-scale CT databases.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "29 pages, 7+10supp figures, 8 tables"
    },
    {
        "paper id": "2409.02828",
        "abstract url": "https://arxiv.org/abs/2409.02828",
        "title": "ExpLLM: Towards Chain of Thought for Facial Expression Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial expression recognition (FER) is a critical task in multimedia with significant implications across various domains. However, analyzing the causes of facial expressions is essential for accurately recognizing them. Current approaches, such as those based on facial action units (AUs), typically provide AU names and intensities but lack insight into the interactions and relationships between AUs and the overall expression. In this paper, we propose a novel method called ExpLLM, which leverages large language models to generate an accurate chain of thought (CoT) for facial expression recognition. Specifically, we have designed the CoT mechanism from three key perspectives: key observations, overall emotional interpretation, and conclusion. The key observations describe the AU's name, intensity, and associated emotions. The overall emotional interpretation provides an analysis based on multiple AUs and their interactions, identifying the dominant emotions and their relationships. Finally, the conclusion presents the final expression label derived from the preceding analysis. Furthermore, we also introduce the Exp-CoT Engine, designed to construct this expression CoT and generate instruction-description data for training our ExpLLM. Extensive experiments on the RAF-DB and AffectNet datasets demonstrate that ExpLLM outperforms current state-of-the-art FER methods. ExpLLM also surpasses the latest GPT-4o in expression CoT generation, particularly in recognizing micro-expressions where GPT-4o frequently fails.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "project page: https://starhiking.github.io/ExpLLM_Page/"
    },
    {
        "paper id": "2409.02832",
        "abstract url": "https://arxiv.org/abs/2409.02832",
        "title": "Diffraction Aided Wireless Positioning",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Wireless positioning in Non-Line-of-Sight (NLOS) scenarios is highly challenging due to multipath, which leads to deterioration in the positioning estimate. This study reexamines electromagnetic field principles and applies them to wireless positioning, resulting in new techniques that enhance positioning accuracy in NLOS scenarios. Further, we use the proposed method to analyze a public safety scenario where it is essential to determine the position of at-risk individuals within buildings, emphasizing improving the Z-axis position estimate. Our analysis uses the Geometrical Theory of Diffraction (GTD) to provide important signal propagation insights and develop a new NLOS path model. Next, we use Fisher information to derive necessary and sufficient conditions for 3D positioning using our proposed positioning technique and finally to lower bound the possible 3D and z-axis positioning performance. On applying this positioning technique in a public safety scenario, we show that it is possible to greatly improve both 3D and Z-axis positioning performance by directly estimating NLOS path lengths.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02833",
        "abstract url": "https://arxiv.org/abs/2409.02833",
        "title": "The Parameterized Complexity of Extending Stack Layouts",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "An $\\ell$-page stack layout (also known as an $\\ell$-page book embedding) of a graph is a linear order of the vertex set together with a partition of the edge set into $\\ell$ stacks (or pages), such that the endpoints of no two edges on the same stack alternate. We study the problem of extending a given partial $\\ell$-page stack layout into a complete one, which can be seen as a natural generalization of the classical NP-hard problem of computing a stack layout of an input graph from scratch. Given the inherent intractability of the problem, we focus on identifying tractable fragments through the refined lens of parameterized complexity analysis. Our results paint a detailed and surprisingly rich complexity-theoretic landscape of the problem which includes the identification of paraNP-hard, W[1]-hard and XP-tractable, as well as fixed-parameter tractable fragments of stack layout extension via a natural sequence of parameterizations.",
        "subjects": [
            "cs.CG",
            "cs.DS"
        ],
        "comment": "Appears in the Proceedings of the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024); 36 pages, 20 figures"
    },
    {
        "paper id": "2409.02844",
        "abstract url": "https://arxiv.org/abs/2409.02844",
        "title": "Knowledge Transfer for Collaborative Misbehavior Detection in Untrusted Vehicular Environments",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Vehicular mobility underscores the need for collaborative misbehavior detection at the vehicular edge. However, locally trained misbehavior detection models are susceptible to adversarial attacks that aim to deliberately influence learning outcomes. In this paper, we introduce a deep reinforcement learning-based approach that employs transfer learning for collaborative misbehavior detection among roadside units (RSUs). In the presence of label-flipping and policy induction attacks, we perform selective knowledge transfer from trustworthy source RSUs to foster relevant expertise in misbehavior detection and avoid negative knowledge sharing from adversary-influenced RSUs. The performance of our proposed scheme is demonstrated with evaluations over a diverse set of misbehavior detection scenarios using an open-source dataset. Experimental results show that our approach significantly reduces the training time at the target RSU and achieves superior detection performance compared to the baseline scheme with tabula rasa learning. Enhanced robustness and generalizability can also be attained, by effectively detecting previously unseen and partially observable misbehavior attacks.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02849",
        "abstract url": "https://arxiv.org/abs/2409.02849",
        "title": "Anomaly Detection in Offshore Open Radio Access Network Using Long Short-Term Memory Models on a Novel Artificial Intelligence-Driven Cloud-Native Data Platform",
        "rating": "-1",
        "keywords": [
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "The radio access network (RAN) is a critical component of modern telecom infrastructure, currently undergoing significant transformation towards disaggregated and open architectures. These advancements are pivotal for integrating intelligent, data-driven applications aimed at enhancing network reliability and operational autonomy through the introduction of cognition capabilities, exemplified by the set of enhancements proposed by the emerging Open radio access network (O-RAN) standards. Despite its potential, the nascent nature of O-RAN technology presents challenges, primarily due to the absence of mature operational standards. This complicates the management of data and applications, particularly in integrating with traditional network management and operational support systems. Divergent vendor-specific design approaches further hinder migration and limit solution reusability. Addressing the skills gap in telecom business-oriented engineering is crucial for the effective deployment of O-RAN and the development of robust data-driven applications. To address these challenges, Boldyn Networks, a global Neutral Host provider, has implemented a novel cloud-native data analytics platform. This platform underwent rigorous testing in real-world scenarios of using advanced artificial intelligence (AI) techniques, significantly improving operational efficiency, and enhancing customer experience. Implementation involved adopting development operations (DevOps) practices, leveraging data lakehouse architectures tailored for AI applications, and employing sophisticated data engineering strategies. The platform successfully addresses connectivity challenges inherent in offshore windfarm deployments using long short-term memory (LSTM) Models for anomaly detection of the connectivity, providing detailed insights into its specialized architecture developed for this purpose.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "16 pages, 12 figures. This manuscript has been submitted to Elsevier for possible publication"
    },
    {
        "paper id": "2409.02851",
        "abstract url": "https://arxiv.org/abs/2409.02851",
        "title": "Human-VDM: Learning Single-Image 3D Human Gaussian Splatting from Video Diffusion Models",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "Diffusion",
                "super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generating lifelike 3D humans from a single RGB image remains a challenging task in computer vision, as it requires accurate modeling of geometry, high-quality texture, and plausible unseen parts. Existing methods typically use multi-view diffusion models for 3D generation, but they often face inconsistent view issues, which hinder high-quality 3D human generation. To address this, we propose Human-VDM, a novel method for generating 3D human from a single RGB image using Video Diffusion Models. Human-VDM provides temporally consistent views for 3D human generation using Gaussian Splatting. It consists of three modules: a view-consistent human video diffusion module, a video augmentation module, and a Gaussian Splatting module. First, a single image is fed into a human video diffusion module to generate a coherent human video. Next, the video augmentation module applies super-resolution and video interpolation to enhance the textures and geometric smoothness of the generated video. Finally, the 3D Human Gaussian Splatting module learns lifelike humans under the guidance of these high-resolution and view-consistent images. Experiments demonstrate that Human-VDM achieves high-quality 3D human from a single image, outperforming state-of-the-art methods in both generation quality and quantity. Project page: https://human-vdm.github.io/Human-VDM/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 Pages, 8 figures, Project page: https://human-vdm.github.io/Human-VDM/"
    },
    {
        "paper id": "2409.02883",
        "abstract url": "https://arxiv.org/abs/2409.02883",
        "title": "Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Drawing tests like the Rey Complex Figure Test (RCFT) are widely used to assess cognitive functions such as visuospatial skills and memory, making them valuable tools for detecting mild cognitive impairment (MCI). Despite their utility, existing predictive models based on these tests often suffer from limitations like small sample sizes and lack of external validation, which undermine their reliability. We developed a multi-stream deep learning framework that integrates two distinct processing streams: a multi-head self-attention based spatial stream using raw RCFT images and a scoring stream employing a previously developed automated scoring system. Our model was trained on data from 1,740 subjects in the Korean cohort and validated on an external hospital dataset of 222 subjects from Korea. The proposed multi-stream model demonstrated superior performance over baseline models (AUC = 0.872, Accuracy = 0.781) in external validation. The integration of both spatial and scoring streams enables the model to capture intricate visual details from the raw images while also incorporating structured scoring data, which together enhance its ability to detect subtle cognitive impairments. This dual approach not only improves predictive accuracy but also increases the robustness of the model, making it more reliable in diverse clinical settings. Our model has practical implications for clinical settings, where it could serve as a cost-effective tool for early MCI screening.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "20 pages, 3 figures, 2 tables"
    },
    {
        "paper id": "2409.02885",
        "abstract url": "https://arxiv.org/abs/2409.02885",
        "title": "CanvOI, an Oncology Intelligence Foundation Model: Scaling FLOPS Differently",
        "rating": "-1",
        "keywords": [
            [
                "biomedical",
                "cancer",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The rapidly evolving field of digital oncopathology faces significant challenges, including the need to address diverse and complex clinical questions, often involving rare conditions, with limited availability of labeled data. These limitations hinder the development of robust AI-driven tools in the biomedical space, where accuracy in probabilistic determinations is of utmost importance. To address this, digital pathology foundation models have begun to emerge, typically developed with the size and diversity of the pre-training dataset and model parameters in mind. Here, we present CanvOI, a ViT-g/10-based foundation model designed to enhance the capabilities of digital pathology by addressing these challenges through a different approach. Considering the unique nature of oncologic histopathological images and the requirements from the embeddings to provide meaningful representations for Multiple Instance Learning (MIL) downstream models, we chose to modify the input image characteristics. By introducing larger tile sizes (380 x 380 pixels) and smaller patch sizes (10 x 10 pixels), we were able to optimize the model's performance, pushing computational resources in a new direction and achieving state-of-the-art performance on cancer-related benchmarks. CanvOI demonstrated a 1.5-7.4% improvement in averaged AUC compared to other leading foundation models built for digital pathology. Moreover, our results demonstrate that CanvOI significantly outperformed the other models, with the performance gap widening substantially when trained on just 10% of the initial cohort. This work highlights an alternative approach that, if integrated with traditional development approaches, has the potential to advance Oncology Intelligence (OI), overcome some of the current barriers and ultimately improve the clinical outcome of cancer patients.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "12 pages, 5 figures"
    },
    {
        "paper id": "2409.02915",
        "abstract url": "https://arxiv.org/abs/2409.02915",
        "title": "Latent Watermarking of Audio Generative Models",
        "rating": "-1",
        "keywords": [
            [
                "Watermarking"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The advancements in audio generative models have opened up new challenges in their responsible disclosure and the detection of their misuse. In response, we introduce a method to watermark latent generative models by a specific watermarking of their training data. The resulting watermarked models produce latent representations whose decoded outputs are detected with high confidence, regardless of the decoding method used. This approach enables the detection of the generated content without the need for a post-hoc watermarking step. It provides a more secure solution for open-sourced models and facilitates the identification of derivative works that fine-tune or use these models without adhering to their license terms. Our results indicate for instance that generated outputs are detected with an accuracy of more than 75% at a false positive rate of $10^{-3}$, even after fine-tuning the latent generative model.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02920",
        "abstract url": "https://arxiv.org/abs/2409.02920",
        "title": "RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics",
                "Robot"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Effective collaboration of dual-arm robots and their tool use capabilities are increasingly important areas in the advancement of robotics. These skills play a significant role in expanding robots' ability to operate in diverse real-world environments. However, progress is impeded by the scarcity of specialized training data. This paper introduces RoboTwin, a novel benchmark dataset combining real-world teleoperated data with synthetic data from digital twins, designed for dual-arm robotic scenarios. Using the COBOT Magic platform, we have collected diverse data on tool usage and human-robot interaction. We present a innovative approach to creating digital twins using AI-generated content, transforming 2D images into detailed 3D models. Furthermore, we utilize large language models to generate expert-level training data and task-specific pose sequences oriented toward functionality. Our key contributions are: 1) the RoboTwin benchmark dataset, 2) an efficient real-to-simulation pipeline, and 3) the use of language models for automatic expert-level data generation. These advancements are designed to address the shortage of robotic training data, potentially accelerating the development of more capable and versatile robotic systems for a wide range of real-world applications. The project page is available at https://robotwin-benchmark.github.io/early-version/",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Project page: https://robotwin-benchmark.github.io/early-version/"
    },
    {
        "paper id": "2409.03055",
        "abstract url": "https://arxiv.org/abs/2409.03055",
        "title": "SymPAC: Scalable Symbolic Music Generation With Prompts And Constraints",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Progress in the task of symbolic music generation may be lagging behind other tasks like audio and text generation, in part because of the scarcity of symbolic training data. In this paper, we leverage the greater scale of audio music data by applying pre-trained MIR models (for transcription, beat tracking, structure analysis, etc.) to extract symbolic events and encode them into token sequences. To the best of our knowledge, this work is the first to demonstrate the feasibility of training symbolic generation models solely from auto-transcribed audio data. Furthermore, to enhance the controllability of the trained model, we introduce SymPAC (Symbolic Music Language Model with Prompting And Constrained Generation), which is distinguished by using (a) prompt bars in encoding and (b) a technique called Constrained Generation via Finite State Machines (FSMs) during inference time. We show the flexibility and controllability of this approach, which may be critical in making music AI useful to creators and users.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "ISMIR 2024"
    },
    {
        "paper id": "2409.03087",
        "abstract url": "https://arxiv.org/abs/2409.03087",
        "title": "Coupling AI and Citizen Science in Creation of Enhanced Training Dataset for Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recent advancements in medical imaging and artificial intelligence (AI) have greatly enhanced diagnostic capabilities, but the development of effective deep learning (DL) models is still constrained by the lack of high-quality annotated datasets. The traditional manual annotation process by medical experts is time- and resource-intensive, limiting the scalability of these datasets. In this work, we introduce a robust and versatile framework that combines AI and crowdsourcing to improve both the quality and quantity of medical image datasets across different modalities. Our approach utilises a user-friendly online platform that enables a diverse group of crowd annotators to label medical images efficiently. By integrating the MedSAM segmentation AI with this platform, we accelerate the annotation process while maintaining expert-level quality through an algorithm that merges crowd-labelled images. Additionally, we employ pix2pixGAN, a generative AI model, to expand the training dataset with synthetic images that capture realistic morphological features. These methods are combined into a cohesive framework designed to produce an enhanced dataset, which can serve as a universal pre-processing pipeline to boost the training of any medical deep learning segmentation model. Our results demonstrate that this framework significantly improves model performance, especially when training data is limited.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03110",
        "abstract url": "https://arxiv.org/abs/2409.03110",
        "title": "MSTT-199: MRI Dataset for Musculoskeletal Soft Tissue Tumor Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "MRI",
                "clinical",
                "Tumor"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Accurate musculoskeletal soft tissue tumor segmentation is vital for assessing tumor size, location, diagnosis, and response to treatment, thereby influencing patient outcomes. However, segmentation of these tumors requires clinical expertise, and an automated segmentation model would save valuable time for both clinician and patient. Training an automatic model requires a large dataset of annotated images. In this work, we describe the collection of an MR imaging dataset of 199 musculoskeletal soft tissue tumors from 199 patients. We trained segmentation models on this dataset and then benchmarked them on a publicly available dataset. Our model achieved the state-of-the-art dice score of 0.79 out of the box without any fine tuning, which shows the diversity and utility of our curated dataset. We analyzed the model predictions and found that its performance suffered on fibrous and vascular tumors due to their diverse anatomical location, size, and intensity heterogeneity. The code and models are available in the following github repository, https://github.com/Reasat/mstt",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Dataset will be made publicly available after the acceptance of the paper"
    },
    {
        "paper id": "2409.03114",
        "abstract url": "https://arxiv.org/abs/2409.03114",
        "title": "Developing, Analyzing, and Evaluating Self-Drive Algorithms Using Drive-by-Wire Electric Vehicles",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving",
                "Vehicle"
            ],
            [
                "Robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reliable lane-following algorithms are essential for safe and effective autonomous driving. This project was primarily focused on developing and evaluating different lane-following programs to find the most reliable algorithm for a Vehicle to Everything (V2X) project. The algorithms were first tested on a simulator and then with real vehicles equipped with a drive-by-wire system using ROS (Robot Operating System). Their performance was assessed through reliability, comfort, speed, and adaptability metrics. The results show that the two most reliable approaches detect both lane lines and use unsupervised learning to separate them. These approaches proved to be robust in various driving scenarios, making them suitable candidates for integration into the V2X project.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Supported by the National Science Foundation under Grants No. 2150292 and 2150096"
    },
    {
        "paper id": "2409.03120",
        "abstract url": "https://arxiv.org/abs/2409.03120",
        "title": "Approximate Environment Decompositions for Robot Coverage Planning using Submodular Set Cover",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "In this paper, we investigate the problem of decomposing 2D environments for robot coverage planning. Coverage path planning (CPP) involves computing a cost-minimizing path for a robot equipped with a coverage or sensing tool so that the tool visits all points in the environment. CPP is an NP-Hard problem, so existing approaches simplify the problem by decomposing the environment into the minimum number of sectors. Sectors are sub-regions of the environment that can each be covered using a lawnmower path (i.e., along parallel straight-line paths) oriented at an angle. However, traditional methods either limit the coverage orientations to be axis-parallel (horizontal/vertical) or provide no guarantees on the number of sectors in the decomposition. We introduce an approach to decompose the environment into possibly overlapping rectangular sectors. We provide an approximation guarantee on the number of sectors computed using our approach for a given environment. We do this by leveraging the submodular property of the sector coverage function, which enables us to formulate the decomposition problem as a submodular set cover (SSC) problem with well-known approximation guarantees for the greedy algorithm. Our approach improves upon existing coverage planning methods, as demonstrated through an evaluation using maps of complex real-world environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Extended version of the 2024 IEEE CDC paper, 8 pages, 3 figures"
    },
    {
        "paper id": "2409.03163",
        "abstract url": "https://arxiv.org/abs/2409.03163",
        "title": "CyberDep: Towards the Analysis of Cyber-Physical Power System Interdependencies Using Bayesian Networks and Temporal Data",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Modern-day power systems have become increasingly cyber-physical due to the ongoing developments to the grid that include the rise of distributed energy generation and the increase of the deployment of many cyber devices for monitoring and control, such as the Supervisory Control and Data Acquisition (SCADA) system. Such capabilities have made the power system more vulnerable to cyber-attacks that can harm the physical components of the system. As such, it is of utmost importance to study both the physical and cyber components together, focusing on characterizing and quantifying the interdependency between these components. This paper focuses on developing an algorithm, named CyberDep, for Bayesian network generation through conditional probability calculations of cyber traffic flows between system nodes. Additionally, CyberDep is implemented on the temporal data of the cyber-physical emulation of the WSCC 9-bus power system. The results of this work provide a visual representation of the probabilistic relationships within the cyber and physical components of the system, aiding in cyber-physical interdependency quantification.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted and Presented at the 2024 Kansas Power and Energy Conference (KPEC 2024)"
    },
    {
        "paper id": "2409.03169",
        "abstract url": "https://arxiv.org/abs/2409.03169",
        "title": "Two or three things I know about tree transducers",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "You might know that the name \"tree transducers\" refers to various kinds of automata that compute functions on ranked trees, i.e. terms over a first-order signature. But have you ever wondered about how to remember what a macro tree transducer does? Or what are the connections between top-down tree(-to-string) transducers, multi bottom-up tree(-to-string) transducers, tree-walking transducers, (invisible) pebble tree transducers, monadic second-order transductions, unfoldings of rooted directed acyclic graphs (i.e. term graphs) -- and what happens when the functions that they compute are composed? The answers may be found in old papers (mostly coauthored by Engelfriet), but maybe you can save some time by first looking at this short note.",
        "subjects": [
            "cs.FL"
        ],
        "comment": "Unpublished note, compiling known results"
    },
    {
        "paper id": "2409.03201",
        "abstract url": "https://arxiv.org/abs/2409.03201",
        "title": "Model Predictive Online Trajectory Planning for Adaptive Battery Discharging in Fuel Cell Vehicle",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory",
                "Vehicle"
            ]
        ],
        "abstract": "This paper presents an online trajectory planning approach for optimal coordination of Fuel Cell (FC) and battery in plug-in Hybrid Electric Vehicle (HEV). One of the main challenges in energy management of plug-in HEV is generating State-of-Charge (SOC) reference curves by optimally depleting battery under high uncertainties in driving scenarios. Recent studies have begun to explore the potential of utilizing partial trip information for optimal SOC trajectory planning, but dynamic responses of the FC system are not taken into account. On the other hand, research focusing on dynamic operation of FC systems often focuses on air flow management, and battery has been treated only partially. Our aim is to fill this gap by designing an online trajectory planner for dynamic coordination of FC and battery systems that works with a high-level SOC planner in a hierarchical manner. We propose an iterative LQR based online trajectory planning method where the amount of electricity dischargeable at each driving segment can be explicitly and adaptively specified by the high-level planner. Numerical results are provided as a proof of concept example to show the effectiveness of the proposed approach.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03225",
        "abstract url": "https://arxiv.org/abs/2409.03225",
        "title": "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Black-box large language models (LLMs) are increasingly deployed in various environments, making it essential for these models to effectively convey their confidence and uncertainty, especially in high-stakes settings. However, these models often exhibit overconfidence, leading to potential risks and misjudgments. Existing techniques for eliciting and calibrating LLM confidence have primarily focused on general reasoning datasets, yielding only modest improvements. Accurate calibration is crucial for informed decision-making and preventing adverse outcomes but remains challenging due to the complexity and variability of tasks these models perform. In this work, we investigate the miscalibration behavior of black-box LLMs within the healthcare setting. We propose a novel method, \\textit{Atypical Presentations Recalibration}, which leverages atypical presentations to adjust the model's confidence estimates. Our approach significantly improves calibration, reducing calibration errors by approximately 60\\% on three medical question answering datasets and outperforming existing methods such as vanilla verbalized confidence, CoT verbalized confidence and others. Additionally, we provide an in-depth analysis of the role of atypicality within the recalibration framework.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03228",
        "abstract url": "https://arxiv.org/abs/2409.03228",
        "title": "Labeled-to-Unlabeled Distribution Alignment for Partially-Supervised Multi-Organ Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "Organ"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Partially-supervised multi-organ medical image segmentation aims to develop a unified semantic segmentation model by utilizing multiple partially-labeled datasets, with each dataset providing labels for a single class of organs. However, the limited availability of labeled foreground organs and the absence of supervision to distinguish unlabeled foreground organs from the background pose a significant challenge, which leads to a distribution mismatch between labeled and unlabeled pixels. Although existing pseudo-labeling methods can be employed to learn from both labeled and unlabeled pixels, they are prone to performance degradation in this task, as they rely on the assumption that labeled and unlabeled pixels have the same distribution. In this paper, to address the problem of distribution mismatch, we propose a labeled-to-unlabeled distribution alignment (LTUDA) framework that aligns feature distributions and enhances discriminative capability. Specifically, we introduce a cross-set data augmentation strategy, which performs region-level mixing between labeled and unlabeled organs to reduce distribution discrepancy and enrich the training set. Besides, we propose a prototype-based distribution alignment method that implicitly reduces intra-class variation and increases the separation between the unlabeled foreground and background. This can be achieved by encouraging consistency between the outputs of two prototype classifiers and a linear classifier. Extensive experimental results on the AbdomenCT-1K dataset and a union of four benchmark datasets (including LiTS, MSD-Spleen, KiTS, and NIH82) demonstrate that our method outperforms the state-of-the-art partially-supervised methods by a considerable margin, and even surpasses the fully-supervised methods. The source code is publicly available at https://github.com/xjiangmed/LTUDA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by Medical Image Analysis"
    },
    {
        "paper id": "2409.03236",
        "abstract url": "https://arxiv.org/abs/2409.03236",
        "title": "Unveiling Context-Related Anomalies: Knowledge Graph Empowered Decoupling of Scene and Action for Human-Related Video Anomaly Detection",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Detecting anomalies in human-related videos is crucial for surveillance applications. Current methods primarily include appearance-based and action-based techniques. Appearance-based methods rely on low-level visual features such as color, texture, and shape. They learn a large number of pixel patterns and features related to known scenes during training, making them effective in detecting anomalies within these familiar contexts. However, when encountering new or significantly changed scenes, i.e., unknown scenes, they often fail because existing SOTA methods do not effectively capture the relationship between actions and their surrounding scenes, resulting in low generalization. In contrast, action-based methods focus on detecting anomalies in human actions but are usually less informative because they tend to overlook the relationship between actions and their scenes, leading to incorrect detection. For instance, the normal event of running on the beach and the abnormal event of running on the street might both be considered normal due to the lack of scene information. In short, current methods struggle to integrate low-level visual and high-level action features, leading to poor anomaly detection in varied and complex scenes. To address this challenge, we propose a novel decoupling-based architecture for human-related video anomaly detection (DecoAD). DecoAD significantly improves the integration of visual and action features through the decoupling and interweaving of scenes and actions, thereby enabling a more intuitive and accurate understanding of complex behaviors and scenes. DecoAD supports fully supervised, weakly supervised, and unsupervised settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13pages, 9 figures"
    },
    {
        "paper id": "2409.02522",
        "abstract url": "https://arxiv.org/abs/2409.02522",
        "title": "Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments",
        "rating": "-1.5",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "Navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Vision Language Navigation in Continuous Environments (VLN-CE) represents a frontier in embodied AI, demanding agents to navigate freely in unbounded 3D spaces solely guided by natural language instructions. This task introduces distinct challenges in multimodal comprehension, spatial reasoning, and decision-making. To address these challenges, we introduce Cog-GA, a generative agent founded on large language models (LLMs) tailored for VLN-CE tasks. Cog-GA employs a dual-pronged strategy to emulate human-like cognitive processes. Firstly, it constructs a cognitive map, integrating temporal, spatial, and semantic elements, thereby facilitating the development of spatial memory within LLMs. Secondly, Cog-GA employs a predictive mechanism for waypoints, strategically optimizing the exploration trajectory to maximize navigational efficiency. Each waypoint is accompanied by a dual-channel scene description, categorizing environmental cues into 'what' and 'where' streams as the brain. This segregation enhances the agent's attentional focus, enabling it to discern pertinent spatial information for navigation. A reflective mechanism complements these strategies by capturing feedback from prior navigation experiences, facilitating continual learning and adaptive replanning. Extensive evaluations conducted on VLN-CE benchmarks validate Cog-GA's state-of-the-art performance and ability to simulate human-like navigation behaviors. This research significantly contributes to the development of strategic and interpretable VLN-CE agents.",
        "subjects": [
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02580",
        "abstract url": "https://arxiv.org/abs/2409.02580",
        "title": "AlignGroup: Learning and Aligning Group Consensus with Member Preferences for Group Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Group activities are important behaviors in human society, providing personalized recommendations for groups is referred to as the group recommendation task. Existing methods can usually be categorized into two strategies to infer group preferences: 1) determining group preferences by aggregating members' personalized preferences, and 2) inferring group consensus by capturing group members' coherent decisions after common compromises. However, the former would suffer from the lack of group-level considerations, and the latter overlooks the fine-grained preferences of individual users. To this end, we propose a novel group recommendation method AlignGroup, which focuses on both group consensus and individual preferences of group members to infer the group decision-making. Specifically, AlignGroup explores group consensus through a well-designed hypergraph neural network that efficiently learns intra- and inter-group relationships. Moreover, AlignGroup innovatively utilizes a self-supervised alignment task to capture fine-grained group decision-making by aligning the group consensus with members' common preferences. Extensive experiments on two real-world datasets validate that our AlignGroup outperforms the state-of-the-art on both the group recommendation task and the user recommendation task, as well as outperforms the efficiency of most baselines.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "10 pages, accepted by CIKM 2024"
    },
    {
        "paper id": "2409.02588",
        "abstract url": "https://arxiv.org/abs/2409.02588",
        "title": "Multiview Random Vector Functional Link Network for Predicting DNA-Binding Proteins",
        "rating": "-1.5",
        "keywords": [
            [
                "biological",
                "DNA"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The identification of DNA-binding proteins (DBPs) is a critical task due to their significant impact on various biological activities. Understanding the mechanisms underlying protein-DNA interactions is essential for elucidating various life activities. In recent years, machine learning-based models have been prominently utilized for DBP prediction. In this paper, to predict DBPs, we propose a novel framework termed a multiview random vector functional link (MvRVFL) network, which fuses neural network architecture with multiview learning. The proposed MvRVFL model combines the benefits of late and early fusion, allowing for distinct regularization parameters across different views while leveraging a closed-form solution to determine unknown parameters efficiently. The primal objective function incorporates a coupling term aimed at minimizing a composite of errors stemming from all views. From each of the three protein views of the DBP datasets, we extract five features. These features are then fused together by incorporating a hidden feature during the model training process. The performance of the proposed MvRVFL model on the DBP dataset surpasses that of baseline models, demonstrating its superior effectiveness. Furthermore, we extend our assessment to the UCI, KEEL, AwA, and Corel5k datasets, to establish the practicality of the proposed models. The consistency error bound, the generalization error bound, and empirical findings, coupled with rigorous statistical analyses, confirm the superior generalization capabilities of the MvRVFL model compared to the baseline models.",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02614",
        "abstract url": "https://arxiv.org/abs/2409.02614",
        "title": "Evaluating the Effects of Digital Privacy Regulations on User Trust",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "In today's digital society, issues related to digital privacy have become increasingly important. Issues such as data breaches result in misuse of data, financial loss, and cyberbullying, which leads to less user trust in digital services. This research investigates the impact of digital privacy laws on user trust by comparing the regulations in the Netherlands, Ghana, and Malaysia. The study employs a comparative case study method, involving interviews with digital privacy law experts, IT educators, and consumers from each country. The main findings reveal that while the General Data Protection Regulation (GDPR) in the Netherlands is strict, its practical impact is limited by enforcement challenges. In Ghana, the Data Protection Act is underutilized due to low public awareness and insufficient enforcement, leading to reliance on personal protective measures. In Malaysia, trust in digital services is largely dependent on the security practices of individual platforms rather than the Personal Data Protection Act. The study highlights the importance of public awareness, effective enforcement, and cultural considerations in shaping the effectiveness of digital privacy laws. Based on these insights, a recommendation framework is proposed to enhance digital privacy practices, also aiming to provide valuable guidance for policymakers, businesses, and citizens in navigating the challenges of digitalization.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02644",
        "abstract url": "https://arxiv.org/abs/2409.02644",
        "title": "Conformal Prediction in Dynamic Biological Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "Biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Uncertainty quantification (UQ) is the process of systematically determining and characterizing the degree of confidence in computational model predictions. In the context of systems biology, especially with dynamic models, UQ is crucial because it addresses the challenges posed by nonlinearity and parameter sensitivity, allowing us to properly understand and extrapolate the behavior of complex biological systems. Here, we focus on dynamic models represented by deterministic nonlinear ordinary differential equations. Many current UQ approaches in this field rely on Bayesian statistical methods. While powerful, these methods often require strong prior specifications and make parametric assumptions that may not always hold in biological systems. Additionally, these methods face challenges in domains where sample sizes are limited, and statistical inference becomes constrained, with computational speed being a bottleneck in large models of biological systems. As an alternative, we propose the use of conformal inference methods, introducing two novel algorithms that, in some instances, offer non-asymptotic guarantees, enhancing robustness and scalability across various applications. We demonstrate the efficacy of our proposed algorithms through several scenarios, highlighting their advantages over traditional Bayesian approaches. The proposed methods show promising results for diverse biological data structures and scenarios, offering a general framework to quantify uncertainty for dynamic models of biological systems.The software for the methodology and the reproduction of the results is available at https://zenodo.org/doi/10.5281/zenodo.13644870.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02681",
        "abstract url": "https://arxiv.org/abs/2409.02681",
        "title": "Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting",
                "satellite"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This study presents a comprehensive methodology for modeling and forecasting the historical time series of fire spots detected by the AQUA_M-T satellite in the Amazon, Brazil. The approach utilizes a mixed Recurrent Neural Network (RNN) model, combining Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures to predict monthly accumulations of daily detected fire spots. A summary of the data revealed a consistent seasonality over time, with annual maximum and minimum fire spot values tending to repeat at the same periods each year. The primary objective is to verify whether the forecasts capture this inherent seasonality through rigorous statistical analysis. The methodology involved careful data preparation, model configuration, and training using cross-validation with two seeds, ensuring that the data generalizes well to the test and validation sets, and confirming the convergence of the model parameters. The results indicate that the mixed LSTM and GRU model offers improved accuracy in forecasting 12 months ahead, demonstrating its effectiveness in capturing complex temporal patterns and modeling the observed time series. This research significantly contributes to the application of deep learning techniques in environmental monitoring, specifically in fire spot forecasting. In addition to improving forecast accuracy, the proposed approach highlights the potential for adaptation to other time series forecasting challenges, opening new avenues for research and development in machine learning and natural phenomenon prediction. Keywords: Time Series Forecasting, Recurrent Neural Networks, Deep Learning.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.AP"
        ],
        "comment": "16 pages, in Portuguese language, 24 figures"
    },
    {
        "paper id": "2409.02842",
        "abstract url": "https://arxiv.org/abs/2409.02842",
        "title": "SNNAX -- Spiking Neural Networks in JAX",
        "rating": "-1.5",
        "keywords": [
            [
                "biologically"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spiking Neural Networks (SNNs) simulators are essential tools to prototype biologically inspired models and neuromorphic hardware architectures and predict their performance. For such a tool, ease of use and flexibility are critical, but so is simulation speed especially given the complexity inherent to simulating SNN. Here, we present SNNAX, a JAX-based framework for simulating and training such models with PyTorch-like intuitiveness and JAX-like execution speed. SNNAX models are easily extended and customized to fit the desired model specifications and target neuromorphic hardware. Additionally, SNNAX offers key features for optimizing the training and deployment of SNNs such as flexible automatic differentiation and just-in-time compilation. We evaluate and compare SNNAX to other commonly used machine learning (ML) frameworks used for programming SNNs. We provide key performance metrics, best practices, documented examples for simulating SNNs in SNNAX, and implement several benchmarks used in the literature.",
        "subjects": [
            "cs.NE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02856",
        "abstract url": "https://arxiv.org/abs/2409.02856",
        "title": "Building a Scalable, Effective, and Steerable Search and Ranking Platform",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modern e-commerce platforms offer vast product selections, making it difficult for customers to find items that they like and that are relevant to their current session intent. This is why it is key for e-commerce platforms to have near real-time scalable and adaptable personalized ranking and search systems. While numerous methods exist in the scientific literature for building such systems, many are unsuitable for large-scale industrial use due to complexity and performance limitations. Consequently, industrial ranking systems often resort to computationally efficient yet simplistic retrieval or candidate generation approaches, which overlook near real-time and heterogeneous customer signals, which results in a less personalized and relevant experience. Moreover, related customer experiences are served by completely different systems, which increases complexity, maintenance, and inconsistent experiences. In this paper, we present a personalized, adaptable near real-time ranking platform that is reusable across various use cases, such as browsing and search, and that is able to cater to millions of items and customers under heavy load (thousands of requests per second). We employ transformer-based models through different ranking layers which can learn complex behavior patterns directly from customer action sequences while being able to incorporate temporal (e.g. in-session) and contextual information. We validate our system through a series of comprehensive offline and online real-world experiments at a large online e-commerce platform, and we demonstrate its superiority when compared to existing systems, both in terms of customer experience as well as in net revenue. Finally, we share the lessons learned from building a comprehensive, modern ranking platform for use in a large-scale e-commerce environment.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02864",
        "abstract url": "https://arxiv.org/abs/2409.02864",
        "title": "Bioinformatics Retrieval Augmentation Data (BRAD) Digital Assistant",
        "rating": "-1.5",
        "keywords": [
            [
                "Bioinformatics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present a prototype for a Bioinformatics Retrieval Augmentation Data (BRAD) digital assistant. BRAD integrates a suite of tools to handle a wide range of bioinformatics tasks, from code execution to online search. We demonstrate BRAD's capabilities through (1) improved question-and-answering with retrieval augmented generation (RAG), (2) BRAD's ability to run and write complex software pipelines, and (3) BRAD's ability to organize and distribute tasks across individual and teams of agents. We use BRAD for automation of bioinformatics workflows, performing tasks ranging from gene enrichment and searching the archive to automatic code generation and running biomarker identification pipelines. BRAD is a step toward the ultimate goal to develop a digital twin of laboratories driven by self-contained loops for hypothesis generation and testing of digital biology experiments.",
        "subjects": [
            "cs.AI",
            "cs.IR",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03118",
        "abstract url": "https://arxiv.org/abs/2409.03118",
        "title": "Generative artificial intelligence for computational chemistry: a roadmap to predicting emergent phenomena",
        "rating": "-1.5",
        "keywords": [
            [
                "chemistry",
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The recent surge in Generative Artificial Intelligence (AI) has introduced exciting possibilities for computational chemistry. Generative AI methods have made significant progress in sampling molecular structures across chemical species, developing force fields, and speeding up simulations. This Perspective offers a structured overview, beginning with the fundamental theoretical concepts in both Generative AI and computational chemistry. It then covers widely used Generative AI methods, including autoencoders, generative adversarial networks, reinforcement learning, flow models and language models, and highlights their selected applications in diverse areas including force field development, and protein/RNA structure prediction. A key focus is on the challenges these methods face before they become truly predictive, particularly in predicting emergent chemical phenomena. We believe that the ultimate goal of a simulation method or theory is to predict phenomena not seen before, and that Generative AI should be subject to these same standards before it is deemed useful for chemistry. We suggest that to overcome these challenges, future AI models need to integrate core chemical principles, especially from statistical mechanics.",
        "subjects": [
            "cond-mat.stat-mech",
            "cond-mat.dis-nn",
            "cs.LG",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03147",
        "abstract url": "https://arxiv.org/abs/2409.03147",
        "title": "Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "biomarker",
                "disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The rapid global aging trend has led to an increase in dementia cases, including Alzheimer's disease, underscoring the urgent need for early and accurate diagnostic methods. Traditional diagnostic techniques, such as cognitive tests, neuroimaging, and biomarker analysis, face significant limitations in sensitivity, accessibility, and cost, particularly in the early stages. This study explores the potential of machine learning (ML) as a transformative approach to enhance early dementia detection by leveraging ML models to analyze and integrate complex multimodal datasets, including cognitive assessments, neuroimaging, and genetic information. A comprehensive review of existing literature was conducted to evaluate various ML models, including supervised learning, deep learning, and advanced techniques such as ensemble learning and transformer models, assessing their accuracy, interpretability, and potential for clinical integration. The findings indicate that while ML models show significant promise in improving diagnostic precision and enabling earlier interventions, challenges remain in their generalizability, interpretability, and ethical deployment. This research concludes by outlining future directions aimed at enhancing the clinical utility of ML models in dementia detection, emphasizing interdisciplinary collaboration and ethically sound frameworks to improve early detection and intervention strategies for Alzheimer's disease and other forms of dementia.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03239",
        "abstract url": "https://arxiv.org/abs/2409.03239",
        "title": "DiffGrad for Physics-Informed Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Physics-Informed Neural Networks (PINNs) are regarded as state-of-the-art tools for addressing highly nonlinear problems based on partial differential equations. Despite their broad range of applications, PINNs encounter several performance challenges, including issues related to efficiency, minimization of computational cost, and enhancement of accuracy. Burgers' equation, a fundamental equation in fluid dynamics that is extensively used in PINNs, provides flexible results with the Adam optimizer that does not account for past gradients. This paper introduces a novel strategy for solving Burgers' equation by incorporating DiffGrad with PINNs, a method that leverages the difference between current and immediately preceding gradients to enhance performance. A comprehensive computational analysis is conducted using optimizers such as Adam, Adamax, RMSprop, and DiffGrad to evaluate and compare their effectiveness. Our approach includes visualizing the solutions over space at various time intervals to demonstrate the accuracy of the network. The results show that DiffGrad not only improves the accuracy of the solution but also reduces training time compared to the other optimizers.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.comp-ph"
        ],
        "comment": "20 pages, 14 figures"
    },
    {
        "paper id": "2409.03800",
        "abstract url": "https://arxiv.org/abs/2409.03800",
        "title": "Flat-earth communities on Brazilian Telegram: when faith is used to question the existence of gravity as a physics phenomenon",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Conspiracy theories related to flat-earthism have gained traction on Brazilian Telegram, especially in times of global crisis, such as the COVID-19 pandemic, when distrust in scientific and governmental institutions has intensified. Therefore, this study aims to address the research question: how are Brazilian conspiracy theory communities on flat earth topics characterized and articulated on Telegram? It is worth noting that this study is part of a series of seven studies whose main objective is to understand and characterize Brazilian conspiracy theory communities on Telegram. This series of seven studies is openly and originally available on arXiv at Cornell University, applying a mirrored method across the seven studies, changing only the thematic object of analysis and providing investigation replicability, including with proprietary and authored codes, adding to the culture of free and open-source software. Regarding the main findings of this study, the following were observed: During the Pandemic, flat-earthist discussions increased by 400%, driven by distrust in scientific institutions; Flat-Earther communities act as portals for other conspiracy theories, such as the New World Order; Although smaller, the flat-Earther network has influential groups that disseminate content and perpetuate narratives; Religious themes such as God and the Bible are central, combining religious elements with distrust in science; Flat-Earther communities use themes such as gravity to challenge established scientific concepts, reinforcing an alternative view of the world.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "46 pages, 12 figures, #DataConspiraProject. arXiv admin note: substantial text overlap with arXiv:2409.00325, arXiv:2409.02117, arXiv:2409.03130, arXiv:2408.15311, arXiv:2408.15308"
    },
    {
        "paper id": "2409.02483",
        "abstract url": "https://arxiv.org/abs/2409.02483",
        "title": "TASAR: Transferable Attack on Skeletal Action Recognition",
        "rating": "-2",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "autonomous driving"
            ],
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Skeletal sequences, as well-structured representations of human behaviors, are crucial in Human Activity Recognition (HAR). The transferability of adversarial skeletal sequences enables attacks in real-world HAR scenarios, such as autonomous driving, intelligent surveillance, and human-computer interactions. However, existing Skeleton-based HAR (S-HAR) attacks exhibit weak adversarial transferability and, therefore, cannot be considered true transfer-based S-HAR attacks. More importantly, the reason for this failure remains unclear. In this paper, we study this phenomenon through the lens of loss surface, and find that its sharpness contributes to the poor transferability in S-HAR. Inspired by this observation, we assume and empirically validate that smoothening the rugged loss landscape could potentially improve adversarial transferability in S-HAR. To this end, we propose the first Transfer-based Attack on Skeletal Action Recognition, TASAR. TASAR explores the smoothed model posterior without re-training the pre-trained surrogates, which is achieved by a new post-train Dual Bayesian optimization strategy. Furthermore, unlike previous transfer-based attacks that treat each frame independently and overlook temporal coherence within sequences, TASAR incorporates motion dynamics into the Bayesian attack gradient, effectively disrupting the spatial-temporal coherence of S-HARs. To exhaustively evaluate the effectiveness of existing methods and our method, we build the first large-scale robust S-HAR benchmark, comprising 7 S-HAR models, 10 attack methods, 3 S-HAR datasets and 2 defense models. Extensive results demonstrate the superiority of TASAR. Our benchmark enables easy comparisons for future studies, with the code available in the supplementary material.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2407.08572"
    },
    {
        "paper id": "2409.02492",
        "abstract url": "https://arxiv.org/abs/2409.02492",
        "title": "Reliable Deep Diffusion Tensor Estimation: Rethinking the Power of Data-Driven Optimization Routine",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Diffusion tensor imaging (DTI) holds significant importance in clinical diagnosis and neuroscience research. However, conventional model-based fitting methods often suffer from sensitivity to noise, leading to decreased accuracy in estimating DTI parameters. While traditional data-driven deep learning methods have shown potential in terms of accuracy and efficiency, their limited generalization to out-of-training-distribution data impedes their broader application due to the diverse scan protocols used across centers, scanners, and studies. This work aims to tackle these challenges and promote the use of DTI by introducing a data-driven optimization-based method termed DoDTI. DoDTI combines the weighted linear least squares fitting algorithm and regularization by denoising technique. The former fits DW images from diverse acquisition settings into diffusion tensor field, while the latter applies a deep learning-based denoiser to regularize the diffusion tensor field instead of the DW images, which is free from the limitation of fixed-channel assignment of the network. The optimization object is solved using the alternating direction method of multipliers and then unrolled to construct a deep neural network, leveraging a data-driven strategy to learn network parameters. Extensive validation experiments are conducted utilizing both internally simulated datasets and externally obtained in-vivo datasets. The results, encompassing both qualitative and quantitative analyses, showcase that the proposed method attains state-of-the-art performance in DTI parameter estimation. Notably, it demonstrates superior generalization, accuracy, and efficiency, rendering it highly reliable for widespread application in the field.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02520",
        "abstract url": "https://arxiv.org/abs/2409.02520",
        "title": "Bootstrap percolation on rhombus tilings",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "2-boostrap percolation on a graph is a diffusion process where a vertex gets infected whenever it has at least 2 infected neighbours, and then stays infected forever. It has been much studied on the infinite grid for random Bernoulli initial configurations, starting from the seminal result of van Enter that establishes that the entire grid gets almost surely entirely infected for any non-trivial initial probability of infection. In this paper, we generalize this result to any adjacency graph of any rhombus tiling of the plane, including aperiodic ones like Penrose tilings. We actually show almost sure infection of the entire graph for a larger class of measure than non-trivial Bernoulli ones. Our proof strategy combines a geometry toolkit for infected clusters based on chain-convexity, and uniform probabilistic bounds on particular geometric patterns that play the role of 0-1 laws or ergodicity, which are not available in our settings due to the lack of symmetry of the graph considered.",
        "subjects": [
            "cs.DM",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02553",
        "abstract url": "https://arxiv.org/abs/2409.02553",
        "title": "ResiLogic: Leveraging Composability and Diversity to Design Fault and Intrusion Resilient Chips",
        "rating": "-2",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "A long-standing challenge is the design of chips resilient to faults and glitches. Both fine-grained gate diversity and coarse-grained modular redundancy have been used in the past. However, these approaches have not been well-studied under other threat models where some stakeholders in the supply chain are untrusted. Increasing digital sovereignty tensions raise concerns regarding the use of foreign off-the-shelf tools and IPs, or off-sourcing fabrication, driving research into the design of resilient chips under this threat model. This paper addresses a threat model considering three pertinent attacks to resilience: distribution, zonal, and compound attacks. To mitigate these attacks, we introduce the \\texttt{ResiLogic} framework that exploits \\textit{Diversity by Composability}: constructing diverse circuits composed of smaller diverse ones by design. This gives designer the capability to create circuits at design time without requiring extra redundancy in space or cost. Using this approach at different levels of granularity is shown to improve the resilience of circuit design in \\texttt{ResiLogic} against the three considered attacks by a factor of five. Additionally, we also make a case to show how E-Graphs can be utilized to generate diverse circuits under given rewrite rules.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02566",
        "abstract url": "https://arxiv.org/abs/2409.02566",
        "title": "How Do You Perceive My Face? Recognizing Facial Expressions in Multi-Modal Context by Modeling Mental Representations",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial expression perception in humans inherently relies on prior knowledge and contextual cues, contributing to efficient and flexible processing. For instance, multi-modal emotional context (such as voice color, affective text, body pose, etc.) can prompt people to perceive emotional expressions in objectively neutral faces. Drawing inspiration from this, we introduce a novel approach for facial expression classification that goes beyond simple classification tasks. Our model accurately classifies a perceived face and synthesizes the corresponding mental representation perceived by a human when observing a face in context. With this, our model offers visual insights into its internal decision-making process. We achieve this by learning two independent representations of content and context using a VAE-GAN architecture. Subsequently, we propose a novel attention mechanism for context-dependent feature adaptation. The adapted representation is used for classification and to generate a context-augmented expression. We evaluate synthesized expressions in a human study, showing that our model effectively produces approximations of human mental representations. We achieve State-of-the-Art classification accuracies of 81.01% on the RAVDESS dataset and 79.34% on the MEAD dataset. We make our code publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "GCPR 2024"
    },
    {
        "paper id": "2409.02579",
        "abstract url": "https://arxiv.org/abs/2409.02579",
        "title": "Assembling the Puzzle: Exploring Collaboration and Data Sensemaking in Nursing Practices for Remote Patient Monitoring",
        "rating": "-2",
        "keywords": [
            [
                "health",
                "healthcare",
                "clinical"
            ]
        ],
        "abstract": "Remote patient monitoring (RPM) involves the remote collection and transmission of patient health data, serving as a notable application of data-driven healthcare. This technology facilitates clinical monitoring and decision-making, offering benefits like reduced healthcare costs and improved patient outcomes. However, RPM also introduces challenges common to data-driven healthcare, such as additional data work that can disrupt clinician's workflow. This study explores the daily practices, collaboration mechanisms, and sensemaking processes of nurses in RPM through field observations and interviews with six stakeholders. Preliminary results indicate that RPM's scale-up pushes clinicians toward asynchronous collaboration. Data sensemaking is crucial for this type of collaboration, but existing technologies often create friction rather than support. This work provides empirical insights into clinical workflow in nursing practice, especially RPM. We suggest recognizing data sensemaking as a distinct nursing practice within data work and recommend further investigation into its role in the workflow of nurses in RPM.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02597",
        "abstract url": "https://arxiv.org/abs/2409.02597",
        "title": "Rate-Adaptive Generative Semantic Communication Using Conditional Diffusion Models",
        "rating": "-2",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "Diffusion"
            ]
        ],
        "abstract": "Recent advances in deep learning-based joint source-channel coding (DJSCC) have shown promise for end-to-end semantic image transmission. However, most existing schemes primarily focus on optimizing pixel-wise metrics, which often fail to align with human perception, leading to lower perceptual quality. In this letter, we propose a novel generative DJSCC approach using conditional diffusion models to enhance the perceptual quality of transmitted images. Specifically, by utilizing entropy models, we effectively manage transmission bandwidth based on the estimated entropy of transmitted sym-bols. These symbols are then used at the receiver as conditional information to guide a conditional diffusion decoder in image reconstruction. Our model is built upon the emerging advanced mamba-like linear attention (MLLA) skeleton, which excels in image processing tasks while also offering fast inference speed. Besides, we introduce a multi-stage training strategy to ensure the stability and improve the overall performance of the model. Simulation results demonstrate that our proposed method significantly outperforms existing approaches in terms of perceptual quality.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02608",
        "abstract url": "https://arxiv.org/abs/2409.02608",
        "title": "A Medical Multimodal Large Language Model for Pediatric Pneumonia",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "diagnosing",
                "CT",
                "X-ray",
                "disease",
                "clinical",
                "radiology"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Pediatric pneumonia is the leading cause of death among children under five years worldwide, imposing a substantial burden on affected families. Currently, there are three significant hurdles in diagnosing and treating pediatric pneumonia. Firstly, pediatric pneumonia shares similar symptoms with other respiratory diseases, making rapid and accurate differential diagnosis challenging. Secondly, primary hospitals often lack sufficient medical resources and experienced doctors. Lastly, providing personalized diagnostic reports and treatment recommendations is labor-intensive and time-consuming. To tackle these challenges, we proposed a Medical Multimodal Large Language Model for Pediatric Pneumonia (P2Med-MLLM). It was capable of handling diverse clinical tasks, such as generating free-text radiology reports and medical records within a unified framework. Specifically, P2Med-MLLM can process both pure text and image-text data, trained on an extensive and large-scale dataset (P2Med-MD), including real clinical information from 163,999 outpatient and 8,684 inpatient cases. This dataset comprised 2D chest X-ray images, 3D chest CT images, corresponding radiology reports, and outpatient and inpatient records. We designed a three-stage training strategy to enable P2Med-MLLM to comprehend medical knowledge and follow instructions for various clinical tasks. To rigorously evaluate P2Med-MLLM's performance, we developed P2Med-MBench, a benchmark consisting of 642 meticulously verified samples by pediatric pulmonology specialists, covering six clinical decision-support tasks and a balanced variety of diseases. The automated scoring results demonstrated the superiority of P2Med-MLLM. This work plays a crucial role in assisting primary care doctors with prompt disease diagnosis and treatment planning, reducing severe symptom mortality rates, and optimizing the allocation of medical resources.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 10 figures"
    },
    {
        "paper id": "2409.02618",
        "abstract url": "https://arxiv.org/abs/2409.02618",
        "title": "Neuromorphic Heart Rate Monitors: Neural State Machines for Monotonic Change Detection",
        "rating": "-2",
        "keywords": [
            [
                "bio-signals",
                "health",
                "cardiac"
            ]
        ],
        "abstract": "Detecting monotonic changes in heart rate (HR) is crucial for early identification of cardiac conditions and health management. This is particularly important for dementia patients, where HR trends can signal stress or agitation. Developing wearable technologies that can perform always-on monitoring of HRs is essential to effectively detect slow changes over extended periods of time. However, designing compact electronic circuits that can monitor and process bio-signals continuously, and that can operate in a low-power regime to ensure long-lasting performance, is still an open challenge. Neuromorphic technology offers an energy-efficient solution for real-time health monitoring. We propose a neuromorphic implementation of a Neural State Machine (NSM) network to encode different health states and switch between them based on the input stimuli. Our focus is on detecting monotonic state switches in electrocardiogram data to identify progressive HR increases. This innovative approach promises significant advancements in continuous health monitoring and management.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02638",
        "abstract url": "https://arxiv.org/abs/2409.02638",
        "title": "MADiff: Motion-Aware Mamba Diffusion Models for Hand Trajectory Prediction on Egocentric Videos",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Trajectory"
            ],
            [
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding human intentions and actions through egocentric videos is important on the path to embodied artificial intelligence. As a branch of egocentric vision techniques, hand trajectory prediction plays a vital role in comprehending human motion patterns, benefiting downstream tasks in extended reality and robot manipulation. However, capturing high-level human intentions consistent with reasonable temporal causality is challenging when only egocentric videos are available. This difficulty is exacerbated under camera egomotion interference and the absence of affordance labels to explicitly guide the optimization of hand waypoint distribution. In this work, we propose a novel hand trajectory prediction method dubbed MADiff, which forecasts future hand waypoints with diffusion models. The devised denoising operation in the latent space is achieved by our proposed motion-aware Mamba, where the camera wearer's egomotion is integrated to achieve motion-driven selective scan (MDSS). To discern the relationship between hands and scenarios without explicit affordance supervision, we leverage a foundation model that fuses visual and language features to capture high-level semantics from video clips. Comprehensive experiments conducted on five public datasets with the existing and our proposed new evaluation metrics demonstrate that MADiff predicts comparably reasonable hand trajectories compared to the state-of-the-art baselines, and achieves real-time performance. We will release our code and pretrained models of MADiff at the project page: https://irmvlab.github.io/madiff.github.io.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02676",
        "abstract url": "https://arxiv.org/abs/2409.02676",
        "title": "Improved Single Camera BEV Perception Using Multi-Camera Training",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving",
                "trajectory",
                "vehicle"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Bird's Eye View (BEV) map prediction is essential for downstream autonomous driving tasks like trajectory prediction. In the past, this was accomplished through the use of a sophisticated sensor configuration that captured a surround view from multiple cameras. However, in large-scale production, cost efficiency is an optimization goal, so that using fewer cameras becomes more relevant. But the consequence of fewer input images correlates with a performance drop. This raises the problem of developing a BEV perception model that provides a sufficient performance on a low-cost sensor setup. Although, primarily relevant for inference time on production cars, this cost restriction is less problematic on a test vehicle during training. Therefore, the objective of our approach is to reduce the aforementioned performance drop as much as possible using a modern multi-camera surround view model reduced for single-camera inference. The approach includes three features, a modern masking technique, a cyclic Learning Rate (LR) schedule, and a feature reconstruction loss for supervising the transition from six-camera inputs to one-camera input during training. Our method outperforms versions trained strictly with one camera or strictly with six-camera surround view for single-camera inference resulting in reduced hallucination and better quality of the BEV map.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This Paper has been accepted to the 27th IEEE International Conference on Intelligent Transportation Systems (ITSC 2024)"
    },
    {
        "paper id": "2409.02718",
        "abstract url": "https://arxiv.org/abs/2409.02718",
        "title": "Alignment-Aware Model Extraction Attacks on Large Language Models",
        "rating": "-2",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "watermark"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Model extraction attacks (MEAs) on large language models (LLMs) have received increasing research attention lately. Existing attack methods on LLMs inherit the extraction strategies from those designed for deep neural networks (DNNs) yet neglect the inconsistency of training tasks between MEA and LLMs' alignments. As such, they result in poor attack performances. To tackle this issue, we present Locality Reinforced Distillation (LoRD), a novel model extraction attack algorithm specifically for LLMs. In particular, we design a policy-gradient-style training task, which utilizes victim models' responses as a signal to guide the crafting of preference for the local model. Theoretical analysis has shown that i) LoRD's convergence procedure in MEAs is consistent with the alignments of LLMs, and ii) LoRD can reduce query complexity while mitigating watermark protection through exploration-based stealing. Extensive experiments on domain-specific extractions demonstrate the superiority of our method by examining the extraction of various state-of-the-art commercial LLMs.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "comment": "Source code: https://github.com/liangzid/alignmentExtraction"
    },
    {
        "paper id": "2409.02735",
        "abstract url": "https://arxiv.org/abs/2409.02735",
        "title": "RTFM: How hard are IoT platform providers making it for their developers?",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Internet of Things (IoT) devices routinely have security issues, but are the platform designers providing enough support to IoT developers for them to easily implement security features for their platforms? We surveyed the documentation, code and guidance from nine IoT manufacturers to look at what guidance they provided for implementing three security features required by several security standards (secure boot, device identity keys and unique per device passwords). We find that more needs to be done to support developers if we want them to adopt security features -- especially in the face of incoming legislation that will require developers to implement them.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Presented at the 6th Joint Workshop on CPS & IoT Security and Privacy in conjunction with the ACM Conference on Computer and Communications Security 2024"
    },
    {
        "paper id": "2409.02745",
        "abstract url": "https://arxiv.org/abs/2409.02745",
        "title": "Adaptive Formation Learning Control for Cooperative AUVs under Complete Uncertainty",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "This paper presents a two-layer control framework for Autonomous Underwater Vehicles (AUVs) designed to handle uncertain nonlinear dynamics, including the mass matrix, previously assumed known. Unlike prior studies, this approach makes the controller independent of the robot's configuration and varying environmental conditions. The proposed framework applies across different environmental conditions affecting AUVs. It features a first-layer cooperative estimator and a second-layer decentralized deterministic learning controller. This architecture supports robust operation under diverse underwater scenarios, managing environmental effects like changes in water viscosity and flow, which impact the AUV's effective mass and damping dynamics. The first-layer estimator enables seamless inter-agent communication by sharing crucial system estimates without relying on global information. The second-layer controller uses local feedback to adjust each AUV's trajectory, ensuring accurate formation control and dynamic adaptability. Radial basis function neural networks enable local learning and knowledge storage, allowing AUVs to efficiently reapply learned dynamics after system restarts. Simulations validate the effectiveness of this framework, marking it as a significant advancement in distributed adaptive control systems for AUVs, enhancing operational flexibility and resilience in unpredictable marine environments.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Submitted in journal of Frontiers in Robotics and AI, 30 pages, 8 figures, 1 table"
    },
    {
        "paper id": "2409.02771",
        "abstract url": "https://arxiv.org/abs/2409.02771",
        "title": "CoolerSpace: A Language for Physically Correct and Computationally Efficient Color Programming",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Color programmers manipulate lights, materials, and the resulting colors from light-material interactions. Existing libraries for color programming provide only a thin layer of abstraction around matrix operations. Color programs are, thus, vulnerable to bugs arising from mathematically permissible but physically meaningless matrix computations. Correct implementations are difficult to write and optimize. We introduce CoolerSpace to facilitate physically correct and computationally efficient color programming. CoolerSpace raises the level of abstraction of color programming by allowing programmers to focus on describing the logic of color physics. Correctness and efficiency are handled by CoolerSpace. The type system in CoolerSpace assigns physical meaning and dimensions to user-defined objects. The typing rules permit only legal computations informed by color physics and perception. Along with type checking, CoolerSpace also generates performance-optimized programs using equality saturation. CoolerSpace is implemented as a Python library and compiles to ONNX, a common intermediate representation for tensor computations. CoolerSpace not only prevents common errors in color programming, but also does so without run-time overhead: even unoptimized CoolerSpace programs out-perform existing Python-based color programming systems by up to 5.7 times; our optimizations provide up to an additional 1.4 times speed-up.",
        "subjects": [
            "cs.PL",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02785",
        "abstract url": "https://arxiv.org/abs/2409.02785",
        "title": "A Novel Interference Minimizing Waveform for Wireless Channels with Fractional Delay: Inter-block Interference Analysis",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "In the physical layer (PHY) of modern cellular systems, information is transmitted as a sequence of resource blocks (RBs) across various domains with each resource block limited to a certain time and frequency duration. In the PHY of 4G/5G systems, data is transmitted in the unit of transport block (TB) across a fixed number of physical RBs based on resource allocation decisions. This simultaneous time and frequency localized structure of resource allocation is at odds with the perennial time-frequency compactness limits. Specifically, the band-limiting operation will disrupt the time localization and lead to inter-block interference (IBI). The IBI extent, i.e., the number of neighboring blocks that contribute to the interference, depends mainly on the spectral concentration properties of the signaling waveforms. Deviating from the standard Gabor-frame based multi-carrier approaches which use time-frequency shifted versions of a single prototype pulse, the use of a set of multiple mutually orthogonal pulse shapes-that are not related by a time-frequency shift relationship-is proposed. We hypothesize that using discrete prolate spheroidal sequences (DPSS) as the set of waveform pulse shapes reduces IBI. Analytical expressions for upper bounds on IBI are derived as well as simulation results provided that support our hypothesis.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02797",
        "abstract url": "https://arxiv.org/abs/2409.02797",
        "title": "Joint Beamforming for Backscatter Integrated Sensing and Communication",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Integrated sensing and communication (ISAC) is a key technology of next generation wireless communication. Backscatter communication (BackCom) plays an important role for internet of things (IoT). Then the integration of ISAC with BackCom technology enables low-power data transmission while enhancing the system sensing ability, which is expected to provide a potentially revolutionary solution for IoT applications. In this paper, we propose a novel backscatter-ISAC (B-ISAC) system and focus on the joint beamforming design for the system. We formulate the communication and sensing model of the B-ISAC system and derive the metrics of communication and sensing performance respectively, i.e., communication rate and detection probability. We propose a joint beamforming scheme aiming to optimize the communication rate under sensing constraint and power budget. A successive convex approximation (SCA) based algorithm and an iterative algorithm are developed for solving the complicated non-convex optimization problem. Numerical results validate the effectiveness of the proposed scheme and associated algorithms. The proposed B-ISAC system has broad application prospect in IoT scenarios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 4 figures, IEEE Global Communications Conference (Globecom) 2024. This paper is the conference version of the following work: arXiv:2407.19235"
    },
    {
        "paper id": "2409.02826",
        "abstract url": "https://arxiv.org/abs/2409.02826",
        "title": "Automatic facial axes standardization of 3D fetal ultrasound images",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "diagnosis",
                "clinical",
                "facial"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Craniofacial anomalies indicate early developmental disturbances and are usually linked to many genetic syndromes. Early diagnosis is critical, yet ultrasound (US) examinations often fail to identify these features. This study presents an AI-driven tool to assist clinicians in standardizing fetal facial axes/planes in 3D US, reducing sonographer workload and facilitating the facial evaluation. Our network, structured into three blocks-feature extractor, rotation and translation regression, and spatial transformer-processes three orthogonal 2D slices to estimate the necessary transformations for standardizing the facial planes in the 3D US. These transformations are applied to the original 3D US using a differentiable module (the spatial transformer block), yielding a standardized 3D US and the corresponding 2D facial standard planes. The dataset used consists of 1180 fetal facial 3D US images acquired between weeks 20 and 35 of gestation. Results show that our network considerably reduces inter-observer rotation variability in the test set, with a mean geodesic angle difference of 14.12$^{\\circ}$ $\\pm$ 18.27$^{\\circ}$ and an Euclidean angle error of 7.45$^{\\circ}$ $\\pm$ 14.88$^{\\circ}$. These findings demonstrate the network's ability to effectively standardize facial axes, crucial for consistent fetal facial assessments. In conclusion, the proposed network demonstrates potential for improving the consistency and accuracy of fetal facial assessments in clinical settings, facilitating early evaluation of craniofacial anomalies.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02845",
        "abstract url": "https://arxiv.org/abs/2409.02845",
        "title": "Multi-Track MusicLDM: Towards Versatile Music Generation with Latent Diffusion Model",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Music",
                "text-to-music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Diffusion models have shown promising results in cross-modal generation tasks involving audio and music, such as text-to-sound and text-to-music generation. These text-controlled music generation models typically focus on generating music by capturing global musical attributes like genre and mood. However, music composition is a complex, multilayered task that often involves musical arrangement as an integral part of the process. This process involves composing each instrument to align with existing ones in terms of beat, dynamics, harmony, and melody, requiring greater precision and control over tracks than text prompts usually provide. In this work, we address these challenges by extending the MusicLDM, a latent diffusion model for music, into a multi-track generative model. By learning the joint probability of tracks sharing a context, our model is capable of generating music across several tracks that correspond well to each other, either conditionally or unconditionally. Additionally, our model is capable of arrangement generation, where the model can generate any subset of tracks given the others (e.g., generating a piano track complementing given bass and drum tracks). We compared our model with an existing multi-track generative model and demonstrated that our model achieves considerable improvements across objective metrics for both total and arrangement generation tasks.",
        "subjects": [
            "cs.SD",
            "cs.MM",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02912",
        "abstract url": "https://arxiv.org/abs/2409.02912",
        "title": "Design of a Standard-Compliant Real-Time Neural Receiver for 5G NR",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "We detail the steps required to deploy a multi-user multiple-input multiple-output (MU-MIMO) neural receiver (NRX) in an actual cellular communication system. This raises several exciting research challenges, including the need for real-time inference and compatibility with the 5G NR standard. As the network configuration in a practical setup can change dynamically within milliseconds, we propose an adaptive NRX architecture capable of supporting dynamic modulation and coding scheme (MCS) configurations without the need for any re-training and without additional inference cost. We optimize the latency of the neural network (NN) architecture to achieve inference times of less than 1ms on an NVIDIA A100 GPU using the TensorRT inference library. These latency constraints effectively limit the size of the NN and we quantify the resulting signal-to-noise ratio (SNR) degradation as less than 0.7 dB when compared to a preliminary non-real-time NRX architecture. Finally, we explore the potential for site-specific adaptation of the receiver by investigating the required size of the training dataset and the number of fine-tuning iterations to optimize the NRX for specific radio environments using a ray tracing-based channel model. The resulting NRX is ready for deployment in a real-time 5G NR system and the source code including the TensorRT experiments is available online.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02917",
        "abstract url": "https://arxiv.org/abs/2409.02917",
        "title": "UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views",
        "rating": "-2",
        "keywords": [
            [
                "NeRF",
                "Radiance Fields"
            ],
            [
                "surgical",
                "Endoscopic"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Visualizing surgical scenes is crucial for revealing internal anatomical structures during minimally invasive procedures. Novel View Synthesis is a vital technique that offers geometry and appearance reconstruction, enhancing understanding, planning, and decision-making in surgical scenes. Despite the impressive achievements of Neural Radiance Field (NeRF), its direct application to surgical scenes produces unsatisfying results due to two challenges: endoscopic sparse views and significant photometric inconsistencies. In this paper, we propose uncertainty-aware conditional NeRF for novel view synthesis to tackle the severe shape-radiance ambiguity from sparse surgical views. The core of UC-NeRF is to incorporate the multi-view uncertainty estimation to condition the neural radiance field for modeling the severe photometric inconsistencies adaptively. Specifically, our UC-NeRF first builds a consistency learner in the form of multi-view stereo network, to establish the geometric correspondence from sparse views and generate uncertainty estimation and feature priors. In neural rendering, we design a base-adaptive NeRF network to exploit the uncertainty estimation for explicitly handling the photometric inconsistencies. Furthermore, an uncertainty-guided geometry distillation is employed to enhance geometry learning. Experiments on the SCARED and Hamlyn datasets demonstrate our superior performance in rendering appearance and geometry, consistently outperforming the current state-of-the-art approaches. Our code will be released at \\url{https://github.com/wrld/UC-NeRF}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03010",
        "abstract url": "https://arxiv.org/abs/2409.03010",
        "title": "Geometry of the cumulant series in neuroimaging",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "MRI",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Water diffusion gives rise to micrometer-scale sensitivity of diffusion MRI (dMRI) to cellular-level tissue structure. The advent of precision medicine and quantitative imaging hinges on revealing the information content of dMRI, and providing its parsimonious basis- and hardware-independent \"fingerprint\". Here we reveal the geometry of a multi-dimensional dMRI signal, classify all 21 invariants of diffusion and covariance tensors in terms of irreducible representations of the group of rotations, and relate them to tissue properties. Previously studied dMRI contrasts are expressed via 7 invariants, while the remaining 14 provide novel complementary information. We design acquisitions based on icosahedral vertices guaranteeing minimal number of measurements to determine 3-4 most used invariants in only 1-2 minutes for the whole brain. Representing dMRI signals via scalar invariant maps with definite symmetries will underpin machine learning classifiers of brain pathology, development, and aging, while fast protocols will enable translation of advanced dMRI into clinical practice.",
        "subjects": [
            "physics.med-ph",
            "eess.IV",
            "physics.bio-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03046",
        "abstract url": "https://arxiv.org/abs/2409.03046",
        "title": "Oddballness: universal anomaly detection with language models",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "We present a new method to detect anomalies in texts (in general: in sequences of any data), using language models, in a totally unsupervised manner. The method considers probabilities (likelihoods) generated by a language model, but instead of focusing on low-likelihood tokens, it considers a new metric introduced in this paper: oddballness. Oddballness measures how ``strange'' a given token is according to the language model. We demonstrate in grammatical error detection tasks (a specific case of text anomaly detection) that oddballness is better than just considering low-likelihood events, if a totally unsupervised setup is assumed.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03057",
        "abstract url": "https://arxiv.org/abs/2409.03057",
        "title": "VECA: Reliable and Confidential Resource Clustering for Volunteer Edge-Cloud Computing",
        "rating": "-2",
        "keywords": [
            [
                "bioinformatics",
                "health"
            ]
        ],
        "abstract": "Volunteer Edge-Cloud (VEC) computing has a significant potential to support scientific workflows in user communities contributing volunteer edge nodes. However, managing heterogeneous and intermittent resources to support machine/deep learning (ML/DL) based workflows poses challenges in resource governance for reliability, and confidentiality for model/data privacy protection. There is a need for approaches to handle the volatility of volunteer edge node availability, and also to scale the confidential data-intensive workflow execution across a large number of VEC nodes. In this paper, we present VECA, a reliable and confidential VEC resource clustering solution featuring three-fold methods tailored for executing ML/DL-based scientific workflows on VEC resources. Firstly, a capacity-based clustering approach enhances system reliability and minimizes VEC node search latency. Secondly, a novel two-phase, globally distributed scheduling scheme optimizes job allocation based on node attributes and using time-series-based Recurrent Neural Networks. Lastly, the integration of confidential computing ensures privacy preservation of the scientific workflows, where model and data information are not shared with VEC resources providers. We evaluate VECA in a Function-as-a-Service (FaaS) cloud testbed that features OpenFaaS and MicroK8S to support two ML/DL-based scientific workflows viz., G2P-Deep (bioinformatics) and PAS-ML (health informatics). Results from tested experiments demonstrate that our proposed VECA approach outperforms state-of-the-art methods; especially VECA exhibits a two-fold reduction in VEC node search latency and over 20% improvement in productivity rates following execution failures compared to the next best method.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted - IC2E 2024 Conference"
    },
    {
        "paper id": "2409.03061",
        "abstract url": "https://arxiv.org/abs/2409.03061",
        "title": "Incorporating dense metric depth into neural 3D representations for view synthesis and relighting",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "autonomous driving"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Synthesizing accurate geometry and photo-realistic appearance of small scenes is an active area of research with compelling use cases in gaming, virtual reality, robotic-manipulation, autonomous driving, convenient product capture, and consumer-level photography. When applying scene geometry and appearance estimation techniques to robotics, we found that the narrow cone of possible viewpoints due to the limited range of robot motion and scene clutter caused current estimation techniques to produce poor quality estimates or even fail. On the other hand, in robotic applications, dense metric depth can often be measured directly using stereo and illumination can be controlled. Depth can provide a good initial estimate of the object geometry to improve reconstruction, while multi-illumination images can facilitate relighting. In this work we demonstrate a method to incorporate dense metric depth into the training of neural 3D representations and address an artifact observed while jointly refining geometry and appearance by disambiguating between texture and geometry edges. We also discuss a multi-flash stereo camera system developed to capture the necessary data for our pipeline and show results on relighting and view synthesis with a few training views.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.RO"
        ],
        "comment": "Project webpage: https://stereomfc.github.io"
    },
    {
        "paper id": "2409.03094",
        "abstract url": "https://arxiv.org/abs/2409.03094",
        "title": "A Bayesian Optimization through Sequential Monte Carlo and Statistical Physics-Inspired Techniques",
        "rating": "-2",
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "In this paper, we propose an approach for an application of Bayesian optimization using Sequential Monte Carlo (SMC) and concepts from the statistical physics of classical systems. Our method leverages the power of modern machine learning libraries such as NumPyro and JAX, allowing us to perform Bayesian optimization on multiple platforms, including CPUs, GPUs, TPUs, and in parallel. Our approach enables a low entry level for exploration of the methods while maintaining high performance. We present a promising direction for developing more efficient and effective techniques for a wide range of optimization problems in diverse fields.",
        "subjects": [
            "stat.CO",
            "cs.DC",
            "physics.data-an"
        ],
        "comment": "8 pages, 7 figures, accepted to the International Conference on Computer Science 2023"
    },
    {
        "paper id": "2409.03119",
        "abstract url": "https://arxiv.org/abs/2409.03119",
        "title": "Register Aggregation for Hardware Decompilation",
        "rating": "-2",
        "keywords": [
            [
                "FPGAs"
            ]
        ],
        "abstract": "Hardware decompilation reverses logic synthesis, converting a gate-level digital electronic design, or netlist, back up to hardware description language (HDL) code. Existing techniques decompile data-oriented features in netlists, like loops and modules, but struggle with sequential logic. In particular, they cannot decompile memory elements, which pose difficulty due to their deconstruction into individual bits and the feedback loops they form in the netlist. Recovering multi-bit registers and memory blocks from netlists would expand the applications of hardware decompilation, notably towards retargeting technologies (e.g. FPGAs to ASICs) and decompiling processor memories. We devise a method for register aggregation, to identify relationships between the data flip-flops in a netlist and group them into registers and memory blocks, resulting in HDL code that instantiates these memory elements. We aggregate flip-flops by identifying common enable pins, and derive the bit-order of the resulting registers using functional dependencies. This scales similarly to memory blocks, where we repeat the algorithm in the second dimension with special attention to the read, write, and address ports of each memory block. We evaluate our technique over a dataset of 13 gate-level netlists, comprising circuits from binary multipliers to CPUs, and we compare the quantity and widths of recovered registers and memory blocks with the original source code. The technique successfully recovers memory elements in all of the tested circuits, even aggregating beyond the source code expectation. In 10 / 13 circuits, all source code memory elements are accounted for, and we are able to compact up to 2048 disjoint bits into a single memory block.",
        "subjects": [
            "cs.AR",
            "cs.PL"
        ],
        "comment": "6 pages, 6 figures"
    },
    {
        "paper id": "2409.03121",
        "abstract url": "https://arxiv.org/abs/2409.03121",
        "title": "QHDOPT: A Software for Nonlinear Optimization with Quantum Hamiltonian Descent",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We develop an open-source, end-to-end software (named QHDOPT), which can solve nonlinear optimization problems using the quantum Hamiltonian descent (QHD) algorithm. QHDOPT offers an accessible interface and automatically maps tasks to various supported quantum backends (i.e., quantum hardware machines). These features enable users, even those without prior knowledge or experience in quantum computing, to utilize the power of existing quantum devices for nonlinear and nonconvex optimization tasks. In its intermediate compilation layer, QHDOPT employs SimuQ, an efficient interface for Hamiltonian-oriented programming, to facilitate multiple algorithmic specifications and ensure compatible cross-hardware deployment. The detailed documentation of QHDOPT is available at https://github.com/jiaqileng/QHDOPT.",
        "subjects": [
            "quant-ph",
            "cs.MS",
            "math.OC"
        ],
        "comment": "23 pages, 7 figures. The full repository is available at https://github.com/jiaqileng/QHDOPT"
    },
    {
        "paper id": "2409.03140",
        "abstract url": "https://arxiv.org/abs/2409.03140",
        "title": "GraphEx: A Graph-based Extraction Method for Advertiser Keyphrase Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Online sellers and advertisers are recommended keyphrases for their listed products, which they bid on to enhance their sales. One popular paradigm that generates such recommendations is Extreme Multi-Label Classification (XMC), which involves tagging/mapping keyphrases to items. We outline the limitations of using traditional item-query based tagging or mapping techniques for keyphrase recommendations on E-Commerce platforms. We introduce GraphEx, an innovative graph-based approach that recommends keyphrases to sellers using extraction of token permutations from item titles. Additionally, we demonstrate that relying on traditional metrics such as precision/recall can be misleading in practical applications, thereby necessitating a combination of metrics to evaluate performance in real-world scenarios. These metrics are designed to assess the relevance of keyphrases to items and the potential for buyer outreach. GraphEx outperforms production models at eBay, achieving the objectives mentioned above. It supports near real-time inferencing in resource-constrained production environments and scales effectively for billions of items.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03179",
        "abstract url": "https://arxiv.org/abs/2409.03179",
        "title": "Perceptual-Distortion Balanced Image Super-Resolution is a Multi-Objective Optimization Problem",
        "rating": "-2",
        "keywords": [
            [
                "GAN",
                "Super-Resolution"
            ],
            [
                "image restoration",
                "quality assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Training Single-Image Super-Resolution (SISR) models using pixel-based regression losses can achieve high distortion metrics scores (e.g., PSNR and SSIM), but often results in blurry images due to insufficient recovery of high-frequency details. Conversely, using GAN or perceptual losses can produce sharp images with high perceptual metric scores (e.g., LPIPS), but may introduce artifacts and incorrect textures. Balancing these two types of losses can help achieve a trade-off between distortion and perception, but the challenge lies in tuning the loss function weights. To address this issue, we propose a novel method that incorporates Multi-Objective Optimization (MOO) into the training process of SISR models to balance perceptual quality and distortion. We conceptualize the relationship between loss weights and image quality assessment (IQA) metrics as black-box objective functions to be optimized within our Multi-Objective Bayesian Optimization Super-Resolution (MOBOSR) framework. This approach automates the hyperparameter tuning process, reduces overall computational cost, and enables the use of numerous loss functions simultaneously. Extensive experiments demonstrate that MOBOSR outperforms state-of-the-art methods in terms of both perceptual quality and distortion, significantly advancing the perception-distortion Pareto frontier. Our work points towards a new direction for future research on balancing perceptual quality and fidelity in nearly all image restoration tasks. The source code and pretrained models are available at: https://github.com/ZhuKeven/MOBOSR.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03185",
        "abstract url": "https://arxiv.org/abs/2409.03185",
        "title": "DasAtom: A Divide-and-Shuttle Atom Approach to Quantum Circuit Transformation",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Neutral atom (NA) quantum systems are emerging as a leading platform for quantum computation, offering superior or competitive qubit count and gate fidelity compared to superconducting circuits and ion traps. However, the unique features of NA devices, such as long-range interactions, long qubit coherence time, and the ability to physically move qubits, present distinct challenges for quantum circuit compilation. In this paper, we introduce DasAtom, a novel divide-and-shuttle atom approach designed to optimise quantum circuit transformation for NA devices by leveraging these capabilities. DasAtom partitions circuits into subcircuits, each associated with a qubit mapping that allows all gates within the subcircuit to be directly executed. The algorithm then shuttles atoms to transition seamlessly from one mapping to the next, enhancing both execution efficiency and overall fidelity. For a 30-qubit Quantum Fourier Transform (QFT), DasAtom achieves a 414x improvement in fidelity over the move-based algorithm Enola and a 10.6x improvement over the SWAP-based algorithm Tetris. Notably, this improvement is expected to increase exponentially with the number of qubits, positioning DasAtom as a highly promising solution for scaling quantum computation on NA platforms.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03200",
        "abstract url": "https://arxiv.org/abs/2409.03200",
        "title": "Active Fake: DeepFake Camouflage",
        "rating": "-2",
        "keywords": [
            [
                "DeepFake"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "DeepFake technology has gained significant attention due to its ability to manipulate facial attributes with high realism, raising serious societal concerns. Face-Swap DeepFake is the most harmful among these techniques, which fabricates behaviors by swapping original faces with synthesized ones. Existing forensic methods, primarily based on Deep Neural Networks (DNNs), effectively expose these manipulations and have become important authenticity indicators. However, these methods mainly concentrate on capturing the blending inconsistency in DeepFake faces, raising a new security issue, termed Active Fake, emerges when individuals intentionally create blending inconsistency in their authentic videos to evade responsibility. This tactic is called DeepFake Camouflage. To achieve this, we introduce a new framework for creating DeepFake camouflage that generates blending inconsistencies while ensuring imperceptibility, effectiveness, and transferability. This framework, optimized via an adversarial learning strategy, crafts imperceptible yet effective inconsistencies to mislead forensic detectors. Extensive experiments demonstrate the effectiveness and robustness of our method, highlighting the need for further research in active fake detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03213",
        "abstract url": "https://arxiv.org/abs/2409.03213",
        "title": "Optimizing 3D Gaussian Splatting for Sparse Viewpoint Scene Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "Depth",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "diffusion"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting (3DGS) has emerged as a promising approach for 3D scene representation, offering a reduction in computational overhead compared to Neural Radiance Fields (NeRF). However, 3DGS is susceptible to high-frequency artifacts and demonstrates suboptimal performance under sparse viewpoint conditions, thereby limiting its applicability in robotics and computer vision. To address these limitations, we introduce SVS-GS, a novel framework for Sparse Viewpoint Scene reconstruction that integrates a 3D Gaussian smoothing filter to suppress artifacts. Furthermore, our approach incorporates a Depth Gradient Profile Prior (DGPP) loss with a dynamic depth mask to sharpen edges and 2D diffusion with Score Distillation Sampling (SDS) loss to enhance geometric consistency in novel view synthesis. Experimental evaluations on the MipNeRF-360 and SeaThru-NeRF datasets demonstrate that SVS-GS markedly improves 3D reconstruction from sparse viewpoints, offering a robust and efficient solution for scene understanding in robotics and computer vision applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03223",
        "abstract url": "https://arxiv.org/abs/2409.03223",
        "title": "Why mamba is effective? Exploit Linear Transformer-Mamba Network for Multi-Modality Image Fusion",
        "rating": "-2",
        "keywords": [
            [
                "infrared"
            ],
            [
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modality image fusion aims to integrate the merits of images from different sources and render high-quality fusion images. However, existing feature extraction and fusion methods are either constrained by inherent local reduction bias and static parameters during inference (CNN) or limited by quadratic computational complexity (Transformers), and cannot effectively extract and fuse features. To solve this problem, we propose a dual-branch image fusion network called Tmamba. It consists of linear Transformer and Mamba, which has global modeling capabilities while maintaining linear complexity. Due to the difference between the Transformer and Mamba structures, the features extracted by the two branches carry channel and position information respectively. T-M interaction structure is designed between the two branches, using global learnable parameters and convolutional layers to transfer position and channel information respectively. We further propose cross-modal interaction at the attention level to obtain cross-modal attention. Experiments show that our Tmamba achieves promising results in multiple fusion tasks, including infrared-visible image fusion and medical image fusion. Code with checkpoints will be available after the peer-review process.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03245",
        "abstract url": "https://arxiv.org/abs/2409.03245",
        "title": "UAV (Unmanned Aerial Vehicles): Diverse Applications of UAV Datasets in Segmentation, Classification, Detection, and Tracking",
        "rating": "-2",
        "keywords": [
            [
                "Vehicle",
                "re-identification"
            ],
            [
                "UAV",
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unmanned Aerial Vehicles (UAVs), have greatly revolutionized the process of gathering and analyzing data in diverse research domains, providing unmatched adaptability and effectiveness. This paper presents a thorough examination of Unmanned Aerial Vehicle (UAV) datasets, emphasizing their wide range of applications and progress. UAV datasets consist of various types of data, such as satellite imagery, images captured by drones, and videos. These datasets can be categorized as either unimodal or multimodal, offering a wide range of detailed and comprehensive information. These datasets play a crucial role in disaster damage assessment, aerial surveillance, object recognition, and tracking. They facilitate the development of sophisticated models for tasks like semantic segmentation, pose estimation, vehicle re-identification, and gesture recognition. By leveraging UAV datasets, researchers can significantly enhance the capabilities of computer vision models, thereby advancing technology and improving our understanding of complex, dynamic environments from an aerial perspective. This review aims to encapsulate the multifaceted utility of UAV datasets, emphasizing their pivotal role in driving innovation and practical applications in multiple domains.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03249",
        "abstract url": "https://arxiv.org/abs/2409.03249",
        "title": "Multiple weather images restoration using the task transformer and adaptive mixup strategy",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "haze"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The current state-of-the-art in severe weather removal predominantly focuses on single-task applications, such as rain removal, haze removal, and snow removal. However, real-world weather conditions often consist of a mixture of several weather types, and the degree of weather mixing in autonomous driving scenarios remains unknown. In the presence of complex and diverse weather conditions, a single weather removal model often encounters challenges in producing clear images from severe weather images. Therefore, there is a need for the development of multi-task severe weather removal models that can effectively handle mixed weather conditions and improve image quality in autonomous driving scenarios. In this paper, we introduce a novel multi-task severe weather removal model that can effectively handle complex weather conditions in an adaptive manner. Our model incorporates a weather task sequence generator, enabling the self-attention mechanism to selectively focus on features specific to different weather types. To tackle the challenge of repairing large areas of weather degradation, we introduce Fast Fourier Convolution (FFC) to increase the receptive field. Additionally, we propose an adaptive upsampling technique that effectively processes both the weather task information and underlying image features by selectively retaining relevant information. Our proposed model has achieved state-of-the-art performance on the publicly available dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 5 figures and 2 table"
    },
    {
        "paper id": "2409.03798",
        "abstract url": "https://arxiv.org/abs/2409.03798",
        "title": "Interpretable Cyber Threat Detection for Enterprise Industrial Networks: A Computational Design Science Approach",
        "rating": "-2",
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "Enterprise industrial networks face threats that risk data and operations. However, designing efficient threat detection system is challenging due to data scarcity, especially where privacy is a concern. The complexity of enterprise industrial network data adds to this challenge, causing high false positives and interpretation issues. Towards this, we use IS computational design science paradigm to develop a two-stage cyber threat detection system for enterprise-level IS that are both secure and capable of adapting to evolving technological and business environments. The first stage generates synthetic industrial network data using a modified generative adversarial network. The second stage develops a novel bidirectional gated recurrent unit and a modified attention mechanism for effective threat detection. We also use shapley additive explanations and a decision tree technique for enhancing interpretability. Our analysis on two public datasets shows the frameworks high precision in threat detection and offers practical cybersecurity solutions and methodological advancements.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages, 11 figures"
    },
    {
        "paper id": "2409.03803",
        "abstract url": "https://arxiv.org/abs/2409.03803",
        "title": "OGRePy: An Object-Oriented General Relativity Package for Python",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "We present OGRePy, the official Python port of the popular Mathematica tensor calculus package OGRe (Object-Oriented General Relativity) - a powerful, yet user-friendly, tool for advanced tensor calculations in mathematics and physics, especially suitable for general relativity. The Python port uses the same robust and performance-oriented algorithms as the original package, and retains its core design principles. However, its truly object-oriented interface, enabled by Python, is more intuitive and flexible than the original Mathematica implementation. It utilizes SymPy for symbolic computations and Jupyter as a notebook interface. OGRePy allows calculating arbitrary tensor formulas using any combination of addition, multiplication by scalar, trace, contraction, partial derivative, covariant derivative, and permutation of indices. Transformations of the tensor components between different index configurations and/or coordinate systems are performed seamlessly behind the scenes as needed, eliminating user error due to combining incompatible representations, and guaranteeing consistent results. In addition, the package provides facilities for easily calculating various curvature tensors and geodesic equations in multiple representations. This paper presents the main features of the package in great detail, including many examples of its use in the context of general relativity research.",
        "subjects": [
            "gr-qc",
            "cs.MS",
            "cs.SC",
            "math.DG"
        ],
        "comment": "72 pages, Python port of arXiv:2109.04193, source code available at https://github.com/bshoshany/OGRePy"
    },
    {
        "paper id": "2409.02702",
        "abstract url": "https://arxiv.org/abs/2409.02702",
        "title": "Incorporating Like-Minded Peers to Overcome Friend Data Sparsity in Session-Based Social Recommendations",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.SI"
            ]
        ],
        "abstract": "Session-based Social Recommendation (SSR) leverages social relationships within online networks to enhance the performance of Session-based Recommendation (SR). However, existing SSR algorithms often encounter the challenge of \"friend data sparsity\". Moreover, significant discrepancies can exist between the purchase preferences of social network friends and those of the target user, reducing the influence of friends relative to the target user's own preferences. To address these challenges, this paper introduces the concept of \"Like-minded Peers\" (LMP), representing users whose preferences align with the target user's current session based on their historical sessions. This is the first work, to our knowledge, that uses LMP to enhance the modeling of social influence in SSR. This approach not only alleviates the problem of friend data sparsity but also effectively incorporates users with similar preferences to the target user. We propose a novel model named Transformer Encoder with Graph Attention Aggregator Recommendation (TEGAARec), which includes the TEGAA module and the GAT-based social aggregation module. The TEGAA module captures and merges both long-term and short-term interests for target users and LMP users. Concurrently, the GAT-based social aggregation module is designed to aggregate the target users' dynamic interests and social influence in a weighted manner. Extensive experiments on four real-world datasets demonstrate the efficacy and superiority of our proposed model and ablation studies are done to illustrate the contributions of each component in TEGAARec.",
        "subjects": [
            "cs.SI",
            "cs.AI"
        ],
        "comment": "None"
    },
    {
        "paper id": "2409.02802",
        "abstract url": "https://arxiv.org/abs/2409.02802",
        "title": "Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recently, the issue of adversarial robustness in the time series domain has garnered significant attention. However, the available defense mechanisms remain limited, with adversarial training being the predominant approach, though it does not provide theoretical guarantees. Randomized Smoothing has emerged as a standout method due to its ability to certify a provable lower bound on robustness radius under $\\ell_p$-ball attacks. Recognizing its success, research in the time series domain has started focusing on these aspects. However, existing research predominantly focuses on time series forecasting, or under the non-$\\ell_p$ robustness in statistic feature augmentation for time series classification~(TSC). Our review found that Randomized Smoothing performs modestly in TSC, struggling to provide effective assurances on datasets with poor robustness. Therefore, we propose a self-ensemble method to enhance the lower bound of the probability confidence of predicted labels by reducing the variance of classification margins, thereby certifying a larger radius. This approach also addresses the computational overhead issue of Deep Ensemble~(DE) while remaining competitive and, in some cases, outperforming it in terms of robustness. Both theoretical analysis and experimental results validate the effectiveness of our method, demonstrating superior performance in robustness testing compared to baseline approaches.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "stat.ML"
        ],
        "comment": "6 figures, 4 tables, 10 pages"
    },
    {
        "paper id": "2409.02891",
        "abstract url": "https://arxiv.org/abs/2409.02891",
        "title": "Regional data-driven weather modeling with a global stretched-grid",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "A data-driven model (DDM) suitable for regional weather forecasting applications is presented. The model extends the Artificial Intelligence Forecasting System by introducing a stretched-grid architecture that dedicates higher resolution over a regional area of interest and maintains a lower resolution elsewhere on the globe. The model is based on graph neural networks, which naturally affords arbitrary multi-resolution grid configurations. The model is applied to short-range weather prediction for the Nordics, producing forecasts at 2.5 km spatial and 6 h temporal resolution. The model is pre-trained on 43 years of global ERA5 data at 31 km resolution and is further refined using 3.3 years of 2.5 km resolution operational analyses from the MetCoOp Ensemble Prediction System (MEPS). The performance of the model is evaluated using surface observations from measurement stations across Norway and is compared to short-range weather forecasts from MEPS. The DDM outperforms both the control run and the ensemble mean of MEPS for 2 m temperature. The model also produces competitive precipitation and wind speed forecasts, but is shown to underestimate extreme events.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03005",
        "abstract url": "https://arxiv.org/abs/2409.03005",
        "title": "PIETRA: Physics-Informed Evidential Learning for Traversing Out-of-Distribution Terrain",
        "rating": "-2.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Self-supervised learning is a powerful approach for developing traversability models for off-road navigation, but these models often struggle with inputs unseen during training. Existing methods utilize techniques like evidential deep learning to quantify model uncertainty, helping to identify and avoid out-of-distribution terrain. However, always avoiding out-of-distribution terrain can be overly conservative, e.g., when novel terrain can be effectively analyzed using a physics-based model. To overcome this challenge, we introduce Physics-Informed Evidential Traversability (PIETRA), a self-supervised learning framework that integrates physics priors directly into the mathematical formulation of evidential neural networks and introduces physics knowledge implicitly through an uncertainty-aware, physics-informed training loss. Our evidential network seamlessly transitions between learned and physics-based predictions for out-of-distribution inputs. Additionally, the physics-informed loss regularizes the learned model, ensuring better alignment with the physics model. Extensive simulations and hardware experiments demonstrate that PIETRA improves both learning accuracy and navigation performance in environments with significant distribution shifts.",
        "subjects": [
            "cs.RO",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "Submitted to RA-L. Video: https://youtu.be/OTnNZ96oJRk"
    },
    {
        "paper id": "2409.03148",
        "abstract url": "https://arxiv.org/abs/2409.03148",
        "title": "Discovering Cyclists' Street Visual Preferences Through Multi-Source Big Data Using Deep Inverse Reinforcement Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cycling has gained global popularity for its health benefits and positive urban impacts. To effectively promote cycling, early studies have extensively investigated the relationship between cycling behaviors and environmental factors, especially cyclists' preferences when making route decisions. However, these studies often struggle to comprehensively describe detailed cycling procedures at a large scale due to data limitations, and they tend to overlook the complex nature of cyclists' preferences. To address these issues, we propose a novel framework aimed to quantify and interpret cyclists' complicated street visual preferences from cycling records by leveraging maximum entropy deep inverse reinforcement learning (MEDIRL) and explainable artificial intelligence (XAI). Implemented in Bantian Sub-district, Shenzhen, we adapt MEDIRL model for efficient estimation of cycling reward function by integrating dockless-bike-sharing (DBS) trajectory and street view images (SVIs), which serves as a representation of cyclists' preferences for street visual environments during routing. In addition, we demonstrate the feasibility and reliability of MEDIRL in discovering cyclists' street visual preferences. Further analysis reveals the nonlinear and interactive effects of street visual elements on cyclists' preferences, offering a holistic perspective on streetscape design. Our proposed framework advances the understanding of individual cycling behaviors and provides actionable insights for urban planners to design bicycle-friendly streetscapes that prioritize cyclists' preferences.",
        "subjects": [
            "cs.LG",
            "cs.HC"
        ],
        "comment": "38 pages, 16 figures"
    },
    {
        "paper id": "2409.03180",
        "abstract url": "https://arxiv.org/abs/2409.03180",
        "title": "Machine learning-based algorithms for at-home respiratory disease monitoring and respiratory assessment",
        "rating": "-2.5",
        "keywords": [
            [
                "SVM",
                "support vector machine"
            ],
            [
                "health",
                "disease",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Respiratory diseases impose a significant burden on global health, with current diagnostic and management practices primarily reliant on specialist clinical testing. This work aims to develop machine learning-based algorithms to facilitate at-home respiratory disease monitoring and assessment for patients undergoing continuous positive airway pressure (CPAP) therapy. Data were collected from 30 healthy adults, encompassing respiratory pressure, flow, and dynamic thoraco-abdominal circumferential measurements under three breathing conditions: normal, panting, and deep breathing. Various machine learning models, including the random forest classifier, logistic regression, and support vector machine (SVM), were trained to predict breathing types. The random forest classifier demonstrated the highest accuracy, particularly when incorporating breathing rate as a feature. These findings support the potential of AI-driven respiratory monitoring systems to transition respiratory assessments from clinical settings to home environments, enhancing accessibility and patient autonomy. Future work involves validating these models with larger, more diverse populations and exploring additional machine learning techniques.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 2 figures"
    },
    {
        "paper id": "2409.02518",
        "abstract url": "https://arxiv.org/abs/2409.02518",
        "title": "AirFogSim: A Light-Weight and Modular Simulator for UAV-Integrated Vehicular Fog Computing",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Vehicular Fog Computing (VFC) is significantly enhancing the efficiency, safety, and computational capabilities of Intelligent Transportation Systems (ITS), and the integration of Unmanned Aerial Vehicles (UAVs) further elevates these advantages by incorporating flexible and auxiliary services. This evolving UAV-integrated VFC paradigm opens new doors while presenting unique complexities within the cooperative computation framework. Foremost among the challenges, modeling the intricate dynamics of aerial-ground interactive computing networks is a significant endeavor, and the absence of a comprehensive and flexible simulation platform may impede the exploration of this field. Inspired by the pressing need for a versatile tool, this paper provides a lightweight and modular aerial-ground collaborative simulation platform, termed AirFogSim. We present the design and implementation of AirFogSim, and demonstrate its versatility with five key missions in the domain of UAV-integrated VFC. A multifaceted use case is carried out to validate AirFogSim's effectiveness, encompassing several integral aspects of the proposed AirFogSim, including UAV trajectory, task offloading, resource allocation, and blockchain. In general, AirFogSim is envisioned to set a new precedent in the UAV-integrated VFC simulation, bridge the gap between theoretical design and practical validation, and pave the way for future intelligent transportation domains. Our code will be available at https://github.com/ZhiweiWei-NAMI/AirFogSim.",
        "subjects": [
            "cs.NI",
            "cs.SE"
        ],
        "comment": "17 pages, 8 figures, submitted to IEEE Transactions on Mobile Computing"
    },
    {
        "paper id": "2409.02606",
        "abstract url": "https://arxiv.org/abs/2409.02606",
        "title": "Real-time design of architectural structures with differentiable simulators and neural networks",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Designing mechanically efficient geometry for architectural structures like shells, towers, and bridges is an expensive iterative process. Existing techniques for solving such inverse mechanical problems rely on traditional direct optimization methods, which are slow and computationally expensive, limiting iteration speed and design exploration. Neural networks would seem to offer an alternative, via data-driven amortized optimization for specific design tasks, but they often require extensive regularization and cannot ensure that important design criteria, such as mechanical integrity, are met. In this work, we combine neural networks with a differentiable mechanics simulator and develop a model that accelerates the solution of shape approximation problems for architectural structures. This approach allows a neural network to capture the physics of the task directly from the simulation during training, instead of having to discern it from input data and penalty terms in a physics-informed loss function. As a result, we can generate feasible designs on a variety of structural types that satisfy mechanical and geometric constraints a priori, with better accuracy than fully neural alternatives trained with handcrafted losses, while achieving comparable performance to direct optimization, but in real time. We validate our method in two distinct structural shape-matching tasks, the design of masonry shells and cable-net towers, and showcase its real-world potential for design exploration by deploying it as a plugin in commercial 3D modeling software. Our work opens up new opportunities for real-time design enhanced by neural networks of mechanically sound and efficient architectural structures in the built environment.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02680",
        "abstract url": "https://arxiv.org/abs/2409.02680",
        "title": "A Low-Cost Real-Time Spiking System for Obstacle Detection based on Ultrasonic Sensors and Rate Coding",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "biology"
            ]
        ],
        "abstract": "Since the advent of mobile robots, obstacle detection has been a topic of great interest. It has also been a subject of study in neuroscience, where flying insects and bats could be considered two of the most interesting cases in terms of vision-based and sound-based mechanisms for obstacle detection, respectively. Currently, many studies focus on vision-based obstacle detection, but not many can be found regarding sound-based obstacle detection. This work focuses on the latter approach, which also makes use of a Spiking Neural Network to exploit the advantages of these architectures and achieve an approach closer to biology. The complete system was tested through a series of experiments that confirm the validity of the spiking architecture for obstacle detection. It is empirically demonstrated that, when the distance between the robot and the obstacle decreases, the output firing rate of the system increases in response as expected, and vice versa. Therefore, there is a direct relation between the two. Furthermore, there is a distance threshold between detectable and undetectable objects which is also empirically measured in this work. An in-depth study on how this system works at low level based on the Inter-Spike Interval concept was performed, which may be useful in the future development of applications based on spiking filters.",
        "subjects": [
            "cs.RO",
            "cs.NE"
        ],
        "comment": "22 pages, 8 figures"
    },
    {
        "paper id": "2409.02724",
        "abstract url": "https://arxiv.org/abs/2409.02724",
        "title": "Surgical Task Automation Using Actor-Critic Frameworks and Self-Supervised Imitation Learning",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "Surgical"
            ]
        ],
        "abstract": "Surgical robot task automation has recently attracted great attention due to its potential to benefit both surgeons and patients. Reinforcement learning (RL) based approaches have demonstrated promising ability to provide solutions to automated surgical manipulations on various tasks. To address the exploration challenge, expert demonstrations can be utilized to enhance the learning efficiency via imitation learning (IL) approaches. However, the successes of such methods normally rely on both states and action labels. Unfortunately action labels can be hard to capture or their manual annotation is prohibitively expensive owing to the requirement for expert knowledge. It therefore remains an appealing and open problem to leverage expert demonstrations composed of pure states in RL. In this work, we present an actor-critic RL framework, termed AC-SSIL, to overcome this challenge of learning with state-only demonstrations collected by following an unknown expert policy. It adopts a self-supervised IL method, dubbed SSIL, to effectively incorporate demonstrated states into RL paradigms by retrieving from demonstrates the nearest neighbours of the query state and utilizing the bootstrapping of actor networks. We showcase through experiments on an open-source surgical simulation platform that our method delivers remarkable improvements over the RL baseline and exhibits comparable performance against action based IL methods, which implies the efficacy and potential of our method for expert demonstration-guided learning scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages,7 figures, 62 conferences"
    },
    {
        "paper id": "2409.02738",
        "abstract url": "https://arxiv.org/abs/2409.02738",
        "title": "SOAR: Simultaneous Exploration and Photographing with Heterogeneous UAVs for Fast Autonomous Reconstruction",
        "rating": "-3",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Unmanned Aerial Vehicles (UAVs) have gained significant popularity in scene reconstruction. This paper presents SOAR, a LiDAR-Visual heterogeneous multi-UAV system specifically designed for fast autonomous reconstruction of complex environments. Our system comprises a LiDAR-equipped explorer with a large field-of-view (FoV), alongside photographers equipped with cameras. To ensure rapid acquisition of the scene's surface geometry, we employ a surface frontier-based exploration strategy for the explorer. As the surface is progressively explored, we identify the uncovered areas and generate viewpoints incrementally. These viewpoints are then assigned to photographers through solving a Consistent Multiple Depot Multiple Traveling Salesman Problem (Consistent-MDMTSP), which optimizes scanning efficiency while ensuring task consistency. Finally, photographers utilize the assigned viewpoints to determine optimal coverage paths for acquiring images. We present extensive benchmarks in the realistic simulator, which validates the performance of SOAR compared with classical and state-of-the-art methods. For more details, please see our project page at https://sysu-star.github.io/SOAR}{sysu-star.github.io/SOAR.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IROS2024. Code: https://github.com/SYSU-STAR/SOAR. Project page: http://sysu-star.com/SOAR/"
    },
    {
        "paper id": "2409.02788",
        "abstract url": "https://arxiv.org/abs/2409.02788",
        "title": "Enhancing 5G Performance: Reducing Service Time and Research Directions for 6G Standards",
        "rating": "-3",
        "keywords": [
            [
                "flight"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "This paper presents several methods for minimizing packet service time in networks using 5G and beyond. We propose leveraging network coding alongside Hybrid Automatic Repeat reQuest (HARQ) to reduce service time as well as optimizing Modulation and Coding Scheme (MCS) selection based on the service time. Our network coding approach includes a method to increase the number of packets in flight, adhering to the current standard of the 16 HARQ process limit, demonstrating that these strategies can enhance throughput and reduce latency. Experimental results show that network coding reduces service times by up to 7% in low SNR regimes, with greater reduction across all SNR as the number of packets in flight increases, suggesting that future 6G standards should consider increasing the number of HARQ processes for better performance.",
        "subjects": [
            "cs.NI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02816",
        "abstract url": "https://arxiv.org/abs/2409.02816",
        "title": "Simple fusion-fission quantifies Israel-Palestine violence and suggests multi-adversary solution",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "survival"
            ]
        ],
        "abstract": "Why humans fight has no easy answer. However, understanding better how humans fight could inform future interventions, hidden shifts and casualty risk. Fusion-fission describes the well-known grouping behavior of fish etc. fighting for survival in the face of strong opponents: they form clusters ('fusion') which provide collective benefits and a cluster scatters when it senses danger ('fission'). Here we show how similar clustering (fusion-fission) of human fighters provides a unified quantitative explanation for complex casualty patterns across decades of Israel-Palestine region violence, as well as the October 7 surprise attack -- and uncovers a hidden post-October 7 shift. State-of-the-art data shows this fighter fusion-fission in action. It also predicts future 'super-shock' attacks that will be more lethal than October 7 and will arrive earlier. It offers a multi-adversary solution. Our results -- which include testable formulae and a plug-and-play simulation -- enable concrete risk assessments of future casualties and policy-making grounded by fighter behavior.",
        "subjects": [
            "physics.soc-ph",
            "cs.CE",
            "math-ph",
            "nlin.AO"
        ],
        "comment": "Comments welcome. Working paper"
    },
    {
        "paper id": "2409.02907",
        "abstract url": "https://arxiv.org/abs/2409.02907",
        "title": "GraphTrials: Visual Proofs of Graph Properties",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "Graph and network visualization supports exploration, analysis and communication of relational data arising in many domains: from biological and social networks, to transportation and powergrid systems. With the arrival of AI-based question-answering tools, issues of trustworthiness and explainability of generated answers motivate a greater role for visualization. In the context of graphs, we see the need for visualizations that can convince a critical audience that an assertion about the graph under analysis is valid. The requirements for such representations that convey precisely one specific graph property are quite different from standard network visualization criteria which optimize general aesthetics and readability. In this paper, we aim to provide a comprehensive introduction to visual proofs of graph properties and a foundation for further research in the area. We present a framework that defines what it means to visually prove a graph property. In the process, we introduce the notion of a visual certificate, that is, a specialized faithful graph visualization that leverages the viewer's perception, in particular, pre-attentive processing (e.g. via pop-out effects), to verify a given assertion about the represented graph. We also discuss the relationships between visual complexity, cognitive load and complexity theory, and propose a classification based on visual proof complexity. Finally, we provide examples of visual certificates for problems in different visual proof complexity classes.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Appears in the Proceedings of the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024)"
    },
    {
        "paper id": "2409.03018",
        "abstract url": "https://arxiv.org/abs/2409.03018",
        "title": "Random sampling of permutations through quantum circuits",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "In this paper, we introduce classical algorithms for random sampling of permutations, drawing inspiration from the Steinhaus-Johnson-Trotter algorithm. Our approach takes a comprehensive view of permutation sampling by expressing them as products of adjacent transpositions. Building on this, we develop a quantum analogue of these classical algorithms using a quantum circuit model for random sampling of permutations for $n$-qubit systems. As an application, we present a quantum algorithm for the two-sample randomization test to assess the difference of means in classical data, utilizing a quantum circuit model. Finally, we propose a nested corona product graph generative model for symmetric groups, which facilitates random sampling of permutations from specific sets of permutations through a quantum circuit model.",
        "subjects": [
            "quant-ph",
            "cs.DM",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03160",
        "abstract url": "https://arxiv.org/abs/2409.03160",
        "title": "Autonomous Drifting Based on Maximal Safety Probability Learning",
        "rating": "-3",
        "keywords": [
            [
                "autonomous driving",
                "trajectory"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "This paper proposes a novel learning-based framework for autonomous driving based on the concept of maximal safety probability. Efficient learning requires rewards that are informative of desirable/undesirable states, but such rewards are challenging to design manually due to the difficulty of differentiating better states among many safe states. On the other hand, learning policies that maximize safety probability does not require laborious reward shaping but is numerically challenging because the algorithms must optimize policies based on binary rewards sparse in time. Here, we show that physics-informed reinforcement learning can efficiently learn this form of maximally safe policy. Unlike existing drift control methods, our approach does not require a specific reference trajectory or complex reward shaping, and can learn safe behaviors only from sparse binary rewards. This is enabled by the use of the physics loss that plays an analogous role to reward shaping. The effectiveness of the proposed approach is demonstrated through lane keeping in a normal cornering scenario and safe drifting in a high-speed racing scenario.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2403.16391"
    },
    {
        "paper id": "2409.03238",
        "abstract url": "https://arxiv.org/abs/2409.03238",
        "title": "Preserving Empirical Probabilities in BERT for Small-sample Clinical Entity Recognition",
        "rating": "-3",
        "keywords": [
            [
                "Clinical"
            ],
            [
                "Named Entity Recognition"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Named Entity Recognition (NER) encounters the challenge of unbalanced labels, where certain entity types are overrepresented while others are underrepresented in real-world datasets. This imbalance can lead to biased models that perform poorly on minority entity classes, impeding accurate and equitable entity recognition. This paper explores the effects of unbalanced entity labels of the BERT-based pre-trained model. We analyze the different mechanisms of loss calculation and loss propagation for the task of token classification on randomized datasets. Then we propose ways to improve the token classification for the highly imbalanced task of clinical entity recognition.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "8 pages, 8 figures"
    },
    {
        "paper id": "2409.02530",
        "abstract url": "https://arxiv.org/abs/2409.02530",
        "title": "Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models",
        "rating": "-3.5",
        "keywords": [
            [
                "medical",
                "clinical"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The estimated Glomerular Filtration Rate (eGFR) is an essential indicator of kidney function in clinical practice. Although traditional equations and Machine Learning (ML) models using clinical and laboratory data can estimate eGFR, accurately predicting future eGFR levels remains a significant challenge for nephrologists and ML researchers. Recent advances demonstrate that Large Language Models (LLMs) and Large Multimodal Models (LMMs) can serve as robust foundation models for diverse applications. This study investigates the potential of LMMs to predict future eGFR levels with a dataset consisting of laboratory and clinical values from 50 patients. By integrating various prompting techniques and ensembles of LMMs, our findings suggest that these models, when combined with precise prompts and visual representations of eGFR trajectories, offer predictive performance comparable to existing ML models. This research extends the application of foundation models and suggests avenues for future studies to harness these models in addressing complex medical forecasting challenges.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "This preprint version includes corrections of typographical errors related to numerical values in Table 2, which were present in the version published at the BDH workshop in MIPR 2024. These corrections do not affect the overall conclusions of the study"
    },
    {
        "paper id": "2409.02779",
        "abstract url": "https://arxiv.org/abs/2409.02779",
        "title": "Governing dual-use technologies: Case studies of international security agreements and lessons for AI governance",
        "rating": "-3.5",
        "keywords": [
            [
                "biosecurity"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "International AI governance agreements and institutions may play an important role in reducing global security risks from advanced AI. To inform the design of such agreements and institutions, we conducted case studies of historical and contemporary international security agreements. We focused specifically on those arrangements around dual-use technologies, examining agreements in nuclear security, chemical weapons, biosecurity, and export controls. For each agreement, we examined four key areas: (a) purpose, (b) core powers, (c) governance structure, and (d) instances of non-compliance. From these case studies, we extracted lessons for the design of international AI agreements and governance institutions. We discuss the importance of robust verification methods, strategies for balancing power between nations, mechanisms for adapting to rapid technological change, approaches to managing trade-offs between transparency and security, incentives for participation, and effective enforcement mechanisms.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02973",
        "abstract url": "https://arxiv.org/abs/2409.02973",
        "title": "SDOoop: Capturing Periodical Patterns and Out-of-phase Anomalies in Streaming Data Analysis",
        "rating": "-3.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "anomaly detection"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Streaming data analysis is increasingly required in applications, e.g., IoT, cybersecurity, robotics, mechatronics or cyber-physical systems. Despite its relevance, it is still an emerging field with open challenges. SDO is a recent anomaly detection method designed to meet requirements of speed, interpretability and intuitive parameterization. In this work, we present SDOoop, which extends the capabilities of SDO's streaming version to retain temporal information of data structures. SDOoop spots contextual anomalies undetectable by traditional algorithms, while enabling the inspection of data geometries, clusters and temporal patterns. We used SDOoop to model real network communications in critical infrastructures and extract patterns that disclose their dynamics. Moreover, we evaluated SDOoop with data from intrusion detection and natural science domains and obtained performances equivalent or superior to state-of-the-art approaches. Our results show the high potential of new model-based methods to analyze and explain streaming data. Since SDOoop operates with constant per-sample space and time complexity, it is ideal for big data, being able to instantly process large volumes of information. SDOoop conforms to next-generation machine learning, which, in addition to accuracy and speed, is expected to provide highly interpretable and informative models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03141",
        "abstract url": "https://arxiv.org/abs/2409.03141",
        "title": "Towards Autonomous Cybersecurity: An Intelligent AutoML Framework for Autonomous Intrusion Detection",
        "rating": "-3.5",
        "keywords": [
            [
                "5G",
                "6G"
            ],
            [
                "Tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The rapid evolution of mobile networks from 5G to 6G has necessitated the development of autonomous network management systems, such as Zero-Touch Networks (ZTNs). However, the increased complexity and automation of these networks have also escalated cybersecurity risks. Existing Intrusion Detection Systems (IDSs) leveraging traditional Machine Learning (ML) techniques have shown effectiveness in mitigating these risks, but they often require extensive manual effort and expert knowledge. To address these challenges, this paper proposes an Automated Machine Learning (AutoML)-based autonomous IDS framework towards achieving autonomous cybersecurity for next-generation networks. To achieve autonomous intrusion detection, the proposed AutoML framework automates all critical procedures of the data analytics pipeline, including data pre-processing, feature engineering, model selection, hyperparameter tuning, and model ensemble. Specifically, it utilizes a Tabular Variational Auto-Encoder (TVAE) method for automated data balancing, tree-based ML models for automated feature selection and base model learning, Bayesian Optimization (BO) for hyperparameter optimization, and a novel Optimized Confidence-based Stacking Ensemble (OCSE) method for automated model ensemble. The proposed AutoML-based IDS was evaluated on two public benchmark network security datasets, CICIDS2017 and 5G-NIDD, and demonstrated improved performance compared to state-of-the-art cybersecurity methods. This research marks a significant step towards fully autonomous cybersecurity in next-generation networks, potentially revolutionizing network security applications.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.NI"
        ],
        "comment": "Accepted to the Workshop on Autonomous Cybersecurity, ACM CCS 2024; Code is available at Github link: https://github.com/Western-OC2-Lab/AutonomousCyber-AutoML-based-Autonomous-Intrusion-Detection-System"
    },
    {
        "paper id": "2409.03231",
        "abstract url": "https://arxiv.org/abs/2409.03231",
        "title": "State-space models are accurate and efficient neural operators for dynamical systems",
        "rating": "-3.5",
        "keywords": [
            [
                "tumor"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-informed machine learning (PIML) has emerged as a promising alternative to classical methods for predicting dynamical systems, offering faster and more generalizable solutions. However, existing models, including recurrent neural networks (RNNs), transformers, and neural operators, face challenges such as long-time integration, long-range dependencies, chaotic dynamics, and extrapolation, to name a few. To this end, this paper introduces state-space models implemented in Mamba for accurate and efficient dynamical system operator learning. Mamba addresses the limitations of existing architectures by dynamically capturing long-range dependencies and enhancing computational efficiency through reparameterization techniques. To extensively test Mamba and compare against another 11 baselines, we introduce several strict extrapolation testbeds that go beyond the standard interpolation benchmarks. We demonstrate Mamba's superior performance in both interpolation and challenging extrapolation tasks. Mamba consistently ranks among the top models while maintaining the lowest computational cost and exceptional extrapolation capabilities. Moreover, we demonstrate the good performance of Mamba for a real-world application in quantitative systems pharmacology for assessing the efficacy of drugs in tumor growth under limited data scenarios. Taken together, our findings highlight Mamba's potential as a powerful tool for advancing scientific machine learning in dynamical systems modeling. (The code will be available at https://github.com/zheyuanhu01/State_Space_Model_Neural_Operator upon acceptance.)",
        "subjects": [
            "cs.LG",
            "math.DS",
            "math.NA",
            "stat.ML"
        ],
        "comment": "34 pages"
    },
    {
        "paper id": "2409.02546",
        "abstract url": "https://arxiv.org/abs/2409.02546",
        "title": "Real-Time Dynamic Scale-Aware Fusion Detection Network: Take Road Damage Detection as an example",
        "rating": "-4",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "6G"
            ],
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unmanned Aerial Vehicle (UAV)-based Road Damage Detection (RDD) is important for daily maintenance and safety in cities, especially in terms of significantly reducing labor costs. However, current UAV-based RDD research is still faces many challenges. For example, the damage with irregular size and direction, the masking of damage by the background, and the difficulty of distinguishing damage from the background significantly affect the ability of UAV to detect road damage in daily inspection. To solve these problems and improve the performance of UAV in real-time road damage detection, we design and propose three corresponding modules: a feature extraction module that flexibly adapts to shape and background; a module that fuses multiscale perception and adapts to shape and background ; an efficient downsampling module. Based on these modules, we designed a multi-scale, adaptive road damage detection model with the ability to automatically remove background interference, called Dynamic Scale-Aware Fusion Detection Model (RT-DSAFDet). Experimental results on the UAV-PDD2023 public dataset show that our model RT-DSAFDet achieves a mAP50 of 54.2%, which is 11.1% higher than that of YOLOv10-m, an efficient variant of the latest real-time object detection model YOLOv10, while the amount of parameters is reduced to 1.8M and FLOPs to 4.6G, with a decreased by 88% and 93%, respectively. Furthermore, on the large generalized object detection public dataset MS COCO2017 also shows the superiority of our model with mAP50-95 is the same as YOLOv9-t, but with 0.5% higher mAP50, 10% less parameters volume, and 40% less FLOPs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02598",
        "abstract url": "https://arxiv.org/abs/2409.02598",
        "title": "SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments",
        "rating": "-4",
        "keywords": [
            [
                "3D",
                "Signed Distance Field",
                "SDF"
            ],
            [
                "navigation"
            ],
            [
                "graph"
            ],
            [
                "Surgical",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Vision-based surgical navigation has received increasing attention due to its non-invasive, cost-effective, and flexible advantages. In particular, a critical element of the vision-based navigation system is tracking surgical instruments. Compared with 2D instrument tracking methods, 3D instrument tracking has broader value in clinical practice, but is also more challenging due to weak texture, occlusion, and lack of Computer-Aided Design (CAD) models for 3D registration. To solve these challenges, we propose the SurgTrack, a two-stage 3D instrument tracking method for CAD-free and robust real-world applications. In the first registration stage, we incorporate an Instrument Signed Distance Field (SDF) modeling the 3D representation of instruments, achieving CAD-freed 3D registration. Due to this, we can obtain the location and orientation of instruments in the 3D space by matching the video stream with the registered SDF model. In the second tracking stage, we devise a posture graph optimization module, leveraging the historical tracking results of the posture memory pool to optimize the tracking results and improve the occlusion robustness. Furthermore, we collect the Instrument3D dataset to comprehensively evaluate the 3D tracking of surgical instruments. The extensive experiments validate the superiority and scalability of our SurgTrack, by outperforming the state-of-the-arts with a remarkable improvement. The code and dataset are available at https://github.com/wenwucode/SurgTrack.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03032",
        "abstract url": "https://arxiv.org/abs/2409.03032",
        "title": "A General Albedo Recovery Approach for Aerial Photogrammetric Images through Inverse Rendering",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "drone"
            ],
            [
                "physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Modeling outdoor scenes for the synthetic 3D environment requires the recovery of reflectance/albedo information from raw images, which is an ill-posed problem due to the complicated unmodeled physics in this process (e.g., indirect lighting, volume scattering, specular reflection). The problem remains unsolved in a practical context. The recovered albedo can facilitate model relighting and shading, which can further enhance the realism of rendered models and the applications of digital twins. Typically, photogrammetric 3D models simply take the source images as texture materials, which inherently embed unwanted lighting artifacts (at the time of capture) into the texture. Therefore, these polluted textures are suboptimal for a synthetic environment to enable realistic rendering. In addition, these embedded environmental lightings further bring challenges to photo-consistencies across different images that cause image-matching uncertainties. This paper presents a general image formation model for albedo recovery from typical aerial photogrammetric images under natural illuminations and derives the inverse model to resolve the albedo information through inverse rendering intrinsic image decomposition. Our approach builds on the fact that both the sun illumination and scene geometry are estimable in aerial photogrammetry, thus they can provide direct inputs for this ill-posed problem. This physics-based approach does not require additional input other than data acquired through the typical drone-based photogrammetric collection and was shown to favorably outperform existing approaches. We also demonstrate that the recovered albedo image can in turn improve typical image processing tasks in photogrammetry such as feature and dense matching, edge, and line extraction.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "ISPRS Journal of Photogrammetry and Remote Sensing"
    },
    {
        "paper id": "2409.03193",
        "abstract url": "https://arxiv.org/abs/2409.03193",
        "title": "Upper-Limb Rehabilitation with a Dual-Mode Individualized Exoskeleton Robot: A Generative-Model-Based Solution",
        "rating": "-4",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ],
            [
                "medical"
            ]
        ],
        "abstract": "Several upper-limb exoskeleton robots have been developed for stroke rehabilitation, but their rather low level of individualized assistance typically limits their effectiveness and practicability. Individualized assistance involves an upper-limb exoskeleton robot continuously assessing feedback from a stroke patient and then meticulously adjusting interaction forces to suit specific conditions and online changes. This paper describes the development of a new upper-limb exoskeleton robot with a novel online generative capability that allows it to provide individualized assistance to support the rehabilitation training of stroke patients. Specifically, the upper-limb exoskeleton robot exploits generative models to customize the fine and fit trajectory for the patient, as medical conditions, responses, and comfort feedback during training generally differ between patients. This generative capability is integrated into the two working modes of the upper-limb exoskeleton robot: an active mirroring mode for patients who retain motor abilities on one side of the body and a passive following mode for patients who lack motor ability on both sides of the body. The performance of the upper-limb exoskeleton robot was illustrated in experiments involving healthy subjects and stroke patients.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02730",
        "abstract url": "https://arxiv.org/abs/2409.02730",
        "title": "Complete and Efficient Covariants for 3D Point Configurations with Application to Learning Molecular Quantum Properties",
        "rating": "-4.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "chemistry"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "When modeling physical properties of molecules with machine learning, it is desirable to incorporate $SO(3)$-covariance. While such models based on low body order features are not complete, we formulate and prove general completeness properties for higher order methods, and show that $6k-5$ of these features are enough for up to $k$ atoms. We also find that the Clebsch--Gordan operations commonly used in these methods can be replaced by matrix multiplications without sacrificing completeness, lowering the scaling from $O(l^6)$ to $O(l^3)$ in the degree of the features. We apply this to quantum chemistry, but the proposed methods are generally applicable for problems involving 3D point configurations.",
        "subjects": [
            "cs.LG",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02980",
        "abstract url": "https://arxiv.org/abs/2409.02980",
        "title": "How DREAMS are made: Emulating Satellite Galaxy and Subhalo Populations with Diffusion Models and Point Clouds",
        "rating": "-4.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Satellite"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The connection between galaxies and their host dark matter (DM) halos is critical to our understanding of cosmology, galaxy formation, and DM physics. To maximize the return of upcoming cosmological surveys, we need an accurate way to model this complex relationship. Many techniques have been developed to model this connection, from Halo Occupation Distribution (HOD) to empirical and semi-analytic models to hydrodynamic. Hydrodynamic simulations can incorporate more detailed astrophysical processes but are computationally expensive; HODs, on the other hand, are computationally cheap but have limited accuracy. In this work, we present NeHOD, a generative framework based on variational diffusion model and Transformer, for painting galaxies/subhalos on top of DM with an accuracy of hydrodynamic simulations but at a computational cost similar to HOD. By modeling galaxies/subhalos as point clouds, instead of binning or voxelization, we can resolve small spatial scales down to the resolution of the simulations. For each halo, NeHOD predicts the positions, velocities, masses, and concentrations of its central and satellite galaxies. We train NeHOD on the TNG-Warm DM suite of the DREAMS project, which consists of 1024 high-resolution zoom-in hydrodynamic simulations of Milky Way-mass halos with varying warm DM mass and astrophysical parameters. We show that our model captures the complex relationships between subhalo properties as a function of the simulation parameters, including the mass functions, stellar-halo mass relations, concentration-mass relations, and spatial clustering. Our method can be used for a large variety of downstream applications, from galaxy clustering to strong lensing studies.",
        "subjects": [
            "astro-ph.GA",
            "astro-ph.CO",
            "cs.LG"
        ],
        "comment": "Submitted to ApJ; 30 + 6 pages; 11 + 4 figures; Comments welcomed"
    },
    {
        "paper id": "2409.02748",
        "abstract url": "https://arxiv.org/abs/2409.02748",
        "title": "Non-Orthogonal Multiple-Access Strategies for Direct-to-Satellite IoT Networks",
        "rating": "-5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "IoT"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Direct-to-Satellite IoT (DtS-IoT) has the potential to support multiple verticals, including agriculture, industry, smart cities, and environmental disaster prevention. This work introduces two novel DtS-IoT schemes using power domain NonOrthogonal Multiple Access (NOMA) in the uplink with either fixed (FTP) or controlled (CTP) transmit power. We consider that the IoT devices use LoRa technology to transmit data packets to the satellite in orbit, equipped with a Successive Interference Cancellation (SIC)-enabled gateway. We also assume the IoT devices are empowered with a predictor of the satellite orbit. Using real geographic location and trajectory data, we evaluate the performance of the average number of successfully decoded transmissions, goodput (bytes/lap), and energy consumption (bytes/Joule) as a function of the number of network devices. Numerical results show the trade-off between goodput and energy efficiency for both proposed schemes. Comparing FTP and CTP with regular ALOHA for 100 (600) devices, we find goodput improvements of 65% (29%) and 52% (101%), respectively. Notably, CTP effectively leverages transmission opportunities as the network size increases, outperforming the other strategies. Moreover, CTP shows the best performance in energy efficiency compared to FTP and ALOHA.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "9 pages, 8 figures"
    },
    {
        "paper id": "2409.02447",
        "abstract url": "https://arxiv.org/abs/2409.02447",
        "title": "FDA-MIMO-Based Integrated Sensing and Communication System with Complex Coefficients Index Modulation for Multi-Target Sensing",
        "rating": "-10",
        "keywords": [],
        "abstract": "The echo signals of frequency diverse array multiple-input multiple-output (FDA-MIMO) feature angle-range coupling, enabling simultaneous discrimination and estimation of multiple targets at different locations. In light of this, based on FDA-MIMO, this paper explores an sensing-centric integrated sensing and communication (ISAC) system for multi-target sensing. On the transmitter side, the complex coefficients index modulation (CCIM) scheme is designed, which carries extra bits by selecting complex coefficients from the coefficient vector. At the sensing receiver, we propose the FDA-MIMO-based spatial spectrum multi-target estimation (SSMTE) method, which first jointly estimates the angle and distance of targets and then estimates the velocities. To reduce the sensing computational complexity, the low-complexity spatial spectrum estimation (LCSSE) algorithm is proposed. LCSSE reduces the complexity without degrading the sensing performance by converting the joint angle-range search into two one-dimensional searches. To address the range ambiguity caused by frequency offset, a frequency offset design criterion (FODC) is proposed. It designs the integer and fractional components of the frequency offset to ensure the ambiguity distance exceeds the maximum sensing range, thereby alleviating parameters pairing errors. Moreover, the closed-form expressions for the bit error rate (BER) tight upper bound and the Cram\u00e9r-Rao bound (CRB) are derived. Simulation results show that the proposed system excels in multi-target sensing and communications.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02454",
        "abstract url": "https://arxiv.org/abs/2409.02454",
        "title": "Multi-Sources Fusion Learning for Multi-Points NLOS Localization in OFDM System",
        "rating": "-10",
        "keywords": [],
        "abstract": "Accurate localization of mobile terminals is a pivotal aspect of integrated sensing and communication systems. Traditional fingerprint-based localization methods, which infer coordinates from channel information within pre-set rectangular areas, often face challenges due to the heterogeneous distribution of fingerprints inherent in non-line-of-sight (NLOS) scenarios, particularly within orthogonal frequency division multiplexing systems. To overcome this limitation, we develop a novel multi-sources information fusion learning framework referred to as the Autosync Multi-Domains NLOS Localization (AMDNLoc). Specifically, AMDNLoc employs a two-stage matched filter fused with a target tracking algorithm and iterative centroid-based clustering to automatically and irregularly segment NLOS regions, ensuring uniform distribution within channel state information across frequency, power, and time-delay domains. Additionally, the framework utilizes a segment-specific linear classifier array, coupled with deep residual network-based feature extraction and fusion, to establish the correlation function between fingerprint features and coordinates within these regions. Simulation results reveal that AMDNLoc achieves an impressive NLOS localization accuracy of 1.46 meters on typical wireless artificial intelligence research datasets and demonstrates significant improvements in interpretability, adaptability, and scalability.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "12 pages, 14 figures, accepted by IEEE Journal of Selected Topics in Signal Processing (JSTSP). arXiv admin note: substantial text overlap with arXiv:2401.12538"
    },
    {
        "paper id": "2409.02464",
        "abstract url": "https://arxiv.org/abs/2409.02464",
        "title": "Nonlinear Precoding in the RIS-Aided MIMO Broadcast Channel",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose to use Tomlinson-Harashima Precoding (THP) for the reconfigurable intelligent surface (RIS)-aided multiple-input multiple-output (MIMO) broadcast channel where we assume a line of sight (LOS) connection between the base station (BS) and the RIS. In this scenario, nonlinear precoding, like THP or dirty paper coding (DPC), has certain advantages compared to linear precoding as it is more robust in case the BS-RIS channel is not orthogonal to the direct channel. Additionally, THP and DPC allow a simple phase shift optimization which is in strong contrast to linear precoding for which the solution is quite intricate. Besides being difficult to optimize, it can be shown that linear precoding has fundamental limitations for statistical and random phase shifts which do not hold for nonlinear precoding. Moreover, we show that the advantages of THP/DPC are especially pronounced for discrete phase shifts.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02473",
        "abstract url": "https://arxiv.org/abs/2409.02473",
        "title": "A Variable Power Surface Error Function backstepping based Dynamic Surface Control of Non-Lower Triangular Nonlinear Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "A control design for error reduction in the tracking control for a class of non-lower triangular nonlinear systems is presented by combining techniques of Variable Power Surface Error Function (VPSEF), backstepping, and dynamic surface control. At each step of design, a surface error is obtained, and based on its magnitude, the VPSEF technique decides the surface error to be used. Thus, the backstepping-based virtual and actual control law is designed to stabilize the corresponding subsystem. To address the issue of circular structure, a first-order low-pass filter is used to handle the virtual control signal at each intermediate stage of the recursive design. The stability analysis of the closed-loop system demonstrates that all signals indicate semi-global uniform ultimate boundedness. Moreover, by using the switching strategy of the control input using the VPSEF technique suitably, it is possible to ensure that the steady-state tracking error converges to a neighborhood of zero with an arbitrarily very small size. The effectiveness of the proposed concept has been verified using two different simulated demonstrations.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02478",
        "abstract url": "https://arxiv.org/abs/2409.02478",
        "title": "Test-time data augmentation: improving predictions of recurrent neural network models of composites",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recurrent Neural Networks (RNNs) have emerged as an interesting alternative to conventional material modeling approaches, particularly for nonlinear path dependent materials. Remarkable computational enhancements are obtained using RNNs compared to classical approaches such as the computational homogenization method. However, RNN predictive errors accumulate, leading to issues when predicting temporal dependencies in time series data. This study aims to address and mitigate inaccuracies induced by neural networks in predicting path dependent plastic deformations of short fiber reinforced composite materials. We propose using an approach of Test Time data Augmentation (TTA), which, to the best of the authors knowledge, is previously untested in the context of RNNs. The method is based on augmenting the input test data using random rotations and subsequently rotating back the predicted output signal. By aggregating the back rotated predictions, a more accurate prediction compared to individual predictions is obtained. Our analysis also demonstrates improved shape consistency between the prediction and the target pseudo time signal. Additionally, this method provides an uncertainty estimation which correlates with the absolute prediction error. The TTA approach is reproducible with different randomly generated data augmentations, establishing a promising framework for optimizing predictions of deep learning models. We believe there are broader implications of the proposed method for various fields reliant on accurate predictive data driven modeling.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02528",
        "abstract url": "https://arxiv.org/abs/2409.02528",
        "title": "A design of magnetic tunnel junctions for the deployment of neuromorphic hardware for edge computing",
        "rating": "-10",
        "keywords": [],
        "abstract": "The electrically readable complex dynamics of robust and scalable magnetic tunnel junctions (MTJs) offer promising opportunities for advancing neuromorphic computing. In this work, we present an MTJ design with a free layer and two polarizers capable of computing the sigmoidal activation function and its gradient at the device level. This design enables both feedforward and backpropagation computations within a single device, extending neuromorphic computing frameworks previously explored in the literature by introducing the ability to perform backpropagation directly in hardware. Our algorithm implementation reveals two key findings: (i) the small discrepancies between the MTJ-generated curves and the exact software-generated curves have a negligible impact on the performance of the backpropagation algorithm, (ii) the device implementation is highly robust to inter-device variation and noise, and (iii) the proposed method effectively supports transfer learning and knowledge distillation. To demonstrate this, we evaluated the performance of an edge computing network using weights from a software-trained model implemented with our MTJ design. The results show a minimal loss of accuracy of only 0.1% for the Fashion MNIST dataset and 2% for the CIFAR-100 dataset compared to the original software implementation. These results highlight the potential of our MTJ design for compact, hardware-based neural networks in edge computing applications, particularly for transfer learning.",
        "subjects": [
            "physics.app-ph",
            "cs.ET"
        ],
        "comment": "18 pages, 5 figures"
    },
    {
        "paper id": "2409.02592",
        "abstract url": "https://arxiv.org/abs/2409.02592",
        "title": "Exploring Citation Diversity in Scholarly Literature: An Entropy-Based Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study explores global citation diversity,examining its various patterns across countries and academic disciplines.We analyzed citation distributions in top institutes worldwide,revealing that the higher citation end of the distribution follow Power law or Pareto law pattern and the Pareto law's scaling exponent changes with the number of institutes considered.An entropy based novel citation inequality measure has been introduced, enhancing the precision of our analysis. Our findings show that countries with small and large economies often group similarly based on citation diversity, with shifting the groupings as the number of institutes considered changes.Moreover,we analyzed citation diversity among award-winning scientists across six scientific disciplines,finding significant variations.We also explored the evolution of citation diversity over the past century across multiple fields.A gender-based study in various disciplines highlights citation inequalities among male and female scientists.Our innovative citation diversity measure stands out as a vital tool for evaluating citation inequality,providing insights beyond what traditional citation counts can offer.This thorough analysis deepens our understanding of global scientific contributions and promotes a more equitable view of academic accomplishments.",
        "subjects": [
            "physics.soc-ph",
            "cs.DL"
        ],
        "comment": "21 pages, 18 figures, 13 tables"
    },
    {
        "paper id": "2409.02595",
        "abstract url": "https://arxiv.org/abs/2409.02595",
        "title": "Computation and Concurrency",
        "rating": "-10",
        "keywords": [],
        "abstract": "We try to clarify the relationship between computation and concurrency. Base on the so-called truly concurrent automata, we introduce communication and more operators, and establish the algebras modulo language equivalence and bisimilarity.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2304.04406"
    },
    {
        "paper id": "2409.02603",
        "abstract url": "https://arxiv.org/abs/2409.02603",
        "title": "Formalising inductive and coinductive containers",
        "rating": "-10",
        "keywords": [],
        "abstract": "Containers capture the concept of strictly positive data types in programming. The original development of containers is done in the internal language of Locally Cartesian Closed Categories (LCCCs) with disjoint coproducts and W-types. Although it is claimed that these developments can also be interpreted in extensional Martin-L\u00f6f type theory, this interpretation is not made explicit. Moreover, as a result of extensionality, these developments freely assume Uniqueness of Identity Proofs (UIP), so it is not clear whether this is a necessary condition. In this paper, we present a formalisation of the result that `containers preserve least and greatest fixed points' in Cubical Agda, thereby giving a formulation in intensional type theory, and showing that UIP is not necessary. Our main incentive for using Cubical Agda is that its path type restores the equivalence between bisimulation and coinductive equality. Thus, besides developing container theory in a more general setting, we also demonstrate the usefulness of Cubical Agda's path type to coinductive proofs.",
        "subjects": [
            "cs.LO",
            "math.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02609",
        "abstract url": "https://arxiv.org/abs/2409.02609",
        "title": "Proportionality for Constrained Public Decisions",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study situations where a group of voters need to take a collective decision over a number of public issues, with the goal of getting a result that reflects the voters' opinions in a proportional manner. Our focus is on interconnected public decisions, where the decision on one or more issues has repercussions on the acceptance or rejection of other public issues in the agenda. We show that the adaptations of classical justified-representation axioms to this enriched setting are always satisfiable only for restricted classes of public agendas. However, the use of suitably adapted well-known decision rules on a class of quite expressive constraints, yields proportionality guarantees that match these justified-representation properties in an approximate sense. We also identify another path to achieving proportionality via an adaptation of the notion of priceability.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02616",
        "abstract url": "https://arxiv.org/abs/2409.02616",
        "title": "Group Information Geometry Approach for Ultra-Massive MIMO Signal Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a group information geometry approach (GIGA) for ultra-massive multiple-input multiple-output (MIMO) signal detection. The signal detection task is framed as computing the approximate marginals of the a posteriori distribution of the transmitted data symbols of all users. With the approximate marginals, we perform the maximization of the {\\textsl{a posteriori}} marginals (MPM) detection to recover the symbol of each user. Based on the information geometry theory and the grouping of the components of the received signal, three types of manifolds are constructed and the approximate a posteriori marginals are obtained through m-projections. The Berry-Esseen theorem is introduced to offer an approximate calculation of the m-projection, while its direct calculation is exponentially complex. In most cases, more groups, less complexity of GIGA. However, when the number of groups exceeds a certain threshold, the complexity of GIGA starts to increase. Simulation results confirm that the proposed GIGA achieves better bit error rate (BER) performance within a small number of iterations, which demonstrates that it can serve as an efficient detection method in ultra-massive MIMO systems.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02620",
        "abstract url": "https://arxiv.org/abs/2409.02620",
        "title": "A Software Visualization Approach for Multiple Visual Output Devices",
        "rating": "-10",
        "keywords": [],
        "abstract": "As software systems grow, environments that not only facilitate program comprehension through software visualization but also enable collaborative exploration of software systems become increasingly important. Most approaches to software visualization focus on a single monitor as a visual output device, which offers limited immersion and lacks in potential for collaboration. More recent approaches address augmented and virtual reality environments to increase immersion and enable collaboration to facilitate program comprehension. We present a novel approach to software visualization with software cities that fills a gap between existing approaches by using multiple displays or projectors. Thereby, an increase in screen real estate and new use case scenarios for co-located environments are enabled. Our web-based live trace visualization tool ExplorViz is extended with a service to synchronize the visualization across multiple browser instances. Multiple browser instances can then extend or complement each other's views with respect to a given configuration. The ARENA2, a spatially immersive visualization environment with five projectors, is used to showcase our approach. A preliminary study indicates that this environment can be useful for collaborative exploration of software cities. This publication is accompanied by a video. In addition, our implementation is open source and we invite other researchers to explore and adapt it for their use cases. Video URL: https://youtu.be/OiutBn3zIl8",
        "subjects": [
            "cs.SE"
        ],
        "comment": "submitted to VISSOFT 2024, see https://vissoft.info/2024/program"
    },
    {
        "paper id": "2409.02635",
        "abstract url": "https://arxiv.org/abs/2409.02635",
        "title": "Modelling, Design Optimization and Prototype development of Knee Exoskeleton",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study focuses on enhancing the design of an existing knee exoskeleton by addressing limitations in the range of motion (ROM) during Sit-to-Stand (STS) motions. While current knee exoskeletons emphasize toughness and rehabilitation, their closed-loop mechanisms hinder optimal ROM, which is crucial for effective rehabilitation. This research aims to optimize the exoskeleton design to achieve the necessary ROM, improving its functionality in rehabilitation. This can be achieved by utilizing kinematic modeling and formulation, the existing design was represented in the non-linear and non-convex mathematical functions. Optimization techniques, considering constraints based on human leg measurements, were applied to determine the best dimensions for the exoskeleton. This resulted in a significant increase in ROM compared to existing models. A MATLAB program was developed to compare the ROM of the optimized exoskeleton with the original design. To validate the practicality of the optimized design, analysis was conducted using a mannequin with average human dimensions, followed by constructing a cardboard dummy model to confirm simulation results. The STS motion of an average human was captured using a camera and TRACKER software, and the motion was compared with that of the dummy model to identify any misalignments between the human and exoskeleton knee joints. Furthermore, a prototype of the knee joint exoskeleton is being developed to further investigate misalignments and improve the design. Future work includes the use of EMG sensors for more detailed analysis and better results.",
        "subjects": [
            "cs.RO",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02636",
        "abstract url": "https://arxiv.org/abs/2409.02636",
        "title": "Mamba as a motion encoder for robotic imitation learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent advancements in imitation learning, particularly with the integration of LLM techniques, are set to significantly improve robots' dexterity and adaptability. In this study, we propose using Mamba, a state-of-the-art architecture with potential applications in LLMs, for robotic imitation learning, highlighting its ability to function as an encoder that effectively captures contextual information. By reducing the dimensionality of the state space, Mamba operates similarly to an autoencoder. It effectively compresses the sequential information into state variables while preserving the essential temporal dynamics necessary for accurate motion prediction. Experimental results in tasks such as cup placing and case loading demonstrate that despite exhibiting higher estimation errors, Mamba achieves superior success rates compared to Transformers in practical task execution. This performance is attributed to Mamba's structure, which encompasses the state space model. Additionally, the study investigates Mamba's capacity to serve as a real-time motion generator with a limited amount of training data.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "7 pages, 7 figures"
    },
    {
        "paper id": "2409.02640",
        "abstract url": "https://arxiv.org/abs/2409.02640",
        "title": "Linear Convergence in Hilbert's Projective Metric for Computing Augustin Information and a R\u00e9nyi Information Measure",
        "rating": "-10",
        "keywords": [],
        "abstract": "Consider the problems of computing the Augustin information and a R\u00e9nyi information measure of statistical independence, previously explored by Lapidoth and Pfister (\\textit{IEEE Information Theory Workshop}, 2018) and Tomamichel and Hayashi (\\textit{IEEE Trans. Inf. Theory}, 64(2):1064--1082, 2018). Both quantities are defined as solutions to optimization problems and lack closed-form expressions. This paper analyzes two iterative algorithms: Augustin's fixed-point iteration for computing the Augustin information, and the algorithm by Kamatsuka et al. (arXiv:2404.10950) for the R\u00e9nyi information measure. Previously, it was only known that these algorithms converge asymptotically. We establish the linear convergence of Augustin's algorithm for the Augustin information of order $\u03b1\\in (1/2, 1) \\cup (1, 3/2)$ and Kamatsuka et al.'s algorithm for the R\u00e9nyi information measure of order $\u03b1\\in [1/2, 1) \\cup (1, \\infty)$, using Hilbert's projective metric.",
        "subjects": [
            "math.OC",
            "cs.IT"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2409.02663",
        "abstract url": "https://arxiv.org/abs/2409.02663",
        "title": "Generalized Individual Q-learning for Polymatrix Games with Partial Observations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper addresses the challenge of limited observations in non-cooperative multi-agent systems where agents can have partial access to other agents' actions. We present the generalized individual Q-learning dynamics that combine belief-based and payoff-based learning for the networked interconnections of more than two self-interested agents. This approach leverages access to opponents' actions whenever possible, demonstrably achieving a faster (guaranteed) convergence to quantal response equilibrium in multi-agent zero-sum and potential polymatrix games. Notably, the dynamics reduce to the well-studied smoothed fictitious play and individual Q-learning under full and no access to opponent actions, respectively. We further quantify the improvement in convergence rate due to observing opponents' actions through numerical simulations.",
        "subjects": [
            "cs.GT",
            "eess.SY"
        ],
        "comment": "Extended version (including proofs of Propositions 1 and 2) of the paper: A. S. Donmez and M. O. Sayin, \"Generalized individual Q-learning for polymatrix games with partial observations\", to appear in the Proceedings of the 63rd IEEE Conference on Decision and Control, 2024"
    },
    {
        "paper id": "2409.02706",
        "abstract url": "https://arxiv.org/abs/2409.02706",
        "title": "Beyond Nash Equilibrium: Achieving Bayesian Perfect Equilibrium with Belief Update Fictitious Play",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the domain of machine learning and game theory, the quest for Nash Equilibrium (NE) in extensive-form games with incomplete information is challenging yet crucial for enhancing AI's decision-making support under varied scenarios. Traditional Counterfactual Regret Minimization (CFR) techniques excel in navigating towards NE, focusing on scenarios where opponents deploy optimal strategies. However, the essence of machine learning in strategic game play extends beyond reacting to optimal moves; it encompasses aiding human decision-making in all circumstances. This includes not only crafting responses to optimal strategies but also recovering from suboptimal decisions and capitalizing on opponents' errors. Herein lies the significance of transitioning from NE to Bayesian Perfect Equilibrium (BPE), which accounts for every possible condition, including the irrationality of opponents. To bridge this gap, we propose Belief Update Fictitious Play (BUFP), which innovatively blends fictitious play with belief to target BPE, a more comprehensive equilibrium concept than NE. Specifically, through adjusting iteration stepsizes, BUFP allows for strategic convergence to both NE and BPE. For instance, in our experiments, BUFP(EF) leverages the stepsize of Extensive Form Fictitious Play (EFFP) to achieve BPE, outperforming traditional CFR by securing a 48.53\\% increase in benefits in scenarios characterized by dominated strategies.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02757",
        "abstract url": "https://arxiv.org/abs/2409.02757",
        "title": "V-Words, Lyndon Words and Galois Words",
        "rating": "-10",
        "keywords": [],
        "abstract": "We say that a family $\\mathcal{W}$ of strings over $\u03a3^+$ forms a Unique Maximal Factorization Family (UMFF) if and only if every $w \\in \\mathcal{W}$ has a unique maximal factorization. Further, an UMFF $\\mathcal{W}$ is called a circ-UMFF whenever it contains exactly one rotation of every primitive string $x \\in \u03a3^+$. $V$-order is a non-lexicographical total ordering on strings that determines a circ-UMFF. In this paper we propose a generalization of circ-UMFF called the substring circ-UMFF and extend combinatorial research on $V$-order by investigating connections to Lyndon words. Then we extend these concepts to any total order. Applications of this research arise in efficient text indexing, compression, and search problems.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "30 pages"
    },
    {
        "paper id": "2409.02777",
        "abstract url": "https://arxiv.org/abs/2409.02777",
        "title": "Designing Fair Systems for Consumers to Exploit Personalized Pricing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many online marketplaces personalize prices based on consumer attributes. Since these prices are private, consumers will not realize if they spend more on a good than the lowest possible price, and cannot easily take action to get better prices. In this paper we introduce a system that takes advantage of personalized pricing so consumers can profit while improving fairness. Our system matches consumers for trading; the lower-paying consumer buys the good for the higher-paying consumer for some fee. We explore various modeling choices and fairness targets to determine which schema will leave consumers best off, while also earning revenue for the system itself. We show that when consumers individually negotiate the transaction price, they are able to achieve the most fair outcomes. Conversely, when transaction prices are centrally set, consumers are often unwilling to transact. Minimizing the average price paid by an individual or group is most profitable for the system, while achieving a $67\\%$ reduction in prices. We see that a high dispersion (or range) of original prices is necessary for our system to be viable. Higher dispersion can actually lead to increased consumer welfare, and act as a check against extreme personalization. Our results provide theoretical evidence that such a system could improve fairness for consumers while sustaining itself financially.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02823",
        "abstract url": "https://arxiv.org/abs/2409.02823",
        "title": "Design Contradictions: Help or Hindrance?",
        "rating": "-10",
        "keywords": [],
        "abstract": "The need for innovative ideas in data visualisation drives us to explore new creative approaches. Combining two or more creative words, particularly those that contradict each other, can positively impact the creative process, sparking novel ideas and designs. As we move towards AI-driven design, an open question arises: do these design contradictions work positively with AI tools? Currently, the answer is no. AI systems, like large language models (LLMs), rely on algorithms that engender similarity, whereas creativity often requires divergence and novelty. This poster initiates a conversation on how to drive AI systems to be more creative and generate new ideas. This research invites us to reconsider traditional design methods and explore new approaches in an AI-driven world. Can we apply the same techniques used in traditional design, like the double diamond model, or do we need new methods for design engineering? How can we quickly design visualisations and craft new ideas with generative AI? This paper seeks to start this critical conversation and offers practical insights into the potential of AI in driving creativity in data visualisation.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02830",
        "abstract url": "https://arxiv.org/abs/2409.02830",
        "title": "Towards a Scalable and Efficient PGAS-based Distributed OpenMP",
        "rating": "-10",
        "keywords": [],
        "abstract": "MPI+X has been the de facto standard for distributed memory parallel programming. It is widely used primarily as an explicit two-sided communication model, which often leads to complex and error-prone code. Alternatively, PGAS model utilizes efficient one-sided communication and more intuitive communication primitives. In this paper, we present a novel approach that integrates PGAS concepts into the OpenMP programming model, leveraging the LLVM compiler infrastructure and the GASNet-EX communication library. Our model addresses the complexity associated with traditional MPI+OpenMP programming models while ensuring excellent performance and scalability. We evaluate our approach using a set of micro-benchmarks and application kernels on two distinct platforms: Ookami from Stony Brook University and NERSC Perlmutter. The results demonstrate that DiOMP achieves superior bandwidth and lower latency compared to MPI+OpenMP, up to 25% higher bandwidth and down to 45% on latency. DiOMP offers a promising alternative to the traditional MPI+OpenMP hybrid programming model, towards providing a more productive and efficient way to develop high-performance parallel applications for distributed memory systems.",
        "subjects": [
            "cs.DC",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02852",
        "abstract url": "https://arxiv.org/abs/2409.02852",
        "title": "Key Compression Limits for $k$-Minimum Value Sketches",
        "rating": "-10",
        "keywords": [],
        "abstract": "The $k$-Minimum Values (\\kmv) data sketch algorithm stores the $k$ least hash keys generated by hashing the items in a dataset. We show that compression based on ordering the keys and encoding successive differences can offer $O(\\log n)$ bits per key in expected storage savings, where $n$ is the number of unique values in the data set. We also show that $O(\\log n)$ expected bits saved per key is optimal for any form of compression for the $k$ least of $n$ random values -- that the encoding method is near-optimal among all methods to encode a \\kmv sketch. We present a practical method to perform that compression, show that it is computationally efficient, and demonstrate that its average savings in practice is within about five percent of the theoretical minimum based on entropy. We verify that our method outperforms off-the-shelf compression methods, and we demonstrate that it is practical, using real and synthetic data.",
        "subjects": [
            "cs.DS",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.02858",
        "abstract url": "https://arxiv.org/abs/2409.02858",
        "title": "Revisiting ILP Models for Exact Crossing Minimization in Storyline Drawings",
        "rating": "-10",
        "keywords": [],
        "abstract": "Storyline drawings are a popular visualization of interactions of a set of characters over time, e.g., to show participants of scenes in a book or movie. Characters are represented as $x$-monotone curves that converge vertically for interactions and diverge otherwise. Combinatorially, the task of computing storyline drawings reduces to finding a sequence of permutations of the character curves for the different time points, with the primary objective being crossing minimization of the induced character trajectories. In this paper, we revisit exact integer linear programming (ILP) approaches for this NP-hard problem. By enriching previous formulations with additional problem-specific insights and new heuristics, we obtain exact solutions for an extended new benchmark set of larger and more complex instances than had been used before. Our experiments show that our enriched formulations lead to better performing algorithms when compared to state-of-the-art modelling techniques. In particular, our best algorithms are on average 2.6-3.2 times faster than the state-of-the-art and succeed in solving complex instances that could not be solved before within the given time limit. Further, we show in an ablation study that our enrichment components contribute considerably to the performance of the new ILP formulation.",
        "subjects": [
            "cs.DS",
            "cs.CG"
        ],
        "comment": "28 pages, 7 figures"
    },
    {
        "paper id": "2409.02863",
        "abstract url": "https://arxiv.org/abs/2409.02863",
        "title": "CONClave -- Secure and Robust Cooperative Perception for CAVs Using Authenticated Consensus and Trust Scoring",
        "rating": "-10",
        "keywords": [],
        "abstract": "Connected Autonomous Vehicles have great potential to improve automobile safety and traffic flow, especially in cooperative applications where perception data is shared between vehicles. However, this cooperation must be secured from malicious intent and unintentional errors that could cause accidents. Previous works typically address singular security or reliability issues for cooperative driving in specific scenarios rather than the set of errors together. In this paper, we propose CONClave, a tightly coupled authentication, consensus, and trust scoring mechanism that provides comprehensive security and reliability for cooperative perception in autonomous vehicles. CONClave benefits from the pipelined nature of the steps such that faults can be detected significantly faster and with less compute. Overall, CONClave shows huge promise in preventing security flaws, detecting even relatively minor sensing faults, and increasing the robustness and accuracy of cooperative perception in CAVs while adding minimal overhead.",
        "subjects": [
            "cs.RO",
            "cs.CR",
            "cs.MA"
        ],
        "comment": "6 pages, 6 figures, Design Automation Conference June 2024"
    },
    {
        "paper id": "2409.02905",
        "abstract url": "https://arxiv.org/abs/2409.02905",
        "title": "State Machine Mutation-based Testing Framework for Wireless Communication Protocols",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes Proteus, a protocol state machine, property-guided, and budget-aware automated testing approach for discovering logical vulnerabilities in wireless protocol implementations. Proteus maintains its budget awareness by generating test cases (i.e., each being a sequence of protocol messages) that are not only meaningful (i.e., the test case mostly follows the desirable protocol flow except for some controlled deviations) but also have a high probability of violating the desirable properties. To demonstrate its effectiveness, we evaluated Proteus in two different protocol implementations, namely 4G LTE and BLE, across 23 consumer devices (11 for 4G LTE and 12 for BLE). Proteus discovered 26 unique vulnerabilities, including 113 instances. Affected vendors have positively acknowledged 12 vulnerabilities through 5 CVEs.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted to ACM CCS 2024"
    },
    {
        "paper id": "2409.02918",
        "abstract url": "https://arxiv.org/abs/2409.02918",
        "title": "SpecMon: Modular Black-Box Runtime Monitoring of Security Protocols",
        "rating": "-10",
        "keywords": [],
        "abstract": "There exists a verification gap between formal protocol specifications and their actual implementations, which this work aims to bridge via monitoring for compliance to the formal specification. We instrument the networking and cryptographic library the application uses to obtain a stream of events. This is possible even without source code access. We then use an efficient algorithm to match these observations to traces that are valid in the specification model. In contrast to prior work, our algorithm can handle non-determinism and thus, multiple sessions. It also achieves a low overhead, which we demonstrate on the WireGuard reference implementation and a case study from prior work. We find that the reference Tamarin model for WireGuard can be used with little change: We only need to specify wire formats and correct some small inaccuracies that we discovered while conducting the case study. We also provide a soundness result for our algorithm that ensures it accepts only event streams that are valid according to the specification model.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "21 pages, Full version of the corresponding ACM CCS '24 paper"
    },
    {
        "paper id": "2409.02968",
        "abstract url": "https://arxiv.org/abs/2409.02968",
        "title": "A Comprehensive Survey of Blockchain Scalability: Shaping Inner-Chain and Inter-Chain Perspectives",
        "rating": "-10",
        "keywords": [],
        "abstract": "Blockchain is widely applied in logistics, finance, and agriculture. As single blockchain users grow, scalability becomes crucial. However, existing works lack a comprehensive summary of blockchain scalability. They focus on single chains or cross-chain technologies. This survey summarizes scalability across the physical and logical layers, as well as inner-chain, inter-chain, and technology dimensions. The physical layer covers data and protocols, while the logical layer represents blockchain architecture. Each component is analyzed from inner-chain and inter-chain perspectives, considering technological factors. The aim is to enhance researchers' understanding of blockchain's architecture, data, and protocols to advance scalability research.",
        "subjects": [
            "cs.DB",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03013",
        "abstract url": "https://arxiv.org/abs/2409.03013",
        "title": "Angular Spread Statistics for 6.75 GHz FR1(C) and 16.95 GHz FR3 Mid-Band Frequencies in an Indoor Hotspot Environment",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present detailed multipath propagation spatial statistics for next-generation wireless systems operating at lower and upper mid-band frequencies spanning 6--24 GHz. The large-scale spatial characteristics of the wireless channel include Azimuth angular Spread of Departure (ASD) and Zenith angular Spread of Departure (ZSD) of multipath components (MPC) from a transmitter and the Azimuth angular Spread of Arrival (ASA) and Zenith angular Spread of Arrival (ZSA) at a receiver. The angular statistics calculated from measurements were compared with industry-standard 3GPP models, and ASD and ASA values were found to be in close agreement at both 6.75 GHz and 16.95 GHz. Measured LOS ASD was found larger than 3GPP ASD indicating more diverse MPC departure directions in the azimuth. ZSA and ZSD were observed smaller than the 3GPP modeling results as most multipath arrivals and departures during measurements were recorded at the boresight antenna elevation. The wide angular spreads indicate a multipath-rich spatial propagation at 6.75 GHz and 16.95 GHz, showing greater promise for the implementation of MIMO beamforming systems in the mid-band spectrum.",
        "subjects": [
            "eess.SP",
            "eess.SY"
        ],
        "comment": "6 pages, 3 figures, 1 table, IEEE Wireless Communications and Networking Conference"
    },
    {
        "paper id": "2409.03020",
        "abstract url": "https://arxiv.org/abs/2409.03020",
        "title": "Online Scheduling via Gradient Descent for Weighted Flow Time Minimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we explore how a natural generalization of Shortest Remaining Processing Time (SRPT) can be a powerful \\emph{meta-algorithm} for online scheduling. The meta-algorithm processes jobs to maximally reduce the objective of the corresponding offline scheduling problem of the remaining jobs: minimizing the total weighted completion time of them (the residual optimum). We show that it achieves scalability for minimizing total weighted flow time when the residual optimum exhibits \\emph{supermodularity}. Scalability here means it is $O(1)$-competitive with an arbitrarily small speed augmentation advantage over the adversary, representing the best possible outcome achievable for various scheduling problems. Thanks to this finding, our approach does not require the residual optimum to have a closed mathematical form. Consequently, we can obtain the schedule by solving a linear program, which makes our approach readily applicable to a rich body of applications. Furthermore, by establishing a novel connection to \\emph{substitute valuations in Walrasian markets}, we show how to achieve supermodularity, thereby obtaining scalable algorithms for various scheduling problems, such as matroid scheduling, generalized network flow, and generalized arbitrary speed-up curves, etc., and this is the \\emph{first} non-trivial or scalable algorithm for many of them.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03028",
        "abstract url": "https://arxiv.org/abs/2409.03028",
        "title": "Rigid-Body Attitude Control on $\\mathsf{SO(3)}$ using Nonlinear Dynamic Inversion",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a cascaded control architecture, based on nonlinear dynamic inversion (NDI), for rigid body attitude control. The proposed controller works directly with the rotation matrix parameterization, that is, with elements of the Special Orthogonal Group $\\mathsf{SO(3)}$, and avoids problems related to singularities and non-uniqueness which affect other commonly used attitude representations such as Euler angles, unit quaternions, modified Rodrigues parameters, etc. The proposed NDI-based controller is capable of imposing desired linear dynamics of any order for the outer attitude loop and the inner rate loop, and gives control designers the flexibility to choose higher-order dynamic compensators in both loops. In addition, sufficient conditions are presented in the form of linear matrix inequalities (LMIs) which ensure that the outer loop controller renders the attitude loop almost globally asymptotically stable (AGAS) and the rate loop globally asymptotically stable (GAS). Furthermore, the overall cascaded control architecture is shown to be AGAS in the case of attitude error regulation. Lastly, the proposed scheme is compared with an Euler angles-based NDI scheme from literature for a tracking problem involving agile maneuvering of a multicopter in a high-fidelity nonlinear simulation.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "7 pages, 6 figures, accepted in IEEE Conference on Decision and Control (CDC), 2024"
    },
    {
        "paper id": "2409.03029",
        "abstract url": "https://arxiv.org/abs/2409.03029",
        "title": "GreenWhisk: Emission-Aware Computing for Serverless Platform",
        "rating": "-10",
        "keywords": [],
        "abstract": "Serverless computing is an emerging cloud computing abstraction wherein the cloud platform transparently manages all resources, including explicitly provisioning resources and geographical load balancing when the demand for service spikes. Users provide code as functions, and the cloud platform runs these functions handling all aspects of function execution. While prior work has primarily focused on optimizing performance, this paper focuses on reducing the carbon footprint of these systems making variations in grid carbon intensity and intermittency from renewables transparent to the user. We introduce GreenWhisk, a carbon-aware serverless computing platform built upon Apache OpenWhisk, operating in two modes - grid-connected and grid-isolated - addressing intermittency challenges arising from renewables and the grid's carbon footprint. Moreover, we develop carbon-aware load balancing algorithms that leverage energy and carbon information to reduce the carbon footprint. Our evaluation results show that GreenWhisk can easily incorporate carbon-aware algorithms, thereby reducing the carbon footprint of functions without significantly impacting the performance of function execution. In doing so, our system design enables the integration of new carbon-aware strategies into a serverless computing platform.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "11 pages, 13 figures, IC2E 2024"
    },
    {
        "paper id": "2409.03031",
        "abstract url": "https://arxiv.org/abs/2409.03031",
        "title": "Debugging with Open-Source Large Language Models: An Evaluation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language models have shown good potential in supporting software development tasks. This is why more and more developers turn to LLMs (e.g. ChatGPT) to support them in fixing their buggy code. While this can save time and effort, many companies prohibit it due to strict code sharing policies. To address this, companies can run open-source LLMs locally. But until now there is not much research evaluating the performance of open-source large language models in debugging. This work is a preliminary evaluation of the capabilities of open-source LLMs in fixing buggy code. The evaluation covers five open-source large language models and uses the benchmark DebugBench which includes more than 4000 buggy code instances written in Python, Java and C++. Open-source LLMs achieved scores ranging from 43.9% to 66.6% with DeepSeek-Coder achieving the best score for all three programming languages.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "7 pages, 2 figure, ESEM2024"
    },
    {
        "paper id": "2409.03041",
        "abstract url": "https://arxiv.org/abs/2409.03041",
        "title": "Nonlinear Monolithic Two-Level Schwarz Methods for the Navier-Stokes Equations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Nonlinear domain decomposition methods became popular in recent years since they can improve the nonlinear convergence behavior of Newton's method significantly for many complex problems. In this article, a nonlinear two-level Schwarz approach is considered and, for the first time, equipped with monolithic GDSW (Generalized Dryja-Smith-Widlund) coarse basis functions for the Navier-Stokes equations. Results for lid-driven cavity problems with high Reynolds numbers are presented and compared with classical global Newton's method equipped with a linear Schwarz preconditioner. Different options, for example, local pressure corrections on the subdomain and recycling of coarse basis functions are discussed in the nonlinear Schwarz approach for the first time.",
        "subjects": [
            "math.NA",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03051",
        "abstract url": "https://arxiv.org/abs/2409.03051",
        "title": "Successive-Cancellation Flip Decoding of Polar Codes Under Fixed Channel-Production Rate",
        "rating": "-10",
        "keywords": [],
        "abstract": "Polar codes are a class of error-correcting codes that provably achieve the capacity of practical channels under the low-complexity successive-cancellation flip (SCF) decoding algorithm. However, the SCF decoding algorithm has a variable execution time with a high (worst-case) decoding latency. This characteristic poses a challenge to the design of receivers that have to operate at fixed data rates. In this work, we propose a multi-threshold mechanism that restrains the delay of a SCF decoder depending on the state of the buffer to avoid overflow. We show that the proposed mechanism provides better error-correction performance compared to a straightforward codeword-dropping mechanism at the cost of a small increase in complexity. In the region of interest for wireless communications, the proposed mechanism can prevent buffer overflow while operating with a fixed channel-production rate that is 1.125 times lower than the rate associated to a single decoding trial.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03054",
        "abstract url": "https://arxiv.org/abs/2409.03054",
        "title": "Context-Aware Image Descriptions for Web Accessibility",
        "rating": "-10",
        "keywords": [],
        "abstract": "Blind and low vision (BLV) internet users access images on the web via text descriptions. New vision-to-language models such as GPT-V, Gemini, and LLaVa can now provide detailed image descriptions on-demand. While prior research and guidelines state that BLV audiences' information preferences depend on the context of the image, existing tools for accessing vision-to-language models provide only context-free image descriptions by generating descriptions for the image alone without considering the surrounding webpage context. To explore how to integrate image context into image descriptions, we designed a Chrome Extension that automatically extracts webpage context to inform GPT-4V-generated image descriptions. We gained feedback from 12 BLV participants in a user study comparing typical context-free image descriptions to context-aware image descriptions. We then further evaluated our context-informed image descriptions with a technical evaluation. Our user evaluation demonstrated that BLV participants frequently prefer context-aware descriptions to context-free descriptions. BLV participants also rated context-aware descriptions significantly higher in quality, imaginability, relevance, and plausibility. All participants shared that they wanted to use context-aware descriptions in the future and highlighted the potential for use in online shopping, social media, news, and personal interest blogs.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "17 pages, 11 figures"
    },
    {
        "paper id": "2409.03071",
        "abstract url": "https://arxiv.org/abs/2409.03071",
        "title": "Minimizing Cost Rather Than Maximizing Reward in Restless Multi-Armed Bandits",
        "rating": "-10",
        "keywords": [],
        "abstract": "Restless Multi-Armed Bandits (RMABs) offer a powerful framework for solving resource constrained maximization problems. However, the formulation can be inappropriate for settings where the limiting constraint is a reward threshold rather than a budget. We introduce a constrained minimization problem for RMABs that balances the goal of achieving a reward threshold while minimizing total cost. We show that even a bi-criteria approximate version of the problem is PSPACE-hard. Motivated by the hardness result, we define a decoupled problem, indexability and a Whittle index for the minimization problem, mirroring the corresponding concepts for the maximization problem. Further, we show that the Whittle index for the minimization problem can easily be computed from the Whittle index for the maximization problem. Consequently, Whittle index results on RMAB instances for the maximization problem give Whittle index results for the minimization problem. Despite the similarities between the minimization and maximization problems, solving the minimization problem is not as simple as taking direct analogs of the heuristics for the maximization problem. We give an example of an RMAB for which the greedy Whittle index heuristic achieves the optimal solution for the maximization problem, while the analogous heuristic yields the worst possible solution for the minimization problem. In light of this, we present and compare several heuristics for solving the minimization problem on real and synthetic data. Our work suggests the importance of continued investigation into the minimization problem.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03072",
        "abstract url": "https://arxiv.org/abs/2409.03072",
        "title": "Space to Teach: Content-Rich Canvases for Visually-Intensive Education",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the decreasing cost of consumer display technologies making it easier for universities to have larger displays in classrooms, and the ubiquitous use of online tools such as collaborative whiteboards for remote learning during the COVID-19 pandemic, combining the two can be useful in higher education. This is especially true in visually intensive classes, such as data visualization courses, that can benefit from additional \"space to teach,\" coined after the \"space to think\" sense-making idiom. In this paper, we reflect on our approach to using SAGE3, a collaborative whiteboard with advanced features, in higher education to teach visually intensive classes, provide examples of activities from our own visually-intensive courses, and present student feedback. We gather our observations into usage patterns for using content-rich canvases in education.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "To be published in the EDUVIS workshop at IEEE VIS 2024"
    },
    {
        "paper id": "2409.03086",
        "abstract url": "https://arxiv.org/abs/2409.03086",
        "title": "Intersecting Liminality: Acquiring a Smartphone as a Blind or Low Vision Older Adult",
        "rating": "-10",
        "keywords": [],
        "abstract": "Older adults are increasingly acquiring smartphones. But acquiring smartphones can be difficult, and little is known about the particular challenges of older adults who are additionally blind or losing their vision. We shed light on the social and technical aspects of acquiring smartphones with vision loss, based on deep qualitative interviews with 22 blind or low vision (BLV) older adults aged 60 and over. Through our grounded theory analysis, we found that BLV older adults experience liminality as they acquire smartphones and transition through re-acquiring smartphones as they become blind, and they can transition through liminality by participating in mutual aid within the blind community. We contribute the notion of \"Intersecting Liminality,\" which explains the marginalizing experience of simultaneously transitioning through vision loss, aging, and technology acquisition. We contend that Intersecting Liminality can serve as a framework that centers the dynamic nature of disability to help our community generate a more nuanced understanding of technology acquisition and more effective assistive interventions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "14 pages, 2 figures, 2 tables, conference paper accepted to The 26th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2024)"
    },
    {
        "paper id": "2409.03089",
        "abstract url": "https://arxiv.org/abs/2409.03089",
        "title": "Generative Manufacturing: A requirements and resource-driven approach to part making",
        "rating": "-10",
        "keywords": [],
        "abstract": "Advances in CAD and CAM have enabled engineers and design teams to digitally design parts with unprecedented ease. Software solutions now come with a range of modules for optimizing designs for performance requirements, generating instructions for manufacturing, and digitally tracking the entire process from design to procurement in the form of product life-cycle management tools. However, existing solutions force design teams and corporations to take a primarily serial approach where manufacturing and procurement decisions are largely contingent on design, rather than being an integral part of the design process. In this work, we propose a new approach to part making where design, manufacturing, and supply chain requirements and resources can be jointly considered and optimized. We present the Generative Manufacturing compiler that accepts as input the following: 1) An engineering part requirements specification that includes quantities such as loads, domain envelope, mass, and compliance, 2) A business part requirements specification that includes production volume, cost, and lead time, 3) Contextual knowledge about the current manufacturing state such as availability of relevant manufacturing equipment, materials, and workforce, both locally and through the supply chain. Based on these factors, the compiler generates and evaluates manufacturing process alternatives and the optimal derivative designs that are implied by each process, and enables a user guided iterative exploration of the design space. As part of our initial implementation of this compiler, we demonstrate the effectiveness of our approach on examples of a cantilever beam problem and a rocket engine mount problem and showcase its utility in creating and selecting optimal solutions according to the requirements and resources.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03093",
        "abstract url": "https://arxiv.org/abs/2409.03093",
        "title": "Multi-language Unit Test Generation using LLMs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Implementing automated unit tests is an important but time consuming activity in software development. Developers dedicate substantial time to writing tests for validating an application and preventing regressions. To support developers in this task, software engineering research over the past few decades has developed many techniques for automating unit test generation. However, despite this effort, usable tools exist for very few programming languages -- mainly Java, C, and C# and, more recently, for Python. Moreover, studies have found that automatically generated tests suffer poor readability and often do not resemble developer-written tests. In this work, we present a rigorous investigation of how large language models (LLMs) can help bridge the gap. We describe a generic pipeline that incorporates static analysis to guide LLMs in generating compilable and high-coverage test cases. We illustrate how the pipeline can be applied to different programming languages, specifically Java and Python, and to complex software requiring environment mocking. We conducted a through empirical study to assess the quality of the generated tests in terms of coverage, mutation score, and test naturalness -- evaluating them on standard as well as enterprise Java applications and a large Python benchmark. Our results demonstrate that LLM-based test generation, when guided by static analysis, can be competitive with, and even outperform, state-of-the-art test-generation techniques in coverage achieved while also producing considerably more natural test cases that developers find easy to read and understand. We also present the results of a user study, conducted with 161 professional developers, that highlights the naturalness characteristics of the tests generated by our approach.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03095",
        "abstract url": "https://arxiv.org/abs/2409.03095",
        "title": "On Advanced Monte Carlo Methods for Linear Algebra on Advanced Accelerator Architectures",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we present computational experiments with the Markov Chain Monte Carlo Matrix Inversion ($(\\text{MC})^2\\text{MI}$) on several accelerator architectures and investigate their impact on performance and scalability of the method. The method is used as a preconditioner and for solving the corresponding system of linear equations iterative methods, such as generalized minimal residuals (GMRES) or bi-conjugate gradient (stabilized) (BICGstab), are used. Numerical experiments are carried out to highlight the benefits and deficiencies of both approaches and to assess their overall usefulness in light of scalability of the method.",
        "subjects": [
            "math.NA",
            "cs.DC"
        ],
        "comment": "10 pages, 8 figures, 2 pages IEEE artifact information, accepted to the 9th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems"
    },
    {
        "paper id": "2409.03146",
        "abstract url": "https://arxiv.org/abs/2409.03146",
        "title": "Envisioning an Optimal Network of Space-Based Lasers for Orbital Debris Remediation",
        "rating": "-10",
        "keywords": [],
        "abstract": "The rapid increase in resident space objects, including satellites and orbital debris, threatens the safety and sustainability of space missions. This paper explores orbital debris remediation using laser ablation with a network of collaborative space-based lasers. A novel delta-v vector analysis framework quantifies the effects of multiple simultaneous laser-to-debris (L2D) engagements by leveraging a vector composition of imparted delta-v vectors. The paper introduces the Concurrent Location-Scheduling Problem (CLSP), which optimizes the placement of laser platforms and schedules L2D engagements to maximize debris remediation capacity. Due to the computational complexity of CLSP, it is decomposed into two sequential subproblems: (1) optimal laser platform locations are determined using the Maximal Covering Location Problem, and (2) a novel integer linear programming-based approach schedules L2D engagements within the network configuration to maximize remediation capacity. Computational experiments are conducted to evaluate the proposed framework's effectiveness under various mission scenarios, demonstrating key network functions such as collaborative nudging, deorbiting, and just-in-time collision avoidance. A cost-benefit analysis further explores how varying the number and distribution of laser platforms affects debris remediation capacity, providing insights into optimizing the performance of space-based laser networks.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "41 pages, 13 figures, submitted to the Journal of Spacecraft and Rockets"
    },
    {
        "paper id": "2409.03152",
        "abstract url": "https://arxiv.org/abs/2409.03152",
        "title": "A Brief Overview of the Pawns Programming Language",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pawns is a programming language under development which supports pure functional programming (including algebraic data types, higher order programming and parametric polymorphism) and imperative programming (including pointers, destructive update of shared data structures and global variables), integrated so each can call the other and with purity checked by the compiler. For pure functional code the programmer need not understand the representation of the data structures. For imperative code the representation must be understood and all effects and dependencies must be documented in the code. For example, if a function may update one of its arguments, this must be declared in the function type signature and noted where the function is called. A single update operation may affect several variables due to sharing of representations (pointer aliasing). Pawns code requires all affected variables to be annotated wherever they may be updated and information about sharing to be declared. Annotations are also required where IO or other global variables are used and this must be declared in type signatures as well. Sharing analysis, performed by the compiler, is the key to many aspects of Pawns. It enables us to check that all effects are made obvious in the source code, effects can be encapsulated inside a pure interface and effects can be used safely in the presence of polymorphism.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03153",
        "abstract url": "https://arxiv.org/abs/2409.03153",
        "title": "Can we enhance prosocial behavior? Using post-ride feedback to improve micromobility interactions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Micromobility devices, such as e-scooters and delivery robots, hold promise for eco-friendly and cost-effective alternatives for future urban transportation. However, their lack of societal acceptance remains a challenge. Therefore, we must consider ways to promote prosocial behavior in micromobility interactions. We investigate how post-ride feedback can encourage the prosocial behavior of e-scooter riders while interacting with sidewalk users, including pedestrians and delivery robots. Using a web-based platform, we measure the prosocial behavior of e-scooter riders. Results found that post-ride feedback can successfully promote prosocial behavior, and objective measures indicated better gap behavior, lower speeds at interaction, and longer stopping time around other sidewalk actors. The findings of this study demonstrate the efficacy of post-ride feedback and provide a step toward designing methodologies to improve the prosocial behavior of mobility users.",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": "In 16th International ACM Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI'24), September 22-25, 2024, Stanford, CA, USA. 11 pages"
    },
    {
        "paper id": "2409.03170",
        "abstract url": "https://arxiv.org/abs/2409.03170",
        "title": "Solving Stochastic Orienteering Problems with Chance Constraints Using Monte Carlo Tree Search",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a new Monte Carlo Tree Search (MCTS) algorithm to solve the stochastic orienteering problem with chance constraints, i.e., a version of the problem where travel costs are random, and one is assigned a bound on the tolerable probability of exceeding the budget. The algorithm we present is online and anytime, i.e., it alternates planning and execution, and the quality of the solution it produces increases as the allowed computational time increases. Differently from most former MCTS algorithms, for each action available in a state the algorithm maintains estimates of both its value and the probability that its execution will eventually result in a violation of the chance constraint. Then, at action selection time, our proposed solution prunes away trajectories that are estimated to violate the failure probability. Extensive simulation results show that this approach can quickly produce high-quality solutions and is competitive with the optimal but time-consuming solution.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Paper to appear on the IEEE Transactions on Automation Science and Engineering"
    },
    {
        "paper id": "2409.03175",
        "abstract url": "https://arxiv.org/abs/2409.03175",
        "title": "Data-based approaches to learning and control by similarity between heterogeneous systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes basic definitions of similarity and similarity indexes between admissible behaviors of heterogeneous host and guest systems and further presents a similarity-based learning control framework by exploiting offline sampled data. By exploring helpful geometric properties of the admissible behavior and decomposing it into the subspace and offset components, the similarity indexes between two admissible behaviors are defined as the principal angles between their corresponding subspace components. By reconstructing the admissible behaviors leveraging sampled data, an efficient strategy for calculating the similarity indexes is developed, based on which a similarity-based learning control framework is proposed. It is shown that the host system can directly accomplish the same control tasks by utilizing the successful experience from the guest system, without having to undergo the trial-and-error process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03189",
        "abstract url": "https://arxiv.org/abs/2409.03189",
        "title": "A note on the differential spectrum of the Ness-Helleseth function",
        "rating": "-10",
        "keywords": [],
        "abstract": "Let $n\\geqslant3$ be an odd integer and $u$ an element in the finite field $\\gf_{3^n}$. The Ness-Helleseth function is the binomial $f_u(x)=ux^{d_1}+x^{d_2}$ over $\\gf_{3^n}$, where $d_1=\\frac{3^n-1}{2}-1$ and $d_2=3^n-2$. In 2007, Ness and Helleseth showed that $f_u$ is an APN function when $\u03c7(u+1)=\u03c7(u-1)=\u03c7(u)$, is differentially $3$-uniform when $\u03c7(u+1)=\u03c7(u-1)\\neq\u03c7(u)$, and has differential uniformity at most 4 if $ \u03c7(u+1)\\neq\u03c7(u-1)$ and $u\\notin\\gf_3$. Here $\u03c7(\\cdot)$ denotes the quadratic character on $\\gf_{3^n}$. Recently, Xia et al. determined the differential uniformity of $f_u$ for all $u$ and computed the differential spectrum of $f_u$ for $u$ satisfying $\u03c7(u+1)=\u03c7(u-1)$ or $u\\in\\gf_3$. The remaining problem is the differential spectrum of $f_u$ with $\u03c7(u+1)\\neq\u03c7(u-1)$ and $u\\notin\\gf_3$. In this paper, we fill in the gap. By studying differential equations arising from the Ness-Helleseth function $f_u$ more carefully, we express the differential spectrum of $f_u$ for such $u$ in terms of two quadratic character sums. This complements the previous work of Xia et al.",
        "subjects": [
            "cs.CR",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03227",
        "abstract url": "https://arxiv.org/abs/2409.03227",
        "title": "Memristors based Computation and Synthesis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Memristor has been identified as the fourth fundamental circuit element by Dr. Leon Chua in 1971 and since then it has gathered a lot of interest because of its non-volatility and are considered as a viable solution to the beyond CMOS era computation. Recently, memristor have been used to perform basic logic operations like AND, OR, NAND, NOR, XOR etc. and are also used in applications like Dot Product Engine, Convolution Neural Networks etc. This paper presents a new behavioural model of memristor then using it to build a 32-bit ripple carry adder. The paper later compares the area, power and time delay of the 32 bit Ripple Carry Adder using memristor with the 45nm CMOS technology and highlights its advantages and pitfalls.",
        "subjects": [
            "eess.SY",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03230",
        "abstract url": "https://arxiv.org/abs/2409.03230",
        "title": "Improving agent performance in fluid environments by perceptual pretraining",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we construct a pretraining framework for fluid environment perception, which includes an information compression model and the corresponding pretraining method. We test this framework in a two-cylinder problem through numerical simulation. The results show that after unsupervised pretraining with this framework, the intelligent agent can acquire key features of surrounding fluid environment, thereby adapting more quickly and effectively to subsequent multi-scenario tasks. In our research, these tasks include perceiving the position of the upstream obstacle and actively avoiding shedding vortices in the flow field to achieve drag reduction. Better performance of the pretrained agent is discussed in the sensitivity analysis.",
        "subjects": [
            "cs.RO",
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2409.03243",
        "abstract url": "https://arxiv.org/abs/2409.03243",
        "title": "Robust End-to-End Image Transmission with Residual Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, deep learning (DL) based image transmission at the physical layer (PL) has become a rising trend due to its ability to significantly outperform conventional separation-based digital transmissions. However, implementing solutions at the PL requires a major shift in established standards, such as those in cellular communications. Application layer (AL) solutions present a more feasible and standards-compliant alternative. In this work, we propose a layered image transmission scheme at the AL that is robust to end-to-end (E2E) channel errors. The base layer transmits a coarse image, while the enhancement layer transmits the residual between the original and coarse images. By mapping the residual image into a latent representation that aligns with the structure of the E2E channel, our proposed solution demonstrates high robustness to E2E channel errors.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "19 single-column pages, 11 figures and 6 tables"
    },
    {
        "paper id": "2409.03244",
        "abstract url": "https://arxiv.org/abs/2409.03244",
        "title": "Grid-Forming Storage Networks: Analytical Characterization of Damping and Design Insights",
        "rating": "-10",
        "keywords": [],
        "abstract": "The paper presents a theoretical study on small-signal stability and damping in bulk power systems with multiple grid-forming inverter-based storage resources. A detailed analysis is presented, characterizing the impacts of inverter droop gains and storage size on the slower eigenvalues, particularly those concerning inter-area oscillation modes. From these parametric sensitivity studies, a set of necessary conditions are derived that the design of droop gain must satisfy to enhance damping performance. The analytical findings are structured into propositions highlighting potential design considerations for improving system stability. The findings are illustrated via numerical studies on an IEEE 68-bus grid-forming storage network.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "accepted for presentation at The 63rd IEEE Conference on Decision and Control"
    },
    {
        "paper id": "2409.03247",
        "abstract url": "https://arxiv.org/abs/2409.03247",
        "title": "End User Authoring of Personalized Content Classifiers: Comparing Example Labeling, Rule Writing, and LLM Prompting",
        "rating": "-10",
        "keywords": [],
        "abstract": "Existing tools for laypeople to create personal classifiers often assume a motivated user working uninterrupted in a single, lengthy session. However, users tend to engage with social media casually, with many short sessions on an ongoing, daily basis. To make creating personal classifiers for content curation easier for such users, tools should support rapid initialization and iterative refinement. In this work, we compare three strategies -- (1) example labeling, (2) rule writing, and (3) large language model (LLM) prompting -- for end users to build personal content classifiers. From an experiment with 37 non-programmers tasked with creating personalized comment moderation filters, we found that with LLM prompting, participants reached 95\\% of peak performance in 5 minutes, beating other strategies due to higher recall, but all strategies struggled with iterative refinement. Despite LLM prompting's better performance, participants preferred different strategies in different contexts and, even when prompting, provided examples or wrote rule-like prompts, suggesting hybrid approaches.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    }
]