[
    {
        "paper id": "2409.04774",
        "abstract url": "https://arxiv.org/abs/2409.04774",
        "title": "Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models",
        "rating": "2",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLM) have prioritized expanding the context window from which models can incorporate more information. However, training models to handle long contexts presents significant challenges. These include the scarcity of high-quality natural long-context data, the potential for performance degradation on short-context tasks, and the reduced training efficiency associated with attention mechanisms. In this paper, we introduce Untie the Knots (\\textbf{UtK}), a novel data augmentation strategy employed during the continue pre-training phase, designed to efficiently enable LLMs to gain long-context capabilities without the need to modify the existing data mixture. In particular, we chunk the documents, shuffle the chunks, and create a complex and knotted structure of long texts; LLMs are then trained to untie these knots and identify relevant segments within seemingly chaotic token sequences. This approach greatly improves the model's performance by accurately attending to relevant information in long context and the training efficiency is also largely increased. We conduct extensive experiments on models with 7B and 72B parameters, trained on 20 billion tokens, demonstrating that UtK achieves 75\\% and 84.5\\% accurracy on RULER at 128K context length, significantly outperforming other long context strategies. The trained models will open-source for further research.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04796",
        "abstract url": "https://arxiv.org/abs/2409.04796",
        "title": "Enhancing Outlier Knowledge for Few-Shot Out-of-Distribution Detection with Extensible Local Prompts",
        "rating": "2",
        "keywords": [
            [
                "vision-language",
                "VLM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Out-of-Distribution (OOD) detection, aiming to distinguish outliers from known categories, has gained prominence in practical scenarios. Recently, the advent of vision-language models (VLM) has heightened interest in enhancing OOD detection for VLM through few-shot tuning. However, existing methods mainly focus on optimizing global prompts, ignoring refined utilization of local information with regard to outliers. Motivated by this, we freeze global prompts and introduce a novel coarse-to-fine tuning paradigm to emphasize regional enhancement with local prompts. Our method comprises two integral components: global prompt guided negative augmentation and local prompt enhanced regional regularization. The former utilizes frozen, coarse global prompts as guiding cues to incorporate negative augmentation, thereby leveraging local outlier knowledge. The latter employs trainable local prompts and a regional regularization to capture local information effectively, aiding in outlier identification. We also propose regional-related metric to empower the enrichment of OOD detection. Moreover, since our approach explores enhancing local prompts only, it can be seamlessly integrated with trained global prompts during inference to boost the performance. Comprehensive experiments demonstrate the effectiveness and potential of our method. Notably, our method reduces average FPR95 by 5.17% against state-of-the-art method in 4-shot tuning on challenging ImageNet-1k dataset, even outperforming 16-shot results of previous methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04828",
        "abstract url": "https://arxiv.org/abs/2409.04828",
        "title": "POINTS: Improving Your Vision-language Model with Affordable Strategies",
        "rating": "2",
        "keywords": [
            [
                "Vision-language"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, vision-language models have made significant strides, excelling in tasks like optical character recognition and geometric problem-solving. However, several critical issues remain: 1) Proprietary models often lack transparency about their architectures, while open-source models need more detailed ablations of their training strategies. 2) Pre-training data in open-source works is under-explored, with datasets added empirically, making the process cumbersome. 3) Fine-tuning often focuses on adding datasets, leading to diminishing returns. To address these issues, we propose the following contributions: 1) We trained a robust baseline model using the latest advancements in vision-language models, introducing effective improvements and conducting comprehensive ablation and validation for each technique. 2) Inspired by recent work on large language models, we filtered pre-training data using perplexity, selecting the lowest perplexity data for training. This approach allowed us to train on a curated 1M dataset, achieving competitive performance. 3) During visual instruction tuning, we used model soup on different datasets when adding more datasets yielded marginal improvements. These innovations resulted in a 9B parameter model that performs competitively with state-of-the-art models. Our strategies are efficient and lightweight, making them easily adoptable by the community.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04949",
        "abstract url": "https://arxiv.org/abs/2409.04949",
        "title": "Attention-Based Efficient Breath Sound Removal in Studio Audio Recordings",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this research, we present an innovative, parameter-efficient model that utilizes the attention U-Net architecture for the automatic detection and eradication of non-speech vocal sounds, specifically breath sounds, in vocal recordings. This task is of paramount importance in the field of sound engineering, despite being relatively under-explored. The conventional manual process for detecting and eliminating these sounds requires significant expertise and is extremely time-intensive. Existing automated detection and removal methods often fall short in terms of efficiency and precision. Our proposed model addresses these limitations by offering a streamlined process and superior accuracy, achieved through the application of advanced deep learning techniques. A unique dataset, derived from Device and Produced Speech (DAPS), was employed for this purpose. The training phase of the model emphasizes a log spectrogram and integrates an early stopping mechanism to prevent overfitting. Our model not only conserves precious time for sound engineers but also enhances the quality and consistency of audio production. This constitutes a significant breakthrough, as evidenced by its comparative efficiency, necessitating only 1.9M parameters and a training duration of 3.2 hours - markedly less than the top-performing models in this domain. The model is capable of generating identical outputs as previous models with drastically improved precision, making it an optimal choice.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04803",
        "abstract url": "https://arxiv.org/abs/2409.04803",
        "title": "Cross-attention Inspired Selective State Space Models for Target Sound Extraction",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "The Transformer model, particularly its cross-attention module, is widely used for feature fusion in target sound extraction which extracts the signal of interest based on given clues. Despite its effectiveness, this approach suffers from low computational efficiency. Recent advancements in state space models, notably the latest work Mamba, have shown comparable performance to Transformer-based methods while significantly reducing computational complexity in various tasks. However, Mamba's applicability in target sound extraction is limited due to its inability to capture dependencies between different sequences as the cross-attention does. In this paper, we propose CrossMamba for target sound extraction, which leverages the hidden attention mechanism of Mamba to compute dependencies between the given clues and the audio mixture. The calculation of Mamba can be divided to the query, key and value. We utilize the clue to generate the query and the audio mixture to derive the key and value, adhering to the principle of the cross-attention mechanism in Transformers. Experimental results from two representative target sound extraction methods validate the efficacy of the proposed CrossMamba.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "5 pages, 2 figures, submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.04820",
        "abstract url": "https://arxiv.org/abs/2409.04820",
        "title": "FreeAugment: Data Augmentation Search Across All Degrees of Freedom",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Data augmentation has become an integral part of deep learning, as it is known to improve the generalization capabilities of neural networks. Since the most effective set of image transformations differs between tasks and domains, automatic data augmentation search aims to alleviate the extreme burden of manually finding the optimal image transformations. However, current methods are not able to jointly optimize all degrees of freedom: (1) the number of transformations to be applied, their (2) types, (3) order, and (4) magnitudes. Many existing methods risk picking the same transformation more than once, limit the search to two transformations only, or search for the number of transformations exhaustively or iteratively in a myopic manner. Our approach, FreeAugment, is the first to achieve global optimization of all four degrees of freedom simultaneously, using a fully differentiable method. It efficiently learns the number of transformations and a probability distribution over their permutations, inherently refraining from redundant repetition while sampling. Our experiments demonstrate that this joint learning of all degrees of freedom significantly improves performance, achieving state-of-the-art results on various natural image benchmarks and beyond across other domains. Project page at https://tombekor.github.io/FreeAugment-web",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "math.OC"
        ],
        "comment": "Accepted by ECCV 2024"
    },
    {
        "paper id": "2409.04859",
        "abstract url": "https://arxiv.org/abs/2409.04859",
        "title": "Flow-TSVAD: Target-Speaker Voice Activity Detection via Latent Flow Matching",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Speaker diarization is typically considered a discriminative task, using discriminative approaches to produce fixed diarization results. In this paper, we explore the use of neural network-based generative methods for speaker diarization for the first time. We implement a Flow-Matching (FM) based generative algorithm within the sequence-to-sequence target speaker voice activity detection (Seq2Seq-TSVAD) diarization system. Our experiments reveal that applying the generative method directly to the original binary label sequence space of the TS-VAD output is ineffective. To address this issue, we propose mapping the binary label sequence into a dense latent space before applying the generative algorithm and our proposed Flow-TSVAD method outperforms the Seq2Seq-TSVAD system. Additionally, we observe that the FM algorithm converges rapidly during the inference stage, requiring only two inference steps to achieve promising results. As a generative model, Flow-TSVAD allows for sampling different diarization results by running the model multiple times. Moreover, ensembling results from various sampling instances further enhances diarization performance.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.04734",
        "abstract url": "https://arxiv.org/abs/2409.04734",
        "title": "Swin Transformer for Robust Differentiation of Real and Synthetic Images: Intra- and Inter-Dataset Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "\\textbf{Purpose} This study aims to address the growing challenge of distinguishing computer-generated imagery (CGI) from authentic digital images in the RGB color space. Given the limitations of existing classification methods in handling the complexity and variability of CGI, this research proposes a Swin Transformer-based model for accurate differentiation between natural and synthetic images. \\textbf{Methods} The proposed model leverages the Swin Transformer's hierarchical architecture to capture local and global features crucial for distinguishing CGI from natural images. The model's performance was evaluated through intra-dataset and inter-dataset testing across three distinct datasets: CiFAKE, JSSSTU, and Columbia. The datasets were tested individually (D1, D2, D3) and in combination (D1+D2+D3) to assess the model's robustness and domain generalization capabilities. \\textbf{Results} The Swin Transformer-based model demonstrated high accuracy, consistently achieving a range of 97-99\\% across all datasets and testing scenarios. These results confirm the model's effectiveness in detecting CGI, showcasing its robustness and reliability in both intra-dataset and inter-dataset evaluations. \\textbf{Conclusion} The findings of this study highlight the Swin Transformer model's potential as an advanced tool for digital image forensics, particularly in distinguishing CGI from natural images. The model's strong performance across multiple datasets indicates its capability for domain generalization, making it a valuable asset in scenarios requiring precise and reliable image classification.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2409.04742",
        "abstract url": "https://arxiv.org/abs/2409.04742",
        "title": "Enhancing Image Authenticity Detection: Swin Transformers and Color Frame Analysis for CGI vs. Real Images",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancements in computer graphics have greatly enhanced the quality of computer-generated images (CGI), making them increasingly indistinguishable from authentic images captured by digital cameras (ADI). This indistinguishability poses significant challenges, especially in an era of widespread misinformation and digitally fabricated content. This research proposes a novel approach to classify CGI and ADI using Swin Transformers and preprocessing techniques involving RGB and CbCrY color frame analysis. By harnessing the capabilities of Swin Transformers, our method foregoes handcrafted features instead of relying on raw pixel data for model training. This approach achieves state-of-the-art accuracy while offering substantial improvements in processing speed and robustness against joint image manipulations such as noise addition, blurring, and JPEG compression. Our findings highlight the potential of Swin Transformers combined with advanced color frame analysis for effective and efficient image authenticity detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2409.04747",
        "abstract url": "https://arxiv.org/abs/2409.04747",
        "title": "Explicit Mutual Information Maximization for Self-Supervised Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, self-supervised learning (SSL) has been extensively studied. Theoretically, mutual information maximization (MIM) is an optimal criterion for SSL, with a strong theoretical foundation in information theory. However, it is difficult to directly apply MIM in SSL since the data distribution is not analytically available in applications. In practice, many existing methods can be viewed as approximate implementations of the MIM criterion. This work shows that, based on the invariance property of MI, explicit MI maximization can be applied to SSL under a generic distribution assumption, i.e., a relaxed condition of the data distribution. We further illustrate this by analyzing the generalized Gaussian distribution. Based on this result, we derive a loss function based on the MIM criterion using only second-order statistics. We implement the new loss for SSL and demonstrate its effectiveness via extensive experiments.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04759",
        "abstract url": "https://arxiv.org/abs/2409.04759",
        "title": "Adaptative Context Normalization: A Boost for Deep Learning in Image Processing",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep Neural network learning for image processing faces major challenges related to changes in distribution across layers, which disrupt model convergence and performance. Activation normalization methods, such as Batch Normalization (BN), have revolutionized this field, but they rely on the simplified assumption that data distribution can be modelled by a single Gaussian distribution. To overcome these limitations, Mixture Normalization (MN) introduced an approach based on a Gaussian Mixture Model (GMM), assuming multiple components to model the data. However, this method entails substantial computational requirements associated with the use of Expectation-Maximization algorithm to estimate parameters of each Gaussian components. To address this issue, we introduce Adaptative Context Normalization (ACN), a novel supervised approach that introduces the concept of \"context\", which groups together a set of data with similar characteristics. Data belonging to the same context are normalized using the same parameters, enabling local representation based on contexts. For each context, the normalized parameters, as the model weights are learned during the backpropagation phase. ACN not only ensures speed, convergence, and superior performance compared to BN and MN but also presents a fresh perspective that underscores its particular efficacy in the field of image processing.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2403.16798"
    },
    {
        "paper id": "2409.04766",
        "abstract url": "https://arxiv.org/abs/2409.04766",
        "title": "Cross-Dataset Gaze Estimation by Evidential Inter-intra Fusion",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Achieving accurate and reliable gaze predictions in complex and diverse environments remains challenging. Fortunately, it is straightforward to access diverse gaze datasets in real-world applications. We discover that training these datasets jointly can significantly improve the generalization of gaze estimation, which is overlooked in previous works. However, due to the inherent distribution shift across different datasets, simply mixing multiple dataset decreases the performance in the original domain despite gaining better generalization abilities. To address the problem of ``cross-dataset gaze estimation'', we propose a novel Evidential Inter-intra Fusion EIF framework, for training a cross-dataset model that performs well across all source and unseen domains. Specifically, we build independent single-dataset branches for various datasets where the data space is partitioned into overlapping subspaces within each dataset for local regression, and further create a cross-dataset branch to integrate the generalizable features from single-dataset branches. Furthermore, evidential regressors based on the Normal and Inverse-Gamma (NIG) distribution are designed to additionally provide uncertainty estimation apart from predicting gaze. Building upon this foundation, our proposed framework achieves both intra-evidential fusion among multiple local regressors within each dataset and inter-evidential fusion among multiple branches by Mixture \\textbfof Normal Inverse-Gamma (MoNIG distribution. Experiments demonstrate that our method consistently achieves notable improvements in both source domains and unseen domains.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "This paper was previously submitted to ACM MM 2024"
    },
    {
        "paper id": "2409.04778",
        "abstract url": "https://arxiv.org/abs/2409.04778",
        "title": "LoCa: Logit Calibration for Knowledge Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge Distillation (KD), aiming to train a better student model by mimicking the teacher model, plays an important role in model compression. One typical way is to align the output logits. However, we find a common issue named mis-instruction, that the student would be misled when the predictions based on teacher logits do not follow the labels. Meanwhile, there is other useful dark knowledge in the logits such as the class discriminability, which is vital for distillation. In this paper, we propose a simple yet effective Logit Calibration (LoCa) method, which calibrates the logits from the teacher model based on the ground-truth labels. The key insight is to correct the prediction (to address the mis-instruction issue) and maintain useful dark knowledge simultaneously. Our proposed LoCa does not require any additional parameters. Empirical results on image classification and text generation tasks demonstrate that LoCa can effectively improve the performance of baselines.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted by ECAI 2024"
    },
    {
        "paper id": "2409.04787",
        "abstract url": "https://arxiv.org/abs/2409.04787",
        "title": "Selective Self-Rehearsal: A Fine-Tuning Approach to Improve Generalization in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Fine-tuning Large Language Models (LLMs) on specific datasets is a common practice to improve performance on target tasks. However, this performance gain often leads to overfitting, where the model becomes too specialized in either the task or the characteristics of the training data, resulting in a loss of generalization. This paper introduces Selective Self-Rehearsal (SSR), a fine-tuning approach that achieves performance comparable to the standard supervised fine-tuning (SFT) while improving generalization. SSR leverages the fact that there can be multiple valid responses to a query. By utilizing the model's correct responses, SSR reduces model specialization during the fine-tuning stage. SSR first identifies the correct model responses from the training set by deploying an appropriate LLM as a judge. Then, it fine-tunes the model using the correct model responses and the gold response for the remaining samples. The effectiveness of SSR is demonstrated through experiments on the task of identifying unanswerable queries across various datasets. The results show that standard SFT can lead to an average performance drop of up to $16.7\\%$ on multiple benchmarks, such as MMLU and TruthfulQA. In contrast, SSR results in close to $2\\%$ drop on average, indicating better generalization capabilities compared to standard SFT.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "14 pages, 8 figures"
    },
    {
        "paper id": "2409.04799",
        "abstract url": "https://arxiv.org/abs/2409.04799",
        "title": "PB-LRDWWS System for the SLT 2024 Low-Resource Dysarthria Wake-Up Word Spotting Challenge",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "For the SLT 2024 Low-Resource Dysarthria Wake-Up Word Spotting (LRDWWS) Challenge, we introduce the PB-LRDWWS system. This system combines a dysarthric speech content feature extractor for prototype construction with a prototype-based classification method. The feature extractor is a fine-tuned HuBERT model obtained through a three-stage fine-tuning process using cross-entropy loss. This fine-tuned HuBERT extracts features from the target dysarthric speaker's enrollment speech to build prototypes. Classification is achieved by calculating the cosine similarity between the HuBERT features of the target dysarthric speaker's evaluation speech and prototypes. Despite its simplicity, our method demonstrates effectiveness through experimental results. Our system achieves second place in the final Test-B of the LRDWWS Challenge.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "accept by SLT 2024"
    },
    {
        "paper id": "2409.04825",
        "abstract url": "https://arxiv.org/abs/2409.04825",
        "title": "Metadata augmented deep neural networks for wild animal classification",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Camera trap imagery has become an invaluable asset in contemporary wildlife surveillance, enabling researchers to observe and investigate the behaviors of wild animals. While existing methods rely solely on image data for classification, this may not suffice in cases of suboptimal animal angles, lighting, or image quality. This study introduces a novel approach that enhances wild animal classification by combining specific metadata (temperature, location, time, etc) with image data. Using a dataset focused on the Norwegian climate, our models show an accuracy increase from 98.4% to 98.9% compared to existing methods. Notably, our approach also achieves high accuracy with metadata-only classification, highlighting its potential to reduce reliance on image quality. This work paves the way for integrated systems that advance wildlife classification technology.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04831",
        "abstract url": "https://arxiv.org/abs/2409.04831",
        "title": "MILE: A Mutation Testing Framework of In-Context Learning Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In-context Learning (ICL) has achieved notable success in the applications of large language models (LLMs). By adding only a few input-output pairs that demonstrate a new task, the LLM can efficiently learn the task during inference without modifying the model parameters. Such mysterious ability of LLMs has attracted great research interests in understanding, formatting, and improving the in-context demonstrations, while still suffering from drawbacks like black-box mechanisms and sensitivity against the selection of examples. In this work, inspired by the foundations of adopting testing techniques in machine learning (ML) systems, we propose a mutation testing framework designed to characterize the quality and effectiveness of test data for ICL systems. First, we propose several mutation operators specialized for ICL demonstrations, as well as corresponding mutation scores for ICL test sets. With comprehensive experiments, we showcase the effectiveness of our framework in evaluating the reliability and quality of ICL test suites. Our code is available at https://github.com/weizeming/MILE.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04833",
        "abstract url": "https://arxiv.org/abs/2409.04833",
        "title": "Achieving Peak Performance for Large Language Models: A Systematic Review",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, large language models (LLMs) have achieved remarkable success in natural language processing (NLP). LLMs require an extreme amount of parameters to attain high performance. As models grow into the trillion-parameter range, computational and memory costs increase significantly. This makes it difficult for many researchers to access the resources needed to train or apply these models. Optimizing LLM performance involves two main approaches: fine-tuning pre-trained models for specific tasks to achieve state-of-the-art performance, and reducing costs or improving training time while maintaining similar performance. This paper presents a systematic literature review (SLR) following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement. We reviewed 65 publications out of 983 from 2017 to December 2023, retrieved from 5 databases. The study presents methods to optimize and accelerate LLMs while achieving cutting-edge results without sacrificing accuracy. We begin with an overview of the development of language modeling, followed by a detailed explanation of commonly used frameworks and libraries, and a taxonomy for improving and speeding up LLMs based on three classes: LLM training, LLM inference, and system serving. We then delve into recent optimization and acceleration strategies such as training optimization, hardware optimization, scalability and reliability, accompanied by the taxonomy and categorization of these strategies. Finally, we provide an in-depth comparison of each class and strategy, with two case studies on optimizing model training and enhancing inference efficiency. These case studies showcase practical approaches to address LLM resource limitations while maintaining performance.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "34 pages, 7 figures, 8 tables. Journal Article: IEEE Access"
    },
    {
        "paper id": "2409.04867",
        "abstract url": "https://arxiv.org/abs/2409.04867",
        "title": "Contrastive Disentangling: Fine-grained representation learning through multi-level contrastive learning without class priors",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in unsupervised representation learning often leverage class information to enhance feature extraction and clustering performance. However, this reliance on class priors limits the applicability of such methods in real-world scenarios where class information is unavailable or ambiguous. In this paper, we propose Contrastive Disentangling (CD), a simple and effective framework that learns representations without any reliance on class priors. Our framework employs a multi-level contrastive learning strategy that combines instance-level and feature-level losses with a normalized entropy loss to learn semantically rich and fine-grained representations. Specifically, (1) the instance-level contrastive loss encourages the separation of feature representations for different samples, (2) the feature-level contrastive loss promotes independence among the feature head predictions, and (3) the normalized entropy loss encourages the feature heads to capture meaningful and prevalent attributes from the data. These components work together to enable CD to significantly outperform existing methods, as demonstrated by extensive experiments on benchmark datasets including CIFAR-10, CIFAR-100, STL-10, and ImageNet-10, particularly in scenarios where class priors are absent. The code is available at https://github.com/Hoper-J/Contrastive-Disentangling.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04897",
        "abstract url": "https://arxiv.org/abs/2409.04897",
        "title": "Centralized Selection with Preferences in the Presence of Biases",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "This paper considers the scenario in which there are multiple institutions, each with a limited capacity for candidates, and candidates, each with preferences over the institutions. A central entity evaluates the utility of each candidate to the institutions, and the goal is to select candidates for each institution in a way that maximizes utility while also considering the candidates' preferences. The paper focuses on the setting in which candidates are divided into multiple groups and the observed utilities of candidates in some groups are biased--systematically lower than their true utilities. The first result is that, in these biased settings, prior algorithms can lead to selections with sub-optimal true utility and significant discrepancies in the fraction of candidates from each group that get their preferred choices. Subsequently, an algorithm is presented along with proof that it produces selections that achieve near-optimal group fairness with respect to preferences while also nearly maximizing the true utility under distributional assumptions. Further, extensive empirical validation of these results in real-world and synthetic settings, in which the distributional assumptions may not hold, are presented.",
        "subjects": [
            "cs.DS",
            "cs.CY",
            "cs.LG",
            "econ.TH",
            "stat.ML"
        ],
        "comment": "The conference version of this paper appears in ICML 2024"
    },
    {
        "paper id": "2409.04918",
        "abstract url": "https://arxiv.org/abs/2409.04918",
        "title": "Training-free ZS-CIR via Weighted Modality Fusion and Similarity",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Composed image retrieval (CIR), which formulates the query as a combination of a reference image and modified text, has emerged as a new form of image search due to its enhanced ability to capture users' intentions. However, training a CIR model in a supervised manner typically requires labor-intensive collection of (reference image, text modifier, target image) triplets. While existing zero-shot CIR (ZS-CIR) methods eliminate the need for training on specific downstream datasets, they still require additional pretraining with large-scale image-text pairs. In this paper, we introduce a training-free approach for ZS-CIR. Our approach, \\textbf{Wei}ghted \\textbf{Mo}dality fusion and similarity for \\textbf{CIR} (WeiMoCIR), operates under the assumption that image and text modalities can be effectively combined using a simple weighted average. This allows the query representation to be constructed directly from the reference image and text modifier. To further enhance retrieval performance, we employ multimodal large language models (MLLMs) to generate image captions for the database images and incorporate these textual captions into the similarity computation by combining them with image information using a weighted average. Our approach is simple, easy to implement, and its effectiveness is validated through experiments on the FashionIQ and CIRR datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 3 figures"
    },
    {
        "paper id": "2409.04927",
        "abstract url": "https://arxiv.org/abs/2409.04927",
        "title": "Just ASR + LLM? A Study on Speech Large Language Models' Ability to Identify and Understand Speaker in Spoken Dialogue",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "In recent years, we have observed a rapid advancement in speech language models (SpeechLLMs), catching up with humans' listening and reasoning abilities. Remarkably, SpeechLLMs have demonstrated impressive spoken dialogue question-answering (SQA) performance in benchmarks like Gaokao, the English listening test of the college entrance exam in China, which seemingly requires understanding both the spoken content and voice characteristics of speakers in a conversation. However, after carefully examining Gaokao's questions, we find the correct answers to many questions can be inferred from the conversation context alone without identifying the speaker asked in the question. Our evaluation of state-of-the-art models Qwen-Audio and WavLLM in both Gaokao and our proposed \"What Do You Like?\" dataset shows a significantly higher accuracy in these context-based questions than in identity-critical questions, which can only be answered correctly with correct speaker identification. Our results and analysis suggest that when solving SQA, the current SpeechLLMs exhibit limited speaker awareness from the audio and behave similarly to an LLM reasoning from the conversation transcription without sound. We propose that our definitions and automated classification of context-based and identity-critical questions could offer a more accurate evaluation framework of SpeechLLMs in SQA tasks.",
        "subjects": [
            "cs.CL",
            "eess.AS"
        ],
        "comment": "Accepted to IEEE SLT 2024"
    },
    {
        "paper id": "2409.04934",
        "abstract url": "https://arxiv.org/abs/2409.04934",
        "title": "Maximizing Relation Extraction Potential: A Data-Centric Study to Unveil Challenges and Opportunities",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Relation extraction is a Natural Language Processing task aiming to extract relationships from textual data. It is a critical step for information extraction. Due to its wide-scale applicability, research in relation extraction has rapidly scaled to using highly advanced neural networks. Despite their computational superiority, modern relation extractors fail to handle complicated extraction scenarios. However, a comprehensive performance analysis of the state-of-the-art relation extractors that compile these challenges has been missing from the literature, and this paper aims to bridge this gap. The goal has been to investigate the possible data-centric characteristics that impede neural relation extraction. Based on extensive experiments conducted using 15 state-of-the-art relation extraction algorithms ranging from recurrent architectures to large language models and seven large-scale datasets, this research suggests that modern relation extractors are not robust to complex data and relation characteristics. It emphasizes pivotal issues, such as contextual ambiguity, correlating relations, long-tail data, and fine-grained relation distributions. In addition, it sets a marker for future directions to alleviate these issues, thereby proving to be a critical resource for novice and advanced researchers. Efficient handling of the challenges described can have significant implications for the field of information extraction, which is a critical part of popular systems such as search engines and chatbots. Data and relevant code can be found at https://github.com/anushkasw/MaxRE.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.04945",
        "abstract url": "https://arxiv.org/abs/2409.04945",
        "title": "Fast Deep Predictive Coding Networks for Videos Feature Extraction without Labels",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Brain-inspired deep predictive coding networks (DPCNs) effectively model and capture video features through a bi-directional information flow, even without labels. They are based on an overcomplete description of video scenes, and one of the bottlenecks has been the lack of effective sparsification techniques to find discriminative and robust dictionaries. FISTA has been the best alternative. This paper proposes a DPCN with a fast inference of internal model variables (states and causes) that achieves high sparsity and accuracy of feature clustering. The proposed unsupervised learning procedure, inspired by adaptive dynamic programming with a majorization-minimization framework, and its convergence are rigorously analyzed. Experiments in the data sets CIFAR-10, Super Mario Bros video game, and Coil-100 validate the approach, which outperforms previous versions of DPCNs on learning rate, sparsity ratio, and feature clustering accuracy. Because of DCPN's solid foundation and explainability, this advance opens the door for general applications in object recognition in video without labels.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04953",
        "abstract url": "https://arxiv.org/abs/2409.04953",
        "title": "Evaluating Neural Networks Architectures for Spring Reverb Modelling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "Reverberation is a key element in spatial audio perception, historically achieved with the use of analogue devices, such as plate and spring reverb, and in the last decades with digital signal processing techniques that have allowed different approaches for Virtual Analogue Modelling (VAM). The electromechanical functioning of the spring reverb makes it a nonlinear system that is difficult to fully emulate in the digital domain with white-box modelling techniques. In this study, we compare five different neural network architectures, including convolutional and recurrent models, to assess their effectiveness in replicating the characteristics of this audio effect. The evaluation is conducted on two datasets at sampling rates of 16 kHz and 48 kHz. This paper specifically focuses on neural audio architectures that offer parametric control, aiming to advance the boundaries of current black-box modelling techniques in the domain of spring reverberation.",
        "subjects": [
            "cs.SD",
            "cs.AI"
        ],
        "comment": "8 pages, 7 figures, 2 tables"
    },
    {
        "paper id": "2409.04958",
        "abstract url": "https://arxiv.org/abs/2409.04958",
        "title": "DDNet: Deformable Convolution and Dense FPN for Surface Defect Detection in Recycled Books",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recycled and recirculated books, such as ancient texts and reused textbooks, hold significant value in the second-hand goods market, with their worth largely dependent on surface preservation. However, accurately assessing surface defects is challenging due to the wide variations in shape, size, and the often imprecise detection of defects. To address these issues, we propose DDNet, an innovative detection model designed to enhance defect localization and classification. DDNet introduces a surface defect feature extraction module based on a deformable convolution operator (DC) and a densely connected FPN module (DFPN). The DC module dynamically adjusts the convolution grid to better align with object contours, capturing subtle shape variations and improving boundary delineation and prediction accuracy. Meanwhile, DFPN leverages dense skip connections to enhance feature fusion, constructing a hierarchical structure that generates multi-resolution, high-fidelity feature maps, thus effectively detecting defects of various sizes. In addition to the model, we present a comprehensive dataset specifically curated for surface defect detection in recycled and recirculated books. This dataset encompasses a diverse range of defect types, shapes, and sizes, making it ideal for evaluating the robustness and effectiveness of defect detection models. Through extensive evaluations, DDNet achieves precise localization and classification of surface defects, recording a mAP value of 46.7% on our proprietary dataset - an improvement of 14.2% over the baseline model - demonstrating its superior detection capabilities.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04964",
        "abstract url": "https://arxiv.org/abs/2409.04964",
        "title": "Evaluation of Google Translate for Mandarin Chinese translation using sentiment and semantic analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Machine translation using large language models (LLMs) is having a significant global impact, making communication easier. Mandarin Chinese is the official language used for communication by the government, education institutes, and media in China. In this study, we provide an automated assessment of machine translation models with human experts using sentiment and semantic analysis. In order to demonstrate our framework, we select classic early twentieth-century novel 'The True Story of Ah Q' with selected Mandarin Chinese to English translations. We also us Google Translate to generate the given text into English and then conduct a chapter-wise sentiment analysis and semantic analysis to compare the extracted sentiments across the different translations. We utilise LLMs for semantic and sentiment analysis. Our results indicate that the precision of Google Translate differs both in terms of semantic and sentiment analysis when compared to human expert translations. We find that Google Translate is unable to translate some of the specific words or phrases in Chinese, such as Chinese traditional allusions. The mistranslations have to its lack of contextual significance and historical knowledge of China. Thus, this framework brought us some new insights about machine translation for Chinese Mandarin. The future work can explore other languages or types of texts with this framework.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04968",
        "abstract url": "https://arxiv.org/abs/2409.04968",
        "title": "Natias: Neuron Attribution based Transferable Image Adversarial Steganography",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image steganography is a technique to conceal secret messages within digital images. Steganalysis, on the contrary, aims to detect the presence of secret messages within images. Recently, deep-learning-based steganalysis methods have achieved excellent detection performance. As a countermeasure, adversarial steganography has garnered considerable attention due to its ability to effectively deceive deep-learning-based steganalysis. However, steganalysts often employ unknown steganalytic models for detection. Therefore, the ability of adversarial steganography to deceive non-target steganalytic models, known as transferability, becomes especially important. Nevertheless, existing adversarial steganographic methods do not consider how to enhance transferability. To address this issue, we propose a novel adversarial steganographic scheme named Natias. Specifically, we first attribute the output of a steganalytic model to each neuron in the target middle layer to identify critical features. Next, we corrupt these critical features that may be adopted by diverse steganalytic models. Consequently, it can promote the transferability of adversarial steganography. Our proposed method can be seamlessly integrated with existing adversarial steganography frameworks. Thorough experimental analyses affirm that our proposed technique possesses improved transferability when contrasted with former approaches, and it attains heightened security in retraining scenarios.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": "Accepted by IEEE TIFS"
    },
    {
        "paper id": "2409.04711",
        "abstract url": "https://arxiv.org/abs/2409.04711",
        "title": "Algorithmic Scenario Generation as Quality Diversity Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The increasing complexity of robots and autonomous agents that interact with people highlights the critical need for approaches that systematically test them before deployment. This review paper presents a general framework for solving this problem, describes the insights that we have gained from working on each component of the framework, and shows how integrating these components leads to the discovery of a diverse range of realistic and challenging scenarios that reveal previously unknown failures in deployed robotic systems interacting with people.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04733",
        "abstract url": "https://arxiv.org/abs/2409.04733",
        "title": "A Sample Efficient Alternating Minimization-based Algorithm For Robust Phase Retrieval",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we study the robust phase retrieval problem where the task is to recover an unknown signal $\u03b8^* \\in \\mathbb{R}^d$ in the presence of potentially arbitrarily corrupted magnitude-only linear measurements. We propose an alternating minimization approach that incorporates an oracle solver for a non-convex optimization problem as a subroutine. Our algorithm guarantees convergence to $\u03b8^*$ and provides an explicit polynomial dependence of the convergence rate on the fraction of corrupted measurements. We then provide an efficient construction of the aforementioned oracle under a sparse arbitrary outliers model and offer valuable insights into the geometric properties of the loss landscape in phase retrieval with corrupted measurements. Our proposed oracle avoids the need for computationally intensive spectral initialization, using a simple gradient descent algorithm with a constant step size and random initialization instead. Additionally, our overall algorithm achieves nearly linear sample complexity, $\\mathcal{O}(d \\, \\mathrm{polylog}(d))$.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04757",
        "abstract url": "https://arxiv.org/abs/2409.04757",
        "title": "Unsupervised Adaptive Normalization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep neural networks have become a staple in solving intricate problems, proving their mettle in a wide array of applications. However, their training process is often hampered by shifting activation distributions during backpropagation, resulting in unstable gradients. Batch Normalization (BN) addresses this issue by normalizing activations, which allows for the use of higher learning rates. Despite its benefits, BN is not without drawbacks, including its dependence on mini-batch size and the presumption of a uniform distribution of samples. To overcome this, several alternatives have been proposed, such as Layer Normalization, Group Normalization, and Mixture Normalization. These methods may still struggle to adapt to the dynamic distributions of neuron activations during the learning process. To bridge this gap, we introduce Unsupervised Adaptive Normalization (UAN), an innovative algorithm that seamlessly integrates clustering for normalization with deep neural network learning in a singular process. UAN executes clustering using the Gaussian mixture model, determining parameters for each identified cluster, by normalizing neuron activations. These parameters are concurrently updated as weights in the deep neural network, aligning with the specific requirements of the target task during backpropagation. This unified approach of clustering and normalization, underpinned by neuron activation normalization, fosters an adaptive data representation that is specifically tailored to the target task. This adaptive feature of UAN enhances gradient stability, resulting in faster learning and augmented neural network performance. UAN outperforms the classical methods by adapting to the target task and is effective in classification, and domain adaptation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2403.16798"
    },
    {
        "paper id": "2409.04777",
        "abstract url": "https://arxiv.org/abs/2409.04777",
        "title": "Optimization Hyper-parameter Laws for Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models have driven significant AI advancements, yet their training is resource-intensive and highly sensitive to hyper-parameter selection. While scaling laws provide valuable guidance on model size and data requirements, they fall short in choosing dynamic hyper-parameters, such as learning-rate (LR) schedules, that evolve during training. To bridge this gap, we present Optimization Hyper-parameter Laws (Opt-Laws), a framework that effectively captures the relationship between hyper-parameters and training outcomes, enabling the pre-selection of potential optimal schedules. Grounded in stochastic differential equations, Opt-Laws introduce novel mathematical interpretability and offer a robust theoretical foundation for some popular LR schedules. Our extensive validation across diverse model sizes and data scales demonstrates Opt-Laws' ability to accurately predict training loss and identify optimal LR schedule candidates in pre-training, continual training, and fine-tuning scenarios. This approach significantly reduces computational costs while enhancing overall model performance.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04779",
        "abstract url": "https://arxiv.org/abs/2409.04779",
        "title": "Component Fourier Neural Operator for Singularly Perturbed Differential Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Solving Singularly Perturbed Differential Equations (SPDEs) poses computational challenges arising from the rapid transitions in their solutions within thin regions. The effectiveness of deep learning in addressing differential equations motivates us to employ these methods for solving SPDEs. In this manuscript, we introduce Component Fourier Neural Operator (ComFNO), an innovative operator learning method that builds upon Fourier Neural Operator (FNO), while simultaneously incorporating valuable prior knowledge obtained from asymptotic analysis. Our approach is not limited to FNO and can be applied to other neural network frameworks, such as Deep Operator Network (DeepONet), leading to potential similar SPDEs solvers. Experimental results across diverse classes of SPDEs demonstrate that ComFNO significantly improves accuracy compared to vanilla FNO. Furthermore, ComFNO exhibits natural adaptability to diverse data distributions and performs well in few-shot scenarios, showcasing its excellent generalization ability in practical situations.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04792",
        "abstract url": "https://arxiv.org/abs/2409.04792",
        "title": "Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep neural networks provide Reinforcement Learning (RL) powerful function approximators to address large-scale decision-making problems. However, these approximators introduce challenges due to the non-stationary nature of RL training. One source of the challenges in RL is that output predictions can churn, leading to uncontrolled changes after each batch update for states not included in the batch. Although such a churn phenomenon exists in each step of network training, how churn occurs and impacts RL remains under-explored. In this work, we start by characterizing churn in a view of Generalized Policy Iteration with function approximation, and we discover a chain effect of churn that leads to a cycle where the churns in value estimation and policy improvement compound and bias the learning dynamics throughout the iteration. Further, we concretize the study and focus on the learning issues caused by the chain effect in different settings, including greedy action deviation in value-based methods, trust region violation in proximal policy optimization, and dual bias of policy value in actor-critic methods. We then propose a method to reduce the chain effect across different settings, called Churn Approximated ReductIoN (CHAIN), which can be easily plugged into most existing DRL algorithms. Our experiments demonstrate the effectiveness of our method in both reducing churn and improving learning performance across online and offline, value-based and policy-based RL settings, as well as a scaling setting.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04819",
        "abstract url": "https://arxiv.org/abs/2409.04819",
        "title": "Top-GAP: Integrating Size Priors in CNNs for more Interpretability, Robustness, and Bias Mitigation",
        "rating": "0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This paper introduces Top-GAP, a novel regularization technique that enhances the explainability and robustness of convolutional neural networks. By constraining the spatial size of the learned feature representation, our method forces the network to focus on the most salient image regions, effectively reducing background influence. Using adversarial attacks and the Effective Receptive Field, we show that Top-GAP directs more attention towards object pixels rather than the background. This leads to enhanced interpretability and robustness. We achieve over 50% robust accuracy on CIFAR-10 with PGD $\u03b5=\\frac{8}{255}$ and $20$ iterations while maintaining the original clean accuracy. Furthermore, we see increases of up to 5% accuracy against distribution shifts. Our approach also yields more precise object localization, as evidenced by up to 25% improvement in Intersection over Union (IOU) compared to methods like GradCAM and Recipro-CAM.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "eXCV Workshop at ECCV 2024"
    },
    {
        "paper id": "2409.04838",
        "abstract url": "https://arxiv.org/abs/2409.04838",
        "title": "SPIRIT: Low Power Seizure Prediction using Unsupervised Online-Learning and Zoom Analog Frontends",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Early prediction of seizures and timely interventions are vital for improving patients' quality of life. While seizure prediction has been shown in software-based implementations, to enable timely warnings of upcoming seizures, prediction must be done on an edge device to reduce latency. Ideally, such devices must also be low-power and track long-term drifts to minimize maintenance from the user. This work presents SPIRIT: Stochastic-gradient-descent-based Predictor with Integrated Retraining and In situ accuracy Tuning. SPIRIT is a complete system-on-a-chip (SoC) integrating an unsupervised online-learning seizure prediction classifier with eight 14.4 uW, 0.057 mm2, 90.5 dB dynamic range, Zoom Analog Frontends. SPIRIT achieves, on average, 97.5%/96.2% sensitivity/specificity respectively, predicting seizures an average of 8.4 minutes before they occur. Through its online learning algorithm, prediction accuracy improves by up to 15%, and prediction times extend by up to 7x, without any external intervention. Its classifier consumes 17.2 uW and occupies 0.14 mm2, the lowest reported for a prediction classifier by >134x in power and >5x in area. SPIRIT is also at least 5.6x more energy efficient than the state-of-the-art.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04840",
        "abstract url": "https://arxiv.org/abs/2409.04840",
        "title": "Sample- and Oracle-Efficient Reinforcement Learning for MDPs with Linearly-Realizable Value Functions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Designing sample-efficient and computationally feasible reinforcement learning (RL) algorithms is particularly challenging in environments with large or infinite state and action spaces. In this paper, we advance this effort by presenting an efficient algorithm for Markov Decision Processes (MDPs) where the state-action value function of any policy is linear in a given feature map. This challenging setting can model environments with infinite states and actions, strictly generalizes classic linear MDPs, and currently lacks a computationally efficient algorithm under online access to the MDP. Specifically, we introduce a new RL algorithm that efficiently finds a near-optimal policy in this setting, using a number of episodes and calls to a cost-sensitive classification (CSC) oracle that are both polynomial in the problem parameters. Notably, our CSC oracle can be efficiently implemented when the feature dimension is constant, representing a clear improvement over state-of-the-art methods, which require solving non-convex problems with horizon-many variables and can incur computational costs that are \\emph{exponential} in the horizon.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04880",
        "abstract url": "https://arxiv.org/abs/2409.04880",
        "title": "Towards identifying Source credibility on Information Leakage in Digital Gadget Market",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The use of Social media to share content is on a constant rise. One of the capsize effect of information sharing on Social media includes the spread of sensitive information on the public domain. With the digital gadget market becoming highly competitive and ever-evolving, the trend of an increasing number of sensitive posts leaking information on devices in social media is observed. Many web-blogs on digital gadget market have mushroomed recently, making the problem of information leak all pervasive. Credible leaks on specifics of an upcoming device can cause a lot of financial damage to the respective organization. Hence, it is crucial to assess the credibility of the platforms that continuously post about a smartphone or digital gadget leaks. In this work, we analyze the headlines of leak web-blog posts and their corresponding official press-release. We first collect 54, 495 leak and press-release headlines for different smartphones. We train our custom NER model to capture the evolving smartphone names with an accuracy of 82.14% on manually annotated results. We further propose a credibility score metric for the web-blog, based on the number of falsified and authentic smartphone leak posts.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04887",
        "abstract url": "https://arxiv.org/abs/2409.04887",
        "title": "Defeasible Reasoning on Concepts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we take first steps toward developing defeasible reasoning on concepts in KLM framework. We define generalizations of cumulative reasoning system C and cumulative reasoning system with loop CL to conceptual setting. We also generalize cumulative models, cumulative ordered models, and preferential models to conceptual setting and show the soundness and completeness results for these models.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04896",
        "abstract url": "https://arxiv.org/abs/2409.04896",
        "title": "Reinforcement Learning-Based Adaptive Load Balancing for Dynamic Cloud Environments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Efficient load balancing is crucial in cloud computing environments to ensure optimal resource utilization, minimize response times, and prevent server overload. Traditional load balancing algorithms, such as round-robin or least connections, are often static and unable to adapt to the dynamic and fluctuating nature of cloud workloads. In this paper, we propose a novel adaptive load balancing framework using Reinforcement Learning (RL) to address these challenges. The RL-based approach continuously learns and improves the distribution of tasks by observing real-time system performance and making decisions based on traffic patterns and resource availability. Our framework is designed to dynamically reallocate tasks to minimize latency and ensure balanced resource usage across servers. Experimental results show that the proposed RL-based load balancer outperforms traditional algorithms in terms of response time, resource utilization, and adaptability to changing workloads. These findings highlight the potential of AI-driven solutions for enhancing the efficiency and scalability of cloud infrastructures.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.NI"
        ],
        "comment": "Length: 6 pages (including references) Figures: 3 figures Submission Type: Conference paper Keywords: Reinforcement Learning, Load Balancing, Cloud Computing, Adaptive Algorithms, AI-driven Load Management"
    },
    {
        "paper id": "2409.04898",
        "abstract url": "https://arxiv.org/abs/2409.04898",
        "title": "Learning Joint Models of Prediction and Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Predict-Then-Optimize framework uses machine learning models to predict unknown parameters of an optimization problem from exogenous features before solving. This setting is common to many real-world decision processes, and recently it has been shown that decision quality can be substantially improved by solving and differentiating the optimization problem within an end-to-end training loop. However, this approach requires significant computational effort in addition to handcrafted, problem-specific rules for backpropagation through the optimization step, challenging its applicability to a broad class of optimization problems. This paper proposes an alternative method, in which optimal solutions are learned directly from the observable features by joint predictive models. The approach is generic, and based on an adaptation of the Learning-to-Optimize paradigm, from which a rich variety of existing techniques can be employed. Experimental evaluations show the ability of several Learning-to-Optimize methods to provide efficient and accurate solutions to an array of challenging Predict-Then-Optimize problems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2311.13087"
    },
    {
        "paper id": "2409.04909",
        "abstract url": "https://arxiv.org/abs/2409.04909",
        "title": "Efficient Training of Transformers for Molecule Property Prediction on Small-scale Datasets",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The blood-brain barrier (BBB) serves as a protective barrier that separates the brain from the circulatory system, regulating the passage of substances into the central nervous system. Assessing the BBB permeability of potential drugs is crucial for effective drug targeting. However, traditional experimental methods for measuring BBB permeability are challenging and impractical for large-scale screening. Consequently, there is a need to develop computational approaches to predict BBB permeability. This paper proposes a GPS Transformer architecture augmented with Self Attention, designed to perform well in the low-data regime. The proposed approach achieved a state-of-the-art performance on the BBB permeability prediction task using the BBBP dataset, surpassing existing models. With a ROC-AUC of 78.8%, the approach sets a state-of-the-art by 5.5%. We demonstrate that standard Self Attention coupled with GPS transformer performs better than other variants of attention coupled with GPS Transformer.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04913",
        "abstract url": "https://arxiv.org/abs/2409.04913",
        "title": "NGD converges to less degenerate solutions than SGD",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The number of free parameters, or dimension, of a model is a straightforward way to measure its complexity: a model with more parameters can encode more information. However, this is not an accurate measure of complexity: models capable of memorizing their training data often generalize well despite their high dimension. Effective dimension aims to more directly capture the complexity of a model by counting only the number of parameters required to represent the functionality of the model. Singular learning theory (SLT) proposes the learning coefficient $ \u03bb$ as a more accurate measure of effective dimension. By describing the rate of increase of the volume of the region of parameter space around a local minimum with respect to loss, $ \u03bb$ incorporates information from higher-order terms. We compare $ \u03bb$ of models trained using natural gradient descent (NGD) and stochastic gradient descent (SGD), and find that those trained with NGD consistently have a higher effective dimension for both of our methods: the Hessian trace $ \\text{Tr}(\\mathbf{H}) $, and the estimate of the local learning coefficient (LLC) $ \\hat\u03bb(w^*) $.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "8 pages, 23 figures"
    },
    {
        "paper id": "2409.04919",
        "abstract url": "https://arxiv.org/abs/2409.04919",
        "title": "Collaborative Learning with Shared Linear Representations: Statistical Rates and Optimal Algorithms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Collaborative learning enables multiple clients to learn shared feature representations across local data distributions, with the goal of improving model performance and reducing overall sample complexity. While empirical evidence shows the success of collaborative learning, a theoretical understanding of the optimal statistical rate remains lacking, even in linear settings. In this paper, we identify the optimal statistical rate when clients share a common low-dimensional linear representation. Specifically, we design a spectral estimator with local averaging that approximates the optimal solution to the least squares problem. We establish a minimax lower bound to demonstrate that our estimator achieves the optimal error rate. Notably, the optimal rate reveals two distinct phases. In typical cases, our rate matches the standard rate based on the parameter counting of the linear representation. However, a statistical penalty arises in collaborative learning when there are too many clients or when local datasets are relatively small. Furthermore, our results, unlike existing ones, show that, at a system level, collaboration always reduces overall sample complexity compared to independent client learning. In addition, at an individual level, we provide a more precise characterization of when collaboration benefits a client in transfer learning and private fine-tuning.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04940",
        "abstract url": "https://arxiv.org/abs/2409.04940",
        "title": "An Analog and Digital Hybrid Attention Accelerator for Transformers with Charge-based In-memory Computing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The attention mechanism is a key computing kernel of Transformers, calculating pairwise correlations across the entire input sequence. The computing complexity and frequent memory access in computing self-attention put a huge burden on the system especially when the sequence length increases. This paper presents an analog and digital hybrid processor to accelerate the attention mechanism for transformers in 65nm CMOS technology. We propose an analog computing-in-memory (CIM) core, which prunes ~75% of low-score tokens on average during runtime at ultra-low power and delay. Additionally, a digital processor performs precise computations only for ~25% unpruned tokens selected by the analog CIM core, preventing accuracy degradation. Measured results show peak energy efficiency of 14.8 and 1.65 TOPS/W, and peak area efficiency of 976.6 and 79.4 GOPS/mm$^\\mathrm{2}$ in the analog core and the system-on-chip (SoC), respectively.",
        "subjects": [
            "cs.AR",
            "cs.LG"
        ],
        "comment": "4 pages, 9 figures, to be published at ESSERC 2024"
    },
    {
        "paper id": "2409.04942",
        "abstract url": "https://arxiv.org/abs/2409.04942",
        "title": "UMOD: A Novel and Effective Urban Metro Origin-Destination Flow Prediction Method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurate prediction of metro Origin-Destination (OD) flow is essential for the development of intelligent transportation systems and effective urban traffic management. Existing approaches typically either predict passenger outflow of departure stations or inflow of destination stations. However, we argue that travelers generally have clearly defined departure and arrival stations, making these OD pairs inherently interconnected. Consequently, considering OD pairs as a unified entity more accurately reflects actual metro travel patterns and allows for analyzing potential spatio-temporal correlations between different OD pairs. To address these challenges, we propose a novel and effective urban metro OD flow prediction method (UMOD), comprising three core modules: a data embedding module, a temporal relation module, and a spatial relation module. The data embedding module projects raw OD pair inputs into hidden space representations, which are subsequently processed by the temporal and spatial relation modules to capture both inter-pair and intra-pair spatio-temporal dependencies. Experimental results on two real-world urban metro OD flow datasets demonstrate that adopting the OD pairs perspective is critical for accurate metro OD flow prediction. Our method outperforms existing approaches, delivering superior predictive performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04714",
        "abstract url": "https://arxiv.org/abs/2409.04714",
        "title": "Unleashing the Power of Generic Segmentation Models: A Simple Baseline for Infrared Small Target Detection",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in deep learning have greatly advanced the field of infrared small object detection (IRSTD). Despite their remarkable success, a notable gap persists between these IRSTD methods and generic segmentation approaches in natural image domains. This gap primarily arises from the significant modality differences and the limited availability of infrared data. In this study, we aim to bridge this divergence by investigating the adaptation of generic segmentation models, such as the Segment Anything Model (SAM), to IRSTD tasks. Our investigation reveals that many generic segmentation models can achieve comparable performance to state-of-the-art IRSTD methods. However, their full potential in IRSTD remains untapped. To address this, we propose a simple, lightweight, yet effective baseline model for segmenting small infrared objects. Through appropriate distillation strategies, we empower smaller student models to outperform state-of-the-art methods, even surpassing fine-tuned teacher results. Furthermore, we enhance the model's performance by introducing a novel query design comprising dense and sparse queries to effectively encode multi-scale features. Through extensive experimentation across four popular IRSTD datasets, our model demonstrates significantly improved performance in both accuracy and throughput compared to existing approaches, surpassing SAM and Semantic-SAM by over 14 IoU on NUDT and 4 IoU on IRSTD1k. The source code and models will be released at https://github.com/O937-blip/SimIR.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ACM MM'24"
    },
    {
        "paper id": "2409.04750",
        "abstract url": "https://arxiv.org/abs/2409.04750",
        "title": "Training-Free Style Consistent Image Synthesis with Condition and Mask Guidance in E-Commerce",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generating style-consistent images is a common task in the e-commerce field, and current methods are largely based on diffusion models, which have achieved excellent results. This paper introduces the concept of the QKV (query/key/value) level, referring to modifications in the attention maps (self-attention and cross-attention) when integrating UNet with image conditions. Without disrupting the product's main composition in e-commerce images, we aim to use a train-free method guided by pre-set conditions. This involves using shared KV to enhance similarity in cross-attention and generating mask guidance from the attention map to cleverly direct the generation of style-consistent images. Our method has shown promising results in practical applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04751",
        "abstract url": "https://arxiv.org/abs/2409.04751",
        "title": "Fisheye-GS: Lightweight and Extensible Gaussian Splatting Module for Fisheye Cameras",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, 3D Gaussian Splatting (3DGS) has garnered attention for its high fidelity and real-time rendering. However, adapting 3DGS to different camera models, particularly fisheye lenses, poses challenges due to the unique 3D to 2D projection calculation. Additionally, there are inefficiencies in the tile-based splatting, especially for the extreme curvature and wide field of view of fisheye lenses, which are crucial for its broader real-life applications. To tackle these challenges, we introduce Fisheye-GS.This innovative method recalculates the projection transformation and its gradients for fisheye cameras. Our approach can be seamlessly integrated as a module into other efficient 3D rendering methods, emphasizing its extensibility, lightweight nature, and modular design. Since we only modified the projection component, it can also be easily adapted for use with different camera models. Compared to methods that train after undistortion, our approach demonstrates a clear improvement in visual quality.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04760",
        "abstract url": "https://arxiv.org/abs/2409.04760",
        "title": "Training-Free Point Cloud Recognition Based on Geometric and Semantic Information Fusion",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The trend of employing training-free methods for point cloud recognition is becoming increasingly popular due to its significant reduction in computational resources and time costs. However, existing approaches are limited as they typically extract either geometric or semantic features. To address this limitation, we propose a novel method that integrates both geometric and semantic features, thereby enhancing the comprehensive understanding of point clouds. For the geometric branch, we adopt a non-parametric strategy to extract geometric features. In the semantic branch, we leverage a model pre-trained through contrastive learning and aligned with text features to obtain semantic features. Experimental results demonstrate that our method outperforms existing state-of-the-art training-free approaches on several popular benchmark datasets, including ModelNet and ScanObiectNN.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04795",
        "abstract url": "https://arxiv.org/abs/2409.04795",
        "title": "Phrase-Level Adversarial Training for Mitigating Bias in Neural Network-based Automatic Essay Scoring",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Automatic Essay Scoring (AES) is widely used to evaluate candidates for educational purposes. However, due to the lack of representative data, most existing AES systems are not robust, and their scoring predictions are biased towards the most represented data samples. In this study, we propose a model-agnostic phrase-level method to generate an adversarial essay set to address the biases and robustness of AES models. Specifically, we construct an attack test set comprising samples from the original test set and adversarially generated samples using our proposed method. To evaluate the effectiveness of the attack strategy and data augmentation, we conducted a comprehensive analysis utilizing various neural network scoring models. Experimental results show that the proposed approach significantly improves AES model performance in the presence of adversarial examples and scenarios without such attacks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04801",
        "abstract url": "https://arxiv.org/abs/2409.04801",
        "title": "SpotActor: Training-Free Layout-Controlled Consistent Image Generation",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image diffusion models significantly enhance the efficiency of artistic creation with high-fidelity image generation. However, in typical application scenarios like comic book production, they can neither place each subject into its expected spot nor maintain the consistent appearance of each subject across images. For these issues, we pioneer a novel task, Layout-to-Consistent-Image (L2CI) generation, which produces consistent and compositional images in accordance with the given layout conditions and text prompts. To accomplish this challenging task, we present a new formalization of dual energy guidance with optimization in a dual semantic-latent space and thus propose a training-free pipeline, SpotActor, which features a layout-conditioned backward update stage and a consistent forward sampling stage. In the backward stage, we innovate a nuanced layout energy function to mimic the attention activations with a sigmoid-like objective. While in the forward stage, we design Regional Interconnection Self-Attention (RISA) and Semantic Fusion Cross-Attention (SFCA) mechanisms that allow mutual interactions across images. To evaluate the performance, we present ActorBench, a specified benchmark with hundreds of reasonable prompt-box pairs stemming from object detection datasets. Comprehensive experiments are conducted to demonstrate the effectiveness of our method. The results prove that SpotActor fulfills the expectations of this task and showcases the potential for practical applications with superior layout alignment, subject consistency, prompt conformity and background diversity.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04822",
        "abstract url": "https://arxiv.org/abs/2409.04822",
        "title": "Exploring Straightforward Conversational Red-Teaming",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are increasingly used in business dialogue systems but they pose security and ethical risks. Multi-turn conversations, where context influences the model's behavior, can be exploited to produce undesired responses. In this paper, we examine the effectiveness of utilizing off-the-shelf LLMs in straightforward red-teaming approaches, where an attacker LLM aims to elicit undesired output from a target LLM, comparing both single-turn and conversational red-teaming tactics. Our experiments offer insights into various usage strategies that significantly affect their performance as red teamers. They suggest that off-the-shelf models can act as effective red teamers and even adjust their attack strategy based on past attempts, although their effectiveness decreases with greater alignment.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04837",
        "abstract url": "https://arxiv.org/abs/2409.04837",
        "title": "Context-Aware Replanning with Pre-explored Semantic Map for Object Navigation",
        "rating": "0",
        "keywords": [
            [
                "visual language",
                "VLMs"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Pre-explored Semantic Maps, constructed through prior exploration using visual language models (VLMs), have proven effective as foundational elements for training-free robotic applications. However, existing approaches assume the map's accuracy and do not provide effective mechanisms for revising decisions based on incorrect maps. To address this, we introduce Context-Aware Replanning (CARe), which estimates map uncertainty through confidence scores and multi-view consistency, enabling the agent to revise erroneous decisions stemming from inaccurate maps without requiring additional labels. We demonstrate the effectiveness of our proposed method by integrating it with two modern mapping backbones, VLMaps and OpenMask3D, and observe significant performance improvements in object navigation tasks. More details can be found on the project page: https://carmaps.github.io/supplements/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "CoRL 2024. The first three authors contributed equally, and their order of authorship is interchangeable. Project page: https://carmaps.github.io/supplements/"
    },
    {
        "paper id": "2409.04843",
        "abstract url": "https://arxiv.org/abs/2409.04843",
        "title": "Leveraging Moving Sound Source Trajectories for Universal Sound Separation",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Existing methods utilizing spatial information for sound source separation require prior knowledge of the direction of arrival (DOA) of the source or utilize estimated but imprecise localization results, which impairs the separation performance, especially when the sound sources are moving. In fact, sound source localization and separation are interconnected problems, that is, sound source localization facilitates sound separation while sound separation contributes to more precise source localization. This paper proposes a method utilizing the mutual facilitation mechanism between sound source localization and separation for moving sources. Initially, sound separation is conducted using rough preliminary sound source tracking results. Sound source tracking is then performed on the separated signals thus the tracking results can become more precise. The precise trajectory can further enhances the separation performance. This mutual facilitation process can be performed over several iterations. Simulation experiments conducted under reverberation conditions and with moving sound sources demonstrate that the proposed method can achieve more accurate separation based on more precise tracking results.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "9 pages,7 figures,submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing(TASLP)"
    },
    {
        "paper id": "2409.04847",
        "abstract url": "https://arxiv.org/abs/2409.04847",
        "title": "Rethinking The Training And Evaluation of Rich-Context Layout-to-Image Generation",
        "rating": "0",
        "keywords": [
            [
                "image editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in generative models have significantly enhanced their capacity for image generation, enabling a wide range of applications such as image editing, completion and video editing. A specialized area within generative modeling is layout-to-image (L2I) generation, where predefined layouts of objects guide the generative process. In this study, we introduce a novel regional cross-attention module tailored to enrich layout-to-image generation. This module notably improves the representation of layout regions, particularly in scenarios where existing methods struggle with highly complex and detailed textual descriptions. Moreover, while current open-vocabulary L2I methods are trained in an open-set setting, their evaluations often occur in closed-set environments. To bridge this gap, we propose two metrics to assess L2I performance in open-vocabulary scenarios. Additionally, we conduct a comprehensive user study to validate the consistency of these metrics with human preferences.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04851",
        "abstract url": "https://arxiv.org/abs/2409.04851",
        "title": "AdaptiveFusion: Adaptive Multi-Modal Multi-View Fusion for 3D Human Body Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in sensor technology and deep learning have led to significant progress in 3D human body reconstruction. However, most existing approaches rely on data from a specific sensor, which can be unreliable due to the inherent limitations of individual sensing modalities. On the other hand, existing multi-modal fusion methods generally require customized designs based on the specific sensor combinations or setups, which limits the flexibility and generality of these methods. Furthermore, conventional point-image projection-based and Transformer-based fusion networks are susceptible to the influence of noisy modalities and sensor poses. To address these limitations and achieve robust 3D human body reconstruction in various conditions, we propose AdaptiveFusion, a generic adaptive multi-modal multi-view fusion framework that can effectively incorporate arbitrary combinations of uncalibrated sensor inputs. By treating different modalities from various viewpoints as equal tokens, and our handcrafted modality sampling module by leveraging the inherent flexibility of Transformer models, AdaptiveFusion is able to cope with arbitrary numbers of inputs and accommodate noisy modalities with only a single training network. Extensive experiments on large-scale human datasets demonstrate the effectiveness of AdaptiveFusion in achieving high-quality 3D human body reconstruction in various environments. In addition, our method achieves superior accuracy compared to state-of-the-art fusion methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04963",
        "abstract url": "https://arxiv.org/abs/2409.04963",
        "title": "GS-PT: Exploiting 3D Gaussian Splatting for Comprehensive Point Cloud Understanding via Self-supervised Learning",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "Point Cloud",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Self-supervised learning of point cloud aims to leverage unlabeled 3D data to learn meaningful representations without reliance on manual annotations. However, current approaches face challenges such as limited data diversity and inadequate augmentation for effective feature learning. To address these challenges, we propose GS-PT, which integrates 3D Gaussian Splatting (3DGS) into point cloud self-supervised learning for the first time. Our pipeline utilizes transformers as the backbone for self-supervised pre-training and introduces novel contrastive learning tasks through 3DGS. Specifically, the transformers aim to reconstruct the masked point cloud. 3DGS utilizes multi-view rendered images as input to generate enhanced point cloud distributions and novel view images, facilitating data augmentation and cross-modal contrastive learning. Additionally, we incorporate features from depth maps. By optimizing these tasks collectively, our method enriches the tri-modal self-supervised learning process, enabling the model to leverage the correlation across 3D point clouds and 2D images from various modalities. We freeze the encoder after pre-training and test the model's performance on multiple downstream tasks. Experimental results indicate that GS-PT outperforms the off-the-shelf self-supervised learning methods on various downstream tasks including 3D object classification, real-world classifications, and few-shot learning and segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04740",
        "abstract url": "https://arxiv.org/abs/2409.04740",
        "title": "Up-sampling-only and Adaptive Mesh-based GNN for Simulating Physical Systems",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Traditional simulation of complex mechanical systems relies on numerical solvers of Partial Differential Equations (PDEs), e.g., using the Finite Element Method (FEM). The FEM solvers frequently suffer from intensive computation cost and high running time. Recent graph neural network (GNN)-based simulation models can improve running time meanwhile with acceptable accuracy. Unfortunately, they are hard to tailor GNNs for complex mechanical systems, including such disadvantages as ineffective representation and inefficient message propagation (MP). To tackle these issues, in this paper, with the proposed Up-sampling-only and Adaptive MP techniques, we develop a novel hierarchical Mesh Graph Network, namely UA-MGN, for efficient and effective mechanical simulation. Evaluation on two synthetic and one real datasets demonstrates the superiority of the UA-MGN. For example, on the Beam dataset, compared to the state-of-the-art MS-MGN, UA-MGN leads to 40.99% lower errors but using only 43.48% fewer network parameters and 4.49% fewer floating point operations (FLOPs).",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04743",
        "abstract url": "https://arxiv.org/abs/2409.04743",
        "title": "GRVFL-2V: Graph Random Vector Functional Link Based on Two-View Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The classification performance of the random vector functional link (RVFL), a randomized neural network, has been widely acknowledged. However, due to its shallow learning nature, RVFL often fails to consider all the relevant information available in a dataset. Additionally, it overlooks the geometrical properties of the dataset. To address these limitations, a novel graph random vector functional link based on two-view learning (GRVFL-2V) model is proposed. The proposed model is trained on multiple views, incorporating the concept of multiview learning (MVL), and it also incorporates the geometrical properties of all the views using the graph embedding (GE) framework. The fusion of RVFL networks, MVL, and GE framework enables our proposed model to achieve the following: i) \\textit{efficient learning}: by leveraging the topology of RVFL, our proposed model can efficiently capture nonlinear relationships within the multi-view data, facilitating efficient and accurate predictions; ii) \\textit{comprehensive representation}: fusing information from diverse perspectives enhance the proposed model's ability to capture complex patterns and relationships within the data, thereby improving the model's overall generalization performance; and iii) \\textit{structural awareness}: by employing the GE framework, our proposed model leverages the original data distribution of the dataset by naturally exploiting both intrinsic and penalty subspace learning criteria. The evaluation of the proposed GRVFL-2V model on various datasets, including 27 UCI and KEEL datasets, 50 datasets from Corel5k, and 45 datasets from AwA, demonstrates its superior performance compared to baseline models. These results highlight the enhanced generalization capabilities of the proposed GRVFL-2V model across a diverse range of datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04775",
        "abstract url": "https://arxiv.org/abs/2409.04775",
        "title": "Leveraging LLMs, Graphs and Object Hierarchies for Task Planning in Large-Scale Environments",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Planning methods struggle with computational intractability in solving task-level problems in large-scale environments. This work explores leveraging the commonsense knowledge encoded in LLMs to empower planning techniques to deal with these complex scenarios. We achieve this by efficiently using LLMs to prune irrelevant components from the planning problem's state space, substantially simplifying its complexity. We demonstrate the efficacy of this system through extensive experiments within a household simulation environment, alongside real-world validation using a 7-DoF manipulator (video https://youtu.be/6ro2UOtOQS4).",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.04793",
        "abstract url": "https://arxiv.org/abs/2409.04793",
        "title": "Action is the primary key: a categorical framework for episode description and logical reasoning",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This research presents a computational framework for describing and recognizing episodes and for logical reasoning. This framework, named cognitive-logs, consists of a set of relational and graph databases. Cognitive-logs record knowledge, particularly in episodes that consist of \"actions\" represented by verbs in natural languages and \"participants\" who perform the actions. These objects are connected by arrows (morphisms) that link each action to its participant and link cause to effect. Operations based on category theory enable comparisons between episodes and deductive inferences, including abstractions of stories. One of the goals of this study is to develop a database-driven artificial intelligence. This artificial intelligence thinks like a human but possesses the accuracy and rigour of a machine. The vast capacities of databases (up to petabyte scales in current technologies) enable the artificial intelligence to store a greater volume of knowledge than neural-network based artificial intelligences. Cognitive-logs serve as a model of human cognition and designed with references to cognitive linguistics. Cognitive-logs also have the potential to model various human mind activities.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "26 pages, 18 figures, 4 tables"
    },
    {
        "paper id": "2409.04813",
        "abstract url": "https://arxiv.org/abs/2409.04813",
        "title": "Generalized Learning of Coefficients in Spectral Graph Convolutional Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Spectral Graph Convolutional Networks (GCNs) have gained popularity in graph machine learning applications due, in part, to their flexibility in specification of network propagation rules. These propagation rules are often constructed as polynomial filters whose coefficients are learned using label information during training. In contrast to learned polynomial filters, explicit filter functions are useful in capturing relationships between network topology and distribution of labels across the network. A number of algorithms incorporating either approach have been proposed; however the relationship between filter functions and polynomial approximations is not fully resolved. This is largely due to the ill-conditioned nature of the linear systems that must be solved to derive polynomial approximations of filter functions. To address this challenge, we propose a novel Arnoldi orthonormalization-based algorithm, along with a unifying approach, called G-Arnoldi-GCN that can efficiently and effectively approximate a given filter function with a polynomial. We evaluate G-Arnoldi-GCN in the context of multi-class node classification across ten datasets with diverse topological characteristics. Our experiments show that G-Arnoldi-GCN consistently outperforms state-of-the-art methods when suitable filter functions are employed. Overall, G-Arnoldi-GCN opens important new directions in graph machine learning by enabling the explicit design and application of diverse filter functions. Code link: https://anonymous.4open.science/r/GArnoldi-GCN-F7E2/README.md",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04829",
        "abstract url": "https://arxiv.org/abs/2409.04829",
        "title": "NASH: Neural Architecture and Accelerator Search for Multiplication-Reduced Hybrid Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The significant computational cost of multiplications hinders the deployment of deep neural networks (DNNs) on edge devices. While multiplication-free models offer enhanced hardware efficiency, they typically sacrifice accuracy. As a solution, multiplication-reduced hybrid models have emerged to combine the benefits of both approaches. Particularly, prior works, i.e., NASA and NASA-F, leverage Neural Architecture Search (NAS) to construct such hybrid models, enhancing hardware efficiency while maintaining accuracy. However, they either entail costly retraining or encounter gradient conflicts, limiting both search efficiency and accuracy. Additionally, they overlook the acceleration opportunity introduced by accelerator search, yielding sub-optimal hardware performance. To overcome these limitations, we propose NASH, a Neural architecture and Accelerator Search framework for multiplication-reduced Hybrid models. Specifically, as for NAS, we propose a tailored zero-shot metric to pre-identify promising hybrid models before training, enhancing search efficiency while alleviating gradient conflicts. Regarding accelerator search, we innovatively introduce coarse-to-fine search to streamline the search process. Furthermore, we seamlessly integrate these two levels of searches to unveil NASH, obtaining the optimal model and accelerator pairing. Experiments validate our effectiveness, e.g., when compared with the state-of-the-art multiplication-based system, we can achieve $\\uparrow$$2.14\\times$ throughput and $\\uparrow$$2.01\\times$ FPS with $\\uparrow$$0.25\\%$ accuracy on CIFAR-100, and $\\uparrow$$1.40\\times$ throughput and $\\uparrow$$1.19\\times$ FPS with $\\uparrow$$0.56\\%$ accuracy on Tiny-ImageNet. Codes are available at \\url{https://github.com/xuyang527/NASH.}",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04832",
        "abstract url": "https://arxiv.org/abs/2409.04832",
        "title": "Reward-Directed Score-Based Diffusion Models via q-Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We propose a new reinforcement learning (RL) formulation for training continuous-time score-based diffusion models for generative AI to generate samples that maximize reward functions while keeping the generated distributions close to the unknown target data distributions. Different from most existing studies, our formulation does not involve any pretrained model for the unknown score functions of the noise-perturbed data distributions. We present an entropy-regularized continuous-time RL problem and show that the optimal stochastic policy has a Gaussian distribution with a known covariance matrix. Based on this result, we parameterize the mean of Gaussian policies and develop an actor-critic type (little) q-learning algorithm to solve the RL problem. A key ingredient in our algorithm design is to obtain noisy observations from the unknown score function via a ratio estimator. Numerically, we show the effectiveness of our approach by comparing its performance with two state-of-the-art RL methods that fine-tune pretrained models. Finally, we discuss extensions of our RL formulation to probability flow ODE implementation of diffusion models and to conditional diffusion models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04834",
        "abstract url": "https://arxiv.org/abs/2409.04834",
        "title": "Reducing Events to Augment Log-based Anomaly Detection Models: An Empirical Study",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "As software systems grow increasingly intricate, the precise detection of anomalies have become both essential and challenging. Current log-based anomaly detection methods depend heavily on vast amounts of log data leading to inefficient inference and potential misguidance by noise logs. However, the quantitative effects of log reduction on the effectiveness of anomaly detection remain unexplored. Therefore, we first conduct a comprehensive study on six distinct models spanning three datasets. Through the study, the impact of log quantity and their effectiveness in representing anomalies is qualifies, uncovering three distinctive log event types that differently influence model performance. Drawing from these insights, we propose LogCleaner: an efficient methodology for the automatic reduction of log events in the context of anomaly detection. Serving as middleware between software systems and models, LogCleaner continuously updates and filters anti-events and duplicative-events in the raw generated logs. Experimental outcomes highlight LogCleaner's capability to reduce over 70% of log events in anomaly detection, accelerating the model's inference speed by approximately 300%, and universally improving the performance of models for anomaly detection.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Accepted By ESEM'24"
    },
    {
        "paper id": "2409.04860",
        "abstract url": "https://arxiv.org/abs/2409.04860",
        "title": "Sequential Classification of Misinformation",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "In recent years there have been a growing interest in online auditing of information flow over social networks with the goal of monitoring undesirable effects, such as, misinformation and fake news. Most previous work on the subject, focus on the binary classification problem of classifying information as fake or genuine. Nonetheless, in many practical scenarios, the multi-class/label setting is of particular importance. For example, it could be the case that a social media platform may want to distinguish between ``true\", ``partly-true\", and ``false\" information. Accordingly, in this paper, we consider the problem of online multiclass classification of information flow. To that end, driven by empirical studies on information flow over real-world social media networks, we propose a probabilistic information flow model over graphs. Then, the learning task is to detect the label of the information flow, with the goal of minimizing a combination of the classification error and the detection time. For this problem, we propose two detection algorithms; the first is based on the well-known multiple sequential probability ratio test, while the second is a novel graph neural network based sequential decision algorithm. For both algorithms, we prove several strong statistical guarantees. We also construct a data driven algorithm for learning the proposed probabilistic model. Finally, we test our algorithms over two real-world datasets, and show that they outperform other state-of-the-art misinformation detection algorithms, in terms of detection time and classification error.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": "42 pages"
    },
    {
        "paper id": "2409.04882",
        "abstract url": "https://arxiv.org/abs/2409.04882",
        "title": "Learning to Open and Traverse Doors with a Legged Manipulator",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics",
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Using doors is a longstanding challenge in robotics and is of significant practical interest in giving robots greater access to human-centric spaces. The task is challenging due to the need for online adaptation to varying door properties and precise control in manipulating the door panel and navigating through the confined doorway. To address this, we propose a learning-based controller for a legged manipulator to open and traverse through doors. The controller is trained using a teacher-student approach in simulation to learn robust task behaviors as well as estimate crucial door properties during the interaction. Unlike previous works, our approach is a single control policy that can handle both push and pull doors through learned behaviour which infers the opening direction during deployment without prior knowledge. The policy was deployed on the ANYmal legged robot with an arm and achieved a success rate of 95.0% in repeated trials conducted in an experimental setting. Additional experiments validate the policy's effectiveness and robustness to various doors and disturbances. A video overview of the method and experiments can be found at youtu.be/tQDZXN_k5NU.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04901",
        "abstract url": "https://arxiv.org/abs/2409.04901",
        "title": "Unlocking the Potential of Model Calibration in Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Over the past several years, various federated learning (FL) methodologies have been developed to improve model accuracy, a primary performance metric in machine learning. However, to utilize FL in practical decision-making scenarios, beyond considering accuracy, the trained model must also have a reliable confidence in each of its predictions, an aspect that has been largely overlooked in existing FL research. Motivated by this gap, we propose Non-Uniform Calibration for Federated Learning (NUCFL), a generic framework that integrates FL with the concept of model calibration. The inherent data heterogeneity in FL environments makes model calibration particularly difficult, as it must ensure reliability across diverse data distributions and client conditions. Our NUCFL addresses this challenge by dynamically adjusting the model calibration objectives based on statistical relationships between each client's local model and the global model in FL. In particular, NUCFL assesses the similarity between local and global model relationships, and controls the penalty term for the calibration loss during client-side local training. By doing so, NUCFL effectively aligns calibration needs for the global model in heterogeneous FL settings while not sacrificing accuracy. Extensive experiments show that NUCFL offers flexibility and effectiveness across various FL algorithms, enhancing accuracy as well as model calibration.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04923",
        "abstract url": "https://arxiv.org/abs/2409.04923",
        "title": "Single-snapshot machine learning for turbulence super resolution",
        "rating": "-0.5",
        "keywords": [
            [
                "super resolution"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modern machine-learning techniques are generally considered data-hungry. However, this may not be the case for turbulence as each of its snapshots can hold more information than a single data file in general machine-learning applications. This study asks the question of whether nonlinear machine-learning techniques can effectively extract physical insights even from as little as a single snapshot of a turbulent vortical flow. As an example, we consider machine-learning-based super-resolution analysis that reconstructs a high-resolution field from low-resolution data for two-dimensional decaying turbulence. We reveal that a carefully designed machine-learning model trained with flow tiles sampled from only a single snapshot can reconstruct vortical structures across a range of Reynolds numbers. Successful flow reconstruction indicates that nonlinear machine-learning techniques can leverage scale-invariance properties to learn turbulent flows. We further show that training data of turbulent flows can be cleverly collected from a single snapshot by considering characteristics of rotation and shear tensors. The present findings suggest that embedding prior knowledge in designing a model and collecting data is important for a range of data-driven analyses for turbulent flows. More broadly, this work hopes to stop machine-learning practitioners from being wasteful with turbulent flow data.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04962",
        "abstract url": "https://arxiv.org/abs/2409.04962",
        "title": "A foundation model enpowered by a multi-modal prompt engine for universal seismic geobody interpretation across surveys",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Seismic geobody interpretation is crucial for structural geology studies and various engineering applications. Existing deep learning methods show promise but lack support for multi-modal inputs and struggle to generalize to different geobody types or surveys. We introduce a promptable foundation model for interpreting any geobodies across seismic surveys. This model integrates a pre-trained vision foundation model (VFM) with a sophisticated multi-modal prompt engine. The VFM, pre-trained on massive natural images and fine-tuned on seismic data, provides robust feature extraction for cross-survey generalization. The prompt engine incorporates multi-modal prior information to iteratively refine geobody delineation. Extensive experiments demonstrate the model's superior accuracy, scalability from 2D to 3D, and generalizability to various geobody types, including those unseen during training. To our knowledge, this is the first highly scalable and versatile multi-modal foundation model capable of interpreting any geobodies across surveys while supporting real-time interactions. Our approach establishes a new paradigm for geoscientific data interpretation, with broad potential for transfer to other tasks.",
        "subjects": [
            "physics.geo-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04971",
        "abstract url": "https://arxiv.org/abs/2409.04971",
        "title": "Soft Actor-Critic with Beta Policy via Implicit Reparameterization Gradients",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in deep reinforcement learning have achieved impressive results in a wide range of complex tasks, but poor sample efficiency remains a major obstacle to real-world deployment. Soft actor-critic (SAC) mitigates this problem by combining stochastic policy optimization and off-policy learning, but its applicability is restricted to distributions whose gradients can be computed through the reparameterization trick. This limitation excludes several important examples such as the beta distribution, which was shown to improve the convergence rate of actor-critic algorithms in high-dimensional continuous control problems thanks to its bounded support. To address this issue, we investigate the use of implicit reparameterization, a powerful technique that extends the class of reparameterizable distributions. In particular, we use implicit reparameterization gradients to train SAC with the beta policy on simulated robot locomotion environments and compare its performance with common baselines. Experimental results show that the beta policy is a viable alternative, as it outperforms the normal policy and is on par with the squashed normal policy, which is the go-to choice for SAC. The code is available at https://github.com/lucadellalib/sac-beta.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2409.04718",
        "abstract url": "https://arxiv.org/abs/2409.04718",
        "title": "Cross-Organ Domain Adaptive Neural Network for Pancreatic Endoscopic Ultrasound Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "cancer",
                "tumor",
                "Endoscopic",
                "Organ",
                "lesion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate segmentation of lesions in pancreatic endoscopic ultrasound (EUS) images is crucial for effective diagnosis and treatment. However, the collection of enough crisp EUS images for effective diagnosis is arduous. Recently, domain adaptation (DA) has been employed to address these challenges by leveraging related knowledge from other domains. Most DA methods only focus on multi-view representations of the same organ, which makes it still tough to clearly depict the tumor lesion area with limited semantic information. Although transferring homogeneous similarity from different organs could benefit the issue, there is a lack of relevant work due to the enormous domain gap between them. To address these challenges, we propose the Cross-Organ Tumor Segmentation Networks (COTS-Nets), consisting of a universal network and an auxiliary network. The universal network utilizes boundary loss to learn common boundary information of different tumors, enabling accurate delineation of tumors in EUS despite limited and low-quality data. Simultaneously, we incorporate consistency loss in the universal network to align the prediction of pancreatic EUS with tumor boundaries from other organs to mitigate the domain gap. To further reduce the cross-organ domain gap, the auxiliary network integrates multi-scale features from different organs, aiding the universal network in acquiring domain-invariant knowledge. Systematic experiments demonstrate that COTS-Nets significantly improves the accuracy of pancreatic cancer diagnosis. Additionally, we developed the Pancreatic Cancer Endoscopic Ultrasound (PCEUS) dataset, comprising 501 pathologically confirmed pancreatic EUS images, to facilitate model development.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04719",
        "abstract url": "https://arxiv.org/abs/2409.04719",
        "title": "Unrolling Plug-and-Play Network for Hyperspectral Unmixing",
        "rating": "-1",
        "keywords": [
            [
                "hyperspectral image"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Deep learning based unmixing methods have received great attention in recent years and achieve remarkable performance. These methods employ a data-driven approach to extract structure features from hyperspectral image, however, they tend to be less physical interpretable. Conventional unmixing methods are with much more interpretability, whereas they require manually designing regularization and choosing penalty parameters. To overcome these limitations, we propose a novel unmixing method by unrolling the plug-and-play unmixing algorithm to conduct the deep architecture. Our method integrates both inner and outer priors. The carefully designed unfolding deep architecture is used to learn the spectral and spatial information from the hyperspectral image, which we refer to as inner priors. Additionally, our approach incorporates deep denoisers that have been pretrained on a large volume of image data to leverage the outer priors. Secondly, we design a dynamic convolution to model the multiscale information. Different scales are fused using an attention module. Experimental results of both synthetic and real datasets demonstrate that our method outperforms compared methods.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04721",
        "abstract url": "https://arxiv.org/abs/2409.04721",
        "title": "Optimal decentralized wavelength control in light sources for lithography",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Pulsed light sources are a critical component of modern lithography, with fine light beam wavelength control paramount for wafer etching accuracy. We study optimal wavelength control by casting it as a decentralized linear quadratic Gaussian (LQG) problem in presence of time-delays. In particular, we consider the multi-optics module (optics and actuators) used for generating the requisite wavelength in light sources as cooperatively interacting systems defined over a directed acyclic graph (DAG). We show that any measurement and other continuous time-delays can be exactly compensated, and the resulting optimal controller implementation at the individual optics-level outperforms any existing wavelength control techniques.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04732",
        "abstract url": "https://arxiv.org/abs/2409.04732",
        "title": "VidLPRO: A $\\underline{Vid}$eo-$\\underline{L}$anguage $\\underline{P}$re-training Framework for $\\underline{Ro}$botic and Laparoscopic Surgery",
        "rating": "-1",
        "keywords": [
            [
                "surgical",
                "Surgery"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We introduce VidLPRO, a novel video-language (VL) pre-training framework designed specifically for robotic and laparoscopic surgery. While existing surgical VL models primarily rely on contrastive learning, we propose a more comprehensive approach to capture the intricate temporal dynamics and align video with language. VidLPRO integrates video-text contrastive learning, video-text matching, and masked language modeling objectives to learn rich VL representations. To support this framework, we present GenSurg+, a carefully curated dataset derived from GenSurgery, comprising 17k surgical video clips paired with captions generated by GPT-4 using transcripts extracted by the Whisper model. This dataset addresses the need for large-scale, high-quality VL data in the surgical domain. Extensive experiments on benchmark datasets, including Cholec80 and AutoLaparo, demonstrate the efficacy of our approach. VidLPRO achieves state-of-the-art performance in zero-shot surgical phase recognition, significantly outperforming existing surgical VL models such as SurgVLP and HecVL. Our model demonstrates improvements of up to 21.5\\% in accuracy and 15.7% in F1 score, setting a new benchmark in the field. Notably, VidLPRO exhibits robust performance even with single-frame inference, while effectively scaling with increased temporal context. Ablation studies reveal the impact of frame sampling strategies on model performance and computational efficiency. These results underscore VidLPRO's potential as a foundation model for surgical video understanding.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04758",
        "abstract url": "https://arxiv.org/abs/2409.04758",
        "title": "SGSeg: Enabling Text-free Inference in Language-guided Segmentation of Chest X-rays via Self-guidance",
        "rating": "-1",
        "keywords": [
            [
                "clinical",
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Segmentation of infected areas in chest X-rays is pivotal for facilitating the accurate delineation of pulmonary structures and pathological anomalies. Recently, multi-modal language-guided image segmentation methods have emerged as a promising solution for chest X-rays where the clinical text reports, depicting the assessment of the images, are used as guidance. Nevertheless, existing language-guided methods require clinical reports alongside the images, and hence, they are not applicable for use in image segmentation in a decision support context, but rather limited to retrospective image analysis after clinical reporting has been completed. In this study, we propose a self-guided segmentation framework (SGSeg) that leverages language guidance for training (multi-modal) while enabling text-free inference (uni-modal), which is the first that enables text-free inference in language-guided segmentation. We exploit the critical location information of both pulmonary and pathological structures depicted in the text reports and introduce a novel localization-enhanced report generation (LERG) module to generate clinical reports for self-guidance. Our LERG integrates an object detector and a location-based attention aggregator, weakly-supervised by a location-aware pseudo-label extraction module. Extensive experiments on a well-benchmarked QaTa-COV19 dataset demonstrate that our SGSeg achieved superior performance than existing uni-modal segmentation methods and closely matched the state-of-the-art performance of multi-modal language-guided segmentation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This preprint has not undergone peer review or any post-submission improvments or corrections"
    },
    {
        "paper id": "2409.04767",
        "abstract url": "https://arxiv.org/abs/2409.04767",
        "title": "Barrier Integral Control for Global Asymptotic Stabilization of Uncertain Nonlinear Systems under Smooth Feedback and Transient Constraints",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "This paper addresses the problem of asymptotic stabilization for high-order control-affine MIMO nonlinear systems with unknown dynamic terms. We introduce Barrier Integral Control, a novel algorithm designed to confine the system's state within a predefined funnel, ensuring adherence to prescribed transient constraints, and asymptotically drive it to zero from any initial condition. The algorithm leverages the innovative integration of a reciprocal barrier function and an error-integral term, featuring smooth feedback control. Notably, it operates without relying on any information or approximation schemes for the (unknown) dynamic terms, which, unlike a large class of previous works, are not assumed to be bounded or to comply with globally Lipschitz/growth conditions. Additionally, the system's trajectory and asymptotic performance are decoupled from the uncertain model, control-gain selection, and initial conditions. Finally, comparative simulation studies validate the effectiveness of the proposed algorithm.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "First version"
    },
    {
        "paper id": "2409.04786",
        "abstract url": "https://arxiv.org/abs/2409.04786",
        "title": "Subexponential Parameterized Algorithms for Hitting Subgraphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "For a finite set $\\mathcal{F}$ of graphs, the $\\mathcal{F}$-Hitting problem aims to compute, for a given graph $G$ (taken from some graph class $\\mathcal{G}$) of $n$ vertices (and $m$ edges) and a parameter $k\\in\\mathbb{N}$, a set $S$ of vertices in $G$ such that $|S|\\leq k$ and $G-S$ does not contain any subgraph isomorphic to a graph in $\\mathcal{F}$. As a generic problem, $\\mathcal{F}$-Hitting subsumes many fundamental vertex-deletion problems that are well-studied in the literature. The $\\mathcal{F}$-Hitting problem admits a simple branching algorithm with running time $2^{O(k)}\\cdot n^{O(1)}$, while it cannot be solved in $2^{o(k)}\\cdot n^{O(1)}$ time on general graphs assuming the ETH. In this paper, we establish a general framework to design subexponential parameterized algorithms for the $\\mathcal{F}$-Hitting problem on a broad family of graph classes. Specifically, our framework yields algorithms that solve $\\mathcal{F}$-Hitting with running time $2^{O(k^c)}\\cdot n+O(m)$ for a constant $c<1$ on any graph class $\\mathcal{G}$ that admits balanced separators whose size is (strongly) sublinear in the number of vertices and polynomial in the size of a maximum clique. Examples include all graph classes of polynomial expansion and many important classes of geometric intersection graphs. Our algorithms also apply to the \\textit{weighted} version of $\\mathcal{F}$-Hitting, where each vertex of $G$ has a weight and the goal is to compute the set $S$ with a minimum weight that satisfies the desired conditions. The core of our framework is an intricate subexponential branching algorithm that reduces an instance of $\\mathcal{F}$-Hitting (on the aforementioned graph classes) to $2^{O(k^c)}$ general hitting-set instances, where the Gaifman graph of each instance has treewidth $O(k^c)$, for some constant $c<1$ depending on $\\mathcal{F}$ and the graph class.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04821",
        "abstract url": "https://arxiv.org/abs/2409.04821",
        "title": "Adjacency Labeling Schemes for Small Classes",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A graph class admits an implicit representation if, for every positive integer $n$, its $n$-vertex graphs have a $O(\\log n)$-bit (adjacency) labeling scheme, i.e., their vertices can be labeled by binary strings of length $O(\\log n)$ such that the presence of an edge between any pair of vertices can be deduced solely from their labels. The famous Implicit Graph Conjecture posited that every hereditary (i.e., closed under taking induced subgraphs) factorial (i.e., containing $2^{O(n \\log n)}$ $n$-vertex graphs) class admits an implicit representation. The conjecture was recently refuted [Hatami and Hatami, FOCS '22], and does not even hold among monotone (i.e., closed under taking subgraphs) factorial classes [Bonnet et al., ICALP '24]. However, monotone small (i.e., containing at most $n! c^n$ many $n$-vertex graphs for some constant $c$) classes do admit implicit representations. This motivates the Small Implicit Graph Conjecture: Every hereditary small class admits an $O(\\log n)$-bit labeling scheme. We provide evidence supporting the Small Implicit Graph Conjecture. First, we show that every small weakly sparse (i.e., excluding some fixed bipartite complete graph as a subgraph) class has an implicit representation. This is a consequence of the following fact of independent interest proved in the paper: Every weakly sparse small class has bounded expansion (hence, in particular, bounded degeneracy). Second, we show that every hereditary small class admits an $O(\\log^3 n)$-bit labeling scheme, which provides a substantial improvement of the best-known polynomial upper bound of $n^{1-\\varepsilon}$ on the size of adjacency labeling schemes for such classes. This is a consequence of another fact of independent interest proved in the paper: Every small class has neighborhood complexity $O(n \\log n)$.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04850",
        "abstract url": "https://arxiv.org/abs/2409.04850",
        "title": "Deep Computer Vision for Solar Physics Big Data: Opportunities and Challenges",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With recent missions such as advanced space-based observatories like the Solar Dynamics Observatory (SDO) and Parker Solar Probe, and ground-based telescopes like the Daniel K. Inouye Solar Telescope (DKIST), the volume, velocity, and variety of data have made solar physics enter a transformative era as solar physics big data (SPBD). With the recent advancement of deep computer vision, there are new opportunities in SPBD for tackling problems that were previously unsolvable. However, there are new challenges arising due to the inherent characteristics of SPBD and deep computer vision models. This vision paper presents an overview of the different types of SPBD, explores new opportunities in applying deep computer vision to SPBD, highlights the unique challenges, and outlines several potential future research directions.",
        "subjects": [
            "cs.CV",
            "astro-ph.SR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04855",
        "abstract url": "https://arxiv.org/abs/2409.04855",
        "title": "Complexity of Deciding the Equality of Matching Numbers",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A matching is said to be disconnected if the saturated vertices induce a disconnected subgraph and induced if the saturated vertices induce a 1-regular graph. The disconnected and induced matching numbers are defined as the maximum cardinality of such matchings, respectively, and are known to be NP-hard to compute. In this paper, we study the relationship between these two parameters and the matching number. In particular, we discuss the complexity of two decision problems; first: deciding if the matching number and disconnected matching number are equal; second: deciding if the disconnected matching number and induced matching number are equal. We show that given a bipartite graph with diameter four, deciding if the matching number and disconnected matching number are equal is NP-complete; the same holds for bipartite graphs with maximum degree three. We characterize diameter three graphs with equal matching number and disconnected matching number, which yields a polynomial time recognition algorithm. Afterwards, we show that deciding if the induced and disconnected matching numbers are equal is co-NP-complete for bipartite graphs of diameter 3. When the induced matching number is large enough compared to the maximum degree, we characterize graphs where these parameters are equal, which results in a polynomial time algorithm for bounded degree graphs.",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04857",
        "abstract url": "https://arxiv.org/abs/2409.04857",
        "title": "IPN-V: The Interplanetary Network Visualizer",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "The Interplanetary Network (IPN) emerges as the backbone for communication between various spacecraft and satellites orbiting distant celestial bodies. This paper introduces the Interplanetary Network Visualizer (IPN-V), a software platform that integrates interplanetary communications planning support, education, and outreach. IPN-V bridges the gap between the complexities of astrodynamics and network engineering by enabling the generation and assessment of dynamic, realistic network topologies that encapsulate the inherent challenges of space communication, such as time-evolving latencies and planetary occlusions. Leveraging the power of Unity 3D and C#, IPN-V provides a user-friendly 3D interface for the interactive visualization of interplanetary networks, incorporating contact tracing models to represent line-of-sight communication constraints accurately. IPN-V supports importing and exporting contact plans compatible with established space communication standards, including NASA's ION and HDTN formats. This paper delineates the conception, architecture, and operational framework of IPN-V while evaluating its performance metrics.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04878",
        "abstract url": "https://arxiv.org/abs/2409.04878",
        "title": "Plug-and-Hide: Provable and Adjustable Diffusion Generative Steganography",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ]
        ],
        "abstract": "Generative Steganography (GS) is a novel technique that utilizes generative models to conceal messages without relying on cover images. Contemporary GS algorithms leverage the powerful generative capabilities of Diffusion Models (DMs) to create high-fidelity stego images. However, these algorithms, while yielding relatively satisfactory generation outcomes and message extraction accuracy, significantly alter modifications to the initial Gaussian noise of DMs, thereby compromising steganographic security. In this paper, we rethink the trade-off among image quality, steganographic security, and message extraction accuracy within Diffusion Generative Steganography (DGS) settings. Our findings reveal that the normality of initial noise of DMs is crucial to these factors and can offer theoretically grounded guidance for DGS design. Based on this insight, we propose a Provable and Adjustable Message Mapping (PA-B2G) approach. It can, on one hand, theoretically guarantee reversible encoding of bit messages from arbitrary distributions into standard Gaussian noise for DMs. On the other hand, its adjustability provides a more natural and fine-grained way to trade off image quality, steganographic security, and message extraction accuracy. By integrating PA-B2G with a probability flow ordinary differential equation, we establish an invertible mapping between secret messages and stego images. PA-B2G can be seamlessly incorporated with most mainstream DMs, such as the Stable Diffusion, without necessitating additional training or fine-tuning. Comprehensive experiments corroborate our theoretical insights regarding the trade-off in DGS settings and demonstrate the effectiveness of our DGS algorithm in producing high-quality stego images while preserving desired levels of steganographic security and extraction accuracy.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04884",
        "abstract url": "https://arxiv.org/abs/2409.04884",
        "title": "Protecting residential electrical panels and service through model predictive control: A field study",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Residential electrification - replacing fossil-fueled appliances and vehicles with electric machines - can significantly reduce greenhouse gas emissions and air pollution. However, installing electric appliances or vehicle charging in a residential building can sharply increase its current draws. In older housing, high current draws can jeopardize electrical infrastructure, such as circuit breaker panels or electrical service (the wires that connect a building to the distribution grid). Upgrading electrical infrastructure can entail long delays and high costs, so poses a significant barrier to electrification. This paper develops and field-tests a control system that avoids the need for electrical upgrades by keeping an electrified home's total current draw within the safe limits of its panel and service. In the proposed control architecture, a high-level controller plans device set-points over a rolling prediction horizon. A low-level controller monitors real-time conditions and ramps down devices if necessary. The control system was tested in an occupied, electrified single-family house with code-minimum insulation, an air-to-air heat pump and backup resistance heat, a resistance water heater, and a plug-in hybrid electric vehicle with Level I charging. The field tests spanned 31 winter days with outdoor temperatures as low as -20 C. The control system maintained the whole-home current within the safe limits of electrical panels and service rated at 100 A, a common rating for older houses in North America, by adjusting only the temperature set-points of the heat pump and water heater. Simulations suggest that the same 100 A limit could accommodate a second electric vehicle with Level II charging. The proposed control system could allow older homes to safely electrify without upgrading electrical panels or service, saving a typical household on the order of $2,000 to $10,000.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04885",
        "abstract url": "https://arxiv.org/abs/2409.04885",
        "title": "A new approach to bipartite stable matching optimization",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "As a common generalization of previously solved optimization problems concerning bipartite stable matchings, we describe a strongly polynomial network flow based algorithm for computing $\\ell$ disjoint stable matchings with minimum total cost. The major observation behind the approach is that stable matchings, as edge sets, can be represented as certain cuts of an associated directed graph. This allows us to use results on disjoint cuts directly to answer questions about disjoint stable matchings. We also provide a construction that represents stable matchings as maximum-size antichains in a partially ordered set (poset), which enables us to apply the theorems of Dilworth, Mirsky, Greene and Kleitman directly to stable matchings. Another consequence of these approaches is a min-max formula for the minimum number of stable matchings covering all stable edges.",
        "subjects": [
            "cs.GT",
            "cs.DS",
            "math.CO"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2409.04921",
        "abstract url": "https://arxiv.org/abs/2409.04921",
        "title": "Fair Allocation of Bandwidth At Edge Servers For Concurrent Hierarchical Federated Learning",
        "rating": "-1",
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "This paper explores concurrent FL processes within a three-tier system, with edge servers between edge devices and FL servers. A challenge in this setup is the limited bandwidth from edge devices to edge servers. Thus, allocating the bandwidth efficiently and fairly to support simultaneous FL processes becomes crucial. We propose a game-theoretic approach to model the bandwidth allocation problem and develop distributed and centralized heuristic schemes to find an approximate Nash Equilibrium of the game. We proposed the approach mentioned above using centralized and entirely distributed assumptions. Through rigorous analysis and experimentation, we demonstrate that our schemes efficiently and fairly assign the bandwidth to the FL processes for centralized and distributed solutions and outperform a baseline scheme where each edge server assigns bandwidth proportionally to the FL servers' requests that it receives. The proposed distributed and centralized schemes have comptetive performance.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04930",
        "abstract url": "https://arxiv.org/abs/2409.04930",
        "title": "PIXHELL Attack: Leaking Sensitive Information from Air-Gap Computers via `Singing Pixels'",
        "rating": "-1",
        "keywords": [
            [
                "Attack"
            ]
        ],
        "abstract": "Air-gapped systems are disconnected from the Internet and other networks because they contain or process sensitive data. However, it is known that attackers can use computer speakers to leak data via sound to circumvent the air-gap defense. To cope with this threat, when highly sensitive data is involved, the prohibition of loudspeakers or audio hardware might be enforced. This measure is known as an `audio gap'. In this paper, we present PIXHELL, a new type of covert channel attack allowing hackers to leak information via noise generated by the pixels on the screen. No audio hardware or loudspeakers is required. Malware in the air-gap and audio-gap computers generates crafted pixel patterns that produce noise in the frequency range of 0 - 22 kHz. The malicious code exploits the sound generated by coils and capacitors to control the frequencies emanating from the screen. Acoustic signals can encode and transmit sensitive information. We present the adversarial attack model, cover related work, and provide technical background. We discuss bitmap generation and correlated acoustic signals and provide implementation details on the modulation and demodulation process. We evaluated the covert channel on various screens and tested it with different types of information. We also discuss \\textit{evasion and stealth} using low-brightness patterns that appear like black, turned-off screens. Finally, we propose a set of countermeasures. Our test shows that with a PIXHELL attack, textual and binary data can be exfiltrated from air-gapped, audio-gapped computers at a distance of 2m via sound modulated from LCD screens.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Version of this paper accepted to 2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)"
    },
    {
        "paper id": "2409.04952",
        "abstract url": "https://arxiv.org/abs/2409.04952",
        "title": "Deep Bayesian Active Learning-to-Rank with Relative Annotation for Estimation of Ulcerative Colitis Severity",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "disease",
                "endoscopic"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic image-based severity estimation is an important task in computer-aided diagnosis. Severity estimation by deep learning requires a large amount of training data to achieve a high performance. In general, severity estimation uses training data annotated with discrete (i.e., quantized) severity labels. Annotating discrete labels is often difficult in images with ambiguous severity, and the annotation cost is high. In contrast, relative annotation, in which the severity between a pair of images is compared, can avoid quantizing severity and thus makes it easier. We can estimate relative disease severity using a learning-to-rank framework with relative annotations, but relative annotation has the problem of the enormous number of pairs that can be annotated. Therefore, the selection of appropriate pairs is essential for relative annotation. In this paper, we propose a deep Bayesian active learning-to-rank that automatically selects appropriate pairs for relative annotation. Our method preferentially annotates unlabeled pairs with high learning efficiency from the model uncertainty of the samples. We prove the theoretical basis for adapting Bayesian neural networks to pairwise learning-to-rank and demonstrate the efficiency of our method through experiments on endoscopic images of ulcerative colitis on both private and public datasets. We also show that our method achieves a high performance under conditions of significant class imbalance because it automatically selects samples from the minority classes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 8 figures, accepted in Medical Image Analysis 2024"
    },
    {
        "paper id": "2409.04965",
        "abstract url": "https://arxiv.org/abs/2409.04965",
        "title": "Enhancing Socially-Aware Robot Navigation through Bidirectional Natural Language Conversation",
        "rating": "-1",
        "keywords": [
            [
                "Robot",
                "Navigation"
            ]
        ],
        "abstract": "Robot navigation is an important research field with applications in various domains. However, traditional approaches often prioritize efficiency and obstacle avoidance, neglecting a nuanced understanding of human behavior or intent in shared spaces. With the rise of service robots, there's an increasing emphasis on endowing robots with the capability to navigate and interact in complex real-world environments. Socially aware navigation has recently become a key research area. However, existing work either predicts pedestrian movements or simply emits alert signals to pedestrians, falling short of facilitating genuine interactions between humans and robots. In this paper, we introduce the Hybrid Soft Actor-Critic with Large Language Model (HSAC-LLM), an innovative model designed for socially-aware navigation in robots. This model seamlessly integrates deep reinforcement learning with large language models, enabling it to predict both continuous and discrete actions for navigation. Notably, HSAC-LLM facilitates bidirectional interaction based on natural language with pedestrian models. When a potential collision with pedestrians is detected, the robot can initiate or respond to communications with pedestrians, obtaining and executing subsequent avoidance strategies. Experimental results in 2D simulation, the Gazebo environment, and the real-world environment demonstrate that HSAC-LLM not only efficiently enables interaction with humans but also exhibits superior performance in navigation and obstacle avoidance compared to state-of-the-art DRL algorithms. We believe this innovative paradigm opens up new avenues for effective and socially aware human-robot interactions in dynamic environments. Videos are available at https://hsacllm.github.io/.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04723",
        "abstract url": "https://arxiv.org/abs/2409.04723",
        "title": "NapTune: Efficient Model Tuning for Mood Classification using Previous Night's Sleep Measures along with Wearable Time-series",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Sleep is known to be a key factor in emotional regulation and overall mental health. In this study, we explore the integration of sleep measures from the previous night into wearable-based mood recognition. To this end, we propose NapTune, a novel prompt-tuning framework that utilizes sleep-related measures as additional inputs to a frozen pre-trained wearable time-series encoder by adding and training lightweight prompt parameters to each Transformer layer. Through rigorous empirical evaluation, we demonstrate that the inclusion of sleep data using NapTune not only improves mood recognition performance across different wearable time-series namely ECG, PPG, and EDA, but also makes it more sample-efficient. Our method demonstrates significant improvements over the best baselines and unimodal variants. Furthermore, we analyze the impact of adding sleep-related measures on recognizing different moods as well as the influence of individual sleep-related measures.",
        "subjects": [
            "eess.SP",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at ICMI 2024"
    },
    {
        "paper id": "2409.04728",
        "abstract url": "https://arxiv.org/abs/2409.04728",
        "title": "Urban traffic analysis and forecasting through shared Koopman eigenmodes",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predicting traffic flow in data-scarce cities is challenging due to limited historical data. To address this, we leverage transfer learning by identifying periodic patterns common to data-rich cities using a customized variant of Dynamic Mode Decomposition (DMD): constrained Hankelized DMD (TrHDMD). This method uncovers common eigenmodes (urban heartbeats) in traffic patterns and transfers them to data-scarce cities, significantly enhancing prediction performance. TrHDMD reduces the need for extensive training datasets by utilizing prior knowledge from other cities. By applying Koopman operator theory to multi-city loop detector data, we identify stable, interpretable, and time-invariant traffic modes. Injecting ``urban heartbeats'' into forecasting tasks improves prediction accuracy and has the potential to enhance traffic management strategies for cities with varying data infrastructures. Our work introduces cross-city knowledge transfer via shared Koopman eigenmodes, offering actionable insights and reliable forecasts for data-scarce urban environments.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04744",
        "abstract url": "https://arxiv.org/abs/2409.04744",
        "title": "LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial",
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The uncertainty inherent in the environmental transition model of Reinforcement Learning (RL) necessitates a careful balance between exploration and exploitation to optimize the use of computational resources for accurately estimating an agent's expected reward. Achieving balance in control systems is particularly challenging in scenarios with sparse rewards. However, given the extensive prior knowledge available for many environments, it is redundant to begin learning from scratch in such settings. To address this, we introduce \\textbf{L}anguage \\textbf{M}odel \\textbf{G}uided \\textbf{T}rade-offs (i.e., \\textbf{LMGT}), a novel, sample-efficient framework that leverages the comprehensive prior knowledge embedded in Large Language Models (LLMs) and their adeptness at processing non-standard data forms, such as wiki tutorials. LMGT proficiently manages the exploration-exploitation trade-off by employing reward shifts guided by LLMs, which direct agents' exploration endeavors, thereby improving sample efficiency. We have thoroughly tested LMGT across various RL tasks and deployed it in industrial-grade RL recommendation systems, where it consistently outperforms baseline methods. The results indicate that our framework can significantly reduce the time cost required during the training phase in RL.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04794",
        "abstract url": "https://arxiv.org/abs/2409.04794",
        "title": "Beyond One-Time Validation: A Framework for Adaptive Validation of Prognostic and Diagnostic AI-based Medical Devices",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "healthcare",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Prognostic and diagnostic AI-based medical devices hold immense promise for advancing healthcare, yet their rapid development has outpaced the establishment of appropriate validation methods. Existing approaches often fall short in addressing the complexity of practically deploying these devices and ensuring their effective, continued operation in real-world settings. Building on recent discussions around the validation of AI models in medicine and drawing from validation practices in other fields, a framework to address this gap is presented. It offers a structured, robust approach to validation that helps ensure device reliability across differing clinical environments. The primary challenges to device performance upon deployment are discussed while highlighting the impact of changes related to individual healthcare institutions and operational processes. The presented framework emphasizes the importance of repeating validation and fine-tuning during deployment, aiming to mitigate these issues while being adaptable to challenges unforeseen during device development. The framework is also positioned within the current US and EU regulatory landscapes, underscoring its practical viability and relevance considering regulatory requirements. Additionally, a practical example demonstrating potential benefits of the framework is presented. Lastly, guidance on assessing model performance is offered and the importance of involving clinical stakeholders in the validation and fine-tuning process is discussed.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": "13 pages, 1 figure"
    },
    {
        "paper id": "2409.04922",
        "abstract url": "https://arxiv.org/abs/2409.04922",
        "title": "Nearest Neighbor CCP-Based Molecular Sequence Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "biological",
                "disease"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Molecular sequence analysis is crucial for comprehending several biological processes, including protein-protein interactions, functional annotation, and disease classification. The large number of sequences and the inherently complicated nature of protein structures make it challenging to analyze such data. Finding patterns and enhancing subsequent research requires the use of dimensionality reduction and feature selection approaches. Recently, a method called Correlated Clustering and Projection (CCP) has been proposed as an effective method for biological sequencing data. The CCP technique is still costly to compute even though it is effective for sequence visualization. Furthermore, its utility for classifying molecular sequences is still uncertain. To solve these two problems, we present a Nearest Neighbor Correlated Clustering and Projection (CCP-NN)-based technique for efficiently preprocessing molecular sequence data. To group related molecular sequences and produce representative supersequences, CCP makes use of sequence-to-sequence correlations. As opposed to conventional methods, CCP doesn't rely on matrix diagonalization, therefore it can be applied to a range of machine-learning problems. We estimate the density map and compute the correlation using a nearest-neighbor search technique. We performed molecular sequence classification using CCP and CCP-NN representations to assess the efficacy of our proposed approach. Our findings show that CCP-NN considerably improves classification task accuracy as well as significantly outperforms CCP in terms of computational runtime.",
        "subjects": [
            "q-bio.GN",
            "cs.AI",
            "cs.CC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04972",
        "abstract url": "https://arxiv.org/abs/2409.04972",
        "title": "Balancing Security and Accuracy: A Novel Federated Learning Approach for Cyberattack Detection in Blockchain Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a novel Collaborative Cyberattack Detection (CCD) system aimed at enhancing the security of blockchain-based data-sharing networks by addressing the complex challenges associated with noise addition in federated learning models. Leveraging the theoretical principles of differential privacy, our approach strategically integrates noise into trained sub-models before reconstructing the global model through transmission. We systematically explore the effects of various noise types, i.e., Gaussian, Laplace, and Moment Accountant, on key performance metrics, including attack detection accuracy, deep learning model convergence time, and the overall runtime of global model generation. Our findings reveal the intricate trade-offs between ensuring data privacy and maintaining system performance, offering valuable insights into optimizing these parameters for diverse CCD environments. Through extensive simulations, we provide actionable recommendations for achieving an optimal balance between data protection and system efficiency, contributing to the advancement of secure and reliable blockchain networks.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2409.04730",
        "abstract url": "https://arxiv.org/abs/2409.04730",
        "title": "IR2: Implicit Rendezvous for Robotic Exploration Teams under Sparse Intermittent Connectivity",
        "rating": "-2",
        "keywords": [
            [
                "robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Information sharing is critical in time-sensitive and realistic multi-robot exploration, especially for smaller robotic teams in large-scale environments where connectivity may be sparse and intermittent. Existing methods often overlook such communication constraints by assuming unrealistic global connectivity. Other works account for communication constraints (by maintaining close proximity or line of sight during information exchange), but are often inefficient. For instance, preplanned rendezvous approaches typically involve unnecessary detours resulting from poorly timed rendezvous, while pursuit-based approaches often result in short-sighted decisions due to their greedy nature. We present IR2, a deep reinforcement learning approach to information sharing for multi-robot exploration. Leveraging attention-based neural networks trained via reinforcement and curriculum learning, IR2 allows robots to effectively reason about the longer-term trade-offs between disconnecting for solo exploration and reconnecting for information sharing. In addition, we propose a hierarchical graph formulation to maintain a sparse yet informative graph, enabling our approach to scale to large-scale environments. We present simulation results in three large-scale Gazebo environments, which show that our approach yields 6.6-34.1% shorter exploration paths and significantly improved mapped area consistency among robots when compared to state-of-the-art baselines. Our simulation training and testing code is available at https://github.com/marmotlab/IR2.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2409.04746",
        "abstract url": "https://arxiv.org/abs/2409.04746",
        "title": "Hybrid Quantum Noise Approximation and Pattern Analysis on Parameterized Component Distributions",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Noise is a vital factor in determining the accuracy of processing the information of the quantum channel. One must consider classical noise effects associated with quantum noise sources for more realistic modelling of quantum channels. A hybrid quantum noise model incorporating both quantum Poisson noise and classical additive white Gaussian noise (AWGN) can be interpreted as an infinite mixture of Gaussians with weightage from the Poisson distribution. The entropy measure of this function is difficult to calculate. This research developed how the infinite mixture can be well approximated by a finite mixture distribution depending on the Poisson parametric setting compared to the number of mixture components. The mathematical analysis of the characterization of hybrid quantum noise has been demonstrated based on Gaussian and Poisson parametric analysis. This helps in the pattern analysis of the parametric values of the component distribution, and it also helps in the calculation of hybrid noise entropy to understand hybrid quantum noise better.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04764",
        "abstract url": "https://arxiv.org/abs/2409.04764",
        "title": "Should I Stay or Should I Go: A Learning Approach for Drone-based Sensing Applications",
        "rating": "-2",
        "keywords": [
            [
                "Drone"
            ]
        ],
        "abstract": "Multicopter drones are becoming a key platform in several application domains, enabling precise on-the-spot sensing and/or actuation. We focus on the case where the drone must process the sensor data in order to decide, depending on the outcome, whether it needs to perform some additional action, e.g., more accurate sensing or some form of actuation. On the one hand, waiting for the computation to complete may waste time, if it turns out that no further action is needed. On the other hand, if the drone starts moving toward the next point of interest before the computation ends, it may need to return back to the previous point, if some action needs to be taken. In this paper, we propose a learning approach that enables the drone to take informed decisions about whether to wait for the result of the computation (or not), based on past experience gathered from previous missions. Through an extensive evaluation, we show that the proposed approach, when properly configured, outperforms several static policies, up to 25.8%, over a wide variety of different scenarios where the probability of some action being required at a given point of interest remains stable as well as for scenarios where this probability varies in time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "9 pages, 9 figures"
    },
    {
        "paper id": "2409.04768",
        "abstract url": "https://arxiv.org/abs/2409.04768",
        "title": "Medical Image Segmentation via Single-Source Domain Generalization with Random Amplitude Spectrum Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The field of medical image segmentation is challenged by domain generalization (DG) due to domain shifts in clinical datasets. The DG challenge is exacerbated by the scarcity of medical data and privacy concerns. Traditional single-source domain generalization (SSDG) methods primarily rely on stacking data augmentation techniques to minimize domain discrepancies. In this paper, we propose Random Amplitude Spectrum Synthesis (RASS) as a training augmentation for medical images. RASS enhances model generalization by simulating distribution changes from a frequency perspective. This strategy introduces variability by applying amplitude-dependent perturbations to ensure broad coverage of potential domain variations. Furthermore, we propose random mask shuffle and reconstruction components, which can enhance the ability of the backbone to process structural information and increase resilience intra- and cross-domain changes. The proposed Random Amplitude Spectrum Synthesis for Single-Source Domain Generalization (RAS^4DG) is validated on 3D fetal brain images and 2D fundus photography, and achieves an improved DG segmentation performance compared to other SSDG models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 4 figures, Medical Image Computing and Computer Assisted Intervention 2024"
    },
    {
        "paper id": "2409.04785",
        "abstract url": "https://arxiv.org/abs/2409.04785",
        "title": "Simulation and optimization of computed torque control 3 DOF RRR manipulator using MATLAB",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "Robot manipulators have become a significant tool for production industries due to their advantages in high speed, accuracy, safety, and repeatability. This paper simulates and optimizes the design of a 3-DOF articulated robotic manipulator (RRR Configuration). The forward and inverse dynamic models are utilized. The trajectory is planned using the end effector's required initial position. A torque compute model is used to calculate the physical end effector's trajectory, position, and velocity. The MATLAB Simulink platform is used for all simulations of the RRR manipulator. With the aid of MATLAB, we primarily focused on manipulator control of the robot using a calculated torque control strategy to achieve the required position.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04810",
        "abstract url": "https://arxiv.org/abs/2409.04810",
        "title": "Debias Can be Unreliable: Mitigating Bias Issue in Evaluating Debiasing Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recent work has improved recommendation models remarkably by equipping them with debiasing methods. Due to the unavailability of fully-exposed datasets, most existing approaches resort to randomly-exposed datasets as a proxy for evaluating debiased models, employing traditional evaluation scheme to represent the recommendation performance. However, in this study, we reveal that traditional evaluation scheme is not suitable for randomly-exposed datasets, leading to inconsistency between the Recall performance obtained using randomly-exposed datasets and that obtained using fully-exposed datasets. Such inconsistency indicates the potential unreliability of experiment conclusions on previous debiasing techniques and calls for unbiased Recall evaluation using randomly-exposed datasets. To bridge the gap, we propose the Unbiased Recall Evaluation (URE) scheme, which adjusts the utilization of randomly-exposed datasets to unbiasedly estimate the true Recall performance on fully-exposed datasets. We provide theoretical evidence to demonstrate the rationality of URE and perform extensive experiments on real-world datasets to validate its soundness.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2409.04812",
        "abstract url": "https://arxiv.org/abs/2409.04812",
        "title": "Power Line Aerial Image Restoration under dverse Weather: Datasets and Baselines",
        "rating": "-2",
        "keywords": [
            [
                "deraining"
            ],
            [
                "Image Restoration",
                "haze",
                "dehazing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Power Line Autonomous Inspection (PLAI) plays a crucial role in the construction of smart grids due to its great advantages of low cost, high efficiency, and safe operation. PLAI is completed by accurately detecting the electrical components and defects in the aerial images captured by Unmanned Aerial Vehicles (UAVs). However, the visible quality of aerial images is inevitably degraded by adverse weather like haze, rain, or snow, which are found to drastically decrease the detection accuracy in our research. To circumvent this problem, we propose a new task of Power Line Aerial Image Restoration under Adverse Weather (PLAIR-AW), which aims to recover clean and high-quality images from degraded images with bad weather thus improving detection performance for PLAI. In this context, we are the first to release numerous corresponding datasets, namely, HazeCPLID, HazeTTPLA, HazeInsPLAD for power line aerial image dehazing, RainCPLID, RainTTPLA, RainInsPLAD for power line aerial image deraining, SnowCPLID, SnowInsPLAD for power line aerial image desnowing, which are synthesized upon the public power line aerial image datasets of CPLID, TTPLA, InsPLAD following the mathematical models. Meanwhile, we select numerous state-of-the-art methods from image restoration community as the baseline methods for PLAIR-AW. At last, we conduct large-scale empirical experiments to evaluate the performance of baseline methods on the proposed datasets. The proposed datasets and trained models are available at https://github.com/ntuhubin/PLAIR-AW.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04827",
        "abstract url": "https://arxiv.org/abs/2409.04827",
        "title": "Incorporate LLMs with Influential Recommender System",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Recommender systems have achieved increasing accuracy over the years. However, this precision often leads users to narrow their interests, resulting in issues such as limited diversity and the creation of echo chambers. Current research addresses these challenges through proactive recommender systems by recommending a sequence of items (called influence path) to guide user interest in the target item. However, existing methods struggle to construct a coherent influence path that builds up with items the user is likely to enjoy. In this paper, we leverage the Large Language Model's (LLMs) exceptional ability for path planning and instruction following, introducing a novel approach named LLM-based Influence Path Planning (LLM-IPP). Our approach maintains coherence between consecutive recommendations and enhances user acceptability of the recommended items. To evaluate LLM-IPP, we implement various user simulators and metrics to measure user acceptability and path coherence. Experimental results demonstrate that LLM-IPP significantly outperforms traditional proactive recommender systems. This study pioneers the integration of LLMs into proactive recommender systems, offering a reliable and user-engaging methodology for future recommendation technologies.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "5 pages, 1 figure"
    },
    {
        "paper id": "2409.04842",
        "abstract url": "https://arxiv.org/abs/2409.04842",
        "title": "Reinforcement Learning for Rate Maximization in IRS-aided OWC Networks",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Optical wireless communication (OWC) is envisioned as one of the main enabling technologies of 6G networks, complementing radio frequency (RF) systems to provide high data rates. One of the crucial issues in indoor OWC is service interruptions due to blockages that obstruct the line of sight (LoS) between users and their access points (APs). Recently, reflecting surfaces referred to as intelligent reflecting surfaces (IRSs) have been considered to provide improved connectivity in OWC systems by reflecting AP signals toward users. In this study, we investigate the integration of IRSs into an indoor OWC system to improve the sum rate of the users and to ensure service continuity. We formulate an optimization problem for sum rate maximization, where the allocation of both APs and mirror elements of IRSs to users is determined to enhance the aggregate data rate. Moreover, reinforcement learning (RL) algorithms, specifically Q-learning and SARSA algorithms, are proposed to provide real-time solutions with low complexity and without prior system knowledge. The results show that the RL algorithms achieve near-optimal solutions that are close to the solutions of mixed integer linear programming (MILP). The results also show that the proposed scheme achieves up to a 45% increase in data rate compared to a traditional scheme that optimizes only the allocation of APs while the mirror elements are assigned to users based on the distance.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6Pages, 5 Figures"
    },
    {
        "paper id": "2409.04888",
        "abstract url": "https://arxiv.org/abs/2409.04888",
        "title": "A Quantitative Approach for Evaluating Disease Focus and Interpretability of Deep Learning Models for Alzheimer's Disease Classification",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "diagnosis",
                "MRI",
                "Disease",
                "clinical",
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning (DL) models have shown significant potential in Alzheimer's Disease (AD) classification. However, understanding and interpreting these models remains challenging, which hinders the adoption of these models in clinical practice. Techniques such as saliency maps have been proven effective in providing visual and empirical clues about how these models work, but there still remains a gap in understanding which specific brain regions DL models focus on and whether these brain regions are pathologically associated with AD. To bridge such gap, in this study, we developed a quantitative disease-focusing strategy to first enhance the interpretability of DL models using saliency maps and brain segmentations; then we propose a disease-focus (DF) score that quantifies how much a DL model focuses on brain areas relevant to AD pathology based on clinically known MRI-based pathological regions of AD. Using this strategy, we compared several state-of-the-art DL models, including a baseline 3D ResNet model, a pretrained MedicalNet model, and a MedicalNet with data augmentation to classify patients with AD vs. cognitive normal patients using MRI data; then we evaluated these models in terms of their abilities to focus on disease-relevant regions. Our results show interesting disease-focusing patterns with different models, particularly characteristic patterns with the pretrained models and data augmentation, and also provide insight into their classification performance. These results suggest that the approach we developed for quantitatively assessing the abilities of DL models to focus on disease-relevant regions may help improve interpretability of these models for AD classification and facilitate their adoption for AD diagnosis in clinical practice. The code is publicly available at https://github.com/Liang-lt/ADNI.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04900",
        "abstract url": "https://arxiv.org/abs/2409.04900",
        "title": "XR Prototyping of Mixed Reality Visualizations: Compensating Interaction Latency for a Medical Imaging Robot",
        "rating": "-2",
        "keywords": [
            [
                "time-efficient"
            ],
            [
                "Robot"
            ],
            [
                "Medical"
            ]
        ],
        "abstract": "Researching novel user experiences in medicine is challenging due to limited access to equipment and strict ethical protocols. Extended Reality (XR) simulation technologies offer a cost- and time-efficient solution for developing interactive systems. Recent work has shown Extended Reality Prototyping (XRP)'s potential, but its applicability to specific domains like controlling complex machinery needs further exploration. This paper explores the benefits and limitations of XRP in controlling a mobile medical imaging robot. We compare two XR visualization techniques to reduce perceived latency between user input and robot activation. Our XRP validation study demonstrates its potential for comparative studies, but identifies a gap in modeling human behavior in the analytic XRP validation framework.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04920",
        "abstract url": "https://arxiv.org/abs/2409.04920",
        "title": "MoistNet: Machine Vision-based Deep Learning Models for Wood Chip Moisture Content Measurement",
        "rating": "-2",
        "keywords": [
            [
                "Architecture Search",
                "NAS"
            ],
            [
                "biofuel"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Quick and reliable measurement of wood chip moisture content is an everlasting problem for numerous forest-reliant industries such as biofuel, pulp and paper, and bio-refineries. Moisture content is a critical attribute of wood chips due to its direct relationship with the final product quality. Conventional techniques for determining moisture content, such as oven-drying, possess some drawbacks in terms of their time-consuming nature, potential sample damage, and lack of real-time feasibility. Furthermore, alternative techniques, including NIR spectroscopy, electrical capacitance, X-rays, and microwaves, have demonstrated potential; nevertheless, they are still constrained by issues related to portability, precision, and the expense of the required equipment. Hence, there is a need for a moisture content determination method that is instant, portable, non-destructive, inexpensive, and precise. This study explores the use of deep learning and machine vision to predict moisture content classes from RGB images of wood chips. A large-scale image dataset comprising 1,600 RGB images of wood chips has been collected and annotated with ground truth labels, utilizing the results of the oven-drying technique. Two high-performing neural networks, MoistNetLite and MoistNetMax, have been developed leveraging Neural Architecture Search (NAS) and hyperparameter optimization. The developed models are evaluated and compared with state-of-the-art deep learning models. Results demonstrate that MoistNetLite achieves 87% accuracy with minimal computational overhead, while MoistNetMax exhibits exceptional precision with a 91% accuracy in wood chip moisture content class prediction. With improved accuracy and faster prediction speed, our proposed MoistNet models hold great promise for the wood chip processing industry.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04944",
        "abstract url": "https://arxiv.org/abs/2409.04944",
        "title": "Delay Balancing with Clock-Follow-Data: Optimizing Area Delay Trade-offs for Robust Rapid Single Flux Quantum Circuits",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "This paper proposes an algorithm for synthesis of clock-follow-data designs that provides robustness against timing violations for RSFQ circuits while maintaining high performance and minimizing area costs. Since superconducting logic gates must be clocked, managing data flow is a challenging problem that often requires the insertion of many path balancing D Flips (DFFs) to properly sequence data, leading to a substantial increase in area. To address this challenge, we present an algorithm to insert DFFs into clock-follow-data RSFQ circuits that partially balances the delays within the circuit to achieve a target throughput while minimizing area. Our algorithm can account for expected timing variations and, by adjusting the bias of the clock network and clock frequency, we can mitigate unexpected timing violations post-fabrication. Quantifying the benefits of our approach with a benchmark suite with nominal delays, our designs offer an average 1.48x improvement in area delay product (ADP) over high frequency full path balancing (FPB) designs and a 2.07x improvement in ADP over the state of the art robust circuits provided by state-of-the-art (SOTA) multi-phase clocking solutions.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04961",
        "abstract url": "https://arxiv.org/abs/2409.04961",
        "title": "Heterogeneous LiDAR Dataset for Benchmarking Robust Localization in Diverse Degenerate Scenarios",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "SLAM"
            ]
        ],
        "abstract": "The ability to estimate pose and generate maps using 3D LiDAR significantly enhances robotic system autonomy. However, existing open-source datasets lack representation of geometrically degenerate environments, limiting the development and benchmarking of robust LiDAR SLAM algorithms. To address this gap, we introduce GEODE, a comprehensive multi-LiDAR, multi-scenario dataset specifically designed to include real-world geometrically degenerate environments. GEODE comprises 64 trajectories spanning over 64 kilometers across seven diverse settings with varying degrees of degeneracy. The data was meticulously collected to promote the development of versatile algorithms by incorporating various LiDAR sensors, stereo cameras, IMUs, and diverse motion conditions. We evaluate state-of-the-art SLAM approaches using the GEODE dataset to highlight current limitations in LiDAR SLAM techniques. This extensive dataset will be publicly available at https://geode.github.io, supporting further advancements in LiDAR-based SLAM.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "15 pages, 9 figures, 6 tables. Submitted for IJRR dataset paper"
    },
    {
        "paper id": "2409.04970",
        "abstract url": "https://arxiv.org/abs/2409.04970",
        "title": "A response-adaptive multi-arm design for continuous endpoints based on a weighted information measure",
        "rating": "-2",
        "keywords": [
            [
                "clinical"
            ]
        ],
        "abstract": "Multi-arm trials are gaining interest in practice given the statistical and logistical advantages that they can offer. The standard approach is to use a fixed (throughout the trial) allocation ratio, but there is a call for making it adaptive and skewing the allocation of patients towards better performing arms. However, among other challenges, it is well-known that these approaches might suffer from lower statistical power. We present a response-adaptive design for continuous endpoints which explicitly allows to control the trade-off between the number of patients allocated to the 'optimal' arm and the statistical power. Such a balance is achieved through the calibration of a tuning parameter, and we explore various strategies to effectively select it. The proposed criterion is based on a context-dependent information measure which gives a greater weight to those treatment arms which have characteristics close to a pre-specified clinical target. We also introduce a simulation-based hypothesis testing procedure which focuses on selecting the target arm, discussing strategies to effectively control the type-I error rate. The potential advantage of the proposed criterion over currently used alternatives is evaluated in simulations, and its practical implementation is illustrated in the context of early Phase IIa proof-of-concept oncology clinical trials.",
        "subjects": [
            "stat.ME",
            "cs.IT",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04737",
        "abstract url": "https://arxiv.org/abs/2409.04737",
        "title": "CrysAtom: Distributed Representation of Atoms for Crystal Property Prediction",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "graphs"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Application of artificial intelligence (AI) has been ubiquitous in the growth of research in the areas of basic sciences. Frequent use of machine learning (ML) and deep learning (DL) based methodologies by researchers has resulted in significant advancements in the last decade. These techniques led to notable performance enhancements in different tasks such as protein structure prediction, drug-target binding affinity prediction, and molecular property prediction. In material science literature, it is well-known that crystalline materials exhibit topological structures. Such topological structures may be represented as graphs and utilization of graph neural network (GNN) based approaches could help encoding them into an augmented representation space. Primarily, such frameworks adopt supervised learning techniques targeted towards downstream property prediction tasks on the basis of electronic properties (formation energy, bandgap, total energy, etc.) and crystalline structures. Generally, such type of frameworks rely highly on the handcrafted atom feature representations along with the structural representations. In this paper, we propose an unsupervised framework namely, CrysAtom, using untagged crystal data to generate dense vector representation of atoms, which can be utilized in existing GNN-based property predictor models to accurately predict important properties of crystals. Empirical results show that our dense representation embeds chemical properties of atoms and enhance the performance of the baseline property predictor models significantly.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04849",
        "abstract url": "https://arxiv.org/abs/2409.04849",
        "title": "FedModule: A Modular Federated Learning Framework",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) has been widely adopted across various applications, such as healthcare, finance, and smart cities. However, as experimental scenarios become more complex, existing FL frameworks and benchmarks have struggled to keep pace. This paper introduces FedModule, a flexible and extensible FL experimental framework that has been open-sourced to support diverse FL paradigms and provide comprehensive benchmarks for complex experimental scenarios. FedModule adheres to the \"one code, all scenarios\" principle and employs a modular design that breaks the FL process into individual components, allowing for the seamless integration of different FL paradigms. The framework supports synchronous, asynchronous, and personalized federated learning, with over 20 implemented algorithms. Experiments conducted on public datasets demonstrate the flexibility and extensibility of FedModule. The framework offers multiple execution modes-including linear, threaded, process-based, and distributed-enabling users to tailor their setups to various experimental needs. Additionally, FedModule provides extensive logging and testing capabilities, which facilitate detailed performance analysis of FL algorithms. Comparative evaluations against existing FL toolkits, such as TensorFlow Federated, PySyft, Flower, and FLGo, highlight FedModule's superior scalability, flexibility, and comprehensive benchmark support. By addressing the limitations of current FL frameworks, FedModule marks a significant advancement in FL experimentation, providing researchers and practitioners with a robust tool for developing and evaluating FL algorithms across a wide range of scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04926",
        "abstract url": "https://arxiv.org/abs/2409.04926",
        "title": "A $\u0394$-evaluation function for column permutation problems",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this study, a new $\u0394$-evaluation method is introduced for solving a column permutation problem defined on a sparse binary matrix with the consecutive ones property. This problem models various $\\mathcal{NP}$-hard problems in graph theory and industrial manufacturing contexts. The computational experiments compare the processing time of the $\u0394$-evaluation method with two other methods used in well-known local search procedures. The study considers a comprehensive set of instances of well-known problems, such as Gate Matrix Layout and Minimization of Open Stacks. The proposed evaluation method is generally competitive and particularly useful for large and dense instances. It can be easily integrated into local search and metaheuristic algorithms to improve solutions without significantly increasing processing time.",
        "subjects": [
            "cs.AI",
            "math.CO",
            "math.OC"
        ],
        "comment": "technical report"
    },
    {
        "paper id": "2409.04936",
        "abstract url": "https://arxiv.org/abs/2409.04936",
        "title": "A Hetero-functional Graph Resilience Analysis for Convergent Systems-of-Systems",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "survival"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Our modern life has grown to depend on many and nearly ubiquitous large complex engineering systems. Many disciplines now seemingly ask the same question: ``In the face of assumed disruption, to what degree will these systems continue to perform and when will they be able to bounce back to normal operation\"? Furthermore, there is a growing recognition that the greatest societal challenges of the Anthropocene era are intertwined, necessitating a convergent systems-of-systems modeling and analysis framework based upon reconciled ontologies, data, and theoretical methods. Consequently, this paper develops a methodology for hetero-functional graph resilience analysis and demonstrates it on a convergent system-of-systems. It uses the Systems Modeling Language, model-based systems engineering and Hetero-Functional Graph Theory (HFGT) to overcome the convergence research challenges when constructing models and measures from multiple disciplines for systems resilience. The paper includes both the ``survival\" as well as ``recovery\" components of resilience. It also strikes a middle ground between two disparate approaches to resilience measurement: structural measurement of formal graphs and detailed behavioral simulation. This paper also generalizes a previous resilience measure based on HFGT and benefits from recent theoretical and computational developments in HFGT. To demonstrate the methodological developments, the resilience analysis is conducted on a hypothetical energy-water nexus system of moderate size as a type of system-of-systems.",
        "subjects": [
            "eess.SY",
            "cs.SI"
        ],
        "comment": "19 pages, 6 figures, 2 tables"
    },
    {
        "paper id": "2409.04761",
        "abstract url": "https://arxiv.org/abs/2409.04761",
        "title": "Transformer Based Tissue Classification in Robotic Needle Biopsy",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "Biopsy",
                "surgery"
            ]
        ],
        "abstract": "Image-guided minimally invasive robotic surgery is commonly employed for tasks such as needle biopsies or localized therapies. However, the nonlinear deformation of various tissue types presents difficulties for surgeons in achieving precise needle tip placement, particularly when relying on low-fidelity biopsy imaging systems. In this paper, we introduce a method to classify needle biopsy interventions and identify tissue types based on a comprehensive needle-tissue contact model that incorporates both position and force parameters. We trained a transformer model using a comprehensive dataset collected from a formerly developed robotics platform, which consists of synthetic and porcine tissue from various locations (liver, kidney, heart, belly, hock) marked with interaction phases (pre-puncture, puncture, post-puncture, neutral). This model achieves a significant classification accuracy of 0.93. Our demonstrated method can assist surgeons in identifying transitions to different tissues, aiding surgeons with tissue awareness.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2409.04817",
        "abstract url": "https://arxiv.org/abs/2409.04817",
        "title": "SSFam: Scribble Supervised Salient Object Detection Family",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "infrared"
            ],
            [
                "thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Scribble supervised salient object detection (SSSOD) constructs segmentation ability of attractive objects from surroundings under the supervision of sparse scribble labels. For the better segmentation, depth and thermal infrared modalities serve as the supplement to RGB images in the complex scenes. Existing methods specifically design various feature extraction and multi-modal fusion strategies for RGB, RGB-Depth, RGB-Thermal, and Visual-Depth-Thermal image input respectively, leading to similar model flood. As the recently proposed Segment Anything Model (SAM) possesses extraordinary segmentation and prompt interactive capability, we propose an SSSOD family based on SAM, named SSFam, for the combination input with different modalities. Firstly, different modal-aware modulators are designed to attain modal-specific knowledge which cooperates with modal-agnostic information extracted from the frozen SAM encoder for the better feature ensemble. Secondly, a siamese decoder is tailored to bridge the gap between the training with scribble prompt and the testing with no prompt for the stronger decoding ability. Our model demonstrates the remarkable performance among combinations of different modalities and refreshes the highest level of scribble supervised methods and comes close to the ones of fully supervised methods. https://github.com/liuzywen/SSFam",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by TMM 2024"
    },
    {
        "paper id": "2409.04915",
        "abstract url": "https://arxiv.org/abs/2409.04915",
        "title": "Activation Function Optimization Scheme for Image Classification",
        "rating": "-3",
        "keywords": [
            [
                "medical"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Activation function has a significant impact on the dynamics, convergence, and performance of deep neural networks. The search for a consistent and high-performing activation function has always been a pursuit during deep learning model development. Existing state-of-the-art activation functions are manually designed with human expertise except for Swish. Swish was developed using a reinforcement learning-based search strategy. In this study, we propose an evolutionary approach for optimizing activation functions specifically for image classification tasks, aiming to discover functions that outperform current state-of-the-art options. Through this optimization framework, we obtain a series of high-performing activation functions denoted as Exponential Error Linear Unit (EELU). The developed activation functions are evaluated for image classification tasks from two perspectives: (1) five state-of-the-art neural network architectures, such as ResNet50, AlexNet, VGG16, MobileNet, and Compact Convolutional Transformer which cover computationally heavy to light neural networks, and (2) eight standard datasets, including CIFAR10, Imagenette, MNIST, Fashion MNIST, Beans, Colorectal Histology, CottonWeedID15, and TinyImageNet which cover from typical machine vision benchmark, agricultural image applications to medical image applications. Finally, we statistically investigate the generalization of the resultant activation functions developed through the optimization scheme. With a Friedman test, we conclude that the optimization scheme is able to generate activation functions that outperform the existing standard ones in 92.8% cases among 28 different cases studied, and $-x\\cdot erf(e^{-x})$ is found to be the best activation function for image classification generated by the optimization scheme.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04916",
        "abstract url": "https://arxiv.org/abs/2409.04916",
        "title": "Chemical Power Variability among Microscopic Robots in Blood Vessels",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "Chemical"
            ]
        ],
        "abstract": "Fuel cells using oxygen and glucose could power microscopic robots operating in blood vessels. Swarms of such robots can significantly reduce oxygen concentration, depending on the time between successive transits of the lung, hematocrit variation in vessels and tissue oxygen consumption. These factors differ among circulation paths through the body. This paper evaluates how these variations affect the minimum oxygen concentration due to robot consumption and where it occurs: mainly in moderate-sized veins toward the end of long paths prior to their merging with veins from shorter paths. This shows that tens of billions of robots can obtain hundreds of picowatts throughout the body with minor reduction in total oxygen. However, a trillion robots significantly deplete oxygen in some parts of the body. By storing oxygen or limiting their consumption in long circulation paths, robots can actively mitigate this depletion. The variation in behavior is illustrated in three cases: the portal system which involves passage through two capillary networks, the spleen whose slits significantly slow some of the flow, and large tissue consumption in coronary circulation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04789",
        "abstract url": "https://arxiv.org/abs/2409.04789",
        "title": "forester: A Tree-Based AutoML Tool in R",
        "rating": "-3.5",
        "keywords": [
            [
                "survival"
            ],
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The majority of automated machine learning (AutoML) solutions are developed in Python, however a large percentage of data scientists are associated with the R language. Unfortunately, there are limited R solutions available. Moreover high entry level means they are not accessible to everyone, due to required knowledge about machine learning (ML). To fill this gap, we present the forester package, which offers ease of use regardless of the user's proficiency in the area of machine learning. The forester is an open-source AutoML package implemented in R designed for training high-quality tree-based models on tabular data. It fully supports binary and multiclass classification, regression, and partially survival analysis tasks. With just a few functions, the user is capable of detecting issues regarding the data quality, preparing the preprocessing pipeline, training and tuning tree-based models, evaluating the results, and creating the report for further analysis.",
        "subjects": [
            "cs.LG",
            "cs.MS",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04808",
        "abstract url": "https://arxiv.org/abs/2409.04808",
        "title": "HULLMI: Human vs LLM identification with explainability",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "As LLMs become increasingly proficient at producing human-like responses, there has been a rise of academic and industrial pursuits dedicated to flagging a given piece of text as \"human\" or \"AI\". Most of these pursuits involve modern NLP detectors like T5-Sentinel and RoBERTa-Sentinel, without paying too much attention to issues of interpretability and explainability of these models. In our study, we provide a comprehensive analysis that shows that traditional ML models (Naive-Bayes,MLP, Random Forests, XGBoost) perform as well as modern NLP detectors, in human vs AI text detection. We achieve this by implementing a robust testing procedure on diverse datasets, including curated corpora and real-world samples. Subsequently, by employing the explainable AI technique LIME, we uncover parts of the input that contribute most to the prediction of each model, providing insights into the detection process. Our study contributes to the growing need for developing production-level LLM detection tools, which can leverage a wide range of traditional as well as modern NLP detectors we propose. Finally, the LIME techniques we demonstrate also have the potential to equip these detection tools with interpretability analysis features, making them more reliable and trustworthy in various domains like education, healthcare, and media.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "17 pages, 8 figures"
    },
    {
        "paper id": "2409.04736",
        "abstract url": "https://arxiv.org/abs/2409.04736",
        "title": "LiTelFuzz : Swarms Fuzzing Based on Linear Temporal Logic Constraints",
        "rating": "-4",
        "keywords": [
            [
                "robot"
            ],
            [
                "attack"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "Multi-robot swarms utilize swarm intelligence to collaborate on tasks and play an increasingly significant role in a variety of practical scenarios. However, due to the complex design, multi-robot swarm systems often have vulnerabilities caused by logical errors, which can severely disrupt the normal operations of multi-robot swarms. Despite the significant security threats that logical vulnerabilities pose to multi-robot swarms, there are still considerable challenges in testing and identifying these vulnerabilities, and related research still faces two major challenges: 1) the explosion of input space for testing, 2) the lack of effective test-guidance strategies. Therefore, in this paper, we overcome the two major challenges mentioned above, and propose a formal verification method to discover logical flaws in multi-robot swarms. Specifically, we abstract linear temporal logic constraints of the swarm and compute swarm robustness based on these constraints thus guiding fuzzing, we call this approach LiTelFuzz (Fuzzing based on Linear Temporal Logic Constraints). The core idea of LiTelFuzz is to design a metric based on behavioral constraints to assess the state of the multi-robot swarm at different moments, and guide fuzz testing based on the assessment results. Based on this idea, we overcome the two challenges of excessive test case input space and the lack of fuzzing guidance. Consequently, we implement a single attack drone fuzzing scheme and a multiple attack drones scheme based on LiTelFuzz. These are named SA-Fuzzing and MA-Fuzzing, respectively. Finally, we tested three popular swarm algorithms using LiTelFuzz with an average success rate of 87.35% for SA-Fuzzing and 91.73% for MA-Fuzzing to find vulnerabilities. The success rate and efficiency are better than the existing state-of-the-art fuzzer SWARMFLAWFINDER.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Submitted to USENIX security'25"
    },
    {
        "paper id": "2409.04738",
        "abstract url": "https://arxiv.org/abs/2409.04738",
        "title": "Modeling Drivers' Risk Perception via Attention to Improve Driving Assistance",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory",
                "vehicle"
            ],
            [
                "forecasting"
            ]
        ],
        "abstract": "Advanced Driver Assistance Systems (ADAS) alert drivers during safety-critical scenarios but often provide superfluous alerts due to a lack of consideration for drivers' knowledge or scene awareness. Modeling these aspects together in a data-driven way is challenging due to the scarcity of critical scenario data with in-cabin driver state and world state recorded together. We explore the benefits of driver modeling in the context of Forward Collision Warning (FCW) systems. Working with real-world video dataset of on-road FCW deployments, we collect observers' subjective validity rating of the deployed alerts. We also annotate participants' gaze-to-objects and extract 3D trajectories of the ego vehicle and other vehicles semi-automatically. We generate a risk estimate of the scene and the drivers' perception in a two step process: First, we model the movement of vehicles in a given scenario as a joint trajectory forecasting problem. Then, we reason about the drivers' risk perception of the scene by counterfactually modifying the input to the forecasting model to represent the drivers' actual observations of vehicles in the scene. The difference in these behaviours gives us an estimate of driver behaviour that accounts for their actual (inattentive) observations and their downstream effect on overall scene risk. We compare both a learned scene representation as well as a more traditional ``worse-case'' deceleration model to achieve the future trajectory forecast. Our experiments show that using this risk formulation to generate FCW alerts may lead to improved false positive rate of FCWs and improved FCW timing.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04931",
        "abstract url": "https://arxiv.org/abs/2409.04931",
        "title": "Noise-Based Authentication: Is It Secure?",
        "rating": "-4",
        "keywords": [
            [
                "biometric"
            ],
            [
                "thermal"
            ]
        ],
        "abstract": "This paper introduces a three-point biometric authentication system for a blockchain-based decentralized identity network. We use existing biometric authentication systems to demonstrate the unique noise fingerprints that belong to each individual human and the respective information leak from the biological characteristics. We then propose the concept of using unique thermal noise amplitudes generated by each user and explore the open questions regarding the robustness of unconditionally secure authentication.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04720",
        "abstract url": "https://arxiv.org/abs/2409.04720",
        "title": "A Comprehensive Survey on Evidential Deep Learning and Its Applications",
        "rating": "-4.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "medical",
                "diagnosis"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Reliable uncertainty estimation has become a crucial requirement for the industrial deployment of deep learning algorithms, particularly in high-risk applications such as autonomous driving and medical diagnosis. However, mainstream uncertainty estimation methods, based on deep ensembling or Bayesian neural networks, generally impose substantial computational overhead. To address this challenge, a novel paradigm called Evidential Deep Learning (EDL) has emerged, providing reliable uncertainty estimation with minimal additional computation in a single forward pass. This survey provides a comprehensive overview of the current research on EDL, designed to offer readers a broad introduction to the field without assuming prior knowledge. Specifically, we first delve into the theoretical foundation of EDL, the subjective logic theory, and discuss its distinctions from other uncertainty estimation frameworks. We further present existing theoretical advancements in EDL from four perspectives: reformulating the evidence collection process, improving uncertainty estimation via OOD samples, delving into various training strategies, and evidential regression networks. Thereafter, we elaborate on its extensive applications across various machine learning paradigms and downstream tasks. In the end, an outlook on future directions for better performances and broader adoption of EDL is provided, highlighting potential research avenues.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04935",
        "abstract url": "https://arxiv.org/abs/2409.04935",
        "title": "Anomaly Detection for Real-World Cyber-Physical Security using Quantum Hybrid Support Vector Machines",
        "rating": "-4.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "attacks"
            ],
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cyber-physical control systems are critical infrastructures designed around highly responsive feedback loops that are measured and manipulated by hundreds of sensors and controllers. Anomalous data, such as from cyber-attacks, greatly risk the safety of the infrastructure and human operators. With recent advances in the quantum computing paradigm, the application of quantum in anomaly detection can greatly improve identification of cyber-attacks in physical sensor data. In this paper, we explore the use of strong pre-processing methods and a quantum-hybrid Support Vector Machine (SVM) that takes advantage of fidelity in parameterized quantum circuits to efficiently and effectively flatten extremely high dimensional data. Our results show an F-1 Score of 0.86 and accuracy of 87% on the HAI CPS dataset using an 8-qubit, 16-feature quantum kernel, performing equally to existing work and 14% better than its classical counterpart.",
        "subjects": [
            "quant-ph",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "6 pages, 5 figures, 2 tables, under ISVLSI 2024 proceedings"
    },
    {
        "paper id": "2409.04724",
        "abstract url": "https://arxiv.org/abs/2409.04724",
        "title": "Maximization of Communication Network Throughput using Dynamic Traffic Allocation Scheme",
        "rating": "-10",
        "keywords": [],
        "abstract": "Optimizing network throughput in real-world dynamic systems is critical, especially for diverse and delay-sensitive multimedia data types such as VoIP and video streaming. Traditional routing protocols, which rely on static metrics and single shortest-path algorithms, were unable in managing this complex information. To address these challenges, we propose a novel approach that enhances resource utilization while maintaining Quality of Service (QoS). Our dynamic traffic allocation model prioritizes different data types based on their delay sensitivity and allocates traffic by considering factors such as bandwidth, latency, and network failures. This approach is shown to significantly improve network throughput compared to static load balancing, especially for multimedia applications. Simulation results confirm the effectiveness of this dynamic method in maximizing network throughput and maintaining QoS across various data types.",
        "subjects": [
            "cs.NI",
            "cs.GT"
        ],
        "comment": "4 pages, 4 figures, 2 tables"
    },
    {
        "paper id": "2409.04726",
        "abstract url": "https://arxiv.org/abs/2409.04726",
        "title": "Physical Design: Methodologies and Developments",
        "rating": "-10",
        "keywords": [],
        "abstract": "The design and production of VLSI chips is a multilevel heirarchical process. As the demand for reduced die-area and technology nodes becomes prevalent, it gets increasingly challenging to optimize Power, Performance and Area (PPA) parameters to accommodate for the ever-increasing core logic on a chip. A well defined heirarchical flow is thus quintessential when it comes to VLSI design process. A robust heirarchical flow should encompass all stages, right from Gate-level RTL Synthesis (Front End Design) to Logic Placement and Verification (Back End Physical Design) and finally culminating with tapeout / production. Physical Design in this aforementioned flow is the process of translating logical circuit description into physically realizable GDSII form. This involves defining the best possible placement and routing for standard cells, macros and I/Os in the design to optimize PPA for any given netlist. This paper helps capture the nitty-gritty of methodologies and algorithms that are pertinent to the building and optimization of an efficient and robust physical design flow in VLSI chip-designing process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04765",
        "abstract url": "https://arxiv.org/abs/2409.04765",
        "title": "Continuous-Time Online Distributed Seeking for Generalized Nash Equilibrium of Nonmonotone Online Game",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper mainly investigates a class of distributed generalized Nash equilibrium (GNE) seeking problems for online nonmonotone game with time-varying coupling inequality constraints. Based on a time-varying control gain, a novel continuous-time distributed GNE seeking algorithm is proposed, which realizes the constant regret bound and sublinear fit bound, matching those of the criteria for online optimization problems. Furthermore, to reduce unnecessary communication among players, a dynamic event-triggered mechanism involving internal variables is introduced into the distributed GNE seeking algorithm, while the constant regret bound and sublinear fit bound are still achieved. Also, the Zeno behavior is strictly prohibited. Finally, a numerical example is given to demonstrate the validity of the theoretical results.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04824",
        "abstract url": "https://arxiv.org/abs/2409.04824",
        "title": "OSS License Identification at Scale: A Comprehensive Dataset Using World of Code",
        "rating": "-10",
        "keywords": [],
        "abstract": "The proliferation of open source software (OSS) has led to a complex landscape of licensing practices, making accurate license identification crucial for legal and compliance purposes. This study presents a comprehensive analysis of OSS licenses using the World of Code (WoC) infrastructure. We employ an exhaustive approach, scanning all files containing ``license'' in their filepath, and apply the winnowing algorithm for robust text matching. Our method identifies and matches over 5.5 million distinct license blobs across millions of OSS projects, creating a detailed project-to-license (P2L) map. We verify the accuracy of our approach through stratified sampling and manual review, achieving a final accuracy of 92.08%, with precision of 87.14%, recall of 95.45%, and an F1 score of 91.11%. This work enhances the understanding of OSS licensing practices and provides a valuable resource for developers, researchers, and legal professionals. Future work will expand the scope of license detection to include code files and references to licenses in project documentation.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04830",
        "abstract url": "https://arxiv.org/abs/2409.04830",
        "title": "Beyond Dependencies: The Role of Copy-Based Reuse in Open Source Software Development",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Open Source Software, resources of any project are open for reuse by introducing dependencies or copying the resource itself. In contrast to dependency-based reuse, the infrastructure to systematically support copy-based reuse appears to be entirely missing. Our aim is to enable future research and tool development to increase efficiency and reduce the risks of copy-based reuse. We seek a better understanding of such reuse by measuring its prevalence and identifying factors affecting the propensity to reuse. To identify reused artifacts and trace their origins, our method exploits World of Code infrastructure. We begin with a set of theory-derived factors related to the propensity to reuse, sample instances of different reuse types, and survey developers to better understand their intentions. Our results indicate that copy-based reuse is common, with many developers being aware of it when writing code. The propensity for a file to be reused varies greatly among languages and between source code and binary files, consistently decreasing over time. Files introduced by popular projects are more likely to be reused, but at least half of reused resources originate from ``small'' and ``medium'' projects. Developers had various reasons for reuse but were generally positive about using a package manager.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04845",
        "abstract url": "https://arxiv.org/abs/2409.04845",
        "title": "Algebraic Representations of Entropy and Fixed-Parity Information Quantities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many information-theoretic quantities have corresponding representations in terms of sets. The prevailing signed measure space for characterising entropy, the $I$-measure of Yeung, is occasionally unable to discern between qualitatively distinct systems. In previous work, we presented a refinement of this signed measure space and demonstrated its capability to represent many quantities, which we called logarithmically decomposable quantities. In the present work we demonstrate that this framework has natural algebraic behaviour which can be expressed in terms of ideals (characterised here as upper-sets), and we show that this behaviour allows us to make various counting arguments and characterise many fixed-parity information quantity expressions. As an application, we give an algebraic proof that the only completely synergistic system of three finite variables $X$, $Y$ and $Z = f(X,Y)$ is the XOR gate.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "12 pages, 2 figures"
    },
    {
        "paper id": "2409.04853",
        "abstract url": "https://arxiv.org/abs/2409.04853",
        "title": "Exploring the Acoustics of the Chinese Transverse Flute (dizi)",
        "rating": "-10",
        "keywords": [],
        "abstract": "We investigate the acoustical characteristics of the Chinese transverse flute, the dizi, employing input impedance measurements, modeling and analysis. The input impedances for various fingerings of a bangdi in the key of F, a particular type of the dizi, are measured and compared to models using both the transfer matrix method and the Transfer Matrix Method with external Interaction (TMMI). In order to get more accurate modeling results, we provide specific transfer matrices for the unique components of the dizi, such as back end-holes, membrane hole and upstream branch. The matching volume length correction for holes drilled in a thick wall is also derived. Comparative analysis of modeling and measurement data validates the improved accuracy of TMMI, confirming the influence of radiated sound from closely spaced toneholes.",
        "subjects": [
            "physics.app-ph",
            "eess.SP"
        ],
        "comment": "11 pages, 11 figures"
    },
    {
        "paper id": "2409.04854",
        "abstract url": "https://arxiv.org/abs/2409.04854",
        "title": "Adaptation Procedure in Misinformation Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study interactions between agents in multi-agent systems, in which the agents are misinformed with regards to the game that they play, essentially having a subjective and incorrect understanding of the setting, without being aware of it. For that, we introduce a new game-theoretic concept, called misinformation games, that provides the necessary toolkit to study this situation. Subsequently, we enhance this framework by developing a time-discrete procedure (called the Adaptation Procedure) that captures iterative interactions in the above context. During the Adaptation Procedure, the agents update their information and reassess their behaviour in each step. We demonstrate our ideas through an implementation, which is used to study the efficiency and characteristics of the Adaptation Procedure.",
        "subjects": [
            "cs.GT",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04868",
        "abstract url": "https://arxiv.org/abs/2409.04868",
        "title": "Moment Constraints and Phase Recovery for Multireference Alignment",
        "rating": "-10",
        "keywords": [],
        "abstract": "Multireference alignment (MRA) refers to the problem of recovering a signal from noisy samples subject to random circular shifts. Expectation maximization (EM) and variational approaches use statistical modeling to achieve high accuracy at the cost of solving computationally expensive optimization problems. The method of moments, instead, achieves fast reconstructions by utilizing the power spectrum and bispectrum to determine the signal up to shift. Our approach combines the two philosophies by viewing the power spectrum as a manifold on which to constrain the signal. We then maximize the data likelihood function on this manifold with a gradient-based approach to estimate the true signal. Algorithmically, our method involves iterating between template alignment and projections onto the manifold. The method offers increased speed compared to EM and demonstrates improved accuracy over bispectrum-based methods.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "24 pages, 10 figures"
    },
    {
        "paper id": "2409.04873",
        "abstract url": "https://arxiv.org/abs/2409.04873",
        "title": "Data driven synthetic wavefront generation for boundary layer data",
        "rating": "-10",
        "keywords": [],
        "abstract": "Disturbances such as atmospheric turbulence and aero-optic effects lead to wavefront aberrations, which degrade performance in imaging and laser propagation applications. Adaptive optics (AO) provide a method to mitigate these effects by pre-compensating the wavefront before propagation. However, development and testing of AO systems requires wavefront aberration data, which is difficult and expensive to obtain. Simulation methods can be used to generate such data less expensively. For atmospheric turbulence, the Kolmogorov-Taylor model provides a well-defined power spectrum that can be combined with the well-known angular spectrum method to generate synthetic phase screens. However, as aero-optics cannot be similarly generalized, this process cannot be applied to aero-optically relevant phenomena. In this paper, we introduce ReVAR (Re-Whitened Vector Auto-Regression), a novel algorithm for data-driven aero-optic phase screen generation. ReVAR trains on an input time-series of spatially and temporally correlated wavefront images from experiment and then generates synthetic data that captures the statistics present in the experimental data. The first training step of ReVAR distills the input images to a set of prediction weights and residuals. A further step we call re-whitening uses a spatial principal component analysis (PCA) to whiten these residuals. ReVAR then uses a white noise generator and inverts the previous transformation to construct synthetic time-series of data. This algorithm is computationally efficient, able to generate arbitrarily long synthetic time-series, and produces high-quality results when tested on turbulent boundary layer (TBL) data measured from a wind tunnel experiment. Using measured data for training, the temporal power spectral density (TPSD) of data generated using ReVAR closely matches the TPSD of the experimental data.",
        "subjects": [
            "eess.SP",
            "stat.AP"
        ],
        "comment": "To be published in SPIE Unconventional Imaging, Sensing, and Adaptive Optics 2024 proceedings"
    },
    {
        "paper id": "2409.04877",
        "abstract url": "https://arxiv.org/abs/2409.04877",
        "title": "Strong Privacy-Preserving Universally Composable AKA Protocol with Seamless Handover Support for Mobile Virtual Network Operator",
        "rating": "-10",
        "keywords": [],
        "abstract": "Consumers seeking a new mobile plan have many choices in the present mobile landscape. The Mobile Virtual Network Operator (MVNO) has recently gained considerable attention among these options. MVNOs offer various benefits, making them an appealing choice for a majority of consumers. These advantages encompass flexibility, access to cutting-edge technologies, enhanced coverage, superior customer service, and substantial cost savings. Even though MVNO offers several advantages, it also creates some security and privacy concerns for the customer simultaneously. For instance, in the existing solution, MVNO needs to hand over all the sensitive details, including the users' identities and master secret keys of their customers, to a mobile operator (MNO) to validate the customers while offering any services. This allows MNOs to have unrestricted access to the MVNO subscribers' location and mobile data, including voice calls, SMS, and Internet, which the MNOs frequently sell to third parties (e.g., advertisement companies and surveillance agencies) for more profit. Although critical for mass users, such privacy loss has been historically ignored due to the lack of practical and privacy-preserving solutions for registration and handover procedures in cellular networks. In this paper, we propose a universally composable authentication and handover scheme with strong user privacy support, where each MVNO user can validate a mobile operator (MNO) and vice-versa without compromising user anonymity and unlinkability support. Here, we anticipate that our proposed solution will most likely be deployed by the MVNO(s) to ensure enhanced privacy support to their customer(s).",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04914",
        "abstract url": "https://arxiv.org/abs/2409.04914",
        "title": "Stable Matching with Contingent Priorities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Using school choice as a motivating example, we introduce a stylized model of a many-to-one matching market where the clearinghouse aims to implement contingent priorities, i.e., priorities that depend on the current assignment, to prioritize students with siblings and match them together. We provide a series of guidelines and introduce two natural approaches to implement them: (i) absolute, whereby a prioritized student can displace any student without siblings assigned to the school, and (ii) partial, whereby prioritized students can only displace students that have a less favorable lottery than their priority provider. We study several properties of the corresponding mechanisms, including the existence of a stable assignment under contingent priorities, the complexity of deciding whether there exists one, and its incentive properties. Furthermore, we introduce a soft version of these priorities to guarantee existence, and we provide mathematical programming formulations to find such stable matching or certify that one does not exist. Finally, using data from the Chilean school choice system, we show that our framework can significantly increase the number of students assigned to their top preference and the number of siblings assigned together relative to current practice.",
        "subjects": [
            "cs.GT",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04924",
        "abstract url": "https://arxiv.org/abs/2409.04924",
        "title": "Performance Analysis of Joint Antenna Selection and Precoding Methods in Multi-user Massive MISO",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a performance analysis of two distinct techniques for antenna selection and precoding in downlink multi-user massive multiple-input single-output systems with limited dynamic range power amplifiers. Both techniques are derived from the original formulation of the regularized-zero forcing precoder, designed as the solution to minimizing a regularized distortion. Based on this, the first technique, called the $\\ell_1$-norm precoder, adopts an $\\ell_1$-norm regularization term to encourage sparse solutions, thereby enabling antenna selection. The second technique, termed the thresholded $\\ell_1$-norm precoder, involves post-processing the precoder solution obtained from the first method by applying an entry-wise thresholding operation. This work conducts a precise performance analysis to compare these two techniques. The analysis leverages the Gaussian min-max theorem which is effective for examining the asymptotic behavior of optimization problems without explicit solutions. While the analysis of the $\\ell_1$-norm precoder follows the conventional Gaussian min-max theorem framework, understanding the thresholded $\\ell_1$-norm precoder is more complex due to the non-linear behavior introduced by the thresholding operation. To address this complexity, we develop a novel Gaussian min-max theorem tailored to these scenarios. We provide precise asymptotic behavior analysis of the precoders, focusing on metrics such as received signal-to-noise and distortion ratio and bit error rate. Our analysis demonstrates that the thresholded $\\ell_1$-norm precoder can offer superior performance when the threshold parameter is carefully selected. Simulations confirm that the asymptotic results are accurate for systems equipped with hundreds of antennas at the base station, serving dozens of user terminals.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04937",
        "abstract url": "https://arxiv.org/abs/2409.04937",
        "title": "CONNECTOR: Enhancing the Traceability of Decentralized Bridge Applications via Automatic Cross-chain Transaction Association",
        "rating": "-10",
        "keywords": [],
        "abstract": "Decentralized bridge applications are important software that connects various blockchains and facilitates cross-chain asset transfer in the decentralized finance (DeFi) ecosystem which currently operates in a multi-chain environment. Cross-chain transaction association identifies and matches unique transactions executed by bridge DApps, which is important research to enhance the traceability of cross-chain bridge DApps. However, existing methods rely entirely on unobservable internal ledgers or APIs, violating the open and decentralized properties of blockchain. In this paper, we analyze the challenges of this issue and then present CONNECTOR, an automated cross-chain transaction association analysis method based on bridge smart contracts. Specifically, CONNECTOR first identifies deposit transactions by extracting distinctive and generic features from the transaction traces of bridge contracts. With the accurate deposit transactions, CONNECTOR mines the execution logs of bridge contracts to achieve withdrawal transaction matching. We conduct real-world experiments on different types of bridges to demonstrate the effectiveness of CONNECTOR. The experiment demonstrates that CONNECTOR successfully identifies 100% deposit transactions, associates 95.81% withdrawal transactions, and surpasses methods for CeFi bridges. Based on the association results, we obtain interesting findings about cross-chain transaction behaviors in DeFi bridges and analyze the tracing abilities of CONNECTOR to assist the DeFi bridge apps.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04941",
        "abstract url": "https://arxiv.org/abs/2409.04941",
        "title": "A Comprehensive Analysis of Process Energy Consumption on Multi-Socket Systems with GPUs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Robustly estimating energy consumption in High-Performance Computing (HPC) is essential for assessing the energy footprint of modern workloads, particularly in fields such as Artificial Intelligence (AI) research, development, and deployment. The extensive use of supercomputers for AI training has heightened concerns about energy consumption and carbon emissions. Existing energy estimation tools often assume exclusive use of computing nodes, a premise that becomes problematic with the advent of supercomputers integrating microservices, as seen in initiatives like Acceleration as a Service (XaaS) and cloud computing. This work investigates the impact of executed instructions on overall power consumption, providing insights into the comprehensive behaviour of HPC systems. We introduce two novel mathematical models to estimate a process's energy consumption based on the total node energy, process usage, and a normalised vector of the probability distribution of instruction types for CPU and GPU processes. Our approach enables energy accounting for specific processes without the need for isolation. Our models demonstrate high accuracy, predicting CPU power consumption with a mere 1.9% error. For GPU predictions, the models achieve a central relative error of 9.7%, showing a clear tendency to fit the test data accurately. These results pave the way for new tools to measure and account for energy consumption in shared supercomputing environments.",
        "subjects": [
            "cs.DC",
            "cs.PF"
        ],
        "comment": "Accepted in Latin American High-Performance Computing Conference (CARLA 2024)"
    }
]