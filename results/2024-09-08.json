[
    {
        "paper id": "2409.05015",
        "abstract url": "https://arxiv.org/abs/2409.05015",
        "title": "Improving Multimodal Emotion Recognition by Leveraging Acoustic Adaptation and Visual Alignment",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Multimodal Emotion Recognition (MER) aims to automatically identify and understand human emotional states by integrating information from various modalities. However, the scarcity of annotated multimodal data significantly hinders the advancement of this research field. This paper presents our solution for the MER-SEMI sub-challenge of MER 2024. First, to better adapt acoustic modality features for the MER task, we experimentally evaluate the contributions of different layers of the pre-trained speech model HuBERT in emotion recognition. Based on these observations, we perform Parameter-Efficient Fine-Tuning (PEFT) on the layers identified as most effective for emotion recognition tasks, thereby achieving optimal adaptation for emotion recognition with a minimal number of learnable parameters. Second, leveraging the strengths of the acoustic modality, we propose a feature alignment pre-training method. This approach uses large-scale unlabeled data to train a visual encoder, thereby promoting the semantic alignment of visual features within the acoustic feature space. Finally, using the adapted acoustic features, aligned visual features, and lexical features, we employ an attention mechanism for feature fusion. On the MER2024-SEMI test set, the proposed method achieves a weighted F1 score of 88.90%, ranking fourth among all participating teams, validating the effectiveness of our approach.",
        "subjects": [
            "cs.HC",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05137",
        "abstract url": "https://arxiv.org/abs/2409.05137",
        "title": "READoc: A Unified Benchmark for Realistic Document Structured Extraction",
        "rating": "2",
        "keywords": [
            [
                "VLMs"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Document Structured Extraction (DSE) aims to extract structured content from raw documents. Despite the emergence of numerous DSE systems, their unified evaluation remains inadequate, significantly hindering the field's advancement. This problem is largely attributed to existing benchmark paradigms, which exhibit fragmented and localized characteristics. To address these limitations and offer a thorough evaluation of DSE systems, we introduce a novel benchmark named READoc, which defines DSE as a realistic task of converting unstructured PDFs into semantically rich Markdown. The READoc dataset is derived from 2,233 diverse and real-world documents from arXiv and GitHub. In addition, we develop a DSE Evaluation S$^3$uite comprising Standardization, Segmentation and Scoring modules, to conduct a unified evaluation of state-of-the-art DSE approaches. By evaluating a range of pipeline tools, expert visual models, and general VLMs, we identify the gap between current work and the unified, realistic DSE objective for the first time. We aspire that READoc will catalyze future research in DSE, fostering more comprehensive and practical solutions.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05212",
        "abstract url": "https://arxiv.org/abs/2409.05212",
        "title": "SS-BRPE: Self-Supervised Blind Room Parameter Estimation Using Attention Mechanisms",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In recent years, dynamic parameterization of acoustic environments has garnered attention in audio processing. This focus includes room volume and reverberation time (RT60), which define local acoustics independent of sound source and receiver orientation. Previous studies show that purely attention-based models can achieve advanced results in room parameter estimation. However, their success relies on supervised pretrainings that require a large amount of labeled true values for room parameters and complex training pipelines. In light of this, we propose a novel Self-Supervised Blind Room Parameter Estimation (SS-BRPE) system. This system combines a purely attention-based model with self-supervised learning to estimate room acoustic parameters, from single-channel noisy speech signals. By utilizing unlabeled audio data for pretraining, the proposed system significantly reduces dependencies on costly labeled datasets. Our model also incorporates dynamic feature augmentation during fine-tuning to enhance adaptability and generalizability. Experimental results demonstrate that the SS-BRPE system not only achieves more superior performance in estimating room parameters than state-of-the-art (SOTA) methods but also effectively maintains high accuracy under conditions with limited labeled data. Code available at https://github.com/bjut-chunxiwang/SS-BRPE.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "5 pages, 3 figures, submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.05303",
        "abstract url": "https://arxiv.org/abs/2409.05303",
        "title": "Resource-Efficient Generative AI Model Deployment in Mobile Edge Networks",
        "rating": "1.5",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The surging development of Artificial Intelligence-Generated Content (AIGC) marks a transformative era of the content creation and production. Edge servers promise attractive benefits, e.g., reduced service delay and backhaul traffic load, for hosting AIGC services compared to cloud-based solutions. However, the scarcity of available resources on the edge pose significant challenges in deploying generative AI models. In this paper, by characterizing the resource and delay demands of typical generative AI models, we find that the consumption of storage and GPU memory, as well as the model switching delay represented by I/O delay during the preloading phase, are significant and vary across models. These multidimensional coupling factors render it difficult to make efficient edge model deployment decisions. Hence, we present a collaborative edge-cloud framework aiming to properly manage generative AI model deployment on the edge. Specifically, we formulate edge model deployment problem considering heterogeneous features of models as an optimization problem, and propose a model-level decision selection algorithm to solve it. It enables pooled resource sharing and optimizes the trade-off between resource consumption and delay in edge generative AI model deployment. Simulation results validate the efficacy of the proposed algorithm compared with baselines, demonstrating its potential to reduce overall costs by providing feature-aware model deployment decisions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05312",
        "abstract url": "https://arxiv.org/abs/2409.05312",
        "title": "Open-World Dynamic Prompt and Continual Visual Representation Learning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "The open world is inherently dynamic, characterized by ever-evolving concepts and distributions. Continual learning (CL) in this dynamic open-world environment presents a significant challenge in effectively generalizing to unseen test-time classes. To address this challenge, we introduce a new practical CL setting tailored for open-world visual representation learning. In this setting, subsequent data streams systematically introduce novel classes that are disjoint from those seen in previous training phases, while also remaining distinct from the unseen test classes. In response, we present Dynamic Prompt and Representation Learner (DPaRL), a simple yet effective Prompt-based CL (PCL) method. Our DPaRL learns to generate dynamic prompts for inference, as opposed to relying on a static prompt pool in previous PCL methods. In addition, DPaRL jointly learns dynamic prompt generation and discriminative representation at each training stage whereas prior PCL methods only refine the prompt learning throughout the process. Our experimental results demonstrate the superiority of our approach, surpassing state-of-the-art methods on well-established open-world image retrieval benchmarks by an average of 4.7\\% improvement in Recall@1 performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2409.05314",
        "abstract url": "https://arxiv.org/abs/2409.05314",
        "title": "Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications",
        "rating": "1.5",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The emergence of large language models (LLMs) has significantly impacted various fields, from natural language processing to sectors like medicine and finance. However, despite their rapid proliferation, the applications of LLMs in telecommunications remain limited, often relying on general-purpose models that lack domain-specific specialization. This lack of specialization results in underperformance, particularly when dealing with telecommunications-specific technical terminology and their associated mathematical representations. This paper addresses this gap by first creating and disseminating Tele-Data, a comprehensive dataset of telecommunications material curated from relevant sources, and Tele-Eval, a large-scale question-and-answer dataset tailored to the domain. Through extensive experiments, we explore the most effective training techniques for adapting LLMs to the telecommunications domain, ranging from examining the division of expertise across various telecommunications aspects to employing parameter-efficient techniques. We also investigate how models of different sizes behave during adaptation and analyze the impact of their training data on this behavior. Leveraging these findings, we develop and open-source Tele-LLMs, the first series of language models ranging from 1B to 8B parameters, specifically tailored for telecommunications. Our evaluations demonstrate that these models outperform their general-purpose counterparts on Tele-Eval while retaining their previously acquired capabilities, thus avoiding the catastrophic forgetting phenomenon.",
        "subjects": [
            "cs.IT",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04976",
        "abstract url": "https://arxiv.org/abs/2409.04976",
        "title": "HYDRA: Hybrid Data Multiplexing and Run-time Layer Configurable DNN Accelerator",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "eess.IV"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) offer plenty of challenges in executing efficient computation at edge nodes, primarily due to the huge hardware resource demands. The article proposes HYDRA, hybrid data multiplexing, and runtime layer configurable DNN accelerators to overcome the drawbacks. The work proposes a layer-multiplexed approach, which further reuses a single activation function within the execution of a single layer with improved Fused-Multiply-Accumulate (FMA). The proposed approach works in iterative mode to reuse the same hardware and execute different layers in a configurable fashion. The proposed architectures achieve reductions over 90% of power consumption and resource utilization improvements of state-of-the-art works, with 35.21 TOPSW. The proposed architecture reduces the area overhead (N-1) times required in bandwidth, AF and layer architecture. This work shows HYDRA architecture supports optimal DNN computations while improving performance on resource-constrained edge devices.",
        "subjects": [
            "cs.AR",
            "cs.AI",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04978",
        "abstract url": "https://arxiv.org/abs/2409.04978",
        "title": "Time-independent Spiking Neuron via Membrane Potential Estimation for Efficient Spiking Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The computational inefficiency of spiking neural networks (SNNs) is primarily due to the sequential updates of membrane potential, which becomes more pronounced during extended encoding periods compared to artificial neural networks (ANNs). This highlights the need to parallelize SNN computations effectively to leverage available hardware parallelism. To address this, we propose Membrane Potential Estimation Parallel Spiking Neurons (MPE-PSN), a parallel computation method for spiking neurons that enhances computational efficiency by enabling parallel processing while preserving the intrinsic dynamic characteristics of SNNs. Our approach exhibits promise for enhancing computational efficiency, particularly under conditions of elevated neuron density. Empirical experiments demonstrate that our method achieves state-of-the-art (SOTA) accuracy and efficiency on neuromorphic datasets without requiring additional training parameters. Codes are available at~\\url{https://github.com/chrazqee/MPE-PSN}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04992",
        "abstract url": "https://arxiv.org/abs/2409.04992",
        "title": "InstInfer: In-Storage Attention Offloading for Cost-Effective Long-Context LLM Inference",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The widespread of Large Language Models (LLMs) marks a significant milestone in generative AI. Nevertheless, the increasing context length and batch size in offline LLM inference escalate the memory requirement of the key-value (KV) cache, which imposes a huge burden on the GPU VRAM, especially for resource-constraint scenarios (e.g., edge computing and personal devices). Several cost-effective solutions leverage host memory or SSDs to reduce storage costs for offline inference scenarios and improve the throughput. Nevertheless, they suffer from significant performance penalties imposed by intensive KV cache accesses due to limited PCIe bandwidth. To address these issues, we propose InstInfer, a novel LLM inference system that offloads the most performance-critical computation (i.e., attention in decoding phase) and data (i.e., KV cache) parts to Computational Storage Drives (CSDs), which minimize the enormous KV transfer overheads. InstInfer designs a dedicated flash-aware in-storage attention engine with KV cache management mechanisms to exploit the high internal bandwidths of CSDs instead of being limited by the PCIe bandwidth. The optimized P2P transmission between GPU and CSDs further reduces data migration overheads. Experimental results demonstrate that for a 13B model using an NVIDIA A6000 GPU, InstInfer improves throughput for long-sequence inference by up to 11.1$\\times$, compared to existing SSD-based solutions such as FlexGen.",
        "subjects": [
            "cs.AR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04999",
        "abstract url": "https://arxiv.org/abs/2409.04999",
        "title": "Visual Grounding with Multi-modal Conditional Adaptation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual grounding is the task of locating objects specified by natural language expressions. Existing methods extend generic object detection frameworks to tackle this task. They typically extract visual and textual features separately using independent visual and textual encoders, then fuse these features in a multi-modal decoder for final prediction. However, visual grounding presents unique challenges. It often involves locating objects with different text descriptions within the same image. Existing methods struggle with this task because the independent visual encoder produces identical visual features for the same image, limiting detection performance. Some recently approaches propose various language-guided visual encoders to address this issue, but they mostly rely solely on textual information and require sophisticated designs. In this paper, we introduce Multi-modal Conditional Adaptation (MMCA), which enables the visual encoder to adaptively update weights, directing its focus towards text-relevant regions. Specifically, we first integrate information from different modalities to obtain multi-modal embeddings. Then we utilize a set of weighting coefficients, which generated from the multimodal embeddings, to reorganize the weight update matrices and apply them to the visual encoder of the visual grounding model. Extensive experiments on four widely used datasets demonstrate that MMCA achieves significant improvements and state-of-the-art results. Ablation experiments further demonstrate the lightweight and efficiency of our method. Our source code is available at: https://github.com/Mr-Bigworth/MMCA.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "Accepted by ACM MM 2024 [Oral]"
    },
    {
        "paper id": "2409.05007",
        "abstract url": "https://arxiv.org/abs/2409.05007",
        "title": "Audio-Guided Fusion Techniques for Multimodal Emotion Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we propose a solution for the semi-supervised learning track (MER-SEMI) in MER2024. First, in order to enhance the performance of the feature extractor on sentiment classification tasks,we fine-tuned video and text feature extractors, specifically CLIP-vit-large and Baichuan-13B, using labeled data. This approach effectively preserves the original emotional information conveyed in the videos. Second, we propose an Audio-Guided Transformer (AGT) fusion mechanism, which leverages the robustness of Hubert-large, showing superior effectiveness in fusing both inter-channel and intra-channel information. Third, To enhance the accuracy of the model, we iteratively apply self-supervised learning by using high-confidence unlabeled data as pseudo-labels. Finally, through black-box probing, we discovered an imbalanced data distribution between the training and test sets. Therefore, We adopt a prior-knowledge-based voting mechanism. The results demonstrate the effectiveness of our strategy, ultimately earning us third place in the MER-SEMI track.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05028",
        "abstract url": "https://arxiv.org/abs/2409.05028",
        "title": "LLM-based Abstraction and Concretization for GUI Test Migration",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "GUI test migration aims to produce test cases with events and assertions to test specific functionalities of a target app. Existing migration approaches typically focus on the widget-mapping paradigm that maps widgets from source apps to target apps. However, since different apps may implement the same functionality in different ways, direct mapping may result in incomplete or buggy test cases, thus significantly impacting the effectiveness of testing target functionality and the practical applicability. In this paper, we propose a new migration paradigm (i.e., abstraction-concretization paradigm) that first abstracts the test logic for the target functionality and then utilizes this logic to generate the concrete GUI test case. Furthermore, we introduce MACdroid, the first approach that migrates GUI test cases based on this paradigm. Specifically, we propose an abstraction technique that utilizes source test cases from source apps targeting the same functionality to extract a general test logic for that functionality. Then, we propose a concretization technique that utilizes the general test logic to guide an LLM in generating the corresponding GUI test case (including events and assertions) for the target app. We evaluate MACdroid on two widely-used datasets (including 31 apps, 34 functionalities, and 123 test cases). On the FrUITeR dataset, the test cases generated by MACdroid successfully test 64% of the target functionalities, improving the baselines by 191%. On the Lin dataset, MACdroid successfully tests 75% of the target functionalities, outperforming the baselines by 42%. These results underscore the effectiveness of MACdroid in GUI test migration.",
        "subjects": [
            "cs.SE",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05035",
        "abstract url": "https://arxiv.org/abs/2409.05035",
        "title": "Deep Generic Representations for Domain-Generalized Anomalous Sound Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Developing a reliable anomalous sound detection (ASD) system requires robustness to noise, adaptation to domain shifts, and effective performance with limited training data. Current leading methods rely on extensive labeled data for each target machine type to train feature extractors using Outlier-Exposure (OE) techniques, yet their performance on the target domain remains sub-optimal. In this paper, we present \\textit{GenRep}, which utilizes generic feature representations from a robust, large-scale pre-trained feature extractor combined with kNN for domain-generalized ASD, without the need for fine-tuning. \\textit{GenRep} incorporates MemMixup, a simple approach for augmenting the target memory bank using nearest source samples, paired with a domain normalization technique to address the imbalance between source and target domains. \\textit{GenRep} outperforms the best OE-based approach without a need for labeled data with an Official Score of 73.79\\% on the DCASE2023T2 Eval set and demonstrates robustness under limited data scenarios. The code is available open-source.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05080",
        "abstract url": "https://arxiv.org/abs/2409.05080",
        "title": "From Computation to Consumption: Exploring the Compute-Energy Link for Training and Testing Neural Networks for SED Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD"
            ]
        ],
        "abstract": "The massive use of machine learning models, particularly neural networks, has raised serious concerns about their environmental impact. Indeed, over the last few years we have seen an explosion in the computing costs associated with training and deploying these systems. It is, therefore, crucial to understand their energy requirements in order to better integrate them into the evaluation of models, which has so far focused mainly on performance. In this paper, we study several neural network architectures that are key components of sound event detection systems, using an audio tagging task as an example. We measure the energy consumption for training and testing small to large architectures and establish complex relationships between the energy consumption, the number of floating-point operations, the number of parameters, and the GPU/memory utilization.",
        "subjects": [
            "cs.LG",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05105",
        "abstract url": "https://arxiv.org/abs/2409.05105",
        "title": "EdaCSC: Two Easy Data Augmentation Methods for Chinese Spelling Correction",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Chinese Spelling Correction (CSC) aims to detect and correct spelling errors in Chinese sentences caused by phonetic or visual similarities. While current CSC models integrate pinyin or glyph features and have shown significant progress,they still face challenges when dealing with sentences containing multiple typos and are susceptible to overcorrection in real-world scenarios. In contrast to existing model-centric approaches, we propose two data augmentation methods to address these limitations. Firstly, we augment the dataset by either splitting long sentences into shorter ones or reducing typos in sentences with multiple typos. Subsequently, we employ different training processes to select the optimal model. Experimental evaluations on the SIGHAN benchmarks demonstrate the superiority of our approach over most existing models, achieving state-of-the-art performance on the SIGHAN15 test set.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "18 pages, 2 figures"
    },
    {
        "paper id": "2409.05125",
        "abstract url": "https://arxiv.org/abs/2409.05125",
        "title": "PdfTable: A Unified Toolkit for Deep Learning-Based Table Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Currently, a substantial volume of document data exists in an unstructured format, encompassing Portable Document Format (PDF) files and images. Extracting information from these documents presents formidable challenges due to diverse table styles, complex forms, and the inclusion of different languages. Several open-source toolkits, such as Camelot, Plumb a PDF (pdfnumber), and Paddle Paddle Structure V2 (PP-StructureV2), have been developed to facilitate table extraction from PDFs or images. However, each toolkit has its limitations. Camelot and pdfnumber can solely extract tables from digital PDFs and cannot handle image-based PDFs and pictures. On the other hand, PP-StructureV2 can comprehensively extract image-based PDFs and tables from pictures. Nevertheless, it lacks the ability to differentiate between diverse application scenarios, such as wired tables and wireless tables, digital PDFs, and image-based PDFs. To address these issues, we have introduced the PDF table extraction (PdfTable) toolkit. This toolkit integrates numerous open-source models, including seven table recognition models, four Optical character recognition (OCR) recognition tools, and three layout analysis models. By refining the PDF table extraction process, PdfTable achieves adaptability across various application scenarios. We substantiate the efficacy of the PdfTable toolkit through verification on a self-labeled wired table dataset and the open-source wireless Publicly Table Reconition Dataset (PubTabNet). The PdfTable code will available on Github: https://github.com/CycloneBoy/pdf_table.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "19 pages, 4 figures"
    },
    {
        "paper id": "2409.05136",
        "abstract url": "https://arxiv.org/abs/2409.05136",
        "title": "MHS-STMA: Multimodal Hate Speech Detection via Scalable Transformer-Based Multilevel Attention Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Social media has a significant impact on people's lives. Hate speech on social media has emerged as one of society's most serious issues recently. Text and pictures are two forms of multimodal data distributed within articles. Unimodal analysis has been the primary emphasis of earlier approaches. Additionally, when doing multimodal analysis, researchers neglect to preserve the distinctive qualities associated with each modality. The present article suggests a scalable architecture for multimodal hate content detection called transformer-based multilevel attention (STMA) to address these shortcomings. This architecture consists of three main parts: a combined attention-based deep learning mechanism, a vision attention mechanism encoder, and a caption attention-mechanism encoder. To identify hate content, each component uses various attention processes and uniquely handles multimodal data. Several studies employing multiple assessment criteria on three hate speech datasets: Hateful memes, MultiOff, and MMHS150K, validate the suggested architecture's efficacy. The outcomes demonstrate that on all three datasets, the suggested strategy performs better than the baseline approaches.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05152",
        "abstract url": "https://arxiv.org/abs/2409.05152",
        "title": "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Despite the recent advancements in Large Language Models (LLMs), which have significantly enhanced the generative capabilities for various NLP tasks, LLMs still face limitations in directly handling retrieval tasks. However, many practical applications demand the seamless integration of both retrieval and generation. This paper introduces a novel and efficient One-pass Generation and retrieval framework (OneGen), designed to improve LLMs' performance on tasks that require both generation and retrieval. The proposed framework bridges the traditionally separate training approaches for generation and retrieval by incorporating retrieval tokens generated autoregressively. This enables a single LLM to handle both tasks simultaneously in a unified forward pass. We conduct experiments on two distinct types of composite tasks, RAG and Entity Linking, to validate the pluggability, effectiveness, and efficiency of OneGen in training and inference. Furthermore, our results show that integrating generation and retrieval within the same context preserves the generative capabilities of LLMs while improving retrieval performance. To the best of our knowledge, OneGen is the first to enable LLMs to conduct vector retrieval during the generation.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DB",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "Work in progress; code is available at https://github.com/zjunlp/OneGen"
    },
    {
        "paper id": "2409.05197",
        "abstract url": "https://arxiv.org/abs/2409.05197",
        "title": "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "State-of-the-art Large Language Models (LLMs) are accredited with an increasing number of different capabilities, ranging from reading comprehension, over advanced mathematical and reasoning skills to possessing scientific knowledge. In this paper we focus on their multi-hop reasoning capability: the ability to identify and integrate information from multiple textual sources. Given the concerns with the presence of simplifying cues in existing multi-hop reasoning benchmarks, which allow models to circumvent the reasoning requirement, we set out to investigate, whether LLMs are prone to exploiting such simplifying cues. We find evidence that they indeed circumvent the requirement to perform multi-hop reasoning, but they do so in more subtle ways than what was reported about their fine-tuned pre-trained language model (PLM) predecessors. Motivated by this finding, we propose a challenging multi-hop reasoning benchmark, by generating seemingly plausible multi-hop reasoning chains, which ultimately lead to incorrect answers. We evaluate multiple open and proprietary state-of-the-art LLMs, and find that their performance to perform multi-hop reasoning is affected, as indicated by up to 45% relative decrease in F1 score when presented with such seemingly plausible alternatives. We conduct a deeper analysis and find evidence that while LLMs tend to ignore misleading lexical cues, misleading reasoning paths indeed present a significant challenge.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "16 pages, 3 figures"
    },
    {
        "paper id": "2409.05199",
        "abstract url": "https://arxiv.org/abs/2409.05199",
        "title": "Interactive Machine Teaching by Labeling Rules and Instances",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Weakly supervised learning aims to reduce the cost of labeling data by using expert-designed labeling rules. However, existing methods require experts to design effective rules in a single shot, which is difficult in the absence of proper guidance and tooling. Therefore, it is still an open question whether experts should spend their limited time writing rules or instead providing instance labels via active learning. In this paper, we investigate how to exploit an expert's limited time to create effective supervision. First, to develop practical guidelines for rule creation, we conduct an exploratory analysis of diverse collections of existing expert-designed rules and find that rule precision is more important than coverage across datasets. Second, we compare rule creation to individual instance labeling via active learning and demonstrate the importance of both across 6 datasets. Third, we propose an interactive learning framework, INTERVAL, that achieves efficiency by automatically extracting candidate rules based on rich patterns (e.g., by prompting a language model), and effectiveness by soliciting expert feedback on both candidate rules and individual instances. Across 6 datasets, INTERVAL outperforms state-of-the-art weakly supervised approaches by 7% in F1. Furthermore, it requires as few as 10 queries for expert feedback to reach F1 values that existing active learning methods cannot match even with 100 queries.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to TACL 2024"
    },
    {
        "paper id": "2409.05202",
        "abstract url": "https://arxiv.org/abs/2409.05202",
        "title": "A Survey on Mixup Augmentations and Beyond",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "As Deep Neural Networks have achieved thrilling breakthroughs in the past decade, data augmentations have garnered increasing attention as regularization techniques when massive labeled data are unavailable. Among existing augmentations, Mixup and relevant data-mixing methods that convexly combine selected samples and the corresponding labels are widely adopted because they yield high performances by generating data-dependent virtual data while easily migrating to various domains. This survey presents a comprehensive review of foundational mixup methods and their applications. We first elaborate on the training pipeline with mixup augmentations as a unified framework containing modules. A reformulated framework could contain various mixup methods and give intuitive operational procedures. Then, we systematically investigate the applications of mixup augmentations on vision downstream tasks, various data modalities, and some analysis \\& theorems of mixup. Meanwhile, we conclude the current status and limitations of mixup research and point out further work for effective and efficient mixup augmentations. This survey can provide researchers with the current state of the art in mixup methods and provide some insights and guidance roles in the mixup arena. An online project with this survey is available at \\url{https://github.com/Westlake-AI/Awesome-Mixup}.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Preprint V1 with 27 pages main text. Online project at https://github.com/Westlake-AI/Awesome-Mixup"
    },
    {
        "paper id": "2409.05224",
        "abstract url": "https://arxiv.org/abs/2409.05224",
        "title": "Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multilingual neural machine translation models support fine-tuning hundreds of languages simultaneously. However, fine-tuning on full parameters solely is inefficient potentially leading to negative interactions among languages. In this work, we demonstrate that the fine-tuning for a language occurs in its intrinsic language-specific subspace with a tiny fraction of entire parameters. Thus, we propose language-specific LoRA to isolate intrinsic language-specific subspaces. Furthermore, we propose architecture learning techniques and introduce a gradual pruning schedule during fine-tuning to exhaustively explore the optimal setting and the minimal intrinsic subspaces for each language, resulting in a lightweight yet effective fine-tuning procedure. The experimental results on a 12-language subset and a 30-language subset of FLORES-101 show that our methods not only outperform full-parameter fine-tuning up to 2.25 spBLEU scores but also reduce trainable parameters to $0.4\\%$ for high and medium-resource languages and $1.6\\%$ for low-resource ones.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05230",
        "abstract url": "https://arxiv.org/abs/2409.05230",
        "title": "A Low-Computational Video Synopsis Framework with a Standard Dataset",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video synopsis is an efficient method for condensing surveillance videos. This technique begins with the detection and tracking of objects, followed by the creation of object tubes. These tubes consist of sequences, each containing chronologically ordered bounding boxes of a unique object. To generate a condensed video, the first step involves rearranging the object tubes to maximize the number of non-overlapping objects in each frame. Then, these tubes are stitched to a background image extracted from the source video. The lack of a standard dataset for the video synopsis task hinders the comparison of different video synopsis models. This paper addresses this issue by introducing a standard dataset, called SynoClip, designed specifically for the video synopsis task. SynoClip includes all the necessary features needed to evaluate various models directly and effectively. Additionally, this work introduces a video synopsis model, called FGS, with low computational cost. The model includes an empty-frame object detector to identify frames empty of any objects, facilitating efficient utilization of the deep object detector. Moreover, a tube grouping algorithm is proposed to maintain relationships among tubes in the synthesized video. This is followed by a greedy tube rearrangement algorithm, which efficiently determines the start time of each tube. Finally, the proposed model is evaluated using the proposed dataset. The source code, fine-tuned object detection model, and tutorials are available at https://github.com/Ramtin-ma/VideoSynopsis-FGS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 8 figures"
    },
    {
        "paper id": "2409.05243",
        "abstract url": "https://arxiv.org/abs/2409.05243",
        "title": "Mamba-Enhanced Text-Audio-Video Alignment Network for Emotion Recognition in Conversations",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Emotion Recognition in Conversations (ERCs) is a vital area within multimodal interaction research, dedicated to accurately identifying and classifying the emotions expressed by speakers throughout a conversation. Traditional ERC approaches predominantly rely on unimodal cues\\-such as text, audio, or visual data\\-leading to limitations in their effectiveness. These methods encounter two significant challenges: 1) Consistency in multimodal information. Before integrating various modalities, it is crucial to ensure that the data from different sources is aligned and coherent. 2) Contextual information capture. Successfully fusing multimodal features requires a keen understanding of the evolving emotional tone, especially in lengthy dialogues where emotions may shift and develop over time. To address these limitations, we propose a novel Mamba-enhanced Text-Audio-Video alignment network (MaTAV) for the ERC task. MaTAV is with the advantages of aligning unimodal features to ensure consistency across different modalities and handling long input sequences to better capture contextual multimodal information. The extensive experiments on the MELD and IEMOCAP datasets demonstrate that MaTAV significantly outperforms existing state-of-the-art methods on the ERC task with a big margin.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05247",
        "abstract url": "https://arxiv.org/abs/2409.05247",
        "title": "Socially Responsible Data for Large Multilingual Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have rapidly increased in size and apparent capabilities in the last three years, but their training data is largely English text. There is growing interest in multilingual LLMs, and various efforts are striving for models to accommodate languages of communities outside of the Global North, which include many languages that have been historically underrepresented in digital realms. These languages have been coined as \"low resource languages\" or \"long-tail languages\", and LLMs performance on these languages is generally poor. While expanding the use of LLMs to more languages may bring many potential benefits, such as assisting cross-community communication and language preservation, great care must be taken to ensure that data collection on these languages is not extractive and that it does not reproduce exploitative practices of the past. Collecting data from languages spoken by previously colonized people, indigenous people, and non-Western languages raises many complex sociopolitical and ethical questions, e.g., around consent, cultural safety, and data sovereignty. Furthermore, linguistic complexity and cultural nuances are often lost in LLMs. This position paper builds on recent scholarship, and our own work, and outlines several relevant social, cultural, and ethical considerations and potential ways to mitigate them through qualitative research, community partnerships, and participatory design approaches. We provide twelve recommendations for consideration when collecting language data on underrepresented language communities outside of the Global North.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05257",
        "abstract url": "https://arxiv.org/abs/2409.05257",
        "title": "UPCS: Unbiased Persona Construction for Dialogue Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Narrative systems, such as dialogue and storytelling systems, often utilize persona profiles to enhance personalized interactions. Existing persona profiles frequently exhibit biases, posing risks to system integrity and fairness. To address this, we introduce the UPCS framework, which categorizes character descriptions into eight dimensions, including bias mitigation strategies. Experimental results demonstrate UPCS's superiority in accuracy, diversity, bias elimination, and user satisfaction, marking a significant advancement in persona construction for reliable narrative systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05260",
        "abstract url": "https://arxiv.org/abs/2409.05260",
        "title": "Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Given a video with $T$ frames, frame sampling is a task to select $N \\ll T$ frames, so as to maximize the performance of a fixed video classifier. Not just brute-force search, but most existing methods suffer from its vast search space of $\\binom{T}{N}$, especially when $N$ gets large. To address this challenge, we introduce a novel perspective of reducing the search space from $O(T^N)$ to $O(T)$. Instead of exploring the entire $O(T^N)$ space, our proposed semi-optimal policy selects the top $N$ frames based on the independently estimated value of each frame using per-frame confidence, significantly reducing the computational complexity. We verify that our semi-optimal policy can efficiently approximate the optimal policy, particularly under practical settings. Additionally, through extensive experiments on various datasets and model architectures, we demonstrate that learning our semi-optimal policy ensures stable and high performance regardless of the size of $N$ and $T$.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05275",
        "abstract url": "https://arxiv.org/abs/2409.05275",
        "title": "RexUniNLU: Recursive Method with Explicit Schema Instructor for Universal NLU",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Information Extraction (IE) and Text Classification (CLS) serve as the fundamental pillars of NLU, with both disciplines relying on analyzing input sequences to categorize outputs into pre-established schemas. However, there is no existing encoder-based model that can unify IE and CLS tasks from this perspective. To fully explore the foundation shared within NLU tasks, we have proposed a Recursive Method with Explicit Schema Instructor for Universal NLU. Specifically, we firstly redefine the true universal information extraction (UIE) with a formal formulation that covers almost all extraction schemas, including quadruples and quintuples which remain unsolved for previous UIE models. Then, we expands the formulation to all CLS and multi-modal NLU tasks. Based on that, we introduce RexUniNLU, an universal NLU solution that employs explicit schema constraints for IE and CLS, which encompasses all IE and CLS tasks and prevent incorrect connections between schema and input sequence. To avoid interference between different schemas, we reset the position ids and attention mask matrices. Extensive experiments are conducted on IE, CLS in both English and Chinese, and multi-modality, revealing the effectiveness and superiority. Our codes are publicly released.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2304.14770"
    },
    {
        "paper id": "2409.05283",
        "abstract url": "https://arxiv.org/abs/2409.05283",
        "title": "On the Relationship between Truth and Political Bias in Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Language model alignment research often attempts to ensure that models are not only helpful and harmless, but also truthful and unbiased. However, optimizing these objectives simultaneously can obscure how improving one aspect might impact the others. In this work, we focus on analyzing the relationship between two concepts essential in both language model alignment and political science: \\textit{truthfulness} and \\textit{political bias}. We train reward models on various popular truthfulness datasets and subsequently evaluate their political bias. Our findings reveal that optimizing reward models for truthfulness on these datasets tends to result in a left-leaning political bias. We also find that existing open-source reward models (i.e. those trained on standard human preference datasets) already show a similar bias and that the bias is larger for larger models. These results raise important questions about both the datasets used to represent truthfulness and what language models capture about the relationship between truth and politics.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05307",
        "abstract url": "https://arxiv.org/abs/2409.05307",
        "title": "RAL:Redundancy-Aware Lipreading Model Based on Differential Learning with Symmetric Views",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Lip reading involves interpreting a speaker's speech by analyzing sequences of lip movements. Currently, most models regard the left and right halves of the lips as a symmetrical whole, lacking a thorough investigation of their differences. However, the left and right halves of the lips are not always symmetrical, and the subtle differences between them contain rich semantic information. In this paper, we propose a differential learning strategy with symmetric views (DLSV) to address this issue. Additionally, input images often contain a lot of redundant information unrelated to recognition results, which can degrade the model's performance. We present a redundancy-aware operation (RAO) to reduce it. Finally, to leverage the relational information between symmetric views and within each view, we further design an adaptive cross-view interaction module (ACVI). Experiments on LRW and LRW-1000 datasets fully demonstrate the effectiveness of our approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2409.04994",
        "abstract url": "https://arxiv.org/abs/2409.04994",
        "title": "Learning nonnegative matrix factorizations from compressed data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a flexible and theoretically supported framework for scalable nonnegative matrix factorization. The goal is to find nonnegative low-rank components directly from compressed measurements, accessing the original data only once or twice. We consider compression through randomized sketching methods that can be adapted to the data, or can be oblivious. We formulate optimization problems that only depend on the compressed data, but which can recover a nonnegative factorization which closely approximates the original matrix. The defined problems can be approached with a variety of algorithms, and in particular, we discuss variations of the popular multiplicative updates method for these compressed problems. We demonstrate the success of our approaches empirically and validate their performance in real-world applications.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05001",
        "abstract url": "https://arxiv.org/abs/2409.05001",
        "title": "A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models (LLMs) have achieved impressive performance on code generation. Although prior studies enhanced LLMs with prompting techniques and code refinement, they still struggle with complex programming problems due to rigid solution plans. In this paper, we draw on pair programming practices to propose PairCoder, a novel LLM-based framework for code generation. PairCoder incorporates two collaborative LLM agents, namely a Navigator agent for high-level planning and a Driver agent for specific implementation. The Navigator is responsible for proposing promising solution plans, selecting the current optimal plan, and directing the next iteration round based on execution feedback. The Driver follows the guidance of Navigator to undertake initial code generation, code testing, and refinement. This interleaved and iterative workflow involves multi-plan exploration and feedback-based refinement, which mimics the collaboration of pair programmers. We evaluate PairCoder with both open-source and closed-source LLMs on various code generation benchmarks. Extensive experimental results demonstrate the superior accuracy of PairCoder, achieving relative pass@1 improvements of 12.00%-162.43% compared to prompting LLMs directly.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Accepted in the 39th IEEE/ACM International Conference on Automated Software Engineering (ASE 2024)"
    },
    {
        "paper id": "2409.05023",
        "abstract url": "https://arxiv.org/abs/2409.05023",
        "title": "Asymptotic and Non-Asymptotic Convergence Analysis of AdaGrad for Non-Convex Optimization via Novel Stopping Time-based Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Adaptive optimizers have emerged as powerful tools in deep learning, dynamically adjusting the learning rate based on iterative gradients. These adaptive methods have significantly succeeded in various deep learning tasks, outperforming stochastic gradient descent (SGD). However, although AdaGrad is a cornerstone adaptive optimizer, its theoretical analysis is inadequate in addressing asymptotic convergence and non-asymptotic convergence rates on non-convex optimization. This study aims to provide a comprehensive analysis and complete picture of AdaGrad. We first introduce a novel stopping time technique from probabilistic theory to establish stability for the norm version of AdaGrad under milder conditions. We further derive two forms of asymptotic convergence: almost sure and mean-square. Furthermore, we demonstrate the near-optimal non-asymptotic convergence rate measured by the average-squared gradients in expectation, which is rarely explored and stronger than the existing high-probability results, under the mild assumptions. The techniques developed in this work are potentially independent of interest for future research on other adaptive stochastic algorithms.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "38 pages"
    },
    {
        "paper id": "2409.05034",
        "abstract url": "https://arxiv.org/abs/2409.05034",
        "title": "TF-Mamba: A Time-Frequency Network for Sound Source Localization",
        "rating": "0.5",
        "keywords": [
            [
                "speech enhancement"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Sound source localization (SSL) determines the position of sound sources using multi-channel audio data. It is commonly used to improve speech enhancement and separation. Extracting spatial features is crucial for SSL, especially in challenging acoustic environments. Previous studies performed well based on long short-term memory models. Recently, a novel scalable SSM referred to as Mamba demonstrated notable performance across various sequence-based modalities, including audio and speech. This study introduces the Mamba for SSL tasks. We consider the Mamba-based model to analyze spatial features from speech signals by fusing both time and frequency features, and we develop an SSL system called TF-Mamba. This system integrates time and frequency fusion, with Bidirectional Mamba managing both time-wise and frequency-wise processing. We conduct the experiments on the simulated dataset and the LOCATA dataset. Experiments show that TF-Mamba significantly outperforms other advanced methods on simulated and real-world data.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.05061",
        "abstract url": "https://arxiv.org/abs/2409.05061",
        "title": "Dynamic Demand Management for Parcel Lockers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In pursuit of a more sustainable and cost-efficient last mile, parcel lockers have gained a firm foothold in the parcel delivery landscape. To fully exploit their potential and simultaneously ensure customer satisfaction, successful management of the locker's limited capacity is crucial. This is challenging as future delivery requests and pickup times are stochastic from the provider's perspective. In response, we propose to dynamically control whether the locker is presented as an available delivery option to each incoming customer with the goal of maximizing the number of served requests weighted by their priority. Additionally, we take different compartment sizes into account, which entails a second type of decision as parcels scheduled for delivery must be allocated. We formalize the problem as an infinite-horizon sequential decision problem and find that exact methods are intractable due to the curses of dimensionality. In light of this, we develop a solution framework that orchestrates multiple algorithmic techniques rooted in Sequential Decision Analytics and Reinforcement Learning, namely cost function approximation and an offline trained parametric value function approximation together with a truncated online rollout. Our innovative approach to combine these techniques enables us to address the strong interrelations between the two decision types. As a general methodological contribution, we enhance the training of our value function approximation with a modified version of experience replay that enforces structure in the value function. Our computational study shows that our method outperforms a myopic benchmark by 13.7% and an industry-inspired policy by 12.6%.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05072",
        "abstract url": "https://arxiv.org/abs/2409.05072",
        "title": "A General Framework for Clustering and Distribution Matching with Bandit Feedback",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop a general framework for clustering and distribution matching problems with bandit feedback. We consider a $K$-armed bandit model where some subset of $K$ arms is partitioned into $M$ groups. Within each group, the random variable associated to each arm follows the same distribution on a finite alphabet. At each time step, the decision maker pulls an arm and observes its outcome from the random variable associated to that arm. Subsequent arm pulls depend on the history of arm pulls and their outcomes. The decision maker has no knowledge of the distributions of the arms or the underlying partitions. The task is to devise an online algorithm to learn the underlying partition of arms with the least number of arm pulls on average and with an error probability not exceeding a pre-determined value $\u03b4$. Several existing problems fall under our general framework, including finding $M$ pairs of arms, odd arm identification, and $M$-ary clustering of $K$ arms belong to our general framework. We derive a non-asymptotic lower bound on the average number of arm pulls for any online algorithm with an error probability not exceeding $\u03b4$. Furthermore, we develop a computationally-efficient online algorithm based on the Track-and-Stop method and Frank--Wolfe algorithm, and show that the average number of arm pulls of our algorithm asymptotically matches that of the lower bound. Our refined analysis also uncovers a novel bound on the speed at which the average number of arm pulls of our algorithm converges to the fundamental limit as $\u03b4$ vanishes.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "22 pages, submitted to Information Theory Transactions in September 2024"
    },
    {
        "paper id": "2409.05082",
        "abstract url": "https://arxiv.org/abs/2409.05082",
        "title": "The limits of progress in the digital era",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The concept of progress clearly percolates the activities in science, technology, economy and society. It is a driving vector (probably the main vector) of our daily activity as researchers. The InThisGen initiative, proudly displayed in places across the University of Berkeley campus, and its headline lemma (what can we change in a single generation?) are clear exponents of the underlying assumption that progress is not only possible but also desirable. But about the concept of progress two major concerns arise. First of all, progress means some kind of going forward, that is a direction in a journey. But deciding the way in the route clearly implies that we are explicit or implicitly defining the goals, as individuals and as society. That is, the concept of progress has a set of underlying values. Additionally, the conceptual paradigm in scientific research (and probably in the whole spirit of our times) it is assuming some kind of endless progress. It is true that many technological innovations and their subsequent impact on society have found resistance, from Luddites to ecologist movements. But the last 150 years (the age of our university) have been witness of an enormous and general increase in knowledge, wealth and welfare, showing how progress can be sustained in the long-term and positively influence the human beings and the society. In this contribution will try to discuss these bounds, addressing the limits of materials, scientific knowledge and technological know-how. We will mainly focus on the limitations in technological knowledge in the software design, a key aspect of the digital era. Our main thesis, which will be addressed through the paper, is that there are intrinsic limits to technological knowledge and the concept of progress should take them into account.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "2018 HSSA (Humanities and Social Sciences Association) Symposium. Berkeley, California, USA"
    },
    {
        "paper id": "2409.05084",
        "abstract url": "https://arxiv.org/abs/2409.05084",
        "title": "Adaptive $k$-nearest neighbor classifier based on the local estimation of the shape operator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The $k$-nearest neighbor ($k$-NN) algorithm is one of the most popular methods for nonparametric classification. However, a relevant limitation concerns the definition of the number of neighbors $k$. This parameter exerts a direct impact on several properties of the classifier, such as the bias-variance tradeoff, smoothness of decision boundaries, robustness to noise, and class imbalance handling. In the present paper, we introduce a new adaptive $k$-nearest neighbours ($kK$-NN) algorithm that explores the local curvature at a sample to adaptively defining the neighborhood size. The rationale is that points with low curvature could have larger neighborhoods (locally, the tangent space approximates well the underlying data shape), whereas points with high curvature could have smaller neighborhoods (locally, the tangent space is a loose approximation). We estimate the local Gaussian curvature by computing an approximation to the local shape operator in terms of the local covariance matrix as well as the local Hessian matrix. Results on many real-world datasets indicate that the new $kK$-NN algorithm yields superior balanced accuracy compared to the established $k$-NN method and also another adaptive $k$-NN algorithm. This is particularly evident when the number of samples in the training data is limited, suggesting that the $kK$-NN is capable of learning more discriminant functions with less data considering many relevant cases.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IT"
        ],
        "comment": "18 pages, 4 figures"
    },
    {
        "paper id": "2409.05139",
        "abstract url": "https://arxiv.org/abs/2409.05139",
        "title": "Revisiting Trace Norm Minimization for Tensor Tucker Completion: A Direct Multilinear Rank Learning Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "To efficiently express tensor data using the Tucker format, a critical task is to minimize the multilinear rank such that the model would not be over-flexible and lead to overfitting. Due to the lack of rank minimization tools in tensor, existing works connect Tucker multilinear rank minimization to trace norm minimization of matrices unfolded from the tensor data. While these formulations try to exploit the common aim of identifying the low-dimensional structure of the tensor and matrix, this paper reveals that existing trace norm-based formulations in Tucker completion are inefficient in multilinear rank minimization. We further propose a new interpretation of Tucker format such that trace norm minimization is applied to the factor matrices of the equivalent representation, rather than some matrices unfolded from tensor data. Based on the newly established problem formulation, a fixed point iteration algorithm is proposed, and its convergence is proved. Numerical results are presented to show that the proposed algorithm exhibits significant improved performance in terms of multilinear rank learning and consequently tensor signal recovery accuracy, compared to existing trace norm based Tucker completion methods.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05144",
        "abstract url": "https://arxiv.org/abs/2409.05144",
        "title": "QuantFactor REINFORCE: Mining Steady Formulaic Alpha Factors with Variance-bounded REINFORCE",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The goal of alpha factor mining is to discover indicative signals of investment opportunities from the historical financial market data of assets. Deep learning based alpha factor mining methods have shown to be powerful, which, however, lack of the interpretability, making them unacceptable in the risk-sensitive real markets. Alpha factors in formulaic forms are more interpretable and therefore favored by market participants, while the search space is complex and powerful explorative methods are urged. Recently, a promising framework is proposed for generating formulaic alpha factors using deep reinforcement learning, and quickly gained research focuses from both academia and industries. This paper first argues that the originally employed policy training method, i.e., Proximal Policy Optimization (PPO), faces several important issues in the context of alpha factors mining, making it ineffective to explore the search space of the formula. Herein, a novel reinforcement learning based on the well-known REINFORCE algorithm is proposed. Given that the underlying state transition function adheres to the Dirac distribution, the Markov Decision Process within this framework exhibit minimal environmental variability, making REINFORCE algorithm more appropriate than PPO. A new dedicated baseline is designed to theoretically reduce the commonly suffered high variance of REINFORCE. Moreover, the information ratio is introduced as a reward shaping mechanism to encourage the generation of steady alpha factors that can better adapt to changes in market volatility. Experimental evaluations on various real assets data show that the proposed algorithm can increase the correlation with asset returns by 3.83%, and a stronger ability to obtain excess returns compared to the latest alpha factors mining methods, which meets the theoretical results well.",
        "subjects": [
            "q-fin.CP",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "15 pages, 7 figures"
    },
    {
        "paper id": "2409.05177",
        "abstract url": "https://arxiv.org/abs/2409.05177",
        "title": "Insights from Benchmarking Frontier Language Models on Web App Code Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents insights from evaluating 16 frontier large language models (LLMs) on the WebApp1K benchmark, a test suite designed to assess the ability of LLMs to generate web application code. The results reveal that while all models possess similar underlying knowledge, their performance is differentiated by the frequency of mistakes they make. By analyzing lines of code (LOC) and failure distributions, we find that writing correct code is more complex than generating incorrect code. Furthermore, prompt engineering shows limited efficacy in reducing errors beyond specific cases. These findings suggest that further advancements in coding LLM should emphasize on model reliability and mistake minimization.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05181",
        "abstract url": "https://arxiv.org/abs/2409.05181",
        "title": "Sliding-Window Thompson Sampling for Non-Stationary Settings",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "$\\textit{Restless Bandits}$ describe sequential decision-making problems in which the rewards evolve with time independently from the actions taken by the policy-maker. It has been shown that classical Bandit algorithms fail when the underlying environment is changing, making clear that in order to tackle more challenging scenarios specifically crafted algorithms are needed. In this paper, extending and correcting the work by \\cite{trovo2020sliding}, we analyze two Thompson-Sampling inspired algorithms, namely $\\texttt{BETA-SWTS}$ and $\\texttt{$\u03b3$-SWGTS}$, introduced to face the additional complexity given by the non-stationary nature of the settings; in particular we derive a general formulation for the regret in $\\textit{any}$ arbitrary restless environment for both Bernoulli and Subgaussian rewards, and, through the introduction of new quantities, we delve in what contribution lays the deeper foundations of the error made by the algorithms. Finally, we infer from the general formulation the regret for two of the most common non-stationary settings: the $\\textit{Abruptly Changing}$ and the $\\textit{Smoothly Changing}$ environments.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2409.05192",
        "abstract url": "https://arxiv.org/abs/2409.05192",
        "title": "Bellwether Trades: Characteristics of Trades influential in Predicting Future Price Movements in Markets",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we leverage powerful non-linear machine learning methods to identify the characteristics of trades that contain valuable information. First, we demonstrate the effectiveness of our optimized neural network predictor in accurately predicting future market movements. Then, we utilize the information from this successful neural network predictor to pinpoint the individual trades within each data point (trading window) that had the most impact on the optimized neural network's prediction of future price movements. This approach helps us uncover important insights about the heterogeneity in information content provided by trades of different sizes, venues, trading contexts, and over time.",
        "subjects": [
            "q-fin.TR",
            "cs.LG",
            "econ.EM",
            "stat.ML"
        ],
        "comment": "49 Pages"
    },
    {
        "paper id": "2409.05227",
        "abstract url": "https://arxiv.org/abs/2409.05227",
        "title": "BBS: Bi-directional Bit-level Sparsity for Deep Learning Acceleration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bit-level sparsity methods skip ineffectual zero-bit operations and are typically applicable within bit-serial deep learning accelerators. This type of sparsity at the bit-level is especially interesting because it is both orthogonal and compatible with other deep neural network (DNN) efficiency methods such as quantization and pruning. In this work, we improve the practicality and efficiency of bitlevel sparsity through a novel algorithmic bit-pruning, averaging, and compression method, and a co-designed efficient bit-serial hardware accelerator. On the algorithmic side, we introduce bidirectional bit sparsity (BBS). The key insight of BBS is that we can leverage bit sparsity in a symmetrical way to prune either zero-bits or one-bits. This significantly improves the load balance of bit-serial computing and guarantees the level of sparsity to be more than 50%. On top of BBS, we further propose two bit-level binary pruning methods that require no retraining, and can be seamlessly applied to quantized DNNs. Combining binary pruning with a new tensor encoding scheme, BBS can both skip computation and reduce the memory footprint associated with bi-directional sparse bit columns. On the hardware side, we demonstrate the potential of BBS through BitVert, a bitserial architecture with an efficient PE design to accelerate DNNs with low overhead, exploiting our proposed binary pruning. Evaluation on seven representative DNN models shows that our approach achieves: (1) on average 1.66$\\times$ reduction in model sizewith negligible accuracy loss of < 0.5%; (2) up to 3.03$\\times$ speedupand 2.44$\\times$ energy saving compared to prior DNN accelerators.",
        "subjects": [
            "cs.LG",
            "cs.AR"
        ],
        "comment": "Accepted by IEEE/ACM MICRO 2024"
    },
    {
        "paper id": "2409.05234",
        "abstract url": "https://arxiv.org/abs/2409.05234",
        "title": "Empowering Bayesian Neural Networks with Functional Priors through Anchored Ensembling for Mechanics Surrogate Modeling Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, neural networks (NNs) have become increasingly popular for surrogate modeling tasks in mechanics and materials modeling applications. While traditional NNs are deterministic functions that rely solely on data to learn the input--output mapping, casting NN training within a Bayesian framework allows to quantify uncertainties, in particular epistemic uncertainties that arise from lack of training data, and to integrate a priori knowledge via the Bayesian prior. However, the high dimensionality and non-physicality of the NN parameter space, and the complex relationship between parameters (NN weights) and predicted outputs, renders both prior design and posterior inference challenging. In this work we present a novel BNN training scheme based on anchored ensembling that can integrate a priori information available in the function space, from e.g. low-fidelity models. The anchoring scheme makes use of low-rank correlations between NN parameters, learnt from pre-training to realizations of the functional prior. We also perform a study to demonstrate how correlations between NN weights, which are often neglected in existing BNN implementations, is critical to appropriately transfer knowledge between the function-space and parameter-space priors. Performance of our novel BNN algorithm is first studied on a small 1D example to illustrate the algorithm's behavior in both interpolation and extrapolation settings. Then, a thorough assessment is performed on a multi--input--output materials surrogate modeling example, where we demonstrate the algorithm's capabilities both in terms of accuracy and quality of the uncertainty estimation, for both in-distribution and out-of-distribution data.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "24 pages, 14 figures"
    },
    {
        "paper id": "2409.05265",
        "abstract url": "https://arxiv.org/abs/2409.05265",
        "title": "Learning Submodular Sequencing from Samples",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses the problem of sequential submodular maximization: selecting and ranking items in a sequence to optimize some composite submodular function. In contrast to most of the previous works, which assume access to the utility function, we assume that we are given only a set of samples. Each sample includes a random sequence of items and its associated utility. We present an algorithm that, given polynomially many samples drawn from a two-stage uniform distribution, achieves an approximation ratio dependent on the curvature of individual submodular functions. Our results apply in a wide variety of real-world scenarios, such as ranking products in online retail platforms, where complete knowledge of the utility function is often impossible to obtain. Our algorithm gives an empirically useful solution in such contexts, thus proving that limited data can be of great use in sequencing tasks. From a technical perspective, our results extend prior work on ``optimization from samples'' by generalizing from optimizing a set function to a sequence-dependent function.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05291",
        "abstract url": "https://arxiv.org/abs/2409.05291",
        "title": "Towards Fast Rates for Federated and Multi-Task Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider a setting involving $N$ agents, where each agent interacts with an environment modeled as a Markov Decision Process (MDP). The agents' MDPs differ in their reward functions, capturing heterogeneous objectives/tasks. The collective goal of the agents is to communicate intermittently via a central server to find a policy that maximizes the average of long-term cumulative rewards across environments. The limited existing work on this topic either only provide asymptotic rates, or generate biased policies, or fail to establish any benefits of collaboration. In response, we propose Fast-FedPG - a novel federated policy gradient algorithm with a carefully designed bias-correction mechanism. Under a gradient-domination condition, we prove that our algorithm guarantees (i) fast linear convergence with exact gradients, and (ii) sub-linear rates that enjoy a linear speedup w.r.t. the number of agents with noisy, truncated policy gradients. Notably, in each case, the convergence is to a globally optimal policy with no heterogeneity-induced bias. In the absence of gradient-domination, we establish convergence to a first-order stationary point at a rate that continues to benefit from collaboration.",
        "subjects": [
            "cs.LG",
            "eess.SY",
            "math.OC"
        ],
        "comment": "Accepted to the Decision and Control Conference (CDC), 2024"
    },
    {
        "paper id": "2409.05305",
        "abstract url": "https://arxiv.org/abs/2409.05305",
        "title": "Closed-Form Interpretation of Neural Network Latent Spaces with Symbolic Gradients",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "It has been demonstrated in many scientific fields that artificial neural networks like autoencoders or Siamese networks encode meaningful concepts in their latent spaces. However, there does not exist a comprehensive framework for retrieving this information in a human-readable form without prior knowledge. In order to extract these concepts, we introduce a framework for finding closed-form interpretations of neurons in latent spaces of artificial neural networks. The interpretation framework is based on embedding trained neural networks into an equivalence class of functions that encode the same concept. We interpret these neural networks by finding an intersection between the equivalence class and human-readable equations defined by a symbolic search space. The approach is demonstrated by retrieving invariants of matrices and conserved quantities of dynamical systems from latent spaces of Siamese neural networks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05325",
        "abstract url": "https://arxiv.org/abs/2409.05325",
        "title": "Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian optimization (BO) is a powerful approach to sample-efficient optimization of black-box functions. However, in settings with very few function evaluations, a successful application of BO may require transferring information from historical experiments. These related experiments may not have exactly the same tunable parameters (search spaces), motivating the need for BO with transfer learning for heterogeneous search spaces. In this paper, we propose two methods for this setting. The first approach leverages a Gaussian process (GP) model with a conditional kernel to transfer information between different search spaces. Our second approach treats the missing parameters as hyperparameters of the GP model that can be inferred jointly with the other GP hyperparameters or set to fixed values. We show that these two methods perform well on several benchmark problems.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04977",
        "abstract url": "https://arxiv.org/abs/2409.04977",
        "title": "Enhancing Convolutional Neural Networks with Higher-Order Numerical Difference Methods",
        "rating": "0",
        "keywords": [
            [
                "architecture search"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "With the rise of deep learning technology in practical applications, Convolutional Neural Networks (CNNs) have been able to assist humans in solving many real-world problems. To enhance the performance of CNNs, numerous network architectures have been explored. Some of these architectures are designed based on the accumulated experience of researchers over time, while others are designed through neural architecture search methods. The improvements made to CNNs by the aforementioned methods are quite significant, but most of the improvement methods are limited in reality by model size and environmental constraints, making it difficult to fully realize the improved performance. In recent years, research has found that many CNN structures can be explained by the discretization of ordinary differential equations. This implies that we can design theoretically supported deep network structures using higher-order numerical difference methods. It should be noted that most of the previous CNN model structures are based on low-order numerical methods. Therefore, considering that the accuracy of linear multi-step numerical difference methods is higher than that of the forward Euler method, this paper proposes a stacking scheme based on the linear multi-step method. This scheme enhances the performance of ResNet without increasing the model size and compares it with the Runge-Kutta scheme. The experimental results show that the performance of the stacking scheme proposed in this paper is superior to existing stacking schemes (ResNet and HO-ResNet), and it has the capability to be extended to other types of neural networks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05021",
        "abstract url": "https://arxiv.org/abs/2409.05021",
        "title": "Vision-fused Attack: Advancing Aggressive and Stealthy Adversarial Text against Neural Machine Translation",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "While neural machine translation (NMT) models achieve success in our daily lives, they show vulnerability to adversarial attacks. Despite being harmful, these attacks also offer benefits for interpreting and enhancing NMT models, thus drawing increased research attention. However, existing studies on adversarial attacks are insufficient in both attacking ability and human imperceptibility due to their sole focus on the scope of language. This paper proposes a novel vision-fused attack (VFA) framework to acquire powerful adversarial text, i.e., more aggressive and stealthy. Regarding the attacking ability, we design the vision-merged solution space enhancement strategy to enlarge the limited semantic solution space, which enables us to search for adversarial candidates with higher attacking ability. For human imperceptibility, we propose the perception-retained adversarial text selection strategy to align the human text-reading mechanism. Thus, the finally selected adversarial text could be more deceptive. Extensive experiments on various models, including large language models (LLMs) like LLaMA and GPT-3.5, strongly support that VFA outperforms the comparisons by large margins (up to 81%/14% improvements on ASR/SSIM).",
        "subjects": [
            "cs.CL"
        ],
        "comment": "IJCAI 2024"
    },
    {
        "paper id": "2409.05032",
        "abstract url": "https://arxiv.org/abs/2409.05032",
        "title": "Exploring WavLM Back-ends for Speech Spoofing and Deepfake Detection",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper describes our submitted systems to the ASVspoof 5 Challenge Track 1: Speech Deepfake Detection - Open Condition, which consists of a stand-alone speech deepfake (bonafide vs spoof) detection task. Recently, large-scale self-supervised models become a standard in Automatic Speech Recognition (ASR) and other speech processing tasks. Thus, we leverage a pre-trained WavLM as a front-end model and pool its representations with different back-end techniques. The complete framework is fine-tuned using only the trained dataset of the challenge, similar to the close condition. Besides, we adopt data-augmentation by adding noise and reverberation using MUSAN noise and RIR datasets. We also experiment with codec augmentations to increase the performance of our method. Ultimately, we use the Bosaris toolkit for score calibration and system fusion to get better Cllr scores. Our fused system achieves 0.0937 minDCF, 3.42% EER, 0.1927 Cllr, and 0.1375 actDCF.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05065",
        "abstract url": "https://arxiv.org/abs/2409.05065",
        "title": "Sight View Constraint for Robust Point Cloud Registration",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Partial to Partial Point Cloud Registration (partial PCR) remains a challenging task, particularly when dealing with a low overlap rate. In comparison to the full-to-full registration task, we find that the objective of partial PCR is still not well-defined, indicating no metric can reliably identify the true transformation. We identify this as the most fundamental challenge in partial PCR tasks. In this paper, instead of directly seeking the optimal transformation, we propose a novel and general Sight View Constraint (SVC) to conclusively identify incorrect transformations, thereby enhancing the robustness of existing PCR methods. Extensive experiments validate the effectiveness of SVC on both indoor and outdoor scenes. On the challenging 3DLoMatch dataset, our approach increases the registration recall from 78\\% to 82\\%, achieving the state-of-the-art result. This research also highlights the significance of the decision version problem of partial PCR, which has the potential to provide novel insights into the partial PCR problem.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2409.05076",
        "abstract url": "https://arxiv.org/abs/2409.05076",
        "title": "PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "SVM"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Large Vision-Language Models (LVLMs) have demonstrated their powerful multimodal capabilities. However, they also face serious safety problems, as adversaries can induce robustness issues in LVLMs through the use of well-designed adversarial examples. Therefore, LVLMs are in urgent need of detection tools for adversarial examples to prevent incorrect responses. In this work, we first discover that LVLMs exhibit regular attention patterns for clean images when presented with probe questions. We propose an unconventional method named PIP, which utilizes the attention patterns of one randomly selected irrelevant probe question (e.g., \"Is there a clock?\") to distinguish adversarial examples from clean examples. Regardless of the image to be tested and its corresponding question, PIP only needs to perform one additional inference of the image to be tested and the probe question, and then achieves successful detection of adversarial examples. Even under black-box attacks and open dataset scenarios, our PIP, coupled with a simple SVM, still achieves more than 98% recall and a precision of over 90%. Our PIP is the first attempt to detect adversarial attacks on LVLMs via simple irrelevant probe questions, shedding light on deeper understanding and introspection within LVLMs. The code is available at https://github.com/btzyd/pip.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted by ACM Multimedia 2024 BNI track (Oral)"
    },
    {
        "paper id": "2409.05134",
        "abstract url": "https://arxiv.org/abs/2409.05134",
        "title": "Hate Content Detection via Novel Pre-Processing Sequencing and Ensemble Methods",
        "rating": "0",
        "keywords": [
            [
                "Support Vector Machine"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Social media, particularly Twitter, has seen a significant increase in incidents like trolling and hate speech. Thus, identifying hate speech is the need of the hour. This paper introduces a computational framework to curb the hate content on the web. Specifically, this study presents an exhaustive study of pre-processing approaches by studying the impact of changing the sequence of text pre-processing operations for the identification of hate content. The best-performing pre-processing sequence, when implemented with popular classification approaches like Support Vector Machine, Random Forest, Decision Tree, Logistic Regression and K-Neighbor provides a considerable boost in performance. Additionally, the best pre-processing sequence is used in conjunction with different ensemble methods, such as bagging, boosting and stacking to improve the performance further. Three publicly available benchmark datasets (WZ-LS, DT, and FOUNTA), were used to evaluate the proposed approach for hate speech identification. The proposed approach achieves a maximum accuracy of 95.14% highlighting the effectiveness of the unique pre-processing approach along with an ensemble classifier.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05148",
        "abstract url": "https://arxiv.org/abs/2409.05148",
        "title": "Better Spanish Emotion Recognition In-the-wild: Bringing Attention to Deep Spectrum Voice Analysis",
        "rating": "0",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.CV",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Within the context of creating new Socially Assistive Robots, emotion recognition has become a key development factor, as it allows the robot to adapt to the user's emotional state in the wild. In this work, we focused on the analysis of two voice recording Spanish datasets: ELRA-S0329 and EmoMatchSpanishDB. Specifically, we centered our work in the paralanguage, e.~g. the vocal characteristics that go along with the message and clarifies the meaning. We proposed the use of the DeepSpectrum method, which consists of extracting a visual representation of the audio tracks and feeding them to a pretrained CNN model. For the classification task, DeepSpectrum is often paired with a Support Vector Classifier --DS-SVC--, or a Fully-Connected deep-learning classifier --DS-FC--. We compared the results of the DS-SVC and DS-FC architectures with the state-of-the-art (SOTA) for ELRA-S0329 and EmoMatchSpanishDB. Moreover, we proposed our own classifier based upon Attention Mechanisms, namely DS-AM. We trained all models against both datasets, and we found that our DS-AM model outperforms the SOTA models for the datasets and the SOTA DeepSpectrum architectures. Finally, we trained our DS-AM model in one dataset and tested it in the other, to simulate real-world conditions on how biased is the model to the dataset.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "cs.CV",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05159",
        "abstract url": "https://arxiv.org/abs/2409.05159",
        "title": "Image color consistency in datasets: the Smooth-TPS3D method",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image color consistency is the key problem in digital imaging consistency when creating datasets. Here, we propose an improved 3D Thin-Plate Splines (TPS3D) color correction method to be used, in conjunction with color charts (i.e. Macbeth ColorChecker) or other machine-readable patterns, to achieve image consistency by post-processing. Also, we benchmark our method against its former implementation and the alternative methods reported to date with an augmented dataset based on the Gehler's ColorChecker dataset. Benchmark includes how corrected images resemble the ground-truth images and how fast these implementations are. Results demonstrate that the TPS3D is the best candidate to achieve image consistency. Furthermore, our Smooth-TPS3D method shows equivalent results compared to the original method and reduced the 11-15% of ill-conditioned scenarios which the previous method failed to less than 1%. Moreover, we demonstrate that the Smooth-TPS method is 20% faster than the original method. Finally, we discuss how different methods offer different compromises between quality, correction accuracy and computational load.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "physics.ins-det",
            "physics.optics"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05162",
        "abstract url": "https://arxiv.org/abs/2409.05162",
        "title": "Can OOD Object Detectors Learn from Foundation Models?",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Out-of-distribution (OOD) object detection is a challenging task due to the absence of open-set OOD data. Inspired by recent advancements in text-to-image generative models, such as Stable Diffusion, we study the potential of generative models trained on large-scale open-set data to synthesize OOD samples, thereby enhancing OOD object detection. We introduce SyncOOD, a simple data curation method that capitalizes on the capabilities of large foundation models to automatically extract meaningful OOD data from text-to-image generative models. This offers the model access to open-world knowledge encapsulated within off-the-shelf foundation models. The synthetic OOD samples are then employed to augment the training of a lightweight, plug-and-play OOD detector, thus effectively optimizing the in-distribution (ID)/OOD decision boundaries. Extensive experiments across multiple benchmarks demonstrate that SyncOOD significantly outperforms existing methods, establishing new state-of-the-art performance with minimal synthetic data usage.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "19 pages, 4 figures"
    },
    {
        "paper id": "2409.05166",
        "abstract url": "https://arxiv.org/abs/2409.05166",
        "title": "CD-NGP: A Fast Scalable Continual Representation for Dynamic Scenes",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present CD-NGP, which is a fast and scalable representation for 3D reconstruction and novel view synthesis in dynamic scenes. Inspired by continual learning, our method first segments input videos into multiple chunks, followed by training the model chunk by chunk, and finally, fuses features of the first branch and subsequent branches. Experiments on the prevailing DyNeRF dataset demonstrate that our proposed novel representation reaches a great balance between memory consumption, model size, training speed, and rendering quality. Specifically, our method consumes $85\\%$ less training memory ($<14$GB) than offline methods and requires significantly lower streaming bandwidth ($<0.4$MB/frame) than other online alternatives.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "23 pages, full version"
    },
    {
        "paper id": "2409.05211",
        "abstract url": "https://arxiv.org/abs/2409.05211",
        "title": "ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "This paper describes the 2nd edition of the ICML Topological Deep Learning Challenge that was hosted within the ICML 2024 ELLIS Workshop on Geometry-grounded Representation Learning and Generative Modeling (GRaM). The challenge focused on the problem of representing data in different discrete topological domains in order to bridge the gap between Topological Deep Learning (TDL) and other types of structured datasets (e.g. point clouds, graphs). Specifically, participants were asked to design and implement topological liftings, i.e. mappings between different data structures and topological domains --like hypergraphs, or simplicial/cell/combinatorial complexes. The challenge received 52 submissions satisfying all the requirements. This paper introduces the main scope of the challenge, and summarizes the main results and findings.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Proceedings of the Geometry-grounded Representation Learning and Generative Modeling Workshop (GRaM) at ICML 2024"
    },
    {
        "paper id": "2409.05258",
        "abstract url": "https://arxiv.org/abs/2409.05258",
        "title": "Towards Automated Machine Learning Research",
        "rating": "0",
        "keywords": [
            [
                "NAS"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper explores a top-down approach to automating incremental advances in machine learning research through component-level innovation, facilitated by Large Language Models (LLMs). Our framework systematically generates novel components, validates their feasibility, and evaluates their performance against existing baselines. A key distinction of this approach lies in how these novel components are generated. Unlike traditional AutoML and NAS methods, which often rely on a bottom-up combinatorial search over predefined, hardcoded base components, our method leverages the cross-domain knowledge embedded in LLMs to propose new components that may not be confined to any hard-coded predefined set. By incorporating a reward model to prioritize promising hypotheses, we aim to improve the efficiency of the hypothesis generation and evaluation process. We hope this approach offers a new avenue for exploration and contributes to the ongoing dialogue in the field.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05311",
        "abstract url": "https://arxiv.org/abs/2409.05311",
        "title": "Fitting Skeletal Models via Graph-based Learning",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Skeletonization is a popular shape analysis technique that models an object's interior as opposed to just its boundary. Fitting template-based skeletal models is a time-consuming process requiring much manual parameter tuning. Recently, machine learning-based methods have shown promise for generating s-reps from object boundaries. In this work, we propose a new skeletonization method which leverages graph convolutional networks to produce skeletal representations (s-reps) from dense segmentation masks. The method is evaluated on both synthetic data and real hippocampus segmentations, achieving promising results and fast inference.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This paper was presented at the 2024 IEEE International Symposium on Biomedical Imaging (ISBI)"
    },
    {
        "paper id": "2409.05327",
        "abstract url": "https://arxiv.org/abs/2409.05327",
        "title": "ICPR 2024 Competition on Safe Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather Conditions",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The ICPR 2024 Competition on Safe Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather Conditions served as a rigorous platform to evaluate and benchmark state-of-the-art semantic segmentation models under challenging conditions for autonomous driving. Over several months, participants were provided with the IDD-AW dataset, consisting of 5000 high-quality RGB-NIR image pairs, each annotated at the pixel level and captured under adverse weather conditions such as rain, fog, low light, and snow. A key aspect of the competition was the use and improvement of the Safe mean Intersection over Union (Safe mIoU) metric, designed to penalize unsafe incorrect predictions that could be overlooked by traditional mIoU. This innovative metric emphasized the importance of safety in developing autonomous driving systems. The competition showed significant advancements in the field, with participants demonstrating models that excelled in semantic segmentation and prioritized safety and robustness in unstructured and adverse conditions. The results of the competition set new benchmarks in the domain, highlighting the critical role of safety in deploying autonomous vehicles in real-world scenarios. The contributions from this competition are expected to drive further innovation in autonomous driving technology, addressing the critical challenges of operating in diverse and unpredictable environments.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "15 pages, 7 figures, ICPR Competition Paper"
    },
    {
        "paper id": "2409.04986",
        "abstract url": "https://arxiv.org/abs/2409.04986",
        "title": "DynamicFL: Federated Learning with Dynamic Communication Resource Allocation",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) is a collaborative machine learning framework that allows multiple users to train models utilizing their local data in a distributed manner. However, considerable statistical heterogeneity in local data across devices often leads to suboptimal model performance compared with independently and identically distributed (IID) data scenarios. In this paper, we introduce DynamicFL, a new FL framework that investigates the trade-offs between global model performance and communication costs for two widely adopted FL methods: Federated Stochastic Gradient Descent (FedSGD) and Federated Averaging (FedAvg). Our approach allocates diverse communication resources to clients based on their data statistical heterogeneity, considering communication resource constraints, and attains substantial performance enhancements compared to uniform communication resource allocation. Notably, our method bridges the gap between FedSGD and FedAvg, providing a flexible framework leveraging communication heterogeneity to address statistical heterogeneity in FL. Through extensive experiments, we demonstrate that DynamicFL surpasses current state-of-the-art methods with up to a 10% increase in model accuracy, demonstrating its adaptability and effectiveness in tackling data statistical heterogeneity challenges.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05005",
        "abstract url": "https://arxiv.org/abs/2409.05005",
        "title": "Towards Patronizing and Condescending Language in Chinese Videos: A Multimodal Dataset and Detector",
        "rating": "-0.5",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.CV",
                "cs.CL"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Patronizing and Condescending Language (PCL) is a form of discriminatory toxic speech targeting vulnerable groups, threatening both online and offline safety. While toxic speech research has mainly focused on overt toxicity, such as hate speech, microaggressions in the form of PCL remain underexplored. Additionally, dominant groups' discriminatory facial expressions and attitudes toward vulnerable communities can be more impactful than verbal cues, yet these frame features are often overlooked. In this paper, we introduce the PCLMM dataset, the first Chinese multimodal dataset for PCL, consisting of 715 annotated videos from Bilibili, with high-quality PCL facial frame spans. We also propose the MultiPCL detector, featuring a facial expression detection module for PCL recognition, demonstrating the effectiveness of modality complementarity in this challenging task. Our work makes an important contribution to advancing microaggression detection within the domain of toxic speech.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Under review in ICASSP 2025"
    },
    {
        "paper id": "2409.05070",
        "abstract url": "https://arxiv.org/abs/2409.05070",
        "title": "Lepskii Principle for Distributed Kernel Ridge Regression",
        "rating": "-0.5",
        "keywords": [
            [
                "kernel learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Parameter selection without communicating local data is quite challenging in distributed learning, exhibing an inconsistency between theoretical analysis and practical application of it in tackling distributively stored data. Motivated by the recently developed Lepskii principle and non-privacy communication protocol for kernel learning, we propose a Lepskii principle to equip distributed kernel ridge regression (DKRR) and consequently develop an adaptive DKRR with Lepskii principle (Lep-AdaDKRR for short) by using a double weighted averaging synthesization scheme. We deduce optimal learning rates for Lep-AdaDKRR and theoretically show that Lep-AdaDKRR succeeds in adapting to the regularity of regression functions, effective dimension decaying rate of kernels and different metrics of generalization, which fills the gap of the mentioned inconsistency between theory and application.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05100",
        "abstract url": "https://arxiv.org/abs/2409.05100",
        "title": "MaxCutPool: differentiable feature-aware Maxcut for pooling in graph neural networks",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel approach to compute the \\texttt{MAXCUT} in attributed graphs, \\textit{i.e.}, graphs with features associated with nodes and edges. Our approach is robust to the underlying graph topology and is fully differentiable, making it possible to find solutions that jointly optimize the \\texttt{MAXCUT} along with other objectives. Based on the obtained \\texttt{MAXCUT} partition, we implement a hierarchical graph pooling layer for Graph Neural Networks, which is sparse, differentiable, and particularly suitable for downstream tasks on heterophilic graphs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05122",
        "abstract url": "https://arxiv.org/abs/2409.05122",
        "title": "PMT: Progressive Mean Teacher via Exploring Temporal Consistency for Semi-Supervised Medical Image Segmentation",
        "rating": "-0.5",
        "keywords": [
            [
                "Medical",
                "MRI",
                "CT"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Semi-supervised learning has emerged as a widely adopted technique in the field of medical image segmentation. The existing works either focuses on the construction of consistency constraints or the generation of pseudo labels to provide high-quality supervisory signals, whose main challenge mainly comes from how to keep the continuous improvement of model capabilities. In this paper, we propose a simple yet effective semi-supervised learning framework, termed Progressive Mean Teachers (PMT), for medical image segmentation, whose goal is to generate high-fidelity pseudo labels by learning robust and diverse features in the training process. Specifically, our PMT employs a standard mean teacher to penalize the consistency of the current state and utilizes two sets of MT architectures for co-training. The two sets of MT architectures are individually updated for prolonged periods to maintain stable model diversity established through performance gaps generated by iteration differences. Additionally, a difference-driven alignment regularizer is employed to expedite the alignment of lagging models with the representation capabilities of leading models. Furthermore, a simple yet effective pseudo-label filtering algorithm is employed for facile evaluation of models and selection of high-fidelity pseudo-labels outputted when models are operating at high performance for co-training purposes. Experimental results on two datasets with different modalities, i.e., CT and MRI, demonstrate that our method outperforms the state-of-the-art medical image segmentation approaches across various dimensions. The code is available at https://github.com/Axi404/PMT.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ECCV2024"
    },
    {
        "paper id": "2409.05135",
        "abstract url": "https://arxiv.org/abs/2409.05135",
        "title": "Imputation of Time-varying Edge Flows in Graphs by Multilinear Kernel Regression and Manifold Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper extends the recently developed framework of multilinear kernel regression and imputation via manifold learning (MultiL-KRIM) to impute time-varying edge flows in a graph. MultiL-KRIM uses simplicial-complex arguments and Hodge Laplacians to incorporate the graph topology, and exploits manifold-learning arguments to identify latent geometries within features which are modeled as a point-cloud around a smooth manifold embedded in a reproducing kernel Hilbert space (RKHS). Following the concept of tangent spaces to smooth manifolds, linear approximating patches are used to add a collaborative-filtering flavor to the point-cloud approximations. Together with matrix factorizations, MultiL-KRIM effects dimensionality reduction, and enables efficient computations, without any training data or additional information. Numerical tests on real-network time-varying edge flows demonstrate noticeable improvements of MultiL-KRIM over several state-of-the-art schemes.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05169",
        "abstract url": "https://arxiv.org/abs/2409.05169",
        "title": "Learning polycrystal plasticity using mesh-based subgraph geometric deep learning",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Polycrystal plasticity in metals is characterized by nonlinear behavior and strain hardening, making numerical models computationally intensive. We employ Graph Neural Network (GNN) to surrogate polycrystal plasticity from finite element method (FEM) simulations. We present a novel message-passing GNN that encodes nodal strain and edge distances between FEM mesh cells, aggregates them to obtain embeddings, and combines the decoded embeddings with the nodal strains to predict stress tensors on graph nodes. We demonstrate training GNN based on subgraphs generated from FEM mesh-graphs, in which the mesh cells are converted to nodes and edges are created between adjacent cells. The GNN is trained on 72 graphs and tested on 18 graphs. We apply the trained GNN to periodic polycrystals and learn the stress-strain maps based on strain-gradient plasticity theory. The GNN is accurately trained based on FEM graphs, in which the $R^2$ for both training and testing sets are 0.993. The proposed GNN plasticity constitutive model speeds up more than 150 times compared with the benchmark FEM method on randomly selected test polycrystals. We also apply the trained GNN to 30 unseen FEM simulations and the GNN generalizes well with an overall $R^2$ of 0.992. Analysis of the von Mises stress distributions in polycrystals shows that the GNN model accurately learns the stress distribution with low error. By comparing the error distribution across training, testing, and unseen datasets, we can deduce that the proposed model does not overfit and generalizes well beyond the training data. This work is expected to pave the way for using graphs as surrogates in polycrystal plasticity modeling.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": "30 pages, 17 figures"
    },
    {
        "paper id": "2409.05191",
        "abstract url": "https://arxiv.org/abs/2409.05191",
        "title": "Generalization of Geometric Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we study the generalization capabilities of geometric graph neural networks (GNNs). We consider GNNs over a geometric graph constructed from a finite set of randomly sampled points over an embedded manifold with topological information captured. We prove a generalization gap between the optimal empirical risk and the optimal statistical risk of this GNN, which decreases with the number of sampled points from the manifold and increases with the dimension of the underlying manifold. This generalization gap ensures that the GNN trained on a graph on a set of sampled points can be utilized to process other unseen graphs constructed from the same underlying manifold. The most important observation is that the generalization capability can be realized with one large graph instead of being limited to the size of the graph as in previous results. The generalization gap is derived based on the non-asymptotic convergence result of a GNN on the sampled graph to the underlying manifold neural networks (MNNs). We verify this theoretical result with experiments on both Arxiv dataset and Cora dataset.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "12 pages, 4 figures. arXiv admin note: text overlap with arXiv:2406.05225"
    },
    {
        "paper id": "2409.05206",
        "abstract url": "https://arxiv.org/abs/2409.05206",
        "title": "SEF: A Method for Computing Prediction Intervals by Shifting the Error Function in Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In today's era, Neural Networks (NN) are applied in various scientific fields such as robotics, medicine, engineering, etc. However, the predictions of neural networks themselves contain a degree of uncertainty that must always be taken into account before any decision is made. This is why many researchers have focused on developing different ways to quantify the uncertainty of neural network predictions. Some of these methods are based on generating prediction intervals (PI) via neural networks for the requested target values. The SEF (Shifting the Error Function) method presented in this paper is a new method that belongs to this category of methods. The proposed approach involves training a single neural network three times, thus generating an estimate along with the corresponding upper and lower bounds for a given problem. A pivotal aspect of the method is the calculation of a parameter from the initial network's estimates, which is then integrated into the loss functions of the other two networks. This innovative process effectively produces PIs, resulting in a robust and efficient technique for uncertainty quantification. To evaluate the effectiveness of our method, a comparison in terms of successful PI generation between the SEF, PI3NN and PIVEN methods was made using two synthetic datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "The paper has been accepted at the 2024 International Conference on Computer and Applications (ICCA24), Cairo, Egypt, December 17-19, 2024. https://icca-conf.info/icca-2024"
    },
    {
        "paper id": "2409.05208",
        "abstract url": "https://arxiv.org/abs/2409.05208",
        "title": "Influence-based Attributions can be Manipulated",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Influence Functions are a standard tool for attributing predictions to training data in a principled manner and are widely used in applications such as data valuation and fairness. In this work, we present realistic incentives to manipulate influencebased attributions and investigate whether these attributions can be systematically tampered by an adversary. We show that this is indeed possible and provide efficient attacks with backward-friendly implementations. Our work raises questions on the reliability of influence-based attributions under adversarial circumstances.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05242",
        "abstract url": "https://arxiv.org/abs/2409.05242",
        "title": "FedFT: Improving Communication Performance for Federated Learning with Frequency Space Transformation",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Communication efficiency is a widely recognised research problem in Federated Learning (FL), with recent work focused on developing techniques for efficient compression, distribution and aggregation of model parameters between clients and the server. Particularly within distributed systems, it is important to balance the need for computational cost and communication efficiency. However, existing methods are often constrained to specific applications and are less generalisable. In this paper, we introduce FedFT (federated frequency-space transformation), a simple yet effective methodology for communicating model parameters in a FL setting. FedFT uses Discrete Cosine Transform (DCT) to represent model parameters in frequency space, enabling efficient compression and reducing communication overhead. FedFT is compatible with various existing FL methodologies and neural architectures, and its linear property eliminates the need for multiple transformations during federated aggregation. This methodology is vital for distributed solutions, tackling essential challenges like data privacy, interoperability, and energy efficiency inherent to these environments. We demonstrate the generalisability of the FedFT methodology on four datasets using comparative studies with three state-of-the-art FL baselines (FedAvg, FedProx, FedSim). Our results demonstrate that using FedFT to represent the differences in model parameters between communication rounds in frequency space results in a more compact representation compared to representing the entire model in frequency space. This leads to a reduction in communication overhead, while keeping accuracy levels comparable and in some cases even improving it. Our results suggest that this reduction can range from 5% to 30% per client, depending on dataset.",
        "subjects": [
            "cs.DC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05284",
        "abstract url": "https://arxiv.org/abs/2409.05284",
        "title": "Efficiently Learning Markov Random Fields from Dynamics",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "An important task in high-dimensional statistics is learning the parameters or dependency structure of an undirected graphical model, or Markov random field (MRF). Much of the prior work on this problem assumes access to i.i.d. samples from the MRF distribution and state-of-the-art algorithms succeed using $n^{\u0398(k)}$ runtime, where $n$ is the dimension and $k$ is the order of the interactions. However, well-known reductions from the sparse parity with noise problem imply that given i.i.d. samples from a sparse, order-$k$ MRF, any learning algorithm likely requires $n^{\u03a9(k)}$ time, impeding the potential for significant computational improvements. In this work, we demonstrate that these fundamental barriers for learning MRFs can surprisingly be completely circumvented when learning from natural, dynamical samples. We show that in bounded-degree MRFs, the dependency structure and parameters can be recovered using a trajectory of Glauber dynamics of length $O(n \\log n)$ with runtime $O(n^2 \\log n)$. The implicit constants depend only on the degree and non-degeneracy parameters of the model, but not the dimension $n$. In particular, learning MRFs from dynamics is $\\textit{provably computationally easier}$ than learning from i.i.d. samples under standard hardness assumptions.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "stat.ML"
        ],
        "comment": "40 pages, 3 figures"
    },
    {
        "paper id": "2409.04980",
        "abstract url": "https://arxiv.org/abs/2409.04980",
        "title": "Multi-V2X: A Large Scale Multi-modal Multi-penetration-rate Dataset for Cooperative Perception",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cooperative perception through vehicle-to-everything (V2X) has garnered significant attention in recent years due to its potential to overcome occlusions and enhance long-distance perception. Great achievements have been made in both datasets and algorithms. However, existing real-world datasets are limited by the presence of few communicable agents, while synthetic datasets typically cover only vehicles. More importantly, the penetration rate of connected and autonomous vehicles (CAVs) , a critical factor for the deployment of cooperative perception technologies, has not been adequately addressed. To tackle these issues, we introduce Multi-V2X, a large-scale, multi-modal, multi-penetration-rate dataset for V2X perception. By co-simulating SUMO and CARLA, we equip a substantial number of cars and roadside units (RSUs) in simulated towns with sensor suites, and collect comprehensive sensing data. Datasets with specified CAV penetration rates can be obtained by masking some equipped cars as normal vehicles. In total, our Multi-V2X dataset comprises 549k RGB frames, 146k LiDAR frames, and 4,219k annotated 3D bounding boxes across six categories. The highest possible CAV penetration rate reaches 86.21%, with up to 31 agents in communication range, posing new challenges in selecting agents to collaborate with. We provide comprehensive benchmarks for cooperative 3D object detection tasks. Our data and code are available at https://github.com/RadetzkyLi/Multi-V2X .",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2409.04982",
        "abstract url": "https://arxiv.org/abs/2409.04982",
        "title": "2DSig-Detect: a semi-supervised framework for anomaly detection on image data using 2D-signatures",
        "rating": "-1",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "attacks"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The rapid advancement of machine learning technologies raises questions about the security of machine learning models, with respect to both training-time (poisoning) and test-time (evasion, impersonation, and inversion) attacks. Models performing image-related tasks, e.g. detection, and classification, are vulnerable to adversarial attacks that can degrade their performance and produce undesirable outcomes. This paper introduces a novel technique for anomaly detection in images called 2DSig-Detect, which uses a 2D-signature-embedded semi-supervised framework rooted in rough path theory. We demonstrate our method in adversarial settings for training-time and test-time attacks, and benchmark our framework against other state of the art methods. Using 2DSig-Detect for anomaly detection, we show both superior performance and a reduction in the computation time to detect the presence of adversarial perturbations in images.",
        "subjects": [
            "cs.CV",
            "math.PR",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05004",
        "abstract url": "https://arxiv.org/abs/2409.05004",
        "title": "Disentangling the Prosody and Semantic Information with Pre-trained Model for In-Context Learning based Zero-Shot Voice Conversion",
        "rating": "-1",
        "keywords": [
            [
                "text-to-speech",
                "Voice Conversion"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Voice conversion (VC) aims to modify the speaker's timbre while retaining speech content. Previous approaches have tokenized the outputs from self-supervised into semantic tokens, facilitating disentanglement of speech content information. Recently, in-context learning (ICL) has emerged in text-to-speech (TTS) systems for effectively modeling specific characteristics such as timbre through context conditioning. This paper proposes an ICL capability enhanced VC system (ICL-VC) employing a mask and reconstruction training strategy based on flow-matching generative models. Augmented with semantic tokens, our experiments on the LibriTTS dataset demonstrate that ICL-VC improves speaker similarity. Additionally, we find that k-means is a versatile tokenization method applicable to various pre-trained models. However, the ICL-VC system faces challenges in preserving the prosody of the source speech. To mitigate this issue, we propose incorporating prosody embeddings extracted from a pre-trained emotion recognition model into our system. Integration of prosody embeddings notably enhances the system's capability to preserve source speech prosody, as validated on the Emotional Speech Database.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05010",
        "abstract url": "https://arxiv.org/abs/2409.05010",
        "title": "Gesture Generation from Trimodal Context for Humanoid Robots",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Natural co-speech gestures are essential components to improve the experience of Human-robot interaction (HRI). However, current gesture generation approaches have many limitations of not being natural, not aligning with the speech and content, or the lack of diverse speaker styles. Therefore, this work aims to repoduce the work by Yoon et,al generating natural gestures in simulation based on tri-modal inputs and apply this to a robot. During evaluation, ``motion variance'' and ``Frechet Gesture Distance (FGD)'' is employed to evaluate the performance objectively. Then, human participants were recruited to subjectively evaluate the gestures. Results show that the movements in that paper have been successfully transferred to the robot and the gestures have diverse styles and are correlated with the speech. Moreover, there is a significant likeability and style difference between different gestures.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05014",
        "abstract url": "https://arxiv.org/abs/2409.05014",
        "title": "Unraveling Challenges with Supply-Chain Levels for Software Artifacts (SLSA) for Securing the Software Supply Chain",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "In 2023, Sonatype reported a 200\\% increase in software supply chain attacks, including major build infrastructure attacks. To secure the software supply chain, practitioners can follow security framework guidance like the Supply-chain Levels for Software Artifacts (SLSA). However, recent surveys and industry summits have shown that despite growing interest, the adoption of SLSA is not widespread. To understand adoption challenges, \\textit{the goal of this study is to aid framework authors and practitioners in improving the adoption and development of Supply-Chain Levels for Software Artifacts (SLSA) through a qualitative study of SLSA-related issues on GitHub}. We analyzed 1,523 SLSA-related issues extracted from 233 GitHub repositories. We conducted a topic-guided thematic analysis, leveraging the Latent Dirichlet Allocation (LDA) unsupervised machine learning algorithm, to explore the challenges of adopting SLSA and the strategies for overcoming these challenges. We identified four significant challenges and five suggested adoption strategies. The two main challenges reported are complex implementation and unclear communication, highlighting the difficulties in implementing and understanding the SLSA process across diverse ecosystems. The suggested strategies include streamlining provenance generation processes, improving the SLSA verification process, and providing specific and detailed documentation. Our findings indicate that some strategies can help mitigate multiple challenges, and some challenges need future research and tool enhancement.",
        "subjects": [
            "cs.CE",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05024",
        "abstract url": "https://arxiv.org/abs/2409.05024",
        "title": "Deep Self-cleansing for Medical Image Segmentation with Noisy Labels",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "surgical",
                "diagnosis",
                "disease",
                "clinical",
                "cardiac",
                "tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical image segmentation is crucial in the field of medical imaging, aiding in disease diagnosis and surgical planning. Most established segmentation methods rely on supervised deep learning, in which clean and precise labels are essential for supervision and significantly impact the performance of models. However, manually delineated labels often contain noise, such as missing labels and inaccurate boundary delineation, which can hinder networks from correctly modeling target characteristics. In this paper, we propose a deep self-cleansing segmentation framework that can preserve clean labels while cleansing noisy ones in the training phase. To achieve this, we devise a gaussian mixture model-based label filtering module that distinguishes noisy labels from clean labels. Additionally, we develop a label cleansing module to generate pseudo low-noise labels for identified noisy samples. The preserved clean labels and pseudo-labels are then used jointly to supervise the network. Validated on a clinical liver tumor dataset and a public cardiac diagnosis dataset, our method can effectively suppress the interference from noisy labels and achieve prominent segmentation performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2409.05037",
        "abstract url": "https://arxiv.org/abs/2409.05037",
        "title": "Towards Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control",
        "rating": "-1",
        "keywords": [
            [
                "GNNs",
                "graph"
            ]
        ],
        "abstract": "Deep reinforcement learning (DRL) methods that incorporate graph neural networks (GNNs) have been extensively studied for intelligent traffic signal control, which aims to coordinate traffic signals effectively across multiple intersections. Despite this progress, the standard graph learning used in these methods still struggles to capture higher-order correlations in real-world traffic flow. In this paper, we propose a multi-agent proximal policy optimization framework DHG-PPO, which incorporates PPO and directed hypergraph module to extract the spatio-temporal attributes of the road networks. DHG-PPO enables multiple agents to ingeniously interact through the dynamical construction of hypergraph. The effectiveness of DHG-PPO is validated in terms of average travel time and throughput against state-of-the-art baselines through extensive experiments.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05045",
        "abstract url": "https://arxiv.org/abs/2409.05045",
        "title": "Using Large Language Models for Template Detection from Security Event Logs",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "In modern IT systems and computer networks, real-time and offline event log analysis is a crucial part of cyber security monitoring. In particular, event log analysis techniques are essential for the timely detection of cyber attacks and for assisting security experts with the analysis of past security incidents. The detection of line patterns or templates from unstructured textual event logs has been identified as an important task of event log analysis since detected templates represent event types in the event log and prepare the logs for downstream online or offline security monitoring tasks. During the last two decades, a number of template mining algorithms have been proposed. However, many proposed algorithms rely on traditional data mining techniques, and the usage of Large Language Models (LLMs) has received less attention so far. Also, most approaches that harness LLMs are supervised, and unsupervised LLM-based template mining remains an understudied area. The current paper addresses this research gap and investigates the application of LLMs for unsupervised detection of templates from unstructured security event logs.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05063",
        "abstract url": "https://arxiv.org/abs/2409.05063",
        "title": "On final opinions of the Friedkin-Johnsen model over random graphs with partially stubborn community",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This paper studies the formation of final opinions for the Friedkin-Johnsen (FJ) model with a community of partially stubborn agents. The underlying network of the FJ model is symmetric and generated from a random graph model, in which each link is added independently from a Bernoulli distribution. It is shown that the final opinions of the FJ model will concentrate around those of an FJ model over the expected graph as the network size grows, on the condition that the stubborn agents are well connected to other agents. Probability bounds are proposed for the distance between these two final opinion vectors, respectively for the cases where there exist non-stubborn agents or not. Numerical experiments are provided to illustrate the theoretical findings. The simulation shows that, in presence of non-stubborn agents, the link probability between the stubborn and the non-stubborn communities affect the distance between the two final opinion vectors significantly. Additionally, if all agents are stubborn, the opinion distance decreases with the agent stubbornness.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05088",
        "abstract url": "https://arxiv.org/abs/2409.05088",
        "title": "Transformer with Leveraged Masked Autoencoder for video-based Pain Assessment",
        "rating": "-1",
        "keywords": [
            [
                "healthcare",
                "diagnosis",
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate pain assessment is crucial in healthcare for effective diagnosis and treatment; however, traditional methods relying on self-reporting are inadequate for populations unable to communicate their pain. Cutting-edge AI is promising for supporting clinicians in pain recognition using facial video data. In this paper, we enhance pain recognition by employing facial video analysis within a Transformer-based deep learning model. By combining a powerful Masked Autoencoder with a Transformers-based classifier, our model effectively captures pain level indicators through both expressions and micro-expressions. We conducted our experiment on the AI4Pain dataset, which produced promising results that pave the way for innovative healthcare solutions that are both comprehensive and objective.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05089",
        "abstract url": "https://arxiv.org/abs/2409.05089",
        "title": "Leveraging WaveNet for Dynamic Listening Head Modeling from Speech",
        "rating": "-1",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The creation of listener facial responses aims to simulate interactive communication feedback from a listener during a face-to-face conversation. Our goal is to generate believable videos of listeners' heads that respond authentically to a single speaker by a sequence-to-sequence model with an combination of WaveNet and Long short-term memory network. Our approach focuses on capturing the subtle nuances of listener feedback, ensuring the preservation of individual listener identity while expressing appropriate attitudes and viewpoints. Experiment results show that our method surpasses the baseline models on ViCo benchmark Dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05095",
        "abstract url": "https://arxiv.org/abs/2409.05095",
        "title": "The first Cadenza challenges: using machine learning competitions to improve music for listeners with a hearing loss",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "It is well established that listening to music is an issue for those with hearing loss, and hearing aids are not a universal solution. How can machine learning be used to address this? This paper details the first application of the open challenge methodology to use machine learning to improve audio quality of music for those with hearing loss. The first challenge was a stand-alone competition (CAD1) and had 9 entrants. The second was an 2024 ICASSP grand challenge (ICASSP24) and attracted 17 entrants. The challenge tasks concerned demixing and remixing pop/rock music to allow a personalised rebalancing of the instruments in the mix, along with amplification to correct for raised hearing thresholds. The software baselines provided for entrants to build upon used two state-of-the-art demix algorithms: Hybrid Demucs and Open-Unmix. Evaluation of systems was done using the objective metric HAAQI, the Hearing-Aid Audio Quality Index. No entrants improved on the best baseline in CAD1 because there was insufficient room for improvement. Consequently, for ICASSP24 the scenario was made more difficult by using loudspeaker reproduction and specified gains to be applied before remixing. This also made the scenario more useful for listening through hearing aids. 9 entrants scored better than the the best ICASSP24 baseline. Most entrants used a refined version of Hybrid Demucs and NAL-R amplification. The highest scoring system combined the outputs of several demixing algorithms in an ensemble approach. These challenges are now open benchmarks for future research with the software and data being freely available.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05099",
        "abstract url": "https://arxiv.org/abs/2409.05099",
        "title": "DreamMapping: High-Fidelity Text-to-3D Generation via Variational Distribution Mapping",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Score Distillation Sampling (SDS) has emerged as a prevalent technique for text-to-3D generation, enabling 3D content creation by distilling view-dependent information from text-to-2D guidance. However, they frequently exhibit shortcomings such as over-saturated color and excess smoothness. In this paper, we conduct a thorough analysis of SDS and refine its formulation, finding that the core design is to model the distribution of rendered images. Following this insight, we introduce a novel strategy called Variational Distribution Mapping (VDM), which expedites the distribution modeling process by regarding the rendered images as instances of degradation from diffusion-based generation. This special design enables the efficient training of variational distribution by skipping the calculations of the Jacobians in the diffusion U-Net. We also introduce timestep-dependent Distribution Coefficient Annealing (DCA) to further improve distilling precision. Leveraging VDM and DCA, we use Gaussian Splatting as the 3D representation and build a text-to-3D generation framework. Extensive experiments and evaluations demonstrate the capability of VDM and DCA to generate high-fidelity and realistic assets with optimization efficiency.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "15 pages, 14 figures"
    },
    {
        "paper id": "2409.05106",
        "abstract url": "https://arxiv.org/abs/2409.05106",
        "title": "Decentralized Control of Multi-Agent Systems Under Acyclic Spatio-Temporal Task Dependencies",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We introduce a novel distributed sampled-data control method tailored for heterogeneous multi-agent systems under a global spatio-temporal task with acyclic dependencies. Specifically, we consider the global task as a conjunction of independent and collaborative tasks, defined over the absolute and relative states of agent pairs. Task dependencies in this form are then represented by a task graph, which we assume to be acyclic. From the given task graph, we provide an algorithmic approach to define a distributed sampled-data controller prioritizing the fulfilment of collaborative tasks as the primary objective, while fulfilling independent tasks unless they conflict with collaborative ones. Moreover, communication maintenance among collaborating agents is seamlessly enforced within the proposed control framework. A numerical simulation is provided to showcase the potential of our control framework.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Short version of this paper was accepted for the Conference on Decision and Control"
    },
    {
        "paper id": "2409.05112",
        "abstract url": "https://arxiv.org/abs/2409.05112",
        "title": "WaterSeeker: Efficient Detection of Watermarked Segments in Large Documents",
        "rating": "-1",
        "keywords": [
            [
                "Watermarking"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Watermarking algorithms for large language models (LLMs) have attained high accuracy in detecting LLM-generated text. However, existing methods primarily focus on distinguishing fully watermarked text from non-watermarked text, overlooking real-world scenarios where LLMs generate only small sections within large documents. In this scenario, balancing time complexity and detection performance poses significant challenges. This paper presents WaterSeeker, a novel approach to efficiently detect and locate watermarked segments amid extensive natural text. It first applies an efficient anomaly extraction method to preliminarily locate suspicious watermarked regions. Following this, it conducts a local traversal and performs full-text detection for more precise verification. Theoretical analysis and experimental results demonstrate that WaterSeeker achieves a superior balance between detection accuracy and computational efficiency. Moreover, WaterSeeker's localization ability supports the development of interpretable AI detection systems. This work pioneers a new direction in watermarked segment detection, facilitating more reliable AI-generated content identification.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "18 pages, 5 figures, 4 tables"
    },
    {
        "paper id": "2409.05116",
        "abstract url": "https://arxiv.org/abs/2409.05116",
        "title": "Diffusion-based Speech Enhancement with Schr\u00f6dinger Bridge and Symmetric Noise Schedule",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Speech Enhancement"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recently, diffusion-based generative models have demonstrated remarkable performance in speech enhancement tasks. However, these methods still encounter challenges, including the lack of structural information and poor performance in low Signal-to-Noise Ratio (SNR) scenarios. To overcome these challenges, we propose the Schr\u00f6odinger Bridge-based Speech Enhancement (SBSE) method, which learns the diffusion processes directly between the noisy input and the clean distribution, unlike conventional diffusion-based speech enhancement systems that learn data to Gaussian distributions. To enhance performance in extremely noisy conditions, we introduce a two-stage system incorporating ratio mask information into the diffusion-based generative model. Our experimental results show that our proposed SBSE method outperforms all the baseline models and achieves state-of-the-art performance, especially in low SNR conditions. Importantly, only a few inference steps are required to achieve the best result.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05171",
        "abstract url": "https://arxiv.org/abs/2409.05171",
        "title": "Exploring Fungal Morphology Simulation and Dynamic Light Containment from a Graphics Generation Perspective",
        "rating": "-1",
        "keywords": [
            [
                "Bio-Art"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Fungal simulation and control are considered crucial techniques in Bio-Art creation. However, coding algorithms for reliable fungal simulations have posed significant challenges for artists. This study equates fungal morphology simulation to a two-dimensional graphic time-series generation problem. We propose a zero-coding, neural network-driven cellular automaton. Fungal spread patterns are learned through an image segmentation model and a time-series prediction model, which then supervise the training of neural network cells, enabling them to replicate real-world spreading behaviors. We further implemented dynamic containment of fungal boundaries with lasers. Synchronized with the automaton, the fungus successfully spreads into pre-designed complex shapes in reality.",
        "subjects": [
            "cs.GR",
            "cs.CV",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "Siggraph Asia 2024 Art Paper"
    },
    {
        "paper id": "2409.05174",
        "abstract url": "https://arxiv.org/abs/2409.05174",
        "title": "Advanced Machine Learning Framework for Efficient Plant Disease Prediction",
        "rating": "-1",
        "keywords": [
            [
                "Disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, Machine Learning (ML) methods are built-in as an important component in many smart agriculture platforms. In this paper, we explore the new combination of advanced ML methods for creating a smart agriculture platform where farmers could reach out for assistance from the public, or a closed circle of experts. Specifically, we focus on an easy way to assist the farmers in understanding plant diseases where the farmers can get help to solve the issues from the members of the community. The proposed system utilizes deep learning techniques for identifying the disease of the plant from the affected image, which acts as an initial identifier. Further, Natural Language Processing techniques are employed for ranking the solutions posted by the user community. In this paper, a message channel is built on top of Twitter, a popular social media platform to establish proper communication among farmers. Since the effect of the solutions can differ based on various other parameters, we extend the use of the concept drift approach and come up with a good solution and propose it to the farmer. We tested the proposed framework on the benchmark dataset, and it produces accurate and reliable results.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05225",
        "abstract url": "https://arxiv.org/abs/2409.05225",
        "title": "Comparison of Two Augmentation Methods in Improving Detection Accuracy of Hemarthrosis",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the increase of computing power, machine learning models in medical imaging have been introduced to help in rending medical diagnosis and inspection, like hemophilia, a rare disorder in which blood cannot clot normally. Often, one of the bottlenecks of detecting hemophilia is the lack of data available to train the algorithm to increase the accuracy. As a possible solution, this research investigated whether introducing augmented data by data synthesis or traditional augmentation techniques can improve model accuracy, helping to diagnose the diseases. To tackle this research, features of ultrasound images were extracted by the pre-trained VGG-16, and similarities were compared by cosine similarity measure based on extracted features in different distributions among real images, synthetic images, and augmentation images (Real vs. Real, Syn vs. Syn, Real vs. Different Batches of Syn, Real vs. Augmentation Techniques). Model testing performance was investigated using EffientNet-B4 to recognize \"blood\" images with two augmentation methods. In addition, a gradient-weighted class activation mapping (Grad-CAM) visualization was used to interpret the unexpected results like loss of accuracy. Synthetic and real images do not show high similarity, with a mean similarity score of 0.4737. Synthetic batch 1 dataset and images by horizontal flip are more similar to the original images. Classic augmentation techniques and data synthesis can improve model accuracy, and data by traditional augmentation techniques have a better performance than synthetic data. In addition, the Grad-CAM heatmap figured out the loss of accuracy is due to a shift in the domain. Overall, this research found that two augmentation methods, data synthesis and traditional augmentation techniques, both can improve accuracy to a certain extent to help to diagnose rare diseases.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05250",
        "abstract url": "https://arxiv.org/abs/2409.05250",
        "title": "MRStyle: A Unified Framework for Color Style Transfer with Multi-Modality Reference",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce MRStyle, a comprehensive framework that enables color style transfer using multi-modality reference, including image and text. To achieve a unified style feature space for both modalities, we first develop a neural network called IRStyle, which generates stylized 3D lookup tables for image reference. This is accomplished by integrating an interaction dual-mapping network with a combined supervised learning pipeline, resulting in three key benefits: elimination of visual artifacts, efficient handling of high-resolution images with low memory usage, and maintenance of style consistency even in situations with significant color style variations. For text reference, we align the text feature of stable diffusion priors with the style feature of our IRStyle to perform text-guided color style transfer (TRStyle). Our TRStyle method is highly efficient in both training and inference, producing notable open-set text-guided transfer results. Extensive experiments in both image and text settings demonstrate that our proposed method outperforms the state-of-the-art in both qualitative and quantitative evaluations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05251",
        "abstract url": "https://arxiv.org/abs/2409.05251",
        "title": "Online Resynthesis of High-Level Collaborative Tasks for Robots with Changing Capabilities",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Given a collaborative high-level task and a team of heterogeneous robots and behaviors to satisfy it, this work focuses on the challenge of automatically, at runtime, adjusting the individual robot behaviors such that the task is still satisfied, when robots encounter changes to their abilities--either failures or additional actions they can perform. We consider tasks encoded in LTL^\u03c8and minimize global teaming reassignments (and as a result, local resynthesis) when robots' capabilities change. We also increase the expressivity of LTL^\u03c8by including additional types of constraints on the overall teaming assignment that the user can specify, such as the minimum number of robots required for each assignment. We demonstrate the framework in a simulated warehouse scenario.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Under review in IEEE Robotics and Automation Letters"
    },
    {
        "paper id": "2409.05255",
        "abstract url": "https://arxiv.org/abs/2409.05255",
        "title": "Label-free evaluation of lung and heart transplant biopsies using virtual staining",
        "rating": "-1",
        "keywords": [
            [
                "biopsies",
                "diagnosis",
                "Organ"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Organ transplantation serves as the primary therapeutic strategy for end-stage organ failures. However, allograft rejection is a common complication of organ transplantation. Histological assessment is essential for the timely detection and diagnosis of transplant rejection and remains the gold standard. Nevertheless, the traditional histochemical staining process is time-consuming, costly, and labor-intensive. Here, we present a panel of virtual staining neural networks for lung and heart transplant biopsies, which digitally convert autofluorescence microscopic images of label-free tissue sections into their brightfield histologically stained counterparts, bypassing the traditional histochemical staining process. Specifically, we virtually generated Hematoxylin and Eosin (H&E), Masson's Trichrome (MT), and Elastic Verhoeff-Van Gieson (EVG) stains for label-free transplant lung tissue, along with H&E and MT stains for label-free transplant heart tissue. Subsequent blind evaluations conducted by three board-certified pathologists have confirmed that the virtual staining networks consistently produce high-quality histology images with high color uniformity, closely resembling their well-stained histochemical counterparts across various tissue features. The use of virtually stained images for the evaluation of transplant biopsies achieved comparable diagnostic outcomes to those obtained via traditional histochemical staining, with a concordance rate of 82.4% for lung samples and 91.7% for heart samples. Moreover, virtual staining models create multiple stains from the same autofluorescence input, eliminating structural mismatches observed between adjacent sections stained in the traditional workflow, while also saving tissue, expert time, and staining costs.",
        "subjects": [
            "physics.med-ph",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "21 Pages, 5 Figures"
    },
    {
        "paper id": "2409.05274",
        "abstract url": "https://arxiv.org/abs/2409.05274",
        "title": "Rethinking the Atmospheric Scattering-driven Attention via Channel and Gamma Correction Priors for Low-Light Image Enhancement",
        "rating": "-1",
        "keywords": [
            [
                "Image Enhancement"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Low-light image enhancement remains a critical challenge in computer vision, as does the lightweight design for edge devices with the computational burden for deep learning models. In this article, we introduce an extended version of Channel-Prior and Gamma-Estimation Network (CPGA-Net), termed CPGA-Net+, which incorporates an attention mechanism driven by a reformulated Atmospheric Scattering Model and effectively addresses both global and local image processing through Plug-in Attention with gamma correction. These innovations enable CPGA-Net+ to achieve superior performance on image enhancement tasks, surpassing lightweight state-of-the-art methods with high efficiency. Our results demonstrate the model's effectiveness and show the potential applications in resource-constrained environments.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05277",
        "abstract url": "https://arxiv.org/abs/2409.05277",
        "title": "Disentangled Representations for Short-Term and Long-Term Person Re-Identification",
        "rating": "-1",
        "keywords": [
            [
                "GAN"
            ],
            [
                "Re-Identification"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We address the problem of person re-identification (reID), that is, retrieving person images from a large dataset, given a query image of the person of interest. A key challenge is to learn person representations robust to intra-class variations, as different persons could have the same attribute, and persons' appearances look different, e.g., with viewpoint changes. Recent reID methods focus on learning person features discriminative only for a particular factor of variations (e.g., human pose), which also requires corresponding supervisory signals (e.g., pose annotations). To tackle this problem, we propose to factorize person images into identity-related and unrelated features. Identity-related features contain information useful for specifying a particular person (e.g., clothing), while identity-unrelated ones hold other factors (e.g., human pose). To this end, we propose a new generative adversarial network, dubbed identity shuffle GAN (IS-GAN). It disentangles identity-related and unrelated features from person images through an identity-shuffling technique that exploits identification labels alone without any auxiliary supervisory signals. We restrict the distribution of identity-unrelated features or encourage the identity-related and unrelated features to be uncorrelated, facilitating the disentanglement process. Experimental results validate the effectiveness of IS-GAN, showing state-of-the-art performance on standard reID benchmarks, including Market-1501, CUHK03, and DukeMTMC-reID. We further demonstrate the advantages of disentangling person representations on a long-term reID task, setting a new state of the art on a Celeb-reID dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:1910.12003"
    },
    {
        "paper id": "2409.05279",
        "abstract url": "https://arxiv.org/abs/2409.05279",
        "title": "BrainDecoder: Style-Based Visual Decoding of EEG Signals",
        "rating": "-1",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Decoding neural representations of visual stimuli from electroencephalography (EEG) offers valuable insights into brain activity and cognition. Recent advancements in deep learning have significantly enhanced the field of visual decoding of EEG, primarily focusing on reconstructing the semantic content of visual stimuli. In this paper, we present a novel visual decoding pipeline that, in addition to recovering the content, emphasizes the reconstruction of the style, such as color and texture, of images viewed by the subject. Unlike previous methods, this ``style-based'' approach learns in the CLIP spaces of image and text separately, facilitating a more nuanced extraction of information from EEG signals. We also use captions for text alignment simpler than previously employed, which we find work better. Both quantitative and qualitative evaluations show that our method better preserves the style of visual stimuli and extracts more fine-grained semantic information from neural signals. Notably, it achieves significant improvements in quantitative results and sets a new state-of-the-art on the popular Brain2Image dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "5 pages, 4 figures, 2 tables"
    },
    {
        "paper id": "2409.05280",
        "abstract url": "https://arxiv.org/abs/2409.05280",
        "title": "RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "disease",
                "Cardiac"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Cardiovascular disease is a major global health concern, contributing significantly to global mortality. Accurately segmenting cardiac medical imaging data is crucial for reducing fatality rates associated with these conditions. However, current state-of-the-art (SOTA) neural networks, including CNN-based and Transformer-based approaches, face challenges in capturing both inter-slice connections and intra-slice details, especially in datasets featuring intricate, long-range details along the z-axis like coronary arteries. Existing methods also struggle with differentiating non-cardiac components from the myocardium, resulting in segmentation inaccuracies and the \"spraying\" phenomenon. To address these issues, we introduce RotCAtt-TransUNet++, a novel architecture designed for robust segmentation of intricate cardiac structures. Our approach enhances global context modeling through multiscale feature aggregation and nested skip connections in the encoder. Transformer layers facilitate capturing intra-slice interactions, while a rotatory attention mechanism handles inter-slice connectivity. A channel-wise cross-attention gate integrates multiscale information and decoder features, effectively bridging semantic gaps. Experimental results across multiple datasets demonstrate superior performance over current methods, achieving near-perfect annotation of coronary arteries and myocardium. Ablation studies confirm that our rotatory attention mechanism significantly improves segmentation accuracy by transforming embedded vectorized patches in semantic dimensional space.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2409.05286",
        "abstract url": "https://arxiv.org/abs/2409.05286",
        "title": "Seek and Solve Reasoning for Table Question Answering",
        "rating": "-1",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Table-based Question Answering (TQA) involves answering questions based on tabular data. The complexity of table structures and question logic makes this task difficult even for Large Language Models (LLMs). This paper improves TQA performance by leveraging LLMs' reasoning capabilities. Inspired by how humans solve TQA tasks, we propose a Seek-and-Solve pipeline that instructs the LLM to first seek relevant information and then answer questions. The two stages are integrated at the reasoning level, and their Chain of Thought (CoT) paths are integrated into a coherent Seek-and-Solve CoT (SS-CoT). Furthermore, we present a compact single-stage TQA-solving prompt distilled from the pipeline. Experiments demonstrate that under In-Context Learning settings, using samples with SS-CoT paths as demonstrations, the TQA-solving prompt can effectively guide the LLM to solve complex TQA tasks, resulting in improved performance and reliability. Our results highlight the importance of properly eliciting LLMs' reasoning capabilities in solving complex TQA tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05292",
        "abstract url": "https://arxiv.org/abs/2409.05292",
        "title": "Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis",
        "rating": "-1",
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "The world is currently experiencing an outbreak of mpox, which has been declared a Public Health Emergency of International Concern by WHO. No prior work related to social media mining has focused on the development of a dataset of Instagram posts about the mpox outbreak. The work presented in this paper aims to address this research gap and makes two scientific contributions to this field. First, it presents a multilingual dataset of 60,127 Instagram posts about mpox, published between July 23, 2022, and September 5, 2024. The dataset, available at https://dx.doi.org/10.21227/7fvc-y093, contains Instagram posts about mpox in 52 languages. For each of these posts, the Post ID, Post Description, Date of publication, language, and translated version of the post (translation to English was performed using the Google Translate API) are presented as separate attributes in the dataset. After developing this dataset, sentiment analysis, hate speech detection, and anxiety or stress detection were performed. This process included classifying each post into (i) one of the sentiment classes, i.e., fear, surprise, joy, sadness, anger, disgust, or neutral, (ii) hate or not hate, and (iii) anxiety/stress detected or no anxiety/stress detected. These results are presented as separate attributes in the dataset. Second, this paper presents the results of performing sentiment analysis, hate speech analysis, and anxiety or stress analysis. The variation of the sentiment classes - fear, surprise, joy, sadness, anger, disgust, and neutral were observed to be 27.95%, 2.57%, 8.69%, 5.94%, 2.69%, 1.53%, and 50.64%, respectively. In terms of hate speech detection, 95.75% of the posts did not contain hate and the remaining 4.25% of the posts contained hate. Finally, 72.05% of the posts did not indicate any anxiety/stress, and the remaining 27.95% of the posts represented some form of anxiety/stress.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CY",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05295",
        "abstract url": "https://arxiv.org/abs/2409.05295",
        "title": "Adaptive Visual Servoing for On-Orbit Servicing",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This paper presents an adaptive visual servoing framework for robotic on-orbit servicing (OOS), specifically designed for capturing tumbling satellites. The vision-guided robotic system is capable of selecting optimal control actions in the event of partial or complete vision system failure, particularly in the short term. The autonomous system accounts for physical and operational constraints, executing visual servoing tasks to minimize a cost function. A hierarchical control architecture is developed, integrating a variant of the Iterative Closest Point (ICP) algorithm for image registration, a constrained noise-adaptive Kalman filter, fault detection and recovery logic, and a constrained optimal path planner. The dynamic estimator provides real-time estimates of unknown states and uncertain parameters essential for motion prediction, while ensuring consistency through a set of inequality constraints. It also adjusts the Kalman filter parameters adaptively in response to unexpected vision errors. In the event of vision system faults, a recovery strategy is activated, guided by fault detection logic that monitors the visual feedback via the metric fit error of image registration. The estimated/predicted pose and parameters are subsequently fed into an optimal path planner, which directs the robot's end-effector to the target's grasping point. This process is subject to multiple constraints, including acceleration limits, smooth capture, and line-of-sight maintenance with the target. Experimental results demonstrate that the proposed visual servoing system successfully captured a free-floating object, despite complete occlusion of the vision system.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2209.02156"
    },
    {
        "paper id": "2409.05310",
        "abstract url": "https://arxiv.org/abs/2409.05310",
        "title": "Neural Surface Reconstruction and Rendering for LiDAR-Visual Systems",
        "rating": "-1",
        "keywords": [
            [
                "NeRF",
                "Radiance Fields",
                "SDF"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a unified surface reconstruction and rendering framework for LiDAR-visual systems, integrating Neural Radiance Fields (NeRF) and Neural Distance Fields (NDF) to recover both appearance and structural information from posed images and point clouds. We address the structural visible gap between NeRF and NDF by utilizing a visible-aware occupancy map to classify space into the free, occupied, visible unknown, and background regions. This classification facilitates the recovery of a complete appearance and structure of the scene. We unify the training of the NDF and NeRF using a spatial-varying scale SDF-to-density transformation for levels of detail for both structure and appearance. The proposed method leverages the learned NDF for structure-aware NeRF training by an adaptive sphere tracing sampling strategy for accurate structure rendering. In return, NeRF further refines structural in recovering missing or fuzzy structures in the NDF. Extensive experiments demonstrate the superior quality and versatility of the proposed method across various scenarios. To benefit the community, the codes will be released at \\url{https://github.com/hku-mars/M2Mapping}.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05319",
        "abstract url": "https://arxiv.org/abs/2409.05319",
        "title": "Machine Anomalous Sound Detection Using Spectral-temporal Modulation Representations Derived from Machine-specific Filterbanks",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.SD"
            ]
        ],
        "abstract": "Early detection of factory machinery malfunctions is crucial in industrial applications. In machine anomalous sound detection (ASD), different machines exhibit unique vibration-frequency ranges based on their physical properties. Meanwhile, the human auditory system is adept at tracking both temporal and spectral dynamics of machine sounds. Consequently, integrating the computational auditory models of the human auditory system with machine-specific properties can be an effective approach to machine ASD. We first quantified the frequency importances of four types of machines using the Fisher ratio (F-ratio). The quantified frequency importances were then used to design machine-specific non-uniform filterbanks (NUFBs), which extract the log non-uniform spectrum (LNS) feature. The designed NUFBs have a narrower bandwidth and higher filter distribution density in frequency regions with relatively high F-ratios. Finally, spectral and temporal modulation representations derived from the LNS feature were proposed. These proposed LNS feature and modulation representations are input into an autoencoder neural-network-based detector for ASD. The quantification results from the training set of the Malfunctioning Industrial Machine Investigation and Inspection dataset with a signal-to-noise (SNR) of 6 dB reveal that the distinguishing information between normal and anomalous sounds of different machines is encoded non-uniformly in the frequency domain. By highlighting these important frequency regions using NUFBs, the LNS feature can significantly enhance performance using the metric of AUC (area under the receiver operating characteristic curve) under various SNR conditions. Furthermore, modulation representations can further improve performance. Specifically, temporal modulation is effective for fans, pumps, and sliders, while spectral modulation is particularly effective for valves.",
        "subjects": [
            "cs.SD",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05324",
        "abstract url": "https://arxiv.org/abs/2409.05324",
        "title": "FIF-UNet: An Efficient UNet Using Feature Interaction and Fusion for Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Nowadays, pre-trained encoders are widely used in medical image segmentation because of their ability to capture complex feature representations. However, the existing models fail to effectively utilize the rich features obtained by the pre-trained encoder, resulting in suboptimal segmentation results. In this work, a novel U-shaped model, called FIF-UNet, is proposed to address the above issue, including three plug-and-play modules. A channel spatial interaction module (CSI) is proposed to obtain informative features by establishing the interaction between encoder stages and corresponding decoder stages. A cascaded conv-SE module (CoSE) is designed to enhance the representation of critical features by adaptively assigning importance weights on different feature channels. A multi-level fusion module (MLF) is proposed to fuse the multi-scale features from the decoder stages, ensuring accurate and robust final segmentation. Comprehensive experiments on the Synapse and ACDC datasets demonstrate that the proposed FIF-UNet outperforms existing state-of-the-art methods, which achieves the highest average DICE of 86.05% and 92.58%, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05022",
        "abstract url": "https://arxiv.org/abs/2409.05022",
        "title": "Sequential Recommendation via Adaptive Robust Attention with Multi-dimensional Embeddings",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Sequential recommendation models have achieved state-of-the-art performance using self-attention mechanism. It has since been found that moving beyond only using item ID and positional embeddings leads to a significant accuracy boost when predicting the next item. In recent literature, it was reported that a multi-dimensional kernel embedding with temporal contextual kernels to capture users' diverse behavioral patterns results in a substantial performance improvement. In this study, we further improve the sequential recommender model's robustness and generalization by introducing a mix-attention mechanism with a layer-wise noise injection (LNI) regularization. We refer to our proposed model as adaptive robust sequential recommendation framework (ADRRec), and demonstrate through extensive experiments that our model outperforms existing self-attention architectures.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05047",
        "abstract url": "https://arxiv.org/abs/2409.05047",
        "title": "Machine Learning-Based Prediction of Key Genes Correlated to the Subretinal Lesion Severity in a Mouse Model of Age-Related Macular Degeneration",
        "rating": "-1.5",
        "keywords": [
            [
                "biological",
                "Lesion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Age-related macular degeneration (AMD) is a major cause of blindness in older adults, severely affecting vision and quality of life. Despite advances in understanding AMD, the molecular factors driving the severity of subretinal scarring (fibrosis) remain elusive, hampering the development of effective therapies. This study introduces a machine learning-based framework to predict key genes that are strongly correlated with lesion severity and to identify potential therapeutic targets to prevent subretinal fibrosis in AMD. Using an original RNA sequencing (RNA-seq) dataset from the diseased retinas of JR5558 mice, we developed a novel and specific feature engineering technique, including pathway-based dimensionality reduction and gene-based feature expansion, to enhance prediction accuracy. Two iterative experiments were conducted by leveraging Ridge and ElasticNet regression models to assess biological relevance and gene impact. The results highlight the biological significance of several key genes and demonstrate the framework's effectiveness in identifying novel therapeutic targets. The key findings provide valuable insights for advancing drug discovery efforts and improving treatment strategies for AMD, with the potential to enhance patient outcomes by targeting the underlying genetic mechanisms of subretinal lesion development.",
        "subjects": [
            "q-bio.GN",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05096",
        "abstract url": "https://arxiv.org/abs/2409.05096",
        "title": "Time-Distributed Feature Learning for Internet of Things Network Traffic Classification",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning-based network traffic classification (NTC) techniques, including conventional and class-of-service (CoS) classifiers, are a popular tool that aids in the quality of service (QoS) and radio resource management for the Internet of Things (IoT) network. Holistic temporal features consist of inter-, intra-, and pseudo-temporal features within packets, between packets, and among flows, providing the maximum information on network services without depending on defined classes in a problem. Conventional spatio-temporal features in the current solutions extract only space and time information between packets and flows, ignoring the information within packets and flow for IoT traffic. Therefore, we propose a new, efficient, holistic feature extraction method for deep-learning-based NTC using time-distributed feature learning to maximize the accuracy of the NTC. We apply a time-distributed wrapper on deep-learning layers to help extract pseudo-temporal features and spatio-temporal features. Pseudo-temporal features are mathematically complex to explain since, in deep learning, a black box extracts them. However, the features are temporal because of the time-distributed wrapper; therefore, we call them pseudo-temporal features. Since our method is efficient in learning holistic-temporal features, we can extend our method to both conventional and CoS NTC. Our solution proves that pseudo-temporal and spatial-temporal features can significantly improve the robustness and performance of any NTC. We analyze the solution theoretically and experimentally on different real-world datasets. The experimental results show that the holistic-temporal time-distributed feature learning method, on average, is 13.5% more accurate than the state-of-the-art conventional and CoS classifiers.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05188",
        "abstract url": "https://arxiv.org/abs/2409.05188",
        "title": "Learning to Classify Quantum Phases of Matter with a Few Measurements",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the identification of quantum phases of matter, at zero temperature, when only part of the phase diagram is known in advance. Following a supervised learning approach, we show how to use our previous knowledge to construct an observable capable of classifying the phase even in the unknown region. By using a combination of classical and quantum techniques, such as tensor networks, kernel methods, generalization bounds, quantum algorithms, and shadow estimators, we show that, in some cases, the certification of new ground states can be obtained with a polynomial number of measurements. An important application of our findings is the classification of the phases of matter obtained in quantum simulators, e.g., cold atom experiments, capable of efficiently preparing ground states of complex many-particle systems and applying simple measurements, e.g., single qubit measurements, but unable to perform a universal set of gates.",
        "subjects": [
            "quant-ph",
            "cond-mat.other",
            "cond-mat.stat-mech",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05215",
        "abstract url": "https://arxiv.org/abs/2409.05215",
        "title": "Synthetic Tabular Data Generation for Class Imbalance and Fairness: A Comparative Study",
        "rating": "-1.5",
        "keywords": [
            [
                "Tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Due to their data-driven nature, Machine Learning (ML) models are susceptible to bias inherited from data, especially in classification problems where class and group imbalances are prevalent. Class imbalance (in the classification target) and group imbalance (in protected attributes like sex or race) can undermine both ML utility and fairness. Although class and group imbalances commonly coincide in real-world tabular datasets, limited methods address this scenario. While most methods use oversampling techniques, like interpolation, to mitigate imbalances, recent advancements in synthetic tabular data generation offer promise but have not been adequately explored for this purpose. To this end, this paper conducts a comparative analysis to address class and group imbalances using state-of-the-art models for synthetic tabular data generation and various sampling strategies. Experimental results on four datasets, demonstrate the effectiveness of generative models for bias mitigation, creating opportunities for further exploration in this direction.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted at the ECML PKDD 2024, 4th Workshop on Bias and Fairness in AI"
    },
    {
        "paper id": "2409.05294",
        "abstract url": "https://arxiv.org/abs/2409.05294",
        "title": "TERD: A Unified Framework for Safeguarding Diffusion Models Against Backdoors",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models have achieved notable success in image generation, but they remain highly vulnerable to backdoor attacks, which compromise their integrity by producing specific undesirable outputs when presented with a pre-defined trigger. In this paper, we investigate how to protect diffusion models from this dangerous threat. Specifically, we propose TERD, a backdoor defense framework that builds unified modeling for current attacks, which enables us to derive an accessible reversed loss. A trigger reversion strategy is further employed: an initial approximation of the trigger through noise sampled from a prior distribution, followed by refinement through differential multi-step samplers. Additionally, with the reversed trigger, we propose backdoor detection from the noise space, introducing the first backdoor input detection approach for diffusion models and a novel model detection algorithm that calculates the KL divergence between reversed and benign distributions. Extensive evaluations demonstrate that TERD secures a 100% True Positive Rate (TPR) and True Negative Rate (TNR) across datasets of varying resolutions. TERD also demonstrates nice adaptability to other Stochastic Differential Equation (SDE)-based models. Our code is available at https://github.com/PKU-ML/TERD.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04975",
        "abstract url": "https://arxiv.org/abs/2409.04975",
        "title": "PatchAlign:Fair and Accurate Skin Disease Image Classification by Alignment with Clinical Labels",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "diagnosis",
                "Disease",
                "Clinical",
                "lesion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning models have achieved great success in automating skin lesion diagnosis. However, the ethnic disparity in these models' predictions needs to be addressed before deploying them. We introduce a novel approach, PatchAlign, to enhance skin condition image classification accuracy and fairness by aligning with clinical text representations of skin conditions. PatchAlign uses Graph Optimal Transport (GOT) Loss as a regularizer to perform cross-domain alignment. The representations obtained are robust and generalize well across skin tones, even with limited training samples. To reduce the effect of noise and artifacts in clinical dermatology images, we propose a learnable Masked Graph Optimal Transport for cross-domain alignment that further improves fairness metrics. We compare our model to the state-of-the-art FairDisCo on two skin lesion datasets with different skin types: Fitzpatrick17k and Diverse Dermatology Images (DDI). PatchAlign enhances the accuracy of skin condition image classification by 2.8% (in-domain) and 6.2% (out-domain) on Fitzpatrick17k, and 4.2% (in-domain) on DDI compared to FairDisCo. Additionally, it consistently improves the fairness of true positive rates across skin tones. The source code for the implementation is available at the following GitHub repository: https://github.com/aayushmanace/PatchAlign24, enabling easy reproduction and further experimentation.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "MICCAI 2024. Early Accept Paper (amongst the top 11% of 2869 papers submitted)"
    },
    {
        "paper id": "2409.05013",
        "abstract url": "https://arxiv.org/abs/2409.05013",
        "title": "Cluster-based Random Radial Basis Kernel Function for Hyperspectral Data Classification",
        "rating": "-2",
        "keywords": [
            [
                "SVM",
                "support vector machine"
            ],
            [
                "Hyperspectral Data"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Kernel-based classification methods, particularly the support vector machine (SVM), are among the most common algorithms for hyperspectral data classification. The Radial Basis function (RBF) kernel has earned great popularity in hyperspectral data classification due to its superior performance among other available kernel functions. Nonetheless, the cross-validation technique usually used for tunning the RBF parameter can be time-consuming and may result in sub-optimal values for the parameter. This paper proposed the cluster-based random radial basis function (CRRBF) kernel function as an alternative to the RBF kernel to achieve similar performance with a more manageable parameter, which is the number of clusters. The CRRBF kernel initially clusters the hyperspectral bands and then constructs an RBF kernel with a randomly assigned value as the kernel parameter from each cluster of bands. The final CRRBF kernel is constructed by adding up these basis RBF kernels. We have designed several experiments to evaluate the SVM performance trained with the CRRBF kernel considering a different number of clusters and training samples, using three hyperspectral data sets. The obtained results showed that the CRRBF kernel could provide comparable or better results than the RBF. The results also showed that the classification performance is pretty robust to the number of clusters, as the only open parameter of the CRRBF kernel.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05025",
        "abstract url": "https://arxiv.org/abs/2409.05025",
        "title": "Cooperative Learning-Based Framework for VNF Caching and Placement Optimization over Low Earth Orbit Satellite Networks",
        "rating": "-2",
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "Low Earth Orbit Satellite Networks (LSNs) are integral to supporting a broad range of modern applications, which are typically modeled as Service Function Chains (SFCs). Each SFC is composed of Virtual Network Functions (VNFs), where each VNF performs a specific task. In this work, we tackle two key challenges in deploying SFCs across an LSN. Firstly, we aim to optimize the long-term system performance by minimizing the average end-to-end SFC execution delay, given that each satellite comes with a pre-installed/cached subset of VNFs. To achieve optimal SFC placement, we formulate an offline Dynamic Programming (DP) equation. To overcome the challenges associated with DP, such as its complexity, the need for probability knowledge, and centralized decision-making, we put forth an online Multi-Agent Q-Learning (MAQL) solution. Our MAQL approach addresses convergence issues in the non-stationary LSN environment by enabling satellites to share learning parameters and update their Q-tables based on distinct rules for their selected actions. Secondly, to determine the optimal VNF subsets for satellite caching, we develop a Bayesian Optimization (BO)-based learning mechanism that operates both offline and continuously in the background during runtime. Extensive experiments demonstrate that our MAQL approach achieves near-optimal performance comparable to the DP model and significantly outperforms existing baselines. Moreover, the BO-based approach effectively enhances the request serving rate over time.",
        "subjects": [
            "cs.IT",
            "eess.SY"
        ],
        "comment": "40 pages, 11 figure, 3 tables"
    },
    {
        "paper id": "2409.05026",
        "abstract url": "https://arxiv.org/abs/2409.05026",
        "title": "A Double-Difference Doppler Shift-Based Positioning Framework with Ephemeris Error Correction of LEO Satellites",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "In signals of opportunity (SOPs)-based positioning utilizing low Earth orbit (LEO) satellites, ephemeris data derived from two-line element files can introduce increasing error over time. To handle the erroneous measurement, an additional base receiver with a known position is often used to compensate for the effect of ephemeris error when positioning the user terminal (UT). However, this approach is insufficient for the long baseline (the distance between the base receiver and UT) as it fails to adequately correct Doppler shift measurement errors caused by ephemeris inaccuracies, resulting in degraded positioning performance. Moreover, the lack of clock synchronization between the base receiver and UT exacerbates erroneous Doppler shift measurements. To address these challenges, we put forth a robust double-difference Doppler shift-based positioning framework, coined 3DPose, to handle the clock synchronization issue between the base receiver and UT, and positioning degradation due to the long baseline. The proposed 3DPose framework leverages double-difference Doppler shift measurements to eliminate the clock synchronization issue and incorporates a novel ephemeris error correction algorithm to enhance UT positioning accuracy in case of the long baseline. The algorithm specifically characterizes and corrects the Doppler shift measurement errors arising from erroneous ephemeris data, focusing on satellite position errors in the tangential direction. To validate the effectiveness of the proposed framework, we conduct comparative analyses across three different scenarios, contrasting its performance with the existing differential Doppler positioning method. The results demonstrate that the proposed 3DPose framework achieves an average reduction of 90% in 3-dimensional positioning errors compared to the existing differential Doppler approach.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "32 pages, 8 figures, 2 tables"
    },
    {
        "paper id": "2409.05029",
        "abstract url": "https://arxiv.org/abs/2409.05029",
        "title": "Limiting Computation Levels in Prioritized Trajectory Planning with Safety Guarantees",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "In prioritized planning for vehicles, vehicles plan trajectories in parallel or in sequence. Parallel prioritized planning offers approximately consistent computation time regardless of the number of vehicles but struggles to guarantee collision-free trajectories. Conversely, sequential prioritized planning can guarantee collision-freeness but results in increased computation time as the number of sequentially computing vehicles, which we term computation levels, grows. This number is determined by the directed coupling graph resulted from the coupling and prioritization of vehicles. In this work, we guarantee safe trajectories in parallel planning through reachability analysis. Although these trajectories are collision-free, they tend to be conservative. We address this by planning with a subset of vehicles in sequence. We formulate the problem of selecting this subset as a graph partitioning problem that allows us to independently set computation levels. Our simulations demonstrate a reduction in computation levels by approximately 64% compared to sequential prioritized planning while maintaining the solution quality.",
        "subjects": [
            "cs.RO",
            "cs.MA",
            "eess.SY"
        ],
        "comment": "8 pages, 4 figures. This is an extended abstract of our previous work published at the 2024 European Control Conference (ECC), June 25-28, 2024. Stockholm, Sweden"
    },
    {
        "paper id": "2409.05054",
        "abstract url": "https://arxiv.org/abs/2409.05054",
        "title": "Adaptive Control based Friction Estimation for Tracking Control of Robot Manipulators",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "Adaptive control is often used for friction compensation in trajectory tracking tasks because it does not require torque sensors. However, it has some drawbacks: first, the most common certainty-equivalence adaptive control design is based on linearized parameterization of the friction model, therefore nonlinear effects, including the stiction and Stribeck effect, are usually omitted. Second, the adaptive control-based estimation can be biased due to non-zero steady-state error. Third, neglecting unknown model mismatch could result in non-robust estimation. This paper proposes a novel linear parameterized friction model capturing the nonlinear static friction phenomenon. Subsequently, an adaptive control-based friction estimator is proposed to reduce the bias during estimation based on backstepping. Finally, we propose an algorithm to generate excitation for robust estimation. Using a KUKA iiwa 14, we conducted trajectory tracking experiments to evaluate the estimated friction model, including random Fourier and drawing trajectories, showing the effectiveness of our methodology in different control schemes.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05101",
        "abstract url": "https://arxiv.org/abs/2409.05101",
        "title": "On the Need to Monitor Continuous Integration Practices -- An Empirical Study",
        "rating": "-2",
        "keywords": [
            [
                "Health"
            ]
        ],
        "abstract": "Continuous Integration (CI) encompasses a set of widely adopted practices that enhance software development. However, there are indications that developers may not adequately monitor CI practices. Hence, this paper explores developers' perceptions regarding the monitoring CI practices. To achieve this, we first perform a Document Analysis to assess developers' expressed need for practice monitoring in pull requests comments generated by developers during the development process. After that, we conduct a survey among developers from 121 open-source projects to understand perception of the significance of monitoring seven CI practices in their projects. Finally, we triangulate the emergent themes from our survey by performing a second Document Analysis to understand the extent of monitoring features supported by existing CI services. Our key findings indicate that: 1) the most frequently mentioned CI practice during the development process is ``Test Coverage'' (> 80\\%), while ``Build Health'' and ``Time to Fix a Broken Build'' present notable opportunities for monitoring CI practices; 2) developers do not adequately monitor all CI practices and express interest in monitoring additional practices; and 3) the most popular CI services currently offer limited native support for monitoring CI practices, requiring the use of third-party tools. Our results lead us to conclude that monitoring CI practices is often overlooked by both CI services and developers. Using third-party tools in conjunction with CI services is challenging, they monitor some redundant practices and still falls short of fully supporting CI practices monitoring. Therefore, CI services should implement CI practices monitoring, which would facilitate and encourage developers to monitor them.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Submitted to the Empirical Software Engineering Journal"
    },
    {
        "paper id": "2409.05151",
        "abstract url": "https://arxiv.org/abs/2409.05151",
        "title": "Ultron: Enabling Temporal Geometry Compression of 3D Mesh Sequences using Temporal Correspondence and Mesh Deformation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "quality assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the advancement of computer vision, dynamic 3D reconstruction techniques have seen significant progress and found applications in various fields. However, these techniques generate large amounts of 3D data sequences, necessitating efficient storage and transmission methods. Existing 3D model compression methods primarily focus on static models and do not consider inter-frame information, limiting their ability to reduce data size. Temporal mesh compression, which has received less attention, often requires all input meshes to have the same topology, a condition rarely met in real-world applications. This research proposes a method to compress mesh sequences with arbitrary topology using temporal correspondence and mesh deformation. The method establishes temporal correspondence between consecutive frames, applies a deformation model to transform the mesh from one frame to subsequent frames, and replaces the original meshes with deformed ones if the quality meets a tolerance threshold. Extensive experiments demonstrate that this method can achieve state-of-the-art performance in terms of compression performance. The contributions of this paper include a geometry and motion-based model for establishing temporal correspondence between meshes, a mesh quality assessment for temporal mesh sequences, an entropy-based encoding and corner table-based method for compressing mesh sequences, and extensive experiments showing the effectiveness of the proposed method. All the code will be open-sourced at https://github.com/lszhuhaichao/ultron.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05185",
        "abstract url": "https://arxiv.org/abs/2409.05185",
        "title": "Covert Vehicle Misguidance and Its Detection: A Hypothesis Testing Game over Continuous-Time Dynamics",
        "rating": "-2",
        "keywords": [
            [
                "trajectory",
                "Vehicle"
            ],
            [
                "attack"
            ]
        ],
        "abstract": "We formulate a stochastic zero-sum game to analyze the competition between the attacker, who tries to covertly misguide the vehicle to an unsafe region, versus the detector, who tries to detect the attack signal based on the observed trajectory of the vehicle. Based on Girsanov's theorem and the generalized Neyman-Pearson lemma, we show that a constant bias injection attack as the attacker's strategy and a likelihood ratio test as the detector's strategy constitute the unique saddle point of the game. We also derive the first-order and the second-order exponents of the type II error as a function of the data length.",
        "subjects": [
            "math.OC",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05200",
        "abstract url": "https://arxiv.org/abs/2409.05200",
        "title": "Lung-DETR: Deformable Detection Transformer for Sparse Lung Nodule Anomaly Detection",
        "rating": "-2",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "CT",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate lung nodule detection for computed tomography (CT) scan imagery is challenging in real-world settings due to the sparse occurrence of nodules and similarity to other anatomical structures. In a typical positive case, nodules may appear in as few as 3% of CT slices, complicating detection. To address this, we reframe the problem as an anomaly detection task, targeting rare nodule occurrences in a predominantly normal dataset. We introduce a novel solution leveraging custom data preprocessing and Deformable Detection Transformer (Deformable- DETR). A 7.5mm Maximum Intensity Projection (MIP) is utilized to combine adjacent lung slices into single images, reducing the slice count and decreasing nodule sparsity. This enhances spatial context, allowing for better differentiation between nodules and other structures such as complex vascular structures and bronchioles. Deformable-DETR is employed to detect nodules, with a custom focal loss function to better handle the imbalanced dataset. Our model achieves state-of-the-art performance on the LUNA16 dataset with an F1 score of 94.2% (95.2% recall, 93.3% precision) on a dataset sparsely populated with lung nodules that is reflective of real-world clinical data.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05217",
        "abstract url": "https://arxiv.org/abs/2409.05217",
        "title": "From Concept to Reality: 5G Positioning with Open-Source Implementation of UL-TDoA in OpenAirInterface",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "This paper presents, for the first time, an open-source implementation of the 3GPP Uplink Time Difference of Arrival (UL-TDoA) positioning method using the OpenAirInterface (OAI) framework. UL-TDoA is a critical positioning technique in 5G networks, leveraging the time differences of signal arrival at multiple base stations to determine the precise location of User Equipment (UE). This implementation aims to democratize access to advanced positioning technology by integrating UL-TDoA capabilities into both the Radio Access Network (RAN) and Core Network (CN) components of OAI, providing a comprehensive and 3GPP-compliant solution. The development includes the incorporation of essential protocol procedures, message flows, and interfaces as defined by 3GPP standards. Validation is conducted using two distinct methods: an OAI-RF simulator-based setup for controlled testing and an O-RAN-based Localization Testbed at EURECOM in real-world conditions. The results demonstrate the viability of this open-source UL-TDoA implementation, enabling precise positioning in various environments. By making this implementation publicly available, the study paves the way for widespread research, development, and innovation in the field of 5G positioning technologies, fostering collaboration and accelerating the advancement of cellular network positioning.",
        "subjects": [
            "cs.IT",
            "cs.ET",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05235",
        "abstract url": "https://arxiv.org/abs/2409.05235",
        "title": "COVID19-CBABM: A City-Based Agent Based Disease Spread Modeling Framework",
        "rating": "-2",
        "keywords": [
            [
                "health",
                "Disease"
            ]
        ],
        "abstract": "In response to the ongoing pandemic and health emergency of COVID-19, several models have been used to understand the dynamics of virus spread. Some employ mathematical models like the compartmental SEIHRD approach and others rely on agent-based modeling (ABM). In this paper, a new city-based agent-based modeling approach called COVID19-CBABM is introduced. It considers not only the transmission mechanism simulated by the SEHIRD compartments but also models people movements and their interactions with their surroundings, particularly their interactions at different types of Points of Interest (POI), such as supermarkets. Through the development of knowledge extraction procedures for Safegraph data, our approach simulates realistic conditions based on spatial patterns and infection conditions considering locations where people spend their time in a given city. Our model was implemented in Python using the Mesa-Geo framework. COVID19-CBABM is portable and can be easily extended by adding more complicated scenarios. Therefore, it is a useful tool to assist the government and health authorities in evaluating strategic decisions and actions efficiently against this epidemic, using the unique mobility patterns of each city.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05249",
        "abstract url": "https://arxiv.org/abs/2409.05249",
        "title": "NetDPSyn: Synthesizing Network Traces under Differential Privacy",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "attacks"
            ]
        ],
        "abstract": "As the utilization of network traces for the network measurement research becomes increasingly prevalent, concerns regarding privacy leakage from network traces have garnered the public's attention. To safeguard network traces, researchers have proposed the trace synthesis that retains the essential properties of the raw data. However, previous works also show that synthesis traces with generative models are vulnerable under linkage attacks. This paper introduces NetDPSyn, the first system to synthesize high-fidelity network traces under privacy guarantees. NetDPSyn is built with the Differential Privacy (DP) framework as its core, which is significantly different from prior works that apply DP when training the generative model. The experiments conducted on three flow and two packet datasets indicate that NetDPSyn achieves much better data utility in downstream tasks like anomaly detection. NetDPSyn is also 2.5 times faster than the other methods on average in data synthesis.",
        "subjects": [
            "cs.CR",
            "cs.DB",
            "cs.NI"
        ],
        "comment": "IMC 2024"
    },
    {
        "paper id": "2409.05268",
        "abstract url": "https://arxiv.org/abs/2409.05268",
        "title": "Robotic Ad-Hoc Networks",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Practical robotic adhoc networks (RANETs), a type of mobile wireless adhoc networks (WANETs) supporting the WiFi-Direct modes common in internet of things and phone devices, is proposed based on a strategy of exploiting WiFi-Direct connection modes to overcome hardware restrictions. For a certain period of time the community was enthusiastic about the endless opportunities in fair, robust, efficient, and cheap communication created by the Adhoc mode of the WiFi IEEE 802.11 independent basic service set (IBSS) configuration that required no dedicated access points. The mode was a main enabler of wireless Adhoc networks (WANETS). This communication mode unfortunately did not get into the standard network cards present in IoT and mobile phones, likely due to the high energy consumption it exacts. Rather, such devices implement WiFi-Direct which is designed for star topologies. Several attempts were made to overcame the restriction and support WANETs, but they break at least the fairness and symmetry property, thereby reducing applicability. Here we show a solution for fair RANETs and evaluate the behavior of various strategies using simulations.",
        "subjects": [
            "cs.RO",
            "cs.NI"
        ],
        "comment": "Presented at the FCRAR 24 conference in May 2024 (Florida Conference on Recent Advances in Robotics)"
    },
    {
        "paper id": "2409.05289",
        "abstract url": "https://arxiv.org/abs/2409.05289",
        "title": "Developing Trajectory Planning with Behavioral Cloning and Proximal Policy Optimization for Path-Tracking and Static Obstacle Nudging",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving",
                "Trajectory"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "End-to-end approaches with Reinforcement Learning (RL) and Imitation Learning (IL) have gained increasing popularity in autonomous driving. However, they do not involve explicit reasoning like classic robotics workflow, nor planning with horizons, leading strategies implicit and myopic. In this paper, we introduce our trajectory planning method that uses Behavioral Cloning (BC) for path-tracking and Proximal Policy Optimization (PPO) bootstrapped by BC for static obstacle nudging. It outputs lateral offset values to adjust the given reference trajectory, and performs modified path for different controllers. Our experimental results show that the algorithm can do path-tracking that mimics the expert performance, and avoiding collision to fixed obstacles by trial and errors. This method makes a good attempt at planning with learning-based methods in trajectory planning problems of autonomous driving.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "6 pages, 7 figures"
    },
    {
        "paper id": "2409.05297",
        "abstract url": "https://arxiv.org/abs/2409.05297",
        "title": "Adaptive Offloading and Enhancement for Low-Light Video Analytics on Mobile Devices",
        "rating": "-2",
        "keywords": [
            [
                "quality assessment"
            ]
        ],
        "abstract": "In this paper, we explore adaptive offloading and enhancement strategies for video analytics tasks on computing-constrained mobile devices in low-light conditions. We observe that the accuracy of low-light video analytics varies from different enhancement algorithms. The root cause could be the disparities in the effectiveness of enhancement algorithms for feature extraction in analytic models. Specifically, the difference in class activation maps (CAMs) between enhanced and low-light frames demonstrates a positive correlation with video analytics accuracy. Motivated by such observations, a novel enhancement quality assessment method is proposed on CAMs to evaluate the effectiveness of different enhancement algorithms for low-light videos. Then, we design a multi-edge system, which adaptively offloads and enhances low-light video analytics tasks from mobile devices. To achieve the trade-off between the enhancement quality and the latency for all system-served mobile devices, we propose a genetic-based scheduling algorithm, which can find a near-optimal solution in a reasonable time to meet the latency requirement. Thereby, the offloading strategies and the enhancement algorithms are properly selected under the condition of limited end-edge bandwidth and edge computation resources. Simulation experiments demonstrate the superiority of the proposed system, improving accuracy up to 20.83\\% compared to existing benchmarks.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05298",
        "abstract url": "https://arxiv.org/abs/2409.05298",
        "title": "Evaluating Post-Quantum Cryptography on Embedded Systems: A Performance Analysis",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The National Institute of Standards and Technology (NIST) has finalized the selection of post-quantum cryptographic (PQC) algorithms for use in the era of quantum computing. Despite their integration into TLS protocol for key establishment and signature generation, there is limited study on profiling these newly standardized algorithms in resource-constrained communication systems. In this work, we integrate PQC into both TLS servers and clients built upon embedded systems. Additionally, we compare the performance overhead of PQC pairs to currently used non-PQC schemes.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.04979",
        "abstract url": "https://arxiv.org/abs/2409.04979",
        "title": "RCBEVDet++: Toward High-accuracy Radar-Camera Fusion 3D Perception Network",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving",
                "Radar"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Perceiving the surrounding environment is a fundamental task in autonomous driving. To obtain highly accurate perception results, modern autonomous driving systems typically employ multi-modal sensors to collect comprehensive environmental data. Among these, the radar-camera multi-modal perception system is especially favored for its excellent sensing capabilities and cost-effectiveness. However, the substantial modality differences between radar and camera sensors pose challenges in fusing information. To address this problem, this paper presents RCBEVDet, a radar-camera fusion 3D object detection framework. Specifically, RCBEVDet is developed from an existing camera-based 3D object detector, supplemented by a specially designed radar feature extractor, RadarBEVNet, and a Cross-Attention Multi-layer Fusion (CAMF) module. Firstly, RadarBEVNet encodes sparse radar points into a dense bird's-eye-view (BEV) feature using a dual-stream radar backbone and a Radar Cross Section aware BEV encoder. Secondly, the CAMF module utilizes a deformable attention mechanism to align radar and camera BEV features and adopts channel and spatial fusion layers to fuse them. To further enhance RCBEVDet's capabilities, we introduce RCBEVDet++, which advances the CAMF through sparse fusion, supports query-based multi-view camera perception models, and adapts to a broader range of perception tasks. Extensive experiments on the nuScenes show that our method integrates seamlessly with existing camera-based 3D perception models and improves their performance across various perception tasks. Furthermore, our method achieves state-of-the-art radar-camera fusion results in 3D object detection, BEV semantic segmentation, and 3D multi-object tracking tasks. Notably, with ViT-L as the image backbone, RCBEVDet++ achieves 72.73 NDS and 67.34 mAP in 3D object detection without test-time augmentation or model ensembling.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The extended work of RCBEVDet (CVPR2024)"
    },
    {
        "paper id": "2409.05030",
        "abstract url": "https://arxiv.org/abs/2409.05030",
        "title": "Some Results on Neural Network Stability, Consistency, and Convergence: Insights into Non-IID Data, High-Dimensional Settings, and Physics-Informed Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses critical challenges in machine learning, particularly the stability, consistency, and convergence of neural networks under non-IID data, distribution shifts, and high-dimensional settings. We provide new theoretical results on uniform stability for neural networks with dynamic learning rates in non-convex settings. Further, we establish consistency bounds for federated learning models in non-Euclidean spaces, accounting for distribution shifts and curvature effects. For Physics-Informed Neural Networks (PINNs), we derive stability, consistency, and convergence guarantees for solving Partial Differential Equations (PDEs) in noisy environments. These results fill significant gaps in understanding model behavior in complex, non-ideal conditions, paving the way for more robust and reliable machine learning applications.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05006",
        "abstract url": "https://arxiv.org/abs/2409.05006",
        "title": "HelmetPoser: A Helmet-Mounted IMU Dataset for Data-Driven Estimation of Human Head Motion in Diverse Conditions",
        "rating": "-3",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Helmet-mounted wearable positioning systems are crucial for enhancing safety and facilitating coordination in industrial, construction, and emergency rescue environments. These systems, including LiDAR-Inertial Odometry (LIO) and Visual-Inertial Odometry (VIO), often face challenges in localization due to adverse environmental conditions such as dust, smoke, and limited visual features. To address these limitations, we propose a novel head-mounted Inertial Measurement Unit (IMU) dataset with ground truth, aimed at advancing data-driven IMU pose estimation. Our dataset captures human head motion patterns using a helmet-mounted system, with data from ten participants performing various activities. We explore the application of neural networks, specifically Long Short-Term Memory (LSTM) and Transformer networks, to correct IMU biases and improve localization accuracy. Additionally, we evaluate the performance of these methods across different IMU data window dimensions, motion patterns, and sensor types. We release a publicly available dataset, demonstrate the feasibility of advanced neural network approaches for helmet-based localization, and provide evaluation metrics to establish a baseline for future studies in this field. Data and code can be found at \\url{https://lqiutong.github.io/HelmetPoser.github.io/}.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05016",
        "abstract url": "https://arxiv.org/abs/2409.05016",
        "title": "Using vs. Purchasing Industrial Robots: Adding an Organizational Perspective to Industrial HRI",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "Industrial"
            ]
        ],
        "abstract": "Purpose: Industrial robots allow manufacturing companies to increase productivity and remain competitive. For robots to be used, they must be accepted by operators on the one hand and bought by decision-makers on the other. The roles involved in such organizational processes have very different perspectives. It is therefore essential for suppliers and robot customers to understand these motives so that robots can successfully be integrated on manufacturing shopfloors. Methodology: We present findings of a qualitative study with operators and decision-makers from two Swiss manufacturing SMEs. Using laddering interviews and means-end analysis, we compare operators' and deciders' relevant elements and how these elements are linked to each other on different abstraction levels. These findings represent drivers and barriers to the acquisition, integration and acceptance of robots in the industry. Findings: We present the differing foci of operators and deciders, and how they can be used by demanders as well as suppliers of robots to achieve robot acceptance and deployment. First, we present a list of relevant attributes, consequences and values that constitute robot acceptance and/or rejection. Second, we provide quantified relevancies for these elements, and how they differ between operators and deciders. And third, we demonstrate how the elements are linked with each other on different abstraction levels, and how these links differ between the two groups.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "25 pages, 2 figures, 3 tables"
    },
    {
        "paper id": "2409.05040",
        "abstract url": "https://arxiv.org/abs/2409.05040",
        "title": "Unsupervised Multimodal 3D Medical Image Registration with Multilevel Correlation Balanced Optimization",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "navigation"
            ],
            [
                "Medical",
                "Surgical",
                "surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Surgical navigation based on multimodal image registration has played a significant role in providing intraoperative guidance to surgeons by showing the relative position of the target area to critical anatomical structures during surgery. However, due to the differences between multimodal images and intraoperative image deformation caused by tissue displacement and removal during the surgery, effective registration of preoperative and intraoperative multimodal images faces significant challenges. To address the multimodal image registration challenges in Learn2Reg 2024, an unsupervised multimodal medical image registration method based on multilevel correlation balanced optimization (MCBO) is designed to solve these problems. First, the features of each modality are extracted based on the modality independent neighborhood descriptor, and the multimodal images is mapped to the feature space. Second, a multilevel pyramidal fusion optimization mechanism is designed to achieve global optimization and local detail complementation of the deformation field through dense correlation analysis and weight-balanced coupled convex optimization for input features at different scales. For preoperative medical images in different modalities, the alignment and stacking of valid information between different modalities is achieved by the maximum fusion between deformation fields. Our method focuses on the ReMIND2Reg task in Learn2Reg 2024, and to verify the generality of the method, we also tested it on the COMULIS3DCLEM task. Based on the results, our method achieved second place in the validation of both two tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Method description for MICCAI Learn2Reg 2024 challenge"
    },
    {
        "paper id": "2409.05049",
        "abstract url": "https://arxiv.org/abs/2409.05049",
        "title": "The Influence of Demographic Variation on the Perception of Industrial Robot Movements",
        "rating": "-3",
        "keywords": [
            [
                "Robot"
            ],
            [
                "Industrial"
            ]
        ],
        "abstract": "The influence of individual differences on the perception and evaluation of interactions with robots has been researched for decades. Some human demographic characteristics have been shown to affect how individuals perceive interactions with robots. Still, it is to-date not clear whether, which and to what extent individual differences influence how we perceive robots, and even less is known about human factors and their effect on the perception of robot movements. In addition, most results on the relevance of individual differences investigate human-robot interactions with humanoid or social robots whereas interactions with industrial robots are underrepresented. We present a literature review on the relationship of robot movements and the influence of demographic variation. Our review reveals a limited comparability of existing findings due to a lack of standardized robot manipulations, various dependent variables used and differing experimental setups including different robot types. In addition, most studies have insufficient sample sizes to derive generalizable results. To overcome these shortcomings, we report the results from a Web-based experiment with 930 participants that studies the effect of demographic characteristics on the evaluation of movement behaviors of an articulated robot arm. Our findings demonstrate that most participants prefer an approach from the side, a large movement range, conventional numbers of rotations, smooth movements and neither fast nor slow movement speeds. Regarding individual differences, most of these preferences are robust to demographic variation, and only gender and age was found to cause slight preference differences between slow and fast movements.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05118",
        "abstract url": "https://arxiv.org/abs/2409.05118",
        "title": "Physics-augmented Deep Learning with Adversarial Domain Adaptation: Applications to STM Image Denoising",
        "rating": "-3",
        "keywords": [
            [
                "medical"
            ],
            [
                "quantum",
                "Physics"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Image denoising is a critical task in various scientific fields such as medical imaging and material characterization, where the accurate recovery of underlying structures from noisy data is essential. Although supervised denoising techniques have achieved significant advancements, they typically require large datasets of paired clean-noisy images for training. Unsupervised methods, while not reliant on paired data, typically necessitate a set of unpaired clean images for training, which are not always accessible. In this paper, we propose a physics-augmented deep learning with adversarial domain adaption (PDA-Net) framework for unsupervised image denoising, with applications to denoise real-world scanning tunneling microscopy (STM) images. Our PDA-Net leverages the underlying physics to simulate and envision the ground truth for denoised STM images. Additionally, built upon Generative Adversarial Networks (GANs), we incorporate a cycle-consistency module and a domain adversarial module into our PDA-Net to address the challenge of lacking paired training data and achieve information transfer between the simulated and real experimental domains. Finally, we propose to implement feature alignment and weight-sharing techniques to fully exploit the similarity between simulated and real experimental images, thereby enhancing the denoising performance in both the simulation and experimental domains. Experimental results demonstrate that the proposed PDA-Net successfully enhances the quality of STM images, offering promising applications to enhance scientific discovery and accelerate experimental quantum material research.",
        "subjects": [
            "eess.IV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05119",
        "abstract url": "https://arxiv.org/abs/2409.05119",
        "title": "Enhancing the Performance of Multi-Vehicle Navigation in Unstructured Environments using Hard Sample Mining",
        "rating": "-3",
        "keywords": [
            [
                "autonomous driving",
                "Vehicle"
            ],
            [
                "Navigation"
            ],
            [
                "GNNs"
            ]
        ],
        "abstract": "Contemporary research in autonomous driving has demonstrated tremendous potential in emulating the traits of human driving. However, they primarily cater to areas with well built road infrastructure and appropriate traffic management systems. Therefore, in the absence of traffic signals or in unstructured environments, these self-driving algorithms are expected to fail. This paper proposes a strategy for autonomously navigating multiple vehicles in close proximity to their desired destinations without traffic rules in unstructured environments. Graphical Neural Networks (GNNs) have demonstrated good utility for this task of multi-vehicle control. Among the different alternatives of training GNNs, supervised methods have proven to be most data-efficient, albeit require ground truth labels. However, these labels may not always be available, particularly in unstructured environments without traffic regulations. Therefore, a tedious optimization process may be required to determine them while ensuring that the vehicles reach their desired destination and do not collide with each other or any obstacles. Therefore, in order to expedite the training process, it is essential to reduce the optimization time and select only those samples for labeling that add most value to the training. In this paper, we propose a warm start method that first uses a pre-trained model trained on a simpler subset of data. Inference is then done on more complicated scenarios, to determine the hard samples wherein the model faces the greatest predicament. This is measured by the difficulty vehicles encounter in reaching their desired destination without collision. Experimental results demonstrate that mining for hard samples in this manner reduces the requirement for supervised training data by 10 fold. Videos and code can be found here: \\url{https://yininghase.github.io/multiagent-collision-mining/}.",
        "subjects": [
            "cs.MA"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2409.05142",
        "abstract url": "https://arxiv.org/abs/2409.05142",
        "title": "TanDepth: Leveraging Global DEMs for Metric Monocular Depth Estimation in UAVs",
        "rating": "-3",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Vehicle"
            ],
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Aerial scene understanding systems face stringent payload restrictions and must often rely on monocular depth estimation for modelling scene geometry, which is an inherently ill-posed problem. Moreover, obtaining accurate ground truth data required by learning-based methods raises significant additional challenges in the aerial domain. Self-supervised approaches can bypass this problem, at the cost of providing only up-to-scale results. Similarly, recent supervised solutions which make good progress towards zero-shot generalization also provide only relative depth values. This work presents TanDepth, a practical, online scale recovery method for obtaining metric depth results from relative estimations at inference-time, irrespective of the type of model generating them. Tailored for Unmanned Aerial Vehicle (UAV) applications, our method leverages sparse measurements from Global Digital Elevation Models (GDEM) by projecting them to the camera view using extrinsic and intrinsic information. An adaptation to the Cloth Simulation Filter is presented, which allows selecting ground points from the estimated depth map to then correlate with the projected reference points. We evaluate and compare our method against alternate scaling methods adapted for UAVs, on a variety of real-world scenes. Considering the limited availability of data for this domain, we construct and release a comprehensive, depth-focused extension to the popular UAVid dataset to further research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05207",
        "abstract url": "https://arxiv.org/abs/2409.05207",
        "title": "Low Latency Transformer Inference on FPGAs for Physics Applications with hls4ml",
        "rating": "-3.5",
        "keywords": [
            [
                "FPGAs"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study presents an efficient implementation of transformer architectures in Field-Programmable Gate Arrays(FPGAs) using hls4ml. We demonstrate the strategy for implementing the multi-head attention, softmax, and normalization layer and evaluate three distinct models. Their deployment on VU13P FPGA chip achieved latency less than 2us, demonstrating the potential for real-time applications. HLS4ML compatibility with any TensorFlow-built transformer model further enhances the scalability and applicability of this work. Index Terms: FPGAs, machine learning, transformers, high energy physics, LIGO",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05240",
        "abstract url": "https://arxiv.org/abs/2409.05240",
        "title": "A Physics-Enforced Neural Network to Predict Polymer Melt Viscosity",
        "rating": "-4",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "Physics"
            ]
        ],
        "abstract": "Achieving superior polymeric components through additive manufacturing (AM) relies on precise control of rheology. One key rheological property particularly relevant to AM is melt viscosity ($\u03b7$). Melt viscosity is influenced by polymer chemistry, molecular weight ($M_w$), polydispersity, induced shear rate ($\\dot\u03b3$), and processing temperature ($T$). The relationship of $\u03b7$ with $M_w$, $\\dot\u03b3$, and $T$ may be captured by parameterized equations. Several physical experiments are required to fit the parameters, so predicting $\u03b7$ of a new polymer material in unexplored physical domains is a laborious process. Here, we develop a Physics-Enforced Neural Network (PENN) model that predicts the empirical parameters and encodes the parametrized equations to calculate $\u03b7$ as a function of polymer chemistry, $M_w$, polydispersity, $\\dot\u03b3$, and $T$. We benchmark our PENN against physics-unaware Artificial Neural Network (ANN) and Gaussian Process Regression (GPR) models. Finally, we demonstrate that the PENN offers superior values of $\u03b7$ when extrapolating to unseen values of $M_w$, $\\dot\u03b3$, and $T$ for sparsely seen polymers.",
        "subjects": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05033",
        "abstract url": "https://arxiv.org/abs/2409.05033",
        "title": "A Survey on Diffusion Models for Recommender Systems",
        "rating": "-4.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "recommendation"
            ],
            [
                "bird's-eye view"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "While traditional recommendation techniques have made significant strides in the past decades, they still suffer from limited generalization performance caused by factors like inadequate collaborative signals, weak latent representations, and noisy data. In response, diffusion models (DMs) have emerged as promising solutions for recommender systems due to their robust generative capabilities, solid theoretical foundations, and improved training stability. To this end, in this paper, we present the first comprehensive survey on diffusion models for recommendation, and draw a bird's-eye view from the perspective of the whole pipeline in real-world recommender systems. We systematically categorize existing research works into three primary domains: (1) diffusion for data engineering & encoding, focusing on data augmentation and representation enhancement; (2) diffusion as recommender models, employing diffusion models to directly estimate user preferences and rank items; and (3) diffusion for content presentation, utilizing diffusion models to generate personalized content such as fashion and advertisement creatives. Our taxonomy highlights the unique strengths of diffusion models in capturing complex data distributions and generating high-quality, diverse samples that closely align with user preferences. We also summarize the core characteristics of the adapting diffusion models for recommendation, and further identify key areas for future exploration, which helps establish a roadmap for researchers and practitioners seeking to advance recommender systems through the innovative application of diffusion models. To further facilitate the research community of recommender systems based on diffusion models, we actively maintain a GitHub repository for papers and other related resources in this rising direction https://github.com/CHIANGEL/Awesome-Diffusion-for-RecSys.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2409.05143",
        "abstract url": "https://arxiv.org/abs/2409.05143",
        "title": "PhysHand: A Hand Simulation Model with Physiological Geometry, Physical Deformation, and Accurate Contact Handling",
        "rating": "-5",
        "keywords": [
            [
                "depth",
                "skeleton",
                "SDF"
            ],
            [
                "Physiological"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "In virtual Hand-Object Interaction (HOI) scenarios, the authenticity of the hand's deformation is important to immersive experience, such as natural manipulation or tactile feedback. Unrealistic deformation arises from simplified hand geometry, neglect of the different physics attributes of the hand, and penetration due to imprecise contact handling. To address these problems, we propose PhysHand, a novel hand simulation model, which enhances the realism of deformation in HOI. First, we construct a physiologically plausible geometry, a layered mesh with a \"skin-flesh-skeleton\" structure. Second, to satisfy the distinct physics features of different soft tissues, a constraint-based dynamics framework is adopted with carefully designed layer-corresponding constraints to maintain flesh attached and skin smooth. Finally, we employ an SDF-based method to eliminate the penetration caused by contacts and enhance its accuracy by introducing a novel multi-resolution querying strategy. Extensive experiments have been conducted to demonstrate the outstanding performance of PhysHand in calculating deformations and handling contacts. Compared to existing methods, our PhysHand: 1) can compute both physiologically and physically plausible deformation; 2) significantly reduces the depth and count of penetration in HOI.",
        "subjects": [
            "cs.GR",
            "cs.HC"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2409.04984",
        "abstract url": "https://arxiv.org/abs/2409.04984",
        "title": "FPT approximations for Capacitated Sum of Radii and Diameters",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Capacitated Sum of Radii problem involves partitioning a set of points $P$, where each point $p\\in P$ has capacity $U_p$, into $k$ clusters that minimize the sum of cluster radii, such that the number of points in the cluster centered at point $p$ is at most $U_p$. We begin by showing that the problem is APX-hard, and that under gap-ETH there is no parameterized approximation scheme (FPT-AS). We then construct a $\\approx5.83$-approximation algorithm in FPT time (improving a previous $\\approx7.61$ approximation in FPT time). Our results also hold when the objective is a general monotone symmetric norm of radii. We also improve the approximation factors for the uniform capacity case, and for the closely related problem of Capacitated Sum of Diameters.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "56 pages, 9 figures"
    },
    {
        "paper id": "2409.04987",
        "abstract url": "https://arxiv.org/abs/2409.04987",
        "title": "How to Align Large Language Models for Teaching English? Designing and Developing LLM based-Chatbot for Teaching English Conversation in EFL, Findings and Limitations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study investigates the design, development, and evaluation of a Large Language Model (LLM)-based chatbot for teaching English conversations in an English as a Foreign Language (EFL) context. Employing the Design and Development Research (DDR), we analyzed needs, established design principles, and iteratively refined a chatbot through experimenting various LLMs and alignment methods. Through both quantitative and qualitative evaluations, we identified the most effective LLM and its prompt combination to generate high-quality, contextually appropriate responses. Interviews with teachers provided insights into desirable system features, potential educational applications, and ethical considerations in the development and deployment of the chatbots. The design iterations yielded the importance of feedback mechanisms and customizable AI personas. Future research should explore adaptive feedback strategies, collaborative approaches with various stakeholders, and the integration of insights from human-computer interaction (HCI) and user experience (UX) design. This study contributes to the growing body of research on applying LLMs in language education, providing insights and recommendations for the design, development, and evaluation of LLM-based chatbots for EFL conversation practice. As the field evolves, ongoing research and collaboration among educators, AI engineers, and other stakeholders will be essential to harness the potential of these technologies to enhance language learning experiences.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "56 pages"
    },
    {
        "paper id": "2409.04998",
        "abstract url": "https://arxiv.org/abs/2409.04998",
        "title": "A Double Tracking Method for Optimization with Decentralized Generalized Orthogonality Constraints",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we consider the decentralized optimization problems with generalized orthogonality constraints, where both the objective function and the constraint exhibit a distributed structure. Such optimization problems, albeit ubiquitous in practical applications, remain unsolvable by existing algorithms in the presence of distributed constraints. To address this issue, we convert the original problem into an unconstrained penalty model by resorting to the recently proposed constraint-dissolving operator. However, this transformation compromises the essential property of separability in the resulting penalty function, rendering it impossible to employ existing algorithms to solve. We overcome this difficulty by introducing a novel algorithm that tracks the gradient of the objective function and the Jacobian of the constraint mapping simultaneously. The global convergence guarantee is rigorously established with an iteration complexity. To substantiate the effectiveness and efficiency of our proposed algorithm, we present numerical results on both synthetic and real-world datasets.",
        "subjects": [
            "math.OC",
            "cs.DC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05019",
        "abstract url": "https://arxiv.org/abs/2409.05019",
        "title": "Unified External Stakeholder Engagement and Requirements Strategy",
        "rating": "-10",
        "keywords": [],
        "abstract": "Understanding stakeholder needs is essential for project success, as stakeholder importance varies across projects. This study proposes a framework for early stakeholder identification and continuous engagement throughout the project lifecycle. The framework addresses common organizational failures in stakeholder communication that lead to project delays and cancellations. By classifying stakeholders by influence and interest, establishing clear communication channels, and implementing regular feedback loops, the framework ensures effective stakeholder involvement. This approach allows for necessary project adjustments and builds long-term relationships, validated by a survey of IT professionals. Engaging stakeholders strategically at all stages minimizes misunderstandings and project risks, contributing to better project management and lifecycle outcomes.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "15 Pages"
    },
    {
        "paper id": "2409.05020",
        "abstract url": "https://arxiv.org/abs/2409.05020",
        "title": "A Performance Bound for the Greedy Algorithm in a Generalized Class of String Optimization Problems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a simple performance bound for the greedy scheme in string optimization problems that obtains strong results. Our approach vastly generalizes the group of previously established greedy curvature bounds by Conforti and Cornu\u00e9jols (1984). We consider three constants, $\u03b1_G$, $\u03b1_G'$, and $\u03b1_G''$ introduced by Conforti and Cornu\u00e9jols (1984), that are used in performance bounds of greedy schemes in submodular set optimization. We first generalize both of the $\u03b1_G$ and $\u03b1_G''$ bounds to string optimization problems in a manner that includes maximizing submodular set functions over matroids as a special case. We then derive a much simpler and computable bound that allows for applications to a far more general class of functions with string domains. We prove that our bound is superior to both the $\u03b1_G$ and $\u03b1_G''$ bounds and provide a counterexample to show that the $\u03b1_G'$ bound is incorrect under the assumptions in Conforti and Cornu\u00e9jols (1984). We conclude with two applications. The first is an application of our result to sensor coverage problems. We demonstrate our performance bound in cases where the objective function is set submodular and string submodular. The second is an application to a social welfare maximization problem with black-box utility functions.",
        "subjects": [
            "eess.SY",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05042",
        "abstract url": "https://arxiv.org/abs/2409.05042",
        "title": "Efficient Rare Temporal Pattern Mining in Time Series",
        "rating": "-10",
        "keywords": [],
        "abstract": "Time series data from various domains are increasing continuously. Extracting and analyzing the temporal patterns in these series can reveal significant insights. Temporal pattern mining (TPM) extends traditional pattern mining by incorporating event time intervals into extracted patterns, enhancing their expressiveness but increasing time and space complexities. One valuable type of temporal pattern is known as rare temporal patterns (RTPs), which occur rarely but with high confidence. There exist several challenges when mining rare temporal patterns. The support measure is set very low, leading to a further combinatorial explosion and potentially producing too many uninteresting patterns. Thus, an efficient approach to rare temporal pattern mining is needed. This paper introduces our Rare Temporal Pattern Mining from Time Series (RTPMfTS) method for discovering rare temporal patterns, featuring the following key contributions: (1) An end-to-end RTPMfTS process that takes time series data as input and yields rare temporal patterns as output. (2) An efficient Rare Temporal Pattern Mining (RTPM) algorithm that uses optimized data structures for quick event and pattern retrieval and utilizes effective pruning techniques for much faster mining. (3) A thorough experimental evaluation of RTPM, showing that RTPM outperforms the baseline in terms of runtime and memory usage.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2306.10994"
    },
    {
        "paper id": "2409.05044",
        "abstract url": "https://arxiv.org/abs/2409.05044",
        "title": "An Analysis of Logit Learning with the r-Lambert Function",
        "rating": "-10",
        "keywords": [],
        "abstract": "The well-known replicator equation in evolutionary game theory describes how population-level behaviors change over time when individuals make decisions using simple imitation learning rules. In this paper, we study evolutionary dynamics based on a fundamentally different class of learning rules known as logit learning. Numerous previous studies on logit dynamics provide numerical evidence of bifurcations of multiple fixed points for several types of games. Our results here provide a more explicit analysis of the logit fixed points and their stability properties for the entire class of two-strategy population games -- by way of the $r$-Lambert function. We find that for Prisoner's Dilemma and anti-coordination games, there is only a single fixed point for all rationality levels. However, coordination games exhibit a pitchfork bifurcation: there is a single fixed point in a low-rationality regime, and three fixed points in a high-rationality regime. We provide an implicit characterization for the level of rationality where this bifurcation occurs. In all cases, the set of logit fixed points converges to the full set of Nash equilibria in the high rationality limit.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "9 pages, one figure, to be included in CDC 2024 conference proceedings"
    },
    {
        "paper id": "2409.05046",
        "abstract url": "https://arxiv.org/abs/2409.05046",
        "title": "Fully Characterizing Lossy Catalytic Computation",
        "rating": "-10",
        "keywords": [],
        "abstract": "A catalytic machine is a model of computation where a traditional space-bounded machine is augmented with an additional, significantly larger, \"catalytic\" tape, which, while being available as a work tape, has the caveat of being initialized with an arbitrary string, which must be preserved at the end of the computation. Despite this restriction, catalytic machines have been shown to have surprising additional power; a logspace machine with a polynomial length catalytic tape, known as catalytic logspace ($CL$), can compute problems which are believed to be impossible for $L$. A fundamental question of the model is whether the catalytic condition, of leaving the catalytic tape in its exact original configuration, is robust to minor deviations. This study was initialized by Gupta et al. (2024), who defined lossy catalytic logspace ($LCL[e]$) as a variant of $CL$ where we allow up to $e$ errors when resetting the catalytic tape. They showed that $LCL[e] = CL$ for any $e = O(1)$, which remains the frontier of our understanding. In this work we completely characterize lossy catalytic space ($LCSPACE[s,c,e]$) in terms of ordinary catalytic space ($CSPACE[s,c]$). We show that $$LCSPACE[s,c,e] = CSPACE[\u0398(s + e \\log c), \u0398(c)]$$ In other words, allowing $e$ errors on a catalytic tape of length $c$ is equivalent, up to a constant stretch, to an equivalent errorless catalytic machine with an additional $e \\log c$ bits of ordinary working memory. As a consequence, we show that for any $e$, $LCL[e] = CL$ implies $SPACE[e \\log n] \\subseteq ZPP$, thus giving a barrier to any improvement beyond $LCL[O(1)] = CL$. We also show equivalent results for non-deterministic and randomized catalytic space.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2409.05055",
        "abstract url": "https://arxiv.org/abs/2409.05055",
        "title": "Investigating the Role of Cultural Values in Adopting Large Language Models for Software Engineering",
        "rating": "-10",
        "keywords": [],
        "abstract": "As a socio-technical activity, software development involves the close interconnection of people and technology. The integration of Large Language Models (LLMs) into this process exemplifies the socio-technical nature of software development. Although LLMs influence the development process, software development remains fundamentally human-centric, necessitating an investigation of the human factors in this adoption. Thus, with this study we explore the factors influencing the adoption of LLMs in software development, focusing on the role of professionals' cultural values. Guided by the Unified Theory of Acceptance and Use of Technology (UTAUT2) and Hofstede's cultural dimensions, we hypothesized that cultural values moderate the relationships within the UTAUT2 framework. Using Partial Least Squares-Structural Equation Modelling and data from 188 software engineers, we found that habit and performance expectancy are the primary drivers of LLM adoption, while cultural values do not significantly moderate this process. These findings suggest that, by highlighting how LLMs can boost performance and efficiency, organizations can encourage their use, no matter the cultural differences. Practical steps include offering training programs to demonstrate LLM benefits, creating a supportive environment for regular use, and continuously tracking and sharing performance improvements from using LLMs.",
        "subjects": [
            "cs.SE",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05086",
        "abstract url": "https://arxiv.org/abs/2409.05086",
        "title": "Exploring the Optimal Size of Grid-forming Energy Storage in an Off-grid Renewable P2H System under Multi-timescale Energy Management",
        "rating": "-10",
        "keywords": [],
        "abstract": "Utility-scale off-grid renewable power-to-hydrogen systems (OReP2HSs) typically include photovoltaic plants, wind turbines, electrolyzers (ELs), and energy storage systems. As an island system, OReP2HS requires at least one component, generally the battery energy storage system (BESS), that operates for grid-forming control to provide frequency and voltage references and regulate them through transient power support and short-term energy balance regulation. While larger BESS capacity increases this ability, it also raises investment costs. This paper proposes a framework of layered multi-timescale energy management system (EMS) and evaluates the most cost-effective size of the grid-forming BESS in the OReP2HS. The proposed EMS covers the timescales ranging from those for power system transient behaviors to intra-day scheduling, coordinating renewable power, BESS, and ELs. Then, an iterative search procedure based on high-fidelity simulation is employed to determine the size of the BESS with minimal levelized cost of hydrogen (LCOH). Simulations over a reference year, based on the data from a planned OReP2HS project in Inner Mongolia, China, show that with the proposed EMS, the base-case optimal LCOH is 33.212 CNY/kg (4.581 USD/kg). The capital expenditure of the BESS accounts for 17.83% of the total, and the optimal BESS size accounts for 13.6% of the rated hourly energy output of power sources. Sensitivity analysis reveals that by reducing the electrolytic load adjustment time step from 90 to 5 s and increasing its ramping limit from 1% to 10% rated power per second, the BESS size decreases by 53.57%, and the LCOH decreases to 25.458 CNY/kg (3.511 USD/kg). Considering the cost of designing and manufacturing utility-scale ELs with fast load regulation capability, a load adjustment time step of 5-10 s and a ramping limit of 4-6% rated power per second are recommended.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05092",
        "abstract url": "https://arxiv.org/abs/2409.05092",
        "title": "Towards an AI/ML-driven SMO Framework in O-RAN: Scenarios, Solutions, and Challenges",
        "rating": "-10",
        "keywords": [],
        "abstract": "The emergence of the open radio access network (O-RAN) architecture offers a paradigm shift in cellular network management and service orchestration, leveraging data-driven, intent-based, autonomous, and intelligent solutions. Within O-RAN, the service management and orchestration (SMO) framework plays a pivotal role in managing network functions (NFs), resource allocation, service provisioning, and others. However, the increasing complexity and scale of O-RANs demand autonomous and intelligent models for optimizing SMO operations. To achieve this goal, it is essential to integrate intelligence and automation into the operations of SMO. In this manuscript, we propose three scenarios for integrating machine learning (ML) algorithms into SMO. We then focus on exploring one of the scenarios in which the non-real-time RAN intelligence controller (Non-RT RIC) plays a major role in data collection, as well as model training, deployment, and refinement, by proposing a centralized ML architecture. Finally, we identify potential challenges associated with implementing a centralized ML solution within SMO.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05093",
        "abstract url": "https://arxiv.org/abs/2409.05093",
        "title": "CloudNativeSim: a toolkit for modeling and simulation of cloud-native applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cloud-native applications are increasingly becoming popular in modern software design. Employing a microservice-based architecture into these applications is a prevalent strategy that enhances system availability and flexibility. However, cloud-native applications also introduce new challenges, such as frequent inter-service communication and the complexity of managing heterogeneous codebases and hardware, resulting in unpredictable complexity and dynamism. Furthermore, as applications scale, only limited research teams or enterprises possess the resources for large-scale deployment and testing, which impedes progress in the cloud-native domain. To address these challenges, we propose CloudNativeSim, a simulator for cloud-native applications with a microservice-based architecture. CloudNativeSim offers several key benefits: (i) comprehensive and dynamic modeling for cloud-native applications, (ii) an extended simulation framework with new policy interfaces for scheduling cloud-native applications, and (iii) support for customized application scenarios and user feedback based on Quality of Service (QoS) metrics. CloudNativeSim can be easily deployed on standard computers to manage a high volume of requests and services. Its performance was validated through a case study, demonstrating higher than 94.5% accuracy in terms of response time. The study further highlights the feasibility of CloudNativeSim by illustrating the effects of various scaling policies.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "24 pages"
    },
    {
        "paper id": "2409.05113",
        "abstract url": "https://arxiv.org/abs/2409.05113",
        "title": "Nonlinear Cooperative Output Regulation with Input Delay Compensation",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the cooperative output regulation (COR) of nonlinear multi-agent systems (MASs) with long input delay based on periodic event-triggered mechanism. Compared with other mechanisms, periodic event-triggered control can automatically guarantee a Zeno-free behavior and avoid the continuous monitoring of triggered conditions. First, a new periodic event-triggered distributed observer, which is based on the fully asynchronous communication data, is proposed to estimate the leader information. Second, a new distributed predictor feedback control method is proposed for the considered nonlinear MASs with input delay. By coordinate transformation, the MASs are mapped into new coupled ODE-PDE target systems with some disturbance-like terms. Then, we show that the COR problem is solvable. At last, to further save the communication resource, a periodic event-triggered mechanism is considered in the sensor-to-controller transmission in every agent. A new periodic event-triggered filter is proposed to deal with the periodic event-triggered feedback data. The MASs with input delay are mapped into coupled ODE-PDE target systems with sampled data information. Then, Lyapunov-Krasovskii functions are constructed to demonstrate the exponential stability of the MASs. Simulations verify the validity of the proposed results.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Acceptted by IEEE Trans. Automatic Control"
    },
    {
        "paper id": "2409.05128",
        "abstract url": "https://arxiv.org/abs/2409.05128",
        "title": "From Struggle to Simplicity with a Usable and Secure API for Encryption in Java",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cryptography misuses are prevalent in the wild. Crypto APIs are hard to use for developers, and static analysis tools do not detect every misuse. We developed SafEncrypt, an API that streamlines encryption tasks for Java developers. It is built on top of the native Java Cryptography Architecture, and it shields developers from crypto complexities and erroneous low-level details. Experiments showed that SafEncrypt is suitable for developers with varying levels of experience.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": "ESEM 2024"
    },
    {
        "paper id": "2409.05132",
        "abstract url": "https://arxiv.org/abs/2409.05132",
        "title": "Large-scale road network partitioning: a deep learning method based on convolutional autoencoder model",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the development of urbanization, the scale of urban road network continues to expand, especially in some Asian countries. Short-term traffic state prediction is one of the bases of traffic management and control. Constrained by the space-time cost of computation, the short-term traffic state prediction of large-scale urban road network is difficult. One way to solve this problem is to partition the whole network into multiple sub-networks to predict traffic state separately. In this study, a deep learning method is proposed for road network partitioning. The method mainly includes three steps. First, the daily speed series for roads are encoded into the matrix. Second, a convolutional autoencoder (AE) is built to extract series features and compress data. Third, the spatial hierarchical clustering method with adjacency relationship is applied in the road network. The proposed method was verified by the road network of Shenzhen which contains more than 5000 links. The results show that AE-hierarchical clustering distinguishes the tidal traffic characteristics and reflects the process of congestion propagation. Furthermore, two indicators are designed to make a quantitative comparison with spectral clustering: intra homogeneity increases by about 9% on average while inter heterogeneity about 9.5%. Compared with past methods, the time cost also decreases. The results may suggest ways to improve the management and control of urban road network in other metropolitan cities. The proposed method is expected to be extended to other problems related to large-scale networks.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05153",
        "abstract url": "https://arxiv.org/abs/2409.05153",
        "title": "A Remote Control Painting System for Exterior Walls of High-Rise Buildings through Robotic System",
        "rating": "-10",
        "keywords": [],
        "abstract": "Exterior painting of high-rise buildings is a challenging task. In our country, as well as in other countries of the world, this task is accomplished manually, which is risky and life-threatening for the workers. Researchers and industry experts are trying to find an automatic and robotic solution for the exterior painting of high-rise building walls. In this paper, we propose a solution to this problem. We design and implement a prototype for automatically painting the building walls' exteriors. A spray mechanism was introduced in the prototype that can move in four different directions (up-down and left-right). All the movements are achieved by using microcontroller-operated servo motors. Further, these components create a scope to upgrade the proposed remote-controlled system to a robotic system in the future. In the presented system, all the operations are controlled remotely from a smartphone interface. Bluetooth technology is used for remote communications. It is expected that the suggested system will improve productivity with better workplace safety.",
        "subjects": [
            "cs.RO",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05155",
        "abstract url": "https://arxiv.org/abs/2409.05155",
        "title": "Difference Between Cyclic and Distributed Approach in Stochastic Optimization for Multi-agent System",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many stochastic optimization problems in multi-agent systems can be decomposed into smaller subproblems or reduced decision subspaces. The cyclic and distributed approaches are two widely used strategies for solving such problems. In this manuscript, we review four existing methods for addressing these problems and compare them based on their suitable problem frameworks and update rules.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05176",
        "abstract url": "https://arxiv.org/abs/2409.05176",
        "title": "Using Generative Artificial Intelligence Creatively in the Classroom: Examples and Lessons Learned",
        "rating": "-10",
        "keywords": [],
        "abstract": "Although generative artificial intelligence (AI) is not new, recent technological breakthroughs have transformed its capabilities across many domains. These changes necessitate new attention from educators and specialized training within the atmospheric sciences and related fields. Enabling students to use generative AI effectively, responsibly, and ethically is critically important for their academic and professional preparation. Educators can also use generative AI to create engaging classroom activities, such as active learning modules and games, but must be aware of potential pitfalls and biases. There are also ethical implications in using tools that lack transparency, as well as equity concerns for students who lack access to more sophisticated paid versions of generative AI tools. This article is written for students and educators alike, particularly those who want to learn more about generative AI in education, including use cases, ethical concerns, and a brief history of its emergence. Sample user prompts are also provided across numerous applications in education and the atmospheric and related sciences. While we don't have solutions for some broader ethical concerns surrounding the use of generative AI in education, our goal is to start a conversation that could galvanize the education community around shared goals and values.",
        "subjects": [
            "cs.HC",
            "physics.ao-ph"
        ],
        "comment": "This Work has been submitted to the Bulletin of the American Meteorological Society. Copyright in this Work may be transferred without further notice; 14 pages, 2 figures, 2 tables"
    },
    {
        "paper id": "2409.05189",
        "abstract url": "https://arxiv.org/abs/2409.05189",
        "title": "Energy Internet: A Standardization-Based Blueprint Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "The decarbonization of power and energy systems faces a bottleneck: The enormous number of user-side resources cannot be properly managed and operated by centralized system operators, who used to send dispatch instructions only to a few large power plants. To break through, we need not only new devices and algorithms, but structural reforms of our energy systems. Taking the Internet as a paradigm, a practicable design of the Energy Internet is presented based on the principle of standardization. A combination of stylized data and energy delivery, referred to as a Block of Energy Exchange (BEE), is designed as the media to be communicated, which is parsed by the Energy Internet Card. Each Energy Internet Card is assigned a unique MAC address, defining a participant of the Energy Internet, whose standardized profile will be automatically updated according to BEE transfers without the intervention of any centralized operator. The structure of Energy Internet and protocols thereof to support the transfer of BEE are presented. System operators will become Energy Internet Service Providers, who operate the energy system by flow control and dispatching centralized resources, which is decoupled from users' behaviors in the Energy Internet. Example shows that the Energy Internet can not only reduce carbon emissions via interactions between peers, but also promotes energy democracy and dwindles the gap in energy equity.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05196",
        "abstract url": "https://arxiv.org/abs/2409.05196",
        "title": "AI-Driven Robotic Crystal Explorer for Rapid Polymorph Identification",
        "rating": "-10",
        "keywords": [],
        "abstract": "Crystallisation is an important phenomenon which facilitates the purification as well as structural and bulk phase material characterisation using crystallographic methods. However, different conditions can lead to a vast set of different crystal structure polymorphs and these often exhibit different physical properties, allowing materials to be tailored to specific purposes. This means the high dimensionality that can result from variations in the conditions which affect crystallisation, and the interaction between them, means that exhaustive exploration is difficult, time-consuming, and costly to explore. Herein we present a robotic crystal search engine for the automated and efficient high-throughput approach to the exploration of crystallisation conditions. The system comprises a closed-loop computer crystal-vision system that uses machine learning to both identify crystals and classify their identity in a multiplexed robotic platform. By exploring the formation of a well-known polymorph, we were able to show how a robotic system could be used to efficiently search experimental space as a function of relative polymorph amount and efficiently create a high dimensionality phase diagram with minimal experimental budget and without expensive analytical techniques such as crystallography. In this way, we identify the set of polymorphs possible within a set of experimental conditions, as well as the optimal values of these conditions to grow each polymorph.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "18 pages, 6 figures, 20 references"
    },
    {
        "paper id": "2409.05203",
        "abstract url": "https://arxiv.org/abs/2409.05203",
        "title": "CARDinality: Interactive Card-shaped Robots with Locomotion and Haptics using Vibration",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces a novel approach to interactive robots by leveraging the form-factor of cards to create thin robots equipped with vibrational capabilities for locomotion and haptic feedback. The system is composed of flat-shaped robots with on-device sensing and wireless control, which offer lightweight portability and scalability. This research introduces a hardware prototype. Applications include augmented card playing, educational tools, and assistive technology, which showcase CARDinality's versatility in tangible interaction.",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": "Accepted for ACM UIST 2024"
    },
    {
        "paper id": "2409.05205",
        "abstract url": "https://arxiv.org/abs/2409.05205",
        "title": "Efficient Homomorphically Encrypted Convolutional Neural Network Without Rotation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Privacy-preserving neural network (NN) inference can be achieved by utilizing homomorphic encryption (HE), which allows computations to be directly carried out over ciphertexts. Popular HE schemes are built over large polynomial rings. To allow simultaneous multiplications in the convolutional (Conv) and fully-connected (FC) layers, multiple input data are mapped to coefficients in the same polynomial, so are the weights of NNs. However, ciphertext rotations are necessary to compute the sums of products and/or incorporate the outputs of different channels into the same polynomials. Ciphertext rotations have much higher complexity than ciphertext multiplications and contribute to the majority of the latency of HE-evaluated Conv and FC layers. This paper proposes a novel reformulated server-client joint computation procedure and a new filter coefficient packing scheme to eliminate ciphertext rotations without affecting the security of the HE scheme. Our proposed scheme also leads to substantial reductions on the number of coefficient multiplications needed and the communication cost between the server and client. For various plain-20 classifiers over the CIFAR-10/100 datasets, our design reduces the running time of the Conv and FC layers by 15.5% and the communication cost between client and server by more than 50%, compared to the best prior design.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "12 pages, 7 figures, journal paper"
    },
    {
        "paper id": "2409.05264",
        "abstract url": "https://arxiv.org/abs/2409.05264",
        "title": "How We Lost The Internet",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we reexamine an assumption that underpinned the development of the Internet architecture, namely that a stateless and loosely synchronous point-to-point datagram delivery service would be sufficient to meet the needs of all network applications, including those which deliver content and services to a mass audience at global scale. Such applications are inherently asynchronous and point-to-multipoint in nature. We explain how the inability of distributed systems based on this stateless datagram service to provide adequate and affordable support for them within the public (I.e., universally shared and available) network led to the development of private overlay infrastructures, specifically Content Delivery Networks and distributed Cloud data centers. We argue that the burdens imposed by reliance on these private overlays may have been an obstacle to achieving the Open Data Networking goals of early Internet advocates. The contradiction between those initial goals and the exploitative commercial imperatives of hypergiant overlay operators is offered as a possibly important reason for the negative impact of their most profitable applications (e.g., social media) and monetization strategies (e.g., targeted advertisement). We propose that one important step in resolving this contradiction may be to reconsider the adequacy Internet's stateless datagram service model.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2306.01101"
    },
    {
        "paper id": "2409.05273",
        "abstract url": "https://arxiv.org/abs/2409.05273",
        "title": "A new method to derive the calculation formula of antenna total isotropic sensitivity",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the OTA test of the antenna spatial performance of communication equipment,the total radiated power TRP and the total isotropic sensitivity TIS are two important characterization parameters,representing the overall transmission and reception performance of the antenna in space.In order to gain a deeper understanding of the physical meaning of these two parameters and the calculation method of TIS,this paper proposes a new method for deriving the TIS calculation formula.This method uses the reciprocity principle of the transmitting antenna and the receiving antenna.By comparing the transmitting process,two corresponding receiving antenna parameters are newly defined in the receiving process analysis.Combining the relationship between the antenna pattern and the receiving intensity,the relationship formula between TIS and equivalent isotropic sensitivity EIS is obtained after a simple deduction.This formula is consistent with the calculation formula given in the reference,but the derivation method in the reference is to use the ideal omnidirectional antenna as a reference,calculate the received power at the receiver input,and combine factors such as the actual antenna gain to derive the TIS calculation formula;the method proposed in this paper is to first derive the expression of the receiving directivity coefficient by definition,introduce the receiving strength parameter,calculate the full-space receiving power at the antenna,and derive the TIS calculation formula.In comparison,the derivation process in this paper calculates the received power from the input end of the receiving antenna,so there is no need to consider the efficiency of the antenna itself.The received power calculation starts directly from the receiving intensity.The entire derivation process is intuitive and easy to understand,avoiding complex concepts and formulas.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "3 pages, 2 figures"
    },
    {
        "paper id": "2409.05278",
        "abstract url": "https://arxiv.org/abs/2409.05278",
        "title": "Path-Parameterised RRTs for Underactuated Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a sample-based motion planning algorithm specialised to a class of underactuated systems using path parameterisation. The structure this class presents under a path parameterisation enables the trivial computation of dynamic feasibility along a path. Using this, a specialised state-based steering mechanism within an RRT motion planning algorithm is developed, enabling the generation of both geometric paths and their time parameterisations without introducing excessive computational overhead. We find with two systems that our algorithm computes feasible trajectories with higher rates of success and lower mean computation times compared to existing approaches.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, accepted for publication at the 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)"
    },
    {
        "paper id": "2409.05281",
        "abstract url": "https://arxiv.org/abs/2409.05281",
        "title": "Exact equality of the MSEs for two types of nonlinear adaptive systems: Saturation and dead-zone types",
        "rating": "-10",
        "keywords": [],
        "abstract": "Adaptive signal processing systems, commonly utilized in applications such as active noise control and acoustic echo cancellation, often encompass nonlinearities due to hardware components such as loudspeakers, microphones, and amplifiers. Examining the impact of these nonlinearities on the overall performance of adaptive systems is critically important. In this study, we employ a statistical-mechanical method to investigate the behaviors of adaptive systems, each containing an unknown system with a nonlinearity in its output. We specifically address two types of nonlinearity: saturation and dead-zone types. We analyze both the dynamic and steady-state behaviors of these systems under the effect of such nonlinearities. Our findings indicate that when the saturation value is equal to the dead-zone width, the mean square errors (MSEs) in steady states are identical for both nonlinearity types. Furthermore, we derive a self-consistent equation to obtain the saturation value and dead-zone width that maximize the steady-state MSE. We theoretically clarify that these values depend on neither the step size nor the variance of background noise.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.05293",
        "abstract url": "https://arxiv.org/abs/2409.05293",
        "title": "Distributed Robust Continuous-Time Optimization Algorithms for Time-Varying Constrained Cost",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a distributed continuous-time optimization framework aimed at overcoming the challenges posed by time-varying cost functions and constraints in multi-agent systems, particularly those subject to disturbances. By incorporating tools such as log-barrier penalty functions to address inequality constraints, an integral sliding mode control for disturbance mitigation is proposed. The algorithm ensures asymptotic tracking of the optimal solution, achieving a tracking error of zero. The convergence of the introduced algorithms is demonstrated through Lyapunov analysis and nonsmooth techniques. Furthermore, the framework's effectiveness is validated through numerical simulations considering two scenarios for the communication networks.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "7 pages, 3 figures, Accepted for publication in the 12th International Conference on Control, Mechatronics and Automation (ICCMA 2024)"
    }
]