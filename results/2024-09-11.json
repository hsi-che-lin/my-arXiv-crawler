[
    {
        "paper id": "2409.07078",
        "abstract url": "https://arxiv.org/abs/2409.07078",
        "title": "Multimodal Emotion Recognition with Vision-language Prompting and Modality Dropout",
        "rating": "2",
        "keywords": [
            [
                "Vision-language"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we present our solution for the Second Multimodal Emotion Recognition Challenge Track 1(MER2024-SEMI). To enhance the accuracy and generalization performance of emotion recognition, we propose several methods for Multimodal Emotion Recognition. Firstly, we introduce EmoVCLIP, a model fine-tuned based on CLIP using vision-language prompt learning, designed for video-based emotion recognition tasks. By leveraging prompt learning on CLIP, EmoVCLIP improves the performance of pre-trained CLIP on emotional videos. Additionally, to address the issue of modality dependence in multimodal fusion, we employ modality dropout for robust information fusion. Furthermore, to aid Baichuan in better extracting emotional information, we suggest using GPT-4 as the prompt for Baichuan. Lastly, we utilize a self-training strategy to leverage unlabeled videos. In this process, we use unlabeled videos with high-confidence pseudo-labels generated by our model and incorporate them into the training set. Experimental results demonstrate that our model ranks 1st in the MER2024-SEMI track, achieving an accuracy of 90.15% on the test set.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07541",
        "abstract url": "https://arxiv.org/abs/2409.07541",
        "title": "ENACT: Entropy-based Clustering of Attention Input for Improving the Computational Performance of Object Detection Transformers",
        "rating": "2",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Transformers demonstrate competitive performance in terms of precision on the problem of vision-based object detection. However, they require considerable computational resources due to the quadratic size of the attention weights. In this work, we propose to cluster the transformer input on the basis of its entropy. The reason for this is that the self-information of each pixel (whose sum is the entropy), is likely to be similar among pixels corresponding to the same objects. Clustering reduces the size of data given as input to the transformer and therefore reduces training time and GPU memory usage, while at the same time preserves meaningful information to be passed through the remaining parts of the network. The proposed process is organized in a module called ENACT, that can be plugged-in any transformer architecture that consists of a multi-head self-attention computation in its encoder. We ran extensive experiments using the COCO object detection dataset, and three detection transformers. The obtained results demonstrate that in all tested cases, there is consistent reduction in the required computational resources, while the precision of the detection task is only slightly reduced. The code of the ENACT module will become available at https://github.com/GSavathrakis/ENACT",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07577",
        "abstract url": "https://arxiv.org/abs/2409.07577",
        "title": "Self-Masking Networks for Unsupervised Adaptation",
        "rating": "2",
        "keywords": [
            [
                "efficient fine-tuning"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "With the advent of billion-parameter foundation models, efficient fine-tuning has become increasingly important for the adaptation of models to downstream tasks. However, especially in computer vision, it can be hard to achieve good performance when access to quality labeled data is lacking. In this work, we propose a method adapting pretrained generalist models in a self-supervised manner by learning binary masks. These self-supervised masking networks (SMNs) are up to 79x more efficient to store and significantly improve performance on label-efficient downstream tasks. We validate the usefulness of learning binary masks as a fine-tuning method on 8 datasets and 3 model architectures, and we demonstrate the effectiveness of SMNs in 3 label-efficient settings.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Oral at GCPR'24, code at https://github.com/alvitawa/UnsupervisedMasking"
    },
    {
        "paper id": "2409.07703",
        "abstract url": "https://arxiv.org/abs/2409.07703",
        "title": "DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI software engineers. Recently, many data science benchmarks have been proposed to investigate their performance in the data science domain. However, existing data science benchmarks still fall short when compared to real-world data science applications due to their simplified settings. To bridge this gap, we introduce DSBench, a comprehensive benchmark designed to evaluate data science agents with realistic tasks. This benchmark includes 466 data analysis tasks and 74 data modeling tasks, sourced from Eloquence and Kaggle competitions. DSBench offers a realistic setting by encompassing long contexts, multimodal task backgrounds, reasoning with large data files and multi-table structures, and performing end-to-end data modeling tasks. Our evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle with most tasks, with the best agent solving only 34.12% of data analysis tasks and achieving a 34.74% Relative Performance Gap (RPG). These findings underscore the need for further advancements in developing more practical, intelligent, and autonomous data science agents.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07127",
        "abstract url": "https://arxiv.org/abs/2409.07127",
        "title": "DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound Training",
        "rating": "1.5",
        "keywords": [
            [
                "Training Efficient"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Efficient communication can enhance the overall performance of collaborative multi-agent reinforcement learning. A common approach is to share observations through full communication, leading to significant communication overhead. Existing work attempts to perceive the global state by conducting teammate model based on local information. However, they ignore that the uncertainty generated by prediction may lead to difficult training. To address this problem, we propose a Demand-aware Customized Multi-Agent Communication (DCMAC) protocol, which use an upper bound training to obtain the ideal policy. By utilizing the demand parsing module, agent can interpret the gain of sending local message on teammate, and generate customized messages via compute the correlation between demands and local observation using cross-attention mechanism. Moreover, our method can adapt to the communication resources of agents and accelerate the training progress by appropriating the ideal policy which is trained with joint observation. Experimental results reveal that DCMAC significantly outperforms the baseline algorithms in both unconstrained and communication constrained scenarios.",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07379",
        "abstract url": "https://arxiv.org/abs/2409.07379",
        "title": "FIRAL: An Active Learning Algorithm for Multinomial Logistic Regression",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We investigate theory and algorithms for pool-based active learning for multiclass classification using multinomial logistic regression. Using finite sample analysis, we prove that the Fisher Information Ratio (FIR) lower and upper bounds the excess risk. Based on our theoretical analysis, we propose an active learning algorithm that employs regret minimization to minimize the FIR. To verify our derived excess risk bounds, we conduct experiments on synthetic datasets. Furthermore, we compare FIRAL with five other methods and found that our scheme outperforms them: it consistently produces the smallest classification error in the multiclass logistic regression setting, as demonstrated through experiments on MNIST, CIFAR-10, and 50-class ImageNet.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)"
    },
    {
        "paper id": "2409.07713",
        "abstract url": "https://arxiv.org/abs/2409.07713",
        "title": "Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Generative AI models, such as the GPT and Llama series, have significant potential to assist laypeople in answering legal questions. However, little prior work focuses on the data sourcing, inference, and evaluation of these models in the context of laypersons. To this end, we propose a human-centric legal NLP pipeline, covering data sourcing, inference, and evaluation. We introduce and release a dataset, LegalQA, with real and specific legal questions spanning from employment law to criminal law, corresponding answers written by legal experts, and citations for each answer. We develop an automatic evaluation protocol for this dataset, then show that retrieval-augmented generation from only 850 citations in the train set can match or outperform internet-wide retrieval, despite containing 9 orders of magnitude less data. Finally, we propose future directions for open-sourced efforts, which fall behind closed-sourced models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted into GenLaw '24 (ICML 2024 workshop)"
    },
    {
        "paper id": "2409.07714",
        "abstract url": "https://arxiv.org/abs/2409.07714",
        "title": "CollaMamba: Efficient Collaborative Perception with Cross-Agent Spatial-Temporal State Space Model",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "By sharing complementary perceptual information, multi-agent collaborative perception fosters a deeper understanding of the environment. Recent studies on collaborative perception mostly utilize CNNs or Transformers to learn feature representation and fusion in the spatial dimension, which struggle to handle long-range spatial-temporal features under limited computing and communication resources. Holistically modeling the dependencies over extensive spatial areas and extended temporal frames is crucial to enhancing feature quality. To this end, we propose a resource efficient cross-agent spatial-temporal collaborative state space model (SSM), named CollaMamba. Initially, we construct a foundational backbone network based on spatial SSM. This backbone adeptly captures positional causal dependencies from both single-agent and cross-agent views, yielding compact and comprehensive intermediate features while maintaining linear complexity. Furthermore, we devise a history-aware feature boosting module based on temporal SSM, extracting contextual cues from extended historical frames to refine vague features while preserving low overhead. Extensive experiments across several datasets demonstrate that CollaMamba outperforms state-of-the-art methods, achieving higher model accuracy while reducing computational and communication overhead by up to 71.9% and 1/64, respectively. This work pioneers the exploration of the Mamba's potential in collaborative perception. The source code will be made available.",
        "subjects": [
            "cs.CV",
            "cs.MA"
        ],
        "comment": "Submitted to AAAI 2025"
    },
    {
        "paper id": "2409.07041",
        "abstract url": "https://arxiv.org/abs/2409.07041",
        "title": "SoftShadow: Leveraging Penumbra-Aware Soft Masks for Shadow Removal",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in deep learning have yielded promising results for the image shadow removal task. However, most existing methods rely on binary pre-generated shadow masks. The binary nature of such masks could potentially lead to artifacts near the boundary between shadow and non-shadow areas. In view of this, inspired by the physical model of shadow formation, we introduce novel soft shadow masks specifically designed for shadow removal. To achieve such soft masks, we propose a \\textit{SoftShadow} framework by leveraging the prior knowledge of pretrained SAM and integrating physical constraints. Specifically, we jointly tune the SAM and the subsequent shadow removal network using penumbra formation constraint loss and shadow removal loss. This framework enables accurate predictions of penumbra (partially shaded regions) and umbra (fully shaded regions) areas while simultaneously facilitating end-to-end shadow removal. Through extensive experiments on popular datasets, we found that our SoftShadow framework, which generates soft masks, can better restore boundary artifacts, achieve state-of-the-art performance, and demonstrate superior generalizability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07045",
        "abstract url": "https://arxiv.org/abs/2409.07045",
        "title": "Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "With the availability of various instruction datasets, a pivotal challenge is how to effectively select and integrate these instructions to fine-tune large language models (LLMs). Previous research mainly focuses on selecting individual high-quality instructions. However, these works overlooked the joint interactions and dependencies between different categories of instructions, leading to suboptimal selection strategies. Moreover, the nature of these interaction patterns remains largely unexplored, let alone optimize the instruction set with regard to them. To fill these gaps, in this paper, we: (1) systemically investigate interaction and dependency patterns between different categories of instructions, (2) manage to optimize the instruction set concerning the interaction patterns using a linear programming-based method, and optimize the learning schema of SFT using an instruction dependency taxonomy guided curriculum learning. Experimental results across different LLMs demonstrate improved performance over strong baselines on widely adopted benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07054",
        "abstract url": "https://arxiv.org/abs/2409.07054",
        "title": "Native vs Non-Native Language Prompting: A Comparative Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown remarkable abilities in different fields, including standard Natural Language Processing (NLP) tasks. To elicit knowledge from LLMs, prompts play a key role, consisting of natural language instructions. Most open and closed source LLMs are trained on available labeled and unlabeled resources--digital content such as text, images, audio, and videos. Hence, these models have better knowledge for high-resourced languages but struggle with low-resourced languages. Since prompts play a crucial role in understanding their capabilities, the language used for prompts remains an important research question. Although there has been significant research in this area, it is still limited, and less has been explored for medium to low-resourced languages. In this study, we investigate different prompting strategies (native vs. non-native) on 11 different NLP tasks associated with 12 different Arabic datasets (9.7K data points). In total, we conducted 197 experiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our findings suggest that, on average, the non-native prompt performs the best, followed by mixed and native prompts.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Foundation Models, Large Language Models, Arabic NLP, LLMs, Native, Contextual Understanding, Arabic LLM"
    },
    {
        "paper id": "2409.07055",
        "abstract url": "https://arxiv.org/abs/2409.07055",
        "title": "Legal Fact Prediction: Task Definition and Dataset Construction",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Legal facts refer to the facts that can be proven by acknowledged evidence in a trial. They form the basis for the determination of court judgments. This paper introduces a novel NLP task: legal fact prediction, which aims to predict the legal fact based on a list of evidence. The predicted facts can instruct the parties and their lawyers involved in a trial to strengthen their submissions and optimize their strategies during the trial. Moreover, since real legal facts are difficult to obtain before the final judgment, the predicted facts also serve as an important basis for legal judgment prediction. We construct a benchmark dataset consisting of evidence lists and ground-truth legal facts for real civil loan cases, LFPLoan. Our experiments on this dataset show that this task is non-trivial and requires further considerable research efforts.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07067",
        "abstract url": "https://arxiv.org/abs/2409.07067",
        "title": "Edge Modeling Activation Free Fourier Network for Spacecraft Image Denoising",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Spacecraft image denoising is a crucial basic technology closely related to aerospace research. However, the existing deep learning-based image denoising methods lack deep consideration of the characteristics of spacecraft image. To address the aforementioned shortcomings, we analyses spacecraft noise image and identifies two main characteristics. One is that there are a large number of low-light images in the obtained spacecraft noise image dataset. Another is there are a lot of repetitive periodic features in spacecraft image. According to the above mentioned characteristics, we propose a Edge modeling Activation Free Fourier Network (EAFFN), which is an efficient spacecraft image denoising method including Edge Modeling Block (EMB) and Activation Free Fourier Block (AFFB). We present EMB to effectively model edge and extract structural information and better identify the spacecraft components from dark regions in spacecraft noise image. We present AFFB and utilize an improved fast fourier block to extract repetitive periodic features and long-range information in noisy spacecraft image. In addition, Simple Gate is designed in our AFFB to reduce the computational complexity. Extensive experimental results demonstrate our EAFFN performs competitively to the state-of-the-art on spacecraft noise image datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07072",
        "abstract url": "https://arxiv.org/abs/2409.07072",
        "title": "Latent Space Interpretation for Stylistic Analysis and Explainable Authorship Attribution",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent state-of-the-art authorship attribution methods learn authorship representations of texts in a latent, non-interpretable space, hindering their usability in real-world applications. Our work proposes a novel approach to interpreting these learned embeddings by identifying representative points in the latent space and utilizing LLMs to generate informative natural language descriptions of the writing style of each point. We evaluate the alignment of our interpretable space with the latent one and find that it achieves the best prediction agreement compared to other baselines. Additionally, we conduct a human evaluation to assess the quality of these style descriptions, validating their utility as explanations for the latent space. Finally, we investigate whether human performance on the challenging AA task improves when aided by our system's explanations, finding an average improvement of around +20% in accuracy.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 8 figures, under review"
    },
    {
        "paper id": "2409.07085",
        "abstract url": "https://arxiv.org/abs/2409.07085",
        "title": "Understanding Knowledge Drift in LLMs through Misinformation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have revolutionized numerous applications, making them an integral part of our digital ecosystem. However, their reliability becomes critical, especially when these models are exposed to misinformation. We primarily analyze the susceptibility of state-of-the-art LLMs to factual inaccuracies when they encounter false information in a QnA scenario, an issue that can lead to a phenomenon we refer to as *knowledge drift*, which significantly undermines the trustworthiness of these models. We evaluate the factuality and the uncertainty of the models' responses relying on Entropy, Perplexity, and Token Probability metrics. Our experiments reveal that an LLM's uncertainty can increase up to 56.6% when the question is answered incorrectly due to the exposure to false information. At the same time, repeated exposure to the same false information can decrease the models uncertainty again (-52.8% w.r.t. the answers on the untainted prompts), potentially manipulating the underlying model's beliefs and introducing a drift from its original knowledge. These findings provide insights into LLMs' robustness and vulnerability to adversarial inputs, paving the way for developing more reliable LLM applications across various domains. The code is available at https://github.com/afastowski/knowledge_drift.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "13 pages, 3 figures. Accepted at DELTA workshop at KDD 2024"
    },
    {
        "paper id": "2409.07098",
        "abstract url": "https://arxiv.org/abs/2409.07098",
        "title": "Redundancy-Aware Camera Selection for Indoor Scene Neural Rendering",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Novel view synthesis of indoor scenes can be achieved by capturing a monocular video sequence of the environment. However, redundant information caused by artificial movements in the input video data reduces the efficiency of scene modeling. In this work, we tackle this challenge from the perspective of camera selection. We begin by constructing a similarity matrix that incorporates both the spatial diversity of the cameras and the semantic variation of the images. Based on this matrix, we use the Intra-List Diversity (ILD) metric to assess camera redundancy, formulating the camera selection task as an optimization problem. Then we apply a diversity-based sampling algorithm to optimize the camera selection. We also develop a new dataset, IndoorTraj, which includes long and complex camera movements captured by humans in virtual indoor environments, closely mimicking real-world scenarios. Experimental results demonstrate that our strategy outperforms other approaches under time and memory constraints. Remarkably, our method achieves performance comparable to models trained on the full dataset, while using only an average of 15% of the frames and 75% of the allotted time.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07123",
        "abstract url": "https://arxiv.org/abs/2409.07123",
        "title": "Cross-Refine: Improving Natural Language Explanation Generation by Learning in Tandem",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Natural language explanations (NLEs) are vital for elucidating the reasoning behind large language model (LLM) decisions. Many techniques have been developed to generate NLEs using LLMs. However, like humans, LLMs might not always produce optimal NLEs on first attempt. Inspired by human learning processes, we introduce Cross-Refine, which employs role modeling by deploying two LLMs as generator and critic, respectively. The generator outputs a first NLE and then refines this initial explanation using feedback and suggestions provided by the critic. Cross-Refine does not require any supervised training data or additional training. We validate Cross-Refine across three NLP tasks using three state-of-the-art open-source LLMs through automatic and human evaluation. We select Self-Refine (Madaan et al., 2023) as the baseline, which only utilizes self-feedback to refine the explanations. Our findings from automatic evaluation and a user study indicate that Cross-Refine outperforms Self-Refine. Meanwhile, Cross-Refine can perform effectively with less powerful LLMs, whereas Self-Refine only yields strong results with ChatGPT. Additionally, we conduct an ablation study to assess the importance of feedback and suggestions. Both of them play an important role in refining explanations. We further evaluate Cross-Refine on a bilingual dataset in English and German.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "17 pages; under review"
    },
    {
        "paper id": "2409.07136",
        "abstract url": "https://arxiv.org/abs/2409.07136",
        "title": "Leveraging Unstructured Text Data for Federated Instruction Tuning of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Federated instruction tuning enables multiple clients to collaboratively fine-tune a shared large language model (LLM) that can follow humans' instructions without directly sharing raw data. However, existing literature impractically requires that all the clients readily hold instruction-tuning data (i.e., structured instruction-response pairs), which necessitates massive human annotations since clients' data is usually unstructured text instead. Addressing this, we propose a novel and flexible framework FedIT-U2S, which can automatically transform unstructured corpus into structured data for federated instruction tuning. FedIT-U2S consists two key steps: (1) few-shot instruction-tuning data generation, where each unstructured data piece together with several examples is combined to prompt an LLM in generating an instruction-response pair. To further enhance the flexibility, a retrieval-based example selection technique is proposed, where the examples are automatically selected based on the relatedness between the client's data piece and example pool, bypassing the need of determining examples in advance. (2) A typical federated instruction tuning process based on the generated data. Overall, FedIT-U2S can be applied to diverse scenarios as long as the client holds valuable text corpus, broadening the application scope of federated instruction tuning. We conduct a series of experiments on three domains (medicine, knowledge, and math), showing that our proposed FedIT-U2S can consistently and significantly brings improvement over the base LLM.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "11 pages, work in progress"
    },
    {
        "paper id": "2409.07146",
        "abstract url": "https://arxiv.org/abs/2409.07146",
        "title": "Gated Slot Attention for Efficient Linear-Time Sequence Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Linear attention Transformers and their gated variants, celebrated for enabling parallel training and efficient recurrent inference, still fall short in recall-intensive tasks compared to traditional Transformers and demand significant resources for training from scratch. This paper introduces Gated Slot Attention (GSA), which enhances Attention with Bounded-memory-Control (ABC) by incorporating a gating mechanism inspired by Gated Linear Attention (GLA). Essentially, GSA comprises a two-layer GLA linked via softmax, utilizing context-aware memory reading and adaptive forgetting to improve memory capacity while maintaining compact recurrent state size. This design greatly enhances both training and inference efficiency through GLA's hardware-efficient training algorithm and reduced state size. Additionally, retaining the softmax operation is particularly beneficial in \"finetuning pretrained Transformers to RNNs\" (T2R) settings, reducing the need for extensive training from scratch. Extensive experiments confirm GSA's superior performance in scenarios requiring in-context recall and in T2R settings.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2409.07162",
        "abstract url": "https://arxiv.org/abs/2409.07162",
        "title": "A Fine-grained Sentiment Analysis of App Reviews using Large Language Models: An Evaluation Study",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Analyzing user reviews for sentiment towards app features can provide valuable insights into users' perceptions of app functionality and their evolving needs. Given the volume of user reviews received daily, an automated mechanism to generate feature-level sentiment summaries of user reviews is needed. Recent advances in Large Language Models (LLMs) such as ChatGPT have shown impressive performance on several new tasks without updating the model's parameters i.e. using zero or a few labeled examples. Despite these advancements, LLMs' capabilities to perform feature-specific sentiment analysis of user reviews remain unexplored. This study compares the performance of state-of-the-art LLMs, including GPT-4, ChatGPT, and LLama-2-chat variants, for extracting app features and associated sentiments under 0-shot, 1-shot, and 5-shot scenarios. Results indicate the best-performing GPT-4 model outperforms rule-based approaches by 23.6% in f1-score with zero-shot feature extraction; 5-shot further improving it by 6%. GPT-4 achieves a 74% f1-score for predicting positive sentiment towards correctly predicted app features, with 5-shot enhancing it by 7%. Our study suggests that LLM models are promising for generating feature-specific sentiment summaries of user reviews.",
        "subjects": [
            "cs.CL",
            "cs.SE"
        ],
        "comment": "The summary of the project is available at https://ahmed.jp/project_page/App_LLMs_2024/app_llms.html"
    },
    {
        "paper id": "2409.07165",
        "abstract url": "https://arxiv.org/abs/2409.07165",
        "title": "Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Automatic speech recognition (ASR) with an encoder equipped with self-attention, whether streaming or non-streaming, takes quadratic time in the length of the speech utterance. This slows down training and decoding, increase their cost, and limit the deployment of the ASR in constrained devices. SummaryMixing is a promising linear-time complexity alternative to self-attention for non-streaming speech recognition that, for the first time, preserves or outperforms the accuracy of self-attention models. Unfortunately, the original definition of SummaryMixing is not suited to streaming speech recognition. Hence, this work extends SummaryMixing to a Conformer Transducer that works in both a streaming and an offline mode. It shows that this new linear-time complexity speech encoder outperforms self-attention in both scenarios while requiring less compute and memory during training and decoding.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07210",
        "abstract url": "https://arxiv.org/abs/2409.07210",
        "title": "Enhancing CTC-Based Visual Speech Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper presents LiteVSR2, an enhanced version of our previously introduced efficient approach to Visual Speech Recognition (VSR). Building upon our knowledge distillation framework from a pre-trained Automatic Speech Recognition (ASR) model, we introduce two key improvements: a stabilized video preprocessing technique and feature normalization in the distillation process. These improvements yield substantial performance gains on the LRS2 and LRS3 benchmarks, positioning LiteVSR2 as the current best CTC-based VSR model without increasing the volume of training data or computational resources utilized. Furthermore, we explore the scalability of our approach by examining performance metrics across varying model complexities and training data volumes. LiteVSR2 maintains the efficiency of its predecessor while significantly enhancing accuracy, thereby demonstrating the potential for resource-efficient advancements in VSR technology.",
        "subjects": [
            "cs.CV",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07239",
        "abstract url": "https://arxiv.org/abs/2409.07239",
        "title": "PiTe: Pixel-Temporal Alignment for Large Video-Language Model",
        "rating": "1",
        "keywords": [
            [
                "Visual-Language"
            ],
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fueled by the Large Language Models (LLMs) wave, Large Visual-Language Models (LVLMs) have emerged as a pivotal advancement, bridging the gap between image and text. However, video making it challenging for LVLMs to perform adequately due to the complexity of the relationship between language and spatial-temporal data structure. Recent Large Video-Language Models (LVidLMs) align feature of static visual data like image into latent space of language feature, by general multi-modal tasks to leverage abilities of LLMs sufficiently. In this paper, we explore fine-grained alignment approach via object trajectory for different modalities across both spatial and temporal dimensions simultaneously. Thus, we propose a novel LVidLM by trajectory-guided Pixel-Temporal Alignment, dubbed PiTe, that exhibits promising applicable model property. To achieve fine-grained video-language alignment, we curate a multi-modal pre-training dataset PiTe-143k, the dataset provision of moving trajectories in pixel level for all individual objects, that appear and mention in the video and caption both, by our automatic annotation pipeline. Meanwhile, PiTe demonstrates astounding capabilities on myriad video-related multi-modal tasks through beat the state-of-the-art methods by a large margin.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07246",
        "abstract url": "https://arxiv.org/abs/2409.07246",
        "title": "Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In the past decade, social media platforms have been used for information dissemination and consumption. While a major portion of the content is posted to promote citizen journalism and public awareness, some content is posted to mislead users. Among different content types such as text, images, and videos, memes (text overlaid on images) are particularly prevalent and can serve as powerful vehicles for propaganda, hate, and humor. In the current literature, there have been efforts to individually detect such content in memes. However, the study of their intersection is very limited. In this study, we explore the intersection between propaganda and hate in memes using a multi-agent LLM-based approach. We extend the propagandistic meme dataset with coarse and fine-grained hate labels. Our finding suggests that there is an association between propaganda and hate in memes. We provide detailed experimental results that can serve as a baseline for future studies. We will make the experimental resources publicly available to the community.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "propaganda, hate-speech, disinformation, misinformation, fake news, LLMs, GPT-4, multimodality, multimodal LLMs"
    },
    {
        "paper id": "2409.07257",
        "abstract url": "https://arxiv.org/abs/2409.07257",
        "title": "TopoMap++: A faster and more space efficient technique to compute projections with topological guarantees",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "High-dimensional data, characterized by many features, can be difficult to visualize effectively. Dimensionality reduction techniques, such as PCA, UMAP, and t-SNE, address this challenge by projecting the data into a lower-dimensional space while preserving important relationships. TopoMap is another technique that excels at preserving the underlying structure of the data, leading to interpretable visualizations. In particular, TopoMap maps the high-dimensional data into a visual space, guaranteeing that the 0-dimensional persistence diagram of the Rips filtration of the visual space matches the one from the high-dimensional data. However, the original TopoMap algorithm can be slow and its layout can be too sparse for large and complex datasets. In this paper, we propose three improvements to TopoMap: 1) a more space-efficient layout, 2) a significantly faster implementation, and 3) a novel TreeMap-based representation that makes use of the topological hierarchy to aid the exploration of the projections. These advancements make TopoMap, now referred to as TopoMap++, a more powerful tool for visualizing high-dimensional data which we demonstrate through different use case scenarios.",
        "subjects": [
            "cs.GR",
            "cs.CG",
            "cs.CV",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "This is the author's version of the article that has been accepted for publication in IEEE Transactions on Visualization and Computer Graphics (TVCG)"
    },
    {
        "paper id": "2409.07259",
        "abstract url": "https://arxiv.org/abs/2409.07259",
        "title": "ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this study, we introduce ManaTTS, the most extensive publicly accessible single-speaker Persian corpus, and a comprehensive framework for collecting transcribed speech datasets for the Persian language. ManaTTS, released under the open CC-0 license, comprises approximately 86 hours of audio with a sampling rate of 44.1 kHz. Alongside ManaTTS, we also generated the VirgoolInformal dataset to evaluate Persian speech recognition models used for forced alignment, extending over 5 hours of audio. The datasets are supported by a fully transparent, MIT-licensed pipeline, a testament to innovation in the field. It includes unique tools for sentence tokenization, bounded audio segmentation, and a novel forced alignment method. This alignment technique is specifically designed for low-resource languages, addressing a crucial need in the field. With this dataset, we trained a Tacotron2-based TTS model, achieving a Mean Opinion Score (MOS) of 3.76, which is remarkably close to the MOS of 3.86 for the utterances generated by the same vocoder and natural spectrogram, and the MOS of 4.01 for the natural waveform, demonstrating the exceptional quality and effectiveness of the corpus.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "33 pages, 12 figures"
    },
    {
        "paper id": "2409.07267",
        "abstract url": "https://arxiv.org/abs/2409.07267",
        "title": "MiniDrive: More Efficient Vision-Language Models with Multi-Level 2D Features as Text Tokens for Autonomous Driving",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-language models (VLMs) serve as general-purpose end-to-end models in autonomous driving, performing subtasks such as prediction, planning, and perception through question-and-answer interactions. However, most existing methods rely on computationally expensive visual encoders and large language models (LLMs), making them difficult to deploy in real-world scenarios and real-time applications. Meanwhile, most existing VLMs lack the ability to process multiple images, making it difficult to adapt to multi-camera perception in autonomous driving. To address these issues, we propose a novel framework called MiniDrive, which incorporates our proposed Feature Engineering Mixture of Experts (FE-MoE) module and Dynamic Instruction Adapter (DI-Adapter). The FE-MoE effectively maps 2D features into visual token embeddings before being input into the language model. The DI-Adapter enables the visual token embeddings to dynamically change with the instruction text embeddings, resolving the issue of static visual token embeddings for the same image in previous approaches. Compared to previous works, MiniDrive achieves state-of-the-art performance in terms of parameter size, floating point operations, and response efficiency, with the smallest version containing only 83M parameters.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07275",
        "abstract url": "https://arxiv.org/abs/2409.07275",
        "title": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The performance of the standard Online Robust Principal Component Analysis (OR-PCA) technique depends on the optimum tuning of the explicit regularizers and this tuning is dataset sensitive. We aim to remove the dependency on these tuning parameters by using implicit regularization. We propose to use the implicit regularization effect of various modified gradient descents to make OR-PCA tuning free. Our method incorporates three different versions of modified gradient descent that separately but naturally encourage sparsity and low-rank structures in the data. The proposed method performs comparable or better than the tuned OR-PCA for both simulated and real-world datasets. Tuning-free ORPCA makes it more scalable for large datasets since we do not require dataset-dependent parameter tuning.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07284",
        "abstract url": "https://arxiv.org/abs/2409.07284",
        "title": "TLD-READY: Traffic Light Detection -- Relevance Estimation and Deployment Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Effective traffic light detection is a critical component of the perception stack in autonomous vehicles. This work introduces a novel deep-learning detection system while addressing the challenges of previous work. Utilizing a comprehensive dataset amalgamation, including the Bosch Small Traffic Lights Dataset, LISA, the DriveU Traffic Light Dataset, and a proprietary dataset from Karlsruhe, we ensure a robust evaluation across varied scenarios. Furthermore, we propose a relevance estimation system that innovatively uses directional arrow markings on the road, eliminating the need for prior map creation. On the DriveU dataset, this approach results in 96% accuracy in relevance estimation. Finally, a real-world evaluation is performed to evaluate the deployment and generalizing abilities of these models. For reproducibility and to facilitate further research, we provide the model weights and code: https://github.com/KASTEL-MobilityLab/traffic-light-detection.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07286",
        "abstract url": "https://arxiv.org/abs/2409.07286",
        "title": "Using Generative Agents to Create Tip Sheets for Investigative Data Reporting",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces a system using generative AI agents to create tip sheets for investigative data reporting. Our system employs three specialized agents--an analyst, a reporter, and an editor--to collaboratively generate and refine tips from datasets. We validate this approach using real-world investigative stories, demonstrating that our agent-based system generally generates more newsworthy and accurate insights compared to a baseline model without agents, although some variability was noted between different stories. Our findings highlight the potential of generative AI to provide leads for investigative data reporting.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Short paper to be presented at Computation + Journalism 2024"
    },
    {
        "paper id": "2409.07292",
        "abstract url": "https://arxiv.org/abs/2409.07292",
        "title": "A Unified Contrastive Loss for Self-Training",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Self-training methods have proven to be effective in exploiting abundant unlabeled data in semi-supervised learning, particularly when labeled data is scarce. While many of these approaches rely on a cross-entropy loss function (CE), recent advances have shown that the supervised contrastive loss function (SupCon) can be more effective. Additionally, unsupervised contrastive learning approaches have also been shown to capture high quality data representations in the unsupervised setting. To benefit from these advantages in a semi-supervised setting, we propose a general framework to enhance self-training methods, which replaces all instances of CE losses with a unique contrastive loss. By using class prototypes, which are a set of class-wise trainable parameters, we recover the probability distributions of the CE setting and show a theoretical equivalence with it. Our framework, when applied to popular self-training methods, results in significant performance improvements across three different datasets with a limited number of labeled data. Additionally, we demonstrate further improvements in convergence speed, transfer ability, and hyperparameter stability. The code is available at \\url{https://github.com/AurelienGauffre/semisupcon/}.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07295",
        "abstract url": "https://arxiv.org/abs/2409.07295",
        "title": "PaveSAM Segment Anything for Pavement Distress",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automated pavement monitoring using computer vision can analyze pavement conditions more efficiently and accurately than manual methods. Accurate segmentation is essential for quantifying the severity and extent of pavement defects and consequently, the overall condition index used for prioritizing rehabilitation and maintenance activities. Deep learning-based segmentation models are however, often supervised and require pixel-level annotations, which can be costly and time-consuming. While the recent evolution of zero-shot segmentation models can generate pixel-wise labels for unseen classes without any training data, they struggle with irregularities of cracks and textured pavement backgrounds. This research proposes a zero-shot segmentation model, PaveSAM, that can segment pavement distresses using bounding box prompts. By retraining SAM's mask decoder with just 180 images, pavement distress segmentation is revolutionized, enabling efficient distress segmentation using bounding box prompts, a capability not found in current segmentation models. This not only drastically reduces labeling efforts and costs but also showcases our model's high performance with minimal input, establishing the pioneering use of SAM in pavement distress segmentation. Furthermore, researchers can use existing open-source pavement distress images annotated with bounding boxes to create segmentation masks, which increases the availability and diversity of segmentation pavement distress datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07331",
        "abstract url": "https://arxiv.org/abs/2409.07331",
        "title": "Learning to Compress Contexts for Efficient Knowledge-based Visual Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated great zero-shot performance on visual question answering (VQA). However, when it comes to knowledge-based VQA (KB-VQA), MLLMs may lack human commonsense or specialized domain knowledge to answer such questions and require obtaining necessary information from external knowledge sources. Previous works like Retrival-Augmented VQA-v2 (RAVQA-v2) focus on utilizing as much input information, such as image-based textual descriptions and retrieved knowledge, as possible to improve performance, but they all overlook the issue that with the number of input tokens increasing, inference efficiency significantly decreases, which contradicts the demands of practical applications. To address this issue, we propose Retrieval-Augmented MLLM with Compressed Contexts (RACC). RACC learns to compress and aggregate retrieved contexts, from which it generates a compact modulation in the form of Key-Value (KV) cache. This modulation is then used to adapt the downstream frozen MLLM, thereby achieving effective and efficient inference. RACC achieves a state-of-the-art (SOTA) performance of 62.9% on OK-VQA. Moreover, it significantly reduces inference latency by 22.0%-59.7% compared to the prominent RAVQA-v2. Abundant experiments show RACC's broad applicability. It is compatible with various off-the-shelf MLLMs and can also handle different knowledge sources including textual and multimodal documents.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07335",
        "abstract url": "https://arxiv.org/abs/2409.07335",
        "title": "Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid advancement of artificial intelligence systems has brought the challenge of AI alignment to the forefront of research, particularly in complex decision-making and task execution. As these systems surpass human-level performance in sophisticated problems, ensuring their alignment with human values, intentions, and ethical guidelines becomes crucial. Building on previous work in explanation generation for human-agent alignment, we address the more complex dynamics of multi-agent systems and human-AI teams. This paper introduces a novel approach to model alignment through weak-to-strong generalization in the context of language models. We present a framework where a strong model facilitates the improvement of a weaker model, bridging the gap between explanation generation and model alignment. Our method, formalized as a facilitation function, allows for the transfer of capabilities from advanced models to less capable ones without direct access to extensive training data. Our results suggest that this facilitation-based approach not only enhances model performance but also provides insights into the nature of model alignment and the potential for scalable oversight of AI systems.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07353",
        "abstract url": "https://arxiv.org/abs/2409.07353",
        "title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which bypass safety protocols and cause the model to generate misleading or harmful responses. This vulnerability stems from both the inherent susceptibilities of LLMs and the expanded attack surface introduced by the visual modality. We propose Sim-CLIP+, a novel defense mechanism that adversarially fine-tunes the CLIP vision encoder by leveraging a Siamese architecture. This approach maximizes cosine similarity between perturbed and clean samples, facilitating resilience against adversarial manipulations. Sim-CLIP+ offers a plug-and-play solution, allowing seamless integration into existing LVLM architectures as a robust vision encoder. Unlike previous defenses, our method requires no structural modifications to the LVLM and incurs minimal computational overhead. Sim-CLIP+ demonstrates effectiveness against both gradient-based adversarial attacks and various jailbreak techniques. We evaluate Sim-CLIP+ against three distinct jailbreak attack strategies and perform clean evaluations using standard downstream datasets, including COCO for image captioning and OKVQA for visual question answering. Extensive experiments demonstrate that Sim-CLIP+ maintains high clean accuracy while substantially improving robustness against both gradient-based adversarial attacks and jailbreak techniques. Our code and robust vision encoders are available at https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07355",
        "abstract url": "https://arxiv.org/abs/2409.07355",
        "title": "Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study introduces \\textbf{InteractEval}, a framework that integrates human expertise and Large Language Models (LLMs) using the Think-Aloud (TA) method to generate attributes for checklist-based text evaluation. By combining human flexibility and reasoning with LLM consistency, InteractEval outperforms traditional non-LLM-based and LLM-based baselines across four distinct dimensions, consisting of Coherence, Fluency, Consistency, and Relevance. The experiment also investigates the effectiveness of the TA method, showing that it promotes divergent thinking in both humans and LLMs, leading to the generation of a wider range of relevant attributes and enhance text evaluation performance. Comparative analysis reveals that humans excel at identifying attributes related to internal quality (Coherence and Fluency), but LLMs perform better at those attributes related to external alignment (Consistency and Relevance). Consequently, leveraging both humans and LLMs together produces the best evaluation outcomes. In other words, this study emphasizes the necessity of effectively combining humans and LLMs in an automated checklist-based text evaluation framework. The code is available at \\textbf{\\url{https://github.com/BBeeChu/InteractEval.git}}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07372",
        "abstract url": "https://arxiv.org/abs/2409.07372",
        "title": "Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The vast pre-existing slides serve as rich and important materials to carry lecture knowledge. However, effectively leveraging lecture slides to serve students is difficult due to the multi-modal nature of slide content and the heterogeneous teaching actions. We study the problem of discovering effective designs that convert a slide into an interactive lecture. We develop Slide2Lecture, a tuning-free and knowledge-regulated intelligent tutoring system that can (1) effectively convert an input lecture slide into a structured teaching agenda consisting of a set of heterogeneous teaching actions; (2) create and manage an interactive lecture that generates responsive interactions catering to student learning demands while regulating the interactions to follow teaching actions. Slide2Lecture contains a complete pipeline for learners to obtain an interactive classroom experience to learn the slide. For teachers and developers, Slide2Lecture enables customization to cater to personalized demands. The evaluation rated by annotators and students shows that Slide2Lecture is effective in outperforming the remaining implementation. Slide2Lecture's online deployment has made more than 200K interaction with students in the 3K lecture sessions. We open source Slide2Lecture's implementation in https://anonymous.4open.science/r/slide2lecture-4210/.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07394",
        "abstract url": "https://arxiv.org/abs/2409.07394",
        "title": "AdaCAD: Adaptively Decoding to Balance Conflicts between Contextual and Parametric Knowledge",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge conflict arises from discrepancies between information in the context of a large language model (LLM) and the knowledge stored in its parameters. This can hurt performance when using standard decoding techniques, which tend to ignore the context. Existing test-time contrastive methods seek to address this by comparing the LLM's output distribution with and without the context and adjust the model according to the contrast between them. However, we find that these methods frequently misjudge the degree of conflict and struggle to handle instances that vary in their amount of conflict, with static methods over-adjusting when conflict is absent. We propose a fine-grained, instance-level approach called AdaCAD, which dynamically infers the weight of adjustment based on the degree of conflict, as measured by the Jensen-Shannon divergence between distributions representing contextual and parametric knowledge. Our experiments across four models on six diverse question-answering (QA) datasets and three summarization tasks demonstrate that our training-free adaptive method consistently outperforms other decoding methods on QA, with average accuracy gains of 14.21% (absolute) over a static contrastive baseline, and improves the factuality of summaries by 5.59 (AlignScore). Furthermore, our analysis shows that while decoding with contrastive baselines hurts performance when conflict is absent, AdaCAD mitigates these losses, making it more applicable to real-world datasets in which some examples have conflict and others do not.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "16 pages, Code: https://github.com/HanNight/AdaCAD"
    },
    {
        "paper id": "2409.07402",
        "abstract url": "https://arxiv.org/abs/2409.07402",
        "title": "What to align in multimodal contrastive learning?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Humans perceive the world through multisensory integration, blending the information of different modalities to adapt their behavior. Contrastive learning offers an appealing solution for multimodal self-supervised learning. Indeed, by considering each modality as a different view of the same entity, it learns to align features of different modalities in a shared representation space. However, this approach is intrinsically limited as it only learns shared or redundant information between modalities, while multimodal interactions can arise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal learning strategy that enables the communication between modalities in a single multimodal space. Instead of imposing cross- or intra- modality constraints, we propose to align multimodal representations by maximizing the mutual information between augmented versions of these multimodal features. Our theoretical analysis shows that shared, synergistic and unique terms of information naturally emerge from this formulation, allowing us to estimate multimodal interactions beyond redundancy. We test CoMM both in a controlled and in a series of real-world settings: in the former, we demonstrate that CoMM effectively captures redundant, unique and synergistic information between modalities. In the latter, CoMM learns complex multimodal interactions and achieves state-of-the-art results on the six multimodal benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2409.07414",
        "abstract url": "https://arxiv.org/abs/2409.07414",
        "title": "NVRC: Neural Video Representation Compression",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recent advances in implicit neural representation (INR)-based video coding have demonstrated its potential to compete with both conventional and other learning-based approaches. With INR methods, a neural network is trained to overfit a video sequence, with its parameters compressed to obtain a compact representation of the video content. However, although promising results have been achieved, the best INR-based methods are still out-performed by the latest standard codecs, such as VVC VTM, partially due to the simple model compression techniques employed. In this paper, rather than focusing on representation architectures as in many existing works, we propose a novel INR-based video compression framework, Neural Video Representation Compression (NVRC), targeting compression of the representation. Based on the novel entropy coding and quantization models proposed, NVRC, for the first time, is able to optimize an INR-based video codec in a fully end-to-end manner. To further minimize the additional bitrate overhead introduced by the entropy models, we have also proposed a new model compression framework for coding all the network, quantization and entropy model parameters hierarchically. Our experiments show that NVRC outperforms many conventional and learning-based benchmark codecs, with a 24% average coding gain over VVC VTM (Random Access) on the UVG dataset, measured in PSNR. As far as we are aware, this is the first time an INR-based video codec achieving such performance. The implementation of NVRC will be released at www.github.com.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07431",
        "abstract url": "https://arxiv.org/abs/2409.07431",
        "title": "Synthetic continued pretraining",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Pretraining on large-scale, unstructured internet text has enabled language models to acquire a significant amount of world knowledge. However, this knowledge acquisition is data-inefficient -- to learn a given fact, models must be trained on hundreds to thousands of diverse representations of it. This poses a challenge when adapting a pretrained model to a small corpus of domain-specific documents, where each fact may appear rarely or only once. We propose to bridge this gap with synthetic continued pretraining: using the small domain-specific corpus to synthesize a large corpus more amenable to learning, and then performing continued pretraining on the synthesized corpus. We instantiate this proposal with EntiGraph, a synthetic data augmentation algorithm that extracts salient entities from the source documents and then generates diverse text by drawing connections between the sampled entities. Synthetic continued pretraining using EntiGraph enables a language model to answer questions and follow generic instructions related to the source documents without access to them. If instead, the source documents are available at inference time, we show that the knowledge acquired through our approach compounds with retrieval-augmented generation. To better understand these results, we build a simple mathematical model of EntiGraph, and show how synthetic data augmentation can \"rearrange\" knowledge to enable more data-efficient learning.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07437",
        "abstract url": "https://arxiv.org/abs/2409.07437",
        "title": "A Suite for Acoustic Language Model Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech language models have recently demonstrated great potential as universal speech processing systems. Such models have the ability to model the rich acoustic information existing in audio signals, beyond spoken content, such as emotion, background noise, etc. Despite this, evaluation benchmarks which evaluate awareness to a wide range of acoustic aspects, are lacking. To help bridge this gap, we introduce SALMon, a novel evaluation suite encompassing background noise, emotion, speaker identity and room impulse response. The proposed benchmarks both evaluate the consistency of the inspected element and how much it matches the spoken text. We follow a modelling based approach, measuring whether a model gives correct samples higher scores than incorrect ones. This approach makes the benchmark fast to compute even for large models. We evaluated several speech language models on SALMon, thus highlighting the strengths and weaknesses of each evaluated method. Code and data are publicly available at https://pages.cs.huji.ac.il/adiyoss-lab/salmon/ .",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07440",
        "abstract url": "https://arxiv.org/abs/2409.07440",
        "title": "SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Given that Large Language Models (LLMs) have made significant progress in writing code, can they now be used to autonomously reproduce results from research repositories? Such a capability would be a boon to the research community, helping researchers validate, understand, and extend prior work. To advance towards this goal, we introduce SUPER, the first benchmark designed to evaluate the capability of LLMs in setting up and executing tasks from research repositories. SUPERaims to capture the realistic challenges faced by researchers working with Machine Learning (ML) and Natural Language Processing (NLP) research repositories. Our benchmark comprises three distinct problem sets: 45 end-to-end problems with annotated expert solutions, 152 sub problems derived from the expert set that focus on specific challenges (e.g., configuring a trainer), and 602 automatically generated problems for larger-scale development. We introduce various evaluation measures to assess both task success and progress, utilizing gold solutions when available or approximations otherwise. We show that state-of-the-art approaches struggle to solve these problems with the best model (GPT-4o) solving only 16.3% of the end-to-end set, and 46.1% of the scenarios. This illustrates the challenge of this task, and suggests that SUPER can serve as a valuable resource for the community to make and measure progress.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07446",
        "abstract url": "https://arxiv.org/abs/2409.07446",
        "title": "Adaptive Adapter Routing for Long-Tailed Class-Incremental Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In our ever-evolving world, new data exhibits a long-tailed distribution, such as e-commerce platform reviews. This necessitates continuous model learning imbalanced data without forgetting, addressing the challenge of long-tailed class-incremental learning (LTCIL). Existing methods often rely on retraining linear classifiers with former data, which is impractical in real-world settings. In this paper, we harness the potent representation capabilities of pre-trained models and introduce AdaPtive Adapter RouTing (APART) as an exemplar-free solution for LTCIL. To counteract forgetting, we train inserted adapters with frozen pre-trained weights for deeper adaptation and maintain a pool of adapters for selection during sequential model updates. Additionally, we present an auxiliary adapter pool designed for effective generalization, especially on minority classes. Adaptive instance routing across these pools captures crucial correlations, facilitating a comprehensive representation of all classes. Consequently, APART tackles the imbalance problem as well as catastrophic forgetting in a unified framework. Extensive benchmark experiments validate the effectiveness of APART. Code is available at: https://github.com/vita-qzh/APART",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted to Machine Learning Journal. Code is available at: https://github.com/vita-qzh/APART"
    },
    {
        "paper id": "2409.07588",
        "abstract url": "https://arxiv.org/abs/2409.07588",
        "title": "2D bidirectional gated recurrent unit convolutional Neural networks for end-to-end violence detection In videos",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Abnormal behavior detection, action recognition, fight and violence detection in videos is an area that has attracted a lot of interest in recent years. In this work, we propose an architecture that combines a Bidirectional Gated Recurrent Unit (BiGRU) and a 2D Convolutional Neural Network (CNN) to detect violence in video sequences. A CNN is used to extract spatial characteristics from each frame, while the BiGRU extracts temporal and local motion characteristics using CNN extracted features from multiple frames. The proposed end-to-end deep learning network is tested in three public datasets with varying scene complexities. The proposed network achieves accuracies up to 98%. The obtained results are promising and show the performance of the proposed end-to-end approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 6 figures, 2020 International Conference on Image Analysis and Recognition (ICIAR)"
    },
    {
        "paper id": "2409.07613",
        "abstract url": "https://arxiv.org/abs/2409.07613",
        "title": "Token Turing Machines are Efficient Vision Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We propose Vision Token Turing Machines (ViTTM), an efficient, low-latency, memory-augmented Vision Transformer (ViT). Our approach builds on Neural Turing Machines and Token Turing Machines, which were applied to NLP and sequential visual understanding tasks. ViTTMs are designed for non-sequential computer vision tasks such as image classification and segmentation. Our model creates two sets of tokens: process tokens and memory tokens; process tokens pass through encoder blocks and read-write from memory tokens at each encoder block in the network, allowing them to store and retrieve information from memory. By ensuring that there are fewer process tokens than memory tokens, we are able to reduce the inference time of the network while maintaining its accuracy. On ImageNet-1K, the state-of-the-art ViT-B has median latency of 529.5ms and 81.0% accuracy, while our ViTTM-B is 56% faster (234.1ms), with 2.4 times fewer FLOPs, with an accuracy of 82.9%. On ADE20K semantic segmentation, ViT-B achieves 45.65mIoU at 13.8 frame-per-second (FPS) whereas our ViTTM-B model acheives a 45.17 mIoU with 26.8 FPS (+94%).",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07615",
        "abstract url": "https://arxiv.org/abs/2409.07615",
        "title": "Zero-Shot Machine-Generated Text Detection Using Mixture of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The dissemination of Large Language Models (LLMs), trained at scale, and endowed with powerful text-generating abilities has vastly increased the threats posed by generative AI technologies by reducing the cost of producing harmful, toxic, faked or forged content. In response, various proposals have been made to automatically discriminate artificially generated from human-written texts, typically framing the problem as a classification problem. Most approaches evaluate an input document by a well-chosen detector LLM, assuming that low-perplexity scores reliably signal machine-made content. As using one single detector can induce brittleness of performance, we instead consider several and derive a new, theoretically grounded approach to combine their respective strengths. Our experiments, using a variety of generator LLMs, suggest that our method effectively increases the robustness of detection.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Preprint, work in progress"
    },
    {
        "paper id": "2409.07638",
        "abstract url": "https://arxiv.org/abs/2409.07638",
        "title": "Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper we explore evaluation of LLM capabilities. We present measurements of GPT-4 performance on several deterministic tasks; each task involves a basic calculation and takes as input parameter some element drawn from a large well-defined population (e.g., count elements in a list, multiply two k-digit numbers, etc). We examine several conditions per-task and perform enough trials so that statistically significant differences can be detected. This allows us to investigate the sensitivity of task-accuracy both to query phrasing and input parameter population. We find that seemingly trivial modifications in the task-prompt or input population can yield differences far larger than can be explained by sampling effects. For example, performance on a simple list-counting task varies with query-phrasing and list-length, but also with list composition (i.e., the thing-to-be-counted) and object frequency (e.g., success when an element accounts for $\\approx$ 50\\% of a list is different from when it accounts for $\\approx$ 70\\% etc). We conclude that efforts to quantify LLM capabilities easily succumb to the language-as-fixed-effect fallacy, where experimental observations are improperly generalized beyond what the data supports. A consequence appears to be that intuitions that have been formed based on interactions with humans form a very unreliable guide as to which input modifications should ``make no difference'' to LLM performance.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07641",
        "abstract url": "https://arxiv.org/abs/2409.07641",
        "title": "SimulBench: Evaluating Language Models with Creative Simulation Tasks",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We introduce SimulBench, a benchmark designed to evaluate large language models (LLMs) across a diverse collection of creative simulation scenarios, such as acting as a Linux terminal or playing text games with users. While these simulation tasks serve as effective measures of an LLM's general intelligence, they are seldom incorporated into existing benchmarks. A major challenge is to develop an evaluation framework for testing different LLMs fairly while preserving the multi-round interactive nature of simulation tasks between users and AI. To tackle this issue, we suggest using a fixed LLM as a user agent to engage with an LLM to collect dialogues first under different tasks. Then, challenging dialogue scripts are extracted for evaluating different target LLMs. To facilitate automatic assessment on \\DataName{}, GPT-4 is employed as the evaluator, tasked with reviewing the quality of the final response generated by the target LLMs given multi-turn dialogue scripts. Our comprehensive experiments indicate that these simulation tasks continue to pose a significant challenge with their unique natures and show the gap between proprietary models and the most advanced open LLMs. For example, GPT-4-turbo outperforms LLaMA-3-70b-Chat on 18.55\\% more cases.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Website: https://simulbench.github.io/"
    },
    {
        "paper id": "2409.07672",
        "abstract url": "https://arxiv.org/abs/2409.07672",
        "title": "An Unsupervised Dialogue Topic Segmentation Model Based on Utterance Rewriting",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Dialogue topic segmentation plays a crucial role in various types of dialogue modeling tasks. The state-of-the-art unsupervised DTS methods learn topic-aware discourse representations from conversation data through adjacent discourse matching and pseudo segmentation to further mine useful clues in unlabeled conversational relations. However, in multi-round dialogs, discourses often have co-references or omissions, leading to the fact that direct use of these discourses for representation learning may negatively affect the semantic similarity computation in the neighboring discourse matching task. In order to fully utilize the useful cues in conversational relations, this study proposes a novel unsupervised dialog topic segmentation method that combines the Utterance Rewriting (UR) technique with an unsupervised learning algorithm to efficiently utilize the useful cues in unlabeled dialogs by rewriting the dialogs in order to recover the co-referents and omitted words. Compared with existing unsupervised models, the proposed Discourse Rewriting Topic Segmentation Model (UR-DTS) significantly improves the accuracy of topic segmentation. The main finding is that the performance on DialSeg711 improves by about 6% in terms of absolute error score and WD, achieving 11.42% in terms of absolute error score and 12.97% in terms of WD. on Doc2Dial the absolute error score and WD improves by about 3% and 2%, respectively, resulting in SOTA reaching 35.17% in terms of absolute error score and 38.49% in terms of WD. This shows that the model is very effective in capturing the nuances of conversational topics, as well as the usefulness and challenges of utilizing unlabeled conversations.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "in Chinese language"
    },
    {
        "paper id": "2409.07684",
        "abstract url": "https://arxiv.org/abs/2409.07684",
        "title": "Modeling Information Narrative Detection and Evolution on Telegram during the Russia-Ukraine War",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SI"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Following the Russian Federation's full-scale invasion of Ukraine in February 2022, a multitude of information narratives emerged within both pro-Russian and pro-Ukrainian communities online. As the conflict progresses, so too do the information narratives, constantly adapting and influencing local and global community perceptions and attitudes. This dynamic nature of the evolving information environment (IE) underscores a critical need to fully discern how narratives evolve and affect online communities. Existing research, however, often fails to capture information narrative evolution, overlooking both the fluid nature of narratives and the internal mechanisms that drive their evolution. Recognizing this, we introduce a novel approach designed to both model narrative evolution and uncover the underlying mechanisms driving them. In this work we perform a comparative discourse analysis across communities on Telegram covering the initial three months following the invasion. First, we uncover substantial disparities in narratives and perceptions between pro-Russian and pro-Ukrainian communities. Then, we probe deeper into prevalent narratives of each group, identifying key themes and examining the underlying mechanisms fueling their evolution. Finally, we explore influences and factors that may shape the development and spread of narratives.",
        "subjects": [
            "cs.SI",
            "cs.AI"
        ],
        "comment": "12 pages, International AAAI Conference on Web and Social Media 2025"
    },
    {
        "paper id": "2409.07694",
        "abstract url": "https://arxiv.org/abs/2409.07694",
        "title": "Learn from Balance: Rectifying Knowledge Transfer for Long-Tailed Scenarios",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Knowledge Distillation (KD) transfers knowledge from a large pre-trained teacher network to a compact and efficient student network, making it suitable for deployment on resource-limited media terminals. However, traditional KD methods require balanced data to ensure robust training, which is often unavailable in practical applications. In such scenarios, a few head categories occupy a substantial proportion of examples. This imbalance biases the trained teacher network towards the head categories, resulting in severe performance degradation on the less represented tail categories for both the teacher and student networks. In this paper, we propose a novel framework called Knowledge Rectification Distillation (KRDistill) to address the imbalanced knowledge inherited in the teacher network through the incorporation of the balanced category priors. Furthermore, we rectify the biased predictions produced by the teacher network, particularly focusing on the tail categories. Consequently, the teacher network can provide balanced and accurate knowledge to train a reliable student network. Intensive experiments conducted on various long-tailed datasets demonstrate that our KRDistill can effectively train reliable student networks in realistic scenarios of data imbalance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07701",
        "abstract url": "https://arxiv.org/abs/2409.07701",
        "title": "TMFNet: Two-Stream Multi-Channels Fusion Networks for Color Image Operation Chain Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image operation chain detection techniques have gained increasing attention recently in the field of multimedia forensics. However, existing detection methods suffer from the generalization problem. Moreover, the channel correlation of color images that provides additional forensic evidence is often ignored. To solve these issues, in this article, we propose a novel two-stream multi-channels fusion networks for color image operation chain detection in which the spatial artifact stream and the noise residual stream are explored in a complementary manner. Specifically, we first propose a novel deep residual architecture without pooling in the spatial artifact stream for learning the global features representation of multi-channel correlation. Then, a set of filters is designed to aggregate the correlation information of multi-channels while capturing the low-level features in the noise residual stream. Subsequently, the high-level features are extracted by the deep residual model. Finally, features from the two streams are fed into a fusion module, to effectively learn richer discriminative representations of the operation chain. Extensive experiments show that the proposed method achieves state-of-the-art generalization ability while maintaining robustness to JPEG compression. The source code used in these experiments will be released at https://github.com/LeiTan-98/TMFNet.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "15 pages, 12 figures"
    },
    {
        "paper id": "2409.07704",
        "abstract url": "https://arxiv.org/abs/2409.07704",
        "title": "Super Monotonic Alignment Search",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "eess.AS"
            ]
        ],
        "abstract": "Monotonic alignment search (MAS), introduced by Glow-TTS, is one of the most popular algorithm in TTS to estimate unknown alignments between text and speech. Since this algorithm needs to search for the most probable alignment with dynamic programming by caching all paths, the time complexity of the algorithm is $O(T \\times S)$. The authors of Glow-TTS run this algorithm on CPU, and while they mentioned it is difficult to parallelize, we found that MAS can be parallelized in text-length dimension and CPU execution consumes an inordinate amount of time for inter-device copy. Therefore, we implemented a Triton kernel and PyTorch JIT script to accelerate MAS on GPU without inter-device copy. As a result, Super-MAS Triton kernel is up to 72 times faster in the extreme-length case. The code is available at \\url{https://github.com/supertone-inc/super-monotonic-align}.",
        "subjects": [
            "eess.AS",
            "cs.AI"
        ],
        "comment": "Technical Report"
    },
    {
        "paper id": "2409.07736",
        "abstract url": "https://arxiv.org/abs/2409.07736",
        "title": "Transfer Learning Applied to Computer Vision Problems: Survey on Current Progress, Limitations, and Opportunities",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The field of Computer Vision (CV) has faced challenges. Initially, it relied on handcrafted features and rule-based algorithms, resulting in limited accuracy. The introduction of machine learning (ML) has brought progress, particularly Transfer Learning (TL), which addresses various CV problems by reusing pre-trained models. TL requires less data and computing while delivering nearly equal accuracy, making it a prominent technique in the CV landscape. Our research focuses on TL development and how CV applications use it to solve real-world problems. We discuss recent developments, limitations, and opportunities.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "16 pages, 8 figures"
    },
    {
        "paper id": "2409.07737",
        "abstract url": "https://arxiv.org/abs/2409.07737",
        "title": "Ruri: Japanese General Text Embeddings",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We report the development of Ruri, a series of Japanese general text embedding models. While the development of general-purpose text embedding models in English and multilingual contexts has been active in recent years, model development in Japanese remains insufficient. The primary reasons for this are the lack of datasets and the absence of necessary expertise. In this report, we provide a detailed account of the development process of Ruri. Specifically, we discuss the training of embedding models using synthesized datasets generated by LLMs, the construction of the reranker for dataset filtering and knowledge distillation, and the performance evaluation of the resulting general-purpose text embedding models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07748",
        "abstract url": "https://arxiv.org/abs/2409.07748",
        "title": "Top-down Activity Representation Learning for Video Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Capturing complex hierarchical human activities, from atomic actions (e.g., picking up one present, moving to the sofa, unwrapping the present) to contextual events (e.g., celebrating Christmas) is crucial for achieving high-performance video question answering (VideoQA). Recent works have expanded multimodal models (e.g., CLIP, LLaVA) to process continuous video sequences, enhancing the model's temporal reasoning capabilities. However, these approaches often fail to capture contextual events that can be decomposed into multiple atomic actions non-continuously distributed over relatively long-term sequences. In this paper, to leverage the spatial visual context representation capability of the CLIP model for obtaining non-continuous visual representations in terms of contextual events in videos, we convert long-term video sequences into a spatial image domain and finetune the multimodal model LLaVA for the VideoQA task. Our approach achieves competitive performance on the STAR task, in particular, with a 78.4% accuracy score, exceeding the current state-of-the-art score by 2.8 points on the NExTQA task.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "presented at MIRU2024"
    },
    {
        "paper id": "2409.07014",
        "abstract url": "https://arxiv.org/abs/2409.07014",
        "title": "A Practical Theory of Generalization in Selectivity Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Query-driven machine learning models have emerged as a promising estimation technique for query selectivities. Yet, surprisingly little is known about the efficacy of these techniques from a theoretical perspective, as there exist substantial gaps between practical solutions and state-of-the-art (SOTA) theory based on the Probably Approximately Correct (PAC) learning framework. In this paper, we aim to bridge the gaps between theory and practice. First, we demonstrate that selectivity predictors induced by signed measures are learnable, which relaxes the reliance on probability measures in SOTA theory. More importantly, beyond the PAC learning framework (which only allows us to characterize how the model behaves when both training and test workloads are drawn from the same distribution), we establish, under mild assumptions, that selectivity predictors from this class exhibit favorable out-of-distribution (OOD) generalization error bounds. These theoretical advances provide us with a better understanding of both the in-distribution and OOD generalization capabilities of query-driven selectivity learning, and facilitate the design of two general strategies to improve OOD generalization for existing query-driven selectivity models. We empirically verify that our techniques help query-driven selectivity models generalize significantly better to OOD queries both in terms of prediction accuracy and query latency performance, while maintaining their superior in-distribution generalization performance.",
        "subjects": [
            "stat.ML",
            "cs.DB",
            "cs.LG"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.07071",
        "abstract url": "https://arxiv.org/abs/2409.07071",
        "title": "Addressing Pilot Contamination in Channel Estimation with Variational Autoencoders",
        "rating": "0.5",
        "keywords": [
            [
                "ICASSP"
            ]
        ],
        "abstract": "Pilot contamination (PC) is a well-known problem that affects massive multiple-input multiple-output (MIMO) systems. When frequency and pilots are reused between different cells, PC constitutes one of the main bottlenecks of the system's performance. In this paper, we propose a method based on the variational autoencoder (VAE), capable of reducing the impact of PC-related interference during channel estimation (CE). We obtain the first and second-order statistics of the conditionally Gaussian (CG) channels for both the user equipments (UEs) in a cell of interest and those in interfering cells, and we then use these moments to compute conditional linear minimum mean square error estimates. We show that the proposed estimator is capable of exploiting the interferers' additional statistical knowledge, outperforming other classical approaches. Moreover, we highlight how the achievable performance is tied to the chosen setup, making the setup selection crucial in the study of multi-cell CE.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures, submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.07102",
        "abstract url": "https://arxiv.org/abs/2409.07102",
        "title": "DisasterNeedFinder: Understanding the Information Needs in the 2024 Noto Earthquake (Comprehensive Explanation)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "We propose and demonstrate the DisasterNeedFinder framework in order to provide appropriate information support for the Noto Peninsula Earthquake. In the event of a large-scale disaster, it is essential to accurately capture the ever-changing information needs. However, it is difficult to obtain appropriate information from the chaotic situation on the ground. Therefore, as a data-driven approach, we aim to pick up precise information needs at the site by integrally analyzing the location information of disaster victims and search information. It is difficult to make a clear estimation of information needs by just analyzing search history information in disaster areas, due to the large amount of noise and the small number of users. Therefore, the idea of assuming that the magnitude of information needs is not the volume of searches, but the degree of abnormalities in searches, enables an appropriate understanding of the information needs of the disaster victims. DNF has been continuously clarifying the information needs of disaster areas since the disaster strike, and has been recognized as a new approach to support disaster areas by being featured in the major Japanese media on several occasions.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07114",
        "abstract url": "https://arxiv.org/abs/2409.07114",
        "title": "A Continual and Incremental Learning Approach for TinyML On-device Training Using Dataset Distillation and Model Size Adaption",
        "rating": "0.5",
        "keywords": [
            [
                "memory efficient"
            ],
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "A new algorithm for incremental learning in the context of Tiny Machine learning (TinyML) is presented, which is optimized for low-performance and energy efficient embedded devices. TinyML is an emerging field that deploys machine learning models on resource-constrained devices such as microcontrollers, enabling intelligent applications like voice recognition, anomaly detection, predictive maintenance, and sensor data processing in environments where traditional machine learning models are not feasible. The algorithm solve the challenge of catastrophic forgetting through the use of knowledge distillation to create a small, distilled dataset. The novelty of the method is that the size of the model can be adjusted dynamically, so that the complexity of the model can be adapted to the requirements of the task. This offers a solution for incremental learning in resource-constrained environments, where both model size and computational efficiency are critical factors. Results show that the proposed algorithm offers a promising approach for TinyML incremental learning on embedded devices. The algorithm was tested on five datasets including: CIFAR10, MNIST, CORE50, HAR, Speech Commands. The findings indicated that, despite using only 43% of Floating Point Operations (FLOPs) compared to a larger fixed model, the algorithm experienced a negligible accuracy loss of just 1%. In addition, the presented method is memory efficient. While state-of-the-art incremental learning is usually very memory intensive, the method requires only 1% of the original data set.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07119",
        "abstract url": "https://arxiv.org/abs/2409.07119",
        "title": "Credibility-Limited Revision for Epistemic Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We consider credibility-limited revision in the framework of belief change for epistemic spaces, permitting inconsistent belief sets and inconsistent beliefs. In this unrestricted setting, the class of credibility-limited revision operators does not include any AGM revision operators. We extend the class of credibility-limited revision operators in a way that all AGM revision operators are included while keeping the original spirit of credibility-limited revision. Extended credibility-limited revision operators are defined axiomatically. A semantic characterization of extended credibility-limited revision operators that employ total preorders on possible worlds is presented.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07135",
        "abstract url": "https://arxiv.org/abs/2409.07135",
        "title": "Unsupervised Novelty Detection Methods Benchmarking with Wavelet Decomposition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Novelty detection is a critical task in various engineering fields. Numerous approaches to novelty detection rely on supervised or semi-supervised learning, which requires labelled datasets for training. However, acquiring labelled data, when feasible, can be expensive and time-consuming. For these reasons, unsupervised learning is a powerful alternative that allows performing novelty detection without needing labelled samples. In this study, numerous unsupervised machine learning algorithms for novelty detection are compared, highlighting their strengths and weaknesses in the context of vibration sensing. The proposed framework uses a continuous metric, unlike most traditional methods that merely flag anomalous samples without quantifying the degree of anomaly. Moreover, a new dataset is gathered from an actuator vibrating at specific frequencies to benchmark the algorithms and evaluate the framework. Novel conditions are introduced by altering the input wave signal. Our findings offer valuable insights into the adaptability and robustness of unsupervised learning techniques for real-world novelty detection applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "To be published in the 8th International Conference on System Reliability and Safety. Sicily, Italy - November 20-22, 2024. 15 pages, 7 figures, 4 tables"
    },
    {
        "paper id": "2409.07137",
        "abstract url": "https://arxiv.org/abs/2409.07137",
        "title": "Combined Optimization of Dynamics and Assimilation with End-to-End Learning on Sparse Observations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fitting nonlinear dynamical models to sparse and noisy observations is fundamentally challenging. Identifying dynamics requires data assimilation (DA) to estimate system states, but DA requires an accurate dynamical model. To break this deadlock we present CODA, an end-to-end optimization scheme for jointly learning dynamics and DA directly from sparse and noisy observations. A neural network is trained to carry out data accurate, efficient and parallel-in-time DA, while free parameters of the dynamical system are simultaneously optimized. We carry out end-to-end learning directly on observation data, introducing a novel learning objective that combines unrolled auto-regressive dynamics with the data- and self-consistency terms of weak-constraint 4Dvar DA. By taking into account interactions between new and existing simulation components over multiple time steps, CODA can recover initial conditions, fit unknown dynamical parameters and learn neural network-based PDE terms to match both available observations and self-consistency constraints. In addition to facilitating end-to-end learning of dynamics and providing fast, amortized, non-sequential DA, CODA provides greater robustness to model misspecification than classical DA approaches.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph"
        ],
        "comment": "Submitted to Journal of Advances in Modeling Earth Systems (JAMES)"
    },
    {
        "paper id": "2409.07175",
        "abstract url": "https://arxiv.org/abs/2409.07175",
        "title": "Coupling Machine Learning Local Predictions with a Computational Fluid Dynamics Solver to Accelerate Transient Buoyant Plume Simulations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data-driven methods demonstrate considerable potential for accelerating the inherently expensive computational fluid dynamics (CFD) solvers. Nevertheless, pure machine-learning surrogate models face challenges in ensuring physical consistency and scaling up to address real-world problems. This study presents a versatile and scalable hybrid methodology, combining CFD and machine learning, to accelerate long-term incompressible fluid flow simulations without compromising accuracy. A neural network was trained offline using simulated data of various two-dimensional transient buoyant plume flows. The objective was to leverage local features to predict the temporal changes in the pressure field in comparable scenarios. Due to cell-level predictions, the methodology was successfully applied to diverse geometries without additional training. Pressure estimates were employed as initial values to accelerate the pressure-velocity coupling procedure. The results demonstrated an average improvement of 94% in the initial guess for solving the Poisson equation. The first pressure corrector acceleration reached a mean factor of 3, depending on the iterative solver employed. Our work reveals that machine learning estimates at the cell level can enhance the efficiency of CFD iterative linear solvers while maintaining accuracy. Although the scalability of the methodology to more complex cases has yet to be demonstrated, this study underscores the prospective value of domain-specific hybrid solvers for CFD.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG"
        ],
        "comment": "Twelfth International Conference on Computational Fluid Dynamics (ICCFD12), Kobe, Japan, July 14-19, 2024. 18 pages, 8 figures"
    },
    {
        "paper id": "2409.07192",
        "abstract url": "https://arxiv.org/abs/2409.07192",
        "title": "How Mature is Requirements Engineering for AI-based Systems? A Systematic Mapping Study on Practices, Challenges, and Future Research Directions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial intelligence (AI) permeates all fields of life, which resulted in new challenges in requirements engineering for artificial intelligence (RE4AI), e.g., the difficulty in specifying and validating requirements for AI or considering new quality requirements due to emerging ethical implications. It is currently unclear if existing RE methods are sufficient or if new ones are needed to address these challenges. Therefore, our goal is to provide a comprehensive overview of RE4AI to researchers and practitioners. What has been achieved so far, i.e., what practices are available, and what research gaps and challenges still need to be addressed? To achieve this, we conducted a systematic mapping study combining query string search and extensive snowballing. The extracted data was aggregated, and results were synthesized using thematic analysis. Our selection process led to the inclusion of 126 primary studies. Existing RE4AI research focuses mainly on requirements analysis and elicitation, with most practices applied in these areas. Furthermore, we identified requirements specification, explainability, and the gap between machine learning engineers and end-users as the most prevalent challenges, along with a few others. Additionally, we proposed seven potential research directions to address these challenges. Practitioners can use our results to identify and select suitable RE methods for working on their AI-based systems, while researchers can build on the identified gaps and research directions to push the field forward.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Accepted in Requirements Engineering Journal, 2024"
    },
    {
        "paper id": "2409.07194",
        "abstract url": "https://arxiv.org/abs/2409.07194",
        "title": "Cyber Deception: State of the art, Trends and Open challenges",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The growing interest in cybersecurity has significantly increased articles designing and implementing various Cyber Deception (CYDEC) mechanisms. This trend reflects the urgent need for new strategies to address cyber threats effectively. Since its emergence, CYDEC has established itself as an innovative defense against attackers, thanks to its proactive and reactive capabilities, finding applications in numerous real-life scenarios. Despite the considerable work devoted to CYDEC, the literature still presents significant gaps. In particular, there has not been (i) a comprehensive analysis of the main components characterizing CYDEC, (ii) a generic classification covering all types of solutions, nor (iii) a survey of the current state of the literature in various contexts. This article aims to fill these gaps through a detailed review of the main features that comprise CYDEC, developing a comprehensive classification taxonomy. In addition, the different frameworks used to generate CYDEC are reviewed, presenting a more comprehensive one. Existing solutions in the literature using CYDEC, both without Artificial Intelligence (AI) and with AI, are studied and compared. Finally, the most salient trends of the current state of the art are discussed, offering a list of pending challenges for future research.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.GT"
        ],
        "comment": "38 pages"
    },
    {
        "paper id": "2409.07215",
        "abstract url": "https://arxiv.org/abs/2409.07215",
        "title": "Is merging worth it? Securely evaluating the information gain for causal dataset acquisition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Merging datasets across institutions is a lengthy and costly procedure, especially when it involves private information. Data hosts may therefore want to prospectively gauge which datasets are most beneficial to merge with, without revealing sensitive information. For causal estimation this is particularly challenging as the value of a merge will depend not only on the reduction in epistemic uncertainty but also the improvement in overlap. To address this challenge, we introduce the first cryptographically secure information-theoretic approach for quantifying the value of a merge in the context of heterogeneous treatment effect estimation. We do this by evaluating the Expected Information Gain (EIG) and utilising multi-party computation to ensure it can be securely computed without revealing any raw data. As we demonstrate, this can be used with differential privacy (DP) to ensure privacy requirements whilst preserving more accurate computation than naive DP alone. To the best of our knowledge, this work presents the first privacy-preserving method for dataset acquisition tailored to causal estimation. We demonstrate the effectiveness and reliability of our method on a range of simulated and realistic benchmarks. The code is available anonymously.",
        "subjects": [
            "stat.ML",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07269",
        "abstract url": "https://arxiv.org/abs/2409.07269",
        "title": "Realistic and Efficient Face Swapping: A Unified Approach with Diffusion Models",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion",
                "inpainting"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Despite promising progress in face swapping task, realistic swapped images remain elusive, often marred by artifacts, particularly in scenarios involving high pose variation, color differences, and occlusion. To address these issues, we propose a novel approach that better harnesses diffusion models for face-swapping by making following core contributions. (a) We propose to re-frame the face-swapping task as a self-supervised, train-time inpainting problem, enhancing the identity transfer while blending with the target image. (b) We introduce a multi-step Denoising Diffusion Implicit Model (DDIM) sampling during training, reinforcing identity and perceptual similarities. (c) Third, we introduce CLIP feature disentanglement to extract pose, expression, and lighting information from the target image, improving fidelity. (d) Further, we introduce a mask shuffling technique during inpainting training, which allows us to create a so-called universal model for swapping, with an additional feature of head swapping. Ours can swap hair and even accessories, beyond traditional face swapping. Unlike prior works reliant on multiple off-the-shelf models, ours is a relatively unified approach and so it is resilient to errors in other off-the-shelf models. Extensive experiments on FFHQ and CelebA datasets validate the efficacy and robustness of our approach, showcasing high-fidelity, realistic face-swapping with minimal inference time. Our code is available at https://github.com/Sanoojan/REFace.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted as a conference paper at WACV 2025"
    },
    {
        "paper id": "2409.07307",
        "abstract url": "https://arxiv.org/abs/2409.07307",
        "title": "Data Augmentation via Latent Diffusion for Saliency Prediction",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Saliency prediction models are constrained by the limited diversity and quantity of labeled data. Standard data augmentation techniques such as rotating and cropping alter scene composition, affecting saliency. We propose a novel data augmentation method for deep saliency prediction that edits natural images while preserving the complexity and variability of real-world scenes. Since saliency depends on high-level and low-level features, our approach involves learning both by incorporating photometric and semantic attributes such as color, contrast, brightness, and class. To that end, we introduce a saliency-guided cross-attention mechanism that enables targeted edits on the photometric properties, thereby enhancing saliency within specific image regions. Experimental results show that our data augmentation method consistently improves the performance of various saliency models. Moreover, leveraging the augmentation features for saliency prediction yields superior performance on publicly available saliency benchmarks. Our predictions align closely with human visual attention patterns in the edited images, as validated by a user study.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, published in ECCV 2024"
    },
    {
        "paper id": "2409.07313",
        "abstract url": "https://arxiv.org/abs/2409.07313",
        "title": "Regulatory Requirements Engineering in Large Enterprises: An Interview Study on the European Accessibility Act",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Context: Regulations, such as the European Accessibility Act (EAA), impact the engineering of software products and services. Managing that impact while providing meaningful inputs to development teams is one of the emerging requirements engineering (RE) challenges. Problem: Enterprises conduct Regulatory Impact Analysis (RIA) to consider the effects of regulations on software products offered and formulate requirements at an enterprise level. Despite its practical relevance, we are unaware of any studies on this large-scale regulatory RE process. Methodology: We conducted an exploratory interview study of RIA in three large enterprises. We focused on how they conduct RIA, emphasizing cross-functional interactions, and using the EAA as an example. Results: RIA, as a regulatory RE process, is conducted to address the needs of executive management and central functions. It involves coordination between different functions and levels of enterprise hierarchy. Enterprises use artifacts to support interpretation and communication of the results of RIA. Challenges to RIA are mainly related to the execution of such coordination and managing the knowledge involved. Conclusion: RIA in large enterprises demands close coordination of multiple stakeholders and roles. Applying interpretation and compliance artifacts is one approach to support such coordination. However, there are no established practices for creating and managing such artifacts.",
        "subjects": [
            "cs.SE",
            "cs.CY"
        ],
        "comment": "Accepted to PROFES 2024"
    },
    {
        "paper id": "2409.07325",
        "abstract url": "https://arxiv.org/abs/2409.07325",
        "title": "Statistically Valid Information Bottleneck via Multiple Hypothesis Testing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The information bottleneck (IB) problem is a widely studied framework in machine learning for extracting compressed features that are informative for downstream tasks. However, current approaches to solving the IB problem rely on a heuristic tuning of hyperparameters, offering no guarantees that the learned features satisfy information-theoretic constraints. In this work, we introduce a statistically valid solution to this problem, referred to as IB via multiple hypothesis testing (IB-MHT), which ensures that the learned features meet the IB constraints with high probability, regardless of the size of the available dataset. The proposed methodology builds on Pareto testing and learn-then-test (LTT), and it wraps around existing IB solvers to provide statistical guarantees on the IB constraints. We demonstrate the performance of IB-MHT on classical and deterministic IB formulations, validating the effectiveness of IB-MHT in outperforming conventional methods in terms of statistical robustness and reliability.",
        "subjects": [
            "cs.IT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07340",
        "abstract url": "https://arxiv.org/abs/2409.07340",
        "title": "A Framework for Predicting the Impact of Game Balance Changes through Meta Discovery",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "A metagame is a collection of knowledge that goes beyond the rules of a game. In competitive, team-based games like Pok\u00e9mon or League of Legends, it refers to the set of current dominant characters and/or strategies within the player base. Developer changes to the balance of the game can have drastic and unforeseen consequences on these sets of meta characters. A framework for predicting the impact of balance changes could aid developers in making more informed balance decisions. In this paper we present such a Meta Discovery framework, leveraging Reinforcement Learning for automated testing of balance changes. Our results demonstrate the ability to predict the outcome of balance changes in Pok\u00e9mon Showdown, a collection of competitive Pok\u00e9mon tiers, with high accuracy.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "11 pages, 1 figure, IEEE Transactions on Games"
    },
    {
        "paper id": "2409.07341",
        "abstract url": "https://arxiv.org/abs/2409.07341",
        "title": "Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Interactive artificial intelligence in the motion control field is an interesting topic, especially when universal knowledge is adaptive to multiple tasks and universal environments. Despite there being increasing efforts in the field of Reinforcement Learning (RL) with the aid of transformers, most of them might be limited by the offline training pipeline, which prohibits exploration and generalization abilities. To address this limitation, we propose the framework of Online Decision MetaMorphFormer (ODM) which aims to achieve self-awareness, environment recognition, and action planning through a unified model architecture. Motivated by cognitive and behavioral psychology, an ODM agent is able to learn from others, recognize the world, and practice itself based on its own experience. ODM can also be applied to any arbitrary agent with a multi-joint body, located in different environments, and trained with different types of tasks using large-scale pre-trained datasets. Through the use of pre-trained datasets, ODM can quickly warm up and learn the necessary knowledge to perform the desired task, while the target environment continues to reinforce the universal policy. Extensive online experiments as well as few-shot and zero-shot environmental tests are used to verify ODM's performance and generalization ability. The results of our study contribute to the study of general artificial intelligence in embodied and cognitive fields. Code, results, and video examples can be found on the website \\url{https://rlodm.github.io/odm/}.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2409.07362",
        "abstract url": "https://arxiv.org/abs/2409.07362",
        "title": "GitSEED: A Git-backed Automated Assessment Tool for Software Engineering and Programming Education",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Due to the substantial number of enrollments in programming courses, a key challenge is delivering personalized feedback to students. The nature of this feedback varies significantly, contingent on the subject and the chosen evaluation method. However, tailoring current Automated Assessment Tools (AATs) to integrate other program analysis tools is not straightforward. Moreover, AATs usually support only specific programming languages, providing feedback exclusively through dedicated websites based on test suites. This paper introduces GitSEED, a language-agnostic automated assessment tool designed for Programming Education and Software Engineering (SE) and backed by GitLab. The students interact with GitSEED through GitLab. Using GitSEED, students in Computer Science (CS) and SE can master the fundamentals of git while receiving personalized feedback on their programming assignments and projects. Furthermore, faculty members can easily tailor GitSEED's pipeline by integrating various code evaluation tools (e.g., memory leak detection, fault localization, program repair, etc.) to offer personalized feedback that aligns with the needs of each CS/SE course. Our experiments assess GitSEED's efficacy via comprehensive user evaluation, examining the impact of feedback mechanisms and features on student learning outcomes. Findings reveal positive correlations between GitSEED usage and student engagement.",
        "subjects": [
            "cs.SE",
            "cs.CY"
        ],
        "comment": "7 pages, 2 figures. Accepted at SIGCSE Virtual 2024"
    },
    {
        "paper id": "2409.07387",
        "abstract url": "https://arxiv.org/abs/2409.07387",
        "title": "A Contrastive Symmetric Forward-Forward Algorithm (SFFA) for Continual Learning Tasks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The so-called Forward-Forward Algorithm (FFA) has recently gained momentum as an alternative to the conventional back-propagation algorithm for neural network learning, yielding competitive performance across various modeling tasks. By replacing the backward pass of gradient back-propagation with two contrastive forward passes, the FFA avoids several shortcomings undergone by its predecessor (e.g., vanishing/exploding gradient) by enabling layer-wise training heuristics. In classification tasks, this contrastive method has been proven to effectively create a latent sparse representation of the input data, ultimately favoring discriminability. However, FFA exhibits an inherent asymmetric gradient behavior due to an imbalanced loss function between positive and negative data, adversely impacting on the model's generalization capabilities and leading to an accuracy degradation. To address this issue, this work proposes the Symmetric Forward-Forward Algorithm (SFFA), a novel modification of the original FFA which partitions each layer into positive and negative neurons. This allows the local fitness function to be defined as the ratio between the activation of positive neurons and the overall layer activity, resulting in a symmetric loss landscape during the training phase. To evaluate the enhanced convergence of our method, we conduct several experiments using multiple image classification benchmarks, comparing the accuracy of models trained with SFFA to those trained with its FFA counterpart. As a byproduct of this reformulation, we explore the advantages of using a layer-wise training algorithm for Continual Learning (CL) tasks. The specialization of neurons and the sparsity of their activations induced by layer-wise training algorithms enable efficient CL strategies that incorporate new knowledge (classes) into the neural network, while preventing catastrophic forgetting of previously...",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at 3rd Conference on Lifelong Learning Agents (CoLLAs), 2024"
    },
    {
        "paper id": "2409.07392",
        "abstract url": "https://arxiv.org/abs/2409.07392",
        "title": "A Scalable Algorithm for Active Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "FIRAL is a recently proposed deterministic active learning algorithm for multiclass classification using logistic regression. It was shown to outperform the state-of-the-art in terms of accuracy and robustness and comes with theoretical performance guarantees. However, its scalability suffers when dealing with datasets featuring a large number of points $n$, dimensions $d$, and classes $c$, due to its $\\mathcal{O}(c^2d^2+nc^2d)$ storage and $\\mathcal{O}(c^3(nd^2 + bd^3 + bn))$ computational complexity where $b$ is the number of points to select in active learning. To address these challenges, we propose an approximate algorithm with storage requirements reduced to $\\mathcal{O}(n(d+c) + cd^2)$ and a computational complexity of $\\mathcal{O}(bncd^2)$. Additionally, we present a parallel implementation on GPUs. We demonstrate the accuracy and scalability of our approach using MNIST, CIFAR-10, Caltech101, and ImageNet. The accuracy tests reveal no deterioration in accuracy compared to FIRAL. We report strong and weak scaling tests on up to 12 GPUs, for three million point synthetic dataset.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "To be appeared at SC'24. Link: https://sc24.conference-program.com/presentation/?id=pap624&sess=sess397"
    },
    {
        "paper id": "2409.07397",
        "abstract url": "https://arxiv.org/abs/2409.07397",
        "title": "Revisiting Static Feature-Based Android Malware Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The increasing reliance on machine learning (ML) in computer security, particularly for malware classification, has driven significant advancements. However, the replicability and reproducibility of these results are often overlooked, leading to challenges in verifying research findings. This paper highlights critical pitfalls that undermine the validity of ML research in Android malware detection, focusing on dataset and methodological issues. We comprehensively analyze Android malware detection using two datasets and assess offline and continual learning settings with six widely used ML models. Our study reveals that when properly tuned, simpler baseline methods can often outperform more complex models. To address reproducibility challenges, we propose solutions for improving datasets and methodological practices, enabling fairer model comparisons. Additionally, we open-source our code to facilitate malware analysis, making it extensible for new models and datasets. Our paper aims to support future research in Android malware detection and other security domains, enhancing the reliability and reproducibility of published results.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07401",
        "abstract url": "https://arxiv.org/abs/2409.07401",
        "title": "Convergence of continuous-time stochastic gradient descent with applications to linear deep neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study a continuous-time approximation of the stochastic gradient descent process for minimizing the expected loss in learning problems. The main results establish general sufficient conditions for the convergence, extending the results of Chatterjee (2022) established for (nonstochastic) gradient descent. We show how the main result can be applied to the case of overparametrized linear neural network training.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07407",
        "abstract url": "https://arxiv.org/abs/2409.07407",
        "title": "CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have shown great promise in vulnerability identification. As C/C++ comprises half of the Open-Source Software (OSS) vulnerabilities over the past decade and updates in OSS mainly occur through commits, enhancing LLMs' ability to identify C/C++ Vulnerability-Contributing Commits (VCCs) is essential. However, current studies primarily focus on further pre-training LLMs on massive code datasets, which is resource-intensive and poses efficiency challenges. In this paper, we enhance the ability of BERT-based LLMs to identify C/C++ VCCs in a lightweight manner. We propose CodeLinguaNexus (CLNX) as a bridge facilitating communication between C/C++ programs and LLMs. Based on commits, CLNX efficiently converts the source code into a more natural representation while preserving key details. Specifically, CLNX first applies structure-level naturalization to decompose complex programs, followed by token-level naturalization to interpret complex symbols. We evaluate CLNX on public datasets of 25,872 C/C++ functions with their commits. The results show that CLNX significantly enhances the performance of LLMs on identifying C/C++ VCCs. Moreover, CLNX-equipped CodeBERT achieves new state-of-the-art and identifies 38 OSS vulnerabilities in the real world.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "8 pages, 2 figures, conference"
    },
    {
        "paper id": "2409.07412",
        "abstract url": "https://arxiv.org/abs/2409.07412",
        "title": "Manifold Learning via Foliations and Knowledge Transfer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Understanding how real data is distributed in high dimensional spaces is the key to many tasks in machine learning. We want to provide a natural geometric structure on the space of data employing a deep ReLU neural network trained as a classifier. Through the data information matrix (DIM), a variation of the Fisher information matrix, the model will discern a singular foliation structure on the space of data. We show that the singular points of such foliation are contained in a measure zero set, and that a local regular foliation exists almost everywhere. Experiments show that the data is correlated with leaves of such foliation. Moreover we show the potential of our approach for knowledge transfer by analyzing the spectrum of the DIM to measure distances between datasets.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07434",
        "abstract url": "https://arxiv.org/abs/2409.07434",
        "title": "Asymptotics of Stochastic Gradient Descent with Dropout Regularization in Linear Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes an asymptotic theory for online inference of the stochastic gradient descent (SGD) iterates with dropout regularization in linear regression. Specifically, we establish the geometric-moment contraction (GMC) for constant step-size SGD dropout iterates to show the existence of a unique stationary distribution of the dropout recursive function. By the GMC property, we provide quenched central limit theorems (CLT) for the difference between dropout and $\\ell^2$-regularized iterates, regardless of initialization. The CLT for the difference between the Ruppert-Polyak averaged SGD (ASGD) with dropout and $\\ell^2$-regularized iterates is also presented. Based on these asymptotic normality results, we further introduce an online estimator for the long-run covariance matrix of ASGD dropout to facilitate inference in a recursive manner with efficiency in computational time and memory. The numerical experiments demonstrate that for sufficiently large samples, the proposed confidence intervals for ASGD with dropout nearly achieve the nominal coverage probability.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": "77 pages, 5 figures, 4 tables"
    },
    {
        "paper id": "2409.07453",
        "abstract url": "https://arxiv.org/abs/2409.07453",
        "title": "\"My Grade is Wrong!\": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Interactive feedback, where feedback flows in both directions between teacher and student, is more effective than traditional one-way feedback. However, it is often too time-consuming for widespread use in educational practice. While Large Language Models (LLMs) have potential for automating feedback, they struggle with reasoning and interaction in an interactive setting. This paper introduces CAELF, a Contestable AI Empowered LLM Framework for automating interactive feedback. CAELF allows students to query, challenge, and clarify their feedback by integrating a multi-agent system with computational argumentation. Essays are first assessed by multiple Teaching-Assistant Agents (TA Agents), and then a Teacher Agent aggregates the evaluations through formal reasoning to generate feedback and grades. Students can further engage with the feedback to refine their understanding. A case study on 500 critical thinking essays with user studies demonstrates that CAELF significantly improves interactive feedback, enhancing the reasoning and interaction capabilities of LLMs. This approach offers a promising solution to overcoming the time and resource barriers that have limited the adoption of interactive feedback in educational settings.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07510",
        "abstract url": "https://arxiv.org/abs/2409.07510",
        "title": "Still More Shades of Null: A Benchmark for Responsible Missing Value Imputation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "We present Shades-of-NULL, a benchmark for responsible missing value imputation. Our benchmark includes state-of-the-art imputation techniques, and embeds them into the machine learning development lifecycle. We model realistic missingness scenarios that go beyond Rubin's classic Missing Completely at Random (MCAR), Missing At Random (MAR) and Missing Not At Random (MNAR), to include multi-mechanism missingness (when different missingness patterns co-exist in the data) and missingness shift (when the missingness mechanism changes between training and test). Another key novelty of our work is that we evaluate imputers holistically, based on the predictive performance, fairness and stability of the models that are trained and tested on the data they produce. We use Shades-of-NULL to conduct a large-scale empirical study involving 20,952 experimental pipelines, and find that, while there is no single best-performing imputation approach for all missingness types, interesting performance patterns do emerge when comparing imputer performance in simpler vs. more complex missingness scenarios. Further, while predictive performance, fairness and stability can be seen as orthogonal, we identify trade-offs among them that arise due to the combination of missingness scenario, the choice of an imputer, and the architecture of the model trained on the data post-imputation. We make Shades-of-NULL publicly available, and hope to enable researchers to comprehensively and rigorously evaluate new missing value imputation methods on a wide range of evaluation metrics, in plausible and socially meaningful missingness scenarios.",
        "subjects": [
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07523",
        "abstract url": "https://arxiv.org/abs/2409.07523",
        "title": "Using Neural Network Models to Estimate Stellar Ages from Lithium Equivalent Widths: An EAGLES Expansion",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present an Artificial Neural Network (ANN) model of photospheric lithium depletion in cool stars (3000 < Teff / K < 6500), producing estimates and probability distributions of age from Li I 6708A equivalent width (LiEW) and effective temperature data inputs. The model is trained on the same sample of 6200 stars from 52 open clusters, observed in the Gaia-ESO spectroscopic survey, and used to calibrate the previously published analytical EAGLES model, with ages 2 - 6000 Myr and -0.3 < [Fe/H] < 0.2. The additional flexibility of the ANN provides some improvements, including better modelling of the \"lithium dip\" at ages < 50 Myr and Teff ~ 3500K, and of the intrinsic dispersion in LiEW at all ages. Poor age discrimination is still an issue at ages > 1 Gyr, confirming that additional modelling flexibility is not sufficient to fully represent the LiEW - age - Teff relationship, and suggesting the involvement of further astrophysical parameters. Expansion to include such parameters - rotation, accretion, and surface gravity - is discussed, and the use of an ANN means these can be more easily included in future iterations, alongside more flexible functional forms for the LiEW dispersion. Our methods and ANN model are provided in an updated version 2.0 of the EAGLES software.",
        "subjects": [
            "astro-ph.SR",
            "astro-ph.GA",
            "astro-ph.IM",
            "cs.LG"
        ],
        "comment": "Accepted for publication in Monthly Notices of the Royal Astronomical Society. Code available at https://github.com/robdjeff/eagles. Electronic tables are available from the author"
    },
    {
        "paper id": "2409.07571",
        "abstract url": "https://arxiv.org/abs/2409.07571",
        "title": "FaVoR: Features via Voxel Rendering for Camera Relocalization",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "Voxel"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Camera relocalization methods range from dense image alignment to direct camera pose regression from a query image. Among these, sparse feature matching stands out as an efficient, versatile, and generally lightweight approach with numerous applications. However, feature-based methods often struggle with significant viewpoint and appearance changes, leading to matching failures and inaccurate pose estimates. To overcome this limitation, we propose a novel approach that leverages a globally sparse yet locally dense 3D representation of 2D features. By tracking and triangulating landmarks over a sequence of frames, we construct a sparse voxel map optimized to render image patch descriptors observed during tracking. Given an initial pose estimate, we first synthesize descriptors from the voxels using volumetric rendering and then perform feature matching to estimate the camera pose. This methodology enables the generation of descriptors for unseen views, enhancing robustness to view changes. We extensively evaluate our method on the 7-Scenes and Cambridge Landmarks datasets. Our results show that our method significantly outperforms existing state-of-the-art feature representation techniques in indoor environments, achieving up to a 39% improvement in median translation error. Additionally, our approach yields comparable results to other methods for outdoor scenarios while maintaining lower memory and computational costs.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Submitted to the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Tucson, Arizona, US, Feb 28-Mar 4, 2025"
    },
    {
        "paper id": "2409.07578",
        "abstract url": "https://arxiv.org/abs/2409.07578",
        "title": "A Novel Mathematical Framework for Objective Evaluation of Ideas using a Conversational AI (CAI) System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The demand for innovation in product design necessitates a prolific ideation phase. Conversational AI (CAI) systems that use Large Language Models (LLMs) such as GPT (Generative Pre-trained Transformer) have been shown to be fruitful in augmenting human creativity, providing numerous novel and diverse ideas. Despite the success in ideation quantity, the qualitative assessment of these ideas remains challenging and traditionally reliant on expert human evaluation. This method suffers from limitations such as human judgment errors, bias, and oversight. Addressing this gap, our study introduces a comprehensive mathematical framework for automated analysis to objectively evaluate the plethora of ideas generated by CAI systems and/or humans. This framework is particularly advantageous for novice designers who lack experience in selecting promising ideas. By converting the ideas into higher dimensional vectors and quantitatively measuring the diversity between them using tools such as UMAP, DBSCAN and PCA, the proposed method provides a reliable and objective way of selecting the most promising ideas, thereby enhancing the efficiency of the ideation phase.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "20 pages, 12 figures, 5 tables"
    },
    {
        "paper id": "2409.07590",
        "abstract url": "https://arxiv.org/abs/2409.07590",
        "title": "Deep Learning for predicting rate-induced tipping",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Nonlinear dynamical systems exposed to changing forcing can exhibit catastrophic transitions between alternative and often markedly different states. The phenomenon of critical slowing down (CSD) can be used to anticipate such transitions if caused by a bifurcation and if the change in forcing is slow compared to the internal time scale of the system. However, in many real-world situations, these assumptions are not met and transitions can be triggered because the forcing exceeds a critical rate. For example, given the pace of anthropogenic climate change in comparison to the internal time scales of key Earth system components, such as the polar ice sheets or the Atlantic Meridional Overturning Circulation, such rate-induced tipping poses a severe risk. Moreover, depending on the realisation of random perturbations, some trajectories may transition across an unstable boundary, while others do not, even under the same forcing. CSD-based indicators generally cannot distinguish these cases of noise-induced tipping versus no tipping. This severely limits our ability to assess the risks of tipping, and to predict individual trajectories. To address this, we make a first attempt to develop a deep learning framework to predict transition probabilities of dynamical systems ahead of rate-induced transitions. Our method issues early warnings, as demonstrated on three prototypical systems for rate-induced tipping, subjected to time-varying equilibrium drift and noise perturbations. Exploiting explainable artificial intelligence methods, our framework captures the fingerprints necessary for early detection of rate-induced tipping, even in cases of long lead times. Our findings demonstrate the predictability of rate-induced and noise-induced tipping, advancing our ability to determine safe operating spaces for a broader class of dynamical systems than possible so far.",
        "subjects": [
            "cs.LG",
            "math.DS",
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07606",
        "abstract url": "https://arxiv.org/abs/2409.07606",
        "title": "The Role of Deep Learning Regularizations on Actors in Offline RL",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning regularization techniques, such as \\emph{dropout}, \\emph{layer normalization}, or \\emph{weight decay}, are widely adopted in the construction of modern artificial neural networks, often resulting in more robust training processes and improved generalization capabilities. However, in the domain of \\emph{Reinforcement Learning} (RL), the application of these techniques has been limited, usually applied to value function estimators \\citep{hiraoka2021dropout, smith2022walk}, and may result in detrimental effects. This issue is even more pronounced in offline RL settings, which bear greater similarity to supervised learning but have received less attention. Recent work in continuous offline RL has demonstrated that while we can build sufficiently powerful critic networks, the generalization of actor networks remains a bottleneck. In this study, we empirically show that applying standard regularization techniques to actor networks in offline RL actor-critic algorithms yields improvements of 6\\% on average across two algorithms and three different continuous D4RL domains.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "https://github.com/DT6A/ActoReg"
    },
    {
        "paper id": "2409.07610",
        "abstract url": "https://arxiv.org/abs/2409.07610",
        "title": "When More Data Hurts: Optimizing Data Coverage While Mitigating Diversity Induced Underfitting in an Ultra-Fast Machine-Learned Potential",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine-learned interatomic potentials (MLIPs) are becoming an essential tool in materials modeling. However, optimizing the generation of training data used to parameterize the MLIPs remains a significant challenge. This is because MLIPs can fail when encountering local enviroments too different from those present in the training data. The difficulty of determining \\textit{a priori} the environments that will be encountered during molecular dynamics (MD) simulation necessitates diverse, high-quality training data. This study investigates how training data diversity affects the performance of MLIPs using the Ultra-Fast Force Field (UF$^3$) to model amorphous silicon nitride. We employ expert and autonomously generated data to create the training data and fit four force-field variants to subsets of the data. Our findings reveal a critical balance in training data diversity: insufficient diversity hinders generalization, while excessive diversity can exceed the MLIP's learning capacity, reducing simulation accuracy. Specifically, we found that the UF$^3$ variant trained on a subset of the training data, in which nitrogen-rich structures were removed, offered vastly better prediction and simulation accuracy than any other variant. By comparing these UF$^3$ variants, we highlight the nuanced requirements for creating accurate MLIPs, emphasizing the importance of application-specific training data to achieve optimal performance in modeling complex material behaviors.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": "6 pages, 4 figures"
    },
    {
        "paper id": "2409.07611",
        "abstract url": "https://arxiv.org/abs/2409.07611",
        "title": "Detection and Classification of Twitter Users' Opinions on Drought Crises in Iran Using Machine Learning Techniques",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The main objective of this research is to identify and classify the opinions of Persian-speaking Twitter users related to drought crises in Iran and subsequently develop a model for detecting these opinions on the platform. To achieve this, a model has been developed using machine learning and text mining methods to detect the opinions of Persian-speaking Twitter users regarding the drought issues in Iran. The statistical population for the research included 42,028 drought-related tweets posted over a one-year period. These tweets were extracted from Twitter using keywords related to the drought crises in Iran. Subsequently, a sample of 2,300 tweets was qualitatively analyzed, labeled, categorized, and examined. Next, a four-category classification of users` opinions regarding drought crises and Iranians' resilience to these crises was identified. Based on these four categories, a machine learning model based on logistic regression was trained to predict and detect various opinions in Twitter posts. The developed model exhibits an accuracy of 66.09% and an F-score of 60%, indicating that this model has good performance for detecting Iranian Twitter users' opinions regarding drought crises. The ability to detect opinions regarding drought crises on platforms like Twitter using machine learning methods can intelligently represent the resilience level of the Iranian society in the face of these crises, and inform policymakers in this area about changes in public opinion.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07618",
        "abstract url": "https://arxiv.org/abs/2409.07618",
        "title": "Understanding Foundation Models: Are We Back in 1924?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This position paper explores the rapid development of Foundation Models (FMs) in AI and their implications for intelligence and reasoning. It examines the characteristics of FMs, including their training on vast datasets and use of embedding spaces to capture semantic relationships. The paper discusses recent advancements in FMs' reasoning abilities which we argue cannot be attributed to increased model size but to novel training techniques which yield learning phenomena like grokking. It also addresses the challenges in benchmarking FMs and compares their structure to the human brain. We argue that while FMs show promising developments in reasoning and knowledge representation, understanding their inner workings remains a significant challenge, similar to ongoing efforts in neuroscience to comprehend human brain function. Despite having some similarities, fundamental differences between FMs and the structure of human brain warn us against making direct comparisons or expecting neuroscience to provide immediate insights into FM function.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "7 pages, 4 Figures, to appear in Proceedings of the 2nd International Conference on Foundation and Large Language Models (FLLM2024) 26-29 November, 2024, Dubai, UAE"
    },
    {
        "paper id": "2409.07629",
        "abstract url": "https://arxiv.org/abs/2409.07629",
        "title": "Dividable Configuration Performance Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Machine/deep learning models have been widely adopted for predicting the configuration performance of software systems. However, a crucial yet unaddressed challenge is how to cater for the sparsity inherited from the configuration landscape: the influence of configuration options (features) and the distribution of data samples are highly sparse. In this paper, we propose a model-agnostic and sparsity-robust framework for predicting configuration performance, dubbed DaL, based on the new paradigm of dividable learning that builds a model via \"divide-and-learn\". To handle sample sparsity, the samples from the configuration landscape are divided into distant divisions, for each of which we build a sparse local model, e.g., regularized Hierarchical Interaction Neural Network, to deal with the feature sparsity. A newly given configuration would then be assigned to the right model of division for the final prediction. Further, DaL adaptively determines the optimal number of divisions required for a system and sample size without any extra training or profiling. Experiment results from 12 real-world systems and five sets of training data reveal that, compared with the state-of-the-art approaches, DaL performs no worse than the best counterpart on 44 out of 60 cases with up to 1.61x improvement on accuracy; requires fewer samples to reach the same/better accuracy; and producing acceptable training overhead. In particular, the mechanism that adapted the parameter d can reach the optimal value for 76.43% of the individual runs. The result also confirms that the paradigm of dividable learning is more suitable than other similar paradigms such as ensemble learning for predicting configuration performance. Practically, DaL considerably improves different global models when using them as the underlying local models, which further strengthens its flexibility.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Submitted to TSE as a regular journal paper. arXiv admin note: text overlap with arXiv:2306.06651"
    },
    {
        "paper id": "2409.07642",
        "abstract url": "https://arxiv.org/abs/2409.07642",
        "title": "Deep Learning of Dynamic Systems using System Identification Toolbox(TM)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "MATLAB(R) releases over the last 3 years have witnessed a continuing growth in the dynamic modeling capabilities offered by the System Identification Toolbox(TM). The emphasis has been on integrating deep learning architectures and training techniques that facilitate the use of deep neural networks as building blocks of nonlinear models. The toolbox offers neural state-space models which can be extended with auto-encoding features that are particularly suited for reduced-order modeling of large systems. The toolbox contains several other enhancements that deepen its integration with the state-of-art machine learning techniques, leverage auto-differentiation features for state estimation, and enable a direct use of raw numeric matrices and timetables for training models.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07652",
        "abstract url": "https://arxiv.org/abs/2409.07652",
        "title": "Gaussian Process Upper Confidence Bounds in Distributed Point Target Tracking over Wireless Sensor Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Uncertainty quantification plays a key role in the development of autonomous systems, decision-making, and tracking over wireless sensor networks (WSNs). However, there is a need of providing uncertainty confidence bounds, especially for distributed machine learning-based tracking, dealing with different volumes of data collected by sensors. This paper aims to fill in this gap and proposes a distributed Gaussian process (DGP) approach for point target tracking and derives upper confidence bounds (UCBs) of the state estimates. A unique contribution of this paper includes the derived theoretical guarantees on the proposed approach and its maximum accuracy for tracking with and without clutter measurements. Particularly, the developed approaches with uncertainty bounds are generic and can provide trustworthy solutions with an increased level of reliability. A novel hybrid Bayesian filtering method is proposed to enhance the DGP approach by adopting a Poisson measurement likelihood model. The proposed approaches are validated over a WSN case study, where sensors have limited sensing ranges. Numerical results demonstrate the tracking accuracy and robustness of the proposed approaches. The derived UCBs constitute a tool for trustworthiness evaluation of DGP approaches. The simulation results reveal that the proposed UCBs successfully encompass the true target states with 88% and 42% higher probability in X and Y coordinates, respectively, when compared to the confidence interval-based method.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07656",
        "abstract url": "https://arxiv.org/abs/2409.07656",
        "title": "Passed the Turing Test: Living in Turing Futures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "The world has seen the emergence of machines based on pretrained models, transformers, also known as generative artificial intelligences for their ability to produce various types of content, including text, images, audio, and synthetic data. Without resorting to preprogramming or special tricks, their intelligence grows as they learn from experience, and to ordinary people, they can appear human-like in conversation. This means that they can pass the Turing test, and that we are now living in one of many possible Turing futures where machines can pass for what they are not. However, the learning machines that Turing imagined would pass his imitation tests were machines inspired by the natural development of the low-energy human cortex. They would be raised like human children and naturally learn the ability to deceive an observer. These ``child machines,'' Turing hoped, would be powerful enough to have an impact on society and nature.",
        "subjects": [
            "cs.AI",
            "cs.CY"
        ],
        "comment": "Author's version. Forthcoming in Intelligent Computing, a Science Partner Journal published in affiliation with Zhejiang Lab (https://spj.science.org/journal/icomputing). First submitted 19 Feb 2024. Revised 16 Jul 2024. Accepted 15 Aug 2024"
    },
    {
        "paper id": "2409.07679",
        "abstract url": "https://arxiv.org/abs/2409.07679",
        "title": "Ratio Divergence Learning Using Target Energy in Restricted Boltzmann Machines: Beyond Kullback--Leibler Divergence Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose ratio divergence (RD) learning for discrete energy-based models, a method that utilizes both training data and a tractable target energy function. We apply RD learning to restricted Boltzmann machines (RBMs), which are a minimal model that satisfies the universal approximation theorem for discrete distributions. RD learning combines the strength of both forward and reverse Kullback-Leibler divergence (KLD) learning, effectively addressing the \"notorious\" issues of underfitting with the forward KLD and mode-collapse with the reverse KLD. Since the summation of forward and reverse KLD seems to be sufficient to combine the strength of both approaches, we include this learning method as a direct baseline in numerical experiments to evaluate its effectiveness. Numerical experiments demonstrate that RD learning significantly outperforms other learning methods in terms of energy function fitting, mode-covering, and learning stability across various discrete energy-based models. Moreover, the performance gaps between RD learning and the other learning methods become more pronounced as the dimensions of target models increase.",
        "subjects": [
            "stat.ML",
            "cond-mat.dis-nn",
            "cs.LG",
            "math.ST",
            "stat.ME"
        ],
        "comment": "14 pages, 19 figures"
    },
    {
        "paper id": "2409.07708",
        "abstract url": "https://arxiv.org/abs/2409.07708",
        "title": "Dataset-Free Weight-Initialization on Restricted Boltzmann Machine",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In feed-forward neural networks, dataset-free weight-initialization method such as LeCun, Xavier (or Glorot), and He initializations have been developed. These methods randomly determine the initial values of weight parameters based on specific distributions (e.g., Gaussian or uniform distributions) without using training datasets. To the best of the authors' knowledge, such a dataset-free weight-initialization method is yet to be developed for restricted Boltzmann machines (RBMs), which are probabilistic neural networks consisting of two layers, In this study, we derive a dataset-free weight-initialization method for Bernoulli--Bernoulli RBMs based on a statistical mechanical analysis. In the proposed weight-initialization method, the weight parameters are drawn from a Gaussian distribution with zero mean. The standard deviation of the Gaussian distribution is optimized based on our hypothesis which is that a standard deviation providing a larger layer correlation (LC) between the two layers improves the learning efficiency. The expression of the LC is derived based on a statistical mechanical analysis. The optimal value of the standard deviation corresponds to the maximum point of the LC. The proposed weight-initialization method is identical to Xavier initialization in a specific case (i.e., in the case the sizes of the two layers are the same, the random variables of the layers are $\\{-1,1\\}$-binary, and all bias parameters are zero).",
        "subjects": [
            "stat.ML",
            "cond-mat.dis-nn",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07710",
        "abstract url": "https://arxiv.org/abs/2409.07710",
        "title": "Surprising Resilience of Science During a Global Pandemic: A Large-Scale Descriptive Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The COVID-19 pandemic profoundly impacted people globally, yet its effect on scientists and research institutions has yet to be fully examined. To address this knowledge gap, we use a newly available bibliographic dataset covering tens of millions of papers and authors to investigate changes in research activity and collaboration during this period. Employing statistical methods, we analyze the pandemic's disruptions on the participation, productivity, and collaborations of researchers at the top 1,000 institutions worldwide based on historical productivity, taking into account variables such as geography, researcher seniority and gender, and field of study. Our findings reveal an unexpected trend: research activity and output significantly increased in the early stages of the pandemic, indicating a surprising resilience in the scientific community. However, by the end of 2022, there was a notable reversion to historical trends in research participation and productivity. This reversion suggests that the initial spike in research activity was a short-lived disruption rather than a permanent shift. As such, monitoring scientific outputs in 2023 and beyond becomes crucial. There may be a delayed negative effect of the pandemic on research, given the long time horizon for many research fields and the temporary closure of wet labs. Further analysis is needed to fully comprehend the factors that underpin the resilience of scientific innovation in the face of global crises. Our study provides an initial comprehensive exploration up to the end of 2022, offering valuable insights into how the scientific community has adapted and responded over the course of the pandemic.",
        "subjects": [
            "cs.SI",
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07716",
        "abstract url": "https://arxiv.org/abs/2409.07716",
        "title": "Polarization Detection on Social Networks: dual contrastive objectives for Self-supervision",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Echo chambers and online discourses have become prevalent social phenomena where communities engage in dramatic intra-group confirmations and inter-group hostility. Polarization detection is a rising research topic for detecting and identifying such polarized groups. Previous works on polarization detection primarily focus on hand-crafted features derived from dataset-specific characteristics and prior knowledge, which fail to generalize to other datasets. This paper proposes a unified self-supervised polarization detection framework, outperforming previous methods in unsupervised and semi-supervised polarization detection tasks on various publicly available datasets. Our framework utilizes a dual contrastive objective (DocTra): (1) interaction-level: to contrast between node interactions to extract critical features on interaction patterns, and (2) feature-level: to contrast extracted polarized and invariant features to encourage feature decoupling. Our experiments extensively evaluate our methods again 7 baselines on 7 public datasets, demonstrating significant performance improvements.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07720",
        "abstract url": "https://arxiv.org/abs/2409.07720",
        "title": "Keeping it Authentic: The Social Footprint of the Trolls Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "In 2016, a network of social media accounts animated by Russian operatives attempted to divert political discourse within the American public around the presidential elections. This was a coordinated effort, part of a Russian-led complex information operation. Utilizing the anonymity and outreach of social media platforms Russian operatives created an online astroturf that is in direct contact with regular Americans, promoting Russian agenda and goals. The elusiveness of this type of adversarial approach rendered security agencies helpless, stressing the unique challenges this type of intervention presents. Building on existing scholarship on the functions within influence networks on social media, we suggest a new approach to map those types of operations. We argue that pretending to be legitimate social actors obliges the network to adhere to social expectations, leaving a social footprint. To test the robustness of this social footprint we train artificial intelligence to identify it and create a predictive model. We use Twitter data identified as part of the Russian influence network for training the artificial intelligence and to test the prediction. Our model attains 88% prediction accuracy for the test set. Testing our prediction on two additional models results in 90.7% and 90.5% accuracy, validating our model. The predictive and validation results suggest that building a machine learning model around social functions within the Russian influence network can be used to map its actors and functions.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "comment": "28 pages, 03 figures, 06 tables. Further, this paper has been published in Social Network Analysis and Mining"
    },
    {
        "paper id": "2409.07732",
        "abstract url": "https://arxiv.org/abs/2409.07732",
        "title": "Large Language Models are Pattern Matchers: Editing Semi-Structured and Structured Documents with ChatGPT",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) offer numerous applications, the full extent of which is not yet understood. This paper investigates if LLMs can be applied for editing structured and semi-structured documents with minimal effort. Using a qualitative research approach, we conduct two case studies with ChatGPT and thoroughly analyze the results. Our experiments indicate that LLMs can effectively edit structured and semi-structured documents when provided with basic, straightforward prompts. ChatGPT demonstrates a strong ability to recognize and process the structure of annotated documents. This suggests that explicitly structuring tasks and data in prompts might enhance an LLM's ability to understand and solve tasks. Furthermore, the experiments also reveal impressive pattern matching skills in ChatGPT. This observation deserves further investigation, as it may contribute to understanding the processes leading to hallucinations in LLMs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07751",
        "abstract url": "https://arxiv.org/abs/2409.07751",
        "title": "Efficient Privacy-Preserving KAN Inference Using Homomorphic Encryption",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The recently proposed Kolmogorov-Arnold Networks (KANs) offer enhanced interpretability and greater model expressiveness. However, KANs also present challenges related to privacy leakage during inference. Homomorphic encryption (HE) facilitates privacy-preserving inference for deep learning models, enabling resource-limited users to benefit from deep learning services while ensuring data security. Yet, the complex structure of KANs, incorporating nonlinear elements like the SiLU activation function and B-spline functions, renders existing privacy-preserving inference techniques inadequate. To address this issue, we propose an accurate and efficient privacy-preserving inference scheme tailored for KANs. Our approach introduces a task-specific polynomial approximation for the SiLU activation function, dynamically adjusting the approximation range to ensure high accuracy on real-world datasets. Additionally, we develop an efficient method for computing B-spline functions within the HE domain, leveraging techniques such as repeat packing, lazy combination, and comparison functions. We evaluate the effectiveness of our privacy-preserving KAN inference scheme on both symbolic formula evaluation and image classification. The experimental results show that our model achieves accuracy comparable to plaintext KANs across various datasets and outperforms plaintext MLPs. Additionally, on the CIFAR-10 dataset, our inference latency achieves over 7 times speedup compared to the naive method.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07048",
        "abstract url": "https://arxiv.org/abs/2409.07048",
        "title": "Pushing the Limits of Vision-Language Models in Remote Sensing without Human Annotations",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The prominence of generalized foundation models in vision-language integration has witnessed a surge, given their multifarious applications. Within the natural domain, the procurement of vision-language datasets to construct these foundation models is facilitated by their abundant availability and the ease of web crawling. Conversely, in the remote sensing domain, although vision-language datasets exist, their volume is suboptimal for constructing robust foundation models. This study introduces an approach to curate vision-language datasets by employing an image decoding machine learning model, negating the need for human-annotated labels. Utilizing this methodology, we amassed approximately 9.6 million vision-language paired datasets in VHR imagery. The resultant model outperformed counterparts that did not leverage publicly available vision-language datasets, particularly in downstream tasks such as zero-shot classification, semantic localization, and image-text retrieval. Moreover, in tasks exclusively employing vision encoders, such as linear probing and k-NN classification, our model demonstrated superior efficacy compared to those relying on domain-specific vision-language datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This study was primarily conducted during the latter half of 2023"
    },
    {
        "paper id": "2409.07064",
        "abstract url": "https://arxiv.org/abs/2409.07064",
        "title": "Automated Speaking Assessment of Conversation Tests with Novel Graph-based Modeling on Spoken Response Coherence",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Automated speaking assessment in conversation tests (ASAC) aims to evaluate the overall speaking proficiency of an L2 (second-language) speaker in a setting where an interlocutor interacts with one or more candidates. Although prior ASAC approaches have shown promising performance on their respective datasets, there is still a dearth of research specifically focused on incorporating the coherence of the logical flow within a conversation into the grading model. To address this critical challenge, we propose a hierarchical graph model that aptly incorporates both broad inter-response interactions (e.g., discourse relations) and nuanced semantic information (e.g., semantic words and speaker intents), which is subsequently fused with contextual information for the final prediction. Extensive experimental results on the NICT-JLE benchmark dataset suggest that our proposed modeling approach can yield considerable improvements in prediction accuracy with respect to various assessment metrics, as compared to some strong baselines. This also sheds light on the importance of investigating coherence-related facets of spoken responses in ASAC.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by IEEE SLT 2024"
    },
    {
        "paper id": "2409.07088",
        "abstract url": "https://arxiv.org/abs/2409.07088",
        "title": "Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge Graph-to-Text (G2T) generation involves verbalizing structured knowledge graphs into natural language text. Recent advancements in Pretrained Language Models (PLMs) have improved G2T performance, but their effectiveness depends on datasets with precise graph-text alignment. However, the scarcity of high-quality, general-domain G2T generation datasets restricts progress in the general-domain G2T generation research. To address this issue, we introduce Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T dataset generated using a novel method that leverages Large Language Model (LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain graph-text pairs, offers high graph-text consistency without relying on external ontologies. Experimental results demonstrate that PLM fine-tuned on WikiOFGraph outperforms those trained on other datasets across various evaluation metrics. Our method proves to be a scalable and effective solution for generating high-quality G2T data, significantly advancing the field of G2T generation.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "18 pages, 9 figures"
    },
    {
        "paper id": "2409.07129",
        "abstract url": "https://arxiv.org/abs/2409.07129",
        "title": "MVLLaVA: An Intelligent Agent for Unified and Flexible Novel View Synthesis",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces MVLLaVA, an intelligent agent designed for novel view synthesis tasks. MVLLaVA integrates multiple multi-view diffusion models with a large multimodal model, LLaVA, enabling it to handle a wide range of tasks efficiently. MVLLaVA represents a versatile and unified platform that adapts to diverse input types, including a single image, a descriptive caption, or a specific change in viewing azimuth, guided by language instructions for viewpoint generation. We carefully craft task-specific instruction templates, which are subsequently used to fine-tune LLaVA. As a result, MVLLaVA acquires the capability to generate novel view images based on user instructions, demonstrating its flexibility across diverse tasks. Experiments are conducted to validate the effectiveness of MVLLaVA, demonstrating its robust performance and versatility in tackling diverse novel view synthesis challenges.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "project page: https://jamesjg.github.io/MVLLaVA_homepage/"
    },
    {
        "paper id": "2409.07218",
        "abstract url": "https://arxiv.org/abs/2409.07218",
        "title": "Behavioral Cloning Models Reality Check for Autonomous Driving",
        "rating": "0",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "How effective are recent advancements in autonomous vehicle perception systems when applied to real-world autonomous vehicle control? While numerous vision-based autonomous vehicle systems have been trained and evaluated in simulated environments, there is a notable lack of real-world validation for these systems. This paper addresses this gap by presenting the real-world validation of state-of-the-art perception systems that utilize Behavior Cloning (BC) for lateral control, processing raw image data to predict steering commands. The dataset was collected using a scaled research vehicle and tested on various track setups. Experimental results demonstrate that these methods predict steering angles with low error margins in real-time, indicating promising potential for real-world applications.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07224",
        "abstract url": "https://arxiv.org/abs/2409.07224",
        "title": "Analytic Class Incremental Learning for Sound Source Localization with Privacy Protection",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Sound Source Localization (SSL) enabling technology for applications such as surveillance and robotics. While traditional Signal Processing (SP)-based SSL methods provide analytic solutions under specific signal and noise assumptions, recent Deep Learning (DL)-based methods have significantly outperformed them. However, their success depends on extensive training data and substantial computational resources. Moreover, they often rely on large-scale annotated spatial data and may struggle when adapting to evolving sound classes. To mitigate these challenges, we propose a novel Class Incremental Learning (CIL) approach, termed SSL-CIL, which avoids serious accuracy degradation due to catastrophic forgetting by incrementally updating the DL-based SSL model through a closed-form analytic solution. In particular, data privacy is ensured since the learning process does not revisit any historical data (exemplar-free), which is more suitable for smart home scenarios. Empirical results in the public SSLR dataset demonstrate the superior performance of our proposal, achieving a localization accuracy of 90.9%, surpassing other competitive methods.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07238",
        "abstract url": "https://arxiv.org/abs/2409.07238",
        "title": "Diff-VPS: Video Polyp Segmentation via a Multi-task Diffusion Network with Adversarial Temporal Reasoning",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion Probabilistic Models have recently attracted significant attention in the community of computer vision due to their outstanding performance. However, while a substantial amount of diffusion-based research has focused on generative tasks, no work introduces diffusion models to advance the results of polyp segmentation in videos, which is frequently challenged by polyps' high camouflage and redundant temporal cues.In this paper, we present a novel diffusion-based network for video polyp segmentation task, dubbed as Diff-VPS. We incorporate multi-task supervision into diffusion models to promote the discrimination of diffusion models on pixel-by-pixel segmentation. This integrates the contextual high-level information achieved by the joint classification and detection tasks. To explore the temporal dependency, Temporal Reasoning Module (TRM) is devised via reasoning and reconstructing the target frame from the previous frames. We further equip TRM with a generative adversarial self-supervised strategy to produce more realistic frames and thus capture better dynamic cues. Extensive experiments are conducted on SUN-SEG, and the results indicate that our proposed Diff-VPS significantly achieves state-of-the-art performance. Code is available at https://github.com/lydia-yllu/Diff-VPS.",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07253",
        "abstract url": "https://arxiv.org/abs/2409.07253",
        "title": "Alignment of Diffusion Models: Fundamentals, Challenges, and Future",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have emerged as the leading paradigm in generative modeling, excelling in various applications. Despite their success, these models often misalign with human intentions, generating outputs that may not match text prompts or possess desired properties. Inspired by the success of alignment in tuning large language models, recent studies have investigated aligning diffusion models with human expectations and preferences. This work mainly reviews alignment of diffusion models, covering advancements in fundamentals of alignment, alignment techniques of diffusion models, preference benchmarks, and evaluation for diffusion models. Moreover, we discuss key perspectives on current challenges and promising future directions on solving the remaining challenges in alignment of diffusion models. To the best of our knowledge, our work is the first comprehensive review paper for researchers and engineers to comprehend, practice, and research alignment of diffusion models.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "35 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2409.07273",
        "abstract url": "https://arxiv.org/abs/2409.07273",
        "title": "Rethinking Mamba in Speech Processing by Self-Supervised Models",
        "rating": "0",
        "keywords": [
            [
                "speech enhancement"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "The Mamba-based model has demonstrated outstanding performance across tasks in computer vision, natural language processing, and speech processing. However, in the realm of speech processing, the Mamba-based model's performance varies across different tasks. For instance, in tasks such as speech enhancement and spectrum reconstruction, the Mamba model performs well when used independently. However, for tasks like speech recognition, additional modules are required to surpass the performance of attention-based models. We propose the hypothesis that the Mamba-based model excels in \"reconstruction\" tasks within speech processing. However, for \"classification tasks\" such as Speech Recognition, additional modules are necessary to accomplish the \"reconstruction\" step. To validate our hypothesis, we analyze the previous Mamba-based Speech Models from an information theory perspective. Furthermore, we leveraged the properties of HuBERT in our study. We trained a Mamba-based HuBERT model, and the mutual information patterns, along with the model's performance metrics, confirmed our assumptions.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07337",
        "abstract url": "https://arxiv.org/abs/2409.07337",
        "title": "Benchmarking 2D Egocentric Hand Pose Datasets",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Hand pose estimation from egocentric video has broad implications across various domains, including human-computer interaction, assistive technologies, activity recognition, and robotics, making it a topic of significant research interest. The efficacy of modern machine learning models depends on the quality of data used for their training. Thus, this work is devoted to the analysis of state-of-the-art egocentric datasets suitable for 2D hand pose estimation. We propose a novel protocol for dataset evaluation, which encompasses not only the analysis of stated dataset characteristics and assessment of data quality, but also the identification of dataset shortcomings through the evaluation of state-of-the-art hand pose estimation models. Our study reveals that despite the availability of numerous egocentric databases intended for 2D hand pose estimation, the majority are tailored for specific use cases. There is no ideal benchmark dataset yet; however, H2O and GANerated Hands datasets emerge as the most promising real and synthetic datasets, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07365",
        "abstract url": "https://arxiv.org/abs/2409.07365",
        "title": "Event-based Mosaicing Bundle Adjustment",
        "rating": "0",
        "keywords": [
            [
                "event camera"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We tackle the problem of mosaicing bundle adjustment (i.e., simultaneous refinement of camera orientations and scene map) for a purely rotating event camera. We formulate the problem as a regularized non-linear least squares optimization. The objective function is defined using the linearized event generation model in the camera orientations and the panoramic gradient map of the scene. We show that this BA optimization has an exploitable block-diagonal sparsity structure, so that the problem can be solved efficiently. To the best of our knowledge, this is the first work to leverage such sparsity to speed up the optimization in the context of event-based cameras, without the need to convert events into image-like representations. We evaluate our method, called EMBA, on both synthetic and real-world datasets to show its effectiveness (50% photometric error decrease), yielding results of unprecedented quality. In addition, we demonstrate EMBA using high spatial resolution event cameras, yielding delicate panoramas in the wild, even without an initial map. Project page: https://github.com/tub-rip/emba",
        "subjects": [
            "cs.CV",
            "cs.RO",
            "eess.IV"
        ],
        "comment": "14+11 pages, 11 figures, 10 tables, https://github.com/tub-rip/emba"
    },
    {
        "paper id": "2409.07417",
        "abstract url": "https://arxiv.org/abs/2409.07417",
        "title": "Efficient One-Step Diffusion Refinement for Snapshot Compressive Imaging",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Coded Aperture Snapshot Spectral Imaging (CASSI) is a crucial technique for capturing three-dimensional multispectral images (MSIs) through the complex inverse task of reconstructing these images from coded two-dimensional measurements. Current state-of-the-art methods, predominantly end-to-end, face limitations in reconstructing high-frequency details and often rely on constrained datasets like KAIST and CAVE, resulting in models with poor generalizability. In response to these challenges, this paper introduces a novel one-step Diffusion Probabilistic Model within a self-supervised adaptation framework for Snapshot Compressive Imaging (SCI). Our approach leverages a pretrained SCI reconstruction network to generate initial predictions from two-dimensional measurements. Subsequently, a one-step diffusion model produces high-frequency residuals to enhance these initial predictions. Additionally, acknowledging the high costs associated with collecting MSIs, we develop a self-supervised paradigm based on the Equivariant Imaging (EI) framework. Experimental results validate the superiority of our model compared to previous methods, showcasing its simplicity and adaptability to various end-to-end or unfolding techniques.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07423",
        "abstract url": "https://arxiv.org/abs/2409.07423",
        "title": "Enhancing adversarial robustness in Natural Language Inference using explanations",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The surge of state-of-the-art Transformer-based models has undoubtedly pushed the limits of NLP model performance, excelling in a variety of tasks. We cast the spotlight on the underexplored task of Natural Language Inference (NLI), since models trained on popular well-suited datasets are susceptible to adversarial attacks, allowing subtle input interventions to mislead the model. In this work, we validate the usage of natural language explanation as a model-agnostic defence strategy through extensive experimentation: only by fine-tuning a classifier on the explanation rather than premise-hypothesis inputs, robustness under various adversarial attacks is achieved in comparison to explanation-free baselines. Moreover, since there is no standard strategy of testing the semantic validity of the generated explanations, we research the correlation of widely used language generation metrics with human perception, in order for them to serve as a proxy towards robust NLI models. Our approach is resource-efficient and reproducible without significant computational limitations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07429",
        "abstract url": "https://arxiv.org/abs/2409.07429",
        "title": "Agent Workflow Memory",
        "rating": "0",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite the potential of language model-based agents to solve real-world tasks such as web navigation, current methods still struggle with long-horizon tasks with complex action trajectories. In contrast, humans can flexibly solve complex tasks by learning reusable task workflows from past experiences and using them to guide future actions. To build agents that can similarly benefit from this process, we introduce Agent Workflow Memory (AWM), a method for inducing commonly reused routines, i.e., workflows, and selectively providing workflows to the agent to guide subsequent generations. AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly. We experiment on two major web navigation benchmarks -- Mind2Web and WebArena -- that collectively cover 1000+ tasks from 200+ domains across travel, shopping, and social media, among others. AWM substantially improves the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while reducing the number of steps taken to solve WebArena tasks successfully. Furthermore, online AWM robustly generalizes in cross-task, website, and domain evaluations, surpassing baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps widen.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07456",
        "abstract url": "https://arxiv.org/abs/2409.07456",
        "title": "Self-Evolving Depth-Supervised 3D Gaussian Splatting from Rendered Stereo Pairs",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting (GS) significantly struggles to accurately represent the underlying 3D scene geometry, resulting in inaccuracies and floating artifacts when rendering depth maps. In this paper, we address this limitation, undertaking a comprehensive analysis of the integration of depth priors throughout the optimization process of Gaussian primitives, and present a novel strategy for this purpose. This latter dynamically exploits depth cues from a readily available stereo network, processing virtual stereo pairs rendered by the GS model itself during training and achieving consistent self-improvement of the scene representation. Experimental results on three popular datasets, breaking ground as the first to assess depth accuracy for these models, validate our findings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "BMVC 2024. Project page: https://kuis-ai.github.io/StereoGS/"
    },
    {
        "paper id": "2409.07614",
        "abstract url": "https://arxiv.org/abs/2409.07614",
        "title": "FlowSep: Language-Queried Sound Separation with Rectified Flow Matching",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Language-queried audio source separation (LASS) focuses on separating sounds using textual descriptions of the desired sources. Current methods mainly use discriminative approaches, such as time-frequency masking, to separate target sounds and minimize interference from other sources. However, these models face challenges when separating overlapping soundtracks, which may lead to artifacts such as spectral holes or incomplete separation. Rectified flow matching (RFM), a generative model that establishes linear relations between the distribution of data and noise, offers superior theoretical properties and simplicity, but has not yet been explored in sound separation. In this work, we introduce FlowSep, a new generative model based on RFM for LASS tasks. FlowSep learns linear flow trajectories from noise to target source features within the variational autoencoder (VAE) latent space. During inference, the RFM-generated latent features are reconstructed into a mel-spectrogram via the pre-trained VAE decoder, followed by a pre-trained vocoder to synthesize the waveform. Trained on 1,680 hours of audio data, FlowSep outperforms the state-of-the-art models across multiple benchmarks, as evaluated with subjective and objective metrics. Additionally, our results show that FlowSep surpasses a diffusion-based LASS model in both separation quality and inference efficiency, highlighting its strong potential for audio source separation tasks. Code, pre-trained models and demos can be found at: https://audio-agi.github.io/FlowSep_demo/.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07645",
        "abstract url": "https://arxiv.org/abs/2409.07645",
        "title": "Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review",
        "rating": "0",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recent advancements in predicting pedestrian crossing intentions for Autonomous Vehicles using Computer Vision and Deep Neural Networks are promising. However, the black-box nature of DNNs poses challenges in understanding how the model works and how input features contribute to final predictions. This lack of interpretability delimits the trust in model performance and hinders informed decisions on feature selection, representation, and model optimisation; thereby affecting the efficacy of future research in the field. To address this, we introduce Context-aware Permutation Feature Importance (CAPFI), a novel approach tailored for pedestrian intention prediction. CAPFI enables more interpretability and reliable assessments of feature importance by leveraging subdivided scenario contexts, mitigating the randomness of feature values through targeted shuffling. This aims to reduce variance and prevent biased estimations in importance scores during permutations. We divide the Pedestrian Intention Estimation (PIE) dataset into 16 comparable context sets, measure the baseline performance of five distinct neural network architectures for intention prediction in each context, and assess input feature importance using CAPFI. We observed nuanced differences among models across various contextual characteristics. The research reveals the critical role of pedestrian bounding boxes and ego-vehicle speed in predicting pedestrian intentions, and potential prediction biases due to the speed feature through cross-context permutation evaluation. We propose an alternative feature representation by considering proximity change rate for rendering dynamic pedestrian-vehicle locomotion, thereby enhancing the contributions of input features to intention prediction. These findings underscore the importance of contextual features and their diversity to develop accurate and robust intent-predictive models.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.RO",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07683",
        "abstract url": "https://arxiv.org/abs/2409.07683",
        "title": "Open-Vocabulary Remote Sensing Image Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Open-vocabulary image semantic segmentation (OVS) seeks to segment images into semantic regions across an open set of categories. Existing OVS methods commonly depend on foundational vision-language models and utilize similarity computation to tackle OVS tasks. However, these approaches are predominantly tailored to natural images and struggle with the unique characteristics of remote sensing images, such as rapidly changing orientations and significant scale variations. These challenges complicate OVS tasks in earth vision, requiring specialized approaches. To tackle this dilemma, we propose the first OVS framework specifically designed for remote sensing imagery, drawing inspiration from the distinct remote sensing traits. Particularly, to address the varying orientations, we introduce a rotation-aggregative similarity computation module that generates orientation-adaptive similarity maps as initial semantic maps. These maps are subsequently refined at both spatial and categorical levels to produce more accurate semantic maps. Additionally, to manage significant scale changes, we integrate multi-scale image features into the upsampling process, resulting in the final scale-aware semantic masks. To advance OVS in earth vision and encourage reproducible research, we establish the first open-sourced OVS benchmark for remote sensing imagery, including four public remote sensing datasets. Extensive experiments on this benchmark demonstrate our proposed method achieves state-of-the-art performance. All codes and datasets are available at https://github.com/caoql98/OVRS.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07697",
        "abstract url": "https://arxiv.org/abs/2409.07697",
        "title": "Critically Damped Third-Order Langevin Dynamics",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "While systems analysis has been studied for decades in the context of control theory, it has only been recently used to improve the convergence of Denoising Diffusion Probabilistic Models. This work describes a novel improvement to Third- Order Langevin Dynamics (TOLD), a recent diffusion method that performs better than its predecessors. This improvement, abbreviated TOLD++, is carried out by critically damping the TOLD forward transition matrix similarly to Dockhorn's Critically-Damped Langevin Dynamics (CLD). Specifically, it exploits eigen-analysis of the forward transition matrix to derive the optimal set of dynamics under the original TOLD scheme. TOLD++ is theoretically guaranteed to converge faster than TOLD, and its faster convergence is verified on the Swiss Roll toy dataset and CIFAR-10 dataset according to the FID metric.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.SP",
            "eess.SY"
        ],
        "comment": "5 pages, 2 figures, 2 tables, submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.07747",
        "abstract url": "https://arxiv.org/abs/2409.07747",
        "title": "Multi-object event graph representation learning for Video Question Answering",
        "rating": "0",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Video question answering (VideoQA) is a task to predict the correct answer to questions posed about a given video. The system must comprehend spatial and temporal relationships among objects extracted from videos to perform causal and temporal reasoning. While prior works have focused on modeling individual object movements using transformer-based methods, they falter when capturing complex scenarios involving multiple objects (e.g., \"a boy is throwing a ball in a hoop\"). We propose a contrastive language event graph representation learning method called CLanG to address this limitation. Aiming to capture event representations associated with multiple objects, our method employs a multi-layer GNN-cluster module for adversarial graph representation learning, enabling contrastive learning between the question text and its relevant multi-object event graph. Our method outperforms a strong baseline, achieving up to 2.2% higher accuracy on two challenging VideoQA datasets, NExT-QA and TGIF-QA-R. In particular, it is 2.8% better than baselines in handling causal and temporal questions, highlighting its strength in reasoning multiple object-based events.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "presented at MIRU2024"
    },
    {
        "paper id": "2409.07028",
        "abstract url": "https://arxiv.org/abs/2409.07028",
        "title": "Dynamic Error-Bounded Hierarchical Matrices in Neural Network Compression",
        "rating": "-0.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents an innovative framework that integrates hierarchical matrix (H-matrix) compression techniques into the structure and training of Physics-Informed Neural Networks (PINNs). By leveraging the low-rank properties of matrix sub-blocks, the proposed dynamic, error-bounded H-matrix compression method significantly reduces computational complexity and storage requirements without compromising accuracy. This approach is rigorously compared to traditional compression techniques, such as Singular Value Decomposition (SVD), pruning, and quantization, demonstrating superior performance, particularly in maintaining the Neural Tangent Kernel (NTK) properties critical for the stability and convergence of neural networks. The findings reveal that H-matrix compression not only enhances training efficiency but also ensures the scalability and robustness of PINNs for complex, large-scale applications in physics-based modeling. This work offers a substantial contribution to the optimization of deep learning models, paving the way for more efficient and practical implementations of PINNs in real-world scenarios.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07032",
        "abstract url": "https://arxiv.org/abs/2409.07032",
        "title": "From optimal score matching to optimal sampling",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The recent, impressive advances in algorithmic generation of high-fidelity image, audio, and video are largely due to great successes in score-based diffusion models. A key implementing step is score matching, that is, the estimation of the score function of the forward diffusion process from training data. As shown in earlier literature, the total variation distance between the law of a sample generated from the trained diffusion model and the ground truth distribution can be controlled by the score matching risk. Despite the widespread use of score-based diffusion models, basic theoretical questions concerning exact optimal statistical rates for score estimation and its application to density estimation remain open. We establish the sharp minimax rate of score estimation for smooth, compactly supported densities. Formally, given \\(n\\) i.i.d. samples from an unknown \\(\u03b1\\)-H\u00f6lder density \\(f\\) supported on \\([-1, 1]\\), we prove the minimax rate of estimating the score function of the diffused distribution \\(f * \\mathcal{N}(0, t)\\) with respect to the score matching loss is \\(\\frac{1}{nt^2} \\wedge \\frac{1}{nt^{3/2}} \\wedge (t^{\u03b1-1} + n^{-2(\u03b1-1)/(2\u03b1+1)})\\) for all \\(\u03b1> 0\\) and \\(t \\ge 0\\). As a consequence, it is shown the law \\(\\hat{f}\\) of a sample generated from the diffusion model achieves the sharp minimax rate \\(\\bE(\\dTV(\\hat{f}, f)^2) \\lesssim n^{-2\u03b1/(2\u03b1+1)}\\) for all \\(\u03b1> 0\\) without any extraneous logarithmic terms which are prevalent in the literature, and without the need for early stopping which has been required for all existing procedures to the best of our knowledge.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "71 pages"
    },
    {
        "paper id": "2409.07154",
        "abstract url": "https://arxiv.org/abs/2409.07154",
        "title": "Recurrent Aggregators in Neural Algorithmic Reasoning",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Neural algorithmic reasoning (NAR) is an emerging field that seeks to design neural networks that mimic classical algorithmic computations. Today, graph neural networks (GNNs) are widely used in neural algorithmic reasoners due to their message passing framework and permutation equivariance. In this extended abstract, we challenge this design choice, and replace the equivariant aggregation function with a recurrent neural network. While seemingly counter-intuitive, this approach has appropriate grounding when nodes have a natural ordering -- and this is the case frequently in established reasoning benchmarks like CLRS-30. Indeed, our recurrent NAR (RNAR) model performs very strongly on such tasks, while handling many others gracefully. A notable achievement of RNAR is its decisive state-of-the-art result on the Heapsort and Quickselect tasks, both deemed as a significant challenge for contemporary neural algorithmic reasoners -- especially the latter, where RNAR achieves a mean micro-F1 score of 87%.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07202",
        "abstract url": "https://arxiv.org/abs/2409.07202",
        "title": "Heterogeneity-Aware Coordination for Federated Learning via Stitching Pre-trained blocks",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) coordinates multiple devices to collaboratively train a shared model while preserving data privacy. However, large memory footprint and high energy consumption during the training process excludes the low-end devices from contributing to the global model with their own data, which severely deteriorates the model performance in real-world scenarios. In this paper, we propose FedStitch, a hierarchical coordination framework for heterogeneous federated learning with pre-trained blocks. Unlike the traditional approaches that train the global model from scratch, for a new task, FedStitch composes the global model via stitching pre-trained blocks. Specifically, each participating client selects the most suitable block based on their local data from the candidate pool composed of blocks from pre-trained models. The server then aggregates the optimal block for stitching. This process iterates until a new stitched network is generated. Except for the new training paradigm, FedStitch consists of the following three core components: 1) an RL-weighted aggregator, 2) a search space optimizer deployed on the server side, and 3) a local energy optimizer deployed on each participating client. The RL-weighted aggregator helps to select the right block in the non-IID scenario, while the search space optimizer continuously reduces the size of the candidate block pool during stitching. Meanwhile, the local energy optimizer is designed to minimize energy consumption of each client while guaranteeing the overall training progress. The results demonstrate that compared to existing approaches, FedStitch improves the model accuracy up to 20.93%. At the same time, it achieves up to 8.12% speedup, reduces the memory footprint up to 79.5%, and achieves 89.41% energy saving at most during the learning procedure.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07204",
        "abstract url": "https://arxiv.org/abs/2409.07204",
        "title": "Online Graph Filtering Over Expanding Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph filters are a staple tool for processing signals over graphs in a multitude of downstream tasks. However, they are commonly designed for graphs with a fixed number of nodes, despite real-world networks typically grow over time. This topological evolution is often known up to a stochastic model, thus, making conventional graph filters ill-equipped to withstand such topological changes, their uncertainty, as well as the dynamic nature of the incoming data. To tackle these issues, we propose an online graph filtering framework by relying on online learning principles. We design filters for scenarios where the topology is both known and unknown, including a learner adaptive to such evolution. We conduct a regret analysis to highlight the role played by the different components such as the online algorithm, the filter order, and the growing graph model. Numerical experiments with synthetic and real data corroborate the proposed approach for graph signal inference tasks and show a competitive performance w.r.t. baselines and state-of-the-art alternatives.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07223",
        "abstract url": "https://arxiv.org/abs/2409.07223",
        "title": "Riemannian Federated Learning via Averaging Gradient Stream",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, federated learning has garnered significant attention as an efficient and privacy-preserving distributed learning paradigm. In the Euclidean setting, Federated Averaging (FedAvg) and its variants are a class of efficient algorithms for expected (empirical) risk minimization. This paper develops and analyzes a Riemannian Federated Averaging Gradient Stream (RFedAGS) algorithm, which is a generalization of FedAvg, to problems defined on a Riemannian manifold. Under standard assumptions, the convergence rate of RFedAGS with fixed step sizes is proven to be sublinear for an approximate stationary solution. If decaying step sizes are used, the global convergence is established. Furthermore, assuming that the objective obeys the Riemannian Polyak-\u0141ojasiewicz property, the optimal gaps generated by RFedAGS with fixed step size are linearly decreasing up to a tiny upper bound, meanwhile, if decaying step sizes are used, then the gaps sublinearly vanish. Numerical simulations conducted on synthetic and real-world data demonstrate the performance of the proposed RFedAGS.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07268",
        "abstract url": "https://arxiv.org/abs/2409.07268",
        "title": "Multi-Type Preference Learning: Empowering Preference-Based Reinforcement Learning with Equal Preferences",
        "rating": "-0.5",
        "keywords": [
            [
                "robotic manipulation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Preference-Based reinforcement learning (PBRL) learns directly from the preferences of human teachers regarding agent behaviors without needing meticulously designed reward functions. However, existing PBRL methods often learn primarily from explicit preferences, neglecting the possibility that teachers may choose equal preferences. This neglect may hinder the understanding of the agent regarding the task perspective of the teacher, leading to the loss of important information. To address this issue, we introduce the Equal Preference Learning Task, which optimizes the neural network by promoting similar reward predictions when the behaviors of two agents are labeled as equal preferences. Building on this task, we propose a novel PBRL method, Multi-Type Preference Learning (MTPL), which allows simultaneous learning from equal preferences while leveraging existing methods for learning from explicit preferences. To validate our approach, we design experiments applying MTPL to four existing state-of-the-art baselines across ten locomotion and robotic manipulation tasks in the DeepMind Control Suite. The experimental results indicate that simultaneous learning from both equal and explicit preferences enables the PBRL method to more comprehensively understand the feedback from teachers, thereby enhancing feedback efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2409.07310",
        "abstract url": "https://arxiv.org/abs/2409.07310",
        "title": "Optimizing Neural Network Performance and Interpretability with Diophantine Equation Encoding",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper explores the integration of Diophantine equations into neural network (NN) architectures to improve model interpretability, stability, and efficiency. By encoding and decoding neural network parameters as integer solutions to Diophantine equations, we introduce a novel approach that enhances both the precision and robustness of deep learning models. Our method integrates a custom loss function that enforces Diophantine constraints during training, leading to better generalization, reduced error bounds, and enhanced resilience against adversarial attacks. We demonstrate the efficacy of this approach through several tasks, including image classification and natural language processing, where improvements in accuracy, convergence, and robustness are observed. This study offers a new perspective on combining mathematical theory and machine learning to create more interpretable and efficient models.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07323",
        "abstract url": "https://arxiv.org/abs/2409.07323",
        "title": "Efficient and Unbiased Sampling of Boltzmann Distributions via Consistency Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models have shown promising potential for advancing Boltzmann Generators. However, two critical challenges persist: (1) inherent errors in samples due to model imperfections, and (2) the requirement of hundreds of functional evaluations (NFEs) to achieve high-quality samples. While existing solutions like importance sampling and distillation address these issues separately, they are often incompatible, as most distillation models lack the necessary density information for importance sampling. This paper introduces a novel sampling method that effectively combines Consistency Models (CMs) with importance sampling. We evaluate our approach on both synthetic energy functions and equivariant n-body particle systems. Our method produces unbiased samples using only 6-25 NFEs while achieving a comparable Effective Sample Size (ESS) to Denoising Diffusion Probabilistic Models (DDPMs) that require approximately 100 NFEs.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "10 pages, 4 figures"
    },
    {
        "paper id": "2409.07368",
        "abstract url": "https://arxiv.org/abs/2409.07368",
        "title": "Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces SGCode, a flexible prompt-optimizing system to generate secure code with large language models (LLMs). SGCode integrates recent prompt-optimization approaches with LLMs in a unified system accessible through front-end and back-end APIs, enabling users to 1) generate secure code, which is free of vulnerabilities, 2) review and share security analysis, and 3) easily switch from one prompt optimization approach to another, while providing insights on model and system performance. We populated SGCode on an AWS server with PromSec, an approach that optimizes prompts by combining an LLM and security tools with a lightweight generative adversarial graph neural network to detect and fix security vulnerabilities in the generated code. Extensive experiments show that SGCode is practical as a public tool to gain insights into the trade-offs between model utility, secure code generation, and system cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is available at: http://3.131.141.63:8501/.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07409",
        "abstract url": "https://arxiv.org/abs/2409.07409",
        "title": "Robust Robot Walker: Learning Agile Locomotion over Tiny Traps",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Quadruped robots must exhibit robust walking capabilities in practical applications. In this work, we propose a novel approach that enables quadruped robots to pass various small obstacles, or \"tiny traps\". Existing methods often rely on exteroceptive sensors, which can be unreliable for detecting such tiny traps. To overcome this limitation, our approach focuses solely on proprioceptive inputs. We introduce a two-stage training framework incorporating a contact encoder and a classification head to learn implicit representations of different traps. Additionally, we design a set of tailored reward functions to improve both the stability of training and the ease of deployment for goal-tracking tasks. To benefit further research, we design a new benchmark for tiny trap task. Extensive experiments in both simulation and real-world settings demonstrate the effectiveness and robustness of our method. Project Page: https://robust-robot-walker.github.io/",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "10 pages, 17 figures"
    },
    {
        "paper id": "2409.07448",
        "abstract url": "https://arxiv.org/abs/2409.07448",
        "title": "Introducing Perturb-ability Score (PS) to Enhance Robustness Against Evasion Adversarial Attacks on ML-NIDS",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes a novel Perturb-ability Score (PS) that can be used to identify Network Intrusion Detection Systems (NIDS) features that can be easily manipulated by attackers in the problem-space. We demonstrate that using PS to select only non-perturb-able features for ML-based NIDS maintains detection performance while enhancing robustness against adversarial attacks.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07454",
        "abstract url": "https://arxiv.org/abs/2409.07454",
        "title": "DreamMesh: Jointly Manipulating and Texturing Triangle Meshes for Text-to-3D Generation",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "NeRF",
                "radiance fields"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Learning radiance fields (NeRF) with powerful 2D diffusion models has garnered popularity for text-to-3D generation. Nevertheless, the implicit 3D representations of NeRF lack explicit modeling of meshes and textures over surfaces, and such surface-undefined way may suffer from the issues, e.g., noisy surfaces with ambiguous texture details or cross-view inconsistency. To alleviate this, we present DreamMesh, a novel text-to-3D architecture that pivots on well-defined surfaces (triangle meshes) to generate high-fidelity explicit 3D model. Technically, DreamMesh capitalizes on a distinctive coarse-to-fine scheme. In the coarse stage, the mesh is first deformed by text-guided Jacobians and then DreamMesh textures the mesh with an interlaced use of 2D diffusion models in a tuning free manner from multiple viewpoints. In the fine stage, DreamMesh jointly manipulates the mesh and refines the texture map, leading to high-quality triangle meshes with high-fidelity textured materials. Extensive experiments demonstrate that DreamMesh significantly outperforms state-of-the-art text-to-3D methods in faithfully generating 3D content with richer textual details and enhanced geometry. Our project page is available at https://dreammesh.github.io.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "ECCV 2024. Project page is available at \\url{https://dreammesh.github.io}"
    },
    {
        "paper id": "2409.07582",
        "abstract url": "https://arxiv.org/abs/2409.07582",
        "title": "Minimizing Embedding Distortion for Robust Out-of-Distribution Performance",
        "rating": "-0.5",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Foundational models, trained on vast and diverse datasets, have demonstrated remarkable capabilities in generalizing across different domains and distributions for various zero-shot tasks. Our work addresses the challenge of retaining these powerful generalization capabilities when adapting foundational models to specific downstream tasks through fine-tuning. To this end, we introduce a novel approach we call \"similarity loss\", which can be incorporated into the fine-tuning process of any task. By minimizing the distortion of fine-tuned embeddings from the pre-trained embeddings, our method strikes a balance between task-specific adaptation and preserving broad generalization abilities. We evaluate our approach on two diverse tasks: image classification on satellite imagery and face recognition, focusing on open-class and domain shift scenarios to assess out-of-distribution (OOD) performance. We demonstrate that this approach significantly improves OOD performance while maintaining strong in-distribution (ID) performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV 2024 workshop"
    },
    {
        "paper id": "2409.07585",
        "abstract url": "https://arxiv.org/abs/2409.07585",
        "title": "Efficient Localized Adaptation of Neural Weather Forecasting: A Case Study in the MENA Region",
        "rating": "-0.5",
        "keywords": [
            [
                "parameter-efficient",
                "PEFT",
                "efficient fine-tuning"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Accurate weather and climate modeling is critical for both scientific advancement and safeguarding communities against environmental risks. Traditional approaches rely heavily on Numerical Weather Prediction (NWP) models, which simulate energy and matter flow across Earth's systems. However, heavy computational requirements and low efficiency restrict the suitability of NWP, leading to a pressing need for enhanced modeling techniques. Neural network-based models have emerged as promising alternatives, leveraging data-driven approaches to forecast atmospheric variables. In this work, we focus on limited-area modeling and train our model specifically for localized region-level downstream tasks. As a case study, we consider the MENA region due to its unique climatic challenges, where accurate localized weather forecasting is crucial for managing water resources, agriculture and mitigating the impacts of extreme weather events. This targeted approach allows us to tailor the model's capabilities to the unique conditions of the region of interest. Our study aims to validate the effectiveness of integrating parameter-efficient fine-tuning (PEFT) methodologies, specifically Low-Rank Adaptation (LoRA) and its variants, to enhance forecast accuracy, as well as training speed, computational resource utilization, and memory efficiency in weather and climate modeling for specific regions.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.ao-ph"
        ],
        "comment": "Our codebase and pre-trained models can be accessed at: [this url](https://github.com/akhtarvision/weather-regional)"
    },
    {
        "paper id": "2409.07712",
        "abstract url": "https://arxiv.org/abs/2409.07712",
        "title": "Virtual Node Generation for Node Classification in Sparsely-Labeled Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "In the broader machine learning literature, data-generation methods demonstrate promising results by generating additional informative training examples via augmenting sparse labels. Such methods are less studied in graphs due to the intricate dependencies among nodes in complex topology structures. This paper presents a novel node generation method that infuses a small set of high-quality synthesized nodes into the graph as additional labeled nodes to optimally expand the propagation of labeled information. By simply infusing additional nodes, the framework is orthogonal to the graph learning and downstream classification techniques, and thus is compatible with most popular graph pre-training (self-supervised learning), semi-supervised learning, and meta-learning methods. The contribution lies in designing the generated node set by solving a novel optimization problem. The optimization places the generated nodes in a manner that: (1) minimizes the classification loss to guarantee training accuracy and (2) maximizes label propagation to low-confidence nodes in the downstream task to ensure high-quality propagation. Theoretically, we show that the above dual optimization maximizes the global confidence of node classification. Our Experiments demonstrate statistically significant performance improvements over 14 baselines on 10 publicly available datasets.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07718",
        "abstract url": "https://arxiv.org/abs/2409.07718",
        "title": "Unsupervised node clustering via contrastive hard sampling",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "This paper introduces a fine-grained contrastive learning scheme for unsupervised node clustering. Previous clustering methods only focus on a small feature set (class-dependent features), which demonstrates explicit clustering characteristics, ignoring the rest of the feature spaces (class-invariant features). This paper exploits class-invariant features via graph contrastive learning to discover additional high-quality features for unsupervised clustering. We formulate a novel node-level fine-grained augmentation framework for self-supervised learning, which iteratively identifies competitive contrastive samples from the whole feature spaces, in the form of positive and negative examples of node relations. While positive examples of node relations are usually expressed as edges in graph homophily, negative examples are implicit without a direct edge. We show, however, that simply sampling nodes beyond the local neighborhood results in less competitive negative pairs, that are less effective for contrastive learning. Inspired by counterfactual augmentation, we instead sample competitive negative node relations by creating virtual nodes that inherit (in a self-supervised fashion) class-invariant features, while altering class-dependent features, creating contrasting pairs that lie closer to the boundary and offering better contrast. Consequently, our experiments demonstrate significant improvements in supervised node clustering tasks on six baselines and six real-world social network datasets.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07725",
        "abstract url": "https://arxiv.org/abs/2409.07725",
        "title": "GRE^2-MDCL: Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph representation learning has emerged as a powerful tool for preserving graph topology when mapping nodes to vector representations, enabling various downstream tasks such as node classification and community detection. However, most current graph neural network models face the challenge of requiring extensive labeled data, which limits their practical applicability in real-world scenarios where labeled data is scarce. To address this challenge, researchers have explored Graph Contrastive Learning (GCL), which leverages enhanced graph data and contrastive learning techniques. While promising, existing GCL methods often struggle with effectively capturing both local and global graph structures, and balancing the trade-off between nodelevel and graph-level representations. In this work, we propose Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning (GRE2-MDCL). Our model introduces a novel triple network architecture with a multi-head attention GNN as the core. GRE2-MDCL first globally and locally augments the input graph using SVD and LAGNN techniques. It then constructs a multidimensional contrastive loss, incorporating cross-network, cross-view, and neighbor contrast, to optimize the model. Extensive experiments on benchmark datasets Cora, Citeseer, and PubMed demonstrate that GRE2-MDCL achieves state-of-the-art performance, with average accuracies of 82.5%, 72.5%, and 81.6% respectively. Visualizations further show tighter intra-cluster aggregation and clearer inter-cluster boundaries, highlighting the effectiveness of our framework in improving upon baseline GCL models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07734",
        "abstract url": "https://arxiv.org/abs/2409.07734",
        "title": "DFDG: Data-Free Dual-Generator Adversarial Distillation for One-Shot Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) is a distributed machine learning scheme in which clients jointly participate in the collaborative training of a global model by sharing model information rather than their private datasets. In light of concerns associated with communication and privacy, one-shot FL with a single communication round has emerged as a de facto promising solution. However, existing one-shot FL methods either require public datasets, focus on model homogeneous settings, or distill limited knowledge from local models, making it difficult or even impractical to train a robust global model. To address these limitations, we propose a new data-free dual-generator adversarial distillation method (namely DFDG) for one-shot FL, which can explore a broader local models' training space via training dual generators. DFDG is executed in an adversarial manner and comprises two parts: dual-generator training and dual-model distillation. In dual-generator training, we delve into each generator concerning fidelity, transferability and diversity to ensure its utility, and additionally tailor the cross-divergence loss to lessen the overlap of dual generators' output spaces. In dual-model distillation, the trained dual generators work together to provide the training data for updates of the global model. At last, our extensive experiments on various image classification tasks show that DFDG achieves significant performance gains in accuracy compared to SOTA baselines.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "comment": "Accepted by ICDM2024 main conference (long paper)"
    },
    {
        "paper id": "2409.07016",
        "abstract url": "https://arxiv.org/abs/2409.07016",
        "title": "Improving Anomalous Sound Detection via Low-Rank Adaptation Fine-Tuning of Pre-Trained Audio Models",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Anomalous Sound Detection (ASD) has gained significant interest through the application of various Artificial Intelligence (AI) technologies in industrial settings. Though possessing great potential, ASD systems can hardly be readily deployed in real production sites due to the generalization problem, which is primarily caused by the difficulty of data collection and the complexity of environmental factors. This paper introduces a robust ASD model that leverages audio pre-trained models. Specifically, we fine-tune these models using machine operation data, employing SpecAug as a data augmentation strategy. Additionally, we investigate the impact of utilizing Low-Rank Adaptation (LoRA) tuning instead of full fine-tuning to address the problem of limited data for fine-tuning. Our experiments on the DCASE2023 Task 2 dataset establish a new benchmark of 77.75% on the evaluation set, with a significant improvement of 6.48% compared with previous state-of-the-art (SOTA) models, including top-tier traditional convolutional networks and speech pre-trained models, which demonstrates the effectiveness of audio pre-trained models with LoRA tuning. Ablation studies are also conducted to showcase the efficacy of the proposed scheme.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07021",
        "abstract url": "https://arxiv.org/abs/2409.07021",
        "title": "An Improved Height Difference Based Model of Height Profile for Drop-on-Demand 3D Printing With UV Curable Ink",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper proposes an improved height profile model for drop-on-demand 3D printing with UV curable ink. It is extended from a previously validated model and computes height profile indirectly from volume and area propagation to ensure volume conservation. To accommodate 2D patterns using multiple passes, volume change and area change within region of interest are modeled as a piecewise function of height difference before drop deposition. Model coefficients are experimentally obtained and validated with bootstrapping of experimental samples. Six different drop patterns are experimentally validated. The RMS height profile errors for 2D patterns from the proposed model are consistently smaller than existing models from literature and are on the same level as 1D patterns reported in our previous publication.",
        "subjects": [
            "physics.flu-dyn",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07022",
        "abstract url": "https://arxiv.org/abs/2409.07022",
        "title": "Insight Any Instance: Promptable Instance Segmentation for Remote Sensing Images",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Instance segmentation of remote sensing images (RSIs) is an essential task for a wide range of applications such as land planning and intelligent transport. Instance segmentation of RSIs is constantly plagued by the unbalanced ratio of foreground and background and limited instance size. And most of the instance segmentation models are based on deep feature learning and contain operations such as multiple downsampling, which is harmful to instance segmentation of RSIs, and thus the performance is still limited. Inspired by the recent superior performance of prompt learning in visual tasks, we propose a new prompt paradigm to address the above issues. Based on the existing instance segmentation model, firstly, a local prompt module is designed to mine local prompt information from original local tokens for specific instances; secondly, a global-to-local prompt module is designed to model the contextual information from the global tokens to the local tokens where the instances are located for specific instances. Finally, a proposal's area loss function is designed to add a decoupling dimension for proposals on the scale to better exploit the potential of the above two prompt modules. It is worth mentioning that our proposed approach can extend the instance segmentation model to a promptable instance segmentation model, i.e., to segment the instances with the specific boxes prompt. The time consumption for each promptable instance segmentation process is only 40 ms. The paper evaluates the effectiveness of our proposed approach based on several existing models in four instance segmentation datasets of RSIs, and thorough experiments prove that our proposed approach is effective for addressing the above issues and is a competitive model for instance segmentation of RSIs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07035",
        "abstract url": "https://arxiv.org/abs/2409.07035",
        "title": "Approximately counting maximal independent set is equivalent to #SAT",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A maximal independent set is an independent set that is not a subset of any other independent set. It is also the key problem of mathematics, computer science, and other fields. A counting problem is a type of computational problem that associated with the number of solutions. Besides, counting problems help us better understand several fields such as algorithm analysis, complexity theory, artificial intelligence, etc. The problem of counting maximal independent sets is #P-complete. So it is natural to think about approximate counting for maximal independent sets problem. In this article, we study the complexity of approximately counting maximal independent sets. Specifically, we are the first to prove that the #MIS problem is AP-interreducible with the #SAT of a given general graph.",
        "subjects": [
            "cs.CC",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07040",
        "abstract url": "https://arxiv.org/abs/2409.07040",
        "title": "Retinex-RAWMamba: Bridging Demosaicing and Denoising for Low-Light RAW Image Enhancement",
        "rating": "-1",
        "keywords": [
            [
                "Image Enhancement"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Low-light image enhancement, particularly in cross-domain tasks such as mapping from the raw domain to the sRGB domain, remains a significant challenge. Many deep learning-based methods have been developed to address this issue and have shown promising results in recent years. However, single-stage methods, which attempt to unify the complex mapping across both domains, leading to limited denoising performance. In contrast, two-stage approaches typically decompose a raw image with color filter arrays (CFA) into a four-channel RGGB format before feeding it into a neural network. However, this strategy overlooks the critical role of demosaicing within the Image Signal Processing (ISP) pipeline, leading to color distortions under varying lighting conditions, especially in low-light scenarios. To address these issues, we design a novel Mamba scanning mechanism, called RAWMamba, to effectively handle raw images with different CFAs. Furthermore, we present a Retinex Decomposition Module (RDM) grounded in Retinex prior, which decouples illumination from reflectance to facilitate more effective denoising and automatic non-linear exposure correction. By bridging demosaicing and denoising, better raw image enhancement is achieved. Experimental evaluations conducted on public datasets SID and MCR demonstrate that our proposed RAWMamba achieves state-of-the-art performance on cross-domain mapping.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07091",
        "abstract url": "https://arxiv.org/abs/2409.07091",
        "title": "Learning Task Specifications from Demonstrations as Probabilistic Automata",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Specifying tasks for robotic systems traditionally requires coding expertise, deep domain knowledge, and significant time investment. While learning from demonstration offers a promising alternative, existing methods often struggle with tasks of longer horizons. To address this limitation, we introduce a computationally efficient approach for learning probabilistic deterministic finite automata (PDFA) that capture task structures and expert preferences directly from demonstrations. Our approach infers sub-goals and their temporal dependencies, producing an interpretable task specification that domain experts can easily understand and adjust. We validate our method through experiments involving object manipulation tasks, showcasing how our method enables a robot arm to effectively replicate diverse expert strategies while adapting to changing conditions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07115",
        "abstract url": "https://arxiv.org/abs/2409.07115",
        "title": "Attention Down-Sampling Transformer, Relative Ranking and Self-Consistency for Blind Image Quality Assessment",
        "rating": "-1",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The no-reference image quality assessment is a challenging domain that addresses estimating image quality without the original reference. We introduce an improved mechanism to extract local and non-local information from images via different transformer encoders and CNNs. The utilization of Transformer encoders aims to mitigate locality bias and generate a non-local representation by sequentially processing CNN features, which inherently capture local visual structures. Establishing a stronger connection between subjective and objective assessments is achieved through sorting within batches of images based on relative distance information. A self-consistency approach to self-supervision is presented, explicitly addressing the degradation of no-reference image quality assessment (NR-IQA) models under equivariant transformations. Our approach ensures model robustness by maintaining consistency between an image and its horizontally flipped equivalent. Through empirical evaluation of five popular image quality assessment datasets, the proposed model outperforms alternative algorithms in the context of no-reference image quality assessment datasets, especially on smaller datasets. Codes are available at \\href{https://github.com/mas94/ADTRS}{https://github.com/mas94/ADTRS}",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted in International Conference on Image Processing (ICIP)"
    },
    {
        "paper id": "2409.07116",
        "abstract url": "https://arxiv.org/abs/2409.07116",
        "title": "iKalibr-RGBD: Partially-Specialized Target-Free Visual-Inertial Spatiotemporal Calibration For RGBDs via Continuous-Time Velocity Estimation",
        "rating": "-1",
        "keywords": [
            [
                "RGBD",
                "depth"
            ]
        ],
        "abstract": "Visual-inertial systems have been widely studied and applied in the last two decades, mainly due to their low cost and power consumption, small footprint, and high availability. Such a trend simultaneously leads to a large amount of visual-inertial calibration methods being presented, as accurate spatiotemporal parameters between sensors are a prerequisite for visual-inertial fusion. In our previous work, i.e., iKalibr, a continuous-time-based visual-inertial calibration method was proposed as a part of one-shot multi-sensor resilient spatiotemporal calibration. While requiring no artificial target brings considerable convenience, computationally expensive pose estimation is demanded in initialization and batch optimization, limiting its availability. Fortunately, this could be vastly improved for the RGBDs with additional depth information, by employing mapping-free ego-velocity estimation instead of mapping-based pose estimation. In this paper, we present the continuous-time ego-velocity estimation-based RGBD-inertial spatiotemporal calibration, termed as iKalibr-RGBD, which is also targetless but computationally efficient. The general pipeline of iKalibr-RGBD is inherited from iKalibr, composed of a rigorous initialization procedure and several continuous-time batch optimizations. The implementation of iKalibr-RGBD is open-sourced at (https://github.com/Unsigned-Long/iKalibr) to benefit the research community.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07128",
        "abstract url": "https://arxiv.org/abs/2409.07128",
        "title": "Deep Learning Techniques for Hand Vein Biometrics: A Comprehensive Review",
        "rating": "-1",
        "keywords": [
            [
                "Biometrics"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Biometric authentication has garnered significant attention as a secure and efficient method of identity verification. Among the various modalities, hand vein biometrics, including finger vein, palm vein, and dorsal hand vein recognition, offer unique advantages due to their high accuracy, low susceptibility to forgery, and non-intrusiveness. The vein patterns within the hand are highly complex and distinct for each individual, making them an ideal biometric identifier. Additionally, hand vein recognition is contactless, enhancing user convenience and hygiene compared to other modalities such as fingerprint or iris recognition. Furthermore, the veins are internally located, rendering them less susceptible to damage or alteration, thus enhancing the security and reliability of the biometric system. The combination of these factors makes hand vein biometrics a highly effective and secure method for identity verification. This review paper delves into the latest advancements in deep learning techniques applied to finger vein, palm vein, and dorsal hand vein recognition. It encompasses all essential fundamentals of hand vein biometrics, summarizes publicly available datasets, and discusses state-of-the-art metrics used for evaluating the three modes. Moreover, it provides a comprehensive overview of suggested approaches for finger, palm, dorsal, and multimodal vein techniques, offering insights into the best performance achieved, data augmentation techniques, and effective transfer learning methods, along with associated pretrained deep learning models. Additionally, the review addresses research challenges faced and outlines future directions and perspectives, encouraging researchers to enhance existing methods and propose innovative techniques.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07131",
        "abstract url": "https://arxiv.org/abs/2409.07131",
        "title": "Reranking Laws for Language Generation: A Communication-Theoretic Perspective",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "To ensure large language models (LLMs) are used safely, one must reduce their propensity to hallucinate or to generate unacceptable answers. A simple and often used strategy is to first let the LLM generate multiple hypotheses and then employ a reranker to choose the best one. In this paper, we draw a parallel between this strategy and the use of redundancy to decrease the error rate in noisy communication channels. We conceptualize the generator as a sender transmitting multiple descriptions of a message through parallel noisy channels. The receiver decodes the message by ranking the (potentially corrupted) descriptions and selecting the one found to be most reliable. We provide conditions under which this protocol is asymptotically error-free (i.e., yields an acceptable answer almost surely) even in scenarios where the reranker is imperfect (governed by Mallows or Zipf-Mandelbrot models) and the channel distributions are statistically dependent. We use our framework to obtain reranking laws which we validate empirically on two real-world tasks using LLMs: text-to-code generation with DeepSeek-Coder 7B and machine translation of medical data with TowerInstruct 13B.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2409.07132",
        "abstract url": "https://arxiv.org/abs/2409.07132",
        "title": "LLM-based feature generation from text for interpretable machine learning",
        "rating": "-1",
        "keywords": [
            [
                "grammatical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Existing text representations such as embeddings and bag-of-words are not suitable for rule learning due to their high dimensionality and absent or questionable feature-level interpretability. This article explores whether large language models (LLMs) could address this by extracting a small number of interpretable features from text. We demonstrate this process on two datasets (CORD-19 and M17+) containing several thousand scientific articles from multiple disciplines and a target being a proxy for research impact. An evaluation based on testing for the statistically significant correlation with research impact has shown that LLama 2-generated features are semantically meaningful. We consequently used these generated features in text classification to predict the binary target variable representing the citation rate for the CORD-19 dataset and the ordinal 5-class target representing an expert-awarded grade in the M17+ dataset. Machine-learning models trained on the LLM-generated features provided similar predictive performance to the state-of-the-art embedding model SciBERT for scientific text. The LLM used only 62 features compared to 768 features in SciBERT embeddings, and these features were directly interpretable, corresponding to notions such as article methodological rigor, novelty, or grammatical correctness. As the final step, we extract a small number of well-interpretable action rules. Consistently competitive results obtained with the same LLM feature set across both thematically diverse datasets show that this approach generalizes across domains.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07151",
        "abstract url": "https://arxiv.org/abs/2409.07151",
        "title": "Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment",
        "rating": "-1",
        "keywords": [
            [
                "Text-to-Speech"
            ],
            [
                "cs.AI",
                "eess.AS"
            ]
        ],
        "abstract": "Second language (L2) learners can improve their pronunciation by imitating golden speech, especially when the speech that aligns with their respective speech characteristics. This study explores the hypothesis that learner-specific golden speech generated with zero-shot text-to-speech (ZS-TTS) techniques can be harnessed as an effective metric for measuring the pronunciation proficiency of L2 learners. Building on this exploration, the contributions of this study are at least two-fold: 1) design and development of a systematic framework for assessing the ability of a synthesis model to generate golden speech, and 2) in-depth investigations of the effectiveness of using golden speech in automatic pronunciation assessment (APA). Comprehensive experiments conducted on the L2-ARCTIC and Speechocean762 benchmark datasets suggest that our proposed modeling can yield significant performance improvements with respect to various assessment metrics in relation to some prior arts. To our knowledge, this study is the first to explore the role of golden speech in both ZS-TTS and APA, offering a promising regime for computer-assisted pronunciation training (CAPT).",
        "subjects": [
            "eess.AS",
            "cs.AI"
        ],
        "comment": "11 pages, 4 figures, 4 tables"
    },
    {
        "paper id": "2409.07155",
        "abstract url": "https://arxiv.org/abs/2409.07155",
        "title": "Compliant Blind Handover Control for Human-Robot Collaboration",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "This paper presents a Human-Robot Blind Handover architecture within the context of Human-Robot Collaboration (HRC). The focus lies on a blind handover scenario where the operator is intentionally faced away, focused in a task, and requires an object from the robot. In this context, it is imperative for the robot to autonomously manage the entire handover process. Key considerations include ensuring safety while handing the object to the operator's hand, and detect the proper timing to release the object. The article explores strategies to navigate these challenges, emphasizing the need for a robot to operate safely and independently in facilitating blind handovers, thereby contributing to the advancement of HRC protocols and fostering a natural and efficient collaboration between humans and robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07158",
        "abstract url": "https://arxiv.org/abs/2409.07158",
        "title": "Collaborative Conversation in Safe Multimodal Human-Robot Collaboration",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "In the context of Human-Robot Collaboration (HRC), it is crucial that the two actors are able to communicate with each other in a natural and efficient manner. The absence of a communication interface is often a cause of undesired slowdowns. On one hand, this is because unforeseen events may occur, leading to errors. On the other hand, due to the close contact between humans and robots, the speed must be reduced significantly to comply with safety standard ISO/TS 15066. In this paper, we propose a novel architecture that enables operators and robots to communicate efficiently, emulating human-to-human dialogue, while addressing safety concerns. This approach aims to establish a communication framework that not only facilitates collaboration but also reduces undesired speed reduction. Through the use of a predictive simulator, we can anticipate safety-related limitations, ensuring smoother workflows, minimizing risks, and optimizing efficiency. The overall architecture has been validated with a UR10e and compared with a state of the art technique. The results show a significant improvement in user experience, with a corresponding 23% reduction in execution times and a 50% decrease in robot downtime.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07163",
        "abstract url": "https://arxiv.org/abs/2409.07163",
        "title": "Mamba Policy: Towards Efficient 3D Diffusion Policy with Hybrid Selective State Models",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have been widely employed in the field of 3D manipulation due to their efficient capability to learn distributions, allowing for precise prediction of action trajectories. However, diffusion models typically rely on large parameter UNet backbones as policy networks, which can be challenging to deploy on resource-constrained devices. Recently, the Mamba model has emerged as a promising solution for efficient modeling, offering low computational complexity and strong performance in sequence modeling. In this work, we propose the Mamba Policy, a lighter but stronger policy that reduces the parameter count by over 80% compared to the original policy network while achieving superior performance. Specifically, we introduce the XMamba Block, which effectively integrates input information with conditional features and leverages a combination of Mamba and Attention mechanisms for deep feature extraction. Extensive experiments demonstrate that the Mamba Policy excels on the Adroit, Dexart, and MetaWorld datasets, requiring significantly fewer computational resources. Additionally, we highlight the Mamba Policy's enhanced robustness in long-horizon scenarios compared to baseline methods and explore the performance of various Mamba variants within the Mamba Policy framework. Our project page is in https://andycao1125.github.io/mamba_policy/.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2409.07167",
        "abstract url": "https://arxiv.org/abs/2409.07167",
        "title": "H$_2$O$_2$RAM: A High-Performance Hierarchical Doubly Oblivious RAM",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The combination of Oblivious RAM (ORAM) with Trusted Execution Environments (TEE) has found numerous real-world applications due to their complementary nature. TEEs alleviate the performance bottlenecks of ORAM, such as network bandwidth and roundtrip latency, and ORAM provides general-purpose protection for TEE applications against attacks exploiting memory access patterns. The defining property of this combination, which sets it apart from traditional ORAM designs, is its ability to ensure that memory accesses, both inside and outside of TEEs, are made oblivious, thus termed doubly oblivious RAM (O$_2$RAM). Efforts to develop O$_2$RAM with enhanced performance are ongoing. In this work, we propose H$_2$O$_2$RAM, a high-performance doubly oblivious RAM construction. The distinguishing feature of our approach, compared to the existing tree-based doubly oblivious designs, is its first adoption of the hierarchical framework that enjoys inherently better data locality and parallelization. While the latest hierarchical solution, FutORAMa, achieves concrete efficiency in the classic client-server model by leveraging a relaxed assumption of sublinear-sized client-side private memory, adapting it to our scenario poses challenges due to the conflict between this relaxed assumption and our doubly oblivious requirement. To this end, we introduce several new efficient oblivious components to build a high-performance hierarchical O$_2$RAM (H$_2$O$_2$RAM). We implement our design and evaluate it on various scenarios. The results indicate that H$_2$O$_2$RAM reduces execution time by up to $\\sim 10^3$ times and saves memory usage by $5\\sim44$ times compared to state-of-the-art solutions.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07170",
        "abstract url": "https://arxiv.org/abs/2409.07170",
        "title": "Learning Efficient Recursive Numeral Systems via Reinforcement Learning",
        "rating": "-1",
        "keywords": [
            [
                "grammar"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The emergence of mathematical concepts, such as number systems, is an understudied area in AI for mathematics and reasoning. It has previously been shown Carlsson et al. (2021) that by using reinforcement learning (RL), agents can derive simple approximate and exact-restricted numeral systems. However, it is a major challenge to show how more complex recursive numeral systems, similar to the one utilised in English, could arise via a simple learning mechanism such as RL. Here, we introduce an approach towards deriving a mechanistic explanation of the emergence of recursive number systems where we consider an RL agent which directly optimizes a lexicon under a given meta-grammar. Utilising a slightly modified version of the seminal meta-grammar of Hurford (1975), we demonstrate that our RL agent can effectively modify the lexicon towards Pareto-optimal configurations which are comparable to those observed within human numeral systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.07172",
        "abstract url": "https://arxiv.org/abs/2409.07172",
        "title": "Swin-LiteMedSAM: A Lightweight Box-Based Segment Anything Model for Large-Scale Medical Image Datasets",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "diagnosis",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical imaging is essential for the diagnosis and treatment of diseases, with medical image segmentation as a subtask receiving high attention. However, automatic medical image segmentation models are typically task-specific and struggle to handle multiple scenarios, such as different imaging modalities and regions of interest. With the introduction of the Segment Anything Model (SAM), training a universal model for various clinical scenarios has become feasible. Recently, several Medical SAM (MedSAM) methods have been proposed, but these models often rely on heavy image encoders to achieve high performance, which may not be practical for real-world applications due to their high computational demands and slow inference speed. To address this issue, a lightweight version of the MedSAM (LiteMedSAM) can provide a viable solution, achieving high performance while requiring fewer resources and less time. In this work, we introduce Swin-LiteMedSAM, a new variant of LiteMedSAM. This model integrates the tiny Swin Transformer as the image encoder, incorporates multiple types of prompts, including box-based points and scribble generated from a given bounding box, and establishes skip connections between the image encoder and the mask decoder. In the \\textit{Segment Anything in Medical Images on Laptop} challenge (CVPR 2024), our approach strikes a good balance between segmentation performance and speed, demonstrating significantly improved overall results across multiple modalities compared to the LiteMedSAM baseline provided by the challenge organizers. Our proposed model achieved a DSC score of \\textbf{0.8678} and an NSD score of \\textbf{0.8844} on the validation set. On the final test set, it attained a DSC score of \\textbf{0.8193} and an NSD score of \\textbf{0.8461}, securing fourth place in the challenge.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2409.07220",
        "abstract url": "https://arxiv.org/abs/2409.07220",
        "title": "Watchlist Challenge: 3rd Open-set Face Detection and Identification",
        "rating": "-1",
        "keywords": [
            [
                "biometrics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the current landscape of biometrics and surveillance, the ability to accurately recognize faces in uncontrolled settings is paramount. The Watchlist Challenge addresses this critical need by focusing on face detection and open-set identification in real-world surveillance scenarios. This paper presents a comprehensive evaluation of participating algorithms, using the enhanced UnConstrained College Students (UCCS) dataset with new evaluation protocols. In total, four participants submitted four face detection and nine open-set face recognition systems. The evaluation demonstrates that while detection capabilities are generally robust, closed-set identification performance varies significantly, with models pre-trained on large-scale datasets showing superior performance. However, open-set scenarios require further improvement, especially at higher true positive identification rates, i.e., lower thresholds.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for presentation at IJCB 2024"
    },
    {
        "paper id": "2409.07226",
        "abstract url": "https://arxiv.org/abs/2409.07226",
        "title": "Muskits-ESPnet: A Comprehensive Toolkit for Singing Voice Synthesis in New Paradigm",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This research presents Muskits-ESPnet, a versatile toolkit that introduces new paradigms to Singing Voice Synthesis (SVS) through the application of pretrained audio models in both continuous and discrete approaches. Specifically, we explore discrete representations derived from SSL models and audio codecs and offer significant advantages in versatility and intelligence, supporting multi-format inputs and adaptable data processing workflows for various SVS models. The toolkit features automatic music score error detection and correction, as well as a perception auto-evaluation module to imitate human subjective evaluating scores. Muskits-ESPnet is available at \\url{https://github.com/espnet/espnet}.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by ACMMM 2024 demo track"
    },
    {
        "paper id": "2409.07228",
        "abstract url": "https://arxiv.org/abs/2409.07228",
        "title": "Reusability and Modifiability in Robotics Software (Extended Version)",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "robot"
            ]
        ],
        "abstract": "We show the design of the software of the microcontroller unit of a weeding robot based on the Process Control architectural style and design patterns. The design consists of 133 modules resulting from using 8 design patterns for a total of 30 problems. As a result the design yields more reusable components and an easily modifiable and extensible program. Design documentation is also presented. Finally, the implementation (12 KLOC of C++ code) is empirically evaluated to prove that the design does not produce an inefficient implementation.",
        "subjects": [
            "cs.RO",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07256",
        "abstract url": "https://arxiv.org/abs/2409.07256",
        "title": "MRAC Track 1: 2nd Workshop on Multimodal, Generative and Responsible Affective Computing",
        "rating": "-1",
        "keywords": [
            [
                "physiological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the rapid advancements in multimodal generative technology, Affective Computing research has provoked discussion about the potential consequences of AI systems equipped with emotional intelligence. Affective Computing involves the design, evaluation, and implementation of Emotion AI and related technologies aimed at improving people's lives. Designing a computational model in affective computing requires vast amounts of multimodal data, including RGB images, video, audio, text, and physiological signals. Moreover, Affective Computing research is deeply engaged with ethical considerations at various stages-from training emotionally intelligent models on large-scale human data to deploying these models in specific applications. Fundamentally, the development of any AI system must prioritize its impact on humans, aiming to augment and enhance human abilities rather than replace them, while drawing inspiration from human intelligence in a safe and responsible manner. The MRAC 2024 Track 1 workshop seeks to extend these principles from controlled, small-scale lab environments to real-world, large-scale contexts, emphasizing responsible development. The workshop also aims to highlight the potential implications of generative technology, along with the ethical consequences of its use, to researchers and industry professionals. To the best of our knowledge, this is the first workshop series to comprehensively address the full spectrum of multimodal, generative affective computing from a responsible AI perspective, and this is the second iteration of this workshop. Webpage: https://react-ws.github.io/2024/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ACM MM Workshop 2024. Workshop webpage: https://react-ws.github.io/2024/"
    },
    {
        "paper id": "2409.07265",
        "abstract url": "https://arxiv.org/abs/2409.07265",
        "title": "Cross-Dialect Text-To-Speech in Pitch-Accent Language Incorporating Multi-Dialect Phoneme-Level BERT",
        "rating": "-1",
        "keywords": [
            [
                "Text-To-Speech"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We explore cross-dialect text-to-speech (CD-TTS), a task to synthesize learned speakers' voices in non-native dialects, especially in pitch-accent languages. CD-TTS is important for developing voice agents that naturally communicate with people across regions. We present a novel TTS model comprising three sub-modules to perform competitively at this task. We first train a backbone TTS model to synthesize dialect speech from a text conditioned on phoneme-level accent latent variables (ALVs) extracted from speech by a reference encoder. Then, we train an ALV predictor to predict ALVs tailored to a target dialect from input text leveraging our novel multi-dialect phoneme-level BERT. We conduct multi-dialect TTS experiments and evaluate the effectiveness of our model by comparing it with a baseline derived from conventional dialect TTS methods. The results show that our model improves the dialectal naturalness of synthetic speech in CD-TTS.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "Accepted by IEEE SLT 2024"
    },
    {
        "paper id": "2409.07283",
        "abstract url": "https://arxiv.org/abs/2409.07283",
        "title": "Deterministic approximation for the volume of the truncated fractional matching polytope",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "We give a deterministic polynomial-time approximation scheme (FPTAS) for the volume of the truncated fractional matching polytope for graphs of maximum degree $\u0394$, where the truncation is by restricting each variable to the interval $[0,\\frac{1+\u03b4}\u0394]$, and $\u03b4\\le \\frac{C}\u0394$ for some constant $C>0$. We also generalise our result to the fractional matching polytope for hypergraphs of maximum degree $\u0394$ and maximum hyperedge size $k$, truncated by $[0,\\frac{1+\u03b4}\u0394]$ as well, where $\u03b4\\le C\u0394^{-\\frac{2k-3}{k-1}}k^{-1}$ for some constant $C>0$. The latter result generalises both the first result for graphs (when $k=2$), and a result by Bencs and Regts (2024) for the truncated independence polytope (when $\u0394=2$). Our approach is based on the cluster expansion technique.",
        "subjects": [
            "cs.DS",
            "cs.DM",
            "math.CO"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2409.07314",
        "abstract url": "https://arxiv.org/abs/2409.07314",
        "title": "MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "healthcare",
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid development of Large Language Models (LLMs) for healthcare applications has spurred calls for holistic evaluation beyond frequently-cited benchmarks like USMLE, to better reflect real-world performance. While real-world assessments are valuable indicators of utility, they often lag behind the pace of LLM evolution, likely rendering findings obsolete upon deployment. This temporal disconnect necessitates a comprehensive upfront evaluation that can guide model selection for specific clinical applications. We introduce MEDIC, a framework assessing LLMs across five critical dimensions of clinical competence: medical reasoning, ethics and bias, data and language understanding, in-context learning, and clinical safety. MEDIC features a novel cross-examination framework quantifying LLM performance across areas like coverage and hallucination detection, without requiring reference outputs. We apply MEDIC to evaluate LLMs on medical question-answering, safety, summarization, note generation, and other tasks. Our results show performance disparities across model sizes, baseline vs medically finetuned models, and have implications on model selection for applications requiring specific model strengths, such as low hallucination or lower cost of inference. MEDIC's multifaceted evaluation reveals these performance trade-offs, bridging the gap between theoretical capabilities and practical implementation in healthcare settings, ensuring that the most promising models are identified and adapted for diverse healthcare applications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Technical report"
    },
    {
        "paper id": "2409.07321",
        "abstract url": "https://arxiv.org/abs/2409.07321",
        "title": "Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in deep learning have markedly improved autonomous driving (AD) models, particularly end-to-end systems that integrate perception, prediction, and planning stages, achieving state-of-the-art performance. However, these models remain vulnerable to adversarial attacks, where human-imperceptible perturbations can disrupt decision-making processes. While adversarial training is an effective method for enhancing model robustness against such attacks, no prior studies have focused on its application to end-to-end AD models. In this paper, we take the first step in adversarial training for end-to-end AD models and present a novel Module-wise Adaptive Adversarial Training (MA2T). However, extending conventional adversarial training to this context is highly non-trivial, as different stages within the model have distinct objectives and are strongly interconnected. To address these challenges, MA2T first introduces Module-wise Noise Injection, which injects noise before the input of different modules, targeting training models with the guidance of overall objectives rather than each independent module loss. Additionally, we introduce Dynamic Weight Accumulation Adaptation, which incorporates accumulated weight changes to adaptively learn and adjust the loss weights of each module based on their contributions (accumulated reduction rates) for better balance and robust training. To demonstrate the efficacy of our defense, we conduct extensive experiments on the widely-used nuScenes dataset across several end-to-end AD models under both white-box and black-box attacks, where our method outperforms other baselines by large margins (+5-10%). Moreover, we validate the robustness of our defense through closed-loop evaluation in the CARLA simulation environment, showing improved resilience even against natural corruption.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.07327",
        "abstract url": "https://arxiv.org/abs/2409.07327",
        "title": "Current Symmetry Group Equivariant Convolution Frameworks for Representation Learning",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "graphs"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Euclidean deep learning is often inadequate for addressing real-world signals where the representation space is irregular and curved with complex topologies. Interpreting the geometric properties of such feature spaces has become paramount in obtaining robust and compact feature representations that remain unaffected by nontrivial geometric transformations, which vanilla CNNs cannot effectively handle. Recognizing rotation, translation, permutation, or scale symmetries can lead to equivariance properties in the learned representations. This has led to notable advancements in computer vision and machine learning tasks under the framework of geometric deep learning, as compared to their invariant counterparts. In this report, we emphasize the importance of symmetry group equivariant deep learning models and their realization of convolution-like operations on graphs, 3D shapes, and non-Euclidean spaces by leveraging group theory and symmetry. We categorize them as regular, steerable, and PDE-based convolutions and thoroughly examine the inherent symmetries of their input spaces and ensuing representations. We also outline the mathematical link between group convolutions or message aggregation operations and the concept of equivariance. The report also highlights various datasets, their application scopes, limitations, and insightful observations on future directions to serve as a valuable reference and stimulate further research in this emerging discipline.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "31 pages, 4 figures"
    },
    {
        "paper id": "2409.07361",
        "abstract url": "https://arxiv.org/abs/2409.07361",
        "title": "Quantifying Knee Cartilage Shape and Lesion: From Image to Metrics",
        "rating": "-1",
        "keywords": [
            [
                "biomarkers",
                "medical",
                "Lesion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Imaging features of knee articular cartilage have been shown to be potential imaging biomarkers for knee osteoarthritis. Despite recent methodological advancements in image analysis techniques like image segmentation, registration, and domain-specific image computing algorithms, only a few works focus on building fully automated pipelines for imaging feature extraction. In this study, we developed a deep-learning-based medical image analysis application for knee cartilage morphometrics, CartiMorph Toolbox (CMT). We proposed a 2-stage joint template learning and registration network, CMT-reg. We trained the model using the OAI-ZIB dataset and assessed its performance in template-to-image registration. The CMT-reg demonstrated competitive results compared to other state-of-the-art models. We integrated the proposed model into an automated pipeline for the quantification of cartilage shape and lesion (full-thickness cartilage loss, specifically). The toolbox provides a comprehensive, user-friendly solution for medical image analysis and data visualization. The software and models are available at https://github.com/YongchengYAO/CMT-AMAI24paper .",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "The paper will be in the conference proceedings of AMAI 2024. See the conference website: https://sites.google.com/view/amai2024/home"
    },
    {
        "paper id": "2409.07388",
        "abstract url": "https://arxiv.org/abs/2409.07388",
        "title": "Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective",
        "rating": "-1",
        "keywords": [
            [
                "facial",
                "physiological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal affective computing (MAC) has garnered increasing attention due to its broad applications in analyzing human behaviors and intentions, especially in text-dominated multimodal affective computing field. This survey presents the recent trends of multimodal affective computing from NLP perspective through four hot tasks: multimodal sentiment analysis, multimodal emotion recognition in conversation, multimodal aspect-based sentiment analysis and multimodal multi-label emotion recognition. The goal of this survey is to explore the current landscape of multimodal affective research, identify development trends, and highlight the similarities and differences across various tasks, offering a comprehensive report on the recent progress in multimodal affective computing from an NLP perspective. This survey covers the formalization of tasks, provides an overview of relevant works, describes benchmark datasets, and details the evaluation metrics for each task. Additionally, it briefly discusses research in multimodal affective computing involving facial expressions, acoustic signals, physiological signals, and emotion causes. Additionally, we discuss the technical approaches, challenges, and future directions in multimodal affective computing. To support further research, we released a repository that compiles related works in multimodal affective computing, providing detailed resources and references for the community.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07422",
        "abstract url": "https://arxiv.org/abs/2409.07422",
        "title": "Controllable retinal image synthesis using conditional StyleGAN and latent space manipulation for improved diagnosis and grading of diabetic retinopathy",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "retinal",
                "lesion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Diabetic retinopathy (DR) is a consequence of diabetes mellitus characterized by vascular damage within the retinal tissue. Timely detection is paramount to mitigate the risk of vision loss. However, training robust grading models is hindered by a shortage of annotated data, particularly for severe cases. This paper proposes a framework for controllably generating high-fidelity and diverse DR fundus images, thereby improving classifier performance in DR grading and detection. We achieve comprehensive control over DR severity and visual features (optic disc, vessel structure, lesion areas) within generated images solely through a conditional StyleGAN, eliminating the need for feature masks or auxiliary networks. Specifically, leveraging the SeFa algorithm to identify meaningful semantics within the latent space, we manipulate the DR images generated conditionally on grades, further enhancing the dataset diversity. Additionally, we propose a novel, effective SeFa-based data augmentation strategy, helping the classifier focus on discriminative regions while ignoring redundant features. Using this approach, a ResNet50 model trained for DR detection achieves 98.09% accuracy, 99.44% specificity, 99.45% precision, and an F1-score of 98.09%. Moreover, incorporating synthetic images generated by conditional StyleGAN into ResNet50 training for DR grading yields 83.33% accuracy, a quadratic kappa score of 87.64%, 95.67% specificity, and 72.24% precision. Extensive experiments conducted on the APTOS 2019 dataset demonstrate the exceptional realism of the generated images and the superior performance of our classifier compared to recent studies.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "30 pages, 17 figures"
    },
    {
        "paper id": "2409.07424",
        "abstract url": "https://arxiv.org/abs/2409.07424",
        "title": "Towards Fairer Health Recommendations: finding informative unbiased samples via Word Sense Disambiguation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Health"
            ],
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "There have been growing concerns around high-stake applications that rely on models trained with biased data, which consequently produce biased predictions, often harming the most vulnerable. In particular, biased medical data could cause health-related applications and recommender systems to create outputs that jeopardize patient care and widen disparities in health outcomes. A recent framework titled Fairness via AI posits that, instead of attempting to correct model biases, researchers must focus on their root causes by using AI to debias data. Inspired by this framework, we tackle bias detection in medical curricula using NLP models, including LLMs, and evaluate them on a gold standard dataset containing 4,105 excerpts annotated by medical experts for bias from a large corpus. We build on previous work by coauthors which augments the set of negative samples with non-annotated text containing social identifier terms. However, some of these terms, especially those related to race and ethnicity, can carry different meanings (e.g., \"white matter of spinal cord\"). To address this issue, we propose the use of Word Sense Disambiguation models to refine dataset quality by removing irrelevant sentences. We then evaluate fine-tuned variations of BERT models as well as GPT models with zero- and few-shot prompting. We found LLMs, considered SOTA on many NLP tasks, unsuitable for bias detection, while fine-tuned BERT models generally perform well across all evaluated metrics.",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "Accepted for long presentation at the FAcctRec @ Recsys 2024"
    },
    {
        "paper id": "2409.07426",
        "abstract url": "https://arxiv.org/abs/2409.07426",
        "title": "Deep Neural Network-Based Sign Language Recognition: A Comprehensive Approach Using Transfer Learning with Explainability",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "To promote inclusion and ensuring effective communication for those who rely on sign language as their main form of communication, sign language recognition (SLR) is crucial. Sign language recognition (SLR) seamlessly incorporates with diverse technology, enhancing accessibility for the deaf community by facilitating their use of digital platforms, video calls, and communication devices. To effectively solve this problem, we suggest a novel solution that uses a deep neural network to fully automate sign language recognition. This methodology integrates sophisticated preprocessing methodologies to optimise the overall performance. The architectures resnet, inception, xception, and vgg are utilised to selectively categorise images of sign language. We prepared a DNN architecture and merged it with the pre-processing architectures. In the post-processing phase, we utilised the SHAP deep explainer, which is based on cooperative game theory, to quantify the influence of specific features on the output of a machine learning model. Bhutanese-Sign-Language (BSL) dataset was used for training and testing the suggested technique. While training on Bhutanese-Sign-Language (BSL) dataset, overall ResNet50 with the DNN model performed better accuracy which is 98.90%. Our model's ability to provide informational clarity was assessed using the SHAP (SHapley Additive exPlanations) method. In part to its considerable robustness and reliability, the proposed methodological approach can be used to develop a fully automated system for sign language recognition.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07447",
        "abstract url": "https://arxiv.org/abs/2409.07447",
        "title": "StereoCrafter: Diffusion-based Generation of Long and High-fidelity Stereoscopic 3D from Monocular Videos",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Diffusion",
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a novel framework for converting 2D videos to immersive stereoscopic 3D, addressing the growing demand for 3D content in immersive experience. Leveraging foundation models as priors, our approach overcomes the limitations of traditional methods and boosts the performance to ensure the high-fidelity generation required by the display devices. The proposed system consists of two main steps: depth-based video splatting for warping and extracting occlusion mask, and stereo video inpainting. We utilize pre-trained stable video diffusion as the backbone and introduce a fine-tuning protocol for the stereo video inpainting task. To handle input video with varying lengths and resolutions, we explore auto-regressive strategies and tiled processing. Finally, a sophisticated data processing pipeline has been developed to reconstruct a large-scale and high-quality dataset to support our training. Our framework demonstrates significant improvements in 2D-to-3D video conversion, offering a practical solution for creating immersive content for 3D devices like Apple Vision Pro and 3D displays. In summary, this work contributes to the field by presenting an effective method for generating high-quality stereoscopic videos from monocular input, potentially transforming how we experience digital media.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "11 pages, 10 figures"
    },
    {
        "paper id": "2409.07450",
        "abstract url": "https://arxiv.org/abs/2409.07450",
        "title": "VMAS: Video-to-Music Generation via Semantic Alignment in Web Music Videos",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We present a framework for learning to generate background music from video inputs. Unlike existing works that rely on symbolic musical annotations, which are limited in quantity and diversity, our method leverages large-scale web videos accompanied by background music. This enables our model to learn to generate realistic and diverse music. To accomplish this goal, we develop a generative video-music Transformer with a novel semantic video-music alignment scheme. Our model uses a joint autoregressive and contrastive learning objective, which encourages the generation of music aligned with high-level video content. We also introduce a novel video-beat alignment scheme to match the generated music beats with the low-level motions in the video. Lastly, to capture fine-grained visual cues in a video needed for realistic background music generation, we introduce a new temporal video encoder architecture, allowing us to efficiently process videos consisting of many densely sampled frames. We train our framework on our newly curated DISCO-MV dataset, consisting of 2.2M video-music samples, which is orders of magnitude larger than any prior datasets used for video music generation. Our method outperforms existing approaches on the DISCO-MV and MusicCaps datasets according to various music generation evaluation metrics, including human evaluation. Results are available at https://genjib.github.io/project_page/VMAs/index.html",
        "subjects": [
            "cs.MM",
            "cs.CV",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Project Page: https://genjib.github.io/project_page/VMAs/index.html"
    },
    {
        "paper id": "2409.07452",
        "abstract url": "https://arxiv.org/abs/2409.07452",
        "title": "Hi3D: Pursuing High-Resolution Image-to-3D Generation with Video Diffusion Models",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite having tremendous progress in image-to-3D generation, existing methods still struggle to produce multi-view consistent images with high-resolution textures in detail, especially in the paradigm of 2D diffusion that lacks 3D awareness. In this work, we present High-resolution Image-to-3D model (Hi3D), a new video diffusion based paradigm that redefines a single image to multi-view images as 3D-aware sequential image generation (i.e., orbital video generation). This methodology delves into the underlying temporal consistency knowledge in video diffusion model that generalizes well to geometry consistency across multiple views in 3D generation. Technically, Hi3D first empowers the pre-trained video diffusion model with 3D-aware prior (camera pose condition), yielding multi-view images with low-resolution texture details. A 3D-aware video-to-video refiner is learnt to further scale up the multi-view images with high-resolution texture details. Such high-resolution multi-view images are further augmented with novel views through 3D Gaussian Splatting, which are finally leveraged to obtain high-fidelity meshes via 3D reconstruction. Extensive experiments on both novel view synthesis and single view reconstruction demonstrate that our Hi3D manages to produce superior multi-view consistency images with highly-detailed textures. Source code and data are available at \\url{https://github.com/yanghb22-fdu/Hi3D-Official}.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "ACM Multimedia 2024. Source code is available at \\url{https://github.com/yanghb22-fdu/Hi3D-Official}"
    },
    {
        "paper id": "2409.07560",
        "abstract url": "https://arxiv.org/abs/2409.07560",
        "title": "Dynamic Fairness Perceptions in Human-Robot Interaction",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "People deeply care about how fairly they are treated by robots. The established paradigm for probing fairness in Human-Robot Interaction (HRI) involves measuring the perception of the fairness of a robot at the conclusion of an interaction. However, such an approach is limited as interactions vary over time, potentially causing changes in fairness perceptions as well. To validate this idea, we conducted a 2x2 user study with a mixed design (N=40) where we investigated two factors: the timing of unfair robot actions (early or late in an interaction) and the beneficiary of those actions (either another robot or the participant). Our results show that fairness judgments are not static. They can shift based on the timing of unfair robot actions. Further, we explored using perceptions of three key factors (reduced welfare, conduct, and moral transgression) proposed by a Fairness Theory from Organizational Justice to predict momentary perceptions of fairness in our study. Interestingly, we found that the reduced welfare and moral transgression factors were better predictors than all factors together. Our findings reinforce the idea that unfair robot behavior can shape perceptions of group dynamics and trust towards a robot and pave the path to future research directions on moment-to-moment fairness perceptions",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07566",
        "abstract url": "https://arxiv.org/abs/2409.07566",
        "title": "EchoDFKD: Data-Free Knowledge Distillation for Cardiac Ultrasound Segmentation using Synthetic Data",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Cardiac"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The application of machine learning to medical ultrasound videos of the heart, i.e., echocardiography, has recently gained traction with the availability of large public datasets. Traditional supervised tasks, such as ejection fraction regression, are now making way for approaches focusing more on the latent structure of data distributions, as well as generative methods. We propose a model trained exclusively by knowledge distillation, either on real or synthetical data, involving retrieving masks suggested by a teacher model. We achieve state-of-the-art (SOTA) values on the task of identifying end-diastolic and end-systolic frames. By training the model only on synthetic data, it reaches segmentation capabilities close to the performance when trained on real data with a significantly reduced number of weights. A comparison with the 5 main existing methods shows that our method outperforms the others in most cases. We also present a new evaluation method that does not require human annotation and instead relies on a large auxiliary model. We show that this method produces scores consistent with those obtained from human annotations. Relying on the integrated knowledge from a vast amount of records, this method overcomes certain inherent limitations of human annotator labeling. Code: https://github.com/GregoirePetit/EchoDFKD",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07581",
        "abstract url": "https://arxiv.org/abs/2409.07581",
        "title": "Violence detection in videos using deep recurrent and convolutional neural networks",
        "rating": "-1",
        "keywords": [
            [
                "crimes"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Violence and abnormal behavior detection research have known an increase of interest in recent years, due mainly to a rise in crimes in large cities worldwide. In this work, we propose a deep learning architecture for violence detection which combines both recurrent neural networks (RNNs) and 2-dimensional convolutional neural networks (2D CNN). In addition to video frames, we use optical flow computed using the captured sequences. CNN extracts spatial characteristics in each frame, while RNN extracts temporal characteristics. The use of optical flow allows to encode the movements in the scenes. The proposed approaches reach the same level as the state-of-the-art techniques and sometime surpass them. It was validated on 3 databases achieving good results.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "11 pages, 7 figures, 2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)"
    },
    {
        "paper id": "2409.07584",
        "abstract url": "https://arxiv.org/abs/2409.07584",
        "title": "DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer's Early Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "3D"
            ],
            [
                "Diagnosis",
                "disease"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In the field of Alzheimer's disease diagnosis, segmentation and classification tasks are inherently interconnected. Sharing knowledge between models for these tasks can significantly improve training efficiency, particularly when training data is scarce. However, traditional knowledge distillation techniques often struggle to bridge the gap between segmentation and classification due to the distinct nature of tasks and different model architectures. To address this challenge, we propose a dual-stream pipeline that facilitates cross-task and cross-architecture knowledge sharing. Our approach introduces a dual-stream embedding module that unifies feature representations from segmentation and classification models, enabling dimensional integration of these features to guide the classification model. We validated our method on multiple 3D datasets for Alzheimer's disease diagnosis, demonstrating significant improvements in classification performance, especially on small datasets. Furthermore, we extended our pipeline with a residual temporal attention mechanism for early diagnosis, utilizing images taken before the atrophy of patients' brain mass. This advancement shows promise in enabling diagnosis approximately six months earlier in mild and asymptomatic stages, offering critical time for intervention.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "8 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2409.07586",
        "abstract url": "https://arxiv.org/abs/2409.07586",
        "title": "Analyzing the Impact of Copying-and-Pasting Vulnerable Solidity Code Snippets from Question-and-Answer Websites",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Ethereum smart contracts are executable programs deployed on a blockchain. Once deployed, they cannot be updated due to their inherent immutability. Moreover, they often manage valuable assets that are worth millions of dollars, making them attractive targets for attackers. The introduction of vulnerabilities in programs due to the reuse of vulnerable code posted on Q&A websites such as Stack Overflow is not a new issue. However, little effort has been made to analyze the extent of this issue on deployed smart contracts. In this paper, we conduct a study on the impact of vulnerable code reuse from Q&A websites during the development of smart contracts and provide tools uniquely fit to detect vulnerable code patterns in complete and incomplete Smart Contract code. This paper proposes a pattern-based vulnerability detection tool that is able to analyze code snippets (i.e., incomplete code) as well as full smart contracts based on the concept of code property graphs. We also propose a methodology that leverages fuzzy hashing to quickly detect code clones of vulnerable snippets among deployed smart contracts. Our results show that our vulnerability search, as well as our code clone detection, are comparable to state-of-the-art while being applicable to code snippets. Our large-scale study on 18,660 code snippets reveals that 4,596 of them are vulnerable, out of which 616 can be found in 7,852 deployed smart contracts. These results highlight that the reuse of vulnerable code snippets is indeed an issue in currently deployed smart contracts.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07587",
        "abstract url": "https://arxiv.org/abs/2409.07587",
        "title": "Exploring LLMs for Malware Detection: Review, Framework Design, and Countermeasure Approaches",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The rising use of Large Language Models (LLMs) to create and disseminate malware poses a significant cybersecurity challenge due to their ability to generate and distribute attacks with ease. A single prompt can initiate a wide array of malicious activities. This paper addresses this critical issue through a multifaceted approach. First, we provide a comprehensive overview of LLMs and their role in malware detection from diverse sources. We examine five specific applications of LLMs: Malware honeypots, identification of text-based threats, code analysis for detecting malicious intent, trend analysis of malware, and detection of non-standard disguised malware. Our review includes a detailed analysis of the existing literature and establishes guiding principles for the secure use of LLMs. We also introduce a classification scheme to categorize the relevant literature. Second, we propose performance metrics to assess the effectiveness of LLMs in these contexts. Third, we present a risk mitigation framework designed to prevent malware by leveraging LLMs. Finally, we evaluate the performance of our proposed risk mitigation strategies against various factors and demonstrate their effectiveness in countering LLM-enabled malware. The paper concludes by suggesting future advancements and areas requiring deeper exploration in this fascinating field of artificial intelligence.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "26 pages, 7 figures, 4 tables"
    },
    {
        "paper id": "2409.07631",
        "abstract url": "https://arxiv.org/abs/2409.07631",
        "title": "HERL: Tiered Federated Learning with Adaptive Homomorphic Encryption using Reinforcement Learning",
        "rating": "-1",
        "keywords": [
            [
                "Federated Learning"
            ]
        ],
        "abstract": "Federated Learning is a well-researched approach for collaboratively training machine learning models across decentralized data while preserving privacy. However, integrating Homomorphic Encryption to ensure data confidentiality introduces significant computational and communication overheads, particularly in heterogeneous environments where clients have varying computational capacities and security needs. In this paper, we propose HERL, a Reinforcement Learning-based approach that uses Q-Learning to dynamically optimize encryption parameters, specifically the polynomial modulus degree, $N$, and the coefficient modulus, $q$, across different client tiers. Our proposed method involves first profiling and tiering clients according to the chosen clustering approach, followed by dynamically selecting the most suitable encryption parameters using an RL-agent. Experimental results demonstrate that our approach significantly reduces the computational overhead while maintaining utility and a high level of security. Empirical results show that HERL improves utility by 17%, reduces the convergence time by up to 24%, and increases convergence efficiency by up to 30%, with minimal security loss.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07649",
        "abstract url": "https://arxiv.org/abs/2409.07649",
        "title": "DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures",
        "rating": "-1",
        "keywords": [
            [
                "avatar"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Audio-driven talking video generation has advanced significantly, but existing methods often depend on video-to-video translation techniques and traditional generative networks like GANs and they typically generate taking heads and co-speech gestures separately, leading to less coherent outputs. Furthermore, the gestures produced by these methods often appear overly smooth or subdued, lacking in diversity, and many gesture-centric approaches do not integrate talking head generation. To address these limitations, we introduce DiffTED, a new approach for one-shot audio-driven TED-style talking video generation from a single image. Specifically, we leverage a diffusion model to generate sequences of keypoints for a Thin-Plate Spline motion model, precisely controlling the avatar's animation while ensuring temporally coherent and diverse gestures. This innovative approach utilizes classifier-free guidance, empowering the gestures to flow naturally with the audio input without relying on pre-trained classifiers. Experiments demonstrate that DiffTED generates temporally coherent talking videos with diverse co-speech gestures.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07650",
        "abstract url": "https://arxiv.org/abs/2409.07650",
        "title": "Foundation Models Boost Low-Level Perceptual Similarity Metrics",
        "rating": "-1",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "For full-reference image quality assessment (FR-IQA) using deep-learning approaches, the perceptual similarity score between a distorted image and a reference image is typically computed as a distance measure between features extracted from a pretrained CNN or more recently, a Transformer network. Often, these intermediate features require further fine-tuning or processing with additional neural network layers to align the final similarity scores with human judgments. So far, most IQA models based on foundation models have primarily relied on the final layer or the embedding for the quality score estimation. In contrast, this work explores the potential of utilizing the intermediate features of these foundation models, which have largely been unexplored so far in the design of low-level perceptual similarity metrics. We demonstrate that the intermediate features are comparatively more effective. Moreover, without requiring any training, these metrics can outperform both traditional and state-of-the-art learned metrics by utilizing distance measures between the features.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Code: https://github.com/abhijay9/ZS-IQA"
    },
    {
        "paper id": "2409.07689",
        "abstract url": "https://arxiv.org/abs/2409.07689",
        "title": "Entropy Contractions in Markov Chains: Half-Step, Full-Step and Continuous-Time",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This paper considers the speed of convergence (mixing) of a finite Markov kernel $P$ with respect to the Kullback-Leibler divergence (entropy). Given a Markov kernel one defines either a discrete-time Markov chain (with the $n$-step transition kernel given by the matrix power $P^n$) or a continuous-time Markov process (with the time-$t$ transition kernel given by $e^{t(P-\\mathrm{Id})}$). The contraction of entropy for $n=1$ or $t=0+$ are characterized by the famous functional inequalities, the strong data processing inequality (SDPI) and the modified log-Sobolev inequality (MLSI), respectively. When $P=KK^*$ is written as the product of a kernel and its adjoint, one could also consider the ``half-step'' contraction, which is the SDPI for $K$, while the ``full-step'' contraction refers to the SDPI for $P$. The work [DMLM03] claimed that these contraction coefficients (half-step, full-step, and continuous-time) are generally within a constant factor of each other. We disprove this and related conjectures by working out a number of different counterexamples. In particular, we construct (a) a continuous-time Markov process that contracts arbitrarily faster than its discrete-time counterpart; and (b) a kernel $P$ such that $P^{m+1}$ contracts arbitrarily better than $P^m$. Hence, our main conclusion is that the four standard inequalities comparing five common notions of entropy and variance contraction are generally not improvable. In the process of analyzing the counterexamples, we survey and sharpen the tools for bounding the contraction coefficients and characterize properties of extremizers of the respective functional inequalities. As our examples range from Bernoulli-Laplace model, random walks on graphs, to birth-death chains, the paper is also intended as a tutorial on computing MLSI, SDPI and other constants for these types of commonly occurring Markov chains.",
        "subjects": [
            "math.PR",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07691",
        "abstract url": "https://arxiv.org/abs/2409.07691",
        "title": "Enhancing Q&A Text Retrieval with Ranking Models: Benchmarking, fine-tuning and deploying Rerankers for RAG",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Ranking models play a crucial role in enhancing overall accuracy of text retrieval systems. These multi-stage systems typically utilize either dense embedding models or sparse lexical indices to retrieve relevant passages based on a given query, followed by ranking models that refine the ordering of the candidate passages by its relevance to the query. This paper benchmarks various publicly available ranking models and examines their impact on ranking accuracy. We focus on text retrieval for question-answering tasks, a common use case for Retrieval-Augmented Generation systems. Our evaluation benchmarks include models some of which are commercially viable for industrial applications. We introduce a state-of-the-art ranking model, NV-RerankQA-Mistral-4B-v3, which achieves a significant accuracy increase of ~14% compared to pipelines with other rerankers. We also provide an ablation study comparing the fine-tuning of ranking models with different sizes, losses and self-attention mechanisms. Finally, we discuss challenges of text retrieval pipelines with ranking models in real-world industry applications, in particular the trade-offs among model size, ranking accuracy and system requirements like indexing and serving latency / throughput.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted for the 1st Workshop on GenAI and RAG Systems for Enterprise @ CIKM 2024"
    },
    {
        "paper id": "2409.07730",
        "abstract url": "https://arxiv.org/abs/2409.07730",
        "title": "Music auto-tagging in the long tail: A few-shot approach",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In the realm of digital music, using tags to efficiently organize and retrieve music from extensive databases is crucial for music catalog owners. Human tagging by experts is labor-intensive but mostly accurate, whereas automatic tagging through supervised learning has approached satisfying accuracy but is restricted to a predefined set of training tags. Few-shot learning offers a viable solution to expand beyond this small set of predefined tags by enabling models to learn from only a few human-provided examples to understand tag meanings and subsequently apply these tags autonomously. We propose to integrate few-shot learning methodology into multi-label music auto-tagging by using features from pre-trained models as inputs to a lightweight linear classifier, also known as a linear probe. We investigate different popular pre-trained features, as well as different few-shot parametrizations with varying numbers of classes and samples per class. Our experiments demonstrate that a simple model with pre-trained features can achieve performance close to state-of-the-art models while using significantly less training data, such as 20 samples per tag. Additionally, our linear probe performs competitively with leading models when trained on the entire training dataset. The results show that this transfer learning-based few-shot approach could effectively address the issue of automatically assigning long-tail tags with only limited labeled data.",
        "subjects": [
            "eess.AS",
            "cs.IR",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "Published in Audio Engineering Society NY Show 2024 as a Peer Reviewed (Category 1) paper"
    },
    {
        "paper id": "2409.07025",
        "abstract url": "https://arxiv.org/abs/2409.07025",
        "title": "CPSample: Classifier Protected Sampling for Guarding Training Data During Diffusion",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models have a tendency to exactly replicate their training data, especially when trained on small datasets. Most prior work has sought to mitigate this problem by imposing differential privacy constraints or masking parts of the training data, resulting in a notable substantial decrease in image quality. We present CPSample, a method that modifies the sampling process to prevent training data replication while preserving image quality. CPSample utilizes a classifier that is trained to overfit on random binary labels attached to the training data. CPSample then uses classifier guidance to steer the generation process away from the set of points that can be classified with high certainty, a set that includes the training data. CPSample achieves FID scores of 4.97 and 2.97 on CIFAR-10 and CelebA-64, respectively, without producing exact replicates of the training data. Unlike prior methods intended to guard the training images, CPSample only requires training a classifier rather than retraining a diffusion model, which is computationally cheaper. Moreover, our technique provides diffusion models with greater robustness against membership inference attacks, wherein an adversary attempts to discern which images were in the model's training dataset. We show that CPSample behaves like a built-in rejection sampler, and we demonstrate its capabilities to prevent mode collapse in Stable Diffusion.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07033",
        "abstract url": "https://arxiv.org/abs/2409.07033",
        "title": "E-commerce Webpage Recommendation Scheme Base on Semantic Mining and Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In e-commerce websites, web mining web page recommendation technology has been widely used. However, recommendation solutions often cannot meet the actual application needs of online shopping users. To address this problem, this paper proposes an e-commerce web page recommendation solution that combines semantic web mining and BP neural networks. First, the web logs of user searches are processed, and 5 features are extracted: content priority, time consumption priority, online shopping users' explicit/implicit feedback on the website, recommendation semantics and input deviation amount. Then, these features are used as input features of the BP neural network to classify and identify the priority of the final output web page. Finally, the web pages are sorted according to priority and recommended to users. This project uses book sales webpages as samples for experiments. The results show that this solution can quickly and accurately identify the webpages required by users.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2409.01137"
    },
    {
        "paper id": "2409.07057",
        "abstract url": "https://arxiv.org/abs/2409.07057",
        "title": "A Novel Voting System for Medical Catalogues in National Health Insurance",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "Health",
                "healthcare"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "This study explores the conceptual development of a medical insurance catalogue voting system. The methodology is centred on creating a model where doctors would vote on treatment inclusions, aiming to demonstrate transparency and integrity. The results from Monte Carlo simulations suggest a robust consensus on the selection of medicines and treatments. Further theoretical investigations propose incorporating a patient outcome-based incentive mechanism. This conceptual approach could enhance decision-making in healthcare by aligning stakeholder interests with patient outcomes, aiming for an optimised, equitable insurance catalogue with potential blockchain-based smart-contracts to ensure transparency and integrity.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "9 pages, 3 figures"
    },
    {
        "paper id": "2409.07089",
        "abstract url": "https://arxiv.org/abs/2409.07089",
        "title": "TrialSynth: Generation of Synthetic Sequential Clinical Trial Data",
        "rating": "-1.5",
        "keywords": [
            [
                "Clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Analyzing data from past clinical trials is part of the ongoing effort to optimize the design, implementation, and execution of new clinical trials and more efficiently bring life-saving interventions to market. While there have been recent advances in the generation of static context synthetic clinical trial data, due to both limited patient availability and constraints imposed by patient privacy needs, the generation of fine-grained synthetic time-sequential clinical trial data has been challenging. Given that patient trajectories over an entire clinical trial are of high importance for optimizing trial design and efforts to prevent harmful adverse events, there is a significant need for the generation of high-fidelity time-sequence clinical trial data. Here we introduce TrialSynth, a Variational Autoencoder (VAE) designed to address the specific challenges of generating synthetic time-sequence clinical trial data. Distinct from related clinical data VAE methods, the core of our method leverages Hawkes Processes (HP), which are particularly well-suited for modeling event-type and time gap prediction needed to capture the structure of sequential clinical trial data. Our experiments demonstrate that TrialSynth surpasses the performance of other comparable methods that can generate sequential clinical trial data, in terms of both fidelity and in enabling the generation of highly accurate event sequences across multiple real-world sequential event datasets with small patient source populations when using minimal external information. Notably, our empirical findings highlight that TrialSynth not only outperforms existing clinical sequence-generating methods but also produces data with superior utility while empirically preserving patient privacy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07109",
        "abstract url": "https://arxiv.org/abs/2409.07109",
        "title": "Advancing On-Device Neural Network Training with TinyPropv2: Dynamic, Sparse, and Efficient Backpropagation",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This study introduces TinyPropv2, an innovative algorithm optimized for on-device learning in deep neural networks, specifically designed for low-power microcontroller units. TinyPropv2 refines sparse backpropagation by dynamically adjusting the level of sparsity, including the ability to selectively skip training steps. This feature significantly lowers computational effort without substantially compromising accuracy. Our comprehensive evaluation across diverse datasets CIFAR 10, CIFAR100, Flower, Food, Speech Command, MNIST, HAR, and DCASE2020 reveals that TinyPropv2 achieves near-parity with full training methods, with an average accuracy drop of only around 1 percent in most cases. For instance, against full training, TinyPropv2's accuracy drop is minimal, for example, only 0.82 percent on CIFAR 10 and 1.07 percent on CIFAR100. In terms of computational effort, TinyPropv2 shows a marked reduction, requiring as little as 10 percent of the computational effort needed for full training in some scenarios, and consistently outperforms other sparse training methodologies. These findings underscore TinyPropv2's capacity to efficiently manage computational resources while maintaining high accuracy, positioning it as an advantageous solution for advanced embedded device applications in the IoT ecosystem.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "2024 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
        "paper id": "2409.07188",
        "abstract url": "https://arxiv.org/abs/2409.07188",
        "title": "FuXi-2.0: Advancing machine learning weather forecasting model for practical applications",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) models have become increasingly valuable in weather forecasting, providing forecasts that not only lower computational costs but often match or exceed the accuracy of traditional numerical weather prediction (NWP) models. Despite their potential, ML models typically suffer from limitations such as coarse temporal resolution, typically 6 hours, and a limited set of meteorological variables, limiting their practical applicability. To overcome these challenges, we introduce FuXi-2.0, an advanced ML model that delivers 1-hourly global weather forecasts and includes a comprehensive set of essential meteorological variables, thereby expanding its utility across various sectors like wind and solar energy, aviation, and marine shipping. Our study conducts comparative analyses between ML-based 1-hourly forecasts and those from the high-resolution forecast (HRES) of the European Centre for Medium-Range Weather Forecasts (ECMWF) for various practical scenarios. The results demonstrate that FuXi-2.0 consistently outperforms ECMWF HRES in forecasting key meteorological variables relevant to these sectors. In particular, FuXi-2.0 shows superior performance in wind power forecasting compared to ECMWF HRES, further validating its efficacy as a reliable tool for scenarios demanding precise weather forecasts. Additionally, FuXi-2.0 also integrates both atmospheric and oceanic components, representing a significant step forward in the development of coupled atmospheric-ocean models. Further comparative analyses reveal that FuXi-2.0 provides more accurate forecasts of tropical cyclone intensity than its predecessor, FuXi-1.0, suggesting that there are benefits of an atmosphere-ocean coupled model over atmosphere-only models.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07189",
        "abstract url": "https://arxiv.org/abs/2409.07189",
        "title": "A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Molecular dynamics simulations are a crucial computational tool for researchers to understand and engineer molecular structure and function in areas such as drug discovery, protein engineering, and material design. Despite their utility, MD simulations are expensive, owing to the high dimensionality of molecular systems. Interactive molecular dynamics in virtual reality (iMD-VR) has recently been developed as a 'human-in-the-loop' strategy, which leverages high-performance computing to accelerate the researcher's ability to solve the hyperdimensional sampling problem. By providing an immersive 3D environment that enables visualization and manipulation of real-time molecular motion, iMD-VR enables researchers and students to efficiently and intuitively explore and navigate these complex, high-dimensional systems. iMD-VR platforms offer a unique opportunity to quickly generate rich datasets that capture human experts' spatial insight regarding molecular structure and function. This paper explores the possibility of employing user-generated iMD-VR datasets to train AI agents via imitation learning (IL). IL is an important technique in robotics that enables agents to mimic complex behaviors from expert demonstrations, thus circumventing the need for explicit programming or intricate reward design. We review the utilization of IL for manipulation tasks in robotics and discuss how iMD-VR recordings could be used to train IL models for solving specific molecular 'tasks'. We then investigate how such approaches could be applied to the data captured from iMD-VR recordings. Finally, we outline the future research directions and potential challenges of using AI agents to augment human expertise to efficiently navigate conformational spaces, highlighting how this approach could provide valuable insight across domains such as materials science, protein engineering, and computer-aided drug design.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC",
            "q-bio.BM"
        ],
        "comment": "(Accepted for presentation at the First Workshop on \"eXtended Reality \\& Intelligent Agents\" (XRIA24) @ ECAI24, Santiago De Compostela (Spain), 20 October 2024)"
    },
    {
        "paper id": "2409.07190",
        "abstract url": "https://arxiv.org/abs/2409.07190",
        "title": "Applying Multi-Fidelity Bayesian Optimization in Chemistry: Open Challenges and Major Considerations",
        "rating": "-1.5",
        "keywords": [
            [
                "Chemistry",
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multi fidelity Bayesian optimization (MFBO) leverages experimental and or computational data of varying quality and resource cost to optimize towards desired maxima cost effectively. This approach is particularly attractive for chemical discovery due to MFBO's ability to integrate diverse data sources. Here, we investigate the application of MFBO to accelerate the identification of promising molecules or materials. We specifically analyze the conditions under which lower fidelity data can enhance performance compared to single-fidelity problem formulations. We address two key challenges, selecting the optimal acquisition function, understanding the impact of cost, and data fidelity correlation. We then discuss how to assess the effectiveness of MFBO for chemical discovery.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07272",
        "abstract url": "https://arxiv.org/abs/2409.07272",
        "title": "RePlay: a Recommendation Framework for Experimentation and Production Use",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Using a single tool to build and compare recommender systems significantly reduces the time to market for new models. In addition, the comparison results when using such tools look more consistent. This is why many different tools and libraries for researchers in the field of recommendations have recently appeared. Unfortunately, most of these frameworks are aimed primarily at researchers and require modification for use in production due to the inability to work on large datasets or an inappropriate architecture. In this demo, we present our open-source toolkit RePlay - a framework containing an end-to-end pipeline for building recommender systems, which is ready for production use. RePlay also allows you to use a suitable stack for the pipeline on each stage: Pandas, Polars, or Spark. This allows the library to scale computations and deploy to a cluster. Thus, RePlay allows data scientists to easily move from research mode to production mode using the same interfaces.",
        "subjects": [
            "cs.IR",
            "cs.LG",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07326",
        "abstract url": "https://arxiv.org/abs/2409.07326",
        "title": "ART: Artifact Removal Transformer for Reconstructing Noise-Free Multichannel Electroencephalographic Signals",
        "rating": "-1.5",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Artifact removal in electroencephalography (EEG) is a longstanding challenge that significantly impacts neuroscientific analysis and brain-computer interface (BCI) performance. Tackling this problem demands advanced algorithms, extensive noisy-clean training data, and thorough evaluation strategies. This study presents the Artifact Removal Transformer (ART), an innovative EEG denoising model employing transformer architecture to adeptly capture the transient millisecond-scale dynamics characteristic of EEG signals. Our approach offers a holistic, end-to-end denoising solution for diverse artifact types in multichannel EEG data. We enhanced the generation of noisy-clean EEG data pairs using an independent component analysis, thus fortifying the training scenarios critical for effective supervised learning. We performed comprehensive validations using a wide range of open datasets from various BCI applications, employing metrics like mean squared error and signal-to-noise ratio, as well as sophisticated techniques such as source localization and EEG component classification. Our evaluations confirm that ART surpasses other deep-learning-based artifact removal methods, setting a new benchmark in EEG signal processing. This advancement not only boosts the accuracy and reliability of artifact removal but also promises to catalyze further innovations in the field, facilitating the study of brain dynamics in naturalistic environments.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07347",
        "abstract url": "https://arxiv.org/abs/2409.07347",
        "title": "The Role of Explainable AI in Revolutionizing Human Health Monitoring",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "Health",
                "healthcare",
                "diagnosis",
                "cancer",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The complex nature of disease mechanisms and the variability of patient symptoms present significant obstacles in developing effective diagnostic tools. Although machine learning has made considerable advances in medical diagnosis, its decision-making processes frequently lack transparency, which can jeopardize patient outcomes. This underscores the critical need for Explainable AI (XAI), which not only offers greater clarity but also has the potential to significantly improve patient care. In this literature review, we conduct a detailed analysis of analyzing XAI methods identified through searches across various databases, focusing on chronic conditions such as Parkinson's, stroke, depression, cancer, heart disease, and Alzheimer's disease. The literature search revealed the application of 9 trending XAI algorithms in the field of healthcare and highlighted the pros and cons of each of them. Thus, the article is concluded with a critical appraisal of the challenges and future research opportunities for XAI in human health monitoring.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07359",
        "abstract url": "https://arxiv.org/abs/2409.07359",
        "title": "Training-Free Guidance for Discrete Diffusion Models for Molecular Generation",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training-free guidance methods for continuous data have seen an explosion of interest due to the fact that they enable foundation diffusion models to be paired with interchangable guidance models. Currently, equivalent guidance methods for discrete diffusion models are unknown. We present a framework for applying training-free guidance to discrete data and demonstrate its utility on molecular graph generation tasks using the discrete diffusion model architecture of DiGress. We pair this model with guidance functions that return the proportion of heavy atoms that are a specific atom type and the molecular weight of the heavy atoms and demonstrate our method's ability to guide the data generation.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "physics.chem-ph",
            "q-bio.BM"
        ],
        "comment": "5 pages, 2 figures, and 2 tables"
    },
    {
        "paper id": "2409.07416",
        "abstract url": "https://arxiv.org/abs/2409.07416",
        "title": "Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial",
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Modern listwise recommendation systems need to consider both long-term user perceptions and short-term interest shifts. Reinforcement learning can be applied on recommendation to study such a problem but is also subject to large search space, sparse user feedback and long interactive latency. Motivated by recent progress in hierarchical reinforcement learning, we propose a novel framework called mccHRL to provide different levels of temporal abstraction on listwise recommendation. Within the hierarchical framework, the high-level agent studies the evolution of user perception, while the low-level agent produces the item selection policy by modeling the process as a sequential decision-making problem. We argue that such framework has a well-defined decomposition of the outra-session context and the intra-session context, which are encoded by the high-level and low-level agents, respectively. To verify this argument, we implement both a simulator-based environment and an industrial dataset-based experiment. Results observe significant performance improvement by our method, compared with several well-known baselines. Data and codes have been made public.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "18 pages, 4 figures"
    },
    {
        "paper id": "2409.07547",
        "abstract url": "https://arxiv.org/abs/2409.07547",
        "title": "Machine Learning and Constraint Programming for Efficient Healthcare Scheduling",
        "rating": "-1.5",
        "keywords": [
            [
                "Healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Solving combinatorial optimization problems involve satisfying a set of hard constraints while optimizing some objectives. In this context, exact or approximate methods can be used. While exact methods guarantee the optimal solution, they often come with an exponential running time as opposed to approximate methods that trade the solutions quality for a better running time. In this context, we tackle the Nurse Scheduling Problem (NSP). The NSP consist in assigning nurses to daily shifts within a planning horizon such that workload constraints are satisfied while hospitals costs and nurses preferences are optimized. To solve the NSP, we propose implicit and explicit approaches. In the implicit solving approach, we rely on Machine Learning methods using historical data to learn and generate new solutions through the constraints and objectives that may be embedded in the learned patterns. To quantify the quality of using our implicit approach in capturing the embedded constraints and objectives, we rely on the Frobenius Norm, a quality measure used to compute the average error between the generated solutions and historical data. To compensate for the uncertainty related to the implicit approach given that the constraints and objectives may not be concretely visible in the produced solutions, we propose an alternative explicit approach where we first model the NSP using the Constraint Satisfaction Problem (CSP) framework. Then we develop Stochastic Local Search methods and a new Branch and Bound algorithm enhanced with constraint propagation techniques and variables/values ordering heuristics. Since our implicit approach may not guarantee the feasibility or optimality of the generated solution, we propose a data-driven approach to passively learn the NSP as a constraint network. The learned constraint network, formulated as a CSP, will then be solved using the methods we listed earlier.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07594",
        "abstract url": "https://arxiv.org/abs/2409.07594",
        "title": "Automated Discovery of Pairwise Interactions from Unstructured Data",
        "rating": "-1.5",
        "keywords": [
            [
                "biology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Pairwise interactions between perturbations to a system can provide evidence for the causal dependencies of the underlying underlying mechanisms of a system. When observations are low dimensional, hand crafted measurements, detecting interactions amounts to simple statistical tests, but it is not obvious how to detect interactions between perturbations affecting latent variables. We derive two interaction tests that are based on pairwise interventions, and show how these tests can be integrated into an active learning pipeline to efficiently discover pairwise interactions between perturbations. We illustrate the value of these tests in the context of biology, where pairwise perturbation experiments are frequently used to reveal interactions that are not observable from any single perturbation. Our tests can be run on unstructured data, such as the pixels in an image, which enables a more general notion of interaction than typical cell viability experiments, and can be run on cheaper experimental assays. We validate on several synthetic and real biological experiments that our tests are able to identify interacting pairs effectively. We evaluate our approach on a real biological experiment where we knocked out 50 pairs of genes and measured the effect with microscopy images. We show that we are able to recover significantly more known biological interactions than random search and standard active learning baselines.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07626",
        "abstract url": "https://arxiv.org/abs/2409.07626",
        "title": "Generalization Error Bound for Quantum Machine Learning in NISQ Era -- A Survey",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the mounting anticipation for the quantum revolution, the success of Quantum Machine Learning (QML) in the Noisy Intermediate-Scale Quantum (NISQ) era hinges on a largely unexplored factor: the generalization error bound, a cornerstone of robust and reliable machine learning models. Current QML research, while exploring novel algorithms and applications extensively, is predominantly situated in the context of noise-free, ideal quantum computers. However, Quantum Circuit (QC) operations in NISQ-era devices are susceptible to various noise sources and errors. In this article, we conduct a Systematic Mapping Study (SMS) to explore the state-of-the-art generalization bound for supervised QML in NISQ-era and analyze the latest practices in the field. Our study systematically summarizes the existing computational platforms with quantum hardware, datasets, optimization techniques, and the common properties of the bounds found in the literature. We further present the performance accuracy of various approaches in classical benchmark datasets like the MNIST and IRIS datasets. The SMS also highlights the limitations and challenges in QML in the NISQ era and discusses future research directions to advance the field. Using a detailed Boolean operators query in five reliable indexers, we collected 544 papers and filtered them to a small set of 37 relevant articles. This filtration was done following the best practice of SMS with well-defined research questions and inclusion and exclusion criteria.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07632",
        "abstract url": "https://arxiv.org/abs/2409.07632",
        "title": "Learning Robust Observable to Address Noise in Quantum Machine Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantum Machine Learning (QML) has emerged as a promising field that combines the power of quantum computing with the principles of machine learning. One of the significant challenges in QML is dealing with noise in quantum systems, especially in the Noisy Intermediate-Scale Quantum (NISQ) era. Noise in quantum systems can introduce errors in quantum computations and degrade the performance of quantum algorithms. In this paper, we propose a framework for learning observables that are robust against noisy channels in quantum systems. We demonstrate that it is possible to learn observables that remain invariant under the effects of noise and show that this can be achieved through a machine-learning approach. We present a toy example using a Bell state under a depolarization channel to illustrate the concept of robust observables. We then describe a machine-learning framework for learning such observables across six two-qubit quantum circuits and five noisy channels. Our results show that it is possible to learn observables that are more robust to noise than conventional observables. We discuss the implications of this finding for quantum machine learning, including potential applications in enhancing the stability of QML models in noisy environments. By developing techniques for learning robust observables, we can improve the performance and reliability of quantum machine learning models in the presence of noise, contributing to the advancement of practical QML applications in the NISQ era.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07637",
        "abstract url": "https://arxiv.org/abs/2409.07637",
        "title": "Weather-Informed Probabilistic Forecasting and Scenario Generation in Power Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The integration of renewable energy sources (RES) into power grids presents significant challenges due to their intrinsic stochasticity and uncertainty, necessitating the development of new techniques for reliable and efficient forecasting. This paper proposes a method combining probabilistic forecasting and Gaussian copula for day-ahead prediction and scenario generation of load, wind, and solar power in high-dimensional contexts. By incorporating weather covariates and restoring spatio-temporal correlations, the proposed method enhances the reliability of probabilistic forecasts in RES. Extensive numerical experiments compare the effectiveness of different time series models, with performance evaluated using comprehensive metrics on a real-world and high-dimensional dataset from Midcontinent Independent System Operator (MISO). The results highlight the importance of weather information and demonstrate the efficacy of the Gaussian copula in generating realistic scenarios, with the proposed weather-informed Temporal Fusion Transformer (WI-TFT) model showing superior performance.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07640",
        "abstract url": "https://arxiv.org/abs/2409.07640",
        "title": "Scoping Sustainable Collaborative Mixed Reality",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Mixed Reality (MR) is becoming ubiquitous as it finds its applications in education, healthcare, and other sectors beyond leisure. While MR end devices, such as headsets, have low energy intensity, the total number of devices and resource requirements of the entire MR ecosystem, which includes cloud and edge endpoints, can be significant. The resulting operational and embodied carbon footprint of MR has led to concerns about its environmental implications. Recent research has explored reducing the carbon footprint of MR devices by exploring hardware design space or network optimizations. However, many additional avenues for enhancing MR's sustainability remain open, including energy savings in non-processor components and carbon-aware optimizations in collaborative MR ecosystems. In this paper, we aim to identify key challenges, existing solutions, and promising research directions for improving MR sustainability. We explore adjacent fields of embedded and mobile computing systems for insights and outline MR-specific problems requiring new solutions. We identify the challenges that must be tackled to enable researchers, developers, and users to avail themselves of these opportunities in collaborative MR systems.",
        "subjects": [
            "cs.CY",
            "cs.DC",
            "cs.ET",
            "eess.SY"
        ],
        "comment": "IEEE International Symposium on the Emerging Metaverse (ISEMV)"
    },
    {
        "paper id": "2409.07653",
        "abstract url": "https://arxiv.org/abs/2409.07653",
        "title": "STAND: Data-Efficient and Self-Aware Precondition Induction for Interactive Task Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "STAND is a data-efficient and computationally efficient machine learning approach that produces better classification accuracy than popular approaches like XGBoost on small-data tabular classification problems like learning rule preconditions from interactive training. STAND accounts for a complete set of good candidate generalizations instead of selecting a single generalization by breaking ties randomly. STAND can use any greedy concept construction strategy, like decision tree learning or sequential covering, and build a structure that approximates a version space over disjunctive normal logical statements. Unlike candidate elimination approaches to version-space learning, STAND does not suffer from issues of version-space collapse from noisy data nor is it restricted to learning strictly conjunctive concepts. More importantly, STAND can produce a measure called instance certainty that can predict increases in holdout set performance and has high utility as an active-learning heuristic. Instance certainty enables STAND to be self-aware of its own learning: it knows when it learns and what example will help it learn the most. We illustrate that instance certainty has desirable properties that can help users select next training problems, and estimate when training is complete in applications where users interactively teach an AI a complex program.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07706",
        "abstract url": "https://arxiv.org/abs/2409.07706",
        "title": "Attack End-to-End Autonomous Driving through Module-Wise Noise",
        "rating": "-1.5",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "With recent breakthroughs in deep neural networks, numerous tasks within autonomous driving have exhibited remarkable performance. However, deep learning models are susceptible to adversarial attacks, presenting significant security risks to autonomous driving systems. Presently, end-to-end architectures have emerged as the predominant solution for autonomous driving, owing to their collaborative nature across different tasks. Yet, the implications of adversarial attacks on such models remain relatively unexplored. In this paper, we conduct comprehensive adversarial security research on the modular end-to-end autonomous driving model for the first time. We thoroughly consider the potential vulnerabilities in the model inference process and design a universal attack scheme through module-wise noise injection. We conduct large-scale experiments on the full-stack autonomous driving model and demonstrate that our attack method outperforms previous attack methods. We trust that our research will offer fresh insights into ensuring the safety and reliability of autonomous driving systems.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07733",
        "abstract url": "https://arxiv.org/abs/2409.07733",
        "title": "Self-similarity of temporal interaction networks arises from hyperbolic geometry with time-varying curvature",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "The self-similarity of complex systems has been studied intensely across different domains due to its potential applications in system modeling, complexity analysis, etc., as well as for deep theoretical interest. Existing studies rely on scale transformations conceptualized over either a definite geometric structure of the system (very often realized as length-scale transformations) or purely temporal scale transformations. However, many physical and social systems are observed as temporal interactions among agents without any definitive geometry. Yet, one can imagine the existence of an underlying notion of distance as the interactions are mostly localized. Analysing only the time-scale transformations over such systems would uncover only a limited aspect of the complexity. In this work, we propose a novel technique of scale transformation that dissects temporal interaction networks under spatio-temporal scales, namely, flow scales. Upon experimenting with multiple social and biological interaction networks, we find that many of them possess a finite fractal dimension under flow-scale transformation. Finally, we relate the emergence of flow-scale self-similarity to the latent geometry of such networks. We observe strong evidence that justifies the assumption of an underlying, variable-curvature hyperbolic geometry that induces self-similarity of temporal interaction networks. Our work bears implications for modeling temporal interaction networks at different scales and uncovering their latent geometric structures.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07024",
        "abstract url": "https://arxiv.org/abs/2409.07024",
        "title": "SCLNet: A Scale-Robust Complementary Learning Network for Object Detection in UAV Images",
        "rating": "-2",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Most recent UAV (Unmanned Aerial Vehicle) detectors focus primarily on general challenge such as uneven distribution and occlusion. However, the neglect of scale challenges, which encompass scale variation and small objects, continues to hinder object detection in UAV images. Although existing works propose solutions, they are implicitly modeled and have redundant steps, so detection performance remains limited. And one specific work addressing the above scale challenges can help improve the performance of UAV image detectors. Compared to natural scenes, scale challenges in UAV images happen with problems of limited perception in comprehensive scales and poor robustness to small objects. We found that complementary learning is beneficial for the detection model to address the scale challenges. Therefore, the paper introduces it to form our scale-robust complementary learning network (SCLNet) in conjunction with the object detection model. The SCLNet consists of two implementations and a cooperation method. In detail, one implementation is based on our proposed scale-complementary decoder and scale-complementary loss function to explicitly extract complementary information as complement, named comprehensive-scale complementary learning (CSCL). Another implementation is based on our proposed contrastive complement network and contrastive complement loss function to explicitly guide the learning of small objects with the rich texture detail information of the large objects, named inter-scale contrastive complementary learning (ICCL). In addition, an end-to-end cooperation (ECoop) between two implementations and with the detection model is proposed to exploit each potential.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07049",
        "abstract url": "https://arxiv.org/abs/2409.07049",
        "title": "Synchronization Control-Plane Protocol for Quantum Link Layer",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Heralded entanglement generation between nodes of a future quantum internet is a fundamental operation that unlocks the potential for quantum communication. In this paper, we propose a decentralized synchronization protocol that operates at the classical control-plane of the link layer, to navigate the coordination challenges of generating heralded entanglement across few-qubit quantum network nodes. Additionally, with quantum network simulations using NetSquid, we show that our protocol achieves lower entanglement request latencies than a naive distributed queue approach. We observe a sixfold reduction in average request latency growth as the number of quantum network links increases. The Eventual Synchronization Protocol (ESP) allows nodes to coordinate on heralded entanglement generation in a scalable manner within multi-peer quantum networks. To the best of our knowledge, this is the first decentralized synchronization protocol for managing heralded entanglement requests.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "accepted by the 20th International Conference on Network and Service Management (CNSM), 2024"
    },
    {
        "paper id": "2409.07050",
        "abstract url": "https://arxiv.org/abs/2409.07050",
        "title": "Invariant filtering for wheeled vehicle localization with unknown wheel radius and unknown GNSS lever arm",
        "rating": "-2",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "We consider the problem of observer design for a nonholonomic car (more generally a wheeled robot) equipped with wheel speeds with unknown wheel radius, and whose position is measured via a GNSS antenna placed at an unknown position in the car. In a tutorial and unified exposition, we recall the recent theory of two-frame systems within the field of invariant Kalman filtering. We then show how to adapt it geometrically to address the considered problem, although it seems at first sight out of its scope. This yields an invariant extended Kalman filter having autonomous error equations, and state-independent Jacobians, which is shown to work remarkably well in simulations. The proposed novel construction thus extends the application scope of invariant filtering.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07069",
        "abstract url": "https://arxiv.org/abs/2409.07069",
        "title": "Benchmarking and Validation of Sub-mW 30GHz VG-LNAs in 22nm FDSOI CMOS for 5G/6G Phased-Array Receivers",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Next-generation (5G/6G) wireless systems demand low-power mm-wave phased-array ICs. Variable-gain LNAs (VGLNAs) are key building blocks enabling hardware complexity reduction, performance enhancement and functionality extension. This paper reports a performance benchmarking of two low-power 30GHz VG-LNAs for phased-array ICs, which provide a 7.5dB gain control for 18dB Taylor taper in a 30GHz 8x8 antenna array, for a comprehensive validation of the new class of VGLNAs and its design methodology. In particular, this paper reports a second and implementation (VG-LNA2) with a reduced number (four) of gain-control back-gate voltages and super-low-Vt MOSFETs, with respect to the previous first implementation (VG-LNA1) with six gain-control back-gate voltages and regular- Vt MOSFETs, both in the same 22nm FDSOI CMOS technology. The results show that VG-LNA2 exhibits performance comparable to those of VG-LNA1, with a slightly lower power consumption. Overall, the performance benchmarking shows that the design methodology adopted for the new class of VG-LNAs leads to record low-power consumption and small form factor solutions reaching the targeted performances, regardless of the arrangements of the back-gate voltages for gain control and transistor sets, resulting in a comprehensive validation of the innovative design features and effective design methodology.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "The final version of this draft will be appearing in the Proceedings of DTTIS 2024 available on IEEE Xplore Digital Library"
    },
    {
        "paper id": "2409.07080",
        "abstract url": "https://arxiv.org/abs/2409.07080",
        "title": "Scenario Execution for Robotics: A generic, backend-agnostic library for running reproducible robotics experiments and tests",
        "rating": "-2",
        "keywords": [
            [
                "automated driving"
            ],
            [
                "Robotics"
            ]
        ],
        "abstract": "Testing and evaluation of robotics systems is a difficult and oftentimes tedious task due to the systems' complexity and a lack of tools to conduct reproducible robotics experiments. Additionally, almost all available tools are either tailored towards a specific application domain, simulator or middleware. Particularly scenario-based testing, a common practice in the domain of automated driving, is not sufficiently covered in the robotics domain. In this paper, we propose a novel backend- and middleware-agnostic approach for conducting systematic, reproducible and automatable robotics experiments called Scenario Execution for Robotics. Our approach is implemented as a Python library built on top of the generic scenario description language OpenSCENARIO 2 and Behavior Trees and is made publicly available on GitHub. In extensive experiments, we demonstrate that our approach supports multiple simulators as backend and can be used as a standalone Python-library or as part of the ROS2 ecosystem. Furthermore, we demonstrate how our approach enables testing over ranges of varying values. Finally, we show how Scenario Execution for Robotics allows to move from simulation-based to real-world experiments with minimal adaptations to the scenario description file.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.07092",
        "abstract url": "https://arxiv.org/abs/2409.07092",
        "title": "CWT-Net: Super-resolution of Histopathology Images Using a Cross-scale Wavelet-based Transformer",
        "rating": "-2",
        "keywords": [
            [
                "Super-resolution"
            ],
            [
                "medical",
                "pathological"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Super-resolution (SR) aims to enhance the quality of low-resolution images and has been widely applied in medical imaging. We found that the design principles of most existing methods are influenced by SR tasks based on real-world images and do not take into account the significance of the multi-level structure in pathological images, even if they can achieve respectable objective metric evaluations. In this work, we delve into two super-resolution working paradigms and propose a novel network called CWT-Net, which leverages cross-scale image wavelet transform and Transformer architecture. Our network consists of two branches: one dedicated to learning super-resolution and the other to high-frequency wavelet features. To generate high-resolution histopathology images, the Transformer module shares and fuses features from both branches at various stages. Notably, we have designed a specialized wavelet reconstruction module to effectively enhance the wavelet domain features and enable the network to operate in different modes, allowing for the introduction of additional relevant information from cross-scale images. Our experimental results demonstrate that our model significantly outperforms state-of-the-art methods in both performance and visualization evaluations and can substantially boost the accuracy of image diagnostic networks.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07100",
        "abstract url": "https://arxiv.org/abs/2409.07100",
        "title": "Fast Medical Shape Reconstruction via Meta-learned Implicit Neural Representations",
        "rating": "-2",
        "keywords": [
            [
                "navigation"
            ],
            [
                "Medical",
                "surgical",
                "MRI",
                "CT",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Efficient and fast reconstruction of anatomical structures plays a crucial role in clinical practice. Minimizing retrieval and processing times not only potentially enhances swift response and decision-making in critical scenarios but also supports interactive surgical planning and navigation. Recent methods attempt to solve the medical shape reconstruction problem by utilizing implicit neural functions. However, their performance suffers in terms of generalization and computation time, a critical metric for real-time applications. To address these challenges, we propose to leverage meta-learning to improve the network parameters initialization, reducing inference time by an order of magnitude while maintaining high accuracy. We evaluate our approach on three public datasets covering different anatomical shapes and modalities, namely CT and MRI. Our experimental results show that our model can handle various input configurations, such as sparse slices with different orientations and spacings. Additionally, we demonstrate that our method exhibits strong transferable capabilities in generalizing to shape domains unobserved at training time.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07105",
        "abstract url": "https://arxiv.org/abs/2409.07105",
        "title": "RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Visual Parameter Space Analysis (VPSA) enables domain scientists to explore input-output relationships of computational models. Existing VPSA applications often feature multi-view visualizations designed by visualization experts for a specific scenario, making it hard for domain scientists to adapt them to their problems without professional help. We present RSVP, the Rapid Suggestive Visualization Prototyping system encoding VPSA knowledge to enable domain scientists to prototype custom visualization dashboards tailored to their specific needs. The system implements a task-oriented, multi-view visualization recommendation strategy over a visualization design space optimized for VPSA to guide users in meeting their analytical demands. We derived the VPSA knowledge implemented in the system by conducting an extensive meta design study over the body of work on VPSA. We show how this process can be used to perform a data and task abstraction, extract a common visualization design space, and derive a task-oriented VisRec strategy. User studies indicate that the system is user-friendly and can uncover novel insights.",
        "subjects": [
            "cs.HC",
            "cs.GR"
        ],
        "comment": "16 pages, 16 figures, 3 tables, accepted for publishing at TVCG Journal"
    },
    {
        "paper id": "2409.07107",
        "abstract url": "https://arxiv.org/abs/2409.07107",
        "title": "End-to-End and Highly-Efficient Differentiable Simulation for Robotics",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robotics"
            ]
        ],
        "abstract": "Over the past few years, robotics simulators have largely improved in efficiency and scalability, enabling them to generate years of simulated data in a few hours. Yet, efficiently and accurately computing the simulation derivatives remains an open challenge, with potentially high gains on the convergence speed of reinforcement learning and trajectory optimization algorithms, especially for problems involving physical contact interactions. This paper contributes to this objective by introducing a unified and efficient algorithmic solution for computing the analytical derivatives of robotic simulators. The approach considers both the collision and frictional stages, accounting for their intrinsic nonsmoothness and also exploiting the sparsity induced by the underlying multibody systems. These derivatives have been implemented in C++, and the code will be open-sourced in the Simple simulator. They depict state-of-the-art timings ranging from 5 microseconds for a 7-dof manipulator up to 95 microseconds for 36-dof humanoid, outperforming alternative solutions by a factor of at least 100.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07144",
        "abstract url": "https://arxiv.org/abs/2409.07144",
        "title": "Dual channel CW nnU-Net for 3D PET-CT Lesion Segmentation in 2024 autoPET III Challenge",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "CT",
                "Lesion"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "PET/CT is extensively used in imaging malignant tumors because it highlights areas of increased glucose metabolism, indicative of cancerous activity. Accurate 3D lesion segmentation in PET/CT imaging is essential for effective oncological diagnostics and treatment planning. In this study, we developed an advanced 3D residual U-Net model for the Automated Lesion Segmentation in Whole-Body PET/CT - Multitracer Multicenter Generalization (autoPET III) Challenge, which will be held jointly with 2024 Medical Image Computing and Computer Assisted Intervention (MICCAI) conference at Marrakesh, Morocco. Proposed model incorporates a novel sample attention boosting technique to enhance segmentation performance by adjusting the contribution of challenging cases during training, improving generalization across FDG and PSMA tracers. The proposed model outperformed the challenge baseline model in the preliminary test set on the Grand Challenge platform, and our team is currently ranking in the 2nd place among 497 participants worldwide from 53 countries (accessed date: 2024/9/4), with Dice score of 0.8700, False Negative Volume of 19.3969 and False Positive Volume of 1.0857.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07186",
        "abstract url": "https://arxiv.org/abs/2409.07186",
        "title": "Enhancing Angular Resolution via Directionality Encoding and Geometric Constraints in Brain Diffusion Tensor Imaging",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "health",
                "MRI",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion-weighted imaging (DWI) is a type of Magnetic Resonance Imaging (MRI) technique sensitised to the diffusivity of water molecules, offering the capability to inspect tissue microstructures and is the only in-vivo method to reconstruct white matter fiber tracts non-invasively. The DWI signal can be analysed with the diffusion tensor imaging (DTI) model to estimate the directionality of water diffusion within voxels. Several scalar metrics, including axial diffusivity (AD), mean diffusivity (MD), radial diffusivity (RD), and fractional anisotropy (FA), can be further derived from DTI to quantitatively summarise the microstructural integrity of brain tissue. These scalar metrics have played an important role in understanding the organisation and health of brain tissue at a microscopic level in clinical studies. However, reliable DTI metrics rely on DWI acquisitions with high gradient directions, which often go beyond the commonly used clinical protocols. To enhance the utility of clinically acquired DWI and save scanning time for robust DTI analysis, this work proposes DirGeo-DTI, a deep learning-based method to estimate reliable DTI metrics even from a set of DWIs acquired with the minimum theoretical number (6) of gradient directions. DirGeo-DTI leverages directional encoding and geometric constraints to facilitate the training process. Two public DWI datasets were used for evaluation, demonstrating the effectiveness of the proposed method. Extensive experimental results show that the proposed method achieves the best performance compared to existing DTI enhancement methods and potentially reveals further clinical insights with routine clinical DWI scans.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted to ICONIP2024, Diffusion Weighted Imaging, Diffusion Tensor Imaging, Angular Resolution Enhancement, Fractional Anisotropy"
    },
    {
        "paper id": "2409.07207",
        "abstract url": "https://arxiv.org/abs/2409.07207",
        "title": "Variability in Grasp Type Distinction for Myoelectric Prosthesis Control Using a Non-Invasive Brain-Machine Interface",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "Decoding multiple movements from the same limb using electroencephalographic (EEG) activity is a key challenge with applications for controlling prostheses in upper-limb amputees. This study investigates the classification of four hand movements to control a modified Myobock prosthesis via EEG signals. We report results from three EEG recording sessions involving four amputees and twenty able-bodied subjects performing four grasp movements under three conditions: Motor Execution (ME), Motor Imagery (MI), and Motor Observation (MO). EEG preprocessing was followed by feature extraction using Common Spatial Patterns (CSP), Wavelet Decomposition (WD), and Riemannian Geometry. Various classification algorithms were applied to decode EEG signals, and a metric assessed pattern separability. We evaluated system performance across different electrode combinations and compared it to the original setup. Our results show that distinguishing movement from no movement achieved 100% accuracy, while classification between movements reached 70-90%. No significant differences were found between recording conditions in classification performance. Able-bodied participants outperformed amputees, but there were no significant differences in Motor Imagery. Performance did not improve across the sessions, and there was considerable variability in EEG pattern distinction. Reducing the number of electrodes by half led to only a 2% average accuracy drop. These results provide insights into developing wearable brain-machine interfaces, particularly for electrode optimization and training in grasp movement classification.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07232",
        "abstract url": "https://arxiv.org/abs/2409.07232",
        "title": "Optimizing the Weather Research and Forecasting Model with OpenMP Offload and Codee",
        "rating": "-2",
        "keywords": [
            [
                "Forecasting"
            ]
        ],
        "abstract": "Currently, the Weather Research and Forecasting model (WRF) utilizes shared memory (OpenMP) and distributed memory (MPI) parallelisms. To take advantage of GPU resources on the Perlmutter supercomputer at NERSC, we port parts of the computationally expensive routines of the Fast Spectral Bin Microphysics (FSBM) microphysical scheme to NVIDIA GPUs using OpenMP device offloading directives. To facilitate this process, we explore a workflow for optimization which uses both runtime profilers and a static code inspection tool Codee to refactor the subroutine. We observe a 2.08x overall speedup for the CONUS-12km thunderstorm test case.",
        "subjects": [
            "cs.DC",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07236",
        "abstract url": "https://arxiv.org/abs/2409.07236",
        "title": "3DGCQA: A Quality Assessment Database for 3D AI-Generated Contents",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Quality Assessment"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Although 3D generated content (3DGC) offers advantages in reducing production costs and accelerating design timelines, its quality often falls short when compared to 3D professionally generated content. Common quality issues frequently affect 3DGC, highlighting the importance of timely and effective quality assessment. Such evaluations not only ensure a higher standard of 3DGCs for end-users but also provide critical insights for advancing generative technologies. To address existing gaps in this domain, this paper introduces a novel 3DGC quality assessment dataset, 3DGCQA, built using 7 representative Text-to-3D generation methods. During the dataset's construction, 50 fixed prompts are utilized to generate contents across all methods, resulting in the creation of 313 textured meshes that constitute the 3DGCQA dataset. The visualization intuitively reveals the presence of 6 common distortion categories in the generated 3DGCs. To further explore the quality of the 3DGCs, subjective quality assessment is conducted by evaluators, whose ratings reveal significant variation in quality across different generation methods. Additionally, several objective quality assessment algorithms are tested on the 3DGCQA dataset. The results expose limitations in the performance of existing algorithms and underscore the need for developing more specialized quality assessment methods. To provide a valuable resource for future research and development in 3D content generation and quality assessment, the dataset has been open-sourced in https://github.com/zyj-2000/3DGCQA.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07237",
        "abstract url": "https://arxiv.org/abs/2409.07237",
        "title": "Negative Sampling in Recommendation: A Survey and Future Directions",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Recommender systems aim to capture users' personalized preferences from the cast amount of user behaviors, making them pivotal in the era of information explosion. However, the presence of the dynamic preference, the \"information cocoons\", and the inherent feedback loops in recommendation make users interact with a limited number of items. Conventional recommendation algorithms typically focus on the positive historical behaviors, while neglecting the essential role of negative feedback in user interest understanding. As a promising but easy-to-ignored area, negative sampling is proficients in revealing the genuine negative aspect inherent in user behaviors, emerging as an inescapable procedure in recommendation. In this survey, we first discuss the role of negative sampling in recommendation and thoroughly analyze challenges that consistently impede its progress. Then, we conduct an extensive literature review on the existing negative sampling strategies in recommendation and classify them into five categories with their discrepant techniques. Finally, we detail the insights of the tailored negative sampling strategies in diverse recommendation scenarios and outline an overview of the prospective research directions toward which the community may engage and benefit.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "38 pages, 9 figures; Under review"
    },
    {
        "paper id": "2409.07245",
        "abstract url": "https://arxiv.org/abs/2409.07245",
        "title": "Single-View 3D Reconstruction via SO(2)-Equivariant Gaussian Sculpting Networks",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "robotic manipulation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces SO(2)-Equivariant Gaussian Sculpting Networks (GSNs) as an approach for SO(2)-Equivariant 3D object reconstruction from single-view image observations. GSNs take a single observation as input to generate a Gaussian splat representation describing the observed object's geometry and texture. By using a shared feature extractor before decoding Gaussian colors, covariances, positions, and opacities, GSNs achieve extremely high throughput (>150FPS). Experiments demonstrate that GSNs can be trained efficiently using a multi-view rendering loss and are competitive, in quality, with expensive diffusion-based reconstruction algorithms. The GSN model is validated on multiple benchmark experiments. Moreover, we demonstrate the potential for GSNs to be used within a robotic manipulation pipeline for object-centric grasping.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted to RSS 2024 Workshop on Geometric and Algebraic Structure in Robot Learning"
    },
    {
        "paper id": "2409.07271",
        "abstract url": "https://arxiv.org/abs/2409.07271",
        "title": "CCFExp: Facial Image Synthesis with Cycle Cross-Fusion Diffusion Model for Facial Paralysis Individuals",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "clinical",
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial paralysis is a debilitating condition that affects the movement of facial muscles, leading to a significant loss of facial expressions. Currently, the diagnosis of facial paralysis remains a challenging task, often relying heavily on the subjective judgment and experience of clinicians, which can introduce variability and uncertainty in the assessment process. One promising application in real-life situations is the automatic estimation of facial paralysis. However, the scarcity of facial paralysis datasets limits the development of robust machine learning models for automated diagnosis and therapeutic interventions. To this end, this study aims to synthesize a high-quality facial paralysis dataset to address this gap, enabling more accurate and efficient algorithm training. Specifically, a novel Cycle Cross-Fusion Expression Generative Model (CCFExp) based on the diffusion model is proposed to combine different features of facial information and enhance the visual details of facial appearance and texture in facial regions, thus creating synthetic facial images that accurately represent various degrees and types of facial paralysis. We have qualitatively and quantitatively evaluated the proposed method on the commonly used public clinical datasets of facial paralysis to demonstrate its effectiveness. Experimental results indicate that the proposed method surpasses state-of-the-art methods, generating more realistic facial images and maintaining identity consistency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07276",
        "abstract url": "https://arxiv.org/abs/2409.07276",
        "title": "STORE: Streamlining Semantic Tokenization and Generative Recommendation with A Single LLM",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Traditional recommendation models often rely on unique item identifiers (IDs) to distinguish between items, which can hinder their ability to effectively leverage item content information and generalize to long-tail or cold-start items. Recently, semantic tokenization has been proposed as a promising solution that aims to tokenize each item's semantic representation into a sequence of discrete tokens. In this way, it preserves the item's semantics within these tokens and ensures that semantically similar items are represented by similar tokens. These semantic tokens have become fundamental in training generative recommendation models. However, existing generative recommendation methods typically involve multiple sub-models for embedding, quantization, and recommendation, leading to an overly complex system. In this paper, we propose to streamline the semantic tokenization and generative recommendation process with a unified framework, dubbed STORE, which leverages a single large language model (LLM) for both tasks. Specifically, we formulate semantic tokenization as a text-to-token task and generative recommendation as a token-to-token task, supplemented by a token-to-text reconstruction task and a text-to-token auxiliary task. All these tasks are framed in a generative manner and trained using a single LLM backbone. Extensive experiments have been conducted to validate the effectiveness of our STORE framework across various recommendation tasks and datasets. We will release the source code and configurations for reproducible research.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07304",
        "abstract url": "https://arxiv.org/abs/2409.07304",
        "title": "BLS-GAN: A Deep Layer Separation Framework for Eliminating Bone Overlap in Conventional Radiographs",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "diagnosing",
                "disease"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Conventional radiography is the widely used imaging technology in diagnosing, monitoring, and prognosticating musculoskeletal (MSK) diseases because of its easy availability, versatility, and cost-effectiveness. In conventional radiographs, bone overlaps are prevalent, and can impede the accurate assessment of bone characteristics by radiologists or algorithms, posing significant challenges to conventional and computer-aided diagnoses. This work initiated the study of a challenging scenario - bone layer separation in conventional radiographs, in which separate overlapped bone regions enable the independent assessment of the bone characteristics of each bone layer and lay the groundwork for MSK disease diagnosis and its automation. This work proposed a Bone Layer Separation GAN (BLS-GAN) framework that can produce high-quality bone layer images with reasonable bone characteristics and texture. This framework introduced a reconstructor based on conventional radiography imaging principles, which achieved efficient reconstruction and mitigates the recurrent calculations and training instability issues caused by soft tissue in the overlapped regions. Additionally, pre-training with synthetic images was implemented to enhance the stability of both the training process and the results. The generated images passed the visual Turing test, and improved performance in downstream tasks. This work affirms the feasibility of extracting bone layer images from conventional radiographs, which holds promise for leveraging bone layer separation technology to facilitate more comprehensive analytical research in MSK diagnosis, monitoring, and prognosis. Code and dataset will be made available.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07306",
        "abstract url": "https://arxiv.org/abs/2409.07306",
        "title": "Visual Compositional Data Analytics for Spatial Transcriptomics",
        "rating": "-2",
        "keywords": [
            [
                "Bio+Med-Vis"
            ]
        ],
        "abstract": "For the Bio+Med-Vis Challenge 2024, we propose a visual analytics system as a redesign for the scatter pie chart visualization of cell type proportions of spatial transcriptomics data. Our design uses three linked views: a view of the histological image of the tissue, a stacked bar chart showing cell type proportions of the spots, and a scatter plot showing a dimensionality reduction of the multivariate proportions. Furthermore, we apply a compositional data analysis framework, the Aitchison geometry, to the proportions for dimensionality reduction and $k$-means clustering. Leveraging brushing and linking, the system allows one to explore and uncover patterns in the cell type mixtures and relate them to their spatial locations on the cellular tissue. This redesign shifts the pattern recognition workload from the human visual system to computational methods commonly used in visual analytics. We provide the code and setup instructions of our visual analytics system on GitHub (https://github.com/UniStuttgart-VISUS/va-for-spatial-transcriptomics).",
        "subjects": [
            "cs.HC"
        ],
        "comment": "2 pages, 2 figures, challenge submission accepted by Bio+Med+Vis workshop at IEEE VIS 2024"
    },
    {
        "paper id": "2409.07315",
        "abstract url": "https://arxiv.org/abs/2409.07315",
        "title": "Integrating Bayesian Approaches and Expert Knowledge for Forecasting Continuous Glucose Monitoring Values in Type 2 Diabetes Mellitus",
        "rating": "-2",
        "keywords": [
            [
                "Forecasting"
            ]
        ],
        "abstract": "Precise and timely forecasting of blood glucose levels is essential for effective diabetes management. While extensive research has been conducted on Type 1 diabetes mellitus, Type 2 diabetes mellitus (T2DM) presents unique challenges due to its heterogeneity, underscoring the need for specialized blood glucose forecasting systems. This study introduces a novel blood glucose forecasting system, applied to a dataset of 100 patients from the ShanghaiT2DM study. Our study uniquely integrates knowledge-driven and data-driven approaches, leveraging expert knowledge to validate and interpret the relationships among diabetes-related variables and deploying the data-driven approach to provide accurate forecast blood glucose levels. The Bayesian network approach facilitates the analysis of dependencies among various diabetes-related variables, thus enabling the inference of continuous glucose monitoring (CGM) trajectories in similar individuals with T2DM. By incorporating past CGM data including inference CGM trajectories, dietary records, and individual-specific information, the Bayesian structural time series (BSTS) model effectively forecasts glucose levels across time intervals ranging from 15 to 60 minutes. Forecast results show a mean absolute error of 6.41 mg/dL, a root mean square error of 8.29 mg/dL, and a mean absolute percentage error of 5.28%, for a 15-minute prediction horizon. This study makes the first application of the ShanghaiT2DM dataset for glucose level forecasting, considering the influences of diabetes-related variables. Its findings establish a foundational framework for developing personalized diabetes management strategies, potentially enhancing diabetes care through more accurate and timely interventions.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07351",
        "abstract url": "https://arxiv.org/abs/2409.07351",
        "title": "Federated Impression for Learning with Distributed Heterogeneous Data",
        "rating": "-2",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "health",
                "clinical",
                "Retina"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Standard deep learning-based classification approaches may not always be practical in real-world clinical applications, as they require a centralized collection of all samples. Federated learning (FL) provides a paradigm that can learn from distributed datasets across clients without requiring them to share data, which can help mitigate privacy and data ownership issues. In FL, sub-optimal convergence caused by data heterogeneity is common among data from different health centers due to the variety in data collection protocols and patient demographics across centers. Through experimentation in this study, we show that data heterogeneity leads to the phenomenon of catastrophic forgetting during local training. We propose FedImpres which alleviates catastrophic forgetting by restoring synthetic data that represents the global information as federated impression. To achieve this, we distill the global model resulting from each communication round. Subsequently, we use the synthetic data alongside the local data to enhance the generalization of local training. Extensive experiments show that the proposed method achieves state-of-the-art performance on both the BloodMNIST and Retina datasets, which contain label imbalance and domain shift, with an improvement in classification accuracy of up to 20%.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07375",
        "abstract url": "https://arxiv.org/abs/2409.07375",
        "title": "PRIME: Phase Reversed Interleaved Multi-Echo acquisition enables highly accelerated distortion-free diffusion MRI",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "MRI",
                "clinical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Purpose: To develop and evaluate a new pulse sequence for highly accelerated distortion-free diffusion MRI (dMRI) by inserting an additional echo without prolonging TR, when generalized slice dithered enhanced resolution (gSlider) radiofrequency encoding is used for volumetric acquisition. Methods: A phase-reversed interleaved multi-echo acquisition (PRIME) was developed for rapid, high-resolution, and distortion-free dMRI, which includes two echoes where the first echo is for target diffusion-weighted imaging (DWI) acquisition with high-resolution and the second echo is acquired with either 1) lower-resolution for high-fidelity field map estimation, or 2) matching resolution to enable efficient diffusion relaxometry acquisitions. The sequence was evaluated on in vivo data acquired from healthy volunteers on clinical and Connectome 2.0 scanners. Results: In vivo experiments demonstrated that 1) high in-plane acceleration (Rin-plane of 5-fold with 2D partial Fourier) was achieved using the high-fidelity field maps estimated from the second echo, which was made at a lower resolution/acceleration to increase its SNR while matching the effective echo spacing of the first readout, 2) high-resolution diffusion relaxometry parameters were estimated from dual-echo PRIME data using a white matter model of multi-TE spherical mean technique (MTE-SMT), and 3) high-fidelity mesoscale DWI at 550 um isotropic resolution could be obtained in vivo by capitalizing on the high-performance gradients of the Connectome 2.0 scanner. Conclusion: The proposed PRIME sequence enabled highly accelerated, high-resolution, and distortion-free dMRI using an additional echo without prolonging scan time when gSlider encoding is utilized.",
        "subjects": [
            "physics.med-ph",
            "eess.IV",
            "eess.SP"
        ],
        "comment": "12 figures, 1 table"
    },
    {
        "paper id": "2409.07451",
        "abstract url": "https://arxiv.org/abs/2409.07451",
        "title": "FreeEnhance: Tuning-Free Image Enhancement via Content-Consistent Noising-and-Denoising Process",
        "rating": "-2",
        "keywords": [
            [
                "diffusion",
                "text-to-image"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The emergence of text-to-image generation models has led to the recognition that image enhancement, performed as post-processing, would significantly improve the visual quality of the generated images. Exploring diffusion models to enhance the generated images nevertheless is not trivial and necessitates to delicately enrich plentiful details while preserving the visual appearance of key content in the original image. In this paper, we propose a novel framework, namely FreeEnhance, for content-consistent image enhancement using the off-the-shelf image diffusion models. Technically, FreeEnhance is a two-stage process that firstly adds random noise to the input image and then capitalizes on a pre-trained image diffusion model (i.e., Latent Diffusion Models) to denoise and enhance the image details. In the noising stage, FreeEnhance is devised to add lighter noise to the region with higher frequency to preserve the high-frequent patterns (e.g., edge, corner) in the original image. In the denoising stage, we present three target properties as constraints to regularize the predicted noise, enhancing images with high acutance and high visual quality. Extensive experiments conducted on the HPDv2 dataset demonstrate that our FreeEnhance outperforms the state-of-the-art image enhancement models in terms of quantitative metrics and human preference. More remarkably, FreeEnhance also shows higher human preference compared to the commercial image enhancement solution of Magnific AI.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "ACM Multimedia 2024"
    },
    {
        "paper id": "2409.07551",
        "abstract url": "https://arxiv.org/abs/2409.07551",
        "title": "Machine Learning Approaches for Defect Detection in a Microwell-based Medical Device",
        "rating": "-2",
        "keywords": [
            [
                "Medical"
            ]
        ],
        "abstract": "Microfluidic devices offer numerous advantages in medical applications, including the capture of single cells in microwell-based platforms for genomic analysis. As the cost of sequencing decreases, the demand for high-throughput single-cell analysis devices increases, leading to more microwells in a single device. However, their small size and large quantity increase the quality control (QC) effort. Currently, QC steps are still performed manually in some devices, requiring intensive training and time and causing inconsistency between different operators. A way to overcome this issue is to through automated defect detection. Computer vision can quickly analyze a large number of images in a short time and can be applied in defect detection. Automated defect detection can replace manual inspection, potentially decreasing variations in QC results. We report a machine learning (ML) algorithm that applies a convolution neural network (CNN) model with 9 layers and 64 units, incorporating dropouts and regularizations. This algorithm can analyze a large number of microwells produced by injection molding, significantly increasing the number of images analyzed compared to manual operator, improving QC, and ensuring the delivery of high-quality products to customers.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07558",
        "abstract url": "https://arxiv.org/abs/2409.07558",
        "title": "Unsupervised Point Cloud Registration with Self-Distillation",
        "rating": "-2",
        "keywords": [
            [
                "Point Cloud",
                "RGB-D"
            ],
            [
                "autonomous driving",
                "radar"
            ],
            [
                "robotics"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Rigid point cloud registration is a fundamental problem and highly relevant in robotics and autonomous driving. Nowadays deep learning methods can be trained to match a pair of point clouds, given the transformation between them. However, this training is often not scalable due to the high cost of collecting ground truth poses. Therefore, we present a self-distillation approach to learn point cloud registration in an unsupervised fashion. Here, each sample is passed to a teacher network and an augmented view is passed to a student network. The teacher includes a trainable feature extractor and a learning-free robust solver such as RANSAC. The solver forces consistency among correspondences and optimizes for the unsupervised inlier ratio, eliminating the need for ground truth labels. Our approach simplifies the training procedure by removing the need for initial hand-crafted features or consecutive point cloud frames as seen in related methods. We show that our method not only surpasses them on the RGB-D benchmark 3DMatch but also generalizes well to automotive radar, where classical features adopted by others fail. The code is available at https://github.com/boschresearch/direg .",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "Oral at BMVC 2024"
    },
    {
        "paper id": "2409.07580",
        "abstract url": "https://arxiv.org/abs/2409.07580",
        "title": "New constructions of pseudorandom codes",
        "rating": "-2",
        "keywords": [
            [
                "watermarking"
            ]
        ],
        "abstract": "Introduced in [CG24], pseudorandom error-correcting codes (PRCs) are a new cryptographic primitive with applications in watermarking generative AI models. These are codes where a collection of polynomially many codewords is computationally indistinguishable from random, except to individuals with the decoding key. In this work, we examine the assumptions under which PRCs with robustness to a constant error rate exist. 1. We show that if both the planted hyperloop assumption introduced in [BKR23] and security of a version of Goldreich's PRG hold, then there exist public-key PRCs for which no efficient adversary can distinguish a polynomial number of codewords from random with better than $o(1)$ advantage. 2. We revisit the construction of [CG24] and show that it can be based on a wider range of assumptions than presented in [CG24]. To do this, we introduce a weakened version of the planted XOR assumption which we call the weak planted XOR assumption and which may be of independent interest. 3. We initiate the study of PRCs which are secure against space-bounded adversaries. We show how to construct secret-key PRCs of length $O(n)$ which are $\\textit{unconditionally}$ indistinguishable from random by $\\text{poly}(n)$ time, $O(n^{1.5-\\varepsilon})$ space adversaries.",
        "subjects": [
            "cs.CR",
            "cs.CC"
        ],
        "comment": "37 pages, 1 figure"
    },
    {
        "paper id": "2409.07589",
        "abstract url": "https://arxiv.org/abs/2409.07589",
        "title": "Multi-scale spatiotemporal representation learning for EEG-based emotion recognition",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "EEG-based emotion recognition holds significant potential in the field of brain-computer interfaces. A key challenge lies in extracting discriminative spatiotemporal features from electroencephalogram (EEG) signals. Existing studies often rely on domain-specific time-frequency features and analyze temporal dependencies and spatial characteristics separately, neglecting the interaction between local-global relationships and spatiotemporal dynamics. To address this, we propose a novel network called Multi-Scale Inverted Mamba (MS-iMamba), which consists of Multi-Scale Temporal Blocks (MSTB) and Temporal-Spatial Fusion Blocks (TSFB). Specifically, MSTBs are designed to capture both local details and global temporal dependencies across different scale subsequences. The TSFBs, implemented with an inverted Mamba structure, focus on the interaction between dynamic temporal dependencies and spatial characteristics. The primary advantage of MS-iMamba lies in its ability to leverage reconstructed multi-scale EEG sequences, exploiting the interaction between temporal and spatial features without the need for domain-specific time-frequency feature extraction. Experimental results on the DEAP, DREAMER, and SEED datasets demonstrate that MS-iMamba achieves classification accuracies of 94.86%, 94.94%, and 91.36%, respectively, using only four-channel EEG signals, outperforming state-of-the-art methods.",
        "subjects": [
            "cs.HC",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07604",
        "abstract url": "https://arxiv.org/abs/2409.07604",
        "title": "Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Large language models (LLMs) are increasingly used in natural language processing tasks. Recommender systems traditionally use methods such as collaborative filtering and matrix factorization, as well as advanced techniques like deep learning and reinforcement learning. Although language models have been applied in recommendation, the recent trend have focused on leveraging the generative capabilities of LLMs for more personalized suggestions. While current research focuses on English due to its resource richness, this work explores the impact of non-English prompts on recommendation performance. Using OpenP5, a platform for developing and evaluating LLM-based recommendations, we expanded its English prompt templates to include Spanish and Turkish. Evaluation on three real-world datasets, namely ML1M, LastFM, and Amazon-Beauty, showed that usage of non-English prompts generally reduce performance, especially in less-resourced languages like Turkish. We also retrained an LLM-based recommender model with multilingual prompts to analyze performance variations. Retraining with multilingual prompts resulted in more balanced performance across languages, but slightly reduced English performance. This work highlights the need for diverse language support in LLM-based recommenders and suggests future research on creating evaluation datasets, using newer models and additional languages.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07623",
        "abstract url": "https://arxiv.org/abs/2409.07623",
        "title": "Object Depth and Size Estimation using Stereo-vision and Integration with SLAM",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Autonomous robots use simultaneous localization and mapping (SLAM) for efficient and safe navigation in various environments. LiDAR sensors are integral in these systems for object identification and localization. However, LiDAR systems though effective in detecting solid objects (e.g., trash bin, bottle, etc.), encounter limitations in identifying semitransparent or non-tangible objects (e.g., fire, smoke, steam, etc.) due to poor reflecting characteristics. Additionally, LiDAR also fails to detect features such as navigation signs and often struggles to detect certain hazardous materials that lack a distinct surface for effective laser reflection. In this paper, we propose a highly accurate stereo-vision approach to complement LiDAR in autonomous robots. The system employs advanced stereo vision-based object detection to detect both tangible and non-tangible objects and then uses simple machine learning to precisely estimate the depth and size of the object. The depth and size information is then integrated into the SLAM process to enhance the robot's navigation capabilities in complex environments. Our evaluation, conducted on an autonomous robot equipped with LiDAR and stereo-vision systems demonstrates high accuracy in the estimation of an object's depth and size. A video illustration of the proposed scheme is available at: \\url{https://www.youtube.com/watch?v=nusI6tA9eSk}.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Accepted version of the published article in IEEE Sensors Letters"
    },
    {
        "paper id": "2409.07627",
        "abstract url": "https://arxiv.org/abs/2409.07627",
        "title": "Leveraging User-Generated Reviews for Recommender Systems with Dynamic Headers",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "E-commerce platforms have a vast catalog of items to cater to their customers' shopping interests. Most of these platforms assist their customers in the shopping process by offering optimized recommendation carousels, designed to help customers quickly locate their desired items. Many models have been proposed in academic literature to generate and enhance the ranking and recall set of items in these carousels. Conventionally, the accompanying carousel title text (header) of these carousels remains static. In most instances, a generic text such as \"Items similar to your current viewing\" is utilized. Fixed variations such as the inclusion of specific attributes \"Other items from a similar seller\" or \"Items from a similar brand\" in addition to \"frequently bought together\" or \"considered together\" are observed as well. This work proposes a novel approach to customize the header generation process of these carousels. Our work leverages user-generated reviews that lay focus on specific attributes (aspects) of an item that were favorably perceived by users during their interaction with the given item. We extract these aspects from reviews and train a graph neural network-based model under the framework of a conditional ranking task. We refer to our innovative methodology as Dynamic Text Snippets (DTS) which generates multiple header texts for an anchor item and its recall set. Our approach demonstrates the potential of utilizing user-generated reviews and presents a unique paradigm for exploring increasingly context-aware recommendation systems.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "7 pages, 3 figures, PAIS 2024 (ECAI)"
    },
    {
        "paper id": "2409.07693",
        "abstract url": "https://arxiv.org/abs/2409.07693",
        "title": "Cooperative Inference with Interleaved Operator Partitioning for CNNs",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Deploying deep learning models on Internet of Things (IoT) devices often faces challenges due to limited memory resources and computing capabilities. Cooperative inference is an important method for addressing this issue, requiring the partitioning and distributive deployment of an intelligent model. To perform horizontal partitions, existing cooperative inference methods take either the output channel of operators or the height and width of feature maps as the partition dimensions. In this manner, since the activation of operators is distributed, they have to be concatenated together before being fed to the next operator, which incurs the delay for cooperative inference. In this paper, we propose the Interleaved Operator Partitioning (IOP) strategy for CNN models. By partitioning an operator based on the output channel dimension and its successive operator based on the input channel dimension, activation concatenation becomes unnecessary, thereby reducing the number of communication connections, which consequently reduces cooperative inference de-lay. Based on IOP, we further present a model segmentation algorithm for minimizing cooperative inference time, which greedily selects operators for IOP pairing based on the inference delay benefit harvested. Experimental results demonstrate that compared with the state-of-the-art partition approaches used in CoEdge, the IOP strategy achieves 6.39% ~ 16.83% faster acceleration and reduces peak memory footprint by 21.22% ~ 49.98% for three classical image classification models.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07723",
        "abstract url": "https://arxiv.org/abs/2409.07723",
        "title": "Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "surgery",
                "endoscopic"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Depth estimation is a cornerstone of 3D reconstruction and plays a vital role in minimally invasive endoscopic surgeries. However, most current depth estimation networks rely on traditional convolutional neural networks, which are limited in their ability to capture global information. Foundation models offer a promising avenue for enhancing depth estimation, but those currently available are primarily trained on natural images, leading to suboptimal performance when applied to endoscopic images. In this work, we introduce a novel fine-tuning strategy for the Depth Anything Model and integrate it with an intrinsic-based unsupervised monocular depth estimation framework. Our approach includes a low-rank adaptation technique based on random vectors, which improves the model's adaptability to different scales. Additionally, we propose a residual block built on depthwise separable convolution to compensate for the transformer's limited ability to capture high-frequency details, such as edges and textures. Our experimental results on the SCARED dataset show that our method achieves state-of-the-art performance while minimizing the number of trainable parameters. Applying this method in minimally invasive endoscopic surgery could significantly enhance both the precision and safety of these procedures.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2409.07746",
        "abstract url": "https://arxiv.org/abs/2409.07746",
        "title": "Learning Brain Tumor Representation in 3D High-Resolution MR Images via Interpretable State Space Models",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Learning meaningful and interpretable representations from high-dimensional volumetric magnetic resonance (MR) images is essential for advancing personalized medicine. While Vision Transformers (ViTs) have shown promise in handling image data, their application to 3D multi-contrast MR images faces challenges due to computational complexity and interpretability. To address this, we propose a novel state-space-model (SSM)-based masked autoencoder which scales ViT-like models to handle high-resolution data effectively while also enhancing the interpretability of learned representations. We propose a latent-to-spatial mapping technique that enables direct visualization of how latent features correspond to specific regions in the input volumes in the context of SSM. We validate our method on two key neuro-oncology tasks: identification of isocitrate dehydrogenase mutation status and 1p/19q co-deletion classification, achieving state-of-the-art accuracy. Our results highlight the potential of SSM-based self-supervised learning to transform radiomics analysis by combining efficiency and interpretability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "The code is available at https://github.com/WinstonHuTiger/mamba_mae"
    },
    {
        "paper id": "2409.07251",
        "abstract url": "https://arxiv.org/abs/2409.07251",
        "title": "Federated $\\mathcal{X}$-armed Bandit with Flexible Personalisation",
        "rating": "-2.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces a novel approach to personalised federated learning within the $\\mathcal{X}$-armed bandit framework, addressing the challenge of optimising both local and global objectives in a highly heterogeneous environment. Our method employs a surrogate objective function that combines individual client preferences with aggregated global knowledge, allowing for a flexible trade-off between personalisation and collective learning. We propose a phase-based elimination algorithm that achieves sublinear regret with logarithmic communication overhead, making it well-suited for federated settings. Theoretical analysis and empirical evaluations demonstrate the effectiveness of our approach compared to existing methods. Potential applications of this work span various domains, including healthcare, smart home devices, and e-commerce, where balancing personalisation with global insights is crucial.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07291",
        "abstract url": "https://arxiv.org/abs/2409.07291",
        "title": "Exploring User-level Gradient Inversion with a Diffusion Prior",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "attack"
            ],
            [
                "facial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We explore user-level gradient inversion as a new attack surface in distributed learning. We first investigate existing attacks on their ability to make inferences about private information beyond training data reconstruction. Motivated by the low reconstruction quality of existing methods, we propose a novel gradient inversion attack that applies a denoising diffusion model as a strong image prior in order to enhance recovery in the large batch setting. Unlike traditional attacks, which aim to reconstruct individual samples and suffer at large batch and image sizes, our approach instead aims to recover a representative image that captures the sensitive shared semantic information corresponding to the underlying user. Our experiments with face images demonstrate the ability of our methods to recover realistic facial images along with private user attributes.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.CV",
            "stat.ML"
        ],
        "comment": "Presented at the International Workshop on Federated Learning in the Age of Foundation Models in conjunction with NeurIPS 2023"
    },
    {
        "paper id": "2409.07308",
        "abstract url": "https://arxiv.org/abs/2409.07308",
        "title": "Non-Invasive Glucose Prediction System Enhanced by Mixed Linear Models and Meta-Forests for Domain Generalization",
        "rating": "-2.5",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we present a non-invasive glucose prediction system that integrates Near-Infrared (NIR) spectroscopy and millimeter-wave (mm-wave) sensing. We employ a Mixed Linear Model (MixedLM) to analyze the association between mm-wave frequency S_21 parameters and blood glucose levels within a heterogeneous dataset. The MixedLM method considers inter-subject variability and integrates multiple predictors, offering a more comprehensive analysis than traditional correlation analysis. Additionally, we incorporate a Domain Generalization (DG) model, Meta-forests, to effectively handle domain variance in the dataset, enhancing the model's adaptability to individual differences. Our results demonstrate promising accuracy in glucose prediction for unseen subjects, with a mean absolute error (MAE) of 17.47 mg/dL, a root mean square error (RMSE) of 31.83 mg/dL, and a mean absolute percentage error (MAPE) of 10.88%, highlighting its potential for clinical application. This study marks a significant step towards developing accurate, personalized, and non-invasive glucose monitoring systems, contributing to improved diabetes management.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07415",
        "abstract url": "https://arxiv.org/abs/2409.07415",
        "title": "SoK: Security and Privacy Risks of Medical AI",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Medical",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The integration of technology and healthcare has ushered in a new era where software systems, powered by artificial intelligence and machine learning, have become essential components of medical products and services. While these advancements hold great promise for enhancing patient care and healthcare delivery efficiency, they also expose sensitive medical data and system integrity to potential cyberattacks. This paper explores the security and privacy threats posed by AI/ML applications in healthcare. Through a thorough examination of existing research across a range of medical domains, we have identified significant gaps in understanding the adversarial attacks targeting medical AI systems. By outlining specific adversarial threat models for medical settings and identifying vulnerable application domains, we lay the groundwork for future research that investigates the security and resilience of AI-driven medical systems. Through our analysis of different threat models and feasibility studies on adversarial attacks in different medical domains, we provide compelling insights into the pressing need for cybersecurity research in the rapidly evolving field of AI healthcare technology.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07505",
        "abstract url": "https://arxiv.org/abs/2409.07505",
        "title": "A Survey of Anomaly Detection in In-Vehicle Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Modern vehicles are equipped with Electronic Control Units (ECU) that are used for controlling important vehicle functions including safety-critical operations. ECUs exchange information via in-vehicle communication buses, of which the Controller Area Network (CAN bus) is by far the most widespread representative. Problems that may occur in the vehicle's physical parts or malicious attacks may cause anomalies in the CAN traffic, impairing the correct vehicle operation. Therefore, the detection of such anomalies is vital for vehicle safety. This paper reviews the research on anomaly detection for in-vehicle networks, more specifically for the CAN bus. Our main focus is the evaluation of methods used for CAN bus anomaly detection together with the datasets used in such analysis. To provide the reader with a more comprehensive understanding of the subject, we first give a brief review of related studies on time series-based anomaly detection. Then, we conduct an extensive survey of recent deep learning-based techniques as well as conventional techniques for CAN bus anomaly detection. Our comprehensive analysis delves into anomaly detection algorithms employed in in-vehicle networks, specifically focusing on their learning paradigms, inherent strengths, and weaknesses, as well as their efficacy when applied to CAN bus datasets. Lastly, we highlight challenges and open research problems in CAN bus anomaly detection.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07507",
        "abstract url": "https://arxiv.org/abs/2409.07507",
        "title": "Traceable LLM-based validation of statements in knowledge graphs",
        "rating": "-2.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "biosciences"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This article presents a method for verifying RDF triples using LLMs, with an emphasis on providing traceable arguments. Because the LLMs cannot currently reliably identify the origin of the information used to construct the response to the user query, our approach is to avoid using internal LLM factual knowledge altogether. Instead, verified RDF statements are compared to chunks of external documents retrieved through a web search or Wikipedia. To assess the possible application of this workflow on biosciences content, we evaluated 1,719 positive statements from the BioRED dataset and the same number of newly generated negative statements. The resulting precision is 88%, and recall is 44%. This indicates that the method requires human oversight. We demonstrate the method on Wikidata, where a SPARQL query is used to automatically retrieve statements needing verification. Overall, the results suggest that LLMs could be used for large-scale verification of statements in KGs, a task previously unfeasible due to human annotation costs.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07619",
        "abstract url": "https://arxiv.org/abs/2409.07619",
        "title": "Ensemble Methods for Sequence Classification with Hidden Markov Models",
        "rating": "-2.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "biology"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We present a lightweight approach to sequence classification using Ensemble Methods for Hidden Markov Models (HMMs). HMMs offer significant advantages in scenarios with imbalanced or smaller datasets due to their simplicity, interpretability, and efficiency. These models are particularly effective in domains such as finance and biology, where traditional methods struggle with high feature dimensionality and varied sequence lengths. Our ensemble-based scoring method enables the comparison of sequences of any length and improves performance on imbalanced datasets. This study focuses on the binary classification problem, particularly in scenarios with data imbalance, where the negative class is the majority (e.g., normal data) and the positive class is the minority (e.g., anomalous data), often with extreme distribution skews. We propose a novel training approach for HMM Ensembles that generalizes to multi-class problems and supports classification and anomaly detection. Our method fits class-specific groups of diverse models using random data subsets, and compares likelihoods across classes to produce composite scores, achieving high average precisions and AUCs. In addition, we compare our approach with neural network-based methods such as Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTMs), highlighting the efficiency and robustness of HMMs in data-scarce environments. Motivated by real-world use cases, our method demonstrates robust performance across various benchmarks, offering a flexible framework for diverse applications.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07671",
        "abstract url": "https://arxiv.org/abs/2409.07671",
        "title": "Transformed Physics-Informed Neural Networks for The Convection-Diffusion Equation",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Singularly perturbed problems are known to have solutions with steep boundary layers that are hard to resolve numerically. Traditional numerical methods, such as Finite Difference Methods (FDMs), require a refined mesh to obtain stable and accurate solutions. As Physics-Informed Neural Networks (PINNs) have been shown to successfully approximate solutions to differential equations from various fields, it is natural to examine their performance on singularly perturbed problems. The convection-diffusion equation is a representative example of such a class of problems, and we consider the use of PINNs to produce numerical solutions of this equation. We study two ways to use PINNS: as a method for correcting oscillatory discrete solutions obtained using FDMs, and as a method for modifying reduced solutions of unperturbed problems. For both methods, we also examine the use of input transformation to enhance accuracy, and we explain the behavior of input transformations analytically, with the help of neural tangent kernels.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07020",
        "abstract url": "https://arxiv.org/abs/2409.07020",
        "title": "EVENet: Evidence-based Ensemble Learning for Uncertainty-aware Brain Parcellation Using Diffusion MRI",
        "rating": "-3",
        "keywords": [
            [
                "voxel"
            ],
            [
                "Diffusion"
            ],
            [
                "health",
                "MRI",
                "disease",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this study, we developed an Evidence-based Ensemble Neural Network, namely EVENet, for anatomical brain parcellation using diffusion MRI. The key innovation of EVENet is the design of an evidential deep learning framework to quantify predictive uncertainty at each voxel during a single inference. Using EVENet, we obtained accurate parcellation and uncertainty estimates across different datasets from healthy and clinical populations and with different imaging acquisitions. The overall network includes five parallel subnetworks, where each is dedicated to learning the FreeSurfer parcellation for a certain diffusion MRI parameter. An evidence-based ensemble methodology is then proposed to fuse the individual outputs. We perform experimental evaluations on large-scale datasets from multiple imaging sources, including high-quality diffusion MRI data from healthy adults and clinically diffusion MRI data from participants with various brain diseases (schizophrenia, bipolar disorder, attention-deficit/hyperactivity disorder, Parkinson's disease, cerebral small vessel disease, and neurosurgical patients with brain tumors). Compared to several state-of-the-art methods, our experimental results demonstrate highly improved parcellation accuracy across the multiple testing datasets despite the differences in dMRI acquisition protocols and health conditions. Furthermore, thanks to the uncertainty estimation, our EVENet approach demonstrates a good ability to detect abnormal brain regions in patients with lesions, enhancing the interpretability and reliability of the segmentation results.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "15 pages, 5 figures"
    },
    {
        "paper id": "2409.07094",
        "abstract url": "https://arxiv.org/abs/2409.07094",
        "title": "Deep intra-operative illumination calibration of hyperspectral cameras",
        "rating": "-3",
        "keywords": [
            [
                "surgical",
                "surgery",
                "clinical",
                "physiological"
            ],
            [
                "Hyperspectral imaging"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Hyperspectral imaging (HSI) is emerging as a promising novel imaging modality with various potential surgical applications. Currently available cameras, however, suffer from poor integration into the clinical workflow because they require the lights to be switched off, or the camera to be manually recalibrated as soon as lighting conditions change. Given this critical bottleneck, the contribution of this paper is threefold: (1) We demonstrate that dynamically changing lighting conditions in the operating room dramatically affect the performance of HSI applications, namely physiological parameter estimation, and surgical scene segmentation. (2) We propose a novel learning-based approach to automatically recalibrating hyperspectral images during surgery and show that it is sufficiently accurate to replace the tedious process of white reference-based recalibration. (3) Based on a total of 742 HSI cubes from a phantom, porcine models, and rats we show that our recalibration method not only outperforms previously proposed methods, but also generalizes across species, lighting conditions, and image processing tasks. Due to its simple workflow integration as well as high accuracy, speed, and generalization capabilities, our method could evolve as a central component in clinical surgical HSI.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Oral at MICCAI 2024"
    },
    {
        "paper id": "2409.07104",
        "abstract url": "https://arxiv.org/abs/2409.07104",
        "title": "Developing a Framework for Sonifying Variational Quantum Algorithms: Implications for Music Composition",
        "rating": "-3",
        "keywords": [
            [
                "Music"
            ],
            [
                "Quantum",
                "physics"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This chapter examines the Variational Quantum Harmonizer, a software tool and musical interface that focuses on the problem of sonification of the minimization steps of Variational Quantum Algorithms (VQA), used for simulating properties of quantum systems and optimization problems assisted by quantum hardware. Particularly, it details the sonification of Quadratic Unconstrained Binary Optimization (QUBO) problems using VQA. A flexible design enables its future applications both as a sonification tool for auditory displays in scientific investigation, and as a hybrid quantum-digital musical instrument for artistic endeavours. In turn, sonification can help researchers understand complex systems better and can serve for the training of quantum physics and quantum computing. The VQH structure, including its software implementation, control mechanisms, and sonification mappings are detailed. Moreover, it guides the design of QUBO cost functions in VQH as a music compositional object. The discussion is extended to the implications of applying quantum-assisted simulation in quantum-computer aided composition and live-coding performances. An artistic output is showcased by the piece \\textit{Hexagonal Chambers} (Thomas and Itabora\u00ed, 2023).",
        "subjects": [
            "cs.SD",
            "cs.ET",
            "cs.HC",
            "eess.AS",
            "quant-ph"
        ],
        "comment": "This is a non-edited pre-publication version of a chapter to appear in the book Advances in Quantum Computer Music, World Scientific, editor E. R. Miranda, 2024. ISBN:978-981-98-0017-9"
    },
    {
        "paper id": "2409.07110",
        "abstract url": "https://arxiv.org/abs/2409.07110",
        "title": "Bio-Eng-LMM AI Assist chatbot: A Comprehensive Tool for Research and Education",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Bio-Eng-LMM"
            ]
        ],
        "abstract": "This article introduces Bio-Eng-LMM AI chatbot, a versatile platform designed to enhance user interaction for educational and research purposes. Leveraging cutting-edge open-source Large Language Models (LLMs), Bio-Eng-LMM operates as a sophisticated AI assistant, exploiting the capabilities of traditional models like ChatGPT. Central to Bio-Eng-LMM is its implementation of Retrieval Augmented Generation (RAG) through three primary methods: integration of preprocessed documents, real-time processing of user-uploaded files, and information retrieval from any specified website. Additionally, the chatbot incorporates image generation via a Stable Diffusion Model (SDM), image understanding and response generation through LLAVA, and search functionality on the internet powered by secure search engine such as DuckDuckGo. To provide comprehensive support, Bio-Eng-LMM offers text summarization, website content summarization, and both text and voice interaction. The chatbot maintains session memory to ensure contextually relevant and coherent responses. This integrated platform builds upon the strengths of RAG-GPT and Web-Based RAG Query (WBRQ) where the system fetches relevant information directly from the web to enhance the LLMs response generation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07145",
        "abstract url": "https://arxiv.org/abs/2409.07145",
        "title": "The Critical Role of Effective Communication in Human-Robot Collaborative Assembly",
        "rating": "-3",
        "keywords": [
            [
                "Robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "In the rapidly evolving landscape of Human-Robot Collaboration (HRC), effective communication between humans and robots is crucial for complex task execution. Traditional request-response systems often lack naturalness and may hinder efficiency. This study emphasizes the importance of adopting human-like communication interactions to enable fluent vocal communication between human operators and robots simulating a collaborative human-robot industrial assembly. We propose a novel approach that employs human-like interactions through natural dialogue, enabling human operators to engage in vocal conversations with robots. Through a comparative experiment, we demonstrate the efficacy of our approach in enhancing task performance and collaboration efficiency. The robot's ability to engage in meaningful vocal conversations enables it to seek clarification, provide status updates, and ask for assistance when required, leading to improved coordination and a smoother workflow. The results indicate that the adoption of human-like conversational interactions positively influences the human-robot collaborative dynamic. Human operators find it easier to convey complex instructions and preferences, resulting in a more productive and satisfying collaboration experience.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07150",
        "abstract url": "https://arxiv.org/abs/2409.07150",
        "title": "ZKFault: Fault attack analysis on zero-knowledge based post-quantum digital signature schemes",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Computationally hard problems based on coding theory, such as the syndrome decoding problem, have been used for constructing secure cryptographic schemes for a long time. Schemes based on these problems are also assumed to be secure against quantum computers. However, these schemes are often considered impractical for real-world deployment due to large key sizes and inefficient computation time. In the recent call for standardization of additional post-quantum digital signatures by the National Institute of Standards and Technology, several code-based candidates have been proposed, including LESS, CROSS, and MEDS. These schemes are designed on the relatively new zero-knowledge framework. Although several works analyze the hardness of these schemes, there is hardly any work that examines the security of these schemes in the presence of physical attacks. In this work, we analyze these signature schemes from the perspective of fault attacks. All these schemes use a similar tree-based construction to compress the signature size. We attack this component of these schemes. Therefore, our attack is applicable to all of these schemes. In this work, we first analyze the LESS signature scheme and devise our attack. Furthermore, we showed how this attack can be extended to the CROSS signature scheme. Our attacks are built on very simple fault assumptions. Our results show that we can recover the entire secret key of LESS and CROSS using as little as a single fault. Finally, we propose various countermeasures to prevent these kinds of attacks and discuss their efficiency and shortcomings.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "35 pages including appendix and bibliography"
    },
    {
        "paper id": "2409.07160",
        "abstract url": "https://arxiv.org/abs/2409.07160",
        "title": "Distance Measurement for UAVs in Deep Hazardous Tunnels",
        "rating": "-3",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "The localization of Unmanned aerial vehicles (UAVs) in deep tunnels is extremely challenging due to their inaccessibility and hazardous environment. Conventional outdoor localization techniques (such as using GPS) and indoor localization techniques (such as those based on WiFi, Infrared (IR), Ultra-Wideband, etc.) do not work in deep tunnels. We are developing a UAV-based system for the inspection of defects in the Deep Tunnel Sewerage System (DTSS) in Singapore. To enable the UAV localization in the DTSS, we have developed a distance measurement module based on the optical flow technique. However, the standard optical flow technique does not work well in tunnels with poor lighting and a lack of features. Thus, we have developed an enhanced optical flow algorithm with prediction, to improve the distance measurement for UAVs in deep hazardous tunnels.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07171",
        "abstract url": "https://arxiv.org/abs/2409.07171",
        "title": "AC-IND: Sparse CT reconstruction based on attenuation coefficient estimation and implicit neural distribution",
        "rating": "-3",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "CT"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Computed tomography (CT) reconstruction plays a crucial role in industrial nondestructive testing and medical diagnosis. Sparse view CT reconstruction aims to reconstruct high-quality CT images while only using a small number of projections, which helps to improve the detection speed of industrial assembly lines and is also meaningful for reducing radiation in medical scenarios. Sparse CT reconstruction methods based on implicit neural representations (INRs) have recently shown promising performance, but still produce artifacts because of the difficulty of obtaining useful prior information. In this work, we incorporate a powerful prior: the total number of material categories of objects. To utilize the prior, we design AC-IND, a self-supervised method based on Attenuation Coefficient Estimation and Implicit Neural Distribution. Specifically, our method first transforms the traditional INR from scalar mapping to probability distribution mapping. Then we design a compact attenuation coefficient estimator initialized with values from a rough reconstruction and fast segmentation. Finally, our algorithm finishes the CT reconstruction by jointly optimizing the estimator and the generated distribution. Through experiments, we find that our method not only outperforms the comparative methods in sparse CT reconstruction but also can automatically generate semantic segmentation maps.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2409.07179",
        "abstract url": "https://arxiv.org/abs/2409.07179",
        "title": "Phy124: Fast Physics-Driven 4D Content Generation from a Single Image",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "4D content generation focuses on creating dynamic 3D objects that change over time. Existing methods primarily rely on pre-trained video diffusion models, utilizing sampling processes or reference videos. However, these approaches face significant challenges. Firstly, the generated 4D content often fails to adhere to real-world physics since video diffusion models do not incorporate physical priors. Secondly, the extensive sampling process and the large number of parameters in diffusion models result in exceedingly time-consuming generation processes. To address these issues, we introduce Phy124, a novel, fast, and physics-driven method for controllable 4D content generation from a single image. Phy124 integrates physical simulation directly into the 4D generation process, ensuring that the resulting 4D content adheres to natural physical laws. Phy124 also eliminates the use of diffusion models during the 4D dynamics generation phase, significantly speeding up the process. Phy124 allows for the control of 4D dynamics, including movement speed and direction, by manipulating external forces. Extensive experiments demonstrate that Phy124 generates high-fidelity 4D content with significantly reduced inference times, achieving stateof-the-art performance. The code and generated 4D content are available at the provided link: https://anonymous.4open.science/r/BBF2/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07200",
        "abstract url": "https://arxiv.org/abs/2409.07200",
        "title": "ThermalGaussian: Thermal 3D Gaussian Splatting",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "infrared"
            ],
            [
                "Thermal"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Thermography is especially valuable for the military and other users of surveillance cameras. Some recent methods based on Neural Radiance Fields (NeRF) are proposed to reconstruct the thermal scenes in 3D from a set of thermal and RGB images. However, unlike NeRF, 3D Gaussian splatting (3DGS) prevails due to its rapid training and real-time rendering. In this work, we propose ThermalGaussian, the first thermal 3DGS approach capable of rendering high-quality images in RGB and thermal modalities. We first calibrate the RGB camera and the thermal camera to ensure that both modalities are accurately aligned. Subsequently, we use the registered images to learn the multimodal 3D Gaussians. To prevent the overfitting of any single modality, we introduce several multimodal regularization constraints. We also develop smoothing constraints tailored to the physical characteristics of the thermal modality. Besides, we contribute a real-world dataset named RGBT-Scenes, captured by a hand-hold thermal-infrared camera, facilitating future research on thermal scene reconstruction. We conduct comprehensive experiments to show that ThermalGaussian achieves photorealistic rendering of thermal images and improves the rendering quality of RGB images. With the proposed multimodal regularization constraints, we also reduced the model's storage cost by 90\\%. The code and dataset will be released.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "10 pages, 7 figures"
    },
    {
        "paper id": "2409.07255",
        "abstract url": "https://arxiv.org/abs/2409.07255",
        "title": "EMOdiffhead: Continuously Emotional Control in Talking Head Generation via Diffusion",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The task of audio-driven portrait animation involves generating a talking head video using an identity image and an audio track of speech. While many existing approaches focus on lip synchronization and video quality, few tackle the challenge of generating emotion-driven talking head videos. The ability to control and edit emotions is essential for producing expressive and realistic animations. In response to this challenge, we propose EMOdiffhead, a novel method for emotional talking head video generation that not only enables fine-grained control of emotion categories and intensities but also enables one-shot generation. Given the FLAME 3D model's linearity in expression modeling, we utilize the DECA method to extract expression vectors, that are combined with audio to guide a diffusion model in generating videos with precise lip synchronization and rich emotional expressiveness. This approach not only enables the learning of rich facial information from emotion-irrelevant data but also facilitates the generation of emotional videos. It effectively overcomes the limitations of emotional data, such as the lack of diversity in facial and background information, and addresses the absence of emotional details in emotion-irrelevant data. Extensive experiments and user studies demonstrate that our approach achieves state-of-the-art performance compared to other emotion portrait animation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2409.07293",
        "abstract url": "https://arxiv.org/abs/2409.07293",
        "title": "Electrokinetic Propulsion for Electronically Integrated Microscopic Robots",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Robots too small to see by eye have rapidly evolved in recent years thanks to the incorporation of on-board microelectronics. Semiconductor circuits have been used in microrobots capable of executing controlled wireless steering, prescribed legged gait patterns, and user-triggered transitions between digital states. Yet these promising new capabilities have come at the steep price of complicated fabrication. Even though circuit components can be reliably built by semiconductor foundries, currently available actuators for electronically integrated microrobots are built with intricate multi-step cleanroom protocols and use mechanisms like articulated legs or bubble generators that are hard to design and control. Here, we present a propulsion system for electronically integrated microrobots that can be built with a single step of lithographic processing, readily integrates with microelectronics thanks to low current/low voltage operation (1V, 10nA), and yields robots that swim at speeds over one body length per second. Inspired by work on micromotors, these robots generate electric fields in a surrounding fluid, and by extension propulsive electrokinetic flows. The underlying physics is captured by a model in which robot speed is proportional to applied current, making design and control straightforward. As proof, we build basic robots that use on-board circuits and a closed-loop optical control scheme to navigate waypoints and move in coordinated swarms. Broadly, solid-state propulsion clears the way for robust, easy to manufacture, electronically controlled microrobots that operate reliably over months to years.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07322",
        "abstract url": "https://arxiv.org/abs/2409.07322",
        "title": "Three-Dimensional, Multimodal Synchrotron Data for Machine Learning Applications",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "super-resolution"
            ],
            [
                "medical",
                "X-ray"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Machine learning techniques are being increasingly applied in medical and physical sciences across a variety of imaging modalities; however, an important issue when developing these tools is the availability of good quality training data. Here we present a unique, multimodal synchrotron dataset of a bespoke zinc-doped Zeolite 13X sample that can be used to develop advanced deep learning and data fusion pipelines. Multi-resolution micro X-ray computed tomography was performed on a zinc-doped Zeolite 13X fragment to characterise its pores and features, before spatially resolved X-ray diffraction computed tomography was carried out to characterise the homogeneous distribution of sodium and zinc phases. Zinc absorption was controlled to create a simple, spatially isolated, two-phase material. Both raw and processed data is available as a series of Zenodo entries. Altogether we present a spatially resolved, three-dimensional, multimodal, multi-resolution dataset that can be used for the development of machine learning techniques. Such techniques include development of super-resolution, multimodal data fusion, and 3D reconstruction algorithm development.",
        "subjects": [
            "cs.LG",
            "eess.IV"
        ],
        "comment": "9 pages, 4 figures. Image Processing and Artificial Intelligence Conference, 2024"
    },
    {
        "paper id": "2409.07343",
        "abstract url": "https://arxiv.org/abs/2409.07343",
        "title": "Learning Robotic Manipulation Policies from Point Clouds with Conditional Flow Matching",
        "rating": "-3",
        "keywords": [
            [
                "point cloud",
                "6-DoF"
            ],
            [
                "Diffusion"
            ],
            [
                "Robotic Manipulation"
            ]
        ],
        "abstract": "Learning from expert demonstrations is a promising approach for training robotic manipulation policies from limited data. However, imitation learning algorithms require a number of design choices ranging from the input modality, training objective, and 6-DoF end-effector pose representation. Diffusion-based methods have gained popularity as they enable predicting long-horizon trajectories and handle multimodal action distributions. Recently, Conditional Flow Matching (CFM) (or Rectified Flow) has been proposed as a more flexible generalization of diffusion models. In this paper, we investigate the application of CFM in the context of robotic policy learning and specifically study the interplay with the other design choices required to build an imitation learning algorithm. We show that CFM gives the best performance when combined with point cloud input observations. Additionally, we study the feasibility of a CFM formulation on the SO(3) manifold and evaluate its suitability with a simplified example. We perform extensive experiments on RLBench which demonstrate that our proposed PointFlowMatch approach achieves a state-of-the-art average success rate of 67.8% over eight tasks, double the performance of the next best method.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Presented at CoRL 2024. Project website at http://pointflowmatch.cs.uni-freiburg.de/"
    },
    {
        "paper id": "2409.07374",
        "abstract url": "https://arxiv.org/abs/2409.07374",
        "title": "Extracting TCPIP Headers at High Speed for the Anonymized Network Traffic Graph Challenge",
        "rating": "-3",
        "keywords": [
            [
                "Graph"
            ],
            [
                "FPGAs"
            ]
        ],
        "abstract": "Field Programmable Gate Arrays (FPGAs) play a significant role in computationally intensive network processing due to their flexibility and efficiency. Particularly with the high-level abstraction of the P4 network programming model, FPGA shows a powerful potential for packet processing. By supporting the P4 language with FPGA processing, network researchers can create customized FPGA-based network functions and execute network tasks on accelerators directly connected to the network. A feature of the P4 language is that it is stateless; however, the FPGA implementation in this research requires state information. This is accomplished using P4 externs to describe the stateful portions of the design and to implement them on the FPGA using High-Level Synthesis (HLS). This paper demonstrates using an FPGA-based SmartNIC to efficiently extract source-destination IP address information from network packets and construct anonymized network traffic matrices for further analysis. The implementation is the first example of the combination of using P4 and HLS in developing network functions on the latest AMD FPGAs. Our design achieves a processing rate of approximately 95 Gbps with the combined use of P4 and High-level Synthesis and is able to keep up with 100 Gbps traffic received directly from the network.",
        "subjects": [
            "cs.NI",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07390",
        "abstract url": "https://arxiv.org/abs/2409.07390",
        "title": "D-CAPTCHA++: A Study of Resilience of Deepfake CAPTCHA under Transferable Imperceptible Adversarial Attack",
        "rating": "-3",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "Attack"
            ],
            [
                "text-to-speech",
                "voice conversion"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The advancements in generative AI have enabled the improvement of audio synthesis models, including text-to-speech and voice conversion. This raises concerns about its potential misuse in social manipulation and political interference, as synthetic speech has become indistinguishable from natural human speech. Several speech-generation programs are utilized for malicious purposes, especially impersonating individuals through phone calls. Therefore, detecting fake audio is crucial to maintain social security and safeguard the integrity of information. Recent research has proposed a D-CAPTCHA system based on the challenge-response protocol to differentiate fake phone calls from real ones. In this work, we study the resilience of this system and introduce a more robust version, D-CAPTCHA++, to defend against fake calls. Specifically, we first expose the vulnerability of the D-CAPTCHA system under transferable imperceptible adversarial attack. Secondly, we mitigate such vulnerability by improving the robustness of the system by using adversarial training in D-CAPTCHA deepfake detectors and task classifiers.",
        "subjects": [
            "cs.CR",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.07433",
        "abstract url": "https://arxiv.org/abs/2409.07433",
        "title": "Dot Product is All You Need: Bridging the Gap Between Item Recommendation and Link Prediction",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "Recommendation"
            ]
        ],
        "abstract": "Item recommendation (the task of predicting if a user may interact with new items from the catalogue in a recommendation system) and link prediction (the task of identifying missing links in a knowledge graph) have long been regarded as distinct problems. In this work, we show that the item recommendation problem can be seen as an instance of the link prediction problem, where entities in the graph represent users and items, and the task consists of predicting missing instances of the relation type <<interactsWith>>. In a preliminary attempt to demonstrate the assumption, we decide to test three popular factorisation-based link prediction models on the item recommendation task, showing that their predictive accuracy is competitive with ten state-of-the-art recommendation models. The purpose is to show how the former may be seamlessly and effectively applied to the recommendation task without any specific modification to their architectures. Finally, while beginning to unveil the key reasons behind the recommendation performance of the selected link prediction models, we explore different settings for their hyper-parameter values, paving the way for future directions.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07609",
        "abstract url": "https://arxiv.org/abs/2409.07609",
        "title": "A Cost-Aware Approach to Adversarial Robustness in Neural Networks",
        "rating": "-3",
        "keywords": [
            [
                "time-efficient"
            ],
            [
                "attacks"
            ],
            [
                "medical",
                "survival"
            ],
            [
                "drone"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Considering the growing prominence of production-level AI and the threat of adversarial attacks that can evade a model at run-time, evaluating the robustness of models to these evasion attacks is of critical importance. Additionally, testing model changes likely means deploying the models to (e.g. a car or a medical imaging device), or a drone to see how it affects performance, making un-tested changes a public problem that reduces development speed, increases cost of development, and makes it difficult (if not impossible) to parse cause from effect. In this work, we used survival analysis as a cloud-native, time-efficient and precise method for predicting model performance in the presence of adversarial noise. For neural networks in particular, the relationships between the learning rate, batch size, training time, convergence time, and deployment cost are highly complex, so researchers generally rely on benchmark datasets to assess the ability of a model to generalize beyond the training data. To address this, we propose using accelerated failure time models to measure the effect of hardware choice, batch size, number of epochs, and test-set accuracy by using adversarial attacks to induce failures on a reference model architecture before deploying the model to the real world. We evaluate several GPU types and use the Tree Parzen Estimator to maximize model robustness and minimize model run-time simultaneously. This provides a way to evaluate the model and optimise it in a single step, while simultaneously allowing us to model the effect of model parameters on training time, prediction time, and accuracy. Using this technique, we demonstrate that newer, more-powerful hardware does decrease the training time, but with a monetary and power cost that far outpaces the marginal gains in accuracy.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07690",
        "abstract url": "https://arxiv.org/abs/2409.07690",
        "title": "Characterization and Design of A Hollow Cylindrical Ultrasonic Motor",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "MRI"
            ]
        ],
        "abstract": "Piezoelectric ultrasonic motors perform the advantages of compact design, faster reaction time, and simpler setup compared to other motion units such as pneumatic and hydraulic motors, especially its non-ferromagnetic property makes it a perfect match in MRI-compatible robotics systems compared to traditional DC motors. Hollow shaft motors address the advantages of being lightweight and comparable to solid shafts of the same diameter, low rotational inertia, high tolerance to rotational imbalance due to low weight, and tolerance to high temperature due to low specific mass. This article presents a prototype of a hollow cylindrical ultrasonic motor (HCM) to perform direct drive, eliminate mechanical non-linearity, and reduce the size and complexity of the actuator or end effector assembly. Two equivalent HCMs are presented in this work, and under 50g prepressure on the rotor, it performed 383.3333rpm rotation speed and 57.3504mNm torque output when applying 282$V_{pp}$ driving voltage.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages, 9 figures, 2 tables"
    },
    {
        "paper id": "2409.07715",
        "abstract url": "https://arxiv.org/abs/2409.07715",
        "title": "FIReStereo: Forest InfraRed Stereo Dataset for UAS Depth Perception in Visually Degraded Environments",
        "rating": "-3",
        "keywords": [
            [
                "Depth"
            ],
            [
                "LiDAR",
                "InfraRed"
            ],
            [
                "Thermal"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Robust depth perception in visually-degraded environments is crucial for autonomous aerial systems. Thermal imaging cameras, which capture infrared radiation, are robust to visual degradation. However, due to lack of a large-scale dataset, the use of thermal cameras for unmanned aerial system (UAS) depth perception has remained largely unexplored. This paper presents a stereo thermal depth perception dataset for autonomous aerial perception applications. The dataset consists of stereo thermal images, LiDAR, IMU and ground truth depth maps captured in urban and forest settings under diverse conditions like day, night, rain, and smoke. We benchmark representative stereo depth estimation algorithms, offering insights into their performance in degraded conditions. Models trained on our dataset generalize well to unseen smoky conditions, highlighting the robustness of stereo thermal imaging for depth perception. We aim for this work to enhance robotic perception in disaster scenarios, allowing for exploration and operations in previously unreachable areas. The dataset and source code are available at https://firestereo.github.io.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Under review in RA-L. The first 2 authors contributed equally"
    },
    {
        "paper id": "2409.07743",
        "abstract url": "https://arxiv.org/abs/2409.07743",
        "title": "LOCKEY: A Novel Approach to Model Authentication and Deepfake Tracking",
        "rating": "-3",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "watermarking"
            ]
        ],
        "abstract": "This paper presents a novel approach to deter unauthorized deepfakes and enable user tracking in generative models, even when the user has full access to the model parameters, by integrating key-based model authentication with watermarking techniques. Our method involves providing users with model parameters accompanied by a unique, user-specific key. During inference, the model is conditioned upon the key along with the standard input. A valid key results in the expected output, while an invalid key triggers a degraded output, thereby enforcing key-based model authentication. For user tracking, the model embeds the user's unique key as a watermark within the generated content, facilitating the identification of the user's ID. We demonstrate the effectiveness of our approach on two types of models, audio codecs and vocoders, utilizing the SilentCipher watermarking method. Additionally, we assess the robustness of the embedded watermarks against various distortions, validating their reliability in various scenarios.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Authenticating deep generative models, 5 pages, 5 figures, 2 tables"
    },
    {
        "paper id": "2409.07569",
        "abstract url": "https://arxiv.org/abs/2409.07569",
        "title": "A Survey of Inverse Constrained Reinforcement Learning: Definitions, Progress and Challenges",
        "rating": "-3.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "robot"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Inverse Constrained Reinforcement Learning (ICRL) is the task of inferring the implicit constraints followed by expert agents from their demonstration data. As an emerging research topic, ICRL has received considerable attention in recent years. This article presents a categorical survey of the latest advances in ICRL. It serves as a comprehensive reference for machine learning researchers and practitioners, as well as starters seeking to comprehend the definitions, advancements, and important challenges in ICRL. We begin by formally defining the problem and outlining the algorithmic framework that facilitates constraint inference across various scenarios. These include deterministic or stochastic environments, environments with limited demonstrations, and multiple agents. For each context, we illustrate the critical challenges and introduce a series of fundamental methods to tackle these issues. This survey encompasses discrete, virtual, and realistic environments for evaluating ICRL agents. We also delve into the most pertinent applications of ICRL, such as autonomous driving, robot control, and sports analytics. To stimulate continuing research, we conclude the survey with a discussion of key unresolved questions in ICRL that can effectively foster a bridge between theoretical understanding and practical industrial applications.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "28 pages"
    },
    {
        "paper id": "2409.07222",
        "abstract url": "https://arxiv.org/abs/2409.07222",
        "title": "Dual-Step Optimization for Binary Sequences with High Merit Factors",
        "rating": "-4",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "The problem of finding aperiodic low auto-correlation binary sequences (LABS) presents a significant computational challenge, particularly as the sequence length increases. Such sequences have important applications in communication engineering, physics, chemistry, and cryptography. This paper introduces a novel dual-step algorithm for long binary sequences with high merit factors. The first step employs a parallel algorithm utilizing skew-symmetry and restriction classes to generate sequence candidates with merit factors above a predefined threshold. The second step uses a priority queue algorithm to refine these candidates further, searching the entire search space unrestrictedly. By combining GPU-based parallel computing and dual-step optimization, our approach has successfully identified new best-known binary sequences for all lengths ranging from 450 to 527, with the exception of length 518, where the previous best-known value was matched with a different sequence. This hybrid method significantly outperforms traditional exhaustive and stochastic search methods, offering an efficient solution for finding long sequences with good merit factors.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "14 pages, 6 figures, 2 tables"
    },
    {
        "paper id": "2409.07367",
        "abstract url": "https://arxiv.org/abs/2409.07367",
        "title": "Enhancing Sequential Music Recommendation with Negative Feedback-informed Contrastive Learning",
        "rating": "-4",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "Music"
            ]
        ],
        "abstract": "Modern music streaming services are heavily based on recommendation engines to serve content to users. Sequential recommendation -- continuously providing new items within a single session in a contextually coherent manner -- has been an emerging topic in current literature. User feedback -- a positive or negative response to the item presented -- is used to drive content recommendations by learning user preferences. We extend this idea to session-based recommendation to provide context-coherent music recommendations by modelling negative user feedback, i.e., skips, in the loss function. We propose a sequence-aware contrastive sub-task to structure item embeddings in session-based music recommendation, such that true next-positive items (ignoring skipped items) are structured closer in the session embedding space, while skipped tracks are structured farther away from all items in the session. This directly affects item rankings using a K-nearest-neighbors search for next-item recommendations, while also promoting the rank of the true next item. Experiments incorporating this task into SoTA methods for sequential item recommendation show consistent performance gains in terms of next-item hit rate, item ranking, and skip down-ranking on three music recommendation datasets, strongly benefiting from the increasing presence of user feedback.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "To-appear at 18th ACM Conference on Recommendation Systems"
    },
    {
        "paper id": "2409.07389",
        "abstract url": "https://arxiv.org/abs/2409.07389",
        "title": "Dynamic Bayesian Networks, Elicitation and Data Embedding for Secure Environments",
        "rating": "-4",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "attack"
            ],
            [
                "crime"
            ]
        ],
        "abstract": "Serious crime modelling typically needs to be undertaken securely behind a firewall where police knowledge and capabilities can remain undisclosed. Data informing an ongoing incident is often sparse, with a large proportion of relevant data only coming to light after the incident culminates or after police intervene - by which point it is too late to make use of the data to aid real-time decision making for the incident in question. Much of the data that is available to police to support real-time decision making is highly confidential so cannot be shared with academics, and is therefore missing to them. In this paper, we describe the development of a formal protocol where a graphical model is used as a framework for securely translating a model designed by an academic team to a model for use by a police team. We then show, for the first time, how libraries of these models can be built and used for real-time decision support to circumvent the challenges of data missingness and tardiness seen in such a secure environment. The parallel development described by this protocol ensures that any sensitive information collected by police, and missing to academics, remains secured behind a firewall. The protocol nevertheless guides police so that they are able to combine the typically incomplete data streams that are open source with their more sensitive information in a formal and justifiable way. We illustrate the application of this protocol by describing how a new entry - a suspected vehicle attack - can be embedded into such a police library of criminal plots.",
        "subjects": [
            "stat.AP",
            "cs.CR",
            "stat.ME"
        ],
        "comment": "34 pages, 1 figure. Submitted to Entropy journal"
    },
    {
        "paper id": "2409.07441",
        "abstract url": "https://arxiv.org/abs/2409.07441",
        "title": "Instant Facial Gaussians Translator for Relightable and Interactable Facial Rendering",
        "rating": "-4",
        "keywords": [
            [
                "Gaussian Splatting"
            ],
            [
                "diffusion"
            ],
            [
                "Facial"
            ]
        ],
        "abstract": "We propose GauFace, a novel Gaussian Splatting representation, tailored for efficient animation and rendering of physically-based facial assets. Leveraging strong geometric priors and constrained optimization, GauFace ensures a neat and structured Gaussian representation, delivering high fidelity and real-time facial interaction of 30fps@1440p on a Snapdragon 8 Gen 2 mobile platform. Then, we introduce TransGS, a diffusion transformer that instantly translates physically-based facial assets into the corresponding GauFace representations. Specifically, we adopt a patch-based pipeline to handle the vast number of Gaussians effectively. We also introduce a novel pixel-aligned sampling scheme with UV positional encoding to ensure the throughput and rendering quality of GauFace assets generated by our TransGS. Once trained, TransGS can instantly translate facial assets with lighting conditions to GauFace representation, With the rich conditioning modalities, it also enables editing and animation capabilities reminiscent of traditional CG pipelines. We conduct extensive evaluations and user studies, compared to traditional offline and online renderers, as well as recent neural rendering methods, which demonstrate the superior performance of our approach for facial asset rendering. We also showcase diverse immersive applications of facial assets using our TransGS approach and GauFace representation, across various platforms like PCs, phones and even VR headsets.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "Project Page: https://dafei-qin.github.io/TransGS.github.io/"
    },
    {
        "paper id": "2409.07564",
        "abstract url": "https://arxiv.org/abs/2409.07564",
        "title": "TabMixer: Noninvasive Estimation of the Mean Pulmonary Artery Pressure via Imaging and Tabular Data Mixing",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "diagnosing",
                "clinical",
                "Cardiac"
            ],
            [
                "Tabular"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Right Heart Catheterization is a gold standard procedure for diagnosing Pulmonary Hypertension by measuring mean Pulmonary Artery Pressure (mPAP). It is invasive, costly, time-consuming and carries risks. In this paper, for the first time, we explore the estimation of mPAP from videos of noninvasive Cardiac Magnetic Resonance Imaging. To enhance the predictive capabilities of Deep Learning models used for this task, we introduce an additional modality in the form of demographic features and clinical measurements. Inspired by all-Multilayer Perceptron architectures, we present TabMixer, a novel module enabling the integration of imaging and tabular data through spatial, temporal and channel mixing. Specifically, we present the first approach that utilizes Multilayer Perceptrons to interchange tabular information with imaging features in vision models. We test TabMixer for mPAP estimation and show that it enhances the performance of Convolutional Neural Networks, 3D-MLP and Vision Transformers while being competitive with previous modules for imaging and tabular data. Our approach has the potential to improve clinical processes involving both modalities, particularly in noninvasive mPAP estimation, thus, significantly enhancing the quality of life for individuals affected by Pulmonary Hypertension. We provide a source code for using TabMixer at https://github.com/SanoScience/TabMixer.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted for the 27th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2024"
    },
    {
        "paper id": "2409.07591",
        "abstract url": "https://arxiv.org/abs/2409.07591",
        "title": "CAVERNAUTE: a design and manufacturing pipeline of a rigid but foldable indoor airship aerial system for cave exploration",
        "rating": "-4",
        "keywords": [
            [
                "flight"
            ],
            [
                "robot"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Airships, best recognized for their unique quality of payload/energy ratio, present a fascinating challenge for the field of engineering. Their construction and operation require a delicate balance of materials and rules, making them a compelling object of study. They embody a distinct intersection of physics, design, and innovation, offering a wide array of possibilities for future transportation and exploration. Thanks to their long-flight endurance, they are suited for long-term missions. To operate in complex environments such as indoor cluttered spaces, their membrane and mechatronics need to be protected from impacts. This paper presents a new indoor airship design inspired by origami and the Kresling pattern. The airship structure combines a carbon fiber exoskeleton and UV resin micro-lattices for shock absorption. Our design strengthens the robot while granting the ability to access narrow spaces by folding the structure - up to a volume expansion ratio of 19.8. To optimize the numerous parameters of the airship, we present a pipeline for design, manufacture, and assembly. It takes into account manufacturing constraints, dimensions of the target deployment area, and aerostatics, allowing for easy and quick testing of new configurations. We also present unique features made possible by combining origami with airship design, which reduces the chances of mission-compromising failures. We demonstrate the potential of the design with a complete simulation including an effective control strategy leveraging lightweight mechatronics to optimize flight autonomy in exploration missions of unstructured environments.",
        "subjects": [
            "cs.RO",
            "cond-mat.other"
        ],
        "comment": "36 pages, 21 figures"
    },
    {
        "paper id": "2409.07556",
        "abstract url": "https://arxiv.org/abs/2409.07556",
        "title": "SSR-Speech: Towards Stable, Safe and Robust Zero-shot Text-based Speech Editing and Synthesis",
        "rating": "-4.5",
        "keywords": [
            [
                "watermark"
            ],
            [
                "neural codec"
            ],
            [
                "text-to-speech"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In this paper, we introduce SSR-Speech, a neural codec autoregressive model designed for stable, safe, and robust zero-shot text-based speech editing and text-to-speech synthesis. SSR-Speech is built on a Transformer decoder and incorporates classifier-free guidance to enhance the stability of the generation process. A watermark Encodec is proposed to embed frame-level watermarks into the edited regions of the speech so that which parts were edited can be detected. In addition, the waveform reconstruction leverages the original unedited speech segments, providing superior recovery compared to the Encodec model. Our approach achieves the state-of-the-art performance in the RealEdit speech editing task and the LibriTTS text-to-speech task, surpassing previous methods. Furthermore, SSR-Speech excels in multi-span speech editing and also demonstrates remarkable robustness to background sounds. Source code and demos are released.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.07333",
        "abstract url": "https://arxiv.org/abs/2409.07333",
        "title": "Joint Energy and SINR Coverage Probability in UAV Corridor-assisted RF-powered IoT Networks",
        "rating": "-5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "IoT"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "This letter studies the joint energy and signal-to-interference-plus-noise (SINR)-based coverage probability in Unmanned Aerial Vehicle (UAV)-assisted radio frequency (RF)-powered Internet of Things (IoT) networks. The UAVs are spatially distributed in an aerial corridor that is modeled as a one-dimensional (1D) binomial point process (BPP). By accurately capturing the line-of-sight (LoS) probability of a UAV through large-scale fading i) an exact form expression for the energy coverage probability is derived, and ii) a tight approximation for the overall coverage performance is obtained. Among several key findings, numerical results reveal the optimal number of deployed UAV-BSs that maximizes the joint coverage probability, as well as the optimal length of the UAV corridors when designing such UAV-assisted IoT networks.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Single Column, Submitted to IEEE for possible publication"
    },
    {
        "paper id": "2409.07031",
        "abstract url": "https://arxiv.org/abs/2409.07031",
        "title": "Situated Visualization in Motion for Video Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We contribute a systematic review of situated visualizations in motion in the context of video games. Video games produce rich dynamic datasets during gameplay that are often visualized to help players succeed in a game. Often these visualizations are moving either because they are attached to moving game elements or due to camera changes. We want to understand to what extent this motion and contextual game factors impact how players can read these visualizations. In order to ground our work, we surveyed 160 visualizations in motion and their embeddings in the game world. Here, we report on our analysis and categorization of these visualizations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07034",
        "abstract url": "https://arxiv.org/abs/2409.07034",
        "title": "Symbol Level Precoding for Systems with Improper Gaussian Interference",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper focuses on precoding design in multi-antenna systems with improper Gaussian interference (IGI), characterized by correlated real and imaginary parts. We first study block level precoding (BLP) and symbol level precoding (SLP) assuming the receivers apply a pre-whitening filter to decorrelate and normalize the IGI. We then shift to the scenario where the base station (BS) incorporates the IGI statistics in the SLP design, which allows the receivers to employ a standard detection algorithm without pre-whitenting. Finally we address the case where the channel and statistics of the IGI are unknown, and we formulate robust BLP and SLP designs that minimize the worst case performance in such settings. Interestingly, we show that for BLP, the worst-case IGI is in fact proper, while for SLP the worst case occurs when the interference signal is maximally improper, with fully correlated real and imaginary parts. Numerical results reveal the superior performance of SLP in terms of symbol error rate (SER) and energy efficiency (EE), especially for the case where there is uncertainty in the non-circularity of the jammer.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 12 figures"
    },
    {
        "paper id": "2409.07065",
        "abstract url": "https://arxiv.org/abs/2409.07065",
        "title": "Fast Simulation of Cellular Automata by Self-Composition",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is shown that computing the configuration of any one-dimensional cellular automaton at generation $n$ can be accelerated by constructing and running a composite one with a radius proportional to $\\log n$. The new automaton is the original automaton whose local rule function is composed with itself. The asymptotic time complexity to compute the configuration of generation $n$ is reduced from $O(n^2)$ operations to $O(n^2 / \\log n)$ on a given machine with $O(n^2)$ memory usage. Experimental results are given in the case of Rule 30.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "11 pages, 3 figures, includes source code"
    },
    {
        "paper id": "2409.07077",
        "abstract url": "https://arxiv.org/abs/2409.07077",
        "title": "Submonoid Membership in n-dimensional lamplighter groups and S-unit equations",
        "rating": "-10",
        "keywords": [],
        "abstract": "We show that Submonoid Membership is decidable in n-dimensional lamplighter groups $(\\mathbb{Z}/p\\mathbb{Z}) \\wr \\mathbb{Z}^n$ for any prime $p$ and integer $n$. More generally, we show decidability of Submonoid Membership in semidirect products of the form $\\mathcal{Y} \\rtimes \\mathbb{Z}^n$, where $\\mathcal{Y}$ is any finitely presented module over the Laurent polynomial ring $\\mathbb{F}_p[X_1^{\\pm}, \\ldots, X_n^{\\pm}]$. Combined with a result of Shafrir (2024), this gives the first example of a group $G$ and a finite index subgroup $\\widetilde{G} \\leq G$, such that Submonoid Membership is decidable in $\\widetilde{G}$ but undecidable in $G$. To obtain our decidability result, we reduce Submonoid Membership in $\\mathcal{Y} \\rtimes \\mathbb{Z}^n$ to solving S-unit equations over $\\mathbb{F}_p[X_1^{\\pm}, \\ldots, X_n^{\\pm}]$-modules. We show that the solution set of such equations is effectively $p$-automatic, extending a result of Adamczewski and Bell (2012). As an intermediate result, we also obtain that the solution set of the Knapsack Problem in $\\mathcal{Y} \\rtimes \\mathbb{Z}^n$ is effectively $p$-automatic.",
        "subjects": [
            "math.GR",
            "cs.FL",
            "math.NT"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2409.07081",
        "abstract url": "https://arxiv.org/abs/2409.07081",
        "title": "Data Backup System with No Impact on Business Processing Utilizing Storage and Container Technologies",
        "rating": "-10",
        "keywords": [],
        "abstract": "Data backup is a core technology for improving system resilience to system failures. Data backup in enterprise systems is required to minimize the impacts on business processing, which can be categorized into two factors: system slowdown and downtime. To eliminate system slowdown, asynchronous data copy (ADC) technology is prevalent, which copies data asynchronously with original data updates. However, the ADC can collapse backup data when applied to enterprise systems with multiple resources. Then, the demonstration system employed consistency group technology, which makes the order of data updates the same between the original and backup data. In addition, we developed a container platform operator to unravel the complicated correspondence between storage volumes and applications. The operator automates the configuration of the ADC with the setting of consistency groups. We integrated the storage and container technologies into the demonstration system, which can eliminate both system slowdown and downtime.",
        "subjects": [
            "cs.DC",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07082",
        "abstract url": "https://arxiv.org/abs/2409.07082",
        "title": "Extensions to BIER Tree Engineering (BIER-TE) for Large Multicast Domains and 1:1 Protection: Concept, Implementation and Performance",
        "rating": "-10",
        "keywords": [],
        "abstract": "Bit Index Explicit Replication (BIER) has been proposed by the IETF as a stateless multicast transport technology. BIER adds a BIER header containing a bitstring indicating receivers of an IP multicast (IPMC) packet within a BIER domain. BIER-TE extends BIER with tree engineering capabilities, i.e., the bitstring indicates both receivers as well as links over which the packet is transmitted. As the bitstring is of limited size, e.g., 256 bits, only that number of receivers can be addressed within a BIER packet. To scale BIER to larger networks, the receivers of a BIER domain have been assigned to subsets that can be addressed by a bitstring with a subset ID. This approach is even compliant with fast reroute (FRR) mechanisms for BIER. In this work we tackle the challenge of scaling BIER-TE to large networks as the subset mechanism of BIER is not sufficient for that purpose. A major challenge is the support of a protection mechanism in this context. We describe how existing networking concepts like tunneling, egress protection and BIER-TE-FRR can be combined to achieve the goal. Then, we implement the relevant BIER-TE components on the P4-programmable Tofino ASIC which builds upon an existing implementation for BIER. Finally, we consider the forwarding performance of the prototype and explain how weaknesses can be improved from remedies that are well-known for BIER implementations.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07083",
        "abstract url": "https://arxiv.org/abs/2409.07083",
        "title": "echemdb Toolkit -- a Lightweight Approach to Getting Data Ready for Data Management Solutions",
        "rating": "-10",
        "keywords": [],
        "abstract": "According to the FAIR (findability, accessibility, interoperability, and reusability) principles, scientific data should always be stored with machine-readable descriptive metadata. Existing solutions to store data with metadata, such as electronic lab notebooks (ELN), are often very domain-specific and not sufficiently generic for arbitrary experimental or computational results. In this work, we present open-source echemdb toolkit for creating and handling data and metadata. The toolkit is running entirely on the file system level using a file-based approach, which facilitates integration with other tools in a FAIR data life cycle and means that no complicated server setup is required. This also makes the toolkit more accessible to the average researcher since no understanding of more sophisticated database technologies is required. We showcase several aspects and applications of the toolkit: automatic annotation of raw research data with human- and machine-readable metadata, data conversion into standardised frictionless Data Packages, and an API for exploring the data. We also illustrate the web frameworks to illustrate the data using example data from research into energy conversion and storage.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "10 pages, 4 figures"
    },
    {
        "paper id": "2409.07138",
        "abstract url": "https://arxiv.org/abs/2409.07138",
        "title": "Improving Encrypted Transport Protocol Designs: Deep Dive on the QUIC Case",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose in this paper to revisit the design of existing encrypted transport protocols to improve their efficiency. We call the methodology \"Reverso\" from reversing the order of field elements within a protocol specification. We detail how such a benign-looking change within the specifications may unlock implementation optimizations for encrypted protocols. To demonstrate our findings, we release quiceh, a QUIC implementation of QUIC VReverso, an extension of the QUIC V1 standard (RFC9000). Our methodology applied to the QUIC protocol reports ~30% of CPU efficiency improvement for processing packets at no added cost on the sender side and without relaxing any security guarantee from QUIC V1. We also implement a fork of Cloudflare's HTTP/3 module and client/server demonstrator using quiceh and show our optimizations to directly transfer to HTTP/3 as well, resulting in our new HTTP/3 to be ~ 38% more efficient than the baseline implementation using QUIC V1. We argue that Reverso applies to any modern encrypted protocol and its implementations and that similar efficiency improvement can also be unlocked for them, independently of the layer in which they operate.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07142",
        "abstract url": "https://arxiv.org/abs/2409.07142",
        "title": "Randomized Strategic Facility Location with Predictions",
        "rating": "-10",
        "keywords": [],
        "abstract": "We revisit the canonical problem of strategic facility location and study the power and limitations of randomization in the design of truthful mechanisms augmented with machine-learned predictions. In the strategic facility location problem, a set of agents are asked to report their locations in some metric space and the goal is to use these reported locations to determine where to open a new facility, aiming to optimize some aggregate measure of distance of the agents from that facility. However, the agents are strategic and can misreport their locations if this may lead to a facility location choice that they prefer. The goal is to design truthful mechanisms, which ensure the agents cannot benefit by misreporting. A lot of prior work has studied this problem from a worst-case perspective, but a recent line of work proposed a framework to refine these results when the designer is provided with some, possible incorrect, predictions regarding the agents' true locations. The goal is to simultaneously provide strong consistency guarantees (i.e., guarantees when the predictions provided to the mechanism are correct) and near-optimal robustness guarantees (i.e., guarantees that hold irrespective of how inaccurate the predictions may be). In this work we focus on the power of randomization in this problem and analyze the best approximation guarantees achievable with respect to the egalitarian social cost measure for one- and two-dimensional Euclidean spaces.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07148",
        "abstract url": "https://arxiv.org/abs/2409.07148",
        "title": "Jump Restore Light Transport",
        "rating": "-10",
        "keywords": [],
        "abstract": "Markov chain Monte Carlo (MCMC) algorithms come to rescue when sampling from a complex, high-dimensional distribution by a conventional method is intractable. Even though MCMC is a powerful tool, it is also hard to control and tune in practice. Simultaneously achieving both \\emph{local exploration} of the state space and \\emph{global discovery} of the target distribution is a challenging task. In this work, we present a MCMC formulation that subsumes all existing MCMC samplers employed in rendering. We then present a novel framework for \\emph{adjusting} an arbitrary Markov chain, making it exhibit invariance with respect to a specified target distribution. To showcase the potential of the proposed framework, we focus on a first simple application in light transport simulation. As a by-product, we introduce continuous-time MCMC sampling to the computer graphics community. We show how any existing MCMC-based light transport algorithm can be embedded into our framework. We empirically and theoretically prove that this embedding is superior to running the standalone algorithm. In fact, our approach will convert any existing algorithm into a highly parallelizable variant with shorter running time, smaller error and less variance.",
        "subjects": [
            "cs.GR",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07149",
        "abstract url": "https://arxiv.org/abs/2409.07149",
        "title": "Ciphertext Policy Attribute Based Encryption with Intel SGX",
        "rating": "-10",
        "keywords": [],
        "abstract": "Modern computing environments demand robust security measures to protect sensitive data and resources. Ciphertext-Policy Attribute-Based Encryption (CP-ABE) is a well-established encryption technique known for its fine-grained access control capabilities. However, as the digital landscape evolves, there is a growing need to enhance the security of CP-ABE operations. We propose an approach that utilizes CP-ABE with Intel SGX. It allows data to be encrypted and decrypted securely within the SGX enclave based on the rules in policy by ensuring that only authorized users gain access. We evaluate its performance through different experiments by focusing on key parameters such as the number of rules, attributes and file size. Our results demonstrate the performance and scalability of integrating SGX with CP-ABE in enhancing data security with only minimal increase in execution time due to enclave overhead.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07168",
        "abstract url": "https://arxiv.org/abs/2409.07168",
        "title": "A feedback control approach to convex optimization with inequality constraints",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a novel continuous-time algorithm for inequality-constrained convex optimization inspired by proportional-integral control. Unlike the popular primal-dual gradient dynamics, our method includes a proportional term to control the primal variable through the Lagrange multipliers. This approach has both theoretical and practical advantages. On the one hand, it simplifies the proof of the exponential convergence in the case of smooth, strongly convex problems, with a more straightforward assessment of the convergence rate concerning prior literature. On the other hand, through several examples, we show that the proposed algorithm converges faster than primal-dual gradient dynamics. This paper aims to illustrate these points by thoroughly analyzing the algorithm convergence and discussing some numerical simulations.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "accepted for publication in the Proceedings of the 63rd IEEE Conference on Decision and Control, December 16-19, 2024, Milan (Italy)"
    },
    {
        "paper id": "2409.07178",
        "abstract url": "https://arxiv.org/abs/2409.07178",
        "title": "Identify Design Problems Through Questioning: Exploring Role-playing Interactions with Large Language Models to Foster Design Questioning Skills",
        "rating": "-10",
        "keywords": [],
        "abstract": "Identifying design problems is a crucial step for creating plausible solutions, but it is challenging for design novices due to their limited knowledge and experience. Questioning is a promising skill that enables students to independently identify design problems without being passive or relying on instructors. This study explores role-playing interactions with Large Language Model (LLM)-powered Conversational Agents (CAs) to foster the questioning skills of novice design students. We proposed an LLM-powered CA prototype and conducted a preliminary study with 16 novice design students engaged in a real-world design class to observe the interactions between students and the LLM-powered CAs. Our findings indicate that while the CAs stimulated questioning and reduced pressure to ask questions, it also inadvertently led to over-reliance on LLM responses. We proposed design considerations and future works for LLM-powered CA to foster questioning skills.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07187",
        "abstract url": "https://arxiv.org/abs/2409.07187",
        "title": "A Simple Linear Space Data Structure for ANN with Application in Differential Privacy",
        "rating": "-10",
        "keywords": [],
        "abstract": "Locality Sensitive Filters are known for offering a quasi-linear space data structure with rigorous guarantees for the Approximate Near Neighbor search problem. Building on Locality Sensitive Filters, we derive a simple data structure for the Approximate Near Neighbor Counting problem under differential privacy. Moreover, we provide a simple analysis leveraging a connection with concomitant statistics and extreme value theory. Our approach achieves the same performance as the recent findings of Andoni et al. (NeurIPS 2023) but with a more straightforward method. As a side result, the paper provides a more compact description and analysis of Locality Sensitive Filters for Approximate Near Neighbor Search under inner product similarity, improving a previous result in Aum\u00fcller et al. (TODS 2022).",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07195",
        "abstract url": "https://arxiv.org/abs/2409.07195",
        "title": "Perceptive Pedipulation with Local Obstacle Avoidance",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pedipulation leverages the feet of legged robots for mobile manipulation, eliminating the need for dedicated robotic arms. While previous works have showcased blind and task-specific pedipulation skills, they fail to account for static and dynamic obstacles in the environment. To address this limitation, we introduce a reinforcement learning-based approach to train a whole-body obstacle-aware policy that tracks foot position commands while simultaneously avoiding obstacles. Despite training the policy in only five different static scenarios in simulation, we show that it generalizes to unknown environments with different numbers and types of obstacles. We analyze the performance of our method through a set of simulation experiments and successfully deploy the learned policy on the ANYmal quadruped, demonstrating its capability to follow foot commands while navigating around static and dynamic obstacles.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IEEE International Conference on Humanoid Robots 2024"
    },
    {
        "paper id": "2409.07201",
        "abstract url": "https://arxiv.org/abs/2409.07201",
        "title": "Improved Hardness Results of the Cardinality-Based Minimum s-t Cut Problem in Hypergraphs",
        "rating": "-10",
        "keywords": [],
        "abstract": "In hypergraphs an edge that crosses a cut can be split in several ways, depending on how many nodes are placed on each side of the cut. A cardinality-based splitting function assigns a nonnegative cost of $w_i$ for each cut hyperedge $e$ with exactly $i$ nodes on the side of the cut that contains the minority of nodes from $e$. The cardinality-based minimum $s$-$t$ cut aims to find an $s$-$t$ cut with minimum total cost. Assuming the costs $w_i$ are polynomially bounded by the input size and $w_0=0$ and $w_1=1$, we show that if the costs satisfy $w_i > w_{i-j}+w_{j}$ for some $i \\in \\{2, \\ldots \\floor*{n/2}\\}$ and $j \\in \\{1,\\ldots,\\floor*{i/2}\\}$, then the problem becomes NP-hard. Our result also holds for $k$-uniform hypergraphs with $k \\geq 4$. Additionally, we show that the \\textsc{No-Even-Split} problem in $4$-uniform hypergraphs is NP-hard.",
        "subjects": [
            "cs.CC",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07208",
        "abstract url": "https://arxiv.org/abs/2409.07208",
        "title": "Almost-catalytic Computation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Designing algorithms for space bounded models with restoration requirements on the space used by the algorithm is an important challenge posed about the catalytic computation model introduced by Buhrman et al. (2014). Motivated by the scenarios where we do not need to restore unless is useful, we define $ACL(A)$ to be the class of languages that can be accepted by almost-catalytic Turing machines with respect to $A$ (which we call the catalytic set), that uses at most $c\\log n$ work space and $n^c$ catalytic space. We show that if there are almost-catalytic algorithms for a problem with catalytic set as $A \\subseteq \u03a3^*$ and its complement respectively, then the problem can be solved by a ZPP algorithm. Using this, we derive that to design catalytic algorithms, it suffices to design almost-catalytic algorithms where the catalytic set is the set of strings of odd weight ($PARITY$). Towards this, we consider two complexity measures of the set $A$ which are maximized for $PARITY$ - random projection complexity (${\\cal R}(A)$) and the subcube partition complexity (${\\cal P}(A)$). By making use of error-correcting codes, we show that for all $k \\ge 1$, there is a language $A_k \\subseteq \u03a3^*$ such that $DSPACE(n^k) \\subseteq ACL(A_k)$ where for every $m \\ge 1$, $\\mathcal{R}(A_k \\cap \\{0,1\\}^m) \\ge \\frac{m}{4}$ and $\\mathcal{P}(A_k \\cap \\{0,1\\}^m)=2^{m/4}$. This contrasts the catalytic machine model where it is unclear if it can accept all languages in $DSPACE(\\log^{1+\u03b5} n)$ for any $\u03b5> 0$. Improving the partition complexity of the catalytic set $A$ further, we show that for all $k \\ge 1$, there is a $A_k \\subseteq \\{0,1\\}^*$ such that $\\mathsf{DSPACE}(\\log^k n) \\subseteq ACL(A_k)$ where for every $m \\ge 1$, $\\mathcal{R}(A_k \\cap \\{0,1\\}^m) \\ge \\frac{m}{4}$ and $\\mathcal{P}(A_k \\cap \\{0,1\\}^m)=2^{m/4+\u03a9(\\log m)}$.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2409.07242",
        "abstract url": "https://arxiv.org/abs/2409.07242",
        "title": "Orthogonal Mode Decomposition for Finite Discrete Signals",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, an orthogonal mode decomposition method is proposed to decompose ffnite length real signals on both the real and imaginary axes of the complex plane. The interpolation function space of ffnite length discrete signal is constructed, and the relationship between the dimensionality of the interpolation function space and its subspaces and the band width of the interpolation function is analyzed. It is proved that the intrinsic mode is actually the narrow band signal whose intrinsic instantaneous frequency is always positive (or always negative). Thus, the eigenmode decomposition problem is transformed into the orthogonal projection problem of interpolation function space to its low frequency subspace or narrow band subspace. Different from the existing mode decomposition methods, the orthogonal modal decomposition is a local time-frequency domain algorithm. Each operation extracts a speciffc mode. The global decomposition results obtained under the precise deffnition of eigenmodes have uniqueness and orthogonality. The computational complexity of the orthogonal mode decomposition method is also much smaller than that of the existing mode decomposition methods.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07250",
        "abstract url": "https://arxiv.org/abs/2409.07250",
        "title": "Bridging Quantitative and Qualitative Methods for Visualization Research: A Data/Semantics Perspective in Light of Advanced AI",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper revisits the role of quantitative and qualitative methods in visualization research in the context of advancements in artificial intelligence (AI). The focus is on how we can bridge between the different methods in an integrated process of analyzing user study data. To this end, a process model of - potentially iterated - semantic enrichment and transformation of data is proposed. This joint perspective of data and semantics facilitates the integration of quantitative and qualitative methods. The model is motivated by examples of own prior work, especially in the area of eye tracking user studies and coding data-rich observations. Finally, there is a discussion of open issues and research opportunities in the interplay between AI, human analyst, and qualitative and quantitative methods for visualization research.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07254",
        "abstract url": "https://arxiv.org/abs/2409.07254",
        "title": "Low carbon optimal scheduling of integrated energy system considering waste heat utilization under the coordinated operation of incineration power plant and P2G",
        "rating": "-10",
        "keywords": [],
        "abstract": "In order to improve energy utilization and reduce carbon emissions, this paper presents a comprehensive energy system economic operation strategy of Incineration power plant Power-to-gas (P2G) with waste heat recovery. First, consider the coordinated operation of Incineration power plant - P2G, introduce the refined Power-to-gas two-stage operation process, add Hydrogen fuel cells on the basis of traditional Power-to-gas to reduce the energy ladder loss, and recycle the Methanation reaction heat; Secondly, in order to improve the energy utilization efficiency of Incineration, it is considered to install a waste heat recovery device containing a water source heat pump to recover the waste heat of flue gas and consume some electric energy, sourced from wind power, and add a CO2 separation device to combine the recovered CO2 with P2G to synthesize CH4 to achieve carbon recycling. Finally, within the framework of a tiered carbon trading mechanism an IES optimization model for electricity-heat with the goal of minimizing the system operating cost is constructed, and the GUROBI modeling optimization engine is used to solve this model. The results verify the effectiveness of the model.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted by Acta Energiae Solaris Sinica, 9 pages, in Chinese language, 12 figures"
    },
    {
        "paper id": "2409.07278",
        "abstract url": "https://arxiv.org/abs/2409.07278",
        "title": "List-based Optimization of Proximal Decoding for LDPC Codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, the proximal decoding algorithm is considered within the context of additive white Gaussian noise (AWGN) channels. An analysis of the convergence behavior of the algorithm shows that proximal decoding inherently enters an oscillating behavior of the estimate after a certain number of iterations. Due to this oscillation, frame errors arising during decoding can often be attributed to only a few remaining wrongly decoded bit positions. In this letter, an improvement of the proximal decoding algorithm is proposed by establishing an additional step, in which these erroneous positions are attempted to be corrected. We suggest an empirical rule with which the components most likely needing correction can be determined. Using this insight and performing a subsequent ``ML-in-the-list'' decoding, a gain of up to 1 dB is achieved compared to conventional proximal decoding, depending on the decoder parameters and the code.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07285",
        "abstract url": "https://arxiv.org/abs/2409.07285",
        "title": "Temporal Valued Constraint Satisfaction Problems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the complexity of the valued constraint satisfaction problem (VCSP) for every valued structure with the domain ${\\mathbb Q}$ that is preserved by all order-preserving bijections. Such VCSPs will be called temporal, in analogy to the (classical) constraint satisfaction problem: a relational structure is preserved by all order-preserving bijections if and only if all its relations have a first-order definition in $({\\mathbb Q};<)$, and the CSPs for such structures are called temporal CSPs. Many optimization problems that have been studied intensively in the literature can be phrased as a temporal VCSP. We prove that a temporal VCSP is in P, or NP-complete. Our analysis uses the concept of fractional polymorphisms; this is the first dichotomy result for VCSPs over infinite domains which is complete in the sense that it treats all valued structures with a given automorphism group.",
        "subjects": [
            "math.LO",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07288",
        "abstract url": "https://arxiv.org/abs/2409.07288",
        "title": "General Methods for Evaluating Collision Probability of Different Types of Theta-phi Positioners",
        "rating": "-10",
        "keywords": [],
        "abstract": "In many modern astronomical facilities, multi-object telescopes are crucial instruments. Most of these telescopes have thousands of robotic fiber positioners(RFPs) installed on their focal plane, sharing an overlapping workspace. Collisions between RFPs during their movement can result in some targets becoming unreachable and cause structural damage. Therefore, it is necessary to reasonably assess and evaluate the collision probability of the RFPs. In this study, we propose a mathematical models of collision probability and validate its results using Monte Carlo simulations. In addition, a new collision calculation method is proposed for faster calculation(nearly 0.15% of original time). Simulation experiments have verified that our method can evaluate the collision probability between RFPs with both equal and unequal arm lengths. Additionally, we found that adopting a target distribution based on a Poisson distribution can reduce the collision probability by approximately 2.6% on average.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "20pages,11figures"
    },
    {
        "paper id": "2409.07360",
        "abstract url": "https://arxiv.org/abs/2409.07360",
        "title": "Choosing the Right Communication Protocol for your Web Application",
        "rating": "-10",
        "keywords": [],
        "abstract": "Selecting the appropriate communication protocol is crucial for optimizing the performance, scalability, and user experience of web applications. In the diverse ecosystem of web technologies, various protocols like RESTful APIs, gRPC, WebSockets, and others serve distinct purposes. RESTful APIs are widely favored for their simplicity and stateless nature, making them ideal for standard CRUD operations. They offer a straightforward approach to interacting with resources over HTTP/1.1, providing broad compatibility and ease of integration across different platforms. However, in scenarios where applications require high efficiency and real-time communication, gRPC and WebSockets emerge as powerful alternatives. Each protocol comes with its strengths and limitations, influencing factors such as ease of implementation, performance under load, and support for complex data structures. RESTful APIs, while easy to use and widely supported, may introduce overhead due to their stateless nature and reliance on multiple HTTP/1.1 requests. In contrast, gRPC advanced features, while powerful, require a steeper learning curve and more sophisticated infrastructure. Similarly, WebSockets, while excellent for real-time applications, require careful management of persistent connections and security considerations. This paper explores the key considerations in choosing the right communication protocol, emphasizing the need to align technical choices with application requirements and user expectations. By understanding the unique attributes of each protocol, developers can make informed decisions that enhance the responsiveness and reliability of their web applications. The choice of protocol can significantly impact the user experience, scalability, and maintainability of the application, making it a critical decision in the web development process.",
        "subjects": [
            "cs.SE",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07398",
        "abstract url": "https://arxiv.org/abs/2409.07398",
        "title": "The Complexity of Two-Team Polymatrix Games with Independent Adversaries",
        "rating": "-10",
        "keywords": [],
        "abstract": "Adversarial multiplayer games are an important object of study in multiagent learning. In particular, polymatrix zero-sum games are a multiplayer setting where Nash equilibria are known to be efficiently computable. Towards understanding the limits of tractability in polymatrix games, we study the computation of Nash equilibria in such games where each pair of players plays either a zero-sum or a coordination game. We are particularly interested in the setting where players can be grouped into a small number of teams of identical interest. While the three-team version of the problem is known to be PPAD-complete, the complexity for two teams has remained open. Our main contribution is to prove that the two-team version remains hard, namely it is CLS-hard. Furthermore, we show that this lower bound is tight for the setting where one of the teams consists of multiple independent adversaries. On the way to obtaining our main result, we prove hardness of finding any stationary point in the simplest type of non-convex-concave min-max constrained optimization problem, namely for a class of bilinear polynomial objective functions.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07406",
        "abstract url": "https://arxiv.org/abs/2409.07406",
        "title": "Trust Dynamics in Human-Autonomy Interaction: Uncover Associations between Trust Dynamics and Personal Characteristics",
        "rating": "-10",
        "keywords": [],
        "abstract": "While personal characteristics influence people's snapshot trust towards autonomous systems, their relationships with trust dynamics remain poorly understood. We conducted a human-subject experiment with 130 participants performing a simulated surveillance task aided by an automated threat detector. A comprehensive pre-experimental survey collected data on participants' personal characteristics across 12 constructs and 28 dimensions. Based on data collected in the experiment, we clustered participants' trust dynamics into three types and assessed differences among the three clusters in terms of personal characteristics, behaviors, performance, and post-experiment ratings. Participants were clustered into three groups, namely Bayesian decision makers, disbelievers, and oscillators. Results showed that the clusters differ significantly in seven personal characteristics: masculinity, positive affect, extraversion, neuroticism, intellect, performance expectancy, and high expectations. The disbelievers tend to have high neuroticism and low performance expectancy. The oscillators tend to have higher scores in masculinity, positive affect, extraversion and intellect. We also found significant differences in the behaviors and post-experiment ratings among the three groups. The disbelievers are the least likely to blindly follow the recommendations made by the automated threat detector. Based on the significant personal characteristics, we developed a decision tree model to predict cluster types with an accuracy of 70%.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.07420",
        "abstract url": "https://arxiv.org/abs/2409.07420",
        "title": "XDC Staking and Tokenomics -- Improvement Proposal: Enhancing Sustainability and Decentralization on the Eve of XDC 2.0",
        "rating": "-10",
        "keywords": [],
        "abstract": "As the XDC network celebrates five years of stable mainnet operation and prepares for the highly anticipated launch of XDC 2.0, this research proposes a comprehensive improvement plan for the network's staking and tokenomics mechanisms. Our analysis reveals opportunities to optimize the current model, ensuring a more sustainable, decentralized, and resilient ecosystem. We introduce novel concepts, including validator NFTs, decentralized governance, and utility-based tokenomics, to increase validator node liquidity and promote staking participation. Our proposal aims to establish a robust foundation for XDC 2.0, fostering a thriving ecosystem that rewards validators, stakeholders, and users alike. By addressing the intricacies of staking and tokenomics, this research paves the way for XDC to solidify its position as a leading decentralized network, poised for long-term success and growth.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07444",
        "abstract url": "https://arxiv.org/abs/2409.07444",
        "title": "Echoes of Privacy: Uncovering the Profiling Practices of Voice Assistants",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many companies, including Google, Amazon, and Apple, offer voice assistants as a convenient solution for answering general voice queries and accessing their services. These voice assistants have gained popularity and can be easily accessed through various smart devices such as smartphones, smart speakers, smartwatches, and an increasing array of other devices. However, this convenience comes with potential privacy risks. For instance, while companies vaguely mention in their privacy policies that they may use voice interactions for user profiling, it remains unclear to what extent this profiling occurs and whether voice interactions pose greater privacy risks compared to other interaction modalities. In this paper, we conduct 1171 experiments involving a total of 24530 queries with different personas and interaction modalities over the course of 20 months to characterize how the three most popular voice assistants profile their users. We analyze factors such as the labels assigned to users, their accuracy, the time taken to assign these labels, differences between voice and web interactions, and the effectiveness of profiling remediation tools offered by each voice assistant. Our findings reveal that profiling can happen without interaction, can be incorrect and inconsistent at times, may take several days to weeks for changes to occur, and can be influenced by the interaction modality.",
        "subjects": [
            "cs.HC",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07449",
        "abstract url": "https://arxiv.org/abs/2409.07449",
        "title": "Autonomous loading of ore piles with Load-Haul-Dump machines using Deep Reinforcement Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work presents a deep reinforcement learning-based approach to train controllers for the autonomous loading of ore piles with a Load-Haul-Dump (LHD) machine. These controllers must perform a complete loading maneuver, filling the LHD's bucket with material while avoiding wheel drift, dumping material, or getting stuck in the pile. The training process is conducted entirely in simulation, using a simple environment that leverages the Fundamental Equation of Earth-Moving Mechanics so as to achieve a low computational cost. Two different types of policies are trained: one with a hybrid action space and another with a continuous action space. The RL-based policies are evaluated both in simulation and in the real world using a scaled LHD and a scaled muck pile, and their performance is compared to that of a heuristics-based controller and human teleoperation. Additional real-world experiments are performed to assess the robustness of the RL-based policies to measurement errors in the characterization of the piles. Overall, the RL-based controllers show good performance in the real world, achieving fill factors between 71-94%, and less wheel drift than the other baselines during the loading maneuvers. A video showing the training environment and the learned behavior in simulation, as well as some of the performed experiments in the real world, can be found in https://youtu.be/jOpA1rkwhDY.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "19 pages, 19 figures"
    },
    {
        "paper id": "2409.07508",
        "abstract url": "https://arxiv.org/abs/2409.07508",
        "title": "SafeBPF: Hardware-assisted Defense-in-depth for eBPF Kernel Extensions",
        "rating": "-10",
        "keywords": [],
        "abstract": "The eBPF framework enables execution of user-provided code in the Linux kernel. In the last few years, a large ecosystem of cloud services has leveraged eBPF to enhance container security, system observability, and network management. Meanwhile, incessant discoveries of memory safety vulnerabilities have left the systems community with no choice but to disallow unprivileged eBPF programs, which unfortunately limits eBPF use to only privileged users. To improve run-time safety of the framework, we introduce SafeBPF, a general design that isolates eBPF programs from the rest of the kernel to prevent memory safety vulnerabilities from being exploited. We present a pure software implementation using a Software-based Fault Isolation (SFI) approach and a hardware-assisted implementation that leverages ARM's Memory Tagging Extension (MTE). We show that SafeBPF incurs up to 4% overhead on macrobenchmarks while achieving desired security properties.",
        "subjects": [
            "cs.CR",
            "cs.OS"
        ],
        "comment": "15 pages, 9 figures"
    },
    {
        "paper id": "2409.07563",
        "abstract url": "https://arxiv.org/abs/2409.07563",
        "title": "MPPI-Generic: A CUDA Library for Stochastic Optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces a new C++/CUDA library for GPU-accelerated stochastic optimization called MPPI-Generic. It provides implementations of Model Predictive Path Integral control, Tube-Model Predictive Path Integral Control, and Robust Model Predictive Path Integral Control, and allows for these algorithms to be used across many pre-existing dynamics models and cost functions. Furthermore, researchers can create their own dynamics models or cost functions following our API definitions without needing to change the actual Model Predictive Path Integral Control code. Finally, we compare computational performance to other popular implementations of Model Predictive Path Integral Control over a variety of GPUs to show the real-time capabilities our library can allow for. Library code can be found at: https://acdslab.github.io/mppi-generic-website/ .",
        "subjects": [
            "cs.MS",
            "cs.DC",
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07567",
        "abstract url": "https://arxiv.org/abs/2409.07567",
        "title": "Cybersecurity Challenge Analysis of Work-from-Anywhere (WFA) and Recommendations guided by a User Study",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many organizations were forced to quickly transition to the work-from-anywhere (WFA) model as a necessity to continue with their operations and remain in business despite the restrictions imposed during the COVID-19 pandemic. Many decisions were made in a rush, and cybersecurity decency tools were not in place to support this transition. In this paper, we first attempt to uncover some challenges and implications related to the cybersecurity of the WFA model. Secondly, we conducted an online user study to investigate the readiness and cybersecurity awareness of employers and their employees who shifted to work remotely from anywhere. The user study questionnaire addressed different resilience perspectives of individuals and organizations. The collected data includes 45 responses from remotely working employees of different organizational types: universities, government, private, and non-profit organizations. Despite the importance of security training and guidelines, it was surprising that many participants had not received them. A robust communication strategy is necessary to ensure that employees are informed and updated on security incidents that the organization encounters. Additionally, there is an increased need to pay attention to the security-related attributes of employees, such as their behavior, awareness, and compliance. Finally, we outlined best practice recommendations and mitigation tips guided by the study results to help individuals and organizations resist cybercrime and fraud and mitigate WFA-related cybersecurity risks.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2409.07576",
        "abstract url": "https://arxiv.org/abs/2409.07576",
        "title": "fence.t.s: Closing Timing Channels in High-Performance Out-of-Order Cores through ISA-Supported Temporal Partitioning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Microarchitectural timing channels exploit information leakage between security domains that should be isolated, bypassing the operating system's security boundaries. These channels result from contention for shared microarchitectural state. In the RISC-V instruction set, the temporal fence instruction (fence.t) was proposed to close timing channels by providing an operating system with the means to temporally partition microarchitectural state inexpensively in simple in-order cores. This work explores challenges with fence.t in superscalar out-of-order cores featuring large and pervasive microarchitectural state. To overcome these challenges, we propose a novel SW-supported temporal fence (fence.t.s), which reuses existing mechanisms and supports advanced microarchitectural features, enabling full timing channel protection of an exemplary out-of-order core (OpenC910) at negligible hardware costs and a minimal performance impact of 1.0 %.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 3 figures, 1 algorithm, 1 listing. Accepted at the 2024 International Conference on Applications in Electronics Pervading Industry, Environment and Society (APPLEPIES 2024)"
    },
    {
        "paper id": "2409.07598",
        "abstract url": "https://arxiv.org/abs/2409.07598",
        "title": "High Performance Three-Terminal Thyristor RAM with a P+/P/N/P/N/N+ Doping Profile on a Silicon-Photonic CMOS Platform",
        "rating": "-10",
        "keywords": [],
        "abstract": "3T TRAM with doping profile (P+PNPNN+) is experimentally demonstrated on a silicon photonic platform. By using additional implant layers, this device provides excellent memory performance compared to the conventional structure (PNPN). TCAD is used to reflect the physical behavior, and the high-speed memory operations are described through the model.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "4 pages, 15 figures"
    },
    {
        "paper id": "2409.07608",
        "abstract url": "https://arxiv.org/abs/2409.07608",
        "title": "Advancing Malicious Website Identification: A Machine Learning Approach Using Granular Feature Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Malicious website detection is an increasingly relevant yet intricate task that requires the consideration of a vast amount of fine details. Our objective is to create a machine learning model that is trained on as many of these finer details as time will allow us to classify a website as benign or malicious. If malicious, the model will classify the role it plays (phishing, spam, malware hosting, etc.). We proposed 77 features and created a dataset of 441,701 samples spanning 9 website classifications to train our model. We grouped the proposed features into feature subsets based on the time and resources required to compute these features and the performance changes with the inclusion of each subset to the model. We found that the performance of the best performing model increased as more feature subsets were introduced. In the end, our best performing model was able to classify websites into 1 of 9 classifications with a 95.89\\% accuracy score. We then investigated how well the features we proposed ranked in importance and detail the top 10 most relevant features according to our models. 2 of our URL embedding features were found to be the most relevant by our best performing model, with content-based features representing half of the top 10 spots. The rest of the list was populated with singular features from different feature categories including: a host feature, a robots.txt feature, a lexical feature, and a passive domain name system feature.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07616",
        "abstract url": "https://arxiv.org/abs/2409.07616",
        "title": "Public-key encryption from a trapdoor one-way embedding of $SL_2(\\mathbb{N}$)",
        "rating": "-10",
        "keywords": [],
        "abstract": "We obfuscate words of a given length in a free monoid on two generators with a simple factorization algorithm (namely $SL_2(\\mathbb{N})$) to create a public-key encryption scheme. We provide a reference implementation in Python and suggested parameters. The security analysis is between weak and non-existent, left to future work.",
        "subjects": [
            "cs.CR",
            "math.NT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07662",
        "abstract url": "https://arxiv.org/abs/2409.07662",
        "title": "An Open-Source Soft Robotic Platform for Autonomous Aerial Manipulation in the Wild",
        "rating": "-10",
        "keywords": [],
        "abstract": "Aerial manipulation combines the versatility and speed of flying platforms with the functional capabilities of mobile manipulation, which presents significant challenges due to the need for precise localization and control. Traditionally, researchers have relied on offboard perception systems, which are limited to expensive and impractical specially equipped indoor environments. In this work, we introduce a novel platform for autonomous aerial manipulation that exclusively utilizes onboard perception systems. Our platform can perform aerial manipulation in various indoor and outdoor environments without depending on external perception systems. Our experimental results demonstrate the platform's ability to autonomously grasp various objects in diverse settings. This advancement significantly improves the scalability and practicality of aerial manipulation applications by eliminating the need for costly tracking solutions. To accelerate future research, we open source our ROS 2 software stack and custom hardware design, making our contributions accessible to the broader research community.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Project website: https://sites.google.com/view/open-source-soft-platform/open-source-soft-robotic-platform"
    },
    {
        "paper id": "2409.07666",
        "abstract url": "https://arxiv.org/abs/2409.07666",
        "title": "Distributed Controller Design for Discrete-Time Systems Via the Integration of Extended LMI and Clique-Wise Decomposition",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study addresses a distributed controller design problem for discrete-time systems using linear matrix inequalities (LMIs). Sparsity constraints on control gains of distributed controllers result in conservatism via the convexification of the existing methods such as the extended LMI method. In order to mitigate the conservatism, we introduce a novel LMI formulation for this problem, utilizing the clique-wise decomposition method from our previous work on continuous-time systems. By reformulating the sparsity constraint on the gain matrix within cliques, this method achieves a broader solution set. Also, the analytical superiority of our method is confirmed through numerical examples.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07669",
        "abstract url": "https://arxiv.org/abs/2409.07669",
        "title": "A Mixed-Methods Study of Open-Source Software Maintainers On Vulnerability Management and Platform Security Features",
        "rating": "-10",
        "keywords": [],
        "abstract": "In open-source software (OSS), software vulnerabilities have significantly increased. Although researchers have investigated the perspectives of vulnerability reporters and OSS contributor security practices, understanding the perspectives of OSS maintainers on vulnerability management and platform security features is currently understudied. In this paper, we investigate the perspectives of OSS maintainers who maintain projects listed in the GitHub Advisory Database. We explore this area by conducting two studies: identifying aspects through a listing survey ($n_1=80$) and gathering insights from semi-structured interviews ($n_2=22$). Of the 37 identified aspects, we find that supply chain mistrust and lack of automation for vulnerability management are the most challenging, and barriers to adopting platform security features include a lack of awareness and the perception that they are not necessary. Surprisingly, we find that despite being previously vulnerable, some maintainers still allow public vulnerability reporting, or ignore reports altogether. Based on our findings, we discuss implications for OSS platforms and how the research community can better support OSS vulnerability management efforts.",
        "subjects": [
            "cs.SE",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07670",
        "abstract url": "https://arxiv.org/abs/2409.07670",
        "title": "A Deep Dive Into How Open-Source Project Maintainers Review and Resolve Bug Bounty Reports",
        "rating": "-10",
        "keywords": [],
        "abstract": "Researchers have investigated the bug bounty ecosystem from the lens of platforms, programs, and bug hunters. Understanding the perspectives of bug bounty report reviewers, especially those who historically lack a security background and little to no funding for bug hunters, is currently understudied. In this paper, we primarily investigate the perspective of open-source software (OSS) maintainers who have used \\texttt{huntr}, a bug bounty platform that pays bounties to bug hunters who find security bugs in GitHub projects and have had valid vulnerabilities patched as a result. We address this area by conducting three studies: identifying characteristics through a listing survey ($n_1=51$), their ranked importance with Likert-scale survey data ($n_2=90$), and conducting semi-structured interviews to dive deeper into real-world experiences ($n_3=17$). As a result, we categorize 40 identified characteristics into benefits, challenges, helpful features, and wanted features. We find that private disclosure and project visibility are the most important benefits, while hunters focused on money or CVEs and pressure to review are the most challenging to overcome. Surprisingly, lack of communication with bug hunters is the least challenging, and CVE creation support is the second-least helpful feature for OSS maintainers when reviewing bug bounty reports. We present recommendations to make the bug bounty review process more accommodating to open-source maintainers and identify areas for future work.",
        "subjects": [
            "cs.SE",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07680",
        "abstract url": "https://arxiv.org/abs/2409.07680",
        "title": "Upper bounds on minimum size of feedback arc set of directed multigraphs with bounded degree",
        "rating": "-10",
        "keywords": [],
        "abstract": "An oriented multigraph is a directed multigraph without directed 2-cycles. Let ${\\rm fas}(D)$ denote the minimum size of a feedback arc set in an oriented multigraph $D$. The degree of a vertex is the sum of its out- and in-degrees. In several papers, upper bounds for ${\\rm fas}(D)$ were obtained for oriented multigraphs $D$ with maximum degree upper-bounded by a constant. Hanauer (2017) conjectured that ${\\rm fas}(D)\\le 2.5n/3$ for every oriented multigraph $D$ with $n$ vertices and maximum degree at most 5. We prove a strengthening of the conjecture: ${\\rm fas}(D)\\le m/3$ holds for every oriented multigraph $D$ with $m$ arcs and maximum degree at most 5. This bound is tight and improves a bound of Berger and Shor (1990,1997). It would be interesting to determine $c$ such that ${\\rm fas}(D)\\le cn$ for every oriented multigraph $D$ with $n$ vertices and maximum degree at most 5 such that the bound is tight. We show that $\\frac{5}{7}\\le c \\le \\frac{24}{29} < \\frac{2.5}{3}$.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07695",
        "abstract url": "https://arxiv.org/abs/2409.07695",
        "title": "Situated Visualization in Motion for Swimming",
        "rating": "-10",
        "keywords": [],
        "abstract": "Competitive sports coverage increasingly includes information on athlete or team statistics and records. Sports video coverage has traditionally embedded representations of this data in fixed locations on the screen, but more recently also attached representations to athletes or other targets in motion. These publicly used representations so far have been rather simple and systematic investigations of the research space of embedded visualizations in motion are still missing. Here we report on our preliminary research in the domain of professional and amateur swimming. We analyzed how visualizations are currently added to the coverage of Olympics swimming competitions and then plan to derive a design space for embedded data representations for swimming competitions. We are currently conducting a crowdsourced survey to explore which kind of swimming-related data general audiences are interested in, in order to identify opportunities for additional visualizations to be added to swimming competition coverage.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07696",
        "abstract url": "https://arxiv.org/abs/2409.07696",
        "title": "Visualization in Motion in Video Games for Different Types of Data",
        "rating": "-10",
        "keywords": [],
        "abstract": "We contribute an analysis of situated visualizations in motion in video games for different types of data, with a focus on quantitative and categorical data representations. Video games convey a lot of data to players, to help them succeed in the game. These visualizations frequently move across the screen due to camera changes or because the game elements themselves move. Our ultimate goal is to understand how motion factors affect visualization readability in video games and subsequently the players' performance in the game. We started our work by surveying the characteristics of how motion currently influences which kind of data representations in video games. We conducted a systematic review of 160 visualizations in motion in video games and extracted patterns and considerations regarding was what, and how visualizations currently exhibit motion factors in video games.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07700",
        "abstract url": "https://arxiv.org/abs/2409.07700",
        "title": "Disturbance-Robust Backup Control Barrier Functions: Safety Under Uncertain Dynamics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Obtaining a controlled invariant set is crucial for safety-critical control with control barrier functions (CBFs) but is non-trivial for complex nonlinear systems and constraints. Backup control barrier functions allow such sets to be constructed online in a computationally tractable manner by examining the evolution (or flow) of the system under a known backup control law. However, for systems with unmodeled disturbances, this flow cannot be directly computed, making the current methods inadequate for assuring safety in these scenarios. To address this gap, we leverage bounds on the nominal and disturbed flow to compute a forward invariant set online by ensuring safety of an expanding norm ball tube centered around the nominal system evolution. We prove that this set results in robust control constraints which guarantee safety of the disturbed system via our Disturbance-Robust Backup Control Barrier Function (DR-BCBF) solution. Additionally, the efficacy of the proposed framework is demonstrated in simulation, applied to a double integrator problem and a rigid body spacecraft rotation problem with rate constraints.",
        "subjects": [
            "eess.SY",
            "cs.RO",
            "math.DS"
        ],
        "comment": "Submitted to IEEE Control Systems Letters (L-CSS) with ACC option. 6 pages, 4 figures"
    },
    {
        "paper id": "2409.07709",
        "abstract url": "https://arxiv.org/abs/2409.07709",
        "title": "Harnessing TI Feeds for Exploitation Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many organizations rely on Threat Intelligence (TI) feeds to assess the risk associated with security threats. Due to the volume and heterogeneity of data, it is prohibitive to manually analyze the threat information available in different loosely structured TI feeds. Thus, there is a need to develop automated methods to vet and extract actionable information from TI feeds. To this end, we present a machine learning pipeline to automatically detect vulnerability exploitation from TI feeds. We first model threat vocabulary in loosely structured TI feeds using state-of-the-art embedding techniques (Doc2Vec and BERT) and then use it to train a supervised machine learning classifier to detect exploitation of security vulnerabilities. We use our approach to identify exploitation events in 191 different TI feeds. Our longitudinal evaluation shows that it is able to accurately identify exploitation events from TI feeds only using past data for training and even on TI feeds withheld from training. Our proposed approach is useful for a variety of downstream tasks such as data-driven vulnerability risk assessment.",
        "subjects": [
            "cs.CR",
            "cs.IR"
        ],
        "comment": "This paper appears at IEEE International Conference on Cyber Security and Resilience (IEEE CSR 2024)"
    },
    {
        "paper id": "2409.07717",
        "abstract url": "https://arxiv.org/abs/2409.07717",
        "title": "Eyes on the Phish(er): Towards Understanding Users' Email Processing Pattern and Mental Models in Phishing Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "Phishing emails typically masquerade themselves as reputable identities to trick people into providing sensitive information and credentials. Despite advancements in cybersecurity, attackers continuously adapt, posing ongoing threats to individuals and organisations. While email users are the last line of defence, they are not always well-prepared to detect phishing emails. This study examines how workload affects susceptibility to phishing, using eye-tracking technology to observe participants' reading patterns and interactions with tailored phishing emails. Incorporating both quantitative and qualitative analysis, we investigate users' attention to two phishing indicators, email sender and hyperlink URLs, and their reasons for assessing the trustworthiness of emails and falling for phishing emails. Our results provide concrete evidence that attention to the email sender can reduce phishing susceptibility. While we found no evidence that attention to the actual URL in the browser influences phishing detection, attention to the text masking links can increase phishing susceptibility. We also highlight how email relevance, familiarity, and visual presentation impact first impressions of email trustworthiness and phishing susceptibility.",
        "subjects": [
            "cs.HC",
            "cs.CR"
        ],
        "comment": "25 pages, 6 figures, currently accepted in EuroUsec2024, but not yet published"
    },
    {
        "paper id": "2409.07719",
        "abstract url": "https://arxiv.org/abs/2409.07719",
        "title": "Static Pricing for Single Sample Multi-unit Prophet Inequalities",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we study $k$-unit single sample prophet inequalities. A seller has $k$ identical, indivisible items to sell. A sequence of buyers arrive one-by-one, with each buyer's private value for the item, $X_i$, revealed to the seller when they arrive. While the seller is unaware of the distribution from which $X_i$ is drawn, they have access to a single sample, $Y_i$ drawn from the same distribution as $X_i$. What strategies can the seller adopt so as to maximize social welfare? Previous work has demonstrated that when $k = 1$, if the seller sets a price equal to the maximum of the samples, they can achieve a competitive ratio of $\\frac{1}{2}$ of the social welfare, and recently Pashkovich and Sayutina established an analogous result for $k = 2$. In this paper, we prove that for $k \\geq 3$, setting a (static) price equal to the $k^{\\text{th}}$ largest sample also obtains a competitive ratio of $\\frac{1}{2}$, resolving a conjecture Pashkovich and Sayutina pose. We then consider the situation where $k$ is large. We demonstrate that setting a price equal to the $(k-\\sqrt{2k\\log k})^{\\text{th}}$ largest sample obtains a competitive ratio of $1 - \\sqrt{\\frac{2\\log k}{k}} - o\\left(\\sqrt{\\frac{\\log k}{k}}\\right)$, and that this is the optimal possible ratio achievable with a static pricing scheme that sets one of the samples as a price.",
        "subjects": [
            "cs.GT",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.07741",
        "abstract url": "https://arxiv.org/abs/2409.07741",
        "title": "Handling expression evaluation under interference",
        "rating": "-10",
        "keywords": [],
        "abstract": "Hoare-style inference rules for program constructs permit the copying of expressions and tests from program text into logical contexts. It is known that this requires care even for sequential programs but further issues arise for concurrent programs because of potential interference to the values of variables. The \"rely-guarantee\" approach does tackle the issue of recording acceptable interference and offers a way to provide safe inference rules. This paper shows how the algebraic presentation of rely-guarantee ideas can clarify and formalise the conditions for safely re-using expressions and tests from program text in logical contexts for reasoning about programs.",
        "subjects": [
            "cs.LO",
            "cs.SE"
        ],
        "comment": "17 pages, 1 figure"
    }
]