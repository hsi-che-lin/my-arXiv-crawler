[
    {
        "paper id": "2409.11919",
        "abstract url": "https://arxiv.org/abs/2409.11919",
        "title": "LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language Foundation Models",
        "rating": "2.5",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Vision Language Models (VLMs) have shown impressive performances on numerous tasks but their zero-shot capabilities can be limited compared to dedicated or fine-tuned models. Yet, fine-tuning VLMs comes with limitations as it requires `white-box' access to the model's architecture and weights as well as expertise to design the fine-tuning objectives and optimize the hyper-parameters, which are specific to each VLM and downstream task. In this work, we propose LLM-wrapper, a novel approach to adapt VLMs in a `black-box' manner by leveraging large language models (LLMs) so as to reason on their outputs. We demonstrate the effectiveness of LLM-wrapper on Referring Expression Comprehension (REC), a challenging open-vocabulary task that requires spatial and semantic reasoning. Our approach significantly boosts the performance of off-the-shelf models, resulting in competitive results when compared with classic fine-tuning.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "EVAL-FoMo workshop, ECCV 2024"
    },
    {
        "paper id": "2409.11729",
        "abstract url": "https://arxiv.org/abs/2409.11729",
        "title": "DETECLAP: Enhancing Audio-Visual Representation Learning with Object Information",
        "rating": "2",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Current audio-visual representation learning can capture rough object categories (e.g., ``animals'' and ``instruments''), but it lacks the ability to recognize fine-grained details, such as specific categories like ``dogs'' and ``flutes'' within animals and instruments. To address this issue, we introduce DETECLAP, a method to enhance audio-visual representation learning with object information. Our key idea is to introduce an audio-visual label prediction loss to the existing Contrastive Audio-Visual Masked AutoEncoder to enhance its object awareness. To avoid costly manual annotations, we prepare object labels from both audio and visual inputs using state-of-the-art language-audio models and object detectors. We evaluate the method of audio-visual retrieval and classification using the VGGSound and AudioSet20K datasets. Our method achieves improvements in recall@10 of +1.5% and +1.2% for audio-to-visual and visual-to-audio retrieval, respectively, and an improvement in accuracy of +0.6% for audio-visual classification.",
        "subjects": [
            "cs.MM",
            "cs.CV",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "under review"
    },
    {
        "paper id": "2409.12011",
        "abstract url": "https://arxiv.org/abs/2409.12011",
        "title": "Mixture of Prompt Learning for Vision Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision Language",
                "VLMs"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "As powerful pre-trained vision-language models (VLMs) like CLIP gain prominence, numerous studies have attempted to combine VLMs for downstream tasks. Among these, prompt learning has been validated as an effective method for adapting to new tasks, which only requiring a small number of parameters. However, current prompt learning methods face two challenges: first, a single soft prompt struggles to capture the diverse styles and patterns within a dataset; second, fine-tuning soft prompts is prone to overfitting. To address these challenges, we propose a mixture of soft prompt learning method incorporating a routing module. This module is able to capture a dataset's varied styles and dynamically selects the most suitable prompts for each instance. Additionally, we introduce a novel gating mechanism to ensure the router selects prompts based on their similarity to hard prompt templates, which both retaining knowledge from hard prompts and improving selection accuracy. We also implement semantically grouped text-level supervision, initializing each soft prompt with the token embeddings of manually designed templates from its group and applied a contrastive loss between the resulted text feature and hard prompt encoded text feature. This supervision ensures that the text features derived from soft prompts remain close to those from their corresponding hard prompts, preserving initial knowledge and mitigating overfitting. Our method has been validated on 11 datasets, demonstrating evident improvements in few-shot learning, domain generalization, and base-to-new generalization scenarios compared to existing baselines. The code will be available at \\url{https://anonymous.4open.science/r/mocoop-6387}",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12191",
        "abstract url": "https://arxiv.org/abs/2409.12191",
        "title": "Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL models that redefines the conventional predetermined-resolution approach in visual processing. Qwen2-VL introduces the Naive Dynamic Resolution mechanism, which enables the model to dynamically process images of varying resolutions into different numbers of visual tokens. This approach allows the model to generate more efficient and accurate visual representations, closely aligning with human perceptual processes. The model also integrates Multimodal Rotary Position Embedding (M-RoPE), facilitating the effective fusion of positional information across text, images, and videos. We employ a unified paradigm for processing both images and videos, enhancing the model's visual perception capabilities. To explore the potential of large multimodal models, Qwen2-VL investigates the scaling laws for large vision-language models (LVLMs). By scaling both the model size-with versions at 2B, 8B, and 72B parameters-and the amount of training data, the Qwen2-VL Series achieves highly competitive performance. Notably, the Qwen2-VL-72B model achieves results comparable to leading models such as GPT-4o and Claude3.5-Sonnet across various multimodal benchmarks, outperforming other generalist models. Code is available at \\url{https://github.com/QwenLM/Qwen2-VL}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Code is available at https://github.com/QwenLM/Qwen2-VL. arXiv admin note: text overlap with arXiv:2408.15262 by other authors"
    },
    {
        "paper id": "2409.11905",
        "abstract url": "https://arxiv.org/abs/2409.11905",
        "title": "AlignBot: Aligning VLM-powered Customized Task Planning with User Reminders Through Fine-Tuning for Household Robots",
        "rating": "1.5",
        "keywords": [
            [
                "VLM"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents AlignBot, a novel framework designed to optimize VLM-powered customized task planning for household robots by effectively aligning with user reminders. In domestic settings, aligning task planning with user reminders poses significant challenges due to the limited quantity, diversity, and multimodal nature of the reminders. To address these challenges, AlignBot employs a fine-tuned LLaVA-7B model, functioning as an adapter for GPT-4o. This adapter model internalizes diverse forms of user reminders-such as personalized preferences, corrective guidance, and contextual assistance-into structured instruction-formatted cues that prompt GPT-4o in generating customized task plans. Additionally, AlignBot integrates a dynamic retrieval mechanism that selects task-relevant historical successes as prompts for GPT-4o, further enhancing task planning accuracy. To validate the effectiveness of AlignBot, experiments are conducted in real-world household environments, which are constructed within the laboratory to replicate typical household settings. A multimodal dataset with over 1,500 entries derived from volunteer reminders is used for training and evaluation. The results demonstrate that AlignBot significantly improves customized task planning, outperforming existing LLM- and VLM-powered planners by interpreting and aligning with user reminders, achieving 86.8% success rate compared to the vanilla GPT-4o baseline at 21.6%, reflecting a 65% improvement and over four times greater effectiveness. Supplementary materials are available at: https://yding25.com/AlignBot/",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11909",
        "abstract url": "https://arxiv.org/abs/2409.11909",
        "title": "Mixture of Experts Fusion for Fake Audio Detection Using Frozen wav2vec 2.0",
        "rating": "1.5",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Speech synthesis technology has posed a serious threat to speaker verification systems. Currently, the most effective fake audio detection methods utilize pretrained models, and integrating features from various layers of pretrained model further enhances detection performance. However, most of the previously proposed fusion methods require fine-tuning the pretrained models, resulting in excessively long training times and hindering model iteration when facing new speech synthesis technology. To address this issue, this paper proposes a feature fusion method based on the Mixture of Experts, which extracts and integrates features relevant to fake audio detection from layer features, guided by a gating network based on the last layer feature, while freezing the pretrained model. Experiments conducted on the ASVspoof2019 and ASVspoof2021 datasets demonstrate that the proposed method achieves competitive performance compared to those requiring fine-tuning.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "submitted to ICASSP2025"
    },
    {
        "paper id": "2409.11923",
        "abstract url": "https://arxiv.org/abs/2409.11923",
        "title": "Agglomerative Token Clustering",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "We present Agglomerative Token Clustering (ATC), a novel token merging method that consistently outperforms previous token merging and pruning methods across image classification, image synthesis, and object detection & segmentation tasks. ATC merges clusters through bottom-up hierarchical clustering, without the introduction of extra learnable parameters. We find that ATC achieves state-of-the-art performance across all tasks, and can even perform on par with prior state-of-the-art when applied off-the-shelf, i.e. without fine-tuning. ATC is particularly effective when applied with low keep rates, where only a small fraction of tokens are kept and retaining task performance is especially difficult.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024. Project webpage at https://vap.aau.dk/atc/"
    },
    {
        "paper id": "2409.11703",
        "abstract url": "https://arxiv.org/abs/2409.11703",
        "title": "Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As Large Language Models (LLMs) advance in natural language processing, there is growing interest in leveraging their capabilities to simplify software interactions. In this paper, we propose a novel system that integrates LLMs for both classifying natural language inputs into corresponding API calls and automating the creation of sample datasets tailored to specific API functions. By classifying natural language commands, our system allows users to invoke complex software functionalities through simple inputs, improving interaction efficiency and lowering the barrier to software utilization. Our dataset generation approach also enables the efficient and systematic evaluation of different LLMs in classifying API calls, offering a practical tool for developers or business owners to assess the suitability of LLMs for customized API management. We conduct experiments on several prominent LLMs using generated sample datasets for various API functions. The results show that GPT-4 achieves a high classification accuracy of 0.996, while LLaMA-3-8B performs much worse at 0.759. These findings highlight the potential of LLMs to transform API management and validate the effectiveness of our system in guiding model testing and selection across diverse applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11704",
        "abstract url": "https://arxiv.org/abs/2409.11704",
        "title": "From Lists to Emojis: How Format Bias Affects Model Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we study format biases in reinforcement learning from human feedback (RLHF). We observe that many widely-used preference models, including human evaluators, GPT-4, and top-ranking models on the RewardBench benchmark, exhibit strong biases towards specific format patterns, such as lists, links, bold text, and emojis. Furthermore, large language models (LLMs) can exploit these biases to achieve higher rankings on popular benchmarks like AlpacaEval and LMSYS Chatbot Arena. One notable example of this is verbosity bias, where current preference models favor longer responses that appear more comprehensive, even when their quality is equal to or lower than shorter, competing responses. However, format biases beyond verbosity remain largely underexplored in the literature. In this work, we extend the study of biases in preference learning beyond the commonly recognized length bias, offering a comprehensive analysis of a wider range of format biases. Additionally, we show that with a small amount of biased data (less than 1%), we can inject significant bias into the reward model. Moreover, these format biases can also be easily exploited by downstream alignment algorithms, such as best-of-n sampling and online iterative DPO, as it is usually easier to manipulate the format than to improve the quality of responses. Our findings emphasize the need to disentangle format and content both for designing alignment algorithms and evaluating models.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Working in progress"
    },
    {
        "paper id": "2409.11724",
        "abstract url": "https://arxiv.org/abs/2409.11724",
        "title": "TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Current Large Language Models (LLMs) exhibit limited ability to understand table structures and to apply precise numerical reasoning, which is crucial for tasks such as table question answering (TQA) and table-based fact verification (TFV). To address these challenges, we introduce our Tool-Augmented Reasoning framework for Tables (TART), which integrates LLMs with specialized tools. TART contains three key components: a table formatter to ensure accurate data representation, a tool maker to develop specific computational tools, and an explanation generator to maintain explainability. We also present the TOOLTAB dataset, a new benchmark designed specifically for training LLMs in table-tool integration. Our experiments indicate that TART achieves substantial improvements over existing methods (e.g., Chain-of-Thought) by improving both the precision of data processing and the clarity of the reasoning process. Notably, TART paired with CodeLlama achieves 90.0% of the accuracy of the closed-sourced LLM GPT-3.5-turbo, highlighting its robustness in diverse real-world scenarios. All the code and data are available at https://github.com/XinyuanLu00/TART.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "technical report"
    },
    {
        "paper id": "2409.11726",
        "abstract url": "https://arxiv.org/abs/2409.11726",
        "title": "Revealing the Challenge of Detecting Character Knowledge Errors in LLM Role-Playing",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language model (LLM) role-playing has gained widespread attention, where the authentic character knowledge is crucial for constructing realistic LLM role-playing agents. However, existing works usually overlook the exploration of LLMs' ability to detect characters' known knowledge errors (KKE) and unknown knowledge errors (UKE) while playing roles, which would lead to low-quality automatic construction of character trainable corpus. In this paper, we propose a probing dataset to evaluate LLMs' ability to detect errors in KKE and UKE. The results indicate that even the latest LLMs struggle to effectively detect these two types of errors, especially when it comes to familiar knowledge. We experimented with various reasoning strategies and propose an agent-based reasoning method, Self-Recollection and Self-Doubt (S2RD), to further explore the potential for improving error detection capabilities. Experiments show that our method effectively improves the LLMs' ability to detect error character knowledge, but it remains an issue that requires ongoing attention.",
        "subjects": [
            "cs.CL",
            "cs.HC"
        ],
        "comment": "22 pages, 14 figures"
    },
    {
        "paper id": "2409.11727",
        "abstract url": "https://arxiv.org/abs/2409.11727",
        "title": "Enabling Real-Time Conversations with Minimal Training Costs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated the ability to improve human efficiency through conversational interactions. Conventional LLM-powered dialogue systems, operating on a turn-based paradigm, preclude real-time interaction during response generation. To address this limitation, researchers have proposed duplex models. These models can dynamically adapt to user input, facilitating real-time interactive feedback. However, these methods typically require substantial computational resources to acquire the ability. To reduce overhead, this paper presents a new duplex decoding approach that enhances LLMs with duplex ability, requiring minimal additional training. Specifically, our method employs parallel decoding of queries and responses in conversations, effectively implementing a channel-division-multiplexing decoding strategy. Experimental results indicate that our proposed method significantly enhances the naturalness and human-likeness of user-AI interactions with minimal training costs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "7pages, 6 figures, 1 table"
    },
    {
        "paper id": "2409.11731",
        "abstract url": "https://arxiv.org/abs/2409.11731",
        "title": "Insights into the Incorporation of Signal Information in Binaural Signal Matching with Wearable Microphone Arrays",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The increasing popularity of spatial audio in applications such as teleconferencing, entertainment, and virtual reality has led to the recent developments of binaural reproduction methods. However, only a few of these methods are well-suited for wearable and mobile arrays, which typically consist of a small number of microphones. One such method is binaural signal matching (BSM), which has been shown to produce high-quality binaural signals for wearable arrays. However, BSM may be suboptimal in cases of high direct-to-reverberant ratio (DRR) as it is based on the diffuse sound field assumption. To overcome this limitation, previous studies incorporated sound-field models other than diffuse. However, this approach was not studied comprehensively. This paper extensively investigates two BSM-based methods designed for high DRR scenarios. The methods incorporate a sound field model composed of direct and reverberant components.The methods are investigated both mathematically and using simulations, finally validated by a listening test. The results show that the proposed methods can significantly improve the performance of BSM , in particular in the direction of the source, while presenting only a negligible degradation in other directions. Furthermore, when source direction estimation is inaccurate, performance of these methods degrade to equal that of the BSM, presenting a desired robustness quality.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11746",
        "abstract url": "https://arxiv.org/abs/2409.11746",
        "title": "SALT: Standardized Audio event Label Taxonomy",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Machine listening systems often rely on fixed taxonomies to organize and label audio data, key for training and evaluating deep neural networks (DNNs) and other supervised algorithms. However, such taxonomies face significant constraints: they are composed of application-dependent predefined categories, which hinders the integration of new or varied sounds, and exhibits limited cross-dataset compatibility due to inconsistent labeling standards. To overcome these limitations, we introduce SALT: Standardized Audio event Label Taxonomy. Building upon the hierarchical structure of AudioSet's ontology, our taxonomy extends and standardizes labels across 24 publicly available environmental sound datasets, allowing the mapping of class labels from diverse datasets to a unified system. Our proposal comes with a new Python package designed for navigating and utilizing this taxonomy, easing cross-dataset label searching and hierarchical exploration. Notably, our package allows effortless data aggregation from diverse sources, hence easy experimentation with combined datasets.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11770",
        "abstract url": "https://arxiv.org/abs/2409.11770",
        "title": "Knowledge Adaptation Network for Few-Shot Class-Incremental Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot class-incremental learning (FSCIL) aims to incrementally recognize new classes using a few samples while maintaining the performance on previously learned classes. One of the effective methods to solve this challenge is to construct prototypical evolution classifiers. Despite the advancement achieved by most existing methods, the classifier weights are simply initialized using mean features. Because representations for new classes are weak and biased, we argue such a strategy is suboptimal. In this paper, we tackle this issue from two aspects. Firstly, thanks to the development of foundation models, we employ a foundation model, the CLIP, as the network pedestal to provide a general representation for each class. Secondly, to generate a more reliable and comprehensive instance representation, we propose a Knowledge Adapter (KA) module that summarizes the data-specific knowledge from training data and fuses it into the general representation. Additionally, to tune the knowledge learned from the base classes to the upcoming classes, we propose a mechanism of Incremental Pseudo Episode Learning (IPEL) by simulating the actual FSCIL. Taken together, our proposed method, dubbed as Knowledge Adaptation Network (KANet), achieves competitive performance on a wide range of datasets, including CIFAR100, CUB200, and ImageNet-R.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "13 pages;6 figures"
    },
    {
        "paper id": "2409.11785",
        "abstract url": "https://arxiv.org/abs/2409.11785",
        "title": "Distilling Channels for Efficient Deep Tracking",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Deep trackers have proven success in visual tracking. Typically, these trackers employ optimally pre-trained deep networks to represent all diverse objects with multi-channel features from some fixed layers. The deep networks employed are usually trained to extract rich knowledge from massive data used in object classification and so they are capable to represent generic objects very well. However, these networks are too complex to represent a specific moving object, leading to poor generalization as well as high computational and memory costs. This paper presents a novel and general framework termed channel distillation to facilitate deep trackers. To validate the effectiveness of channel distillation, we take discriminative correlation filter (DCF) and ECO for example. We demonstrate that an integrated formulation can turn feature compression, response map generation, and model update into a unified energy minimization problem to adaptively select informative feature channels that improve the efficacy of tracking moving objects on the fly. Channel distillation can accurately extract good channels, alleviating the influence of noisy channels and generally reducing the number of channels, as well as adaptively generalizing to different channels and networks. The resulting deep tracker is accurate, fast, and has low memory requirements. Extensive experimental evaluations on popular benchmarks clearly demonstrate the effectiveness and generalizability of our framework.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Published by IEEE TIP 2020"
    },
    {
        "paper id": "2409.11786",
        "abstract url": "https://arxiv.org/abs/2409.11786",
        "title": "Efficient Low-Resolution Face Recognition via Bridge Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Face recognition in the wild is now advancing towards light-weight models, fast inference speed and resolution-adapted capability. In this paper, we propose a bridge distillation approach to turn a complex face model pretrained on private high-resolution faces into a light-weight one for low-resolution face recognition. In our approach, such a cross-dataset resolution-adapted knowledge transfer problem is solved via two-step distillation. In the first step, we conduct cross-dataset distillation to transfer the prior knowledge from private high-resolution faces to public high-resolution faces and generate compact and discriminative features. In the second step, the resolution-adapted distillation is conducted to further transfer the prior knowledge to synthetic low-resolution faces via multi-task learning. By learning low-resolution face representations and mimicking the adapted high-resolution knowledge, a light-weight student model can be constructed with high efficiency and promising accuracy in recognizing low-resolution faces. Experimental results show that the student model performs impressively in recognizing low-resolution faces with only 0.21M parameters and 0.057MB memory. Meanwhile, its speed reaches up to 14,705, ~934 and 763 faces per second on GPU, CPU and mobile phone, respectively.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "This paper is published in IEEE TIP 2020"
    },
    {
        "paper id": "2409.11798",
        "abstract url": "https://arxiv.org/abs/2409.11798",
        "title": "The Factuality of Large Language Models in the Legal Domain",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper investigates the factuality of large language models (LLMs) as knowledge bases in the legal domain, in a realistic usage scenario: we allow for acceptable variations in the answer, and let the model abstain from answering when uncertain. First, we design a dataset of diverse factual questions about case law and legislation. We then use the dataset to evaluate several LLMs under different evaluation methods, including exact, alias, and fuzzy matching. Our results show that the performance improves significantly under the alias and fuzzy matching methods. Further, we explore the impact of abstaining and in-context examples, finding that both strategies enhance precision. Finally, we demonstrate that additional pre-training on legal documents, as seen with SaulLM, further improves factual precision from 63% to 81%.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "CIKM 2024, short paper"
    },
    {
        "paper id": "2409.11802",
        "abstract url": "https://arxiv.org/abs/2409.11802",
        "title": "Latent fingerprint enhancement for accurate minutiae detection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Identification of suspects based on partial and smudged fingerprints, commonly referred to as fingermarks or latent fingerprints, presents a significant challenge in the field of fingerprint recognition. Although fixed-length embeddings have shown effectiveness in recognising rolled and slap fingerprints, the methods for matching latent fingerprints have primarily centred around local minutiae-based embeddings, failing to fully exploit global representations for matching purposes. Consequently, enhancing latent fingerprints becomes critical to ensuring robust identification for forensic investigations. Current approaches often prioritise restoring ridge patterns, overlooking the fine-macroeconomic details crucial for accurate fingerprint recognition. To address this, we propose a novel approach that uses generative adversary networks (GANs) to redefine Latent Fingerprint Enhancement (LFE) through a structured approach to fingerprint generation. By directly optimising the minutiae information during the generation process, the model produces enhanced latent fingerprints that exhibit exceptional fidelity to ground-truth instances. This leads to a significant improvement in identification performance. Our framework integrates minutiae locations and orientation fields, ensuring the preservation of both local and structural fingerprint features. Extensive evaluations conducted on two publicly available datasets demonstrate our method's dominance over existing state-of-the-art techniques, highlighting its potential to significantly enhance latent fingerprint recognition accuracy in forensic applications.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11827",
        "abstract url": "https://arxiv.org/abs/2409.11827",
        "title": "Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Extract-then-Abstract is a naturally coherent paradigm to conduct abstractive summarization with the help of salient information identified by the extractive model. Previous works that adopt this paradigm train the extractor and abstractor separately and introduce extra parameters to highlight the extracted salients to the abstractor, which results in error accumulation and additional training costs. In this paper, we first introduce a parameter-free highlight method into the encoder-decoder framework: replacing the encoder attention mask with a saliency mask in the cross-attention module to force the decoder to focus only on salient parts of the input. A preliminary analysis compares different highlight methods, demonstrating the effectiveness of our saliency mask. We further propose the novel extract-and-abstract paradigm, ExtAbs, which jointly and seamlessly performs Extractive and Abstractive summarization tasks within single encoder-decoder model to reduce error accumulation. In ExtAbs, the vanilla encoder is augmented to extract salients, and the vanilla decoder is modified with the proposed saliency mask to generate summaries. Built upon BART and PEGASUS, experiments on three datasets show that ExtAbs can achieve superior performance than baselines on the extractive task and performs comparable, or even better than the vanilla models on the abstractive task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11859",
        "abstract url": "https://arxiv.org/abs/2409.11859",
        "title": "Tight and Efficient Upper Bound on Spectral Norm of Convolutional Layers",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Controlling the spectral norm of the Jacobian matrix, which is related to the convolution operation, has been shown to improve generalization, training stability and robustness in CNNs. Existing methods for computing the norm either tend to overestimate it or their performance may deteriorate quickly with increasing the input and kernel sizes. In this paper, we demonstrate that the tensor version of the spectral norm of a four-dimensional convolution kernel, up to a constant factor, serves as an upper bound for the spectral norm of the Jacobian matrix associated with the convolution operation. This new upper bound is independent of the input image resolution, differentiable and can be efficiently calculated during training. Through experiments, we demonstrate how this new bound can be used to improve the performance of convolutional architectures.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2409.11860",
        "abstract url": "https://arxiv.org/abs/2409.11860",
        "title": "Retrieve, Annotate, Evaluate, Repeat: Leveraging Multimodal LLMs for Large-Scale Product Retrieval Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Evaluating production-level retrieval systems at scale is a crucial yet challenging task due to the limited availability of a large pool of well-trained human annotators. Large Language Models (LLMs) have the potential to address this scaling issue and offer a viable alternative to humans for the bulk of annotation tasks. In this paper, we propose a framework for assessing the product search engines in a large-scale e-commerce setting, leveraging Multimodal LLMs for (i) generating tailored annotation guidelines for individual queries, and (ii) conducting the subsequent annotation task. Our method, validated through deployment on a large e-commerce platform, demonstrates comparable quality to human annotations, significantly reduces time and cost, facilitates rapid problem discovery, and provides an effective solution for production-level quality control at scale.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL",
            "cs.ET",
            "cs.HC"
        ],
        "comment": "13 pages, 5 figures, 4 Tables"
    },
    {
        "paper id": "2409.11867",
        "abstract url": "https://arxiv.org/abs/2409.11867",
        "title": "Distillation-free Scaling of Large SSMs for Images and Videos",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "State-space models (SSMs), exemplified by S4, have introduced a novel context modeling method by integrating state-space techniques into deep learning. However, they struggle with global context modeling due to their data-independent matrices. The Mamba model addressed this with data-dependent variants via the S6 selective-scan algorithm, enhancing context modeling, especially for long sequences. However, Mamba-based architectures are difficult to scale with respect to the number of parameters, which is a major limitation for vision applications. This paper addresses the scalability issue of large SSMs for image classification and action recognition without requiring additional techniques like knowledge distillation. We analyze the distinct characteristics of Mamba-based and Attention-based models, proposing a Mamba-Attention interleaved architecture that enhances scalability, robustness, and performance. We demonstrate that the stable and efficient interleaved architecture resolves the scalability issue of Mamba-based architectures for images and videos and increases robustness to common artifacts like JPEG compression. Our thorough evaluation on the ImageNet-1K, Kinetics-400 and Something-Something-v2 benchmarks demonstrates that our approach improves the accuracy of state-of-the-art Mamba-based architectures by up to $+1.7$.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11887",
        "abstract url": "https://arxiv.org/abs/2409.11887",
        "title": "DocMamba: Efficient Document Pre-training with State Space Model",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, visually-rich document understanding has attracted increasing attention. Transformer-based pre-trained models have become the mainstream approach, yielding significant performance gains in this field. However, the self-attention mechanism's quadratic computational complexity hinders their efficiency and ability to process long documents. In this paper, we present DocMamba, a novel framework based on the state space model. It is designed to reduce computational complexity to linear while preserving global modeling capabilities. To further enhance its effectiveness in document processing, we introduce the Segment-First Bidirectional Scan (SFBS) to capture contiguous semantic information. Experimental results demonstrate that DocMamba achieves new state-of-the-art results on downstream datasets such as FUNSD, CORD, and SORIE, while significantly improving speed and reducing memory usage. Notably, experiments on the HRDoc confirm DocMamba's potential for length extrapolation. The code will be available online.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11889",
        "abstract url": "https://arxiv.org/abs/2409.11889",
        "title": "M2R-Whisper: Multi-stage and Multi-scale Retrieval Augmentation for Enhancing Whisper",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "State-of-the-art models like OpenAI's Whisper exhibit strong performance in multilingual automatic speech recognition (ASR), but they still face challenges in accurately recognizing diverse subdialects. In this paper, we propose M2R-whisper, a novel multi-stage and multi-scale retrieval augmentation approach designed to enhance ASR performance in low-resource settings. Building on the principles of in-context learning (ICL) and retrieval-augmented techniques, our method employs sentence-level ICL in the pre-processing stage to harness contextual information, while integrating token-level k-Nearest Neighbors (kNN) retrieval as a post-processing step to further refine the final output distribution. By synergistically combining sentence-level and token-level retrieval strategies, M2R-whisper effectively mitigates various types of recognition errors. Experiments conducted on Mandarin and subdialect datasets, including AISHELL-1 and KeSpeech, demonstrate substantial improvements in ASR accuracy, all achieved without any parameter updates.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11901",
        "abstract url": "https://arxiv.org/abs/2409.11901",
        "title": "LLMs + Persona-Plug = Personalized LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Personalization plays a critical role in numerous language tasks and applications, since users with the same requirements may prefer diverse outputs based on their individual interests. This has led to the development of various personalized approaches aimed at adapting large language models (LLMs) to generate customized outputs aligned with user preferences. Some of them involve fine-tuning a unique personalized LLM for each user, which is too expensive for widespread application. Alternative approaches introduce personalization information in a plug-and-play manner by retrieving the user's relevant historical texts as demonstrations. However, this retrieval-based strategy may break the continuity of the user history and fail to capture the user's overall styles and patterns, hence leading to sub-optimal performance. To address these challenges, we propose a novel personalized LLM model, \\ours{}. It constructs a user-specific embedding for each individual by modeling all her historical contexts through a lightweight plug-in user embedder module. By attaching this embedding to the task input, LLMs can better understand and capture user habits and preferences, thereby producing more personalized outputs without tuning their own parameters. Extensive experiments on various tasks in the language model personalization (LaMP) benchmark demonstrate that the proposed model significantly outperforms existing personalized LLM approaches.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11917",
        "abstract url": "https://arxiv.org/abs/2409.11917",
        "title": "LLMs in Education: Novel Perspectives, Challenges, and Opportunities",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The role of large language models (LLMs) in education is an increasing area of interest today, considering the new opportunities they offer for teaching, learning, and assessment. This cutting-edge tutorial provides an overview of the educational applications of NLP and the impact that the recent advances in LLMs have had on this field. We will discuss the key challenges and opportunities presented by LLMs, grounding them in the context of four major educational applications: reading, writing, and speaking skills, and intelligent tutoring systems (ITS). This COLING 2025 tutorial is designed for researchers and practitioners interested in the educational applications of NLP and the role LLMs have to play in this area. It is the first of its kind to address this timely topic.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "COLING 2025 Tutorial"
    },
    {
        "paper id": "2409.11933",
        "abstract url": "https://arxiv.org/abs/2409.11933",
        "title": "Reinforcement Learning as an Improvement Heuristic for Real-World Production Scheduling",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "The integration of Reinforcement Learning (RL) with heuristic methods is an emerging trend for solving optimization problems, which leverages RL's ability to learn from the data generated during the search process. One promising approach is to train an RL agent as an improvement heuristic, starting with a suboptimal solution that is iteratively improved by applying small changes. We apply this approach to a real-world multiobjective production scheduling problem. Our approach utilizes a network architecture that includes Transformer encoding to learn the relationships between jobs. Afterwards, a probability matrix is generated from which pairs of jobs are sampled and then swapped to improve the solution. We benchmarked our approach against other heuristics using real data from our industry partner, demonstrating its superior performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This paper was accepted at the ICMLA 2024"
    },
    {
        "paper id": "2409.11953",
        "abstract url": "https://arxiv.org/abs/2409.11953",
        "title": "Tracking Any Point with Frame-Event Fusion Network at High Frame Rate",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Tracking any point based on image frames is constrained by frame rates, leading to instability in high-speed scenarios and limited generalization in real-world applications. To overcome these limitations, we propose an image-event fusion point tracker, FE-TAP, which combines the contextual information from image frames with the high temporal resolution of events, achieving high frame rate and robust point tracking under various challenging conditions. Specifically, we designed an Evolution Fusion module (EvoFusion) to model the image generation process guided by events. This module can effectively integrate valuable information from both modalities operating at different frequencies. To achieve smoother point trajectories, we employed a transformer-based refinement strategy that updates the point's trajectories and features iteratively. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches, particularly improving expected feature age by 24$\\%$ on EDS datasets. Finally, we qualitatively validated the robustness of our algorithm in real driving scenarios using our custom-designed high-resolution image-event synchronization device. Our source code will be released at https://github.com/ljx1002/FE-TAP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11964",
        "abstract url": "https://arxiv.org/abs/2409.11964",
        "title": "Data Efficient Acoustic Scene Classification using Teacher-Informed Confusing Class Instruction",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this technical report, we describe the SNTL-NTU team's submission for Task 1 Data-Efficient Low-Complexity Acoustic Scene Classification of the detection and classification of acoustic scenes and events (DCASE) 2024 challenge. Three systems are introduced to tackle training splits of different sizes. For small training splits, we explored reducing the complexity of the provided baseline model by reducing the number of base channels. We introduce data augmentation in the form of mixup to increase the diversity of training samples. For the larger training splits, we use FocusNet to provide confusing class information to an ensemble of multiple Patchout faSt Spectrogram Transformer (PaSST) models and baseline models trained on the original sampling rate of 44.1 kHz. We use Knowledge Distillation to distill the ensemble model to the baseline student model. Training the systems on the TAU Urban Acoustic Scene 2022 Mobile development dataset yielded the highest average testing accuracy of (62.21, 59.82, 56.81, 53.03, 47.97)% on split (100, 50, 25, 10, 5)% respectively over the three systems.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "5 pages, 3 figures"
    },
    {
        "paper id": "2409.11971",
        "abstract url": "https://arxiv.org/abs/2409.11971",
        "title": "Sampling Latent Material-Property Information From LLM-Derived Embedding Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Vector embeddings derived from large language models (LLMs) show promise in capturing latent information from the literature. Interestingly, these can be integrated into material embeddings, potentially useful for data-driven predictions of materials properties. We investigate the extent to which LLM-derived vectors capture the desired information and their potential to provide insights into material properties without additional training. Our findings indicate that, although LLMs can be used to generate representations reflecting certain property information, extracting the embeddings requires identifying the optimal contextual clues and appropriate comparators. Despite this restriction, it appears that LLMs still have the potential to be useful in generating meaningful materials-science representations.",
        "subjects": [
            "cs.CL",
            "cond-mat.mtrl-sci"
        ],
        "comment": "10 pages, 7 figures"
    },
    {
        "paper id": "2409.12010",
        "abstract url": "https://arxiv.org/abs/2409.12010",
        "title": "ChefFusion: Multimodal Foundation Model Integrating Recipe and Food Image Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Significant work has been conducted in the domain of food computing, yet these studies typically focus on single tasks such as t2t (instruction generation from food titles and ingredients), i2t (recipe generation from food images), or t2i (food image generation from recipes). None of these approaches integrate all modalities simultaneously. To address this gap, we introduce a novel food computing foundation model that achieves true multimodality, encompassing tasks such as t2t, t2i, i2t, it2t, and t2ti. By leveraging large language models (LLMs) and pre-trained image encoder and decoder models, our model can perform a diverse array of food computing-related tasks, including food understanding, food recognition, recipe generation, and food image generation. Compared to previous models, our foundation model demonstrates a significantly broader range of capabilities and exhibits superior performance, particularly in food image generation and recipe generation tasks. We open-sourced ChefFusion at GitHub.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12042",
        "abstract url": "https://arxiv.org/abs/2409.12042",
        "title": "ASR Benchmarking: Need for a More Representative Conversational Dataset",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Automatic Speech Recognition (ASR) systems have achieved remarkable performance on widely used benchmarks such as LibriSpeech and Fleurs. However, these benchmarks do not adequately reflect the complexities of real-world conversational environments, where speech is often unstructured and contains disfluencies such as pauses, interruptions, and diverse accents. In this study, we introduce a multilingual conversational dataset, derived from TalkBank, consisting of unstructured phone conversation between adults. Our results show a significant performance drop across various state-of-the-art ASR models when tested in conversational settings. Furthermore, we observe a correlation between Word Error Rate and the presence of speech disfluencies, highlighting the critical need for more realistic, conversational ASR benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12059",
        "abstract url": "https://arxiv.org/abs/2409.12059",
        "title": "Dual-Layer Training and Decoding of Large Language Model with Simultaneously Thinking and Speaking",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Model can reasonably understand and generate human expressions but may lack of thorough thinking and reasoning mechanisms. Recently there have been several studies which enhance the thinking ability of language models but most of them are not data-driven or training-based. In this paper, we are motivated by the cognitive mechanism in the natural world, and design a novel model architecture called TaS which allows it to first consider the thoughts and then express the response based upon the query. We design several pipelines to annotate or generate the thought contents from prompt-response samples, then add language heads in a middle layer which behaves as the thinking layer. We train the language model by the thoughts-augmented data and successfully let the thinking layer automatically generate reasonable thoughts and finally output more reasonable responses. Both qualitative examples and quantitative results validate the effectiveness and performance of TaS. Our code is available at https://anonymous.4open.science/r/TadE.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2409.12060",
        "abstract url": "https://arxiv.org/abs/2409.12060",
        "title": "PARAPHRASUS : A Comprehensive Benchmark for Evaluating Paraphrase Detection Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The task of determining whether two texts are paraphrases has long been a challenge in NLP. However, the prevailing notion of paraphrase is often quite simplistic, offering only a limited view of the vast spectrum of paraphrase phenomena. Indeed, we find that evaluating models in a paraphrase dataset can leave uncertainty about their true semantic understanding. To alleviate this, we release paraphrasus, a benchmark designed for multi-dimensional assessment of paraphrase detection models and finer model selection. We find that paraphrase detection models under a fine-grained evaluation lens exhibit trade-offs that cannot be captured through a single classification dataset.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12097",
        "abstract url": "https://arxiv.org/abs/2409.12097",
        "title": "Skill matching at scale: freelancer-project alignment for efficient multilingual candidate retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "Finding the perfect match between a job proposal and a set of freelancers is not an easy task to perform at scale, especially in multiple languages. In this paper, we propose a novel neural retriever architecture that tackles this problem in a multilingual setting. Our method encodes project descriptions and freelancer profiles by leveraging pre-trained multilingual language models. The latter are used as backbone for a custom transformer architecture that aims to keep the structure of the profiles and project. This model is trained with a contrastive loss on historical data. Thanks to several experiments, we show that this approach effectively captures skill matching similarity and facilitates efficient matching, outperforming traditional methods.",
        "subjects": [
            "cs.CL",
            "cs.IR",
            "cs.LG",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12122",
        "abstract url": "https://arxiv.org/abs/2409.12122",
        "title": "Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In this report, we present a series of math-specific large language models: Qwen2.5-Math and Qwen2.5-Math-Instruct-1.5B/7B/72B. The core innovation of the Qwen2.5 series lies in integrating the philosophy of self-improvement throughout the entire pipeline, from pre-training and post-training to inference: (1) During the pre-training phase, Qwen2-Math-Instruct is utilized to generate large-scale, high-quality mathematical data. (2) In the post-training phase, we develop a reward model (RM) by conducting massive sampling from Qwen2-Math-Instruct. This RM is then applied to the iterative evolution of data in supervised fine-tuning (SFT). With a stronger SFT model, it's possible to iteratively train and update the RM, which in turn guides the next round of SFT data iteration. On the final SFT model, we employ the ultimate RM for reinforcement learning, resulting in the Qwen2.5-Math-Instruct. (3) Furthermore, during the inference stage, the RM is used to guide sampling, optimizing the model's performance. Qwen2.5-Math-Instruct supports both Chinese and English, and possess advanced mathematical reasoning capabilities, including Chain-of-Thought (CoT) and Tool-Integrated Reasoning (TIR). We evaluate our models on 10 mathematics datasets in both English and Chinese, such as GSM8K, MATH, GaoKao, AMC23, and AIME24, covering a range of difficulties from grade school level to math competition problems.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12124",
        "abstract url": "https://arxiv.org/abs/2409.12124",
        "title": "Optimal Visual Search with Highly Heuristic Decision Rules",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual search is a fundamental natural task for humans and other animals. We investigated the decision processes humans use when searching briefly presented displays having well-separated potential target-object locations. Performance was compared with the Bayesian-optimal decision process under the assumption that the information from the different potential target locations is statistically independent. Surprisingly, humans performed slightly better than optimal, despite humans' substantial loss of sensitivity in the fovea, and the implausibility of the human brain replicating the optimal computations. We show that three factors can quantitatively explain these seemingly paradoxical results. Most importantly, simple and fixed heuristic decision rules reach near optimal search performance. Secondly, foveal neglect primarily affects only the central potential target location. Finally, spatially correlated neural noise causes search performance to exceed that predicted for independent noise. These findings have far-reaching implications for understanding visual search tasks and other identification tasks in humans and other animals.",
        "subjects": [
            "q-bio.NC",
            "cs.CV",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12126",
        "abstract url": "https://arxiv.org/abs/2409.12126",
        "title": "Linguini: A benchmark for language-agnostic linguistic reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We propose a new benchmark to measure a language model's linguistic reasoning skills without relying on pre-existing language-specific knowledge. The test covers 894 questions grouped in 160 problems across 75 (mostly) extremely low-resource languages, extracted from the International Linguistic Olympiad corpus. To attain high accuracy on this benchmark, models don't need previous knowledge of the tested language, as all the information needed to solve the linguistic puzzle is presented in the context. We find that, while all analyzed models rank below 25% accuracy, there is a significant gap between open and closed models, with the best-performing proprietary model at 24.05% and the best-performing open model at 8.84%.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12134",
        "abstract url": "https://arxiv.org/abs/2409.12134",
        "title": "BERT-VBD: Vietnamese Multi-Document Summarization Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In tackling the challenge of Multi-Document Summarization (MDS), numerous methods have been proposed, spanning both extractive and abstractive summarization techniques. However, each approach has its own limitations, making it less effective to rely solely on either one. An emerging and promising strategy involves a synergistic fusion of extractive and abstractive summarization methods. Despite the plethora of studies in this domain, research on the combined methodology remains scarce, particularly in the context of Vietnamese language processing. This paper presents a novel Vietnamese MDS framework leveraging a two-component pipeline architecture that integrates extractive and abstractive techniques. The first component employs an extractive approach to identify key sentences within each document. This is achieved by a modification of the pre-trained BERT network, which derives semantically meaningful phrase embeddings using siamese and triplet network structures. The second component utilizes the VBD-LLaMA2-7B-50b model for abstractive summarization, ultimately generating the final summary document. Our proposed framework demonstrates a positive performance, attaining ROUGE-2 scores of 39.6% on the VN-MDS dataset and outperforming the state-of-the-art baselines.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2409.12136",
        "abstract url": "https://arxiv.org/abs/2409.12136",
        "title": "GRIN: GRadient-INformed MoE",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Mixture-of-Experts (MoE) models scale more effectively than dense models due to sparse computation through expert routing, selectively activating only a small subset of expert modules. However, sparse computation challenges traditional training practices, as discrete expert routing hinders standard backpropagation and thus gradient-based optimization, which are the cornerstone of deep learning. To better pursue the scaling power of MoE, we introduce GRIN (GRadient-INformed MoE training), which incorporates sparse gradient estimation for expert routing and configures model parallelism to avoid token dropping. Applying GRIN to autoregressive language modeling, we develop a top-2 16$\\times$3.8B MoE model. Our model, with only 6.6B activated parameters, outperforms a 7B dense model and matches the performance of a 14B dense model trained on the same data. Extensive evaluations across diverse tasks demonstrate the potential of GRIN to significantly enhance MoE efficacy, achieving 79.4 on MMLU, 83.7 on HellaSwag, 74.4 on HumanEval, and 58.9 on MATH.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "58 pages"
    },
    {
        "paper id": "2409.12147",
        "abstract url": "https://arxiv.org/abs/2409.12147",
        "title": "MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models' (LLM) reasoning can be improved using test-time aggregation strategies, i.e., generating multiple samples and voting among generated samples. While these improve performance, they often reach a saturation point. Refinement offers an alternative by using LLM-generated feedback to improve solution quality. However, refinement introduces 3 key challenges: (1) Excessive refinement: Uniformly refining all instances can over-correct and reduce the overall performance. (2) Inability to localize and address errors: LLMs have a limited ability to self-correct and struggle to identify and correct their own mistakes. (3) Insufficient refinement: Deciding how many iterations of refinement are needed is non-trivial, and stopping too soon could leave errors unaddressed. To tackle these issues, we propose MAgICoRe, which avoids excessive refinement by categorizing problem difficulty as easy or hard, solving easy problems with coarse-grained aggregation and hard ones with fine-grained and iterative multi-agent refinement. To improve error localization, we incorporate external step-wise reward model (RM) scores. Moreover, to ensure effective refinement, we employ a multi-agent loop with three agents: Solver, Reviewer (which generates targeted feedback based on step-wise RM scores), and the Refiner (which incorporates feedback). To ensure sufficient refinement, we re-evaluate updated solutions, iteratively initiating further rounds of refinement. We evaluate MAgICoRe on Llama-3-8B and GPT-3.5 and show its effectiveness across 5 math datasets. Even one iteration of MAgICoRe beats Self-Consistency by 3.4%, Best-of-k by 3.2%, and Self-Refine by 4.0% while using less than half the samples. Unlike iterative refinement with baselines, MAgICoRe continues to improve with more iterations. Finally, our ablations highlight the importance of MAgICoRe's RMs and multi-agent communication.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "22 pages, code: https://github.com/dinobby/MAgICoRe"
    },
    {
        "paper id": "2409.12180",
        "abstract url": "https://arxiv.org/abs/2409.12180",
        "title": "Finetuning Language Models to Emit Linguistic Expressions of Uncertainty",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are increasingly employed in information-seeking and decision-making tasks. Despite their broad utility, LLMs tend to generate information that conflicts with real-world facts, and their persuasive style can make these inaccuracies appear confident and convincing. As a result, end-users struggle to consistently align the confidence expressed by LLMs with the accuracy of their predictions, often leading to either blind trust in all outputs or a complete disregard for their reliability. In this work, we explore supervised finetuning on uncertainty-augmented predictions as a method to develop models that produce linguistic expressions of uncertainty. Specifically, we measure the calibration of pre-trained models and then fine-tune language models to generate calibrated linguistic expressions of uncertainty. Through experiments on various question-answering datasets, we demonstrate that LLMs are well-calibrated in assessing their predictions, and supervised finetuning based on the model's own confidence leads to well-calibrated expressions of uncertainty, particularly for single-claim answers.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12181",
        "abstract url": "https://arxiv.org/abs/2409.12181",
        "title": "A Controlled Study on Long Context Extension and Generalization in LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Broad textual understanding and in-context learning require language models that utilize full document contexts. Due to the implementation challenges associated with directly training long-context models, many methods have been proposed for extending models to handle long contexts. However, owing to differences in data and model classes, it has been challenging to compare these approaches, leading to uncertainty as to how to evaluate long-context performance and whether it differs from standard evaluation. We implement a controlled protocol for extension methods with a standardized evaluation, utilizing consistent base models and extension data. Our study yields several insights into long-context behavior. First, we reaffirm the critical role of perplexity as a general-purpose performance indicator even in longer-context tasks. Second, we find that current approximate attention methods systematically underperform across long-context tasks. Finally, we confirm that exact fine-tuning based methods are generally effective within the range of their extension, whereas extrapolation remains challenging. All codebases, models, and checkpoints will be made available open-source, promoting transparency and facilitating further research in this critical area of AI development.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12183",
        "abstract url": "https://arxiv.org/abs/2409.12183",
        "title": "To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Chain-of-thought (CoT) via prompting is the de facto method for eliciting reasoning capabilities from large language models (LLMs). But for what kinds of tasks is this extra ``thinking'' really helpful? To analyze this, we conducted a quantitative meta-analysis covering over 100 papers using CoT and ran our own evaluations of 20 datasets across 14 models. Our results show that CoT gives strong performance benefits primarily on tasks involving math or logic, with much smaller gains on other types of tasks. On MMLU, directly generating the answer without CoT leads to almost identical accuracy as CoT unless the question or model's response contains an equals sign, indicating symbolic operations and reasoning. Following this finding, we analyze the behavior of CoT on these problems by separating planning and execution and comparing against tool-augmented LLMs. Much of CoT's gain comes from improving symbolic execution, but it underperforms relative to using a symbolic solver. Our results indicate that CoT can be applied selectively, maintaining performance while saving inference costs. Furthermore, they suggest a need to move beyond prompt-based CoT to new paradigms that better leverage intermediate computation across the whole range of LLM applications.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12186",
        "abstract url": "https://arxiv.org/abs/2409.12186",
        "title": "Qwen2.5-Coder Technical Report",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this report, we introduce the Qwen2.5-Coder series, a significant upgrade from its predecessor, CodeQwen1.5. This series includes two models: Qwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. As a code-specific model, Qwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained on a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning, scalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder demonstrates impressive code generation capabilities while retaining general versatility. The model has been evaluated on a wide range of code-related tasks, achieving state-of-the-art (SOTA) performance across more than 10 benchmarks, including code generation, completion, reasoning, and repair, consistently outperforming larger models of the same model size. We believe that the release of the Qwen2.5-Coder series will not only push the boundaries of research in code intelligence but also, through its permissive licensing, encourage broader adoption by developers in real-world applications.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12194",
        "abstract url": "https://arxiv.org/abs/2409.12194",
        "title": "Gender Representation and Bias in Indian Civil Service Mock Interviews",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "This paper makes three key contributions. First, via a substantial corpus of 51,278 interview questions sourced from 888 YouTube videos of mock interviews of Indian civil service candidates, we demonstrate stark gender bias in the broad nature of questions asked to male and female candidates. Second, our experiments with large language models show a strong presence of gender bias in explanations provided by the LLMs on the gender inference task. Finally, we present a novel dataset of 51,278 interview questions that can inform future social science studies.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11713",
        "abstract url": "https://arxiv.org/abs/2409.11713",
        "title": "From exponential to finite/fixed-time stability: Applications to optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The development of finite/fixed-time stable optimization algorithms typically involves study of specific problem instances. The lack of a unified framework hinders understanding of more sophisticated algorithms, e.g., primal-dual gradient flow dynamics. The purpose of this paper is to address the following question: Given an exponentially stable optimization algorithm, can it be modified to obtain a finite/fixed-time stable algorithm? We provide an affirmative answer, demonstrate how the solution can be computed on a finite-time interval via a simple scaling of the right-hand-side of the original dynamics, and certify the desired properties of the modified algorithm using the Lyapunov function that proves exponential stability of the original system. Finally, we examine nonsmooth composite optimization problems and smooth problems with linear constraints to demonstrate the merits of our approach.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "eess.SY",
            "math.DS"
        ],
        "comment": "6 pages; 1 figure"
    },
    {
        "paper id": "2409.11718",
        "abstract url": "https://arxiv.org/abs/2409.11718",
        "title": "Free-VSC: Free Semantics from Visual Foundation Models for Unsupervised Video Semantic Compression",
        "rating": "0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Unsupervised video semantic compression (UVSC), i.e., compressing videos to better support various analysis tasks, has recently garnered attention. However, the semantic richness of previous methods remains limited, due to the single semantic learning objective, limited training data, etc. To address this, we propose to boost the UVSC task by absorbing the off-the-shelf rich semantics from VFMs. Specifically, we introduce a VFMs-shared semantic alignment layer, complemented by VFM-specific prompts, to flexibly align semantics between the compressed video and various VFMs. This allows different VFMs to collaboratively build a mutually-enhanced semantic space, guiding the learning of the compression model. Moreover, we introduce a dynamic trajectory-based inter-frame compression scheme, which first estimates the semantic trajectory based on the historical content, and then traverses along the trajectory to predict the future semantics as the coding context. This reduces the overall bitcost of the system, further improving the compression efficiency. Our approach outperforms previous coding methods on three mainstream tasks and six datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV2024"
    },
    {
        "paper id": "2409.11738",
        "abstract url": "https://arxiv.org/abs/2409.11738",
        "title": "Adaptive Selection of Sampling-Reconstruction in Fourier Compressed Sensing",
        "rating": "0.5",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Compressed sensing (CS) has emerged to overcome the inefficiency of Nyquist sampling. However, traditional optimization-based reconstruction is slow and can not yield an exact image in practice. Deep learning-based reconstruction has been a promising alternative to optimization-based reconstruction, outperforming it in accuracy and computation speed. Finding an efficient sampling method with deep learning-based reconstruction, especially for Fourier CS remains a challenge. Existing joint optimization of sampling-reconstruction works (H1) optimize the sampling mask but have low potential as it is not adaptive to each data point. Adaptive sampling (H2) has also disadvantages of difficult optimization and Pareto sub-optimality. Here, we propose a novel adaptive selection of sampling-reconstruction (H1.5) framework that selects the best sampling mask and reconstruction network for each input data. We provide theorems that our method has a higher potential than H1 and effectively solves the Pareto sub-optimality problem in sampling-reconstruction by using separate reconstruction networks for different sampling masks. To select the best sampling mask, we propose to quantify the high-frequency Bayesian uncertainty of the input, using a super-resolution space generation model. Our method outperforms joint optimization of sampling-reconstruction (H1) and adaptive sampling (H2) by achieving significant improvements on several Fourier CS problems.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "30 pages, Accepted to ECCV 2024"
    },
    {
        "paper id": "2409.11741",
        "abstract url": "https://arxiv.org/abs/2409.11741",
        "title": "HARP: Human-Assisted Regrouping with Permutation Invariant Critic for Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Human-in-the-loop reinforcement learning integrates human expertise to accelerate agent learning and provide critical guidance and feedback in complex fields. However, many existing approaches focus on single-agent tasks and require continuous human involvement during the training process, significantly increasing the human workload and limiting scalability. In this paper, we propose HARP (Human-Assisted Regrouping with Permutation Invariant Critic), a multi-agent reinforcement learning framework designed for group-oriented tasks. HARP integrates automatic agent regrouping with strategic human assistance during deployment, enabling and allowing non-experts to offer effective guidance with minimal intervention. During training, agents dynamically adjust their groupings to optimize collaborative task completion. When deployed, they actively seek human assistance and utilize the Permutation Invariant Group Critic to evaluate and refine human-proposed groupings, allowing non-expert users to contribute valuable suggestions. In multiple collaboration scenarios, our approach is able to leverage limited guidance from non-experts and enhance performance. The project can be found at https://github.com/huawen-hu/HARP.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2409.11756",
        "abstract url": "https://arxiv.org/abs/2409.11756",
        "title": "Synthesizing Evolving Symbolic Representations for Autonomous Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recently, AI systems have made remarkable progress in various tasks. Deep Reinforcement Learning(DRL) is an effective tool for agents to learn policies in low-level state spaces to solve highly complex tasks. Researchers have introduced Intrinsic Motivation(IM) to the RL mechanism, which simulates the agent's curiosity, encouraging agents to explore interesting areas of the environment. This new feature has proved vital in enabling agents to learn policies without being given specific goals. However, even though DRL intelligence emerges through a sub-symbolic model, there is still a need for a sort of abstraction to understand the knowledge collected by the agent. To this end, the classical planning formalism has been used in recent research to explicitly represent the knowledge an autonomous agent acquires and effectively reach extrinsic goals. Despite classical planning usually presents limited expressive capabilities, PPDDL demonstrated usefulness in reviewing the knowledge gathered by an autonomous system, making explicit causal correlations, and can be exploited to find a plan to reach any state the agent faces during its experience. This work presents a new architecture implementing an open-ended learning system able to synthesize from scratch its experience into a PPDDL representation and update it over time. Without a predefined set of goals and tasks, the system integrates intrinsic motivations to explore the environment in a self-directed way, exploiting the high-level knowledge acquired during its experience. The system explores the environment and iteratively: (a) discover options, (b) explore the environment using options, (c) abstract the knowledge collected and (d) plan. This paper proposes an alternative approach to implementing open-ended learning architectures exploiting low-level and high-level representations to extend its knowledge in a virtuous loop.",
        "subjects": [
            "cs.AI",
            "cs.SC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11759",
        "abstract url": "https://arxiv.org/abs/2409.11759",
        "title": "My Views Do Not Reflect Those of My Employer: Differences in Behavior of Organizations' Official and Personal Social Media Accounts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "On social media, the boundaries between people's private and public lives often blur. The need to navigate both roles, which are governed by distinct norms, impacts how individuals conduct themselves online, and presents methodological challenges for researchers. We conduct a systematic exploration on how an organization's official Twitter accounts and its members' personal accounts differ. Using a climate change Twitter data set as our case, we find substantial differences in activity and connectivity across the organizational levels we examined. The levels differed considerably in their overall retweet network structures, and accounts within each level were more likely to have similar connections than accounts at different levels. We illustrate the implications of these differences for applied research by showing that the levels closer to the core of the organization display more sectoral homophily but less triadic closure, and how each level consists of very different group structures. Our results show that the common practice of solely analyzing accounts from a single organizational level, grouping together all levels, or excluding certain levels can lead to a skewed understanding of how organizations are represented on social media.",
        "subjects": [
            "cs.SI",
            "cs.HC"
        ],
        "comment": "21 pages, 10 figures"
    },
    {
        "paper id": "2409.11760",
        "abstract url": "https://arxiv.org/abs/2409.11760",
        "title": "Spin Detection Using Racket Bounce Sounds in Table Tennis",
        "rating": "0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "While table tennis players primarily rely on visual cues, sound provides valuable information. The sound generated when the ball strikes the racket can assist in predicting the ball's trajectory, especially in determining the spin. While professional players can distinguish spin through these auditory cues, they often go unnoticed by untrained players. In this paper, we demonstrate that different rackets produce distinct sounds, which can be used to identify the racket type. In addition, we show that the sound generated by the racket can indicate whether spin was applied to the ball, or not. To achieve this, we created a comprehensive dataset featuring bounce sounds from 10 racket configurations, each applying various spins to the ball. To achieve millisecond level temporal accuracy, we first detect high frequency peaks that may correspond to table tennis ball bounces. We then refine these results using a CNN based classifier that accurately predicts both the type of racket used and whether spin was applied.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.11761",
        "abstract url": "https://arxiv.org/abs/2409.11761",
        "title": "Consistent Estimation of a Class of Distances Between Covariance Matrices",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work considers the problem of estimating the distance between two covariance matrices directly from the data. Particularly, we are interested in the family of distances that can be expressed as sums of traces of functions that are separately applied to each covariance matrix. This family of distances is particularly useful as it takes into consideration the fact that covariance matrices lie in the Riemannian manifold of positive definite matrices, thereby including a variety of commonly used metrics, such as the Euclidean distance, Jeffreys' divergence, and the log-Euclidean distance. Moreover, a statistical analysis of the asymptotic behavior of this class of distance estimators has also been conducted. Specifically, we present a central limit theorem that establishes the asymptotic Gaussianity of these estimators and provides closed form expressions for the corresponding means and variances. Empirical evaluations demonstrate the superiority of our proposed consistent estimator over conventional plug-in estimators in multivariate analytical contexts. Additionally, the central limit theorem derived in this study provides a robust statistical framework to assess of accuracy of these estimators.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11772",
        "abstract url": "https://arxiv.org/abs/2409.11772",
        "title": "Symmetry-Based Structured Matrices for Efficient Approximately Equivariant Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "There has been much recent interest in designing symmetry-aware neural networks (NNs) exhibiting relaxed equivariance. Such NNs aim to interpolate between being exactly equivariant and being fully flexible, affording consistent performance benefits. In a separate line of work, certain structured parameter matrices -- those with displacement structure, characterized by low displacement rank (LDR) -- have been used to design small-footprint NNs. Displacement structure enables fast function and gradient evaluation, but permits accurate approximations via compression primarily to classical convolutional neural networks (CNNs). In this work, we propose a general framework -- based on a novel construction of symmetry-based structured matrices -- to build approximately equivariant NNs with significantly reduced parameter counts. Our framework integrates the two aforementioned lines of work via the use of so-called Group Matrices (GMs), a forgotten precursor to the modern notion of regular representations of finite groups. GMs allow the design of structured matrices -- resembling LDR matrices -- which generalize the linear operations of a classical CNN from cyclic groups to general finite groups and their homogeneous spaces. We show that GMs can be employed to extend all the elementary operations of CNNs to general discrete groups. Further, the theory of structured matrices based on GMs provides a generalization of LDR theory focussed on matrices with cyclic structure, providing a tool for implementing approximate equivariance for discrete groups. We test GM-based architectures on a variety of tasks in the presence of relaxed symmetry. We report that our framework consistently performs competitively compared to approximately equivariant NNs, and other structured matrix-based compression frameworks, sometimes with a one or two orders of magnitude lower parameter count.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2409.11805",
        "abstract url": "https://arxiv.org/abs/2409.11805",
        "title": "Inside Out or Not: Privacy Implications of Emotional Disclosure",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Privacy is dynamic, sensitive, and contextual, much like our emotions. Previous studies have explored the interplay between privacy and context, privacy and emotion, and emotion and context. However, there remains a significant gap in understanding the interplay of these aspects simultaneously. In this paper, we present a preliminary study investigating the role of emotions in driving individuals' information sharing behaviour, particularly in relation to urban locations and social ties. We adopt a novel methodology that integrates context (location and time), emotion, and personal information sharing behaviour, providing a comprehensive analysis of how contextual emotions affect privacy. The emotions are assessed with both self-reporting and electrodermal activity (EDA). Our findings reveal that self-reported emotions influence personal information-sharing behaviour with distant social groups, while neutral emotions lead individuals to share less precise information with close social circles, a pattern is potentially detectable with wrist-worn EDA. Our study helps lay the foundation for personalised emotion-aware strategies to mitigate oversharing risks and enhance user privacy in the digital age.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "see https://doi.org/10.1145/3675094.3677598"
    },
    {
        "paper id": "2409.11808",
        "abstract url": "https://arxiv.org/abs/2409.11808",
        "title": "Accelerating the Training and Improving the Reliability of Machine-Learned Interatomic Potentials for Strongly Anharmonic Materials through Active Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Molecular dynamics (MD) employing machine-learned interatomic potentials (MLIPs) serve as an efficient, urgently needed complement to ab initio molecular dynamics (aiMD). By training these potentials on data generated from ab initio methods, their averaged predictions can exhibit comparable performance to ab initio methods at a fraction of the cost. However, insufficient training sets might lead to an improper description of the dynamics in strongly anharmonic materials, because critical effects might be overlooked in relevant cases, or only incorrectly captured, or hallucinated by the MLIP when they are not actually present. In this work, we show that an active learning scheme that combines MD with MLIPs (MLIP-MD) and uncertainty estimates can avoid such problematic predictions. In short, efficient MLIP-MD is used to explore configuration space quickly, whereby an acquisition function based on uncertainty estimates and on energetic viability is employed to maximize the value of the newly generated data and to focus on the most unfamiliar but reasonably accessible regions of phase space. To verify our methodology, we screen over 112 materials and identify 10 examples experiencing the aforementioned problems. Using CuI and AgGaSe$_2$ as archetypes for these problematic materials, we discuss the physical implications for strongly anharmonic effects and demonstrate how the developed active learning scheme can address these issues.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": "15 pages, 13 figures"
    },
    {
        "paper id": "2409.11863",
        "abstract url": "https://arxiv.org/abs/2409.11863",
        "title": "Learning Task Planning from Multi-Modal Demonstration for Multi-Stage Contact-Rich Manipulation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have gained popularity in task planning for long-horizon manipulation tasks. To enhance the validity of LLM-generated plans, visual demonstrations and online videos have been widely employed to guide the planning process. However, for manipulation tasks involving subtle movements but rich contact interactions, visual perception alone may be insufficient for the LLM to fully interpret the demonstration. Additionally, visual data provides limited information on force-related parameters and conditions, which are crucial for effective execution on real robots. In this paper, we introduce an in-context learning framework that incorporates tactile and force-torque information from human demonstrations to enhance LLMs' ability to generate plans for new task scenarios. We propose a bootstrapped reasoning pipeline that sequentially integrates each modality into a comprehensive task plan. This task plan is then used as a reference for planning in new task configurations. Real-world experiments on two different sequential manipulation tasks demonstrate the effectiveness of our framework in improving LLMs' understanding of multi-modal demonstrations and enhancing the overall planning performance.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11884",
        "abstract url": "https://arxiv.org/abs/2409.11884",
        "title": "Recent Advances in OOD Detection: Problems and Approaches",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Out-of-distribution (OOD) detection aims to detect test samples outside the training category space, which is an essential component in building reliable machine learning systems. Existing reviews on OOD detection primarily focus on method taxonomy, surveying the field by categorizing various approaches. However, many recent works concentrate on non-traditional OOD detection scenarios, such as test-time adaptation, multi-modal data sources and other novel contexts. In this survey, we uniquely review recent advances in OOD detection from the problem scenario perspective for the first time. According to whether the training process is completely controlled, we divide OOD detection methods into training-driven and training-agnostic. Besides, considering the rapid development of pre-trained models, large pre-trained model-based OOD detection is also regarded as an important category and discussed separately. Furthermore, we provide a discussion of the evaluation scenarios, a variety of applications, and several future research directions. We believe this survey with new taxonomy will benefit the proposal of new methods and the expansion of more practical scenarios. A curated list of related papers is provided in the Github repository: \\url{https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection}",
        "subjects": [
            "cs.LG"
        ],
        "comment": "September 18, 2024"
    },
    {
        "paper id": "2409.11902",
        "abstract url": "https://arxiv.org/abs/2409.11902",
        "title": "Less Memory Means smaller GPUs: Backpropagation with Compressed Activations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The ever-growing scale of deep neural networks (DNNs) has lead to an equally rapid growth in computational resource requirements. Many recent architectures, most prominently Large Language Models, have to be trained using supercomputers with thousands of accelerators, such as GPUs or TPUs. Next to the vast number of floating point operations the memory footprint of DNNs is also exploding. In contrast, GPU architectures are notoriously short on memory. Even comparatively small architectures like some EfficientNet variants cannot be trained on a single consumer-grade GPU at reasonable mini-batch sizes. During training, intermediate input activations have to be stored until backpropagation for gradient calculation. These make up the vast majority of the memory footprint. In this work we therefore consider compressing activation maps for the backward pass using pooling, which can reduce both the memory footprint and amount of data movement. The forward computation remains uncompressed. We empirically show convergence and study effects on feature detection at the example of the common vision architecture ResNet. With this approach we are able to reduce the peak memory consumption by 29% at the cost of a longer training schedule, while maintaining prediction accuracy compared to an uncompressed baseline.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Presented at ITEM workshop co-located with ECML PKDD 2024, Vilnius LT"
    },
    {
        "paper id": "2409.11995",
        "abstract url": "https://arxiv.org/abs/2409.11995",
        "title": "Unraveling the Hessian: A Key to Smooth Convergence in Loss Function Landscapes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The loss landscape of neural networks is a critical aspect of their training, and understanding its properties is essential for improving their performance. In this paper, we investigate how the loss surface changes when the sample size increases, a previously unexplored issue. We theoretically analyze the convergence of the loss landscape in a fully connected neural network and derive upper bounds for the difference in loss function values when adding a new object to the sample. Our empirical study confirms these results on various datasets, demonstrating the convergence of the loss function surface for image classification tasks. Our findings provide insights into the local geometry of neural loss landscapes and have implications for the development of sample size determination techniques.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12000",
        "abstract url": "https://arxiv.org/abs/2409.12000",
        "title": "\"It Might be Technically Impressive, But It's Practically Useless to Us\": Practices, Challenges, and Opportunities for Cross-Functional Collaboration around AI within the News Industry",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Recently, an increasing number of news organizations have integrated artificial intelligence (AI) into their workflows, leading to a further influx of AI technologists and data workers into the news industry. This has initiated cross-functional collaborations between these professionals and journalists. While prior research has explored the impact of AI-related roles entering the news industry, there is a lack of studies on how cross-functional collaboration unfolds between AI professionals and journalists. Through interviews with 17 journalists, 6 AI technologists, and 3 AI workers with cross-functional experience from leading news organizations, we investigate the current practices, challenges, and opportunities for cross-functional collaboration around AI in today's news industry. We first study how journalists and AI professionals perceive existing cross-collaboration strategies. We further explore the challenges of cross-functional collaboration and provide recommendations for enhancing future cross-functional collaboration around AI in the news industry.",
        "subjects": [
            "cs.HC",
            "cs.CY",
            "cs.LG",
            "cs.SI"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2409.12001",
        "abstract url": "https://arxiv.org/abs/2409.12001",
        "title": "Putting Data at the Centre of Offline Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Offline multi-agent reinforcement learning (MARL) is an exciting direction of research that uses static datasets to find optimal control policies for multi-agent systems. Though the field is by definition data-driven, efforts have thus far neglected data in their drive to achieve state-of-the-art results. We first substantiate this claim by surveying the literature, showing how the majority of works generate their own datasets without consistent methodology and provide sparse information about the characteristics of these datasets. We then show why neglecting the nature of the data is problematic, through salient examples of how tightly algorithmic performance is coupled to the dataset used, necessitating a common foundation for experiments in the field. In response, we take a big step towards improving data usage and data awareness in offline MARL, with three key contributions: (1) a clear guideline for generating novel datasets; (2) a standardisation of over 80 existing datasets, hosted in a publicly available repository, using a consistent storage format and easy-to-use API; and (3) a suite of analysis tools that allow us to understand these datasets better, aiding further development.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12038",
        "abstract url": "https://arxiv.org/abs/2409.12038",
        "title": "A Unified Framework for Neural Computation and Learning Over Time",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes Hamiltonian Learning, a novel unified framework for learning with neural networks \"over time\", i.e., from a possibly infinite stream of data, in an online manner, without having access to future information. Existing works focus on the simplified setting in which the stream has a known finite length or is segmented into smaller sequences, leveraging well-established learning strategies from statistical machine learning. In this paper, the problem of learning over time is rethought from scratch, leveraging tools from optimal control theory, which yield a unifying view of the temporal dynamics of neural computations and learning. Hamiltonian Learning is based on differential equations that: (i) can be integrated without the need of external software solvers; (ii) generalize the well-established notion of gradient-based learning in feed-forward and recurrent networks; (iii) open to novel perspectives. The proposed framework is showcased by experimentally proving how it can recover gradient-based learning, comparing it to out-of-the box optimizers, and describing how it is flexible enough to switch from fully-local to partially/non-local computational schemes, possibly distributed over multiple devices, and BackPropagation without storing activations. Hamiltonian Learning is easy to implement and can help researches approach in a principled and innovative manner the problem of learning over time.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12043",
        "abstract url": "https://arxiv.org/abs/2409.12043",
        "title": "Understanding the Effects of the Baidu-ULTR Logging Policy on Two-Tower Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite the popularity of the two-tower model for unbiased learning to rank (ULTR) tasks, recent work suggests that it suffers from a major limitation that could lead to its collapse in industry applications: the problem of logging policy confounding. Several potential solutions have even been proposed; however, the evaluation of these methods was mostly conducted using semi-synthetic simulation experiments. This paper bridges the gap between theory and practice by investigating the confounding problem on the largest real-world dataset, Baidu-ULTR. Our main contributions are threefold: 1) we show that the conditions for the confounding problem are given on Baidu-ULTR, 2) the confounding problem bears no significant effect on the two-tower model, and 3) we point to a potential mismatch between expert annotations, the golden standard in ULTR, and user click behavior.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": "Accepted at the CONSEQUENCES '24 workshop, co-located with ACM RecSys '24"
    },
    {
        "paper id": "2409.12053",
        "abstract url": "https://arxiv.org/abs/2409.12053",
        "title": "Extended Deep Submodular Functions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a novel category of set functions called Extended Deep Submodular functions (EDSFs), which are neural network-representable. EDSFs serve as an extension of Deep Submodular Functions (DSFs), inheriting crucial properties from DSFs while addressing innate limitations. It is known that DSFs can represent a limiting subset of submodular functions. In contrast, through an analysis of polymatroid properties, we establish that EDSFs possess the capability to represent all monotone submodular functions, a notable enhancement compared to DSFs. Furthermore, our findings demonstrate that EDSFs can represent any monotone set function, indicating the family of EDSFs is equivalent to the family of all monotone set functions. Additionally, we prove that EDSFs maintain the concavity inherent in DSFs when the components of the input vector are non-negative real numbers-an essential feature in certain combinatorial optimization problems. Through extensive experiments, we illustrate that EDSFs exhibit significantly lower empirical generalization error than DSFs in the learning of coverage functions. This suggests that EDSFs present a promising advancement in the representation and learning of set functions with improved generalization capabilities.",
        "subjects": [
            "cs.LG",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12057",
        "abstract url": "https://arxiv.org/abs/2409.12057",
        "title": "Cartan moving frames and the data manifolds",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The purpose of this paper is to employ the language of Cartan moving frames to study the geometry of the data manifolds and its Riemannian structure, via the data information metric and its curvature at data points. Using this framework and through experiments, explanations on the response of a neural network are given by pointing out the output classes that are easily reachable from a given input. This emphasizes how the proposed mathematical relationship between the output of the network and the geometry of its inputs can be exploited as an explainable artificial intelligence tool.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.DG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12067",
        "abstract url": "https://arxiv.org/abs/2409.12067",
        "title": "Fitting Multilevel Factor Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We examine a special case of the multilevel factor model, with covariance given by multilevel low rank (MLR) matrix~\\cite{parshakova2023factor}. We develop a novel, fast implementation of the expectation-maximization (EM) algorithm, tailored for multilevel factor models, to maximize the likelihood of the observed data. This method accommodates any hierarchical structure and maintains linear time and storage complexities per iteration. This is achieved through a new efficient technique for computing the inverse of the positive definite MLR matrix. We show that the inverse of an invertible PSD MLR matrix is also an MLR matrix with the same sparsity in factors, and we use the recursive Sherman-Morrison-Woodbury matrix identity to obtain the factors of the inverse. Additionally, we present an algorithm that computes the Cholesky factorization of an expanded matrix with linear time and space complexities, yielding the covariance matrix as its Schur complement. This paper is accompanied by an open-source package that implements the proposed methods.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.MS",
            "stat.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12071",
        "abstract url": "https://arxiv.org/abs/2409.12071",
        "title": "Quantifying the role of supernatural entities and the effect of missing data in Irish sagas",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "For over a decade, complex networks have been applied to mythological texts in order to quantitatively compare them. This has allowed us to identify similarities between texts in different cultures, as well as to quantify the significance of some heroic characters. Analysing a full mythology of a culture requires gathering data from many individual myths which is time consuming and often impractical. In this work, we attempt to bypass this by analysing the network of characters in a dictionary of mythological characters. We show that the top characters identified by different centrality measures are consistent with central figures in the Irish sagas. Although much of Irish mythology has been lost, we demonstrate that these most central characters are highly robust to a large random removal of edges.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": "10 pages, 3 figures, 1 table"
    },
    {
        "paper id": "2409.12089",
        "abstract url": "https://arxiv.org/abs/2409.12089",
        "title": "The Impact of Element Ordering on LM Agent Performance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "There has been a surge of interest in language model agents that can navigate virtual environments such as the web or desktop. To navigate such environments, agents benefit from information on the various elements (e.g., buttons, text, or images) present. It remains unclear which element attributes have the greatest impact on agent performance, especially in environments that only provide a graphical representation (i.e., pixels). Here we find that the ordering in which elements are presented to the language model is surprisingly impactful--randomizing element ordering in a webpage degrades agent performance comparably to removing all visible text from an agent's state representation. While a webpage provides a hierarchical ordering of elements, there is no such ordering when parsing elements directly from pixels. Moreover, as tasks become more challenging and models more sophisticated, our experiments suggest that the impact of ordering increases. Finding an effective ordering is non-trivial. We investigate the impact of various element ordering methods in web and desktop environments. We find that dimensionality reduction provides a viable ordering for pixel-only environments. We train a UI element detection model to derive elements from pixels and apply our findings to an agent benchmark--OmniACT--where we only have access to pixels. Our method completes more than two times as many tasks on average relative to the previous state-of-the-art.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12100",
        "abstract url": "https://arxiv.org/abs/2409.12100",
        "title": "Symmetry-Enriched Learning: A Category-Theoretic Framework for Robust Machine Learning Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This manuscript presents a novel framework that integrates higher-order symmetries and category theory into machine learning. We introduce new mathematical constructs, including hyper-symmetry categories and functorial representations, to model complex transformations within learning algorithms. Our contributions include the design of symmetry-enriched learning models, the development of advanced optimization techniques leveraging categorical symmetries, and the theoretical analysis of their implications for model robustness, generalization, and convergence. Through rigorous proofs and practical applications, we demonstrate that incorporating higher-dimensional categorical structures enhances both the theoretical foundations and practical capabilities of modern machine learning algorithms, opening new directions for research and innovation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12135",
        "abstract url": "https://arxiv.org/abs/2409.12135",
        "title": "Almost Sure Convergence of Linear Temporal Difference Learning with Arbitrary Features",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Temporal difference (TD) learning with linear function approximation, abbreviated as linear TD, is a classic and powerful prediction algorithm in reinforcement learning. While it is well understood that linear TD converges almost surely to a unique point, this convergence traditionally requires the assumption that the features used by the approximator are linearly independent. However, this linear independence assumption does not hold in many practical scenarios. This work is the first to establish the almost sure convergence of linear TD without requiring linearly independent features. In fact, we do not make any assumptions on the features. We prove that the approximated value function converges to a unique point and the weight iterates converge to a set. We also establish a notion of local stability of the weight iterates. Importantly, we do not need to introduce any other additional assumptions and do not need to make any modification to the linear TD algorithm. Key to our analysis is a novel characterization of bounded invariant sets of the mean ODE of linear TD.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "30 pages, 0 figures"
    },
    {
        "paper id": "2409.12138",
        "abstract url": "https://arxiv.org/abs/2409.12138",
        "title": "Reporting Non-Consensual Intimate Media: An Audit Study of Deepfakes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Non-consensual intimate media (NCIM) inflicts significant harm. Currently, victim-survivors can use two mechanisms to report NCIM - as a non-consensual nudity violation or as copyright infringement. We conducted an audit study of takedown speed of NCIM reported to X (formerly Twitter) of both mechanisms. We uploaded 50 AI-generated nude images and reported half under X's \"non-consensual nudity\" reporting mechanism and half under its \"copyright infringement\" mechanism. The copyright condition resulted in successful image removal within 25 hours for all images (100% removal rate), while non-consensual nudity reports resulted in no image removal for over three weeks (0% removal rate). We stress the need for targeted legislation to regulate NCIM removal online. We also discuss ethical considerations for auditing NCIM on social platforms.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "under review"
    },
    {
        "paper id": "2409.12154",
        "abstract url": "https://arxiv.org/abs/2409.12154",
        "title": "Abductive explanations of classifiers under constraints: Complexity and properties",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Abductive explanations (AXp's) are widely used for understanding decisions of classifiers. Existing definitions are suitable when features are independent. However, we show that ignoring constraints when they exist between features may lead to an explosion in the number of redundant or superfluous AXp's. We propose three new types of explanations that take into account constraints and that can be generated from the whole feature space or from a sample (such as a dataset). They are based on a key notion of coverage of an explanation, the set of instances it explains. We show that coverage is powerful enough to discard redundant and superfluous AXp's. For each type, we analyse the complexity of finding an explanation and investigate its formal properties. The final result is a catalogue of different forms of AXp's with different complexities and different formal guarantees.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Full version with proofs of Martin C. Cooper and Leila Amgoud, Abductive explanations of classifiers under constraints: Complexity and properties, ECAI 2023, 469-476"
    },
    {
        "paper id": "2409.12179",
        "abstract url": "https://arxiv.org/abs/2409.12179",
        "title": "Computational Dynamical Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We study the computational complexity theory of smooth, finite-dimensional dynamical systems. Building off of previous work, we give definitions for what it means for a smooth dynamical system to simulate a Turing machine. We then show that 'chaotic' dynamical systems (more precisely, Axiom A systems) and 'integrable' dynamical systems (more generally, measure-preserving systems) cannot robustly simulate universal Turing machines, although such machines can be robustly simulated by other kinds of dynamical systems. Subsequently, we show that any Turing machine that can be encoded into a structurally stable one-dimensional dynamical system must have a decidable halting problem, and moreover an explicit time complexity bound in instances where it does halt. More broadly, our work elucidates what it means for one 'machine' to simulate another, and emphasizes the necessity of defining low-complexity 'encoders' and 'decoders' to translate between the dynamics of the simulation and the system being simulated. We highlight how the notion of a computational dynamical system leads to questions at the intersection of computational complexity theory, dynamical systems theory, and real algebraic geometry.",
        "subjects": [
            "cs.CC",
            "cs.AI",
            "cs.FL",
            "math.DS"
        ],
        "comment": "46+14 pages, 6 figures; accepted to FOCS 2024"
    },
    {
        "paper id": "2409.11711",
        "abstract url": "https://arxiv.org/abs/2409.11711",
        "title": "LFIC-DRASC: Deep Light Field Image Compression Using Disentangled Representation and Asymmetrical Strip Convolution",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Light-Field (LF) image is emerging 4D data of light rays that is capable of realistically presenting spatial and angular information of 3D scene. However, the large data volume of LF images becomes the most challenging issue in real-time processing, transmission, and storage. In this paper, we propose an end-to-end deep LF Image Compression method Using Disentangled Representation and Asymmetrical Strip Convolution (LFIC-DRASC) to improve coding efficiency. Firstly, we formulate the LF image compression problem as learning a disentangled LF representation network and an image encoding-decoding network. Secondly, we propose two novel feature extractors that leverage the structural prior of LF data by integrating features across different dimensions. Meanwhile, disentangled LF representation network is proposed to enhance the LF feature disentangling and decoupling. Thirdly, we propose the LFIC-DRASC for LF image compression, where two Asymmetrical Strip Convolution (ASC) operators, i.e. horizontal and vertical, are proposed to capture long-range correlation in LF feature space. These two ASC operators can be combined with the square convolution to further decouple LF features, which enhances the model ability in representing intricate spatial relationships. Experimental results demonstrate that the proposed LFIC-DRASC achieves an average of 20.5\\% bit rate reductions comparing with the state-of-the-art methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11725",
        "abstract url": "https://arxiv.org/abs/2409.11725",
        "title": "Dense-TSNet: Dense Connected Two-Stage Structure for Ultra-Lightweight Speech Enhancement",
        "rating": "0",
        "keywords": [
            [
                "Speech Enhancement"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech enhancement aims to improve speech quality and intelligibility in noisy environments. Recent advancements have concentrated on deep neural networks, particularly employing the Two-Stage (TS) architecture to enhance feature extraction. However, the complexity and size of these models remain significant, which limits their applicability in resource-constrained scenarios. Designing models suitable for edge devices presents its own set of challenges. Narrow lightweight models often encounter performance bottlenecks due to uneven loss landscapes. Additionally, advanced operators such as Transformers or Mamba may lack the practical adaptability and efficiency that convolutional neural networks (CNNs) offer in real-world deployments. To address these challenges, we propose Dense-TSNet, an innovative ultra-lightweight speech enhancement network. Our approach employs a novel Dense Two-Stage (Dense-TS) architecture, which, compared to the classic Two-Stage architecture, ensures more robust refinement of the objective function in the later training stages. This leads to improved final performance, addressing the early convergence limitations of the baseline model. We also introduce the Multi-View Gaze Block (MVGB), which enhances feature extraction by incorporating global, channel, and local perspectives through convolutional neural networks (CNNs). Furthermore, we discuss how the choice of loss function impacts perceptual quality. Dense-TSNet demonstrates promising performance with a compact model size of around 14K parameters, making it particularly well-suited for deployment in resource-constrained environments.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11734",
        "abstract url": "https://arxiv.org/abs/2409.11734",
        "title": "InverseMeetInsert: Robust Real Image Editing via Geometric Accumulation Inversion in Guided Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Image Editing"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce Geometry-Inverse-Meet-Pixel-Insert, short for GEO, an exceptionally versatile image editing technique designed to cater to customized user requirements at both local and global scales. Our approach seamlessly integrates text prompts and image prompts to yield diverse and precise editing outcomes. Notably, our method operates without the need for training and is driven by two key contributions: (i) a novel geometric accumulation loss that enhances DDIM inversion to faithfully preserve pixel space geometry and layout, and (ii) an innovative boosted image prompt technique that combines pixel-level editing for text-only inversion with latent space geometry guidance for standard classifier-free reversion. Leveraging the publicly available Stable Diffusion model, our approach undergoes extensive evaluation across various image types and challenging prompt editing scenarios, consistently delivering high-fidelity editing results for real images.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.11749",
        "abstract url": "https://arxiv.org/abs/2409.11749",
        "title": "RockTrack: A 3D Robust Multi-Camera-Ken Multi-Object Tracking Framework",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Multi-Object Tracking (MOT) obtains significant performance improvements with the rapid advancements in 3D object detection, particularly in cost-effective multi-camera setups. However, the prevalent end-to-end training approach for multi-camera trackers results in detector-specific models, limiting their versatility. Moreover, current generic trackers overlook the unique features of multi-camera detectors, i.e., the unreliability of motion observations and the feasibility of visual information. To address these challenges, we propose RockTrack, a 3D MOT method for multi-camera detectors. Following the Tracking-By-Detection framework, RockTrack is compatible with various off-the-shelf detectors. RockTrack incorporates a confidence-guided preprocessing module to extract reliable motion and image observations from distinct representation spaces from a single detector. These observations are then fused in an association module that leverages geometric and appearance cues to minimize mismatches. The resulting matches are propagated through a staged estimation process, forming the basis for heuristic noise modeling. Additionally, we introduce a novel appearance similarity metric for explicitly characterizing object affinities in multi-camera settings. RockTrack achieves state-of-the-art performance on the nuScenes vision-only tracking leaderboard with 59.1% AMOTA while demonstrating impressive computational efficiency.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "RockTrack establishes a new state-of-the-art with 59.1% AMOTA on the nuScenes vision-only test leaderboard with ResNet50-level backbone"
    },
    {
        "paper id": "2409.11804",
        "abstract url": "https://arxiv.org/abs/2409.11804",
        "title": "Conformal Prediction for Manifold-based Source Localization with Gaussian Processes",
        "rating": "0",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We tackle the challenge of uncertainty quantification in the localization of a sound source within adverse acoustic environments. Estimating the position of the source is influenced by various factors such as noise and reverberation, leading to significant uncertainty. Quantifying this uncertainty is essential, particularly when localization outcomes impact critical decision-making processes, such as in robot audition, where the accuracy of location estimates directly influences subsequent actions. Despite this, many localization methods typically offer point estimates without quantifying the estimation uncertainty. To address this, we employ conformal prediction (CP)-a framework that delivers statistically valid prediction intervals with finite-sample guarantees, independent of the data distribution. However, commonly used Inductive CP (ICP) methods require a substantial amount of labeled data, which can be difficult to obtain in the localization setting. To mitigate this limitation, we incorporate a manifold-based localization method using Gaussian process regression (GPR), with an efficient Transductive CP (TCP) technique specifically designed for GPR. We demonstrate that our method generates statistically valid uncertainty intervals across different acoustic conditions.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11813",
        "abstract url": "https://arxiv.org/abs/2409.11813",
        "title": "EventAug: Multifaceted Spatio-Temporal Data Augmentation Methods for Event-based Learning",
        "rating": "0",
        "keywords": [
            [
                "event camera"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The event camera has demonstrated significant success across a wide range of areas due to its low time latency and high dynamic range. However, the community faces challenges such as data deficiency and limited diversity, often resulting in over-fitting and inadequate feature learning. Notably, the exploration of data augmentation techniques in the event community remains scarce. This work aims to address this gap by introducing a systematic augmentation scheme named EventAug to enrich spatial-temporal diversity. In particular, we first propose Multi-scale Temporal Integration (MSTI) to diversify the motion speed of objects, then introduce Spatial-salient Event Mask (SSEM) and Temporal-salient Event Mask (TSEM) to enrich object variants. Our EventAug can facilitate models learning with richer motion patterns, object variants and local spatio-temporal relations, thus improving model robustness to varied moving speeds, occlusions, and action disruptions. Experiment results show that our augmentation method consistently yields significant improvements across different tasks and backbones (e.g., a 4.87% accuracy gain on DVS128 Gesture). Our code will be publicly available for this community.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11817",
        "abstract url": "https://arxiv.org/abs/2409.11817",
        "title": "EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis",
        "rating": "0",
        "keywords": [
            [
                "Efficient Fine-tuning"
            ],
            [
                "medical",
                "diagnosis",
                "X-ray",
                "pathological",
                "retina"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The recent development of deep learning large models in medicine shows remarkable performance in medical image analysis and diagnosis, but their large number of parameters causes memory and inference latency challenges. Knowledge distillation offers a solution, but the slide-level gradients cannot be backpropagated for student model updates due to high-resolution pathological images and slide-level labels. This study presents an Efficient Fine-tuning on Compressed Models (EFCM) framework with two stages: unsupervised feature distillation and fine-tuning. In the distillation stage, Feature Projection Distillation (FPD) is proposed with a TransScan module for adaptive receptive field adjustment to enhance the knowledge absorption capability of the student model. In the slide-level fine-tuning stage, three strategies (Reuse CLAM, Retrain CLAM, and End2end Train CLAM (ETC)) are compared. Experiments are conducted on 11 downstream datasets related to three large medical models: RETFound for retina, MRM for chest X-ray, and BROW for histopathology. The experimental results demonstrate that the EFCM framework significantly improves accuracy and efficiency in handling slide-level pathological image problems, effectively addressing the challenges of deploying large medical models. Specifically, it achieves a 4.33% increase in ACC and a 5.2% increase in AUC compared to the large model BROW on the TCGA-NSCLC and TCGA-BRCA datasets. The analysis of model inference efficiency highlights the high efficiency of the distillation fine-tuning method.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11819",
        "abstract url": "https://arxiv.org/abs/2409.11819",
        "title": "End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation",
        "rating": "0",
        "keywords": [
            [
                "6DoF",
                "6D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "6D object pose estimation is the problem of identifying the position and orientation of an object relative to a chosen coordinate system, which is a core technology for modern XR applications. State-of-the-art 6D object pose estimators directly predict an object pose given an object observation. Due to the ill-posed nature of the pose estimation problem, where multiple different poses can correspond to a single observation, generating additional plausible estimates per observation can be valuable. To address this, we reformulate the state-of-the-art algorithm GDRNPP and introduce EPRO-GDR (End-to-End Probabilistic Geometry-Guided Regression). Instead of predicting a single pose per detection, we estimate a probability density distribution of the pose. Using the evaluation procedure defined by the BOP (Benchmark for 6D Object Pose Estimation) Challenge, we test our approach on four of its core datasets and demonstrate superior quantitative results for EPRO-GDR on LM-O, YCB-V, and ITODD. Our probabilistic solution shows that predicting a pose distribution instead of a single pose can improve state-of-the-art single-view pose estimation while providing the additional benefit of being able to sample multiple meaningful pose candidates.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11844",
        "abstract url": "https://arxiv.org/abs/2409.11844",
        "title": "MEOW: MEMOry Supervised LLM Unlearning Via Inverted Facts",
        "rating": "0",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) can memorize sensitive information, raising concerns about potential misuse. LLM Unlearning, a post-hoc approach to remove this information from trained LLMs, offers a promising solution to mitigate these risks. However, previous practices face three key challenges: 1. Utility: successful unlearning often causes catastrophic collapse on unrelated tasks. 2. Efficiency: many methods either involve adding similarly sized models, which slows down unlearning or inference, or require retain data that are difficult to obtain. 3. Robustness: even effective methods may still leak data via extraction techniques. To address these challenges, we propose MEOW, a simple yet effective gradient descent-based unlearning method. Specifically, we use an offline LLM to generate a set of inverted facts. Then, we design a new metric, MEMO, to quantify memorization in LLMs. Finally, based on the signals provided by MEMO, we select the most appropriate set of inverted facts and finetune the model based on them. We evaluate MEOW on the commonly used unlearn benchmark, ToFU, with Llama2-7B-Chat and Phi-1.5B, and test it on both NLU and NLG tasks. Results demonstrate significant improvement of MEOW in forget quality without substantial loss in model utility. Meanwhile, MEOW does not exhibit significant degradation in NLU or NLG capabilities, and there is even a slight improvement in NLU performance.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11874",
        "abstract url": "https://arxiv.org/abs/2409.11874",
        "title": "ABHINAW: A method for Automatic Evaluation of Typography within AI-Generated Images",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In the fast-evolving field of Generative AI, platforms like MidJourney, DALL-E, and Stable Diffusion have transformed Text-to-Image (T2I) Generation. However, despite their impressive ability to create high-quality images, they often struggle to generate accurate text within these images. Theoretically, if we could achieve accurate text generation in AI images in a ``zero-shot'' manner, it would not only make AI-generated images more meaningful but also democratize the graphic design industry. The first step towards this goal is to create a robust scoring matrix for evaluating text accuracy in AI-generated images. Although there are existing bench-marking methods like CLIP SCORE and T2I-CompBench++, there's still a gap in systematically evaluating text and typography in AI-generated images, especially with diffusion-based methods. In this paper, we introduce a novel evaluation matrix designed explicitly for quantifying the performance of text and typography generation within AI-generated images. We have used letter by letter matching strategy to compute the exact matching scores from the reference text to the AI generated text. Our novel approach to calculate the score takes care of multiple redundancies such as repetition of words, case sensitivity, mixing of words, irregular incorporation of letters etc. Moreover, we have developed a Novel method named as brevity adjustment to handle excess text. In addition we have also done a quantitative analysis of frequent errors arise due to frequently used words and less frequently used words. Project page is available at: https://github.com/Abhinaw3906/ABHINAW-MATRIX.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11904",
        "abstract url": "https://arxiv.org/abs/2409.11904",
        "title": "Finding the Subjective Truth: Collecting 2 Million Votes for Comprehensive Gen-AI Model Evaluation",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Efficiently evaluating the performance of text-to-image models is difficult as it inherently requires subjective judgment and human preference, making it hard to compare different models and quantify the state of the art. Leveraging Rapidata's technology, we present an efficient annotation framework that sources human feedback from a diverse, global pool of annotators. Our study collected over 2 million annotations across 4,512 images, evaluating four prominent models (DALL-E 3, Flux.1, MidJourney, and Stable Diffusion) on style preference, coherence, and text-to-image alignment. We demonstrate that our approach makes it feasible to comprehensively rank image generation models based on a vast pool of annotators and show that the diverse annotator demographics reflect the world population, significantly decreasing the risk of biases.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11937",
        "abstract url": "https://arxiv.org/abs/2409.11937",
        "title": "Differentiable Collision-Supervised Tooth Arrangement Network with a Decoupling Perspective",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Tooth arrangement is an essential step in the digital orthodontic planning process. Existing learning-based methods use hidden teeth features to directly regress teeth motions, which couples target pose perception and motion regression. It could lead to poor perceptions of three-dimensional transformation. They also ignore the possible overlaps or gaps between teeth of predicted dentition, which is generally unacceptable. Therefore, we propose DTAN, a differentiable collision-supervised tooth arrangement network, decoupling predicting tasks and feature modeling. DTAN decouples the tooth arrangement task by first predicting the hidden features of the final teeth poses and then using them to assist in regressing the motions between the beginning and target teeth. To learn the hidden features better, DTAN also decouples the teeth-hidden features into geometric and positional features, which are further supervised by feature consistency constraints. Furthermore, we propose a novel differentiable collision loss function for point cloud data to constrain the related gestures between teeth, which can be easily extended to other 3D point cloud tasks. We propose an arch-width guided tooth arrangement network, named C-DTAN, to make the results controllable. We construct three different tooth arrangement datasets and achieve drastically improved performance on accuracy and speed compared with existing methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 13 figures"
    },
    {
        "paper id": "2409.11974",
        "abstract url": "https://arxiv.org/abs/2409.11974",
        "title": "MitoSeg: Mitochondria Segmentation Tool",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent studies suggest a potential link between the physical structure of mitochondria and neurodegenerative diseases. With advances in Electron Microscopy techniques, it has become possible to visualize the boundary and internal membrane structures of mitochondria in detail. It is crucial to automatically segment mitochondria from these images to investigate the relationship between mitochondria and diseases. In this paper, we present a software solution for mitochondrial segmentation, highlighting mitochondria boundaries in electron microscopy tomography images and generating corresponding 3D meshes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12024",
        "abstract url": "https://arxiv.org/abs/2409.12024",
        "title": "LEMON: Localized Editing with Mesh Optimization and Neural Shaders",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In practical use cases, polygonal mesh editing can be faster than generating new ones, but it can still be challenging and time-consuming for users. Existing solutions for this problem tend to focus on a single task, either geometry or novel view synthesis, which often leads to disjointed results between the mesh and view. In this work, we propose LEMON, a mesh editing pipeline that combines neural deferred shading with localized mesh optimization. Our approach begins by identifying the most important vertices in the mesh for editing, utilizing a segmentation model to focus on these key regions. Given multi-view images of an object, we optimize a neural shader and a polygonal mesh while extracting the normal map and the rendered image from each view. By using these outputs as conditioning data, we edit the input images with a text-to-image diffusion model and iteratively update our dataset while deforming the mesh. This process results in a polygonal mesh that is edited according to the given text instruction, preserving the geometric characteristics of the initial mesh while focusing on the most significant areas. We evaluate our pipeline using the DTU dataset, demonstrating that it generates finely-edited meshes more rapidly than the current state-of-the-art methods. We include our code and additional results in the supplementary material.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12072",
        "abstract url": "https://arxiv.org/abs/2409.12072",
        "title": "PAD-FT: A Lightweight Defense for Backdoor Attacks via Data Purification and Fine-Tuning",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Backdoor attacks pose a significant threat to deep neural networks, particularly as recent advancements have led to increasingly subtle implantation, making the defense more challenging. Existing defense mechanisms typically rely on an additional clean dataset as a standard reference and involve retraining an auxiliary model or fine-tuning the entire victim model. However, these approaches are often computationally expensive and not always feasible in practical applications. In this paper, we propose a novel and lightweight defense mechanism, termed PAD-FT, that does not require an additional clean dataset and fine-tunes only a very small part of the model to disinfect the victim model. To achieve this, our approach first introduces a simple data purification process to identify and select the most-likely clean data from the poisoned training dataset. The self-purified clean dataset is then used for activation clipping and fine-tuning only the last classification layer of the victim model. By integrating data purification, activation clipping, and classifier fine-tuning, our mechanism PAD-FT demonstrates superior effectiveness across multiple backdoor attack methods and datasets, as confirmed through extensive experimental evaluation.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12074",
        "abstract url": "https://arxiv.org/abs/2409.12074",
        "title": "Online Refractive Camera Model Calibration in Visual Inertial Odometry",
        "rating": "0",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a general refractive camera model and online co-estimation of odometry and the refractive index of unknown media. This enables operation in diverse and varying refractive fluids, given only the camera calibration in air. The refractive index is estimated online as a state variable of a monocular visual-inertial odometry framework in an iterative formulation using the proposed camera model. The method was verified on data collected using an underwater robot traversing inside a pool. The evaluations demonstrate convergence to the ideal refractive index for water despite significant perturbations in the initialization. Simultaneously, the approach enables on-par visual-inertial odometry performance in refractive media without prior knowledge of the refractive index or requirement of medium-specific camera calibration.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Accepted at the 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024), 8 pages"
    },
    {
        "paper id": "2409.12140",
        "abstract url": "https://arxiv.org/abs/2409.12140",
        "title": "MoRAG -- Multi-Fusion Retrieval Augmented Generation for Human Motion",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce MoRAG, a novel multi-part fusion based retrieval-augmented generation strategy for text-based human motion generation. The method enhances motion diffusion models by leveraging additional knowledge obtained through an improved motion retrieval process. By effectively prompting large language models (LLMs), we address spelling errors and rephrasing issues in motion retrieval. Our approach utilizes a multi-part retrieval strategy to improve the generalizability of motion retrieval across the language space. We create diverse samples through the spatial composition of the retrieved motions. Furthermore, by utilizing low-level, part-specific motion information, we can construct motion samples for unseen text descriptions. Our experiments demonstrate that our framework can serve as a plug-and-play module, improving the performance of motion diffusion models. Code, pretrained models and sample videos will be made available at: https://motion-rag.github.io/",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11742",
        "abstract url": "https://arxiv.org/abs/2409.11742",
        "title": "Simulating Native Speaker Shadowing for Nonnative Speech Assessment with Latent Speech Representations",
        "rating": "-0.5",
        "keywords": [
            [
                "voice conversion"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Evaluating speech intelligibility is a critical task in computer-aided language learning systems. Traditional methods often rely on word error rates (WER) provided by automatic speech recognition (ASR) as intelligibility scores. However, this approach has significant limitations due to notable differences between human speech recognition (HSR) and ASR. A promising alternative is to involve a native (L1) speaker in shadowing what nonnative (L2) speakers say. Breakdowns or mispronunciations in the L1 speaker's shadowing utterance can serve as indicators for assessing L2 speech intelligibility. In this study, we propose a speech generation system that simulates the L1 shadowing process using voice conversion (VC) techniques and latent speech representations. Our experimental results demonstrate that this method effectively replicates the L1 shadowing process, offering an innovative tool to evaluate L2 speech intelligibility. Notably, systems that utilize self-supervised speech representations (S3R) show a higher degree of similarity to real L1 shadowing utterances in both linguistic accuracy and naturalness.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Submitted to ICASSP2025 Demo available: https://secondtonumb.github.io/publication_demo/ICASSP_2025/index.html"
    },
    {
        "paper id": "2409.11754",
        "abstract url": "https://arxiv.org/abs/2409.11754",
        "title": "NPAT Null-Space Projected Adversarial Training Towards Zero Deterioration",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "To mitigate the susceptibility of neural networks to adversarial attacks, adversarial training has emerged as a prevalent and effective defense strategy. Intrinsically, this countermeasure incurs a trade-off, as it sacrifices the model's accuracy in processing normal samples. To reconcile the trade-off, we pioneer the incorporation of null-space projection into adversarial training and propose two innovative Null-space Projection based Adversarial Training(NPAT) algorithms tackling sample generation and gradient optimization, named Null-space Projected Data Augmentation (NPDA) and Null-space Projected Gradient Descent (NPGD), to search for an overarching optimal solutions, which enhance robustness with almost zero deterioration in generalization performance. Adversarial samples and perturbations are constrained within the null-space of the decision boundary utilizing a closed-form null-space projector, effectively mitigating threat of attack stemming from unreliable features. Subsequently, we conducted experiments on the CIFAR10 and SVHN datasets and reveal that our methodology can seamlessly combine with adversarial training methods and obtain comparable robustness while keeping generalization close to a high-accuracy model.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11764",
        "abstract url": "https://arxiv.org/abs/2409.11764",
        "title": "One Map to Find Them All: Real-time Open-Vocabulary Mapping for Zero-shot Multi-Object Navigation",
        "rating": "-0.5",
        "keywords": [
            [
                "robot",
                "Navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The capability to efficiently search for objects in complex environments is fundamental for many real-world robot applications. Recent advances in open-vocabulary vision models have resulted in semantically-informed object navigation methods that allow a robot to search for an arbitrary object without prior training. However, these zero-shot methods have so far treated the environment as unknown for each consecutive query. In this paper we introduce a new benchmark for zero-shot multi-object navigation, allowing the robot to leverage information gathered from previous searches to more efficiently find new objects. To address this problem we build a reusable open-vocabulary feature map tailored for real-time object search. We further propose a probabilistic-semantic map update that mitigates common sources of errors in semantic feature extraction and leverage this semantic uncertainty for informed multi-object exploration. We evaluate our method on a set of object navigation tasks in both simulation as well as with a real robot, running in real-time on a Jetson Orin AGX. We demonstrate that it outperforms existing state-of-the-art approaches both on single and multi-object navigation tasks. Additional videos, code and the multi-object navigation benchmark will be available on https://finnbsch.github.io/OneMap.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11780",
        "abstract url": "https://arxiv.org/abs/2409.11780",
        "title": "Explaining Non-monotonic Normative Reasoning using Argumentation Theory with Deontic Logic",
        "rating": "-0.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In our previous research, we provided a reasoning system (called LeSAC) based on argumentation theory to provide legal support to designers during the design process. Building on this, this paper explores how to provide designers with effective explanations for their legally relevant design decisions. We extend the previous system for providing explanations by specifying norms and the key legal or ethical principles for justifying actions in normative contexts. Considering that first-order logic has strong expressive power, in the current paper we adopt a first-order deontic logic system with deontic operators and preferences. We illustrate the advantages and necessity of introducing deontic logic and designing explanations under LeSAC by modelling two cases in the context of autonomous driving. In particular, this paper also discusses the requirements of the updated LeSAC to guarantee rationality, and proves that a well-defined LeSAC can satisfy the rationality postulate for rule-based argumentation frameworks. This ensures the system's ability to provide coherent, legally valid explanations for complex design decisions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2409.11816",
        "abstract url": "https://arxiv.org/abs/2409.11816",
        "title": "SymFace: Additional Facial Symmetry Loss for Deep Face Recognition",
        "rating": "-0.5",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Over the past decade, there has been a steady advancement in enhancing face recognition algorithms leveraging advanced machine learning methods. The role of the loss function is pivotal in addressing face verification problems and playing a game-changing role. These loss functions have mainly explored variations among intra-class or inter-class separation. This research examines the natural phenomenon of facial symmetry in the face verification problem. The symmetry between the left and right hemi faces has been widely used in many research areas in recent decades. This paper adopts this simple approach judiciously by splitting the face image vertically into two halves. With the assumption that the natural phenomena of facial symmetry can enhance face verification methodology, we hypothesize that the two output embedding vectors of split faces must project close to each other in the output embedding space. Inspired by this concept, we penalize the network based on the disparity of embedding of the symmetrical pair of split faces. Symmetrical loss has the potential to minimize minor asymmetric features due to facial expression and lightning conditions, hence significantly increasing the inter-class variance among the classes and leading to more reliable face embedding. This loss function propels any network to outperform its baseline performance across all existing network architectures and configurations, enabling us to achieve SoTA results.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 Pages, 6 Figures, 5 Tables, Submitted for WACV 2025"
    },
    {
        "paper id": "2409.11836",
        "abstract url": "https://arxiv.org/abs/2409.11836",
        "title": "NT-ViT: Neural Transcoding Vision Transformers for EEG-to-fMRI Synthesis",
        "rating": "-0.5",
        "keywords": [
            [
                "diagnosis",
                "fMRI",
                "EEG",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "This paper introduces the Neural Transcoding Vision Transformer (\\modelname), a generative model designed to estimate high-resolution functional Magnetic Resonance Imaging (fMRI) samples from simultaneous Electroencephalography (EEG) data. A key feature of \\modelname is its Domain Matching (DM) sub-module which effectively aligns the latent EEG representations with those of fMRI volumes, enhancing the model's accuracy and reliability. Unlike previous methods that tend to struggle with fidelity and reproducibility of images, \\modelname addresses these challenges by ensuring methodological integrity and higher-quality reconstructions which we showcase through extensive evaluation on two benchmark datasets; \\modelname outperforms the current state-of-the-art by a significant margin in both cases, e.g. achieving a $10\\times$ reduction in RMSE and a $3.14\\times$ increase in SSIM on the Oddball dataset. An ablation study also provides insights into the contribution of each component to the model's overall effectiveness. This development is critical in offering a new approach to lessen the time and financial constraints typically linked with high-resolution brain imaging, thereby aiding in the swift and precise diagnosis of neurological disorders. Although it is not a replacement for actual fMRI but rather a step towards making such imaging more accessible, we believe that it represents a pivotal advancement in clinical practice and neuroscience research. Code is available at \\url{https://github.com/rom42pla/ntvit}.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "ECCV24 Workshop on Synthetic Data for Computer Vision"
    },
    {
        "paper id": "2409.11843",
        "abstract url": "https://arxiv.org/abs/2409.11843",
        "title": "Graph Neural Network-State Predictive Information Bottleneck (GNN-SPIB) approach for learning molecular thermodynamics and kinetics",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Molecular dynamics simulations offer detailed insights into atomic motions but face timescale limitations. Enhanced sampling methods have addressed these challenges but even with machine learning, they often rely on pre-selected expert-based features. In this work, we present the Graph Neural Network-State Predictive Information Bottleneck (GNN-SPIB) framework, which combines graph neural networks and the State Predictive Information Bottleneck to automatically learn low-dimensional representations directly from atomic coordinates. Tested on three benchmark systems, our approach predicts essential structural, thermodynamic and kinetic information for slow processes, demonstrating robustness across diverse systems. The method shows promise for complex systems, enabling effective enhanced sampling without requiring pre-defined reaction coordinates or input features.",
        "subjects": [
            "cs.LG",
            "cond-mat.soft",
            "cond-mat.stat-mech"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11899",
        "abstract url": "https://arxiv.org/abs/2409.11899",
        "title": "Multi-Grid Graph Neural Networks with Self-Attention for Computational Mechanics",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Advancement in finite element methods have become essential in various disciplines, and in particular for Computational Fluid Dynamics (CFD), driving research efforts for improved precision and efficiency. While Convolutional Neural Networks (CNNs) have found success in CFD by mapping meshes into images, recent attention has turned to leveraging Graph Neural Networks (GNNs) for direct mesh processing. This paper introduces a novel model merging Self-Attention with Message Passing in GNNs, achieving a 15\\% reduction in RMSE on the well known flow past a cylinder benchmark. Furthermore, a dynamic mesh pruning technique based on Self-Attention is proposed, that leads to a robust GNN-based multigrid approach, also reducing RMSE by 15\\%. Additionally, a new self-supervised training method based on BERT is presented, resulting in a 25\\% RMSE reduction. The paper includes an ablation study and outperforms state-of-the-art models on several challenging datasets, promising advancements similar to those recently achieved in natural language and image processing. Finally, the paper introduces a dataset with meshes larger than existing ones by at least an order of magnitude. Code and Datasets will be released at https://github.com/DonsetPG/multigrid-gnn.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11935",
        "abstract url": "https://arxiv.org/abs/2409.11935",
        "title": "Reinforcement Learning with Lie Group Orientations for Robotics",
        "rating": "-0.5",
        "keywords": [
            [
                "Robotics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Handling orientations of robots and objects is a crucial aspect of many applications. Yet, ever so often, there is a lack of mathematical correctness when dealing with orientations, especially in learning pipelines involving, for example, artificial neural networks. In this paper, we investigate reinforcement learning with orientations and propose a simple modification of the network's input and output that adheres to the Lie group structure of orientations. As a result, we obtain an easy and efficient implementation that is directly usable with existing learning libraries and achieves significantly better performance than other common orientation representations. We briefly introduce Lie theory specifically for orientations in robotics to motivate and outline our approach. Subsequently, a thorough empirical evaluation of different combinations of orientation representations for states and actions demonstrates the superior performance of our proposed approach in different scenarios, including: direct orientation control, end effector orientation control, and pick-and-place tasks.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Submitted to ICRA 2025"
    },
    {
        "paper id": "2409.11984",
        "abstract url": "https://arxiv.org/abs/2409.11984",
        "title": "Spectral clustering of time-evolving networks using the inflated dynamic Laplacian for graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Complex time-varying networks are prominent models for a wide variety of spatiotemporal phenomena. The functioning of networks depends crucially on their connectivity, yet reliable techniques for determining communities in spacetime networks remain elusive. We adapt successful spectral techniques from continuous-time dynamics on manifolds to the graph setting to fill this gap. We formulate an {\\it inflated dynamic Laplacian} for graphs and develop a spectral theory to underpin the corresponding algorithmic realisations. We develop spectral clustering approaches for both multiplex and non-multiplex networks, based on the eigenvectors of the inflated dynamic Laplacian and specialised Sparse EigenBasis Approximation (SEBA) post-processing of these eigenvectors. We demonstrate that our approach can outperform the Leiden algorithm applied both in spacetime and layer-by-layer, and we analyse voting data from the US senate (where senators come and go as congresses evolve) to quantify increasing polarisation in time.",
        "subjects": [
            "cs.SI",
            "math.DS",
            "physics.soc-ph"
        ],
        "comment": "47 pages, 8 figures"
    },
    {
        "paper id": "2409.12005",
        "abstract url": "https://arxiv.org/abs/2409.12005",
        "title": "Representing Positional Information in Generative World Models for Object Manipulation",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Object manipulation capabilities are essential skills that set apart embodied agents engaging with the world, especially in the realm of robotics. The ability to predict outcomes of interactions with objects is paramount in this setting. While model-based control methods have started to be employed for tackling manipulation tasks, they have faced challenges in accurately manipulating objects. As we analyze the causes of this limitation, we identify the cause of underperformance in the way current world models represent crucial positional information, especially about the target's goal specification for object positioning tasks. We introduce a general approach that empowers world model-based agents to effectively solve object-positioning tasks. We propose two declinations of this approach for generative world models: position-conditioned (PCP) and latent-conditioned (LCP) policy learning. In particular, LCP employs object-centric latent representations that explicitly capture object positional information for goal specification. This naturally leads to the emergence of multimodal capabilities, enabling the specification of goals through spatial coordinates or a visual goal. Our methods are rigorously evaluated across several manipulation environments, showing favorable performance compared to current model-based control approaches.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12020",
        "abstract url": "https://arxiv.org/abs/2409.12020",
        "title": "Promise and Peril of Collaborative Code Generation Models: Balancing Effectiveness and Memorization",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the rapidly evolving field of machine learning, training models with datasets from various locations and organizations presents significant challenges due to privacy and legal concerns. The exploration of effective collaborative training settings capable of leveraging valuable knowledge from distributed and isolated datasets is increasingly crucial. This study investigates key factors that impact the effectiveness of collaborative training methods in code next-token prediction, as well as the correctness and utility of the generated code, demonstrating the promise of such methods. Additionally, we evaluate the memorization of different participant training data across various collaborative training settings, including centralized, federated, and incremental training, highlighting their potential risks in leaking data. Our findings indicate that the size and diversity of code datasets are pivotal factors influencing the success of collaboratively trained code models. We show that federated learning achieves competitive performance compared to centralized training while offering better data protection, as evidenced by lower memorization ratios in the generated code. However, federated learning can still produce verbatim code snippets from hidden training data, potentially violating privacy or copyright. Our study further explores effectiveness and memorization patterns in incremental learning, emphasizing the sequence in which individual participant datasets are introduced. We also identify cross-organizational clones as a prevalent challenge in both centralized and federated learning scenarios. Our findings highlight the persistent risk of data leakage during inference, even when training data remains unseen. We conclude with recommendations for practitioners and researchers to optimize multisource datasets, propelling cross-organizational collaboration forward.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Paper accepted to the ASE 2024 Conference Research Track"
    },
    {
        "paper id": "2409.12033",
        "abstract url": "https://arxiv.org/abs/2409.12033",
        "title": "Topological Deep Learning with State-Space Models: A Mamba Approach for Simplicial Complexes",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks based on the message-passing (MP) mechanism are a dominant approach for handling graph-structured data. However, they are inherently limited to modeling only pairwise interactions, making it difficult to explicitly capture the complexity of systems with $n$-body relations. To address this, topological deep learning has emerged as a promising field for studying and modeling higher-order interactions using various topological domains, such as simplicial and cellular complexes. While these new domains provide powerful representations, they introduce new challenges, such as effectively modeling the interactions among higher-order structures through higher-order MP. Meanwhile, structured state-space sequence models have proven to be effective for sequence modeling and have recently been adapted for graph data by encoding the neighborhood of a node as a sequence, thereby avoiding the MP mechanism. In this work, we propose a novel architecture designed to operate with simplicial complexes, utilizing the Mamba state-space model as its backbone. Our approach generates sequences for the nodes based on the neighboring cells, enabling direct communication between all higher-order structures, regardless of their rank. We extensively validate our model, demonstrating that it achieves competitive performance compared to state-of-the-art models developed for simplicial complexes.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12045",
        "abstract url": "https://arxiv.org/abs/2409.12045",
        "title": "Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Safety is one of the key issues preventing the deployment of reinforcement learning techniques in real-world robots. While most approaches in the Safe Reinforcement Learning area do not require prior knowledge of constraints and robot kinematics and rely solely on data, it is often difficult to deploy them in complex real-world settings. Instead, model-based approaches that incorporate prior knowledge of the constraints and dynamics into the learning framework have proven capable of deploying the learning algorithm directly on the real robot. Unfortunately, while an approximated model of the robot dynamics is often available, the safety constraints are task-specific and hard to obtain: they may be too complicated to encode analytically, too expensive to compute, or it may be difficult to envision a priori the long-term safety requirements. In this paper, we bridge this gap by extending the safe exploration method, ATACOM, with learnable constraints, with a particular focus on ensuring long-term safety and handling of uncertainty. Our approach is competitive or superior to state-of-the-art methods in final performance while maintaining safer behavior during training.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12092",
        "abstract url": "https://arxiv.org/abs/2409.12092",
        "title": "IMRL: Integrating Visual, Physical, Temporal, and Geometric Representations for Enhanced Food Acquisition",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Robotic assistive feeding holds significant promise for improving the quality of life for individuals with eating disabilities. However, acquiring diverse food items under varying conditions and generalizing to unseen food presents unique challenges. Existing methods that rely on surface-level geometric information (e.g., bounding box and pose) derived from visual cues (e.g., color, shape, and texture) often lacks adaptability and robustness, especially when foods share similar physical properties but differ in visual appearance. We employ imitation learning (IL) to learn a policy for food acquisition. Existing methods employ IL or Reinforcement Learning (RL) to learn a policy based on off-the-shelf image encoders such as ResNet-50. However, such representations are not robust and struggle to generalize across diverse acquisition scenarios. To address these limitations, we propose a novel approach, IMRL (Integrated Multi-Dimensional Representation Learning), which integrates visual, physical, temporal, and geometric representations to enhance the robustness and generalizability of IL for food acquisition. Our approach captures food types and physical properties (e.g., solid, semi-solid, granular, liquid, and mixture), models temporal dynamics of acquisition actions, and introduces geometric information to determine optimal scooping points and assess bowl fullness. IMRL enables IL to adaptively adjust scooping strategies based on context, improving the robot's capability to handle diverse food acquisition scenarios. Experiments on a real robot demonstrate our approach's robustness and adaptability across various foods and bowl configurations, including zero-shot generalization to unseen settings. Our approach achieves improvement up to $35\\%$ in success rate compared with the best-performing baseline.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12105",
        "abstract url": "https://arxiv.org/abs/2409.12105",
        "title": "FedLF: Adaptive Logit Adjustment and Feature Optimization in Federated Long-Tailed Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning offers a paradigm to the challenge of preserving privacy in distributed machine learning. However, datasets distributed across each client in the real world are inevitably heterogeneous, and if the datasets can be globally aggregated, they tend to be long-tailed distributed, which greatly affects the performance of the model. The traditional approach to federated learning primarily addresses the heterogeneity of data among clients, yet it fails to address the phenomenon of class-wise bias in global long-tailed data. This results in the trained model focusing on the head classes while neglecting the equally important tail classes. Consequently, it is essential to develop a methodology that considers classes holistically. To address the above problems, we propose a new method FedLF, which introduces three modifications in the local training phase: adaptive logit adjustment, continuous class centred optimization, and feature decorrelation. We compare seven state-of-the-art methods with varying degrees of data heterogeneity and long-tailed distribution. Extensive experiments on benchmark datasets CIFAR-10-LT and CIFAR-100-LT demonstrate that our approach effectively mitigates the problem of model performance degradation due to data heterogeneity and long-tailed distribution. our code is available at https://github.com/18sym/FedLF.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by ACML 2024"
    },
    {
        "paper id": "2409.12117",
        "abstract url": "https://arxiv.org/abs/2409.12117",
        "title": "Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference",
        "rating": "-0.5",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Large language models (LLMs) have significantly advanced audio processing through audio codecs that convert audio into discrete tokens, enabling the application of language modeling techniques to audio data. However, audio codecs often operate at high frame rates, resulting in slow training and inference, especially for autoregressive models. To address this challenge, we present the Low Frame-rate Speech Codec (LFSC): a neural audio codec that leverages finite scalar quantization and adversarial training with large speech language models to achieve high-quality audio compression with a 1.89 kbps bitrate and 21.5 frames per second. We demonstrate that our novel codec can make the inference of LLM-based text-to-speech models around three times faster while improving intelligibility and producing quality comparable to previous models.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.SD"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.12150",
        "abstract url": "https://arxiv.org/abs/2409.12150",
        "title": "Decoding Style: Efficient Fine-Tuning of LLMs for Image-Guided Outfit Recommendation with Preference",
        "rating": "-0.5",
        "keywords": [
            [
                "Efficient Fine-Tuning"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Personalized outfit recommendation remains a complex challenge, demanding both fashion compatibility understanding and trend awareness. This paper presents a novel framework that harnesses the expressive power of large language models (LLMs) for this task, mitigating their \"black box\" and static nature through fine-tuning and direct feedback integration. We bridge the item visual-textual gap in items descriptions by employing image captioning with a Multimodal Large Language Model (MLLM). This enables the LLM to extract style and color characteristics from human-curated fashion images, forming the basis for personalized recommendations. The LLM is efficiently fine-tuned on the open-source Polyvore dataset of curated fashion images, optimizing its ability to recommend stylish outfits. A direct preference mechanism using negative examples is employed to enhance the LLM's decision-making process. This creates a self-enhancing AI feedback loop that continuously refines recommendations in line with seasonal fashion trends. Our framework is evaluated on the Polyvore dataset, demonstrating its effectiveness in two key tasks: fill-in-the-blank, and complementary item retrieval. These evaluations underline the framework's ability to generate stylish, trend-aligned outfit suggestions, continuously improving through direct feedback. The evaluation results demonstrated that our proposed framework significantly outperforms the base LLM, creating more cohesive outfits. The improved performance in these tasks underscores the proposed framework's potential to enhance the shopping experience with accurate suggestions, proving its effectiveness over the vanilla LLM based outfit generation.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "CIKM 2024"
    },
    {
        "paper id": "2409.12193",
        "abstract url": "https://arxiv.org/abs/2409.12193",
        "title": "Vista3D: Unravel the 3D Darkside of a Single Image",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "SDF"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "We embark on the age-old quest: unveiling the hidden dimensions of objects from mere glimpses of their visible parts. To address this, we present Vista3D, a framework that realizes swift and consistent 3D generation within a mere 5 minutes. At the heart of Vista3D lies a two-phase approach: the coarse phase and the fine phase. In the coarse phase, we rapidly generate initial geometry with Gaussian Splatting from a single image. In the fine phase, we extract a Signed Distance Function (SDF) directly from learned Gaussian Splatting, optimizing it with a differentiable isosurface representation. Furthermore, it elevates the quality of generation by using a disentangled representation with two independent implicit functions to capture both visible and obscured aspects of objects. Additionally, it harmonizes gradients from 2D diffusion prior with 3D-aware diffusion priors by angular diffusion prior composition. Through extensive evaluation, we demonstrate that Vista3D effectively sustains a balance between the consistency and diversity of the generated 3D objects. Demos and code will be available at https://github.com/florinshen/Vista3D.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GT",
            "cs.MM"
        ],
        "comment": "ECCV'2024"
    },
    {
        "paper id": "2409.11709",
        "abstract url": "https://arxiv.org/abs/2409.11709",
        "title": "Multi-robot connection towards collective obstacle field traversal",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Environments with large terrain height variations present great challenges for legged robot locomotion. Drawing inspiration from fire ants' collective assembly behavior, we study strategies that can enable two ``connectable'' robots to collectively navigate over bumpy terrains with height variations larger than robot leg length. Each robot was designed to be extremely simple, with a cubical body and one rotary motor actuating four vertical peg legs that move in pairs. Two or more robots could physically connect to one another to enhance collective mobility. We performed locomotion experiments with a two-robot group, across an obstacle field filled with uniformly-distributed semi-spherical ``boulders''. Experimentally-measured robot speed suggested that the connection length between the robots has a significant effect on collective mobility: connection length C in [0.86, 0.9] robot unit body length (UBL) were able to produce sustainable movements across the obstacle field, whereas connection length C in [0.63, 0.84] and [0.92, 1.1] UBL resulted in low traversability. An energy landscape based model revealed the underlying mechanism of how connection length modulated collective mobility through the system's potential energy landscape, and informed adaptation strategies for the two-robot system to adapt their connection length for traversing obstacle fields with varying spatial frequencies. Our results demonstrated that by varying the connection configuration between the robots, the two-robot system could leverage mechanical intelligence to better utilize obstacle interaction forces and produce improved locomotion. Going forward, we envision that generalized principles of robot-environment coupling can inform design and control strategies for a large group of small robots to achieve ant-like collective environment negotiation.",
        "subjects": [
            "cs.RO",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11712",
        "abstract url": "https://arxiv.org/abs/2409.11712",
        "title": "Revolutionizing Pharmaceutical Manufacturing: Advances and Challenges of 3D Printing System and Control",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "The advent of 3D printing has transformed the pharmaceutical industry, enabling precision drug manufacturing with controlled release profiles, dosing, and structural complexity. Additive manufacturing (AM) addresses the growing demand for personalized medicine, overcoming limitations of traditional methods. This technology facilitates tailored dosage forms, complex geometries, and real-time quality control. Recent advancements in drop-on-demand printing, UV curable inks, material science, and regulatory frameworks are discussed. Despite opportunities for cost reduction, flexibility, and decentralized manufacturing, challenges persist in scalability, reproducibility, and regulatory adaptation. This review provides an in-depth analysis of the current state of AM in pharmaceutical manufacturing, exploring recent developments, challenges, and future directions for mainstream integration.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "submitted to IMECE 2024"
    },
    {
        "paper id": "2409.11723",
        "abstract url": "https://arxiv.org/abs/2409.11723",
        "title": "Reconfiguration of labeled matchings in triangular grid graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This paper introduces a new reconfiguration problem of matchings in a triangular grid graph. In this problem, we are given a nearly perfect matching in which each matching edge is labeled, and aim to transform it to a target matching by sliding edges one by one. This problem is motivated to investigate the solvability of a sliding-block puzzle called ``Gourds'' on a hexagonal grid board, introduced by Hamersma et al. [ISAAC 2020]. The main contribution of this paper is to prove that, if a triangular grid graph is factor-critical and has a vertex of degree $6$, then any two matchings can be reconfigured to each other. Moreover, for a triangular grid graph (which may not have a degree-6 vertex), we present another sufficient condition using the local connectivity. Both of our results provide broad sufficient conditions for the solvability of the Gourds puzzle on a hexagonal grid board with holes, where Hamersma et al. left it as an open question.",
        "subjects": [
            "cs.DS",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11733",
        "abstract url": "https://arxiv.org/abs/2409.11733",
        "title": "Human-like Affective Cognition in Foundation Models",
        "rating": "-1",
        "keywords": [
            [
                "facial",
                "psychological"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Understanding emotions is fundamental to human interaction and experience. Humans easily infer emotions from situations or facial expressions, situations from emotions, and do a variety of other \\emph{affective cognition}. How adept is modern AI at these inferences? We introduce an evaluation framework for testing affective cognition in foundation models. Starting from psychological theory, we generate 1,280 diverse scenarios exploring relationships between appraisals, emotions, expressions, and outcomes. We evaluate the abilities of foundation models (GPT-4, Claude-3, Gemini-1.5-Pro) and humans (N = 567) across carefully selected conditions. Our results show foundation models tend to agree with human intuitions, matching or exceeding interparticipant agreement. In some conditions, models are ``superhuman'' -- they better predict modal human judgements than the average human. All models benefit from chain-of-thought reasoning. This suggests foundation models have acquired a human-like understanding of emotions and their influence on beliefs and behavior.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11744",
        "abstract url": "https://arxiv.org/abs/2409.11744",
        "title": "Exploring Gaze Pattern in Autistic Children: Clustering, Visualization, and Prediction",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Autism Spectrum Disorder (ASD) significantly affects the social and communication abilities of children, and eye-tracking is commonly used as a diagnostic tool by identifying associated atypical gaze patterns. Traditional methods demand manual identification of Areas of Interest in gaze patterns, lowering the performance of gaze behavior analysis in ASD subjects. To tackle this limitation, we propose a novel method to automatically analyze gaze behaviors in ASD children with superior accuracy. To be specific, we first apply and optimize seven clustering algorithms to automatically group gaze points to compare ASD subjects with typically developing peers. Subsequently, we extract 63 significant features to fully describe the patterns. These features can describe correlations between ASD diagnosis and gaze patterns. Lastly, using these features as prior knowledge, we train multiple predictive machine learning models to predict and diagnose ASD based on their gaze behaviors. To evaluate our method, we apply our method to three ASD datasets. The experimental and visualization results demonstrate the improvements of clustering algorithms in the analysis of unique gaze patterns in ASD children. Additionally, these predictive machine learning models achieved state-of-the-art prediction performance ($81\\%$ AUC) in the field of automatically constructed gaze point features for ASD diagnosis. Our code is available at \\url{https://github.com/username/projectname}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11750",
        "abstract url": "https://arxiv.org/abs/2409.11750",
        "title": "Neural Encoding for Image Recall: Human-Like Memory",
        "rating": "-1",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Achieving human-like memory recall in artificial systems remains a challenging frontier in computer vision. Humans demonstrate remarkable ability to recall images after a single exposure, even after being shown thousands of images. However, this capacity diminishes significantly when confronted with non-natural stimuli such as random textures. In this paper, we present a method inspired by human memory processes to bridge this gap between artificial and biological memory systems. Our approach focuses on encoding images to mimic the high-level information retained by the human brain, rather than storing raw pixel data. By adding noise to images before encoding, we introduce variability akin to the non-deterministic nature of human memory encoding. Leveraging pre-trained models' embedding layers, we explore how different architectures encode images and their impact on memory recall. Our method achieves impressive results, with 97% accuracy on natural images and near-random performance (52%) on textures. We provide insights into the encoding process and its implications for machine learning memory systems, shedding light on the parallels between human and artificial intelligence memory mechanisms.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 7 figures"
    },
    {
        "paper id": "2409.11752",
        "abstract url": "https://arxiv.org/abs/2409.11752",
        "title": "Cross-Organ and Cross-Scanner Adenocarcinoma Segmentation using Rein to Fine-tune Vision Foundation Models",
        "rating": "-1",
        "keywords": [
            [
                "tumor",
                "Organ"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In recent years, significant progress has been made in tumor segmentation within the field of digital pathology. However, variations in organs, tissue preparation methods, and image acquisition processes can lead to domain discrepancies among digital pathology images. To address this problem, in this paper, we use Rein, a fine-tuning method, to parametrically and efficiently fine-tune various vision foundation models (VFMs) for MICCAI 2024 Cross-Organ and Cross-Scanner Adenocarcinoma Segmentation (COSAS2024). The core of Rein consists of a set of learnable tokens, which are directly linked to instances, improving functionality at the instance level in each layer. In the data environment of the COSAS2024 Challenge, extensive experiments demonstrate that Rein fine-tuned the VFMs to achieve satisfactory results. Specifically, we used Rein to fine-tune ConvNeXt and DINOv2. Our team used the former to achieve scores of 0.7719 and 0.7557 on the preliminary test phase and final test phase in task1, respectively, while the latter achieved scores of 0.8848 and 0.8192 on the preliminary test phase and final test phase in task2. Code is available at GitHub.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11753",
        "abstract url": "https://arxiv.org/abs/2409.11753",
        "title": "METEOR: Melody-aware Texture-controllable Symbolic Orchestral Music Generation",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Western music is often characterized by a homophonic texture, in which the musical content can be organized into a melody and an accompaniment. In orchestral music, in particular, the composer can select specific characteristics for each instrument's part within the accompaniment, while also needing to adapt the melody to suit the capabilities of the instruments performing it. In this work, we propose METEOR, a model for Melody-aware Texture-controllable Orchestral music generation. This model performs symbolic multi-track music style transfer with a focus on melodic fidelity. We allow bar- and track-level controllability of the accompaniment with various textural attributes while keeping a homophonic texture. We show that the model can achieve controllability performances similar to strong baselines while greatly improve melodic fidelity.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "https://dinhviettoanle.github.io/meteor"
    },
    {
        "paper id": "2409.11783",
        "abstract url": "https://arxiv.org/abs/2409.11783",
        "title": "Development and bilingual evaluation of Japanese medical large language model within reasonably low computational resources",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "healthcare",
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The recent success of large language models (LLMs) and the scaling law has led to a widespread adoption of larger models. Particularly in the healthcare industry, there is an increasing demand for locally operated LLMs due to security concerns. However, the majority of high quality open-source LLMs have a size of 70B parameters, imposing significant financial burdens on users for GPU preparation and operation. To overcome these issues, we present a medical adaptation based on the recent 7B models, which enables the operation in low computational resources. We compare the performance on medical question-answering benchmarks in two languages (Japanese and English), demonstrating that its scores reach parity with or surpass those of currently existing medical LLMs that are ten times larger. We find that fine-tuning an English-centric base model on Japanese medical dataset improves the score in both language, supporting the effect of cross-lingual knowledge transfer. We hope that this study will alleviate financial challenges, serving as a stepping stone for clinical institutions to practically utilize LLMs locally. Our evaluation code is available at https://huggingface.co/stardust-coder/jmedllm-7b-v1.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "18 pages, 9 tables"
    },
    {
        "paper id": "2409.11811",
        "abstract url": "https://arxiv.org/abs/2409.11811",
        "title": "Abelian and stochastic sandpile models on complete bipartite graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "In the sandpile model, vertices of a graph are allocated grains of sand. At each unit of time, a grain is added to a randomly chosen vertex. If that causes its number of grains to exceed its degree, that vertex is called unstable, and topples. In the Abelian sandpile model (ASM), topplings are deterministic, whereas in the stochastic sandpile model (SSM) they are random. We study the ASM and SSM on complete bipartite graphs. For the SSM, we provide a stochastic version of Dhar's burning algorithm to check if a given (stable) configuration is recurrent or not, with linear complexity. We also exhibit a bijection between sorted recurrent configurations and pairs of compatible Ferrers diagrams. We then provide a similar bijection for the ASM, and also interpret its recurrent configurations in terms of labelled Motzkin paths.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "math.PR"
        ],
        "comment": "19 pages, 9 figures"
    },
    {
        "paper id": "2409.11812",
        "abstract url": "https://arxiv.org/abs/2409.11812",
        "title": "Distributed Resilient Secondary Control for Microgrids with Attention-based Weights against High-density Misbehaving Agents",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Microgrids (MGs) have been equipped with large-scale distributed energy sources (DESs), and become more vulnerable due to the low inertia characteristic. In particular, high-density misbehaving DESs caused by cascading faults bring a great challenge to frequency synchronization and active power sharing among DESs. To tackle the problem, we propose a fully distributed resilient consensus protocol, which utilizes confidence weights to evaluate the level of trust among agents with a first-order filter and a softmax-type function. We pioneer the analysis of this nonlinear control system from the system operating range and the graph structure perspectives. Both necessary and sufficient conditions are provided to ensure DACC to be uniformly ultimately bounded, even in a robust network with low connectivity. Simulations on a modified IEEE33-bus microgrid testbed with 17 DESs validate that DACC outperforms existing methods in the presence of 8 misbehaving DESs.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11831",
        "abstract url": "https://arxiv.org/abs/2409.11831",
        "title": "RaggeDi: Diffusion-based State Estimation of Disordered Rags, Sheets, Towels and Blankets",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Cloth state estimation is an important problem in robotics. It is essential for the robot to know the accurate state to manipulate cloth and execute tasks such as robotic dressing, stitching, and covering/uncovering human beings. However, estimating cloth state accurately remains challenging due to its high flexibility and self-occlusion. This paper proposes a diffusion model-based pipeline that formulates the cloth state estimation as an image generation problem by representing the cloth state as an RGB image that describes the point-wise translation (translation map) between a pre-defined flattened mesh and the deformed mesh in a canonical space. Then we train a conditional diffusion-based image generation model to predict the translation map based on an observation. Experiments are conducted in both simulation and the real world to validate the performance of our method. Results indicate that our method outperforms two recent methods in both accuracy and speed.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11849",
        "abstract url": "https://arxiv.org/abs/2409.11849",
        "title": "System-Level Efficient Performance of EMLA-Driven Heavy-Duty Manipulators via Bilevel Optimization Framework with a Leader--Follower Scenario",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "The global push for sustainability and energy efficiency is driving significant advancements across various industries, including the development of electrified solutions for heavy-duty mobile manipulators (HDMMs). Electromechanical linear actuators (EMLAs), powered by permanent magnet synchronous motors, present an all-electric alternative to traditional internal combustion engine (ICE)-powered hydraulic actuators, offering a promising path toward an eco-friendly future for HDMMs. However, the limited operational range of electrified HDMMs, closely tied to battery capacity, highlights the need to fully exploit the potential of EMLAs that driving the manipulators. This goal is contingent upon a deep understanding of the harmonious interplay between EMLA mechanisms and the dynamic behavior of heavy-duty manipulators. To this end, this paper introduces a bilevel multi-objective optimization framework, conceptualizing the EMLA-actuated manipulator of an electrified HDMM as a leader--follower scenario. At the leader level, the optimization algorithm maximizes EMLA efficiency by considering electrical and mechanical constraints, while the follower level optimizes manipulator motion through a trajectory reference generator that adheres to manipulator limits. This optimization approach ensures that the system operates with a synergistic trade-off between the most efficient operating region of the actuation system, achieving a total efficiency of 70.3\\%, and high manipulator performance. Furthermore, to complement this framework and ensure precise tracking of the generated optimal trajectories, a robust, adaptive, subsystem-based control strategy is developed with accurate control and exponential stability. The proposed methodologies are validated on a three-degrees-of-freedom manipulator, demonstrating significant efficiency improvements while maintaining high-performance operation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "16 pages journal paper"
    },
    {
        "paper id": "2409.11854",
        "abstract url": "https://arxiv.org/abs/2409.11854",
        "title": "Physically-Based Photometric Bundle Adjustment in Non-Lambertian Environments",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Photometric bundle adjustment (PBA) is widely used in estimating the camera pose and 3D geometry by assuming a Lambertian world. However, the assumption of photometric consistency is often violated since the non-diffuse reflection is common in real-world environments. The photometric inconsistency significantly affects the reliability of existing PBA methods. To solve this problem, we propose a novel physically-based PBA method. Specifically, we introduce the physically-based weights regarding material, illumination, and light path. These weights distinguish the pixel pairs with different levels of photometric inconsistency. We also design corresponding models for material estimation based on sequential images and illumination estimation based on point clouds. In addition, we establish the first SLAM-related dataset of non-Lambertian scenes with complete ground truth of illumination and material. Extensive experiments demonstrated that our PBA method outperforms existing approaches in accuracy.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Accepted to 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)"
    },
    {
        "paper id": "2409.11869",
        "abstract url": "https://arxiv.org/abs/2409.11869",
        "title": "SpheriGait: Enriching Spatial Representation via Spherical Projection for LiDAR-based Gait Recognition",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Gait recognition is a rapidly progressing technique for the remote identification of individuals. Prior research predominantly employing 2D sensors to gather gait data has achieved notable advancements; nonetheless, they have unavoidably neglected the influence of 3D dynamic characteristics on recognition. Gait recognition utilizing LiDAR 3D point clouds not only directly captures 3D spatial features but also diminishes the impact of lighting conditions while ensuring privacy protection.The essence of the problem lies in how to effectively extract discriminative 3D dynamic representation from point clouds.In this paper, we proposes a method named SpheriGait for extracting and enhancing dynamic features from point clouds for Lidar-based gait recognition. Specifically, it substitutes the conventional point cloud plane projection method with spherical projection to augment the perception of dynamic feature.Additionally, a network block named DAM-L is proposed to extract gait cues from the projected point cloud data. We conducted extensive experiments and the results demonstrated the SpheriGait achieved state-of-the-art performance on the SUSTech1K dataset, and verified that the spherical projection method can serve as a universal data preprocessing technique to enhance the performance of other LiDAR-based gait recognition methods, exhibiting exceptional flexibility and practicality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11870",
        "abstract url": "https://arxiv.org/abs/2409.11870",
        "title": "SpotLight: Robotic Scene Understanding through Interaction and Affordance Detection",
        "rating": "-1",
        "keywords": [
            [
                "VLM"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Despite increasing research efforts on household robotics, robots intended for deployment in domestic settings still struggle with more complex tasks such as interacting with functional elements like drawers or light switches, largely due to limited task-specific understanding and interaction capabilities. These tasks require not only detection and pose estimation but also an understanding of the affordances these elements provide. To address these challenges and enhance robotic scene understanding, we introduce SpotLight: A comprehensive framework for robotic interaction with functional elements, specifically light switches. Furthermore, this framework enables robots to improve their environmental understanding through interaction. Leveraging VLM-based affordance prediction to estimate motion primitives for light switch interaction, we achieve up to 84% operation success in real world experiments. We further introduce a specialized dataset containing 715 images as well as a custom detection model for light switch detection. We demonstrate how the framework can facilitate robot learning through physical interaction by having the robot explore the environment and discover previously unknown relationships in a scene graph representation. Lastly, we propose an extension to the framework to accommodate other functional interactions such as swing doors, showcasing its flexibility. Videos and Code: timengelbracht.github.io/SpotLight/",
        "subjects": [
            "cs.RO"
        ],
        "comment": "timengelbracht.github.io/SpotLight/"
    },
    {
        "paper id": "2409.11915",
        "abstract url": "https://arxiv.org/abs/2409.11915",
        "title": "Exploring an Inter-Pausal Unit (IPU) based Approach for Indic End-to-End TTS Systems",
        "rating": "-1",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "Sentences in Indian languages are generally longer than those in English. Indian languages are also considered to be phrase-based, wherein semantically complete phrases are concatenated to make up sentences. Long utterances lead to poor training of text-to-speech models and result in poor prosody during synthesis. In this work, we explore an inter-pausal unit (IPU) based approach in the end-to-end (E2E) framework, focusing on synthesising conversational-style text. We consider both autoregressive Tacotron2 and non-autoregressive FastSpeech2 architectures in our study and perform experiments with three Indian languages, namely, Hindi, Tamil and Telugu. With the IPU-based Tacotron2 approach, we see a reduction in insertion and deletion errors in the synthesised audio, providing an alternative approach to the FastSpeech(2) network in terms of error reduction. The IPU-based approach requires less computational resources and produces prosodically richer synthesis compared to conventional sentence-based systems.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11920",
        "abstract url": "https://arxiv.org/abs/2409.11920",
        "title": "Generation of Complex 3D Human Motion by Temporal and Spatial Composition of Diffusion Models",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we address the challenge of generating realistic 3D human motions for action classes that were never seen during the training phase. Our approach involves decomposing complex actions into simpler movements, specifically those observed during training, by leveraging the knowledge of human motion contained in GPTs models. These simpler movements are then combined into a single, realistic animation using the properties of diffusion models. Our claim is that this decomposition and subsequent recombination of simple movements can synthesize an animation that accurately represents the complex input action. This method operates during the inference phase and can be integrated with any pre-trained diffusion model, enabling the synthesis of motion classes not present in the training data. We evaluate our method by dividing two benchmark human motion datasets into basic and complex actions, and then compare its performance against the state-of-the-art.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "13 pages, 6 figures"
    },
    {
        "paper id": "2409.11941",
        "abstract url": "https://arxiv.org/abs/2409.11941",
        "title": "GauTOAO: Gaussian-based Task-Oriented Affordance of Objects",
        "rating": "-1",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "3D"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "When your robot grasps an object using dexterous hands or grippers, it should understand the Task-Oriented Affordances of the Object(TOAO), as different tasks often require attention to specific parts of the object. To address this challenge, we propose GauTOAO, a Gaussian-based framework for Task-Oriented Affordance of Objects, which leverages vision-language models in a zero-shot manner to predict affordance-relevant regions of an object, given a natural language query. Our approach introduces a new paradigm: \"static camera, moving object,\" allowing the robot to better observe and understand the object in hand during manipulation. GauTOAO addresses the limitations of existing methods, which often lack effective spatial grouping, by extracting a comprehensive 3D object mask using DINO features. This mask is then used to conditionally query gaussians, producing a refined semantic distribution over the object for the specified task. This approach results in more accurate TOAO extraction, enhancing the robot's understanding of the object and improving task performance. We validate the effectiveness of GauTOAO through real-world experiments, demonstrating its capability to generalize across various tasks.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2409.11960",
        "abstract url": "https://arxiv.org/abs/2409.11960",
        "title": "A Chinese Continuous Sign Language Dataset Based on Complex Environments",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The current bottleneck in continuous sign language recognition (CSLR) research lies in the fact that most publicly available datasets are limited to laboratory environments or television program recordings, resulting in a single background environment with uniform lighting, which significantly deviates from the diversity and complexity found in real-life scenarios. To address this challenge, we have constructed a new, large-scale dataset for Chinese continuous sign language (CSL) based on complex environments, termed the complex environment - chinese sign language dataset (CE-CSL). This dataset encompasses 5,988 continuous CSL video clips collected from daily life scenes, featuring more than 70 different complex backgrounds to ensure representativeness and generalization capability. To tackle the impact of complex backgrounds on CSLR performance, we propose a time-frequency network (TFNet) model for continuous sign language recognition. This model extracts frame-level features and then utilizes both temporal and spectral information to separately derive sequence features before fusion, aiming to achieve efficient and accurate CSLR. Experimental results demonstrate that our approach achieves significant performance improvements on the CE-CSL, validating its effectiveness under complex background conditions. Additionally, our proposed method has also yielded highly competitive results when applied to three publicly available CSL datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 3 figures"
    },
    {
        "paper id": "2409.11968",
        "abstract url": "https://arxiv.org/abs/2409.11968",
        "title": "Efficacy of Synthetic Data as a Benchmark",
        "rating": "-1",
        "keywords": [
            [
                "named entity recognition"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have enabled a range of applications in zero-shot and few-shot learning settings, including the generation of synthetic datasets for training and testing. However, to reliably use these synthetic datasets, it is essential to understand how representative they are of real-world data. We investigate this by assessing the effectiveness of generating synthetic data through LLM and using it as a benchmark for various NLP tasks. Our experiments across six datasets, and three different tasks, show that while synthetic data can effectively capture performance of various methods for simpler tasks, such as intent classification, it falls short for more complex tasks like named entity recognition. Additionally, we propose a new metric called the bias factor, which evaluates the biases introduced when the same LLM is used to both generate benchmarking data and to perform the tasks. We find that smaller LLMs exhibit biases towards their own generated data, whereas larger models do not. Overall, our findings suggest that the effectiveness of synthetic data as a benchmark varies depending on the task, and that practitioners should rely on data generated from multiple larger models whenever possible.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11975",
        "abstract url": "https://arxiv.org/abs/2409.11975",
        "title": "Particle-based Instance-aware Semantic Occupancy Mapping in Dynamic Environments",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Representing the 3D environment with instance-aware semantic and geometric information is crucial for interaction-aware robots in dynamic environments. Nonetheless, creating such a representation poses challenges due to sensor noise, instance segmentation and tracking errors, and the objects' dynamic motion. This paper introduces a novel particle-based instance-aware semantic occupancy map to tackle these challenges. Particles with an augmented instance state are used to estimate the Probability Hypothesis Density (PHD) of the objects and implicitly model the environment. Utilizing a State-augmented Sequential Monte Carlo PHD (S$^2$MC-PHD) filter, these particles are updated to jointly estimate occupancy status, semantic, and instance IDs, mitigating noise. Additionally, a memory module is adopted to enhance the map's responsiveness to previously observed objects. Experimental results on the Virtual KITTI 2 dataset demonstrate that the proposed approach surpasses state-of-the-art methods across multiple metrics under different noise conditions. Subsequent tests using real-world data further validate the effectiveness of the proposed approach.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11985",
        "abstract url": "https://arxiv.org/abs/2409.11985",
        "title": "An Efficient Model-Agnostic Approach for Uncertainty Estimation in Data-Restricted Pedometric Applications",
        "rating": "-1",
        "keywords": [
            [
                "agricultural"
            ],
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "This paper introduces a model-agnostic approach designed to enhance uncertainty estimation in the predictive modeling of soil properties, a crucial factor for advancing pedometrics and the practice of digital soil mapping. For addressing the typical challenge of data scarcity in soil studies, we present an improved technique for uncertainty estimation. This method is based on the transformation of regression tasks into classification problems, which not only allows for the production of reliable uncertainty estimates but also enables the application of established machine learning algorithms with competitive performance that have not yet been utilized in pedometrics. Empirical results from datasets collected from two German agricultural fields showcase the practical application of the proposed methodology. Our results and findings suggest that the proposed approach has the potential to provide better uncertainty estimation than the models commonly used in pedometrics.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "To be published in the proceedings of ICMLA 2024: 23rd International Conference on Machine Learning and Applications"
    },
    {
        "paper id": "2409.12002",
        "abstract url": "https://arxiv.org/abs/2409.12002",
        "title": "Towards Global Localization using Multi-Modal Object-Instance Re-Identification",
        "rating": "-1",
        "keywords": [
            [
                "RGB-D",
                "depth"
            ],
            [
                "Re-Identification"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Re-identification (ReID) is a critical challenge in computer vision, predominantly studied in the context of pedestrians and vehicles. However, robust object-instance ReID, which has significant implications for tasks such as autonomous exploration, long-term perception, and scene understanding, remains underexplored. In this work, we address this gap by proposing a novel dual-path object-instance re-identification transformer architecture that integrates multimodal RGB and depth information. By leveraging depth data, we demonstrate improvements in ReID across scenes that are cluttered or have varying illumination conditions. Additionally, we develop a ReID-based localization framework that enables accurate camera localization and pose identification across different viewpoints. We validate our methods using two custom-built RGB-D datasets, as well as multiple sequences from the open-source TUM RGB-D datasets. Our approach demonstrates significant improvements in both object instance ReID (mAP of 75.18) and localization accuracy (success rate of 83% on TUM-RGBD), highlighting the essential role of object ReID in advancing robotic perception. Our models, frameworks, and datasets have been made publicly available.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "8 pages, 5 figures, 3 tables. Submitted to ICRA 2025"
    },
    {
        "paper id": "2409.12007",
        "abstract url": "https://arxiv.org/abs/2409.12007",
        "title": "Real-Time-Feasible Collision-Free Motion Planning For Ellipsoidal Objects",
        "rating": "-1",
        "keywords": [
            [
                "robotics"
            ]
        ],
        "abstract": "Online planning of collision-free trajectories is a fundamental task for robotics and self-driving car applications. This paper revisits collision avoidance between ellipsoidal objects using differentiable constraints. Two ellipsoids do not overlap if and only if the endpoint of the vector between the center points of the ellipsoids does not lie in the interior of the Minkowski sum of the ellipsoids. This condition is formulated using a parametric over-approximation of the Minkowski sum, which can be made tight in any given direction. The resulting collision avoidance constraint is included in an optimal control problem (OCP) and evaluated in comparison to the separating-hyperplane approach. Not only do we observe that the Minkowski-sum formulation is computationally more efficient in our experiments, but also that using pre-determined over-approximation parameters based on warm-start trajectories leads to a very limited increase in suboptimality. This gives rise to a novel real-time scheme for collision-free motion planning with model predictive control (MPC). Both the real-time feasibility and the effectiveness of the constraint formulation are demonstrated in challenging real-world experiments.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12016",
        "abstract url": "https://arxiv.org/abs/2409.12016",
        "title": "Computational Imaging for Long-Term Prediction of Solar Irradiance",
        "rating": "-1",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The occlusion of the sun by clouds is one of the primary sources of uncertainties in solar power generation, and is a factor that affects the wide-spread use of solar power as a primary energy source. Real-time forecasting of cloud movement and, as a result, solar irradiance is necessary to schedule and allocate energy across grid-connected photovoltaic systems. Previous works monitored cloud movement using wide-angle field of view imagery of the sky. However, such images have poor resolution for clouds that appear near the horizon, which reduces their effectiveness for long term prediction of solar occlusion. Specifically, to be able to predict occlusion of the sun over long time periods, clouds that are near the horizon need to be detected, and their velocities estimated precisely. To enable such a system, we design and deploy a catadioptric system that delivers wide-angle imagery with uniform spatial resolution of the sky over its field of view. To enable prediction over a longer time horizon, we design an algorithm that uses carefully selected spatio-temporal slices of the imagery using estimated wind direction and velocity as inputs. Using ray-tracing simulations as well as a real testbed deployed outdoors, we show that the system is capable of predicting solar occlusion as well as irradiance for tens of minutes in the future, which is an order of magnitude improvement over prior work.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12026",
        "abstract url": "https://arxiv.org/abs/2409.12026",
        "title": "On Vision Transformers for Classification Tasks in Side-Scan Sonar Imagery",
        "rating": "-1",
        "keywords": [
            [
                "seafloor"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Side-scan sonar (SSS) imagery presents unique challenges in the classification of man-made objects on the seafloor due to the complex and varied underwater environments. Historically, experts have manually interpreted SSS images, relying on conventional machine learning techniques with hand-crafted features. While Convolutional Neural Networks (CNNs) significantly advanced automated classification in this domain, they often fall short when dealing with diverse seafloor textures, such as rocky or ripple sand bottoms, where false positive rates may increase. Recently, Vision Transformers (ViTs) have shown potential in addressing these limitations by utilizing a self-attention mechanism to capture global information in image patches, offering more flexibility in processing spatial hierarchies. This paper rigorously compares the performance of ViT models alongside commonly used CNN architectures, such as ResNet and ConvNext, for binary classification tasks in SSS imagery. The dataset encompasses diverse geographical seafloor types and is balanced between the presence and absence of man-made objects. ViT-based models exhibit superior classification performance across f1-score, precision, recall, and accuracy metrics, although at the cost of greater computational resources. CNNs, with their inductive biases, demonstrate better computational efficiency, making them suitable for deployment in resource-constrained environments like underwater vehicles. Future research directions include exploring self-supervised learning for ViTs and multi-modal fusion to further enhance performance in challenging underwater environments.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12031",
        "abstract url": "https://arxiv.org/abs/2409.12031",
        "title": "PhysMamba: Efficient Remote Physiological Measurement with SlowFast Temporal Difference Mamba",
        "rating": "-1",
        "keywords": [
            [
                "Facial",
                "Physiological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Facial-video based Remote photoplethysmography (rPPG) aims at measuring physiological signals and monitoring heart activity without any contact, showing significant potential in various applications. Previous deep learning based rPPG measurement are primarily based on CNNs and Transformers. However, the limited receptive fields of CNNs restrict their ability to capture long-range spatio-temporal dependencies, while Transformers also struggle with modeling long video sequences with high complexity. Recently, the state space models (SSMs) represented by Mamba are known for their impressive performance on capturing long-range dependencies from long sequences. In this paper, we propose the PhysMamba, a Mamba-based framework, to efficiently represent long-range physiological dependencies from facial videos. Specifically, we introduce the Temporal Difference Mamba block to first enhance local dynamic differences and further model the long-range spatio-temporal context. Moreover, a dual-stream SlowFast architecture is utilized to fuse the multi-scale temporal features. Extensive experiments are conducted on three benchmark datasets to demonstrate the superiority and efficiency of PhysMamba. The codes are available at https://github.com/Chaoqi31/PhysMamba",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by CCBR 2024"
    },
    {
        "paper id": "2409.12040",
        "abstract url": "https://arxiv.org/abs/2409.12040",
        "title": "SFDA-rPPG: Source-Free Domain Adaptive Remote Physiological Measurement with Spatio-Temporal Consistency",
        "rating": "-1",
        "keywords": [
            [
                "facial",
                "Physiological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Remote Photoplethysmography (rPPG) is a non-contact method that uses facial video to predict changes in blood volume, enabling physiological metrics measurement. Traditional rPPG models often struggle with poor generalization capacity in unseen domains. Current solutions to this problem is to improve its generalization in the target domain through Domain Generalization (DG) or Domain Adaptation (DA). However, both traditional methods require access to both source domain data and target domain data, which cannot be implemented in scenarios with limited access to source data, and another issue is the privacy of accessing source domain data. In this paper, we propose the first Source-free Domain Adaptation benchmark for rPPG measurement (SFDA-rPPG), which overcomes these limitations by enabling effective domain adaptation without access to source domain data. Our framework incorporates a Three-Branch Spatio-Temporal Consistency Network (TSTC-Net) to enhance feature consistency across domains. Furthermore, we propose a new rPPG distribution alignment loss based on the Frequency-domain Wasserstein Distance (FWD), which leverages optimal transport to align power spectrum distributions across domains effectively and further enforces the alignment of the three branches. Extensive cross-domain experiments and ablation studies demonstrate the effectiveness of our proposed method in source-free domain adaptation settings. Our findings highlight the significant contribution of the proposed FWD loss for distributional alignment, providing a valuable reference for future research and applications. The source code is available at https://github.com/XieYiping66/SFDA-rPPG",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12046",
        "abstract url": "https://arxiv.org/abs/2409.12046",
        "title": "Using Large Language Models to Generate Clinical Trial Tables and Figures",
        "rating": "-1",
        "keywords": [
            [
                "Clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Tables, figures, and listings (TFLs) are essential tools for summarizing clinical trial data. Creation of TFLs for reporting activities is often a time-consuming task encountered routinely during the execution of clinical trials. This study explored the use of large language models (LLMs) to automate the generation of TFLs through prompt engineering and few-shot transfer learning. Using public clinical trial data in ADaM format, our results demonstrated that LLMs can efficiently generate TFLs with prompt instructions, showcasing their potential in this domain. Furthermore, we developed a conservational agent named Clinical Trial TFL Generation Agent: An app that matches user queries to predefined prompts that produce customized programs to generate specific predefined TFLs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12094",
        "abstract url": "https://arxiv.org/abs/2409.12094",
        "title": "A machine learning framework for acoustic reflector mapping",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "robot",
                "navigation"
            ]
        ],
        "abstract": "Sonar-based indoor mapping systems have been widely employed in robotics for several decades. While such systems are still the mainstream in underwater and pipe inspection settings, the vulnerability to noise reduced, over time, their general widespread usage in favour of other modalities(\\textit{e.g.}, cameras, lidars), whose technologies were encountering, instead, extraordinary advancements. Nevertheless, mapping physical environments using acoustic signals and echolocation can bring significant benefits to robot navigation in adverse scenarios, thanks to their complementary characteristics compared to other sensors. Cameras and lidars, indeed, struggle in harsh weather conditions, when dealing with lack of illumination, or with non-reflective walls. Yet, for acoustic sensors to be able to generate accurate maps, noise has to be properly and effectively handled. Traditional signal processing techniques are not always a solution in those cases. In this paper, we propose a framework where machine learning is exploited to aid more traditional signal processing methods to cope with background noise, by removing outliers and artefacts from the generated maps using acoustic sensors. Our goal is to demonstrate that the performance of traditional echolocation mapping techniques can be greatly enhanced, even in particularly noisy conditions, facilitating the employment of acoustic sensors in state-of-the-art multi-modal robot navigation systems. Our simulated evaluation demonstrates that the system can reliably operate at an SNR of $-10$dB. Moreover, we also show that the proposed method is capable of operating in different reverberate environments. In this paper, we also use the proposed method to map the outline of a simulated room using a robotic platform.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12106",
        "abstract url": "https://arxiv.org/abs/2409.12106",
        "title": "Measuring Human and AI Values based on Generative Psychometrics with Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Human values and their measurement are long-standing interdisciplinary inquiry. Recent advances in AI have sparked renewed interest in this area, with large language models (LLMs) emerging as both tools and subjects of value measurement. This work introduces Generative Psychometrics for Values (GPV), an LLM-based, data-driven value measurement paradigm, theoretically grounded in text-revealed selective perceptions. We begin by fine-tuning an LLM for accurate perception-level value measurement and verifying the capability of LLMs to parse texts into perceptions, forming the core of the GPV pipeline. Applying GPV to human-authored blogs, we demonstrate its stability, validity, and superiority over prior psychological tools. Then, extending GPV to LLM value measurement, we advance the current art with 1) a psychometric methodology that measures LLM values based on their scalable and free-form outputs, enabling context-specific measurement; 2) a comparative analysis of measurement paradigms, indicating response biases of prior methods; and 3) an attempt to bridge LLM values and their safety, revealing the predictive power of different value systems and the impacts of various values on LLM safety. Through interdisciplinary efforts, we aim to leverage AI for next-generation psychometrics and psychometrics for value-aligned AI.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12108",
        "abstract url": "https://arxiv.org/abs/2409.12108",
        "title": "SPRMamba: Surgical Phase Recognition for Endoscopic Submucosal Dissection with Mamba",
        "rating": "-1",
        "keywords": [
            [
                "Surgical",
                "Surgery",
                "cancer",
                "clinical",
                "Endoscopic",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Endoscopic Submucosal Dissection (ESD) is a minimally invasive procedure initially designed for the treatment of early gastric cancer but is now widely used for various gastrointestinal lesions. Computer-assisted Surgery systems have played a crucial role in improving the precision and safety of ESD procedures, however, their effectiveness is limited by the accurate recognition of surgical phases. The intricate nature of ESD, with different lesion characteristics and tissue structures, presents challenges for real-time surgical phase recognition algorithms. Existing surgical phase recognition algorithms struggle to efficiently capture temporal contexts in video-based scenarios, leading to insufficient performance. To address these issues, we propose SPRMamba, a novel Mamba-based framework for ESD surgical phase recognition. SPRMamba leverages the strengths of Mamba for long-term temporal modeling while introducing the Scaled Residual TranMamba block to enhance the capture of fine-grained details, overcoming the limitations of traditional temporal models like Temporal Convolutional Networks and Transformers. Moreover, a Temporal Sample Strategy is introduced to accelerate the processing, which is essential for real-time phase recognition in clinical settings. Extensive testing on the ESD385 dataset and the cholecystectomy Cholec80 dataset demonstrates that SPRMamba surpasses existing state-of-the-art methods and exhibits greater robustness across various surgical phase recognition tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12112",
        "abstract url": "https://arxiv.org/abs/2409.12112",
        "title": "Pareto Data Framework: Steps Towards Resource-Efficient Decision Making Using Minimum Viable Data (MVD)",
        "rating": "-1",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces the Pareto Data Framework, an approach for identifying and selecting the Minimum Viable Data (MVD) required for enabling machine learning applications on constrained platforms such as embedded systems, mobile devices, and Internet of Things (IoT) devices. We demonstrate that strategic data reduction can maintain high performance while significantly reducing bandwidth, energy, computation, and storage costs. The framework identifies Minimum Viable Data (MVD) to optimize efficiency across resource-constrained environments without sacrificing performance. It addresses common inefficient practices in an IoT application such as overprovisioning of sensors and overprecision, and oversampling of signals, proposing scalable solutions for optimal sensor selection, signal extraction and transmission, and data representation. An experimental methodology demonstrates effective acoustic data characterization after downsampling, quantization, and truncation to simulate reduced-fidelity sensors and network and storage constraints; results shows that performance can be maintained up to 95\\% with sample rates reduced by 75\\% and bit depths and clip length reduced by 50\\% which translates into substantial cost and resource reduction. These findings have implications on the design and development of constrained systems. The paper also discusses broader implications of the framework, including the potential to democratize advanced AI technologies across IoT applications and sectors such as agriculture, transportation, and manufacturing to improve access and multiply the benefits of data-driven insights.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12139",
        "abstract url": "https://arxiv.org/abs/2409.12139",
        "title": "Takin: A Cohort of Superior Quality Zero-shot Speech Generation Models",
        "rating": "-1",
        "keywords": [
            [
                "neural codec"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "With the advent of the big data and large language model era, zero-shot personalized rapid customization has emerged as a significant trend. In this report, we introduce Takin AudioLLM, a series of techniques and models, mainly including Takin TTS, Takin VC, and Takin Morphing, specifically designed for audiobook production. These models are capable of zero-shot speech production, generating high-quality speech that is nearly indistinguishable from real human speech and facilitating individuals to customize the speech content according to their own needs. Specifically, we first introduce Takin TTS, a neural codec language model that builds upon an enhanced neural speech codec and a multi-task training framework, capable of generating high-fidelity natural speech in a zero-shot way. For Takin VC, we advocate an effective content and timbre joint modeling approach to improve the speaker similarity, while advocating for a conditional flow matching based decoder to further enhance its naturalness and expressiveness. Last, we propose the Takin Morphing system with highly decoupled and advanced timbre and prosody modeling approaches, which enables individuals to customize speech production with their preferred timbre and prosody in a precise and controllable manner. Extensive experiments validate the effectiveness and robustness of our Takin AudioLLM series models. For detailed demos, please refer to https://takinaudiollm.github.io.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12153",
        "abstract url": "https://arxiv.org/abs/2409.12153",
        "title": "Robots that Learn to Safely Influence via Prediction-Informed Reach-Avoid Dynamic Games",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Robots can influence people to accomplish their tasks more efficiently: autonomous cars can inch forward at an intersection to pass through, and tabletop manipulators can go for an object on the table first. However, a robot's ability to influence can also compromise the safety of nearby people if naively executed. In this work, we pose and solve a novel robust reach-avoid dynamic game which enables robots to be maximally influential, but only when a safety backup control exists. On the human side, we model the human's behavior as goal-driven but conditioned on the robot's plan, enabling us to capture influence. On the robot side, we solve the dynamic game in the joint physical and belief space, enabling the robot to reason about how its uncertainty in human behavior will evolve over time. We instantiate our method, called SLIDE (Safely Leveraging Influence in Dynamic Environments), in a high-dimensional (39-D) simulated human-robot collaborative manipulation task solved via offline game-theoretic reinforcement learning. We compare our approach to a robust baseline that treats the human as a worst-case adversary, a safety controller that does not explicitly reason about influence, and an energy-function-based safety shield. We find that SLIDE consistently enables the robot to leverage the influence it has on the human when it is safe to do so, ultimately allowing the robot to be less conservative while still ensuring a high safety rate during task execution.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12155",
        "abstract url": "https://arxiv.org/abs/2409.12155",
        "title": "Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT",
        "rating": "-1",
        "keywords": [
            [
                "CT",
                "clinical",
                "tumor",
                "lesion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Lesion segmentation in PET/CT imaging is essential for precise tumor characterization, which supports personalized treatment planning and enhances diagnostic precision in oncology. However, accurate manual segmentation of lesions is time-consuming and prone to inter-observer variability. Given the rising demand and clinical use of PET/CT, automated segmentation methods, particularly deep-learning-based approaches, have become increasingly more relevant. The autoPET III Challenge focuses on advancing automated segmentation of tumor lesions in PET/CT images in a multitracer multicenter setting, addressing the clinical need for quantitative, robust, and generalizable solutions. Building on previous challenges, the third iteration of the autoPET challenge introduces a more diverse dataset featuring two different tracers (FDG and PSMA) from two clinical centers. To this extent, we developed a classifier that identifies the tracer of the given PET/CT based on the Maximum Intensity Projection of the PET scan. We trained two individual nnUNet-ensembles for each tracer where anatomical labels are included as a multi-label task to enhance the model's performance. Our final submission achieves cross-validation Dice scores of 76.90% and 61.33% for the publicly available FDG and PSMA datasets, respectively. The code is available at https://github.com/hakal104/autoPETIII/ .",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "AutoPET III challenge submission"
    },
    {
        "paper id": "2409.12159",
        "abstract url": "https://arxiv.org/abs/2409.12159",
        "title": "WeHelp: A Shared Autonomy System for Wheelchair Users",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "There is a large population of wheelchair users. Most of the wheelchair users need help with daily tasks. However, according to recent reports, their needs are not properly satisfied due to the lack of caregivers. Therefore, in this project, we develop WeHelp, a shared autonomy system aimed for wheelchair users. A robot with a WeHelp system has three modes, following mode, remote control mode and tele-operation mode. In the following mode, the robot follows the wheelchair user automatically via visual tracking. The wheelchair user can ask the robot to follow them from behind, by the left or by the right. When the wheelchair user asks for help, the robot will recognize the command via speech recognition, and then switch to the teleoperation mode or remote control mode. In the teleoperation mode, the wheelchair user takes over the robot with a joy stick and controls the robot to complete some complex tasks for their needs, such as opening doors, moving obstacles on the way, reaching objects on a high shelf or on the low ground, etc. In the remote control mode, a remote assistant takes over the robot and helps the wheelchair user complete some complex tasks for their needs. Our evaluation shows that the pipeline is useful and practical for wheelchair users. Source code and demo of the paper are available at \\url{https://github.com/Walleclipse/WeHelp}.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12162",
        "abstract url": "https://arxiv.org/abs/2409.12162",
        "title": "Precise Forecasting of Sky Images Using Spatial Warping",
        "rating": "-1",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The intermittency of solar power, due to occlusion from cloud cover, is one of the key factors inhibiting its widespread use in both commercial and residential settings. Hence, real-time forecasting of solar irradiance for grid-connected photovoltaic systems is necessary to schedule and allocate resources across the grid. Ground-based imagers that capture wide field-of-view images of the sky are commonly used to monitor cloud movement around a particular site in an effort to forecast solar irradiance. However, these wide FOV imagers capture a distorted image of sky image, where regions near the horizon are heavily compressed. This hinders the ability to precisely predict cloud motion near the horizon which especially affects prediction over longer time horizons. In this work, we combat the aforementioned constraint by introducing a deep learning method to predict a future sky image frame with higher resolution than previous methods. Our main contribution is to derive an optimal warping method to counter the adverse affects of clouds at the horizon, and learn a framework for future sky image prediction which better determines cloud evolution for longer time horizons.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12167",
        "abstract url": "https://arxiv.org/abs/2409.12167",
        "title": "multiPI-TransBTS: A Multi-Path Learning Framework for Brain Tumor Image Segmentation Based on Multi-Physical Information",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "MRI",
                "clinical",
                "Tumor"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Brain Tumor Segmentation (BraTS) plays a critical role in clinical diagnosis, treatment planning, and monitoring the progression of brain tumors. However, due to the variability in tumor appearance, size, and intensity across different MRI modalities, automated segmentation remains a challenging task. In this study, we propose a novel Transformer-based framework, multiPI-TransBTS, which integrates multi-physical information to enhance segmentation accuracy. The model leverages spatial information, semantic information, and multi-modal imaging data, addressing the inherent heterogeneity in brain tumor characteristics. The multiPI-TransBTS framework consists of an encoder, an Adaptive Feature Fusion (AFF) module, and a multi-source, multi-scale feature decoder. The encoder incorporates a multi-branch architecture to separately extract modality-specific features from different MRI sequences. The AFF module fuses information from multiple sources using channel-wise and element-wise attention, ensuring effective feature recalibration. The decoder combines both common and task-specific features through a Task-Specific Feature Introduction (TSFI) strategy, producing accurate segmentation outputs for Whole Tumor (WT), Tumor Core (TC), and Enhancing Tumor (ET) regions. Comprehensive evaluations on the BraTS2019 and BraTS2020 datasets demonstrate the superiority of multiPI-TransBTS over the state-of-the-art methods. The model consistently achieves better Dice coefficients, Hausdorff distances, and Sensitivity scores, highlighting its effectiveness in addressing the BraTS challenges. Our results also indicate the need for further exploration of the balance between precision and recall in the ET segmentation task. The proposed framework represents a significant advancement in BraTS, with potential implications for improving clinical outcomes for brain tumor patients.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12172",
        "abstract url": "https://arxiv.org/abs/2409.12172",
        "title": "You Only Read Once (YORO): Learning to Internalize Database Knowledge for Text-to-SQL",
        "rating": "-1",
        "keywords": [
            [
                "SQL"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "While significant progress has been made on the text-to-SQL task, recent solutions repeatedly encode the same database schema for every question, resulting in unnecessary high inference cost and often overlooking crucial database knowledge. To address these issues, we propose You Only Read Once (YORO), a novel paradigm that directly internalizes database knowledge into the parametric knowledge of a text-to-SQL model during training and eliminates the need for schema encoding during inference. YORO significantly reduces the input token length by 66%-98%. Despite its shorter inputs, our empirical results demonstrate YORO's competitive performances with traditional systems on three benchmarks as well as its significant outperformance on large databases. Furthermore, YORO excels in handling questions with challenging value retrievals such as abbreviation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12190",
        "abstract url": "https://arxiv.org/abs/2409.12190",
        "title": "Bundle Adjustment in the Eager Mode",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Bundle adjustment (BA) is a critical technique in various robotic applications, such as simultaneous localization and mapping (SLAM), augmented reality (AR), and photogrammetry. BA optimizes parameters such as camera poses and 3D landmarks to align them with observations. With the growing importance of deep learning in perception systems, there is an increasing need to integrate BA with deep learning frameworks for enhanced reliability and performance. However, widely-used C++-based BA frameworks, such as GTSAM, g$^2$o, and Ceres, lack native integration with modern deep learning libraries like PyTorch. This limitation affects their flexibility, adaptability, ease of debugging, and overall implementation efficiency. To address this gap, we introduce an eager-mode BA framework seamlessly integrated with PyPose, providing PyTorch-compatible interfaces with high efficiency. Our approach includes GPU-accelerated, differentiable, and sparse operations designed for 2nd-order optimization, Lie group and Lie algebra operations, and linear solvers. Our eager-mode BA on GPU demonstrates substantial runtime efficiency, achieving an average speedup of 18.5$\\times$, 22$\\times$, and 23$\\times$ compared to GTSAM, g$^2$o, and Ceres, respectively.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12192",
        "abstract url": "https://arxiv.org/abs/2409.12192",
        "title": "DynaMo: In-Domain Dynamics Pretraining for Visuo-Motor Control",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Robot"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Imitation learning has proven to be a powerful tool for training complex visuomotor policies. However, current methods often require hundreds to thousands of expert demonstrations to handle high-dimensional visual observations. A key reason for this poor data efficiency is that visual representations are predominantly either pretrained on out-of-domain data or trained directly through a behavior cloning objective. In this work, we present DynaMo, a new in-domain, self-supervised method for learning visual representations. Given a set of expert demonstrations, we jointly learn a latent inverse dynamics model and a forward dynamics model over a sequence of image embeddings, predicting the next frame in latent space, without augmentations, contrastive sampling, or access to ground truth actions. Importantly, DynaMo does not require any out-of-domain data such as Internet datasets or cross-embodied datasets. On a suite of six simulated and real environments, we show that representations learned with DynaMo significantly improve downstream imitation learning performance over prior self-supervised learning objectives, and pretrained representations. Gains from using DynaMo hold across policy classes such as Behavior Transformer, Diffusion Policy, MLP, and nearest neighbors. Finally, we ablate over key components of DynaMo and measure its impact on downstream policy performance. Robot videos are best viewed at https://dynamo-ssl.github.io",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11820",
        "abstract url": "https://arxiv.org/abs/2409.11820",
        "title": "Optimizing Job Shop Scheduling in the Furniture Industry: A Reinforcement Learning Approach Considering Machine Setup, Batch Variability, and Intralogistics",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper explores the potential application of Deep Reinforcement Learning in the furniture industry. To offer a broad product portfolio, most furniture manufacturers are organized as a job shop, which ultimately results in the Job Shop Scheduling Problem (JSSP). The JSSP is addressed with a focus on extending traditional models to better represent the complexities of real-world production environments. Existing approaches frequently fail to consider critical factors such as machine setup times or varying batch sizes. A concept for a model is proposed that provides a higher level of information detail to enhance scheduling accuracy and efficiency. The concept introduces the integration of DRL for production planning, particularly suited to batch production industries such as the furniture industry. The model extends traditional approaches to JSSPs by including job volumes, buffer management, transportation times, and machine setup times. This enables more precise forecasting and analysis of production flows and processes, accommodating the variability and complexity inherent in real-world manufacturing processes. The RL agent learns to optimize scheduling decisions. It operates within a discrete action space, making decisions based on detailed observations. A reward function guides the agent's decision-making process, thereby promoting efficient scheduling and meeting production deadlines. Two integration strategies for implementing the RL agent are discussed: episodic planning, which is suitable for low-automation environments, and continuous planning, which is ideal for highly automated plants. While episodic planning can be employed as a standalone solution, the continuous planning approach necessitates the integration of the agent with ERP and Manufacturing Execution Systems. This integration enables real-time adjustments to production schedules based on dynamic changes.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "18 pages, 8 pages"
    },
    {
        "paper id": "2409.11835",
        "abstract url": "https://arxiv.org/abs/2409.11835",
        "title": "DPI-TTS: Directional Patch Interaction for Fast-Converging and Style Temporal Modeling in Text-to-Speech",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Text-to-Speech"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "In recent years, speech diffusion models have advanced rapidly. Alongside the widely used U-Net architecture, transformer-based models such as the Diffusion Transformer (DiT) have also gained attention. However, current DiT speech models treat Mel spectrograms as general images, which overlooks the specific acoustic properties of speech. To address these limitations, we propose a method called Directional Patch Interaction for Text-to-Speech (DPI-TTS), which builds on DiT and achieves fast training without compromising accuracy. Notably, DPI-TTS employs a low-to-high frequency, frame-by-frame progressive inference approach that aligns more closely with acoustic properties, enhancing the naturalness of the generated speech. Additionally, we introduce a fine-grained style temporal modeling method that further improves speaker style similarity. Experimental results demonstrate that our method increases the training speed by nearly 2 times and significantly outperforms the baseline models.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "Submitted to ICASSP2025"
    },
    {
        "paper id": "2409.11845",
        "abstract url": "https://arxiv.org/abs/2409.11845",
        "title": "Law-based and standards-oriented approach for privacy impact assessment in medical devices: a topic for lawyers, engineers and healthcare practitioners in MedTech",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "health",
                "healthcare"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Background: The integration of the General Data Protection Regulation (GDPR) and the Medical Device Regulation (MDR) creates complexities in conducting Data Protection Impact Assessments (DPIAs) for medical devices. The adoption of non-binding standards like ISO and IEC can harmonize these processes by enhancing accountability and privacy by design. Methods: This study employs a multidisciplinary literature review, focusing on GDPR and MDR intersection in medical devices that process personal health data. It evaluates key standards, including ISO/IEC 29134 and IEC 62304, to propose a unified approach for DPIAs that aligns with legal and technical frameworks. Results: The analysis reveals the benefits of integrating ISO/IEC standards into DPIAs, which provide detailed guidance on implementing privacy by design, risk assessment, and mitigation strategies specific to medical devices. The proposed framework ensures that DPIAs are living documents, continuously updated to adapt to evolving data protection challenges. Conclusions: A unified approach combining European Union (EU) regulations and international standards offers a robust framework for conducting DPIAs in medical devices. This integration balances security, innovation, and privacy, enhancing compliance and fostering trust in medical technologies. The study advocates for leveraging both hard law and standards to systematically address privacy and safety in the design and operation of medical devices, thereby raising the maturity of the MedTech ecosystem.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "20 pages, 1 table"
    },
    {
        "paper id": "2409.11847",
        "abstract url": "https://arxiv.org/abs/2409.11847",
        "title": "An efficient wavelet-based physics-informed neural networks for singularly perturbed problems",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Physics-informed neural networks (PINNs) are a class of deep learning models that utilize physics as differential equations to address complex problems, including ones that may involve limited data availability. However, tackling solutions of differential equations with oscillations or singular perturbations and shock-like structures becomes challenging for PINNs. Considering these challenges, we designed an efficient wavelet-based PINNs (W-PINNs) model to solve singularly perturbed differential equations. Here, we represent the solution in wavelet space using a family of smooth-compactly supported wavelets. This framework represents the solution of a differential equation with significantly fewer degrees of freedom while still retaining in capturing, identifying, and analyzing the local structure of complex physical phenomena. The architecture allows the training process to search for a solution within wavelet space, making the process faster and more accurate. The proposed model does not rely on automatic differentiations for derivatives involved in differential equations and does not require any prior information regarding the behavior of the solution, such as the location of abrupt features. Thus, through a strategic fusion of wavelets with PINNs, W-PINNs excel at capturing localized nonlinear information, making them well-suited for problems showing abrupt behavior in certain regions, such as singularly perturbed problems. The efficiency and accuracy of the proposed neural network model are demonstrated in various test problems, i.e., highly singularly perturbed nonlinear differential equations, the FitzHugh-Nagumo (FHN), and Predator-prey interaction models. The proposed design model exhibits impressive comparisons with traditional PINNs and the recently developed wavelet-based PINNs, which use wavelets as an activation function for solving nonlinear differential equations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 12 figures"
    },
    {
        "paper id": "2409.11862",
        "abstract url": "https://arxiv.org/abs/2409.11862",
        "title": "Location based Probabilistic Load Forecasting of EV Charging Sites: Deep Transfer Learning with Multi-Quantile Temporal Convolutional Network",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Electrification of vehicles is a potential way of reducing fossil fuel usage and thus lessening environmental pollution. Electric Vehicles (EVs) of various types for different transport modes (including air, water, and land) are evolving. Moreover, different EV user groups (commuters, commercial or domestic users, drivers) may use different charging infrastructures (public, private, home, and workplace) at various times. Therefore, usage patterns and energy demand are very stochastic. Characterizing and forecasting the charging demand of these diverse EV usage profiles is essential in preventing power outages. Previously developed data-driven load models are limited to specific use cases and locations. None of these models are simultaneously adaptive enough to transfer knowledge of day-ahead forecasting among EV charging sites of diverse locations, trained with limited data, and cost-effective. This article presents a location-based load forecasting of EV charging sites using a deep Multi-Quantile Temporal Convolutional Network (MQ-TCN) to overcome the limitations of earlier models. We conducted our experiments on data from four charging sites, namely Caltech, JPL, Office-1, and NREL, which have diverse EV user types like students, full-time and part-time employees, random visitors, etc. With a Prediction Interval Coverage Probability (PICP) score of 93.62\\%, our proposed deep MQ-TCN model exhibited a remarkable 28.93\\% improvement over the XGBoost model for a day-ahead load forecasting at the JPL charging site. By transferring knowledge with the inductive Transfer Learning (TL) approach, the MQ-TCN model achieved a 96.88\\% PICP score for the load forecasting task at the NREL site using only two weeks of data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "11 pages, 10 figures"
    },
    {
        "paper id": "2409.11897",
        "abstract url": "https://arxiv.org/abs/2409.11897",
        "title": "Secure Control Systems for Autonomous Quadrotors against Cyber-Attacks",
        "rating": "-1.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The problem of safety for robotic systems has been extensively studied. However, little attention has been given to security issues for three-dimensional systems, such as quadrotors. Malicious adversaries can compromise robot sensors and communication networks, causing incidents, achieving illegal objectives, or even injuring people. This study first designs an intelligent control system for autonomous quadrotors. Then, it investigates the problems of optimal false data injection attack scheduling and countermeasure design for unmanned aerial vehicles. Using a state-of-the-art deep learning-based approach, an optimal false data injection attack scheme is proposed to deteriorate a quadrotor's tracking performance with limited attack energy. Subsequently, an optimal tracking control strategy is learned to mitigate attacks and recover the quadrotor's tracking performance. We base our work on Agilicious, a state-of-the-art quadrotor recently deployed for autonomous settings. This paper is the first in the United Kingdom to deploy this quadrotor and implement reinforcement learning on its platform. Therefore, to promote easy reproducibility with minimal engineering overhead, we further provide (1) a comprehensive breakdown of this quadrotor, including software stacks and hardware alternatives; (2) a detailed reinforcement-learning framework to train autonomous controllers on Agilicious agents; and (3) a new open-source environment that builds upon PyFlyt for future reinforcement learning research on Agilicious platforms. Both simulated and real-world experiments are conducted to show the effectiveness of the proposed frameworks in section 5.2.",
        "subjects": [
            "cs.RO",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "The paper is based on an undergraduate thesis and is not intended for publication in a journal"
    },
    {
        "paper id": "2409.11972",
        "abstract url": "https://arxiv.org/abs/2409.11972",
        "title": "Metric-Semantic Factor Graph Generation based on Graph Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "SLAM"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Understanding the relationships between geometric structures and semantic concepts is crucial for building accurate models of complex environments. In indoors, certain spatial constraints, such as the relative positioning of planes, remain consistent despite variations in layout. This paper explores how these invariant relationships can be captured in a graph SLAM framework by representing high-level concepts like rooms and walls, linking them to geometric elements like planes through an optimizable factor graph. Several efforts have tackled this issue with add-hoc solutions for each concept generation and with manually-defined factors. This paper proposes a novel method for metric-semantic factor graph generation which includes defining a semantic scene graph, integrating geometric information, and learning the interconnecting factors, all based on Graph Neural Networks (GNNs). An edge classification network (G-GNN) sorts the edges between planes into same room, same wall or none types. The resulting relations are clustered, generating a room or wall for each cluster. A second family of networks (F-GNN) infers the geometrical origin of the new nodes. The definition of the factors employs the same F-GNN used for the metric attribute of the generated nodes. Furthermore, share the new factor graph with the S-Graphs+ algorithm, extending its graph expressiveness and scene representation with the ultimate goal of improving the SLAM performance. The complexity of the environments is increased to N-plane rooms by training the networks on L-shaped rooms. The framework is evaluated in synthetic and simulated scenarios as no real datasets of the required complex layouts are available.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Submitted to ICRA 2025"
    },
    {
        "paper id": "2409.11992",
        "abstract url": "https://arxiv.org/abs/2409.11992",
        "title": "Additive-feature-attribution methods: a review on explainable artificial intelligence for fluid dynamics and heat transfer",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The use of data-driven methods in fluid mechanics has surged dramatically in recent years due to their capacity to adapt to the complex and multi-scale nature of turbulent flows, as well as to detect patterns in large-scale simulations or experimental tests. In order to interpret the relationships generated in the models during the training process, numerical attributions need to be assigned to the input features. One important example are the additive-feature-attribution methods. These explainability methods link the input features with the model prediction, providing an interpretation based on a linear formulation of the models. The SHapley Additive exPlanations (SHAP values) are formulated as the only possible interpretation that offers a unique solution for understanding the model. In this manuscript, the additive-feature-attribution methods are presented, showing four common implementations in the literature: kernel SHAP, tree SHAP, gradient SHAP, and deep SHAP. Then, the main applications of the additive-feature-attribution methods are introduced, dividing them into three main groups: turbulence modeling, fluid-mechanics fundamentals, and applied problems in fluid dynamics and heat transfer. This review shows thatexplainability techniques, and in particular additive-feature-attribution methods, are crucial for implementing interpretable and physics-compliant deep-learning models in the fluid-mechanics field.",
        "subjects": [
            "physics.flu-dyn",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12047",
        "abstract url": "https://arxiv.org/abs/2409.12047",
        "title": "A Survey-Based Quantitative Analysis of Stress Factors and Their Impacts Among Cybersecurity Professionals",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "This study investigates the prevalence and underlying causes of work-related stress and burnout among cybersecurity professionals using a quantitative survey approach guided by the Job Demands-Resources model. Analysis of responses from 50 cybersecurity practitioners reveals an alarming reality: 44% report experiencing severe work-related stress and burnout, while an additional 28% are uncertain about their condition. The demanding nature of cybersecurity roles, unrealistic expectations, and unsupportive organizational cultures emerge as primary factors fueling this crisis. Notably, 66% of respondents perceive cybersecurity jobs as more stressful than other IT positions, with 84% facing additional challenges due to the pandemic and recent high-profile breaches. The study finds that most cybersecurity experts are reluctant to report their struggles to management, perpetuating a cycle of silence and neglect. To address this critical issue, the paper recommends that organizations foster supportive work environments, implement mindfulness programs, and address systemic challenges. By prioritizing the mental health of cybersecurity professionals, organizations can cultivate a more resilient and effective workforce to protect against an ever-evolving threat landscape.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "10 pages, 8 figures, 6 tables"
    },
    {
        "paper id": "2409.12076",
        "abstract url": "https://arxiv.org/abs/2409.12076",
        "title": "Unsupervised Domain Adaptation Via Data Pruning",
        "rating": "-1.5",
        "keywords": [
            [
                "bioacoustic"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The removal of carefully-selected examples from training data has recently emerged as an effective way of improving the robustness of machine learning models. However, the best way to select these examples remains an open question. In this paper, we consider the problem from the perspective of unsupervised domain adaptation (UDA). We propose AdaPrune, a method for UDA whereby training examples are removed to attempt to align the training distribution to that of the target data. By adopting the maximum mean discrepancy (MMD) as the criterion for alignment, the problem can be neatly formulated and solved as an integer quadratic program. We evaluate our approach on a real-world domain shift task of bioacoustic event detection. As a method for UDA, we show that AdaPrune outperforms related techniques, and is complementary to other UDA algorithms such as CORAL. Our analysis of the relationship between the MMD and model accuracy, along with t-SNE plots, validate the proposed method as a principled and well-founded way of performing data pruning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12087",
        "abstract url": "https://arxiv.org/abs/2409.12087",
        "title": "Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "Disease"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This study explores the potential of utilizing administrative claims data, combined with advanced machine learning and deep learning techniques, to predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major health insurance organization to develop prediction models for multiple observation windows using traditional machine learning methods such as Random Forest and XGBoost as well as deep learning approaches such as Long Short-Term Memory (LSTM) networks. Our findings demonstrate that the LSTM model, particularly with a 24-month observation window, exhibits superior performance in predicting ESRD progression, outperforming existing models in the literature. We further apply SHapley Additive exPlanations (SHAP) analysis to enhance interpretability, providing insights into the impact of individual features on predictions at the individual patient level. This study underscores the value of leveraging administrative claims data for CKD management and predicting ESRD progression.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "10pages, 4 figures, AMIA 2024"
    },
    {
        "paper id": "2409.12116",
        "abstract url": "https://arxiv.org/abs/2409.12116",
        "title": "Stronger Baseline Models -- A Key Requirement for Aligning Machine Learning Research with Clinical Utility",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "Clinical"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Machine Learning (ML) research has increased substantially in recent years, due to the success of predictive modeling across diverse application domains. However, well-known barriers exist when attempting to deploy ML models in high-stakes, clinical settings, including lack of model transparency (or the inability to audit the inference process), large training data requirements with siloed data sources, and complicated metrics for measuring model utility. In this work, we show empirically that including stronger baseline models in healthcare ML evaluations has important downstream effects that aid practitioners in addressing these challenges. Through a series of case studies, we find that the common practice of omitting baselines or comparing against a weak baseline model (e.g. a linear model with no optimization) obscures the value of ML methods proposed in the research literature. Using these insights, we propose some best practices that will enable practitioners to more effectively study and deploy ML models in clinical settings.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": "18 pages, 6 figures"
    },
    {
        "paper id": "2409.11706",
        "abstract url": "https://arxiv.org/abs/2409.11706",
        "title": "RopeBEV: A Multi-Camera Roadside Perception Network in Bird's-Eye-View",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-camera perception methods in Bird's-Eye-View (BEV) have gained wide application in autonomous driving. However, due to the differences between roadside and vehicle-side scenarios, there currently lacks a multi-camera BEV solution in roadside. This paper systematically analyzes the key challenges in multi-camera BEV perception for roadside scenarios compared to vehicle-side. These challenges include the diversity in camera poses, the uncertainty in Camera numbers, the sparsity in perception regions, and the ambiguity in orientation angles. In response, we introduce RopeBEV, the first dense multi-camera BEV approach. RopeBEV introduces BEV augmentation to address the training balance issues caused by diverse camera poses. By incorporating CamMask and ROIMask (Region of Interest Mask), it supports variable camera numbers and sparse perception, respectively. Finally, camera rotation embedding is utilized to resolve orientation ambiguity. Our method ranks 1st on the real-world highway dataset RoScenes and demonstrates its practical value on a private urban dataset that covers more than 50 intersections and 600 cameras.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11743",
        "abstract url": "https://arxiv.org/abs/2409.11743",
        "title": "Physics-Informed Building Occupancy Detection: a Switching Process with Markov Regime",
        "rating": "-2",
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "Energy efficiency of buildings is considered to be one of the major means of achieving the net-zero carbon goal around the world. The big part of the energy savings are supposed to be coming from optimizing the operation of the building heating, ventilation, and air conditioning (HVAC) systems. There is a natural trade-off between the energy efficiency and the indoor comfort level, and finding an optimal operating schedule/regime requires knowing the occupancy of different spaces inside of the building. Moreover, the COVID-19 pandemic has also revealed the need to sustain the high quality of the indoor air in order to reduce the risk of spread of infection. Occupancy detection from indoor sensors is thus an important practical problem. In the present paper, we propose detection of occupancy based on the carbon dioxide measurements inside the building. In particular, a new approach based on the, so-called, switching auto-regressive process with Markov regime is presented and justified by the physical model of the carbon dioxide concentration dynamics. We demonstrate the efficiency of the method compared to simple Hidden Markov approaches on simulated and real-life data. We also show that the model is flexible and can be generalized to account for different ventilation regimes, simultaneously detecting the occupancy and the ventilation rate.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Submitted to Control Systems Letters/American Control Conference"
    },
    {
        "paper id": "2409.11751",
        "abstract url": "https://arxiv.org/abs/2409.11751",
        "title": "Accelerated Algorithms for Source Orientation Detection (AORI) and Spatiotemporal LCMV (ALCMV) Beamforming in EEG Source Localization",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "This paper illustrates the development of two efficient source localization algorithms for electroencephalography (EEG) data, aimed at enhancing real-time brain signal reconstruction while addressing the computational challenges of traditional methods. Accurate EEG source localization is crucial for applications in cognitive neuroscience, neurorehabilitation, and brain-computer interfaces (BCIs). To make significant progress toward precise source orientation detection and improved signal reconstruction, we introduce the Accelerated Linear Constrained Minimum Variance (ALCMV) beamforming toolbox and the Accelerated Brain Source Orientation Detection (AORI) toolbox. The ALCMV algorithm speeds up EEG source reconstruction by utilizing recursive covariance matrix calculations, while AORI simplifies source orientation detection from three dimensions to one, reducing computational load by 66% compared to conventional methods. Using both simulated and real EEG data, we demonstrate that these algorithms maintain high accuracy, with orientation errors below 0.2% and signal reconstruction accuracy within 2%. These findings suggest that the proposed toolboxes represent a substantial advancement in the efficiency and speed of EEG source localization, making them well-suited for real-time neurotechnological applications.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11778",
        "abstract url": "https://arxiv.org/abs/2409.11778",
        "title": "From Group Psychology to Software Engineering Research to Automotive R&D: Measuring Team Development at Volvo Cars",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "From 2019 to 2022, Volvo Cars successfully translated our research discoveries regarding group dynamics within agile teams into widespread industrial practice. We wish to illuminate the insights gained through the process of garnering support, providing training, executing implementation, and sustaining a tool embraced by approximately 700 teams and 9,000 employees. This tool was designed to empower agile teams and propel their internal development. Our experiences underscore the necessity of comprehensive team training, the cultivation of a cadre of trainers across the organization, and the creation of a novel software solution. In essence, we deduce that an automated concise survey tool, coupled with a repository of actionable strategies, holds remarkable potential in fostering the maturation of agile teams, but we also share many of the challenges we encountered during the implementation.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11796",
        "abstract url": "https://arxiv.org/abs/2409.11796",
        "title": "Communication, Sensing and Control integrated Closed-loop System: Modeling, Control Design and Resource Allocation",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "The wireless communication technologies have fundamentally revolutionized industrial operations. The operation of the automated equipment is conducted in a closed-loop manner, where the status of devices is collected and sent to the control center through the uplink channel, and the control center sends the calculated control commands back to the devices via downlink communication. However, existing studies neglect the interdependent relationship between uplink and downlink communications, and there is an absence of a unified approach to model the communication, sensing, and control within the loop. This can lead to inaccurate performance assessments, ultimately hindering the ability to provide guidance for the design of practical systems. Therefore, this paper introduces an integrated closed-loop model that encompasses sensing, communication, and control functionalities, while addressing the coupling effects between uplink and downlink communications. Through the analysis of system convergence, an inequality pertaining to the performances of sensing, communication, and control is derived. Additionally, a joint optimization algorithm for control and resource allocation is proposed. Simulation results are presented to offer an intuitive understanding of the impact of system parameters. The findings of this paper unveil the intricate correlation among sensing, communication, and control, providing insights for the optimal design of industrial closed-loop systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2409.11803",
        "abstract url": "https://arxiv.org/abs/2409.11803",
        "title": "Model-Checking the Implementation of Consent",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Privacy policies define the terms under which personal data may be collected and processed by data controllers. The General Data Protection Regulation (GDPR) imposes requirements on these policies that are often difficult to implement. Difficulties arise in particular due to the heterogeneity of existing systems (e.g., the Internet of Things (IoT), web technology, etc.). In this paper, we propose a method to refine high level GDPR privacy requirements for informed consent into low-level computational models. The method is aimed at software developers implementing systems that require consent management. We mechanize our models in TLA+ and use model-checking to prove that the low-level computational models implement the high-level privacy requirements; TLA+ has been used by software engineers in companies such as Microsoft or Amazon. We demonstrate our method in two real world scenarios: an implementation of cookie banners and a IoT system communicating via Bluetooth low energy.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": "Pre-print of paper to appear in the proceedings of SEFM'24"
    },
    {
        "paper id": "2409.11815",
        "abstract url": "https://arxiv.org/abs/2409.11815",
        "title": "RoboMorph: In-Context Meta-Learning for Robot Dynamics Modeling",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics",
                "Robot"
            ]
        ],
        "abstract": "The landscape of Deep Learning has experienced a major shift with the pervasive adoption of Transformer-based architectures, particularly in Natural Language Processing (NLP). Novel avenues for physical applications, such as solving Partial Differential Equations and Image Vision, have been explored. However, in challenging domains like robotics, where high non-linearity poses significant challenges, Transformer-based applications are scarce. While Transformers have been used to provide robots with knowledge about high-level tasks, few efforts have been made to perform system identification. This paper proposes a novel methodology to learn a meta-dynamical model of a high-dimensional physical system, such as the Franka robotic arm, using a Transformer-based architecture without prior knowledge of the system's physical parameters. The objective is to predict quantities of interest (end-effector pose and joint positions) given the torque signals for each joint. This prediction can be useful as a component for Deep Model Predictive Control frameworks in robotics. The meta-model establishes the correlation between torques and positions and predicts the output for the complete trajectory. This work provides empirical evidence of the efficacy of the in-context learning paradigm, suggesting future improvements in learning the dynamics of robotic systems without explicit knowledge of physical parameters. Code, videos, and supplementary materials can be found at project website. See https://sites.google.com/view/robomorph/",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11828",
        "abstract url": "https://arxiv.org/abs/2409.11828",
        "title": "Model-Free Generic Robust Control for Servo-Driven Actuation Mechanisms with Experimental Verification",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "To advance theoretical solutions and address limitations in modeling complex servo-driven actuation systems experiencing high non-linearity and load disturbances, this paper aims to design a practical model-free generic robust control (GRC) framework for these mechanisms. This framework is intended to be applicable across all actuator systems encompassing electrical, hydraulic, or pneumatic servomechanisms, while also functioning within complex interactions among dynamic components and adhering to control input constraints. In this respect, the state-space model of actuator systems is decomposed into smaller subsystems that incorporate the first principle equation of actuator motion dynamics and interactive energy conversion equations. This decomposition operates under the assumption that the comprehensive model of the servo-driven actuator system and energy conversion, uncertainties, load disturbances, and their bounds are unknown. Then, the GRC employs subsystem-based adaptive control strategies for each state-variant subsystem separately. Despite control input constraints and the unknown interactive system model, the GRC-applied actuator mechanism ensures uniform exponential stability and robustness in tracking desired motions. It features straightforward implementation, experimentally evaluated by applying it to two industrial applications.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been submitted for possible publication in the IEEE"
    },
    {
        "paper id": "2409.11871",
        "abstract url": "https://arxiv.org/abs/2409.11871",
        "title": "User Subgrouping in Scalable Cell-Free Massive MIMO Multicasting Systems",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Cell-free massive multiple-input multiple-output (CF-mMIMO) is a breakthrough technology for beyond-5G systems, designed to significantly boost the energy and spectral efficiencies of future mobile networks while ensuring a consistent quality of service for all users. Additionally, multicasting has gained considerable attention recently because physical-layer multicasting offers an efficient method for simultaneously serving multiple users with identical service demands by sharing radio resources. Typically, multicast services are delivered either via unicast transmissions or a single multicast transmission. This work, however, introduces a novel subgroup-centric multicast CF-mMIMO framework that divides users into several multicast subgroups based on the similarities in their spatial channel characteristics. This approach allows for efficient sharing of the pilot sequences used for channel estimation and the precoding filters used for data transmission. The proposed framework employs two scalable precoding strategies: centralized improved partial MMSE (IP-MMSE) and distributed conjugate beam-forming (CB). Numerical results show that for scenarios where users are uniformly distributed across the service area, unicast transmissions using centralized IP-MMSE precoding are optimal. However, in cases where users are spatially clustered, multicast subgrouping significantly improves the sum spectral efficiency (SE) of the multicast service compared to both unicast and single multicast transmission. Notably, in clustered scenarios, distributed CB precoding outperforms IP-MMSE in terms of per-user SE, making it the best solution for delivering multicast content.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 5 figures, European Wireless 2024 Conference"
    },
    {
        "paper id": "2409.11890",
        "abstract url": "https://arxiv.org/abs/2409.11890",
        "title": "Log2graphs: An Unsupervised Framework for Log Anomaly Detection with Efficient Feature Extraction",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "In the era of rapid Internet development, log data has become indispensable for recording the operations of computer devices and software. These data provide valuable insights into system behavior and necessitate thorough analysis. Recent advances in text analysis have enabled deep learning to achieve significant breakthroughs in log anomaly detection. However, the high cost of manual annotation and the dynamic nature of usage scenarios present major challenges to effective log analysis. This study proposes a novel log feature extraction model called DualGCN-LogAE, designed to adapt to various scenarios. It leverages the expressive power of large models for log content analysis and the capability of graph structures to encapsulate correlations between logs. It retains key log information while integrating the causal relationships between logs to achieve effective feature extraction. Additionally, we introduce Log2graphs, an unsupervised log anomaly detection method based on the feature extractor. By employing graph clustering algorithms for log anomaly detection, Log2graphs enables the identification of abnormal logs without the need for labeled data. We comprehensively evaluate the feature extraction capability of DualGCN-LogAE and the anomaly detection performance of Log2graphs using public log datasets across five different scenarios. Our evaluation metrics include detection accuracy and graph clustering quality scores. Experimental results demonstrate that the log features extracted by DualGCN-LogAE outperform those obtained by other methods on classic classifiers. Moreover, Log2graphs surpasses existing unsupervised log detection methods, providing a robust tool for advancing log anomaly detection research.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11891",
        "abstract url": "https://arxiv.org/abs/2409.11891",
        "title": "User Subgrouping and Power Control for Multicast Massive MIMO over Spatially Correlated Channels",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Massive multiple-input-multiple-output (MIMO) is unquestionably a key enabler of the fifth-generation (5G) technology for mobile systems, enabling to meet the high requirements of upcoming mobile broadband services. Physical-layer multicasting refers to a technique for simultaneously serving multiple users, demanding for the same service and sharing the same radio resources, with a single transmission. Massive MIMO systems with multicast communications have been so far studied under the ideal assumption of uncorrelated Rayleigh fading channels. In this work, we consider a practical multicast massive MIMO system over spatially correlated Rayleigh fading channels, investigating the impact of the spatial channel correlation on the favorable propagation, hence on the performance. We propose a subgrouping strategy for the multicast users based on their channel correlation matrices' similarities. The proposed subgrouping approach capitalizes on the spatial correlation to enhance the quality of the channel estimation, and thereby the effectiveness of the precoding. Moreover, we devise a max-min fairness (MMF) power allocation strategy that makes the spectral efficiency (SE) among different multicast subgroups uniform. Lastly, we propose a novel power allocation for uplink (UL) pilot transmission to maximize the SE among the users within the same multicast subgroup. Simulation results show a significant SE gain provided by our user subgrouping and power allocation strategies. Importantly, we show how spatial channel correlation can be exploited to enhance multicast massive MIMO communications.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "14 pages, 25 figures"
    },
    {
        "paper id": "2409.11910",
        "abstract url": "https://arxiv.org/abs/2409.11910",
        "title": "Tumor aware recurrent inter-patient deformable image registration of computed tomography scans with lung cancer",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Voxel"
            ],
            [
                "CT",
                "cancer",
                "Tumor"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Background: Voxel-based analysis (VBA) for population level radiotherapy (RT) outcomes modeling requires topology preserving inter-patient deformable image registration (DIR) that preserves tumors on moving images while avoiding unrealistic deformations due to tumors occurring on fixed images. Purpose: We developed a tumor-aware recurrent registration (TRACER) deep learning (DL) method and evaluated its suitability for VBA. Methods: TRACER consists of encoder layers implemented with stacked 3D convolutional long short term memory network (3D-CLSTM) followed by decoder and spatial transform layers to compute dense deformation vector field (DVF). Multiple CLSTM steps are used to compute a progressive sequence of deformations. Input conditioning was applied by including tumor segmentations with 3D image pairs as input channels. Bidirectional tumor rigidity, image similarity, and deformation smoothness losses were used to optimize the network in an unsupervised manner. TRACER and multiple DL methods were trained with 204 3D CT image pairs from patients with lung cancers (LC) and evaluated using (a) Dataset I (N = 308 pairs) with DL segmented LCs, (b) Dataset II (N = 765 pairs) with manually delineated LCs, and (c) Dataset III with 42 LC patients treated with RT. Results: TRACER accurately aligned normal tissues. It best preserved tumors, blackindicated by the smallest tumor volume difference of 0.24\\%, 0.40\\%, and 0.13 \\% and mean square error in CT intensities of 0.005, 0.005, 0.004, computed between original and resampled moving image tumors, for Datasets I, II, and III, respectively. It resulted in the smallest planned RT tumor dose difference computed between original and resampled moving images of 0.01 Gy and 0.013 Gy when using a female and a male reference.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Minor revision under the journal of Medical Physics"
    },
    {
        "paper id": "2409.11921",
        "abstract url": "https://arxiv.org/abs/2409.11921",
        "title": "Repeatable Energy-Efficient Perching for Flapping-Wing Robots Using Soft Grippers",
        "rating": "-2",
        "keywords": [
            [
                "vehicle",
                "flight"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "With the emergence of new flapping-wing micro aerial vehicle (FWMAV) designs, a need for extensive and advanced mission capabilities arises. FWMAVs try to adapt and emulate the flight features of birds and flying insects. While current designs already achieve high manoeuvrability, they still almost entirely lack perching and take-off abilities. These capabilities could, for instance, enable long-term monitoring and surveillance missions, and operations in cluttered environments or in proximity to humans and animals. We present the development and testing of a framework that enables repeatable perching and take-off for small to medium-sized FWMAVs, utilising soft, non-damaging grippers. Thanks to its novel active-passive actuation system, an energy-conserving state can be achieved and indefinitely maintained while the vehicle is perched. A prototype of the proposed system weighing under 39 g was manufactured and extensively tested on a 110 g flapping-wing robot. Successful free-flight tests demonstrated the full mission cycle of landing, perching and subsequent take-off. The telemetry data recorded during the flights yields extensive insight into the system's behaviour and is a valuable step towards full automation and optimisation of the entire take-off and landing cycle.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "17 pages, 13 figures, 5 multimedia extensions"
    },
    {
        "paper id": "2409.11928",
        "abstract url": "https://arxiv.org/abs/2409.11928",
        "title": "Atmospheric Turbulence-Immune Free Space Optical Communication System based on Discrete-Time Analog Transmission",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "To effectively mitigate the influence of atmospheric turbulence, a novel discrete-time analog transmission free-space optical (DTAT-FSO) communication scheme is proposed. It directly maps information sources to discrete-time analog symbols via joint source-channel coding and modulation. Differently from traditional digital free space optical (TD-FSO) schemes, the proposed DTAT-FSO approach can automatically adapt to the variation of the channel state, with no need to adjust the specific modulation and coding scheme. The performance of the DTAT-FSO system was evaluated in both intensity modulation/direct detection (IM/DD) and coherent FSO systems for high-resolution image transmission. The results show that the DTAT-FSO reliably transmits images at low received optical powers (ROPs) and automatically enhances quality at high ROPs, while the TD-FSO experiences cliff and leveling effects when the channel state varies. With respect to the TD-FSO scheme, the DTAT-FSO scheme improved receiver sensitivity by 2.5 dB in the IM/DD FSO system and 0.8 dB in the coherent FSO system, and it achieved superior image fidelity under the same ROP. The automatic adaptation feature and improved performance of the DTAT-FSO suggest its potential for terrestrial, airborne, and satellite optical networks, addressing challenges posed by atmospheric turbulence.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11951",
        "abstract url": "https://arxiv.org/abs/2409.11951",
        "title": "GaussianHeads: End-to-End Learning of Drivable Gaussian Head Avatars from Coarse-to-fine Representations",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "avatar"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Real-time rendering of human head avatars is a cornerstone of many computer graphics applications, such as augmented reality, video games, and films, to name a few. Recent approaches address this challenge with computationally efficient geometry primitives in a carefully calibrated multi-view setup. Albeit producing photorealistic head renderings, it often fails to represent complex motion changes such as the mouth interior and strongly varying head poses. We propose a new method to generate highly dynamic and deformable human head avatars from multi-view imagery in real-time. At the core of our method is a hierarchical representation of head models that allows to capture the complex dynamics of facial expressions and head movements. First, with rich facial features extracted from raw input frames, we learn to deform the coarse facial geometry of the template mesh. We then initialize 3D Gaussians on the deformed surface and refine their positions in a fine step. We train this coarse-to-fine facial avatar model along with the head pose as a learnable parameter in an end-to-end framework. This enables not only controllable facial animation via video inputs, but also high-fidelity novel view synthesis of challenging facial expressions, such as tongue deformations and fine-grained teeth structure under large motion changes. Moreover, it encourages the learned head avatar to generalize towards new facial expressions and head poses at inference time. We demonstrate the performance of our method with comparisons against the related methods on different datasets, spanning challenging facial expression sequences across multiple identities. We also show the potential application of our approach by demonstrating a cross-identity facial performance transfer application.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "ACM Transaction on Graphics (SIGGRAPH Asia 2024); Project page: https://vcai.mpi-inf.mpg.de/projects/GaussianHeads/"
    },
    {
        "paper id": "2409.11962",
        "abstract url": "https://arxiv.org/abs/2409.11962",
        "title": "Reactive Collision Avoidance for Safe Agile Navigation",
        "rating": "-2",
        "keywords": [
            [
                "RGB-D",
                "depth"
            ],
            [
                "Navigation"
            ]
        ],
        "abstract": "Reactive collision avoidance is essential for agile robots navigating complex and dynamic environments, enabling real-time obstacle response. However, this task is inherently challenging because it requires a tight integration of perception, planning, and control, which traditional methods often handle separately, resulting in compounded errors and delays. This paper introduces a novel approach that unifies these tasks into a single reactive framework using solely onboard sensing and computing. Our method combines nonlinear model predictive control with adaptive control barrier functions, directly linking perception-driven constraints to real-time planning and control. Constraints are determined by using a neural network to refine noisy RGB-D data, enhancing depth accuracy, and selecting points with the minimum time-to-collision to prioritize the most immediate threats. To maintain a balance between safety and agility, a heuristic dynamically adjusts the optimization process, preventing overconstraints in real time. Extensive experiments with an agile quadrotor demonstrate effective collision avoidance across diverse indoor and outdoor environments, without requiring environment-specific tuning or explicit mapping.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11969",
        "abstract url": "https://arxiv.org/abs/2409.11969",
        "title": "Unveiling the Black Box: Independent Functional Module Evaluation for Bird's-Eye-View Perception Model",
        "rating": "-2",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "End-to-end models are emerging as the mainstream in autonomous driving perception. However, the inability to meticulously deconstruct their internal mechanisms results in diminished development efficacy and impedes the establishment of trust. Pioneering in the issue, we present the Independent Functional Module Evaluation for Bird's-Eye-View Perception Model (BEV-IFME), a novel framework that juxtaposes the module's feature maps against Ground Truth within a unified semantic Representation Space to quantify their similarity, thereby assessing the training maturity of individual functional modules. The core of the framework lies in the process of feature map encoding and representation aligning, facilitated by our proposed two-stage Alignment AutoEncoder, which ensures the preservation of salient information and the consistency of feature structure. The metric for evaluating the training maturity of functional modules, Similarity Score, demonstrates a robust positive correlation with BEV metrics, with an average correlation coefficient of 0.9387, attesting to the framework's reliability for assessment purposes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11983",
        "abstract url": "https://arxiv.org/abs/2409.11983",
        "title": "Intraoperative Registration by Cross-Modal Inverse Neural Rendering",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "surgical",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present in this paper a novel approach for 3D/2D intraoperative registration during neurosurgery via cross-modal inverse neural rendering. Our approach separates implicit neural representation into two components, handling anatomical structure preoperatively and appearance intraoperatively. This disentanglement is achieved by controlling a Neural Radiance Field's appearance with a multi-style hypernetwork. Once trained, the implicit neural representation serves as a differentiable rendering engine, which can be used to estimate the surgical camera pose by minimizing the dissimilarity between its rendered images and the target intraoperative image. We tested our method on retrospective patients' data from clinical cases, showing that our method outperforms state-of-the-art while meeting current clinical standards for registration. Code and additional resources can be found at https://maxfehrentz.github.io/style-ngp/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at MICCAI 2024"
    },
    {
        "paper id": "2409.12014",
        "abstract url": "https://arxiv.org/abs/2409.12014",
        "title": "BRDF-NeRF: Neural Radiance Fields with Optical Satellite Images and BRDF Modelling",
        "rating": "-2",
        "keywords": [
            [
                "NeRF",
                "Radiance Fields"
            ],
            [
                "remote sensing",
                "Satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding the anisotropic reflectance of complex Earth surfaces from satellite imagery is crucial for numerous applications. Neural radiance fields (NeRF) have become popular as a machine learning technique capable of deducing the bidirectional reflectance distribution function (BRDF) of a scene from multiple images. However, prior research has largely concentrated on applying NeRF to close-range imagery, estimating basic Microfacet BRDF models, which fall short for many Earth surfaces. Moreover, high-quality NeRFs generally require several images captured simultaneously, a rare occurrence in satellite imaging. To address these limitations, we propose BRDF-NeRF, developed to explicitly estimate the Rahman-Pinty-Verstraete (RPV) model, a semi-empirical BRDF model commonly employed in remote sensing. We assess our approach using two datasets: (1) Djibouti, captured in a single epoch at varying viewing angles with a fixed Sun position, and (2) Lanzhou, captured over multiple epochs with different viewing angles and Sun positions. Our results, based on only three to four satellite images for training, demonstrate that BRDF-NeRF can effectively synthesize novel views from directions far removed from the training data and produce high-quality digital surface models (DSMs).",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12029",
        "abstract url": "https://arxiv.org/abs/2409.12029",
        "title": "Biological arrow of time: Emergence of tangled information hierarchies and self-modelling dynamics",
        "rating": "-2",
        "keywords": [
            [
                "Biological"
            ]
        ],
        "abstract": "We study open-ended evolution by focusing on computational and information-processing dynamics underlying major evolutionary transitions. In doing so, we consider biological organisms as hierarchical dynamical systems that generate regularities in their phase-spaces through interactions with their environment. These emergent information patterns can then be encoded within the organism's components, leading to self-modelling \"tangled hierarchies\". Our main conjecture is that when macro-scale patterns are encoded within micro-scale components, it creates fundamental tensions (computational inconsistencies) between what is encodable at a particular evolutionary stage and what is potentially realisable in the environment. A resolution of these tensions triggers an evolutionary transition which expands the problem-space, at the cost of generating new tensions in the expanded space, in a continual process. We argue that biological complexification can be interpreted computation-theoretically, within the G\u00f6del--Turing--Post recursion-theoretic framework, as open-ended generation of computational novelty. In general, this process can be viewed as a meta-simulation performed by higher-order systems that successively simulate the computation carried out by lower-order systems. This computation-theoretic argument provides a basis for hypothesising the biological arrow of time.",
        "subjects": [
            "q-bio.PE",
            "cs.FL",
            "cs.LO",
            "nlin.AO",
            "nlin.CG"
        ],
        "comment": "30 pages, 13 figures"
    },
    {
        "paper id": "2409.12055",
        "abstract url": "https://arxiv.org/abs/2409.12055",
        "title": "Artemis: Efficient Commit-and-Prove SNARKs for zkML",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "The widespread adoption of machine learning (ML) in various critical applications, from healthcare to autonomous systems, has raised significant concerns about privacy, accountability, and trustworthiness. To address these concerns, recent research has focused on developing zero-knowledge machine learning (zkML) techniques that enable the verification of various aspects of ML models without revealing sensitive information. Recent advances in zkML have substantially improved efficiency; however, these efforts have primarily optimized the process of proving ML computations correct, often overlooking the substantial overhead associated with verifying the necessary commitments to the model and data. To address this gap, this paper introduces two new Commit-and-Prove SNARK (CP-SNARK) constructions (Apollo and Artemis) that effectively address the emerging challenge of commitment verification in zkML pipelines. Apollo operates on KZG commitments and requires white-box use of the underlying proof system, whereas Artemis is compatible with any homomorphic polynomial commitment and only makes black-box use of the proof system. As a result, Artemis is compatible with state-of-the-art proof systems without trusted setup. We present the first implementation of these CP-SNARKs, evaluate their performance on a diverse set of ML models, and show substantial improvements over existing methods, achieving significant reductions in prover costs and maintaining efficiency even for large-scale models. For example, for the VGG model, we reduce the overhead associated with commitment checks from 11.5x to 1.2x. Our results suggest that these contributions can move zkML towards practical deployment, particularly in scenarios involving large and complex ML models.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2409.12082",
        "abstract url": "https://arxiv.org/abs/2409.12082",
        "title": "ReLU Surrogates in Mixed-Integer MPC for Irrigation Scheduling",
        "rating": "-2",
        "keywords": [
            [
                "agricultural"
            ]
        ],
        "abstract": "Efficient water management in agriculture is important for mitigating the growing freshwater scarcity crisis. Mixed-integer Model Predictive Control (MPC) has emerged as an effective approach for addressing the complex scheduling problems in agricultural irrigation. However, the computational complexity of mixed-integer MPC still poses a significant challenge, particularly in large-scale applications. This study proposes an approach to enhance the computational efficiency of mixed-integer MPC-based irrigation schedulers by employing ReLU surrogate models to describe the soil moisture dynamics of the agricultural field. By leveraging the mixed-integer linear representation of the ReLU operator, the proposed approach transforms the mixed-integer MPC-based scheduler with a quadratic cost function into a mixed-integer quadratic program, which is the simplest class of mixed-integer nonlinear programming problems that can be efficiently solved using global optimization solvers. The effectiveness of this approach is demonstrated through comparative studies conducted on a large-scale agricultural field across two growing seasons, involving other machine learning surrogate models, specifically Long Short-Term Memory (LSTM) networks, and the widely used triggered irrigation scheduling method. The ReLU-based approach significantly reduces solution times -- by up to 99.5\\% -- while achieving comparable performance to the LSTM approach in terms of water savings and Irrigation Water Use Efficiency (IWUE). Moreover, the ReLU-based approach maintains enhanced performance in terms of total prescribed irrigation and IWUE compared to the widely-used triggered irrigation scheduling method.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12099",
        "abstract url": "https://arxiv.org/abs/2409.12099",
        "title": "Brain-Streams: fMRI-to-Image Reconstruction with Multi-modal Guidance",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "fMRI"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding how humans process visual information is one of the crucial steps for unraveling the underlying mechanism of brain activity. Recently, this curiosity has motivated the fMRI-to-image reconstruction task; given the fMRI data from visual stimuli, it aims to reconstruct the corresponding visual stimuli. Surprisingly, leveraging powerful generative models such as the Latent Diffusion Model (LDM) has shown promising results in reconstructing complex visual stimuli such as high-resolution natural images from vision datasets. Despite the impressive structural fidelity of these reconstructions, they often lack details of small objects, ambiguous shapes, and semantic nuances. Consequently, the incorporation of additional semantic knowledge, beyond mere visuals, becomes imperative. In light of this, we exploit how modern LDMs effectively incorporate multi-modal guidance (text guidance, visual guidance, and image layout) for structurally and semantically plausible image generations. Specifically, inspired by the two-streams hypothesis suggesting that perceptual and semantic information are processed in different brain regions, our framework, Brain-Streams, maps fMRI signals from these brain regions to appropriate embeddings. That is, by extracting textual guidance from semantic information regions and visual guidance from perceptual information regions, Brain-Streams provides accurate multi-modal guidance to LDMs. We validate the reconstruction ability of Brain-Streams both quantitatively and qualitatively on a real fMRI dataset comprising natural image stimuli and fMRI data.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12103",
        "abstract url": "https://arxiv.org/abs/2409.12103",
        "title": "Towards practical secure delegated quantum computing with semi-classical light",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Secure Delegated Quantum Computation (SDQC) protocols are a vital piece of the future quantum information processing global architecture since they allow end-users to perform their valuable computations on remote quantum servers without fear that a malicious quantum service provider or an eavesdropper might acquire some information about their data or algorithm. They also allow end-users to check that their computation has been performed as they have specified it. However, existing protocols all have drawbacks that limit their usage in the real world. Most require the client to either operate a single-qubit source or perform single-qubit measurements, thus requiring them to still have some quantum technological capabilities albeit restricted, or require the server to perform operations which are hard to implement on real hardware (e.g isolate single photons from laser pulses and polarisation-preserving photon-number quantum non-demolition measurements). Others remove the need for quantum communications entirely but this comes at a cost in terms of security guarantees and memory overhead on the server's side. We present an SDQC protocol which drastically reduces the technological requirements of both the client and the server while providing information-theoretic composable security. More precisely, the client only manipulates an attenuated laser pulse, while the server only handles interacting quantum emitters with a structure capable of generating spin-photon entanglement. The quantum emitter acts as both a converter from coherent laser pulses to polarisation-encoded qubits and an entanglement generator. Such devices have recently been used to demonstrate the largest entangled photonic state to date, thus hinting at the readiness of our protocol for experimental implementations.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": "44 pages, 14 figures"
    },
    {
        "paper id": "2409.12104",
        "abstract url": "https://arxiv.org/abs/2409.12104",
        "title": "Performance of Quantum Approximate Optimization with Quantum Error Detection",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum algorithms must be scaled up to tackle real-world applications. Doing so requires overcoming the noise present on today's hardware. The quantum approximate optimization algorithm (QAOA) is a promising candidate for scaling up due to its modest resource requirements and documented asymptotic speedup over state-of-the-art classical algorithms for some problems. However, achieving better-than-classical performance with QAOA is believed to require fault tolerance. In this paper, we demonstrate a partially fault-tolerant implementation of QAOA using the $[[k+2,k,2]]$ ``Iceberg'' error detection code. We observe that encoding the circuit with the Iceberg code improves the algorithmic performance as compared to the unencoded circuit for problems with up to $20$ logical qubits on a trapped-ion quantum computer. Additionally, we propose and calibrate a model for predicting the code performance, and use it to characterize the limits of the Iceberg code and extrapolate its performance to future hardware with improved error rates. In particular, we show how our model can be used to determine necessary conditions for QAOA to outperform Goemans-Williamson algorithm on future hardware. Our results demonstrate the largest universal quantum computing algorithm protected by partially fault-tolerant quantum error detection on practical applications to date, paving the way towards solving real-world applications with quantum computers.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": "13 + 4 pages, 12 figures, 7 tables"
    },
    {
        "paper id": "2409.12111",
        "abstract url": "https://arxiv.org/abs/2409.12111",
        "title": "Applications of Knowledge Distillation in Remote Sensing: A Survey",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the ever-growing complexity of models in the field of remote sensing (RS), there is an increasing demand for solutions that balance model accuracy with computational efficiency. Knowledge distillation (KD) has emerged as a powerful tool to meet this need, enabling the transfer of knowledge from large, complex models to smaller, more efficient ones without significant loss in performance. This review article provides an extensive examination of KD and its innovative applications in RS. KD, a technique developed to transfer knowledge from a complex, often cumbersome model (teacher) to a more compact and efficient model (student), has seen significant evolution and application across various domains. Initially, we introduce the fundamental concepts and historical progression of KD methods. The advantages of employing KD are highlighted, particularly in terms of model compression, enhanced computational efficiency, and improved performance, which are pivotal for practical deployments in RS scenarios. The article provides a comprehensive taxonomy of KD techniques, where each category is critically analyzed to demonstrate the breadth and depth of the alternative options, and illustrates specific case studies that showcase the practical implementation of KD methods in RS tasks, such as instance segmentation and object detection. Further, the review discusses the challenges and limitations of KD in RS, including practical constraints and prospective future directions, providing a comprehensive overview for researchers and practitioners in the field of RS. Through this organization, the paper not only elucidates the current state of research in KD but also sets the stage for future research opportunities, thereby contributing significantly to both academic research and real-world applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "50 pages, 11 figures and 9 tables"
    },
    {
        "paper id": "2409.12121",
        "abstract url": "https://arxiv.org/abs/2409.12121",
        "title": "WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent advances in speech spoofing necessitate stronger verification mechanisms in neural speech codecs to ensure authenticity. Current methods embed numerical watermarks before compression and extract them from reconstructed speech for verification, but face limitations such as separate training processes for the watermark and codec, and insufficient cross-modal information integration, leading to reduced watermark imperceptibility, extraction accuracy, and capacity. To address these issues, we propose WMCodec, the first neural speech codec to jointly train compression-reconstruction and watermark embedding-extraction in an end-to-end manner, optimizing both imperceptibility and extractability of the watermark. Furthermore, We design an iterative Attention Imprint Unit (AIU) for deeper feature integration of watermark and speech, reducing the impact of quantization noise on the watermark. Experimental results show WMCodec outperforms AudioSeal with Encodec in most quality metrics for watermark imperceptibility and consistently exceeds both AudioSeal with Encodec and reinforced TraceableSpeech in extraction accuracy of watermark. At bandwidth of 6 kbps with a watermark capacity of 16 bps, WMCodec maintains over 99% extraction accuracy under common attacks, demonstrating strong robustness.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12146",
        "abstract url": "https://arxiv.org/abs/2409.12146",
        "title": "Lempel-Ziv (LZ77) Factorization in Sublinear Time",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Lempel-Ziv (LZ77) factorization is a fundamental problem in string processing: Greedily partition a given string $T$ from left to right into blocks (called phrases) so that each phrase is either the leftmost occurrence of a letter or the longest prefix of the unprocessed suffix that has another occurrence earlier in $T$. Due to numerous applications, LZ77 factorization is one of the most studied problems on strings. In the 47 years since its inception, several algorithms were developed for different models of computation, including parallel, GPU, external-memory, and quantum. Remarkably, however, the complexity of the most basic variant is still not settled: All existing algorithms in the RAM model run in $\u03a9(n)$ time, which is a $\u0398(\\log n)$ factor away from the lower bound of $\u03a9(n/\\log n)$ (following from the necessity to read the input, which takes $\u0398(n/\\log n)$ space for $T\\in\\{0,1\\}^{n}$). We present the first $o(n)$-time algorithm for LZ77 factorization, breaking the linear-time barrier present for nearly 50 years. For $T\\in\\{0,1\\}^{n}$, our algorithm runs in $\\mathcal{O}(n/\\sqrt{\\log n})=o(n)$ time and uses the optimal $\\mathcal{O}(n/\\log n)$ working space. Our algorithm generalizes to $\u03a3=[0..\u03c3)$, where $\u03c3=n^{\\mathcal{O}(1)}$. The runtime and working space then become $\\mathcal{O}((n\\log\u03c3)/\\sqrt{\\log n})$ and $\\mathcal{O}(n/\\log_\u03c3 n)$. To obtain our algorithm, we prove a more general result: For any constant $\u03b5\\in(0,1)$ and $T\\in[0..\u03c3)^{n}$, in $\\mathcal{O}((n\\log\u03c3)/\\sqrt{\\log n})$ time and using $\\mathcal{O}(n/\\log_\u03c3n)$ space, we can construct an $\\mathcal{O}(n/\\log_\u03c3n)$-size index that, given any $P=T[j..j+\\ell)$ (represented as $(j,\\ell)$), computes the leftmost occurrence of $P$ in $T$ in $\\mathcal{O}(\\log^\u03b5n)$ time. In other words, we solve the indexing/online variant of the LZ77 problem.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "Accepted to FOCS 2024"
    },
    {
        "paper id": "2409.12156",
        "abstract url": "https://arxiv.org/abs/2409.12156",
        "title": "JEAN: Joint Expression and Audio-guided NeRF-based Talking Face Generation",
        "rating": "-2",
        "keywords": [
            [
                "NeRF"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce a novel method for joint expression and audio-guided talking face generation. Recent approaches either struggle to preserve the speaker identity or fail to produce faithful facial expressions. To address these challenges, we propose a NeRF-based network. Since we train our network on monocular videos without any ground truth, it is essential to learn disentangled representations for audio and expression. We first learn audio features in a self-supervised manner, given utterances from multiple subjects. By incorporating a contrastive learning technique, we ensure that the learned audio features are aligned to the lip motion and disentangled from the muscle motion of the rest of the face. We then devise a transformer-based architecture that learns expression features, capturing long-range facial expressions and disentangling them from the speech-specific mouth movements. Through quantitative and qualitative evaluation, we demonstrate that our method can synthesize high-fidelity talking face videos, achieving state-of-the-art facial expression transfer along with lip synchronization to unseen audio.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by BMVC 2024. Project Page: https://starc52.github.io/publications/2024-07-19-JEAN"
    },
    {
        "paper id": "2409.12158",
        "abstract url": "https://arxiv.org/abs/2409.12158",
        "title": "Publishing Instincts: An Exploration-Exploitation Framework for Studying Academic Publishing Behavior and \"Home Venues\"",
        "rating": "-2",
        "keywords": [
            [
                "biologically"
            ]
        ],
        "abstract": "Scholarly communication is vital to scientific advancement, enabling the exchange of ideas and knowledge. When selecting publication venues, scholars consider various factors, such as journal relevance, reputation, outreach, and editorial standards and practices. However, some of these factors are inconspicuous or inconsistent across venues and individual publications. This study proposes that scholars' decision-making process can be conceptualized and explored through the biologically inspired exploration-exploitation (EE) framework, which posits that scholars balance between familiar and under-explored publication venues. Building on the EE framework, we introduce a grounded definition for \"Home Venues\" (HVs) - an informal concept used to describe the set of venues where a scholar consistently publishes - and investigate their emergence and key characteristics. Our analysis reveals that the publication patterns of roughly three-quarters of computer science scholars align with the expectations of the EE framework. For these scholars, HVs typically emerge and stabilize after approximately 15-20 publications. Additionally, scholars with higher h-indexes or a greater number of publications, tend to have higher-ranking journals as their HVs.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12164",
        "abstract url": "https://arxiv.org/abs/2409.12164",
        "title": "Blind Deconvolution on Graphs: Exact and Stable Recovery",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Graphs"
            ]
        ],
        "abstract": "We study a blind deconvolution problem on graphs, which arises in the context of localizing a few sources that diffuse over networks. While the observations are bilinear functions of the unknown graph filter coefficients and sparse input signals, a mild requirement on invertibility of the diffusion filter enables an efficient convex relaxation leading to a linear programming formulation that can be tackled with off-the-shelf solvers. Under the Bernoulli-Gaussian model for the inputs, we derive sufficient exact recovery conditions in the noise-free setting. A stable recovery result is then established, ensuring the estimation error remains manageable even when the observations are corrupted by a small amount of noise. Numerical tests with synthetic and real-world network data illustrate the merits of the proposed algorithm, its robustness to noise as well as the benefits of leveraging multiple signals to aid the (blind) localization of sources of diffusion. At a fundamental level, the results presented here broaden the scope of classical blind deconvolution of (spatio-)temporal signals to irregular graph domains.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "14 pages, 3 figures, preprint submitted to Signal Processing"
    },
    {
        "paper id": "2409.11807",
        "abstract url": "https://arxiv.org/abs/2409.11807",
        "title": "Constraint Guided AutoEncoders for Joint Optimization of Condition Indicator Estimation and Anomaly Detection in Machine Condition Monitoring",
        "rating": "-2.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The main goal of machine condition monitoring is, as the name implies, to monitor the condition of industrial applications. The objective of this monitoring can be mainly split into two problems. A diagnostic problem, where normal data should be distinguished from anomalous data, otherwise called Anomaly Detection (AD), or a prognostic problem, where the aim is to predict the evolution of a Condition Indicator (CI) that reflects the condition of an asset throughout its life time. When considering machine condition monitoring, it is expected that this CI shows a monotonic behavior, as the condition of a machine gradually degrades over time. This work proposes an extension to Constraint Guided AutoEncoders (CGAE), which is a robust AD method, that enables building a single model that can be used for both AD and CI estimation. For the purpose of improved CI estimation the extension incorporates a constraint that enforces the model to have monotonically increasing CI predictions over time. Experimental results indicate that the proposed algorithm performs similar, or slightly better, than CGAE, with regards to AD, while improving the monotonic behavior of the CI.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "32 pages, 7 figures, 4 tables"
    },
    {
        "paper id": "2409.11856",
        "abstract url": "https://arxiv.org/abs/2409.11856",
        "title": "Edge-Based Graph Component Pooling",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "chemistry"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph-structured data naturally occurs in many research fields, such as chemistry and sociology. The relational information contained therein can be leveraged to statistically model graph properties through geometrical deep learning. Graph neural networks employ techniques, such as message-passing layers, to propagate local features through a graph. However, message-passing layers can be computationally expensive when dealing with large and sparse graphs. Graph pooling operators offer the possibility of removing or merging nodes in such graphs, thus lowering computational costs. However, pooling operators that remove nodes cause data loss, and pooling operators that merge nodes are often computationally expensive. We propose a pooling operator that merges nodes so as not to cause data loss but is also conceptually simple and computationally inexpensive. We empirically demonstrate that the proposed pooling operator performs statistically significantly better than edge pool on four popular benchmark datasets while reducing time complexity and the number of trainable parameters by 70.6% on average. Compared to another maximally powerful method named Graph Isomporhic Network, we show that we outperform them on two popular benchmark datasets while reducing the number of learnable parameters on average by 60.9%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "15 pages, presented at 21st International Workshop on Mining and Learning with Graphs, AstraZenica Bio & Healthcare award Paper, ECML PKDD 2024 Vilnius"
    },
    {
        "paper id": "2409.12061",
        "abstract url": "https://arxiv.org/abs/2409.12061",
        "title": "Generalized Robot Learning Framework",
        "rating": "-2.5",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Imitation based robot learning has recently gained significant attention in the robotics field due to its theoretical potential for transferability and generalizability. However, it remains notoriously costly, both in terms of hardware and data collection, and deploying it in real-world environments demands meticulous setup of robots and precise experimental conditions. In this paper, we present a low-cost robot learning framework that is both easily reproducible and transferable to various robots and environments. We demonstrate that deployable imitation learning can be successfully applied even to industrial-grade robots, not just expensive collaborative robotic arms. Furthermore, our results show that multi-task robot learning is achievable with simple network architectures and fewer demonstrations than previously thought necessary. As the current evaluating method is almost subjective when it comes to real-world manipulation tasks, we propose Voting Positive Rate (VPR) - a novel evaluation strategy that provides a more objective assessment of performance. We conduct an extensive comparison of success rates across various self-designed tasks to validate our approach. To foster collaboration and support the robot learning community, we have open-sourced all relevant datasets and model checkpoints, available at huggingface.co/ZhiChengAI.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "6 pages, 2 figures. cs.RO"
    },
    {
        "paper id": "2409.11728",
        "abstract url": "https://arxiv.org/abs/2409.11728",
        "title": "Active Reconfigurable Intelligent Surface Empowered Synthetic Aperture Radar Imaging",
        "rating": "-3",
        "keywords": [
            [
                "trajectory",
                "Radar",
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Synthetic Aperture Radar (SAR) utilizes the movement of the radar antenna over a specific area of interest to achieve higher spatial resolution imaging. In this paper, we aim to investigate the realization of SAR imaging for a stationary radar system with the assistance of active reconfigurable intelligent surface (ARIS) mounted on an unmanned aerial vehicle (UAV). As the UAV moves along the stationary trajectory, the ARIS can not only build a high-quality virtual line-of-sight (LoS) propagation path, but its mobility can also effectively create a much larger virtual aperture, which can be utilized to realize a SAR system. In this paper, we first present a range-Doppler (RD) imaging algorithm to obtain imaging results for the proposed ARIS-empowered SAR system. Then, to further improve the SAR imaging performance, we attempt to optimize the reflection coefficients of ARIS to maximize the signal-to-noise ratio (SNR) at the stationary radar receiver under the constraints of ARIS maximum power and amplification factor. An effective algorithm based on fractional programming (FP) and majorization minimization (MM) methods is developed to solve the resulting non-convex problem. Simulation results validate the effectiveness of ARIS-assisted SAR imaging and our proposed RD imaging and ARIS optimization algorithms.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11788",
        "abstract url": "https://arxiv.org/abs/2409.11788",
        "title": "Hook-Based Aerial Payload Grasping from a Moving Platform",
        "rating": "-3",
        "keywords": [
            [
                "trajectory",
                "flight"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "This paper investigates payload grasping from a moving platform using a hook-equipped aerial manipulator. First, a computationally efficient trajectory optimization based on complementarity constraints is proposed to determine the optimal grasping time. To enable application in complex, dynamically changing environments, the future motion of the payload is predicted using physics simulator-based models. The success of payload grasping under model uncertainties and external disturbances is formally verified through a robustness analysis method based on integral quadratic constraints. The proposed algorithms are evaluated in a high-fidelity physical simulator, and in real flight experiments using a custom-designed aerial manipulator platform.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11837",
        "abstract url": "https://arxiv.org/abs/2409.11837",
        "title": "World of Forms: Deformable Geometric Templates for One-Shot Surface Meshing in Coronary CT Angiography",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "graph"
            ],
            [
                "medical",
                "CT"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Deep learning-based medical image segmentation and surface mesh generation typically involve a sequential pipeline from image to segmentation to meshes, often requiring large training datasets while making limited use of prior geometric knowledge. This may lead to topological inconsistencies and suboptimal performance in low-data regimes. To address these challenges, we propose a data-efficient deep learning method for direct 3D anatomical object surface meshing using geometric priors. Our approach employs a multi-resolution graph neural network that operates on a prior geometric template which is deformed to fit object boundaries of interest. We show how different templates may be used for the different surface meshing targets, and introduce a novel masked autoencoder pretraining strategy for 3D spherical data. The proposed method outperforms nnUNet in a one-shot setting for segmentation of the pericardium, left ventricle (LV) cavity and the LV myocardium. Similarly, the method outperforms other lumen segmentation operating on multi-planar reformatted images. Results further indicate that mesh quality is on par with or improves upon marching cubes post-processing of voxel mask predictions, while remaining flexible in the choice of mesh triangulation prior, thus paving the way for more accurate and topologically consistent 3D medical object surface meshing.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "Submitted to Medical Image Analysis"
    },
    {
        "paper id": "2409.11925",
        "abstract url": "https://arxiv.org/abs/2409.11925",
        "title": "Haptic-ACT: Bridging Human Intuition with Compliant Robotic Manipulation via Immersive VR",
        "rating": "-3",
        "keywords": [
            [
                "robotics",
                "robot",
                "Robotic Manipulation"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Robotic manipulation is essential for the widespread adoption of robots in industrial and home settings and has long been a focus within the robotics community. Advances in artificial intelligence have introduced promising learning-based methods to address this challenge, with imitation learning emerging as particularly effective. However, efficiently acquiring high-quality demonstrations remains a challenge. In this work, we introduce an immersive VR-based teleoperation setup designed to collect demonstrations from a remote human user. We also propose an imitation learning framework called Haptic Action Chunking with Transformers (Haptic-ACT). To evaluate the platform, we conducted a pick-and-place task and collected 50 demonstration episodes. Results indicate that the immersive VR platform significantly reduces demonstrator fingertip forces compared to systems without haptic feedback, enabling more delicate manipulation. Additionally, evaluations of the Haptic-ACT framework in both the MuJoCo simulator and on a real robot demonstrate its effectiveness in teaching robots more compliant manipulation compared to the original ACT. Additional materials are available at https://sites.google.com/view/hapticact.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This work is under review by ICRA 2025"
    },
    {
        "paper id": "2409.11952",
        "abstract url": "https://arxiv.org/abs/2409.11952",
        "title": "Human-Robot Cooperative Piano Playing with Learning-Based Real-Time Music Accompaniment",
        "rating": "-3",
        "keywords": [
            [
                "Robot"
            ],
            [
                "Music"
            ]
        ],
        "abstract": "Recent advances in machine learning have paved the way for the development of musical and entertainment robots. However, human-robot cooperative instrument playing remains a challenge, particularly due to the intricate motor coordination and temporal synchronization. In this paper, we propose a theoretical framework for human-robot cooperative piano playing based on non-verbal cues. First, we present a music improvisation model that employs a recurrent neural network (RNN) to predict appropriate chord progressions based on the human's melodic input. Second, we propose a behavior-adaptive controller to facilitate seamless temporal synchronization, allowing the cobot to generate harmonious acoustics. The collaboration takes into account the bidirectional information flow between the human and robot. We have developed an entropy-based system to assess the quality of cooperation by analyzing the impact of different communication modalities during human-robot collaboration. Experiments demonstrate that our RNN-based improvisation can achieve a 93\\% accuracy rate. Meanwhile, with the MPC adaptive controller, the robot could respond to the human teammate in homophony performances with real-time accompaniment. Our designed framework has been validated to be effective in allowing humans and robots to work collaboratively in the artistic piano-playing task.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2409.12008",
        "abstract url": "https://arxiv.org/abs/2409.12008",
        "title": "Panoptic-Depth Forecasting",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "Depth"
            ],
            [
                "LiDAR"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Forecasting the semantics and 3D structure of scenes is essential for robots to navigate and plan actions safely. Recent methods have explored semantic and panoptic scene forecasting; however, they do not consider the geometry of the scene. In this work, we propose the panoptic-depth forecasting task for jointly predicting the panoptic segmentation and depth maps of unobserved future frames, from monocular camera images. To facilitate this work, we extend the popular KITTI-360 and Cityscapes benchmarks by computing depth maps from LiDAR point clouds and leveraging sequential labeled data. We also introduce a suitable evaluation metric that quantifies both the panoptic quality and depth estimation accuracy of forecasts in a coherent manner. Furthermore, we present two baselines and propose the novel PDcast architecture that learns rich spatio-temporal representations by incorporating a transformer-based encoder, a forecasting module, and task-specific decoders to predict future panoptic-depth outputs. Extensive evaluations demonstrate the effectiveness of PDcast across two datasets and three forecasting tasks, consistently addressing the primary challenges. We make the code publicly available at https://pdcast.cs.uni-freiburg.de.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12034",
        "abstract url": "https://arxiv.org/abs/2409.12034",
        "title": "Multi-Sensor Deep Learning for Glacier Mapping",
        "rating": "-3",
        "keywords": [
            [
                "biodiversity"
            ],
            [
                "remote sensing",
                "satellite"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The more than 200,000 glaciers outside the ice sheets play a crucial role in our society by influencing sea-level rise, water resource management, natural hazards, biodiversity, and tourism. However, only a fraction of these glaciers benefit from consistent and detailed in-situ observations that allow for assessing their status and changes over time. This limitation can, in part, be overcome by relying on satellite-based Earth Observation techniques. Satellite-based glacier mapping applications have historically mainly relied on manual and semi-automatic detection methods, while recently, a fast and notable transition to deep learning techniques has started. This chapter reviews how combining multi-sensor remote sensing data and deep learning allows us to better delineate (i.e. map) glaciers and detect their temporal changes. We explain how relying on deep learning multi-sensor frameworks to map glaciers benefits from the extensive availability of regional and global glacier inventories. We also analyse the rationale behind glacier mapping, the benefits of deep learning methodologies, and the inherent challenges in integrating multi-sensor earth observation data with deep learning algorithms. While our review aims to provide a broad overview of glacier mapping efforts, we highlight a few setups where deep learning multi-sensor remote sensing applications have a considerable potential added value. This includes applications for debris-covered and rock glaciers that are visually difficult to distinguish from surroundings and for calving glaciers that are in contact with the ocean. These specific cases are illustrated through a series of visual imageries, highlighting some significant advantages and challenges when detecting glacier changes, including dealing with seasonal snow cover, changing debris coverage, and distinguishing glacier fronts from the surrounding sea ice.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "This article will be a chapter of the book Deep Learning for Multi-Sensor Earth Observation, to be published by Elsevier"
    },
    {
        "paper id": "2409.12051",
        "abstract url": "https://arxiv.org/abs/2409.12051",
        "title": "Uncertainty-Aware Visual-Inertial SLAM with Volumetric Occupancy Mapping",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "SLAM"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "We propose visual-inertial simultaneous localization and mapping that tightly couples sparse reprojection errors, inertial measurement unit pre-integrals, and relative pose factors with dense volumetric occupancy mapping. Hereby depth predictions from a deep neural network are fused in a fully probabilistic manner. Specifically, our method is rigorously uncertainty-aware: first, we use depth and uncertainty predictions from a deep network not only from the robot's stereo rig, but we further probabilistically fuse motion stereo that provides depth information across a range of baselines, therefore drastically increasing mapping accuracy. Next, predicted and fused depth uncertainty propagates not only into occupancy probabilities but also into alignment factors between generated dense submaps that enter the probabilistic nonlinear least squares estimator. This submap representation offers globally consistent geometry at scale. Our method is thoroughly evaluated in two benchmark datasets, resulting in localization and mapping accuracy that exceeds the state of the art, while simultaneously offering volumetric occupancy directly usable for downstream robotic planning and control in real-time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 4 figures, 5 tables, conference"
    },
    {
        "paper id": "2409.12096",
        "abstract url": "https://arxiv.org/abs/2409.12096",
        "title": "An Efficient Projection-Based Next-best-view Planning Framework for Reconstruction of Unknown Objects",
        "rating": "-3",
        "keywords": [
            [
                "voxel"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Efficiently and completely capturing the three-dimensional data of an object is a fundamental problem in industrial and robotic applications. The task of next-best-view (NBV) planning is to infer the pose of the next viewpoint based on the current data, and gradually realize the complete three-dimensional reconstruction. Many existing algorithms, however, suffer a large computational burden due to the use of ray-casting. To address this, this paper proposes a projection-based NBV planning framework. It can select the next best view at an extremely fast speed while ensuring the complete scanning of the object. Specifically, this framework refits different types of voxel clusters into ellipsoids based on the voxel structure.Then, the next best view is selected from the candidate views using a projection-based viewpoint quality evaluation function in conjunction with a global partitioning strategy. This process replaces the ray-casting in voxel structures, significantly improving the computational efficiency. Comparative experiments with other algorithms in a simulation environment show that the framework proposed in this paper can achieve 10 times efficiency improvement on the basis of capturing roughly the same coverage. The real-world experimental results also prove the efficiency and feasibility of the framework.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12189",
        "abstract url": "https://arxiv.org/abs/2409.12189",
        "title": "Massively Multi-Person 3D Human Motion Forecasting with Scene Context",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Forecasting long-term 3D human motion is challenging: the stochasticity of human behavior makes it hard to generate realistic human motion from the input sequence alone. Information on the scene environment and the motion of nearby people can greatly aid the generation process. We propose a scene-aware social transformer model (SAST) to forecast long-term (10s) human motion motion. Unlike previous models, our approach can model interactions between both widely varying numbers of people and objects in a scene. We combine a temporal convolutional encoder-decoder architecture with a Transformer-based bottleneck that allows us to efficiently combine motion and scene information. We model the conditional motion distribution using denoising diffusion models. We benchmark our approach on the Humans in Kitchens dataset, which contains 1 to 16 persons and 29 to 50 objects that are visible simultaneously. Our model outperforms other approaches in terms of realism and diversity on different metrics and in a user study. Code is available at https://github.com/felixbmuller/SAST.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "14 pages, 6 figures"
    },
    {
        "paper id": "2409.12015",
        "abstract url": "https://arxiv.org/abs/2409.12015",
        "title": "All-in-one foundational models learning across quantum chemical levels",
        "rating": "-3.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) potentials typically target a single quantum chemical (QC) level while the ML models developed for multi-fidelity learning have not been shown to provide scalable solutions for foundational models. Here we introduce the all-in-one (AIO) ANI model architecture based on multimodal learning which can learn an arbitrary number of QC levels. Our all-in-one learning approach offers a more general and easier-to-use alternative to transfer learning. We use it to train the AIO-ANI-UIP foundational model with the generalization capability comparable to semi-empirical GFN2-xTB and DFT with a double-zeta basis set for organic molecules. We show that the AIO-ANI model can learn across different QC levels ranging from semi-empirical to density functional theory to coupled cluster. We also use AIO models to design the foundational model \u0394-AIO-ANI based on \u0394-learning with increased accuracy and robustness compared to AIO-ANI-UIP. The code and the foundational models are available at https://github.com/dralgroup/aio-ani; they will be integrated into the universal and updatable AI-enhanced QM (UAIQM) library and made available in the MLatom package so that they can be used online at the XACS cloud computing platform (see https://github.com/dralgroup/mlatom for updates).",
        "subjects": [
            "physics.chem-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11981",
        "abstract url": "https://arxiv.org/abs/2409.11981",
        "title": "LMMCoDrive: Cooperative Driving with Large Multimodal Model",
        "rating": "-4",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "graph"
            ],
            [
                "Bird's-Eye View",
                "BEV"
            ]
        ],
        "abstract": "To address the intricate challenges of decentralized cooperative scheduling and motion planning in Autonomous Mobility-on-Demand (AMoD) systems, this paper introduces LMMCoDrive, a novel cooperative driving framework that leverages a Large Multimodal Model (LMM) to enhance traffic efficiency in dynamic urban environments. This framework seamlessly integrates scheduling and motion planning processes to ensure the effective operation of Cooperative Autonomous Vehicles (CAVs). The spatial relationship between CAVs and passenger requests is abstracted into a Bird's-Eye View (BEV) to fully exploit the potential of the LMM. Besides, trajectories are cautiously refined for each CAV while ensuring collision avoidance through safety constraints. A decentralized optimization strategy, facilitated by the Alternating Direction Method of Multipliers (ADMM) within the LMM framework, is proposed to drive the graph evolution of CAVs. Simulation results demonstrate the pivotal role and significant impact of LMM in optimizing CAV scheduling and enhancing decentralized cooperative optimization process for each vehicle. This marks a substantial stride towards achieving practical, efficient, and safe AMoD systems that are poised to revolutionize urban transportation. The code is available at https://github.com/henryhcliu/LMMCoDrive.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2409.12078",
        "abstract url": "https://arxiv.org/abs/2409.12078",
        "title": "Denoising diffusion models for high-resolution microscopy image restoration",
        "rating": "-4",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "biological"
            ],
            [
                "image restoration"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Advances in microscopy imaging enable researchers to visualize structures at the nanoscale level thereby unraveling intricate details of biological organization. However, challenges such as image noise, photobleaching of fluorophores, and low tolerability of biological samples to high light doses remain, restricting temporal resolutions and experiment durations. Reduced laser doses enable longer measurements at the cost of lower resolution and increased noise, which hinders accurate downstream analyses. Here we train a denoising diffusion probabilistic model (DDPM) to predict high-resolution images by conditioning the model on low-resolution information. Additionally, the probabilistic aspect of the DDPM allows for repeated generation of images that tend to further increase the signal-to-noise ratio. We show that our model achieves a performance that is better or similar to the previously best-performing methods, across four highly diverse datasets. Importantly, while any of the previous methods show competitive performance for some, but not all datasets, our method consistently achieves high performance across all four data sets, suggesting high generalizability.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11782",
        "abstract url": "https://arxiv.org/abs/2409.11782",
        "title": "Smart Data-Driven GRU Predictor for SnO$_2$ Thin films Characteristics",
        "rating": "-4.5",
        "keywords": [
            [
                "3d"
            ],
            [
                "X-ray"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In material physics, characterization techniques are foremost crucial for obtaining the materials data regarding the physical properties as well as structural, electronics, magnetic, optic, dielectric, and spectroscopic characteristics. However, for many materials, ensuring availability and safe accessibility is not always easy and fully warranted. Moreover, the use of modeling and simulation techniques need a lot of theoretical knowledge, in addition of being associated to costly computation time and a great complexity deal. Thus, analyzing materials with different techniques for multiple samples simultaneously, still be very challenging for engineers and researchers. It is worth noting that although of being very risky, X-ray diffraction is the well known and widely used characterization technique which gathers data from structural properties of crystalline 1d, 2d or 3d materials. We propose in this paper, a Smart GRU for Gated Recurrent Unit model to forcast structural characteristics or properties of thin films of tin oxide SnO$_2$(110). Indeed, thin films samples are elaborated and managed experimentally and the collected data dictionary is then used to generate an AI -- Artificial Intelligence -- GRU model for the thin films of tin oxide SnO$_2$(110) structural property characterization.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.AI"
        ],
        "comment": "19 pages, 14 figures. Baltica Journal, Special Issues, September 2024"
    },
    {
        "paper id": "2409.11929",
        "abstract url": "https://arxiv.org/abs/2409.11929",
        "title": "An Explainable Machine Learning Approach to Traffic Accident Fatality Prediction",
        "rating": "-4.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "health"
            ],
            [
                "forecast"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Road traffic accidents (RTA) pose a significant public health threat worldwide, leading to considerable loss of life and economic burdens. This is particularly acute in developing countries like Bangladesh. Building reliable models to forecast crash outcomes is crucial for implementing effective preventive measures. To aid in developing targeted safety interventions, this study presents a machine learning-based approach for classifying fatal and non-fatal road accident outcomes using data from the Dhaka metropolitan traffic crash database from 2017 to 2022. Our framework utilizes a range of machine learning classification algorithms, comprising Logistic Regression, Support Vector Machines, Naive Bayes, Random Forest, Decision Tree, Gradient Boosting, LightGBM, and Artificial Neural Network. We prioritize model interpretability by employing the SHAP (SHapley Additive exPlanations) method, which elucidates the key factors influencing accident fatality. Our results demonstrate that LightGBM outperforms other models, achieving a ROC-AUC score of 0.72. The global, local, and feature dependency analyses are conducted to acquire deeper insights into the behavior of the model. SHAP analysis reveals that casualty class, time of accident, location, vehicle type, and road type play pivotal roles in determining fatality risk. These findings offer valuable insights for policymakers and road safety practitioners in developing countries, enabling the implementation of evidence-based strategies to reduce traffic crash fatalities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 Pages, 6 figures, 2 tables, 28th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems (KES 2024)"
    },
    {
        "paper id": "2409.11906",
        "abstract url": "https://arxiv.org/abs/2409.11906",
        "title": "Fusion in Context: A Multimodal Approach to Affective State Recognition",
        "rating": "-5",
        "keywords": [
            [
                "robot"
            ],
            [
                "facial",
                "physiological"
            ],
            [
                "thermal"
            ]
        ],
        "abstract": "Accurate recognition of human emotions is a crucial challenge in affective computing and human-robot interaction (HRI). Emotional states play a vital role in shaping behaviors, decisions, and social interactions. However, emotional expressions can be influenced by contextual factors, leading to misinterpretations if context is not considered. Multimodal fusion, combining modalities like facial expressions, speech, and physiological signals, has shown promise in improving affect recognition. This paper proposes a transformer-based multimodal fusion approach that leverages facial thermal data, facial action units, and textual context information for context-aware emotion recognition. We explore modality-specific encoders to learn tailored representations, which are then fused using additive fusion and processed by a shared transformer encoder to capture temporal dependencies and interactions. The proposed method is evaluated on a dataset collected from participants engaged in a tangible tabletop Pacman game designed to induce various affective states. Our results demonstrate the effectiveness of incorporating contextual information and multimodal fusion for affective state recognition.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12114",
        "abstract url": "https://arxiv.org/abs/2409.12114",
        "title": "Bi-objective trail-planning for a robot team orienteering in a hazardous environment",
        "rating": "-6",
        "keywords": [
            [
                "robot"
            ],
            [
                "graph"
            ],
            [
                "survival"
            ],
            [
                "chemical"
            ]
        ],
        "abstract": "Teams of mobile [aerial, ground, or aquatic] robots have applications in resource delivery, patrolling, information-gathering, agriculture, forest fire fighting, chemical plume source localization and mapping, and search-and-rescue. Robot teams traversing hazardous environments -- with e.g. rough terrain or seas, strong winds, or adversaries capable of attacking or capturing robots -- should plan and coordinate their trails in consideration of risks of disablement, destruction, or capture. Specifically, the robots should take the safest trails, coordinate their trails to cooperatively achieve the team-level objective with robustness to robot failures, and balance the reward from visiting locations against risks of robot losses. Herein, we consider bi-objective trail-planning for a mobile team of robots orienteering in a hazardous environment. The hazardous environment is abstracted as a directed graph whose arcs, when traversed by a robot, present known probabilities of survival. Each node of the graph offers a reward to the team if visited by a robot (which e.g. delivers a good to or images the node). We wish to search for the Pareto-optimal robot-team trail plans that maximize two [conflicting] team objectives: the expected (i) team reward and (ii) number of robots that survive the mission. A human decision-maker can then select trail plans that balance, according to their values, reward and robot survival. We implement ant colony optimization, guided by heuristics, to search for the Pareto-optimal set of robot team trail plans. As a case study, we illustrate with an information-gathering mission in an art museum.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "v0.0"
    },
    {
        "paper id": "2409.11739",
        "abstract url": "https://arxiv.org/abs/2409.11739",
        "title": "Decision problems on geometric tilings",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study decision problems on geometric tilings. First, we study a variant of the Domino problem where square tiles are replaced by geometric tiles of arbitrary shape. We show that, under some weak assumptions, this variant is undecidable regardless of the shapes, extending previous results on rhombus tiles. This result holds even when the geometric tiling is forced to belong to a fixed set.Second, we consider the problem of deciding whether a geometric subshift has finite local complexity, which is a common assumption when studying geometric tilings. We show that it is undecidable even in a simple setting (square shapes with small modifications).",
        "subjects": [
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11755",
        "abstract url": "https://arxiv.org/abs/2409.11755",
        "title": "Covert Communications Without Pre-Sharing of Side Information and Channel Estimation Over Quasi-Static Fading Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a new covert communication scheme that operates without pre-sharing side information and channel estimation, utilizing a Gaussian-distributed Grassmann constellation for noncoherent detection. By designing constant-amplitude symbols on the Grassmann manifold and multiplying them by random variables, we generate signals that follow an arbitrary probability distribution, such as Gaussian or skew-normal distributions. The mathematical property of the manifold enables the transmitter's random variables to remain unshared with the receiver, and the elimination of pilot symbols that could compromise covertness. The proposed scheme achieved higher covertness and achievable rates compared to conventional coherent Gaussian signaling schemes, without any penalty in terms of complexity.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 5 figures"
    },
    {
        "paper id": "2409.11765",
        "abstract url": "https://arxiv.org/abs/2409.11765",
        "title": "Massively parallel CMA-ES with increasing population",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Increasing Population Covariance Matrix Adaptation Evolution Strategy (IPOP-CMA-ES) algorithm is a reference stochastic optimizer dedicated to blackbox optimization, where no prior knowledge about the underlying problem structure is available. This paper aims at accelerating IPOP-CMA-ES thanks to high performance computing and parallelism when solving large optimization problems. We first show how BLAS and LAPACK routines can be introduced in linear algebra operations, and we then propose two strategies for deploying IPOP-CMA-ES efficiently on large-scale parallel architectures with thousands of CPU cores. The first parallel strategy processes the multiple searches in the same ordering as the sequential IPOP-CMA-ES, while the second one processes concurrently these multiple searches. These strategies are implemented in MPI+OpenMP and compared on 6144 cores of the supercomputer Fugaku. We manage to obtain substantial speedups (up to several thousand) and even super-linear ones, and we provide an in-depth analysis of our results to understand precisely the superior performance of our second strategy.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11779",
        "abstract url": "https://arxiv.org/abs/2409.11779",
        "title": "Evolving Distributions Under Local Motion",
        "rating": "-10",
        "keywords": [],
        "abstract": "Geometric data sets arising in modern applications are often very large and change dynamically over time. A popular framework for dealing with such data sets is the evolving data framework, where a discrete structure continuously varies over time due to the unseen actions of an evolver, which makes small changes to the data. An algorithm probes the current state through an oracle, and the objective is to maintain a hypothesis of the data set's current state that is close to its actual state at all times. In this paper, we apply this framework to maintaining a set of $n$ point objects in motion in $d$-dimensional Euclidean space. To model the uncertainty in the object locations, both the ground truth and hypothesis are based on spatial probability distributions, and the distance between them is measured by the Kullback-Leibler divergence (relative entropy). We introduce a simple and intuitive motion model where with each time step, the distance that any object can move is a fraction of the distance to its nearest neighbor. We present an algorithm that, in steady state, guarantees a distance of $O(n)$ between the true and hypothesized placements. We also show that for any algorithm in this model, there is an evolver that can generate a distance of $\u03a9(n)$, implying that our algorithm is asymptotically optimal.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11781",
        "abstract url": "https://arxiv.org/abs/2409.11781",
        "title": "Investigating team maturity in an agile automotive reorganization",
        "rating": "-10",
        "keywords": [],
        "abstract": "About seven years ago, Volvo Cars initiated a large-scale agile transformation. Midst this journey, a significant restructuring of the R&D department took place. Our study aims to illuminate how team maturity levels are impacted during such comprehensive reorganizations. We collected data from 63 teams to comprehend the effects of organizational changes on these agile teams. Additionally, qualitative data was gathered to validate our findings and explore underlying reasons. Contrary to what was expected, the reorganization did not significantly alter the distribution of team maturity. High turnover rates and frequent reorganizations were identified as key factors to why the less mature teams remained in the early stages of team development. Conversely, teams in the second category remained stable at a higher maturity stage, primarily because the teams themselves remained largely intact, with only management structures changing. In conclusion, while reorganizations may hinder some teams' development, others maintain stability at a higher level of maturity despite substantial managerial changes.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11790",
        "abstract url": "https://arxiv.org/abs/2409.11790",
        "title": "Empowering Visual Artists with Tokenized Digital Assets with NFTs",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Non-Fungible Tokens (NFTs) has the transformative impact on the visual arts industry by examining the nexus between empowering art practices and leveraging blockchain technology. First, we establish the context for this study by introducing some basic but critical technological aspects and affordances of the blockchain domain. Second, we revisit the creative practices involved in producing traditional artwork, covering various types, production processes, trading, and monetization methods. Third, we introduce and define the key fundamentals of the blockchain ecosystem, including its structure, consensus algorithms, smart contracts, and digital wallets. Fourth, we narrow the focus to NFTs, detailing their history, mechanics, lifecycle, and standards, as well as their application in the art world. In particular, we outline the key processes for minting and trading NFTs in various marketplaces and discuss the relevant market dynamics and pricing. We also consider major security concerns, such as wash trading, to underscore some of the central cybersecurity issues facing this domain. Finally, we conclude by considering future research directions, emphasizing improvements in user experience, security, and privacy. Through this innovative research overview, which includes input from creative industry and cybersecurity sdomain expertise, we offer some new insights into how NFTs can empower visual artists and reshape the wider copyright industries.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "46 pages,9 figures"
    },
    {
        "paper id": "2409.11799",
        "abstract url": "https://arxiv.org/abs/2409.11799",
        "title": "Age-of-Information and Energy Optimization in Digital Twin Edge Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we study the intricate realm of digital twin synchronization and deployment in multi-access edge computing (MEC) networks, with the aim of optimizing and balancing the two performance metrics Age of Information (AoI) and energy efficiency. We jointly consider the problems of edge association, power allocation, and digital twin deployment. However, the inherent randomness of the problem presents a significant challenge in identifying an optimal solution. To address this, we first analyze the feasibility conditions of the optimization problem. We then examine a specific scenario involving a static channel and propose a cyclic scheduling scheme. This enables us to derive the sum AoI in closed form. As a result, the joint optimization problem of edge association and power control is solved optimally by finding a minimum weight perfect matching. Moreover, we examine the one-shot optimization problem in the contexts of both frequent digital twin migrations and fixed digital twin deployments, and propose an efficient online algorithm to address the general optimization problem. This algorithm effectively reduces system costs by balancing frequent migrations and fixed deployments. Numerical results demonstrate the effectiveness of our proposed scheme in terms of low cost and high efficiency.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11823",
        "abstract url": "https://arxiv.org/abs/2409.11823",
        "title": "Robust Sensor-Limited Control with Safe Input-Output Constraints for Hydraulic In-Wheel Motor Drive Mobility Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In-wheel drive (IWD) systems enhance the responsiveness, traction, and maintenance efficiency of vehicles by enabling each wheel to operate independently. This paper proposes a novel robust torque-observed valve-based control (RTOVC) framework to address velocity tracking in hydraulic IWDs that actuate heavy-duty wheeled mobile robots (HWMRs), considering such challenges as wheel slippages, sensor limitations, rough terrains, and modeling uncertainties. To overcome the sensor-dependent control systems associated with the closed-loop torque/pressure in hydraulic IWD-actuated HWMRs, a robust observer network based on an adaptive barrier Lyapunov function (BLF) is proposed to estimate the required in-wheel motor torque to track the velocity references. Then, another adaptive BLF for valve control signals is employed to modulate the hydraulic fluid to generate the estimated torque for each IWD. The RTOVC strategy ensures user-defined safety within the logarithmic BLF framework by constraining the valve control signal, actual velocity, velocity tracking error, and torque of each hydraulic IWD in an HWMR to avoid exceeding specified limits. Despite its safety constraints, external disturbances, and modeling uncertainties, robustness and uniformly exponential stability of the RTOVC-applied hydraulic IWD mechanism are ensured in HWMRs. Experimental investigations using a 6,500-kg HWMR, actuated by four independent IWDs under intense disturbances and safety-defined constraints, validate the performance of the RTOVC.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been submitted for possible publication in the IEEE"
    },
    {
        "paper id": "2409.11826",
        "abstract url": "https://arxiv.org/abs/2409.11826",
        "title": "A Taxonomy of Self-Admitted Technical Debt in Deep Learning Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The development of Machine Learning (ML)- and, more recently, of Deep Learning (DL)-intensive systems requires suitable choices, e.g., in terms of technology, algorithms, and hyper-parameters. Such choices depend on developers' experience, as well as on proper experimentation. Due to limited time availability, developers may adopt suboptimal, sometimes temporary choices, leading to a technical debt (TD) specifically related to the ML code. This paper empirically analyzes the presence of Self-Admitted Technical Debt (SATD) in DL systems. After selecting 100 open-source Python projects using popular DL frameworks, we identified SATD from their source comments and created a stratified sample of 443 SATD to analyze manually. We derived a taxonomy of DL-specific SATD through open coding, featuring seven categories and 41 leaves. The identified SATD categories pertain to different aspects of DL models, some of which are technological (e.g., due to hardware or libraries) and some related to suboptimal choices in the DL process, model usage, or configuration. Our findings indicate that DL-specific SATD differs from DL bugs found in previous studies, as it typically pertains to suboptimal solutions rather than functional (\\eg blocking) problems. Last but not least, we found that state-of-the-art static analysis tools do not help developers avoid such problems, and therefore, specific support is needed to cope with DL-specific SATD.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11852",
        "abstract url": "https://arxiv.org/abs/2409.11852",
        "title": "XP-MARL: Auxiliary Prioritization in Multi-Agent Reinforcement Learning to Address Non-Stationarity",
        "rating": "-10",
        "keywords": [],
        "abstract": "Non-stationarity poses a fundamental challenge in Multi-Agent Reinforcement Learning (MARL), arising from agents simultaneously learning and altering their policies. This creates a non-stationary environment from the perspective of each individual agent, often leading to suboptimal or even unconverged learning outcomes. We propose an open-source framework named XP-MARL, which augments MARL with auxiliary prioritization to address this challenge in cooperative settings. XP-MARL is 1) founded upon our hypothesis that prioritizing agents and letting higher-priority agents establish their actions first would stabilize the learning process and thus mitigate non-stationarity and 2) enabled by our proposed mechanism called action propagation, where higher-priority agents act first and communicate their actions, providing a more stationary environment for others. Moreover, instead of using a predefined or heuristic priority assignment, XP-MARL learns priority-assignment policies with an auxiliary MARL problem, leading to a joint learning scheme. Experiments in a motion-planning scenario involving Connected and Automated Vehicles (CAVs) demonstrate that XP-MARL improves the safety of a baseline model by 84.4% and outperforms a state-of-the-art approach, which improves the baseline by only 12.8%. Code: github.com/cas-lab-munich/sigmarl",
        "subjects": [
            "cs.RO",
            "cs.GT",
            "cs.MA"
        ],
        "comment": "7 pages, 5 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.11864",
        "abstract url": "https://arxiv.org/abs/2409.11864",
        "title": "Motivations, Challenges, Best Practices, and Benefits for Bots and Conversational Agents in Software Engineering: A Multivocal Literature Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "Bots are software systems designed to support users by automating a specific process, task, or activity. When such systems implement a conversational component to interact with the users, they are also known as conversational agents. Bots, particularly in their conversation-oriented version and AI-powered, have seen their adoption increase over time for software development and engineering purposes. Despite their exciting potential, ulteriorly enhanced by the advent of Generative AI and Large Language Models, bots still need to be improved to develop and integrate into the development cycle since practitioners report that bots add additional challenges that may worsen rather than improve. In this work, we aim to provide a taxonomy for characterizing bots, as well as a series of challenges for their adoption for Software Engineering associated with potential mitigation strategies. To reach our objectives, we conducted a multivocal literature review, reviewing both research and practitioner's literature. Through such an approach, we hope to contribute to both researchers and practitioners by providing first, a series of future research routes to follow, second, a list of strategies to adopt for improving the use of bots for software engineering purposes, and third, enforce a technology and knowledge transfer from the research field to the practitioners one, that is one of the primary goal of multivocal literature reviews.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11868",
        "abstract url": "https://arxiv.org/abs/2409.11868",
        "title": "Practical Investigation on the Distinguishability of Longa's Atomic Patterns",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the distinguishability of the atomic patterns for elliptic curve point doubling and addition operations proposed by Longa. We implemented a binary elliptic curve scalar multiplication kP algorithm with Longa's atomic patterns for the NIST elliptic curve P-256 using the open-source cryptographic library FLECC in C. We measured and analysed an electromagnetic trace of a single kP execution on a microcontroller (TI Launchpad F28379 board). Due to various technical limitations, significant differences in the execution time and the shapes of the atomic blocks could not be determined. Further investigations of the side channel analysis-resistance can be performed based on this work. Last but not least, we examined and corrected Longa's atomic patterns corresponding to formulae proposed by Longa.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11900",
        "abstract url": "https://arxiv.org/abs/2409.11900",
        "title": "On the complexity of the upgrading version of the maximal covering location problem",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this article, we study the complexity of the upgrading version of the maximal covering location problem with edge length modifications on networks. This problem is NP-hard on general networks. However, in some particular cases, we prove that this problem is solvable in polynomial time. The cases of star and path networks combined with different assumptions for the model parameters are analysed. In particular, we obtain that the problem on star networks is solvable in O(nlogn) time for uniform weights and NP-hard for non-uniform weights. On paths, the single facility problem is solvable in O(n^3) time, while the p-facility problem is NP-hard even with uniform costs and upper bounds (maximal upgrading per edge), as well as, integer parameter values. Furthermore, a pseudo-polynomial algorithm is developed for the single facility problem on trees with integer parameters.",
        "subjects": [
            "cs.DS",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11911",
        "abstract url": "https://arxiv.org/abs/2409.11911",
        "title": "AI paintings vs. Human Paintings? Deciphering Public Interactions and Perceptions towards AI-Generated Paintings on TikTok",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the development of generative AI technology, a vast array of AI-generated paintings (AIGP) have gone viral on social media like TikTok. However, some negative news about AIGP has also emerged. For example, in 2022, numerous painters worldwide organized a large-scale anti-AI movement because of the infringement in generative AI model training. This event reflected a social issue that, with the development and application of generative AI, public feedback and feelings towards it may have been overlooked. Therefore, to investigate public interactions and perceptions towards AIGP on social media, we analyzed user engagement level and comment sentiment scores of AIGP using human painting videos as a baseline. In analyzing user engagement, we also considered the possible moderating effect of the aesthetic quality of Paintings. Utilizing topic modeling, we identified seven reasons, including looks too real, looks too scary, ambivalence, etc., leading to negative public perceptions of AIGP. Our work may provide instructive suggestions for future generative AI technology development and avoid potential crises in human-AI collaboration.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2409.11946",
        "abstract url": "https://arxiv.org/abs/2409.11946",
        "title": "An Imperative Language for Verified Exact Real-Number Computation",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce Clerical, a programming language for exact real-number computation that combines first-order imperative-style programming with a limit operator for computation of real numbers as limits of Cauchy sequences. We address the semidecidability of the linear ordering of the reals by incorporating nondeterministic guarded choice, through which decisions based on partial comparison operations on reals can be patched together to give total programs. The interplay between mutable state, nondeterminism, and computation of limits is controlled by the requirement that expressions computing limits and guards modify only local state. We devise a domain-theoretic denotational semantics that uses a variant of Plotkin powerdomain construction tailored to our specific version of nondeterminism. We formulate a Hoare-style specification logic, show that it is sound for the denotational semantics, and illustrate the setup by implementing and proving correct a program for computation of $\u03c0$ as the least positive zero of $\\sin$. The modular character of Clerical allows us to compose the program from smaller parts, each of which is shown to be correct on its own. We provide a proof-of-concept OCaml implementation of Clerical, and formally verify parts of the development, notably the soundness of specification logic, in the Coq proof assistant.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11948",
        "abstract url": "https://arxiv.org/abs/2409.11948",
        "title": "Research Citations Building Trust in Wikipedia",
        "rating": "-10",
        "keywords": [],
        "abstract": "The use of Wikipedia citations in scholarly research has been the topic of much inquiry over the past decade. A cross-publisher study (Taylor & Francis and University of Michigan Press) convened by Digital Science was established in late 2022 to explore author sentiment towards Wikipedia as a trusted source of information. A short survey was designed to poll published authors about views and uses of Wikipedia and explore how the increased addition of research citations in Wikipedia might help combat misinformation in the context of increasing public engagement with and access to validated research sources. With 21,854 surveys sent, targeting 40,402 papers mentioned in Wikipedia, a total of 750 complete surveys from 60 countries were included in this analysis. In general, responses revealed a positive sentiment towards research citation in Wikipedia and the researcher engagement practices. However, our sub analysis revealed statistically significant differences when comparison articles vs books and across disciplines, but not open vs closed access. This study will open the door to further research and deepen our understanding of authors perceived trustworthiness of the representation of their research in Wikipedia.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.11979",
        "abstract url": "https://arxiv.org/abs/2409.11979",
        "title": "On the Stability of Consensus Control under Rotational Ambiguities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Consensus control of multiagent systems arises in various robotic applications such as rendezvous and formation control. For example, to compute the control inputs of individual agents, the difference in the positions in aligned coordinate frames i.e., the pairwise displacements are typically measured. However, the local coordinate frames might be subject to rotational ambiguities, such as a rotation or a reflection, particularly if the positions of the agent are not directly observed but reconstructed from e.g. pairwise Euclidean distances. This rotational ambiguity causes stability issues in practice, as agents have rotated perceptions of the environment. In this work, we conduct a thorough analysis of the stability in the presence of rotational ambiguities in several scenarios including e.g., proper and improper rotation, and the homogeneity of rotations. We give stability criteria and stability margin on the rotations, which are numerically verified with two traditional examples of consensus control.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.11980",
        "abstract url": "https://arxiv.org/abs/2409.11980",
        "title": "End-to-End Learning of Transmitter and Receiver Filters in Bandwidth Limited Fiber Optic Communication Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the application of end-to-end (E2E) learning for joint optimization of pulse-shaper and receiver filter to reduce intersymbol interference (ISI) in bandwidth-limited communication systems. We investigate this in two numerical simulation models: 1) an additive white Gaussian noise (AWGN) channel with bandwidth limitation and 2) an intensity modulated direct detection (IM/DD) link employing an electro-absorption modulator. For both simulation models, we implement a wavelength division multiplexing (WDM) scheme to ensure that the learned filters adhere to the bandwidth constraints of the WDM channels. Our findings reveal that E2E learning greatly surpasses traditional single-sided transmitter pulse-shaper or receiver filter optimization methods, achieving significant performance gains in terms of symbol error rate with shorter filter lengths. These results suggest that E2E learning can decrease the complexity and enhance the performance of future high-speed optical communication systems.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2409.11986",
        "abstract url": "https://arxiv.org/abs/2409.11986",
        "title": "Data-Efficient Quadratic Q-Learning Using LMIs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reinforcement learning (RL) has seen significant research and application results but often requires large amounts of training data. This paper proposes two data-efficient off-policy RL methods that use parametrized Q-learning. In these methods, the Q-function is chosen to be linear in the parameters and quadratic in selected basis functions in the state and control deviations from a base policy. A cost penalizing the $\\ell_1$-norm of Bellman errors is minimized. We propose two methods: Linear Matrix Inequality Q-Learning (LMI-QL) and its iterative variant (LMI-QLi), which solve the resulting episodic optimization problem through convex optimization. LMI-QL relies on a convex relaxation that yields a semidefinite programming (SDP) problem with linear matrix inequalities (LMIs). LMI-QLi entails solving sequential iterations of an SDP problem. Both methods combine convex optimization with direct Q-function learning, significantly improving learning speed. A numerical case study demonstrates their advantages over existing parametrized Q-learning methods.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Accepted for Presentation at 63rd IEEE Conference on Decision and Control, CDC 2024, Milan, Italy, 2024"
    },
    {
        "paper id": "2409.11989",
        "abstract url": "https://arxiv.org/abs/2409.11989",
        "title": "Equimetrics -- Applying HAR principles to equestrian activities",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents the Equimetrics data capture system. The primary objective is to apply HAR principles to enhance the understanding and optimization of equestrian performance. By integrating data from strategically placed sensors on the rider's body and the horse's limbs, the system provides a comprehensive view of their interactions. Preliminary data collection has demonstrated the system's ability to accurately classify various equestrian activities, such as walking, trotting, cantering, and jumping, while also detecting subtle changes in rider posture and horse movement. The system leverages open-source hardware and software to offer a cost-effective alternative to traditional motion capture technologies, making it accessible for researchers and trainers. The Equimetrics system represents a significant advancement in equestrian performance analysis, providing objective, data-driven insights that can be used to enhance training and competition outcomes.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "5 pages, 6 figures, Additional materials can be found at: https://zenodo.org/records/13367775"
    },
    {
        "paper id": "2409.11999",
        "abstract url": "https://arxiv.org/abs/2409.11999",
        "title": "On Randomized Computational Models and Complexity Classes: a Historical Overview",
        "rating": "-10",
        "keywords": [],
        "abstract": "Since their appearance in the 1950s, computational models capable of performing probabilistic choices have received wide attention and are nowadays pervasive in almost every areas of computer science. Their development was also inextricably linked with inquiries about computation power and resource issues. Although most crucial notions in the field are well-known, the related terminology is sometimes imprecise or misleading. The present work aims to clarify the core features and main differences between machines and classes developed in relation to randomized computation. To do so, we compare the modern definitions with original ones, recalling the context in which they first appeared, and investigate the relations linking probabilistic and counting models.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12012",
        "abstract url": "https://arxiv.org/abs/2409.12012",
        "title": "Shannon Entropy is better Feature than Category and Sentiment in User Feedback Processing",
        "rating": "-10",
        "keywords": [],
        "abstract": "App reviews in mobile app stores contain useful information which is used to improve applications and promote software evolution. This information is processed by automatic tools which prioritize reviews. In order to carry out this prioritization, reviews are decomposed into features like category and sentiment. Then, a weighted function assigns a weight to each feature and a review ranking is calculated. Unfortunately, in order to extract category and sentiment from reviews, its is required at least a classifier trained in an annotated corpus. Therefore this task is computational demanding. Thus, in this work, we propose Shannon Entropy as a simple feature which can replace standard features. Our results show that a Shannon Entropy based ranking is better than a standard ranking according to the NDCG metric. This result is promising even if we require fairness by means of algorithmic bias. Finally, we highlight a computational limit which appears in the search of the best ranking.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2409.12013",
        "abstract url": "https://arxiv.org/abs/2409.12013",
        "title": "Memory Consistency and Program Transformations",
        "rating": "-10",
        "keywords": [],
        "abstract": "A memory consistency model specifies the allowed behaviors of shared memory concurrent programs. At the language level, these models are known to have a non-trivial impact on the safety of program optimizations, limiting the ability to rearrange/refactor code without introducing new behaviors. Existing programming language memory models try to address this by permitting more (relaxed/weak) concurrent behaviors but are still unable to allow all the desired optimizations. A core problem is that weaker consistency models may also render optimizations unsafe, a conclusion that goes against the intuition of them allowing more behaviors. This exposes an open problem of the compositional interaction between memory consistency semantics and optimizations: which parts of the semantics correspond to allowing/disallowing which set of optimizations is unclear. In this work, we establish a formal foundation suitable enough to understand this compositional nature, decomposing optimizations into a finite set of elementary effects on program execution traces, over which aspects of safety can be assessed. We use this decomposition to identify a desirable compositional property (complete) that would guarantee the safety of optimizations from one memory model to another. We showcase its practicality by proving such a property between Sequential Consistency (SC) and $SC_{RR}$, the latter allowing independent read-read reordering over $SC$. Our work potentially paves way to a new design methodology of programming-language memory models, one that places emphasis on the optimizations desired to be performed.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12021",
        "abstract url": "https://arxiv.org/abs/2409.12021",
        "title": "Optimal Offline ORAM with Perfect Security via Simple Oblivious Priority Queues",
        "rating": "-10",
        "keywords": [],
        "abstract": "Oblivious RAM (ORAM) is a well-researched primitive to hide the memory access pattern of a RAM computation; it has a variety of applications in trusted computing, outsourced storage, and multiparty computation. In this paper, we study the so-called offline ORAM in which the sequence of memory access locations to be hidden is known in advance. Apart from their theoretical significance, offline ORAMs can be used to construct efficient oblivious algorithms. We obtain the first optimal offline ORAM with perfect security from oblivious priority queues via time-forward processing. For this, we present a simple construction of an oblivious priority queue with perfect security. Our construction achieves an asymptotically optimal (amortized) runtime of $\u0398(\\log N)$ per operation for a capacity of $N$ elements and is of independent interest. Building on our construction, we additionally present efficient external-memory instantiations of our oblivious, perfectly-secure construction: For the cache-aware setting, we match the optimal I/O complexity of $\u0398(\\frac{1}{B} \\log \\frac{N}{M})$ per operation (amortized), and for the cache-oblivious setting we achieve a near-optimal I/O complexity of $O(\\frac{1}{B} \\log \\frac{N}{M} \\log\\log_M N)$ per operation (amortized).",
        "subjects": [
            "cs.DS",
            "cs.CR"
        ],
        "comment": "23 pages, full version of the paper to appear in ISAAC 2024"
    },
    {
        "paper id": "2409.12027",
        "abstract url": "https://arxiv.org/abs/2409.12027",
        "title": "CEF: Connecting Elaborate Federal QKD Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "As QKD infrastructure becomes increasingly complex while being developed by different actors (typically national governments), interconnecting them into a federated network of very elaborate sub-networks that maintain a high degree of autonomy will pose unique challenges. We identify several such challenges and propose a 4-step orchestration framework to address them based on centralized research, target network planning, optimal QKD design, and protocol enforcement.",
        "subjects": [
            "cs.NI",
            "cs.CR",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12048",
        "abstract url": "https://arxiv.org/abs/2409.12048",
        "title": "Differential dynamic programming with stagewise equality and inequality constraints using interior point method",
        "rating": "-10",
        "keywords": [],
        "abstract": "Differential Dynamic Programming (DDP) is one of the indirect methods for solving an optimal control problem. Several extensions to DDP have been proposed to add stagewise state and control constraints, which can mainly be classified as augmented lagrangian methods, active set methods, and barrier methods. In this paper, we use an interior point method, which is a type of barrier method, to incorporate arbitrary stagewise equality and inequality state and control constraints. We also provide explicit update formulas for all the involved variables. Finally, we apply this algorithm to example systems such as the inverted pendulum, a continuously stirred tank reactor, car parking, and obstacle avoidance.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12068",
        "abstract url": "https://arxiv.org/abs/2409.12068",
        "title": "The repetition threshold for ternary rich words",
        "rating": "-10",
        "keywords": [],
        "abstract": "In 2014, Vesti proposed the problem of determining the repetition threshold for infinite rich words, i.e., for infinite words in which all factors of length $n$ contain $n$ distinct nonempty palindromic factors. In 2020, Currie, Mol, and Rampersad proved a conjecture of Baranwal and Shallit that the repetition threshold for binary rich words is $2 + \\sqrt{2}/2$. In this paper, we prove a structure theorem for $16/7$-power-free ternary rich words. Using the structure theorem, we deduce that the repetition threshold for ternary rich words is $1 + 1/(3 - \u03bc) \\approx 2.25876324$, where $\u03bc$ is the unique real root of the polynomial $x^3 - 2x^2 - 1$.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.FL"
        ],
        "comment": "60 pages"
    },
    {
        "paper id": "2409.12152",
        "abstract url": "https://arxiv.org/abs/2409.12152",
        "title": "Residual Descent Differential Dynamic Game (RD3G) -- A Fast Newton Solver for Constrained General Sum Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present Residual Descent Differential Dynamic Game (RD3G), a Newton-based solver for constrained multi-agent game-control problems. The proposed solver seeks a local Nash equilibrium for problems where agents are coupled through their rewards and state constraints. We compare the proposed method against competing state-of-the-art techniques and showcase the computational benefits of the RD3G algorithm on several example problems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.12161",
        "abstract url": "https://arxiv.org/abs/2409.12161",
        "title": "Generalized compression and compressive search of large datasets",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Big Data explosion has necessitated the development of search algorithms that scale sub-linearly in time and memory. While compression algorithms and search algorithms do exist independently, few algorithms offer both, and those which do are domain-specific. We present panCAKES, a novel approach to compressive search, i.e., a way to perform $k$-NN and $\u03c1$-NN search on compressed data while only decompressing a small, relevant, portion of the data. panCAKES assumes the manifold hypothesis and leverages the low-dimensional structure of the data to compress and search it efficiently. panCAKES is generic over any distance function for which the distance between two points is proportional to the memory cost of storing an encoding of one in terms of the other. This property holds for many widely-used distance functions, e.g. string edit distances (Levenshtein, Needleman-Wunsch, etc.) and set dissimilarity measures (Jaccard, Dice, etc.). We benchmark panCAKES on a variety of datasets, including genomic, proteomic, and set data. We compare compression ratios to gzip, and search performance between the compressed and uncompressed versions of the same dataset. panCAKES achieves compression ratios close to those of gzip, while offering sub-linear time performance for $k$-NN and $\u03c1$-NN search. We conclude that panCAKES is an efficient, general-purpose algorithm for exact compressive search on large datasets that obey the manifold hypothesis. We provide an open-source implementation of panCAKES in the Rust programming language.",
        "subjects": [
            "cs.DS",
            "cs.IR"
        ],
        "comment": null
    }
]