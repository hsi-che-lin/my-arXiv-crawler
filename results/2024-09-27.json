[
    {
        "paper id": "2409.18674",
        "abstract url": "https://arxiv.org/abs/2409.18674",
        "title": "Image-guided topic modeling for interpretable privacy classification",
        "rating": "2.5",
        "keywords": [
            [
                "vision language"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Predicting and explaining the private information contained in an image in human-understandable terms is a complex and contextual task. This task is challenging even for large language models. To facilitate the understanding of privacy decisions, we propose to predict image privacy based on a set of natural language content descriptors. These content descriptors are associated with privacy scores that reflect how people perceive image content. We generate descriptors with our novel Image-guided Topic Modeling (ITM) approach. ITM leverages, via multimodality alignment, both vision information and image textual descriptions from a vision language model. We use the ITM-generated descriptors to learn a privacy predictor, Priv$\\times$ITM, whose decisions are interpretable by design. Our Priv$\\times$ITM classifier outperforms the reference interpretable method by 5 percentage points in accuracy and performs comparably to the current non-interpretable state-of-the-art model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Paper accepted at the eXCV Workshop at ECCV 2024. Supplementary material included. Code available at https://github.com/idiap/itm"
    },
    {
        "paper id": "2409.19132",
        "abstract url": "https://arxiv.org/abs/2409.19132",
        "title": "From Vision to Audio and Beyond: A Unified Model for Audio-Visual Representation and Generation",
        "rating": "2.5",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Video encompasses both visual and auditory data, creating a perceptually rich experience where these two modalities complement each other. As such, videos are a valuable type of media for the investigation of the interplay between audio and visual elements. Previous studies of audio-visual modalities primarily focused on either audio-visual representation learning or generative modeling of a modality conditioned on the other, creating a disconnect between these two branches. A unified framework that learns representation and generates modalities has not been developed yet. In this work, we introduce a novel framework called Vision to Audio and Beyond (VAB) to bridge the gap between audio-visual representation learning and vision-to-audio generation. The key approach of VAB is that rather than working with raw video frames and audio data, VAB performs representation learning and generative modeling within latent spaces. In particular, VAB uses a pre-trained audio tokenizer and an image encoder to obtain audio tokens and visual features, respectively. It then performs the pre-training task of visual-conditioned masked audio token prediction. This training strategy enables the model to engage in contextual learning and simultaneous video-to-audio generation. After the pre-training phase, VAB employs the iterative-decoding approach to rapidly generate audio tokens conditioned on visual features. Since VAB is a unified model, its backbone can be fine-tuned for various audio-visual downstream tasks. Our experiments showcase the efficiency of VAB in producing high-quality audio from video, and its capability to acquire semantic audio-visual features, leading to competitive results in audio-visual retrieval and classification.",
        "subjects": [
            "cs.MM",
            "cs.CV",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted by ICML 2024"
    },
    {
        "paper id": "2409.19173",
        "abstract url": "https://arxiv.org/abs/2409.19173",
        "title": "HM3: Heterogeneous Multi-Class Model Merging",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Foundation language model deployments often include auxiliary guard-rail models to filter or classify text, detecting jailbreak attempts, biased or toxic output, or ensuring topic adherence. These additional models increase the complexity and cost of model inference, especially since many are also large language models. To address this issue, we explore training-free model merging techniques to consolidate these models into a single, multi-functional model. We propose Heterogeneous Multi-Class Model Merging (HM3) as a simple technique for merging multi-class classifiers with heterogeneous label spaces. Unlike parameter-efficient fine-tuning techniques like LoRA, which require extensive training and add complexity during inference, recent advancements allow models to be merged in a training-free manner. We report promising results for merging BERT-based guard models, some of which attain an average F1-score higher than the source models while reducing the inference time by up to 44%. We introduce self-merging to assess the impact of reduced task-vector density, finding that the more poorly performing hate speech classifier benefits from self-merging while higher-performing classifiers do not, which raises questions about using task vector reduction for model tuning.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18618",
        "abstract url": "https://arxiv.org/abs/2409.18618",
        "title": "Model-based Preference Optimization in Abstractive Summarization without Human Feedback",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "In abstractive summarization, the challenge of producing concise and accurate summaries arises from the vast amount of information contained in the source document. Consequently, although Large Language Models (LLMs) can generate fluent text, they often introduce inaccuracies by hallucinating content not found in the original source. While supervised fine-tuning methods that maximize likelihood contribute to this issue, they do not consistently enhance the faithfulness of the summaries. Preference-based optimization methods, such as Direct Preference Optimization (DPO), can further refine the model to align with human preferences. However, these methods still heavily depend on costly human feedback. In this work, we introduce a novel and straightforward approach called Model-based Preference Optimization (MPO) to fine-tune LLMs for improved summarization abilities without any human feedback. By leveraging the model's inherent summarization capabilities, we create a preference dataset that is fully generated by the model using different decoding strategies. Our experiments on standard summarization datasets and various metrics demonstrate that our proposed MPO significantly enhances the quality of generated summaries without relying on human feedback.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted by EMNLP 2024"
    },
    {
        "paper id": "2409.18644",
        "abstract url": "https://arxiv.org/abs/2409.18644",
        "title": "Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Inspired by the legal doctrine of stare decisis, which leverages precedents (prior cases) for informed decision-making, we explore methods to integrate them into LJP models. To facilitate precedent retrieval, we train a retriever with a fine-grained relevance signal based on the overlap ratio of alleged articles between cases. We investigate two strategies to integrate precedents: direct incorporation at inference via label interpolation based on case proximity and during training via a precedent fusion module using a stacked-cross attention model. We employ joint training of the retriever and LJP models to address latent space divergence between them. Our experiments on LJP tasks from the ECHR jurisdiction reveal that integrating precedents during training coupled with joint training of the retriever and LJP model, outperforms models without precedents or with precedents incorporated only at inference, particularly benefiting sparser articles.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EMNLP Findings"
    },
    {
        "paper id": "2409.18645",
        "abstract url": "https://arxiv.org/abs/2409.18645",
        "title": "The Craft of Selective Prediction: Towards Reliable Case Outcome Classification -- An Empirical Study on European Court of Human Rights Cases",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "In high-stakes decision-making tasks within legal NLP, such as Case Outcome Classification (COC), quantifying a model's predictive confidence is crucial. Confidence estimation enables humans to make more informed decisions, particularly when the model's certainty is low, or where the consequences of a mistake are significant. However, most existing COC works prioritize high task performance over model reliability. This paper conducts an empirical investigation into how various design choices including pre-training corpus, confidence estimator and fine-tuning loss affect the reliability of COC models within the framework of selective prediction. Our experiments on the multi-label COC task, focusing on European Court of Human Rights (ECtHR) cases, highlight the importance of a diverse yet domain-specific pre-training corpus for better calibration. Additionally, we demonstrate that larger models tend to exhibit overconfidence, Monte Carlo dropout methods produce reliable confidence estimates, and confident error regularization effectively mitigates overconfidence. To our knowledge, this is the first systematic exploration of selective prediction in legal NLP. Our findings underscore the need for further research on enhancing confidence measurement and improving the trustworthiness of models in the legal domain.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EMNLP Findings"
    },
    {
        "paper id": "2409.18647",
        "abstract url": "https://arxiv.org/abs/2409.18647",
        "title": "HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Rhetorical Role Labeling (RRL) of legal documents is pivotal for various downstream tasks such as summarization, semantic case search and argument mining. Existing approaches often overlook the varying difficulty levels inherent in legal document discourse styles and rhetorical roles. In this work, we propose HiCuLR, a hierarchical curriculum learning framework for RRL. It nests two curricula: Rhetorical Role-level Curriculum (RC) on the outer layer and Document-level Curriculum (DC) on the inner layer. DC categorizes documents based on their difficulty, utilizing metrics like deviation from a standard discourse structure and exposes the model to them in an easy-to-difficult fashion. RC progressively strengthens the model to discern coarse-to-fine-grained distinctions between rhetorical roles. Our experiments on four RRL datasets demonstrate the efficacy of HiCuLR, highlighting the complementary nature of DC and RC.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EMNLP 2024 Findings"
    },
    {
        "paper id": "2409.18680",
        "abstract url": "https://arxiv.org/abs/2409.18680",
        "title": "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Various audio-LLMs (ALLMs) have been explored recently for tackling different audio tasks simultaneously using a single, unified model. While existing evaluations of ALLMs primarily focus on single-audio tasks, real-world applications often involve processing multiple audio streams simultaneously. To bridge this gap, we propose the first multi-audio evaluation (MAE) benchmark that consists of 20 datasets from 11 multi-audio tasks encompassing both speech and sound scenarios. Comprehensive experiments on MAE demonstrate that the existing ALLMs, while being powerful in comprehending primary audio elements in individual audio inputs, struggling to handle multi-audio scenarios. To this end, we propose a novel multi-audio-LLM (MALLM) to capture audio context among multiple similar audios using discriminative learning on our proposed synthetic data. The results demonstrate that the proposed MALLM outperforms all baselines and achieves high data efficiency using synthetic data without requiring human annotations. The proposed MALLM opens the door for ALLMs towards multi-audio processing era and brings us closer to replicating human auditory capabilities in machines.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CL",
            "cs.MM",
            "eess.AS"
        ],
        "comment": "EMNLP24 Findings"
    },
    {
        "paper id": "2409.18686",
        "abstract url": "https://arxiv.org/abs/2409.18686",
        "title": "A Novel Unified Architecture for Low-Shot Counting by Detection and Segmentation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Low-shot object counters estimate the number of objects in an image using few or no annotated exemplars. Objects are localized by matching them to prototypes, which are constructed by unsupervised image-wide object appearance aggregation. Due to potentially diverse object appearances, the existing approaches often lead to overgeneralization and false positive detections. Furthermore, the best-performing methods train object localization by a surrogate loss, that predicts a unit Gaussian at each object center. This loss is sensitive to annotation error, hyperparameters and does not directly optimize the detection task, leading to suboptimal counts. We introduce GeCo, a novel low-shot counter that achieves accurate object detection, segmentation, and count estimation in a unified architecture. GeCo robustly generalizes the prototypes across objects appearances through a novel dense object query formulation. In addition, a novel counting loss is proposed, that directly optimizes the detection task and avoids the issues of the standard surrogate loss. GeCo surpasses the leading few-shot detection-based counters by $\\sim$25\\% in the total count MAE, achieves superior detection accuracy and sets a new solid state-of-the-art result across all low-shot counting setups.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to NeurIPS2024"
    },
    {
        "paper id": "2409.18721",
        "abstract url": "https://arxiv.org/abs/2409.18721",
        "title": "Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs",
        "rating": "1.5",
        "keywords": [
            [
                "time efficiency",
                "GPU memory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Scalability issue plays a crucial role in productionizing modern recommender systems. Even lightweight architectures may suffer from high computational overload due to intermediate calculations, limiting their practicality in real-world applications. Specifically, applying full Cross-Entropy (CE) loss often yields state-of-the-art performance in terms of recommendations quality. Still, it suffers from excessive GPU memory utilization when dealing with large item catalogs. This paper introduces a novel Scalable Cross-Entropy (SCE) loss function in the sequential learning setup. It approximates the CE loss for datasets with large-size catalogs, enhancing both time efficiency and memory usage without compromising recommendations quality. Unlike traditional negative sampling methods, our approach utilizes a selective GPU-efficient computation strategy, focusing on the most informative elements of the catalog, particularly those most likely to be false positives. This is achieved by approximating the softmax distribution over a subset of the model outputs through the maximum inner product search. Experimental results on multiple datasets demonstrate the effectiveness of SCE in reducing peak memory usage by a factor of up to 100 compared to the alternatives, retaining or even exceeding their metrics values. The proposed approach also opens new perspectives for large-scale developments in different domains, such as large language models.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "comment": "11 pages, accepted for RecSys'24"
    },
    {
        "paper id": "2409.18747",
        "abstract url": "https://arxiv.org/abs/2409.18747",
        "title": "Cottention: Linear Transformers With Cosine Attention",
        "rating": "1.5",
        "keywords": [
            [
                "memory-efficient"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Attention mechanisms, particularly softmax attention, have been instrumental in the success of transformer-based models such as GPT. However, the quadratic memory complexity of softmax attention with respect to sequence length poses significant challenges for processing longer sequences. We introduce Cottention, a novel attention mechanism that replaces the softmax operation with cosine similarity. By leveraging the properties of cosine similarity and rearranging the attention equation, Cottention achieves native linear memory complexity with respect to sequence length, making it inherently more memory-efficient than softmax attention. We demonstrate that Cottention can be reformulated as a recurrent neural network (RNN) with a finite hidden state, allowing for constant memory usage during inference. We evaluate Cottention on both the bidirectional BERT and causal GPT tasks, demonstrating comparable performance to softmax attention while significantly reducing memory requirements. To ensure efficient computation, we develop a custom CUDA kernel for Cottention. Our results show that Cottention is a promising alternative to softmax attention, enabling the processing of longer sequences without sacrificing performance, due to its native linear memory complexity and ability to maintain a constant memory footprint during inference.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages, 5 figures"
    },
    {
        "paper id": "2409.18783",
        "abstract url": "https://arxiv.org/abs/2409.18783",
        "title": "DualDn: Dual-domain Denoising via Differentiable ISP",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Image denoising is a critical component in a camera's Image Signal Processing (ISP) pipeline. There are two typical ways to inject a denoiser into the ISP pipeline: applying a denoiser directly to captured raw frames (raw domain) or to the ISP's output sRGB images (sRGB domain). However, both approaches have their limitations. Residual noise from raw-domain denoising can be amplified by the subsequent ISP processing, and the sRGB domain struggles to handle spatially varying noise since it only sees noise distorted by the ISP. Consequently, most raw or sRGB domain denoising works only for specific noise distributions and ISP configurations. To address these challenges, we propose DualDn, a novel learning-based dual-domain denoising. Unlike previous single-domain denoising, DualDn consists of two denoising networks: one in the raw domain and one in the sRGB domain. The raw domain denoising adapts to sensor-specific noise as well as spatially varying noise levels, while the sRGB domain denoising adapts to ISP variations and removes residual noise amplified by the ISP. Both denoising networks are connected with a differentiable ISP, which is trained end-to-end and discarded during the inference stage. With this design, DualDn achieves greater generalizability compared to most learning-based denoising methods, as it can adapt to different unseen noises, ISP parameters, and even novel ISP pipelines. Experiments show that DualDn achieves state-of-the-art performance and can adapt to different denoising architectures. Moreover, DualDn can be used as a plug-and-play denoising module with real cameras without retraining, and still demonstrate better performance than commercial on-camera denoising. The project website is available at: https://openimaginglab.github.io/DualDn/",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted at ECCV 2024, Project page: https://openimaginglab.github.io/DualDn/"
    },
    {
        "paper id": "2409.18892",
        "abstract url": "https://arxiv.org/abs/2409.18892",
        "title": "IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "As Large Language Models (LLMs) grow increasingly adept at managing complex tasks, the evaluation set must keep pace with these advancements to ensure it remains sufficiently discriminative. Item Discrimination (ID) theory, which is widely used in educational assessment, measures the ability of individual test items to differentiate between high and low performers. Inspired by this theory, we propose an ID-induced prompt synthesis framework for evaluating LLMs to ensure the evaluation set can continually update and refine according to model abilities. Our data synthesis framework prioritizes both breadth and specificity. It can generate prompts that comprehensively evaluate the capabilities of LLMs while revealing meaningful performance differences between models, allowing for effective discrimination of their relative strengths and weaknesses across various tasks and domains. To produce high-quality data, we incorporate a self-correct mechanism into our generalization framework, and develop two models to predict prompt discrimination and difficulty score to facilitate our data synthesis framework, contributing valuable tools to evaluation data synthesis research. We apply our generated data to evaluate five SOTA models. Our data achieves an average score of 51.92, accompanied by a variance of 10.06. By contrast, previous works (i.e., SELF-INSTRUCT and WizardLM) obtain an average score exceeding 67, with a variance below 3.2. The results demonstrate that the data generated by our framework is more challenging and discriminative compared to previous works. We will release a dataset of over 3,000 carefully crafted prompts to facilitate evaluation research of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2409.18951",
        "abstract url": "https://arxiv.org/abs/2409.18951",
        "title": "Spectral Wavelet Dropout: Regularization in the Wavelet Domain",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Regularization techniques help prevent overfitting and therefore improve the ability of convolutional neural networks (CNNs) to generalize. One reason for overfitting is the complex co-adaptations among different parts of the network, which make the CNN dependent on their joint response rather than encouraging each part to learn a useful feature representation independently. Frequency domain manipulation is a powerful strategy for modifying data that has temporal and spatial coherence by utilizing frequency decomposition. This work introduces Spectral Wavelet Dropout (SWD), a novel regularization method that includes two variants: 1D-SWD and 2D-SWD. These variants improve CNN generalization by randomly dropping detailed frequency bands in the discrete wavelet decomposition of feature maps. Our approach distinguishes itself from the pre-existing Spectral \"Fourier\" Dropout (2D-SFD), which eliminates coefficients in the Fourier domain. Notably, SWD requires only a single hyperparameter, unlike the two required by SFD. We also extend the literature by implementing a one-dimensional version of Spectral \"Fourier\" Dropout (1D-SFD), setting the stage for a comprehensive comparison. Our evaluation shows that both 1D and 2D SWD variants have competitive performance on CIFAR-10/100 benchmarks relative to both 1D-SFD and 2D-SFD. Specifically, 1D-SWD has a significantly lower computational complexity compared to 1D/2D-SFD. In the Pascal VOC Object Detection benchmark, SWD variants surpass 1D-SFD and 2D-SFD in performance and demonstrate lower computational complexity during training.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by The International Conference on Machine Learning and Applications (ICMLA) 2024"
    },
    {
        "paper id": "2409.18962",
        "abstract url": "https://arxiv.org/abs/2409.18962",
        "title": "Exploring Token Pruning in Vision State Space Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "State Space Models (SSMs) have the advantage of keeping linear computational complexity compared to attention modules in transformers, and have been applied to vision tasks as a new type of powerful vision foundation model. Inspired by the observations that the final prediction in vision transformers (ViTs) is only based on a subset of most informative tokens, we take the novel step of enhancing the efficiency of SSM-based vision models through token-based pruning. However, direct applications of existing token pruning techniques designed for ViTs fail to deliver good performance, even with extensive fine-tuning. To address this issue, we revisit the unique computational characteristics of SSMs and discover that naive application disrupts the sequential token positions. This insight motivates us to design a novel and general token pruning method specifically for SSM-based vision models. We first introduce a pruning-aware hidden state alignment method to stabilize the neighborhood of remaining tokens for performance enhancement. Besides, based on our detailed analysis, we propose a token importance evaluation method adapted for SSM models, to guide the token pruning. With efficient implementation and practical acceleration methods, our method brings actual speedup. Extensive experiments demonstrate that our approach can achieve significant computation reduction with minimal impact on performance across different tasks. Notably, we achieve 81.7\\% accuracy on ImageNet with a 41.6\\% reduction in the FLOPs for pruned PlainMamba-L3. Furthermore, our work provides deeper insights into understanding the behavior of SSM-based vision models for future research.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "NeurIPS'24"
    },
    {
        "paper id": "2409.19044",
        "abstract url": "https://arxiv.org/abs/2409.19044",
        "title": "On the Inductive Bias of Stacking Towards Improving Reasoning",
        "rating": "1.5",
        "keywords": [
            [
                "training-efficient"
            ],
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Given the increasing scale of model sizes, novel training strategies like gradual stacking [Gong et al., 2019, Reddi et al., 2023] have garnered interest. Stacking enables efficient training by gradually growing the depth of a model in stages and using layers from a smaller model in an earlier stage to initialize the next stage. Although efficient for training, the model biases induced by such growing approaches are largely unexplored. In this work, we examine this fundamental aspect of gradual stacking, going beyond its efficiency benefits. We propose a variant of gradual stacking called MIDAS that can speed up language model training by up to 40%. Furthermore we discover an intriguing phenomenon: MIDAS is not only training-efficient but surprisingly also has an inductive bias towards improving downstream tasks, especially tasks that require reasoning abilities like reading comprehension and math problems, despite having similar or slightly worse perplexity compared to baseline training. To further analyze this inductive bias, we construct reasoning primitives -- simple synthetic tasks that are building blocks for reasoning -- and find that a model pretrained with stacking is significantly better than standard pretraining on these primitives, with and without fine-tuning. This provides stronger and more robust evidence for this inductive bias towards reasoning. These findings of training efficiency and inductive bias towards reasoning are verified at 1B, 2B and 8B parameter language models. Finally, we conjecture the underlying reason for this inductive bias by exploring the connection of stacking to looped models and provide strong supporting empirical analysis.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at NeurIPS 2024"
    },
    {
        "paper id": "2409.19074",
        "abstract url": "https://arxiv.org/abs/2409.19074",
        "title": "Show and Guide: Instructional-Plan Grounded Vision and Language Model",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Guiding users through complex procedural plans is an inherently multimodal task in which having visually illustrated plan steps is crucial to deliver an effective plan guidance. However, existing works on plan-following language models (LMs) often are not capable of multimodal input and output. In this work, we present MM-PlanLLM, the first multimodal LLM designed to assist users in executing instructional tasks by leveraging both textual plans and visual information. Specifically, we bring cross-modality through two key tasks: Conversational Video Moment Retrieval, where the model retrieves relevant step-video segments based on user queries, and Visually-Informed Step Generation, where the model generates the next step in a plan, conditioned on an image of the user's current progress. MM-PlanLLM is trained using a novel multitask-multistage approach, designed to gradually expose the model to multimodal instructional-plans semantic layers, achieving strong performance on both multimodal and textual dialogue in a plan-grounded setting. Furthermore, we show that the model delivers cross-modal temporal and plan-structure representations aligned between textual plan steps and instructional video moments.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "Accepted at EMNLP 2024 Main Track"
    },
    {
        "paper id": "2409.19210",
        "abstract url": "https://arxiv.org/abs/2409.19210",
        "title": "Learning to Obstruct Few-Shot Image Classification over Restricted Classes",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Advancements in open-source pre-trained backbones make it relatively easy to fine-tune a model for new tasks. However, this lowered entry barrier poses potential risks, e.g., bad actors developing models for harmful applications. A question arises: Is possible to develop a pre-trained model that is difficult to fine-tune for certain downstream tasks? To begin studying this, we focus on few-shot classification (FSC). Specifically, we investigate methods to make FSC more challenging for a set of restricted classes while maintaining the performance of other classes. We propose to meta-learn over the pre-trained backbone in a manner that renders it a ''poor initialization''. Our proposed Learning to Obstruct (LTO) algorithm successfully obstructs four FSC methods across three datasets, including ImageNet and CIFAR100 for image classification, as well as CelebA for attribute classification.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2409.19232",
        "abstract url": "https://arxiv.org/abs/2409.19232",
        "title": "TrojVLM: Backdoor Attack Against Vision Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "Vision Language",
                "VLMs"
            ],
            [
                "Attack"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "The emergence of Vision Language Models (VLMs) is a significant advancement in integrating computer vision with Large Language Models (LLMs) to produce detailed text descriptions based on visual inputs, yet it introduces new security vulnerabilities. Unlike prior work that centered on single modalities or classification tasks, this study introduces TrojVLM, the first exploration of backdoor attacks aimed at VLMs engaged in complex image-to-text generation. Specifically, TrojVLM inserts predetermined target text into output text when encountering poisoned images. Moreover, a novel semantic preserving loss is proposed to ensure the semantic integrity of the original image content. Our evaluation on image captioning and visual question answering (VQA) tasks confirms the effectiveness of TrojVLM in maintaining original semantic content while triggering specific target text outputs. This study not only uncovers a critical security risk in VLMs and image-to-text generation but also sets a foundation for future research on securing multimodal models against such sophisticated threats.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ECCV 2024"
    },
    {
        "paper id": "2409.18446",
        "abstract url": "https://arxiv.org/abs/2409.18446",
        "title": "Exploring Language Model Generalization in Low-Resource Extractive QA",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we investigate Extractive Question Answering (EQA) with Large Language Models (LLMs) under domain drift, i.e., can LLMs generalize well to closed-domains that require specific knowledge such as medicine and law in a zero-shot fashion without additional in-domain training? To this end, we devise a series of experiments to empirically explain the performance gap. Our findings suggest that: a) LLMs struggle with dataset demands of closed-domains such as retrieving long answer-spans; b) Certain LLMs, despite showing strong overall performance, display weaknesses in meeting basic requirements as discriminating between domain-specific senses of words which we link to pre-processing decisions; c) Scaling model parameters is not always effective for cross-domain generalization; and d) Closed-domain datasets are quantitatively much different than open-domain EQA datasets and current LLMs struggle to deal with them. Our findings point out important directions for improving existing LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18459",
        "abstract url": "https://arxiv.org/abs/2409.18459",
        "title": "FoodMLLM-JP: Leveraging Multimodal Large Language Models for Japanese Recipe Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Research on food image understanding using recipe data has been a long-standing focus due to the diversity and complexity of the data. Moreover, food is inextricably linked to people's lives, making it a vital research area for practical applications such as dietary management. Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities, not only in their vast knowledge but also in their ability to handle languages naturally. While English is predominantly used, they can also support multiple languages including Japanese. This suggests that MLLMs are expected to significantly improve performance in food image understanding tasks. We fine-tuned open MLLMs LLaVA-1.5 and Phi-3 Vision on a Japanese recipe dataset and benchmarked their performance against the closed model GPT-4o. We then evaluated the content of generated recipes, including ingredients and cooking procedures, using 5,000 evaluation samples that comprehensively cover Japanese food culture. Our evaluation demonstrates that the open models trained on recipe data outperform GPT-4o, the current state-of-the-art model, in ingredient generation. Our model achieved F1 score of 0.531, surpassing GPT-4o's F1 score of 0.481, indicating a higher level of accuracy. Furthermore, our model exhibited comparable performance to GPT-4o in generating cooking procedure text.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": "14 pages, 5 figures"
    },
    {
        "paper id": "2409.18472",
        "abstract url": "https://arxiv.org/abs/2409.18472",
        "title": "URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological and Multilingual Knowledge Base",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "URIEL is a knowledge base offering geographical, phylogenetic, and typological vector representations for 7970 languages. It includes distance measures between these vectors for 4005 languages, which are accessible via the lang2vec tool. Despite being frequently cited, URIEL is limited in terms of linguistic inclusion and overall usability. To tackle these challenges, we introduce URIEL+, an enhanced version of URIEL and lang2vec addressing these limitations. In addition to expanding typological feature coverage for 2898 languages, URIEL+ improves user experience with robust, customizable distance calculations to better suit the needs of the users. These upgrades also offer competitive performance on downstream tasks and provide distances that better align with linguistic distance studies.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18478",
        "abstract url": "https://arxiv.org/abs/2409.18478",
        "title": "Temporal2Seq: A Unified Framework for Temporal Video Understanding Tasks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the development of video understanding, there is a proliferation of tasks for clip-level temporal video analysis, including temporal action detection (TAD), temporal action segmentation (TAS), and generic event boundary detection (GEBD). While task-specific video understanding models have exhibited outstanding performance in each task, there remains a dearth of a unified framework capable of simultaneously addressing multiple tasks, which is a promising direction for the next generation of AI. To this end, in this paper, we propose a single unified framework, coined as Temporal2Seq, to formulate the output of these temporal video understanding tasks as a sequence of discrete tokens. With this unified token representation, Temporal2Seq can train a generalist model within a single architecture on different video understanding tasks. In the absence of multi-task learning (MTL) benchmarks, we compile a comprehensive co-training dataset by borrowing the datasets from TAD, TAS, and GEBD tasks. We evaluate our Temporal2Seq generalist model on the corresponding test sets of three tasks, demonstrating that Temporal2Seq can produce reasonable results on various tasks and achieve advantages compared with single-task training on this framework. We also investigate the generalization performance of our generalist model on new datasets from different tasks, which yields superior performance to the specific model.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18497",
        "abstract url": "https://arxiv.org/abs/2409.18497",
        "title": "Neural Video Representation for Redundancy Reduction and Consistency Preservation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Implicit neural representations (INRs) embed various signals into networks. They have gained attention in recent years because of their versatility in handling diverse signal types. For videos, INRs achieve video compression by embedding video signals into networks and compressing them. Conventional methods use an index that expresses the time of the frame or the features extracted from the frame as inputs to the network. The latter method provides greater expressive capability as the input is specific to each video. However, the features extracted from frames often contain redundancy, which contradicts the purpose of video compression. Moreover, since frame time information is not explicitly provided to the network, learning the relationships between frames is challenging. To address these issues, we aim to reduce feature redundancy by extracting features based on the high-frequency components of the frames. In addition, we use feature differences between adjacent frames in order for the network to learn frame relationships smoothly. We propose a video representation method that uses the high-frequency components of frames and the differences in features between adjacent frames. The experimental results show that our method outperforms the existing HNeRV method in 90 percent of the videos.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18511",
        "abstract url": "https://arxiv.org/abs/2409.18511",
        "title": "Do We Need Domain-Specific Embedding Models? An Empirical Investigation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Embedding models play a crucial role in representing and retrieving information across various NLP applications. Recent advancements in Large Language Models (LLMs) have further enhanced the performance of embedding models, which are trained on massive amounts of text covering almost every domain. These models are often benchmarked on general-purpose datasets like Massive Text Embedding Benchmark (MTEB), where they demonstrate superior performance. However, a critical question arises: Is the development of domain-specific embedding models necessary when general-purpose models are trained on vast corpora that already include specialized domain texts? In this paper, we empirically investigate this question, choosing the finance domain as an example. We introduce the Finance Massive Text Embedding Benchmark (FinMTEB), a counterpart to MTEB that consists of financial domain-specific text datasets. We evaluate the performance of seven state-of-the-art embedding models on FinMTEB and observe a significant performance drop compared to their performance on MTEB. To account for the possibility that this drop is driven by FinMTEB's higher complexity, we propose four measures to quantify dataset complexity and control for this factor in our analysis. Our analysis provides compelling evidence that state-of-the-art embedding models struggle to capture domain-specific linguistic and semantic patterns, even when trained on large general-purpose corpora. This study sheds light on the necessity of developing domain-specific embedding models in the LLM era, offering valuable insights for researchers and practitioners.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": "https://github.com/yixuantt/FinMTEB"
    },
    {
        "paper id": "2409.18512",
        "abstract url": "https://arxiv.org/abs/2409.18512",
        "title": "EmoPro: A Prompt Selection Strategy for Emotional Expression in LM-based Speech Synthesis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent advancements in speech synthesis models, trained on extensive datasets, have demonstrated remarkable zero-shot capabilities. These models can control content, timbre, and emotion in generated speech based on prompt inputs. Despite these advancements, the choice of prompts significantly impacts the output quality, yet most existing selection schemes do not adequately address the control of emotional intensity. To address this question, this paper proposes a two-stage prompt selection strategy EmoPro, which is specifically designed for emotionally controllable speech synthesis. This strategy focuses on selecting highly expressive and high-quality prompts by evaluating them from four perspectives: emotional expression strength, speech quality, text-emotion consistency, and model generation performance. Experimental results show that prompts selected using the proposed method result in more emotionally expressive and engaging synthesized speech compared to those obtained through baseline. Audio samples and codes will be available at https://whyrrrrun.github.io/EmoPro/.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18536",
        "abstract url": "https://arxiv.org/abs/2409.18536",
        "title": "How Effective is Pre-training of Large Masked Autoencoders for Downstream Earth Observation Tasks?",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Self-supervised pre-training has proven highly effective for many computer vision tasks, particularly when labelled data are scarce. In the context of Earth Observation (EO), foundation models and various other Vision Transformer (ViT)-based approaches have been successfully applied for transfer learning to downstream tasks. However, it remains unclear under which conditions pre-trained models offer significant advantages over training from scratch. In this study, we investigate the effectiveness of pre-training ViT-based Masked Autoencoders (MAE) for downstream EO tasks, focusing on reconstruction, segmentation, and classification. We consider two large ViT-based MAE pre-trained models: a foundation model (Prithvi) and SatMAE. We evaluate Prithvi on reconstruction and segmentation-based downstream tasks, and for SatMAE we assess its performance on a classification downstream task. Our findings suggest that pre-training is particularly beneficial when the fine-tuning task closely resembles the pre-training task, e.g. reconstruction. In contrast, for tasks such as segmentation or classification, training from scratch with specific hyperparameter adjustments proved to be equally or more effective.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18538",
        "abstract url": "https://arxiv.org/abs/2409.18538",
        "title": "A Survey on Complex Tasks for Goal-Directed Interactive Agents",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Goal-directed interactive agents, which autonomously complete tasks through interactions with their environment, can assist humans in various domains of their daily lives. Recent advances in large language models (LLMs) led to a surge of new, more and more challenging tasks to evaluate such agents. To properly contextualize performance across these tasks, it is imperative to understand the different challenges they pose to agents. To this end, this survey compiles relevant tasks and environments for evaluating goal-directed interactive agents, structuring them along dimensions relevant for understanding current obstacles. An up-to-date compilation of relevant resources can be found on our project website: https://coli-saar.github.io/interactive-agents.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18543",
        "abstract url": "https://arxiv.org/abs/2409.18543",
        "title": "Reducing Semantic Ambiguity In Domain Adaptive Semantic Segmentation Via Probabilistic Prototypical Pixel Contrast",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Domain adaptation aims to reduce the model degradation on the target domain caused by the domain shift between the source and target domains. Although encouraging performance has been achieved by combining cognitive learning with the self-training paradigm, they suffer from ambiguous scenarios caused by scale, illumination, or overlapping when deploying deterministic embedding. To address these issues, we propose probabilistic proto-typical pixel contrast (PPPC), a universal adaptation framework that models each pixel embedding as a probability via multivariate Gaussian distribution to fully exploit the uncertainty within them, eventually improving the representation quality of the model. In addition, we derive prototypes from probability estimation posterior probability estimation which helps to push the decision boundary away from the ambiguity points. Moreover, we employ an efficient method to compute similarity between distributions, eliminating the need for sampling and reparameterization, thereby significantly reducing computational overhead. Further, we dynamically select the ambiguous crops at the image level to enlarge the number of boundary points involved in contrastive learning, which benefits the establishment of precise distributions for each category. Extensive experimentation demonstrates that PPPC not only helps to address ambiguity at the pixel level, yielding discriminative representations but also achieves significant improvements in both synthetic-to-real and day-to-night adaptation tasks. It surpasses the previous state-of-the-art (SOTA) by +5.2% mIoU in the most challenging daytime-to-nighttime adaptation scenario, exhibiting stronger generalization on other unseen datasets. The code and models are available at https://github.com/DarlingInTheSV/Probabilistic-Prototypical-Pixel-Contrast.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "revise"
    },
    {
        "paper id": "2409.18548",
        "abstract url": "https://arxiv.org/abs/2409.18548",
        "title": "Research on Predicting Public Opinion Event Heat Levels Based on Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, with the rapid development of large language models, serval models such as GPT-4o have demonstrated extraordinary capabilities, surpassing human performance in various language tasks. As a result, many researchers have begun exploring their potential applications in the field of public opinion analysis. This study proposes a novel large-language-models-based method for public opinion event heat level prediction. First, we preprocessed and classified 62,836 Chinese hot event data collected between July 2022 and December 2023. Then, based on each event's online dissemination heat index, we used the MiniBatchKMeans algorithm to automatically cluster the events and categorize them into four heat levels (ranging from low heat to very high heat). Next, we randomly selected 250 events from each heat level, totalling 1,000 events, to build the evaluation dataset. During the evaluation process, we employed various large language models to assess their accuracy in predicting event heat levels in two scenarios: without reference cases and with similar case references. The results showed that GPT-4o and DeepseekV2 performed the best in the latter case, achieving prediction accuracies of 41.4% and 41.5%, respectively. Although the overall prediction accuracy remains relatively low, it is worth noting that for low-heat (Level 1) events, the prediction accuracies of these two models reached 73.6% and 70.4%, respectively. Additionally, the prediction accuracy showed a downward trend from Level 1 to Level 4, which correlates with the uneven distribution of data across the heat levels in the actual dataset. This suggests that with the more robust dataset, public opinion event heat level prediction based on large language models will have significant research potential for the future.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "conference"
    },
    {
        "paper id": "2409.18553",
        "abstract url": "https://arxiv.org/abs/2409.18553",
        "title": "Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we propose a framework to enhance the robustness of the neural models by mitigating the effects of process-induced and aging-related variations of analog computing components on the accuracy of the analog neural networks. We model these variations as the noise affecting the precision of the activations and introduce a denoising block inserted between selected layers of a pre-trained model. We demonstrate that training the denoising block significantly increases the model's robustness against various noise levels. To minimize the overhead associated with adding these blocks, we present an exploration algorithm to identify optimal insertion points for the denoising blocks. Additionally, we propose a specialized architecture to efficiently execute the denoising blocks, which can be integrated into mixed-signal accelerators. We evaluate the effectiveness of our approach using Deep Neural Network (DNN) models trained on the ImageNet and CIFAR-10 datasets. The results show that on average, by accepting 2.03% parameter count overhead, the accuracy drop due to the variations reduces from 31.7% to 1.15%.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18556",
        "abstract url": "https://arxiv.org/abs/2409.18556",
        "title": "CodeSCAN: ScreenCast ANalysis for Video Programming Tutorials",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Programming tutorials in the form of coding screencasts play a crucial role in programming education, serving both novices and experienced developers. However, the video format of these tutorials presents a challenge due to the difficulty of searching for and within videos. Addressing the absence of large-scale and diverse datasets for screencast analysis, we introduce the CodeSCAN dataset. It comprises 12,000 screenshots captured from the Visual Studio Code environment during development, featuring 24 programming languages, 25 fonts, and over 90 distinct themes, in addition to diverse layout changes and realistic user interactions. Moreover, we conduct detailed quantitative and qualitative evaluations to benchmark the performance of Integrated Development Environment (IDE) element detection, color-to-black-and-white conversion, and Optical Character Recognition (OCR). We hope that our contributions facilitate more research in coding screencast analysis, and we make the source code for creating the dataset and the benchmark publicly available on this website.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18561",
        "abstract url": "https://arxiv.org/abs/2409.18561",
        "title": "AL-GTD: Deep Active Learning for Gaze Target Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Gaze target detection aims at determining the image location where a person is looking. While existing studies have made significant progress in this area by regressing accurate gaze heatmaps, these achievements have largely relied on access to extensive labeled datasets, which demands substantial human labor. In this paper, our goal is to reduce the reliance on the size of labeled training data for gaze target detection. To achieve this, we propose AL-GTD, an innovative approach that integrates supervised and self-supervised losses within a novel sample acquisition function to perform active learning (AL). Additionally, it utilizes pseudo-labeling to mitigate distribution shifts during the training phase. AL-GTD achieves the best of all AUC results by utilizing only 40-50% of the training data, in contrast to state-of-the-art (SOTA) gaze target detectors requiring the entire training dataset to achieve the same performance. Importantly, AL-GTD quickly reaches satisfactory performance with 10-20% of the training data, showing the effectiveness of our acquisition function, which is able to acquire the most informative samples. We provide a comprehensive experimental analysis by adapting several AL methods for the task. AL-GTD outperforms AL competitors, simultaneously exhibiting superior performance compared to SOTA gaze target detectors when all are trained within a low-data regime. Code is available at https://github.com/francescotonini/al-gtd.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ACM Multimedia 2024"
    },
    {
        "paper id": "2409.18565",
        "abstract url": "https://arxiv.org/abs/2409.18565",
        "title": "Harmonizing knowledge Transfer in Neural Network with Unified Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Knowledge distillation (KD), known for its ability to transfer knowledge from a cumbersome network (teacher) to a lightweight one (student) without altering the architecture, has been garnering increasing attention. Two primary categories emerge within KD methods: feature-based, focusing on intermediate layers' features, and logits-based, targeting the final layer's logits. This paper introduces a novel perspective by leveraging diverse knowledge sources within a unified KD framework. Specifically, we aggregate features from intermediate layers into a comprehensive representation, effectively gathering semantic information from different stages and scales. Subsequently, we predict the distribution parameters from this representation. These steps transform knowledge from the intermediate layers into corresponding distributive forms, thereby allowing for knowledge distillation through a unified distribution constraint at different stages of the network, ensuring the comprehensiveness and coherence of knowledge transfer. Numerous experiments were conducted to validate the effectiveness of the proposed method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18583",
        "abstract url": "https://arxiv.org/abs/2409.18583",
        "title": "Hit the Sweet Spot! Span-Level Ensemble for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Ensembling various LLMs to unlock their complementary potential and leverage their individual strengths is highly valuable. Previous studies typically focus on two main paradigms: sample-level and token-level ensembles. Sample-level ensemble methods either select or blend fully generated outputs, which hinders dynamic correction and enhancement of outputs during the generation process. On the other hand, token-level ensemble methods enable real-time correction through fine-grained ensemble at each generation step. However, the information carried by an individual token is quite limited, leading to suboptimal decisions at each step. To address these issues, we propose SweetSpan, a span-level ensemble method that effectively balances the need for real-time adjustments and the information required for accurate ensemble decisions. Our approach involves two key steps: First, we have each candidate model independently generate candidate spans based on the shared prefix. Second, we calculate perplexity scores to facilitate mutual evaluation among the candidate models and achieve robust span selection by filtering out unfaithful scores. To comprehensively evaluate ensemble methods, we propose a new challenging setting (ensemble models with significant performance gaps) in addition to the standard setting (ensemble the best-performing models) to assess the performance of model ensembles in more realistic scenarios. Experimental results in both standard and challenging settings across various language generation tasks demonstrate the effectiveness, robustness, and versatility of our approach compared with previous ensemble methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18584",
        "abstract url": "https://arxiv.org/abs/2409.18584",
        "title": "ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Automatic speech recognition (ASR) systems have advanced significantly with models like Whisper, Conformer, and self-supervised frameworks such as Wav2vec 2.0 and HuBERT. However, developing robust ASR models for young children's speech remains challenging due to differences in pronunciation, tone, and pace compared to adult speech. In this paper, we introduce a new Mandarin speech dataset focused on children aged 3 to 5, addressing the scarcity of resources in this area. The dataset comprises 41.25 hours of speech with carefully crafted manual transcriptions, collected from 397 speakers across various provinces in China, with balanced gender representation. We provide a comprehensive analysis of speaker demographics, speech duration distribution and geographic coverage. Additionally, we evaluate ASR performance on models trained from scratch, such as Conformer, as well as fine-tuned pre-trained models like HuBERT and Whisper, where fine-tuning demonstrates significant performance improvements. Furthermore, we assess speaker verification (SV) on our dataset, showing that, despite the challenges posed by the unique vocal characteristics of young children, the dataset effectively supports both ASR and SV tasks. This dataset is a valuable contribution to Mandarin child speech research and holds potential for applications in educational technology and child-computer interaction. It will be open-source and freely available for all academic purposes.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18596",
        "abstract url": "https://arxiv.org/abs/2409.18596",
        "title": "ASAG2024: A Combined Benchmark for Short Answer Grading",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Open-ended questions test a more thorough understanding than closed-ended questions and are often a preferred assessment method. However, open-ended questions are tedious to grade and subject to personal bias. Therefore, there have been efforts to speed up the grading process through automation. Short Answer Grading (SAG) systems aim to automatically score students' answers. Despite growth in SAG methods and capabilities, there exists no comprehensive short-answer grading benchmark across different subjects, grading scales, and distributions. Thus, it is hard to assess the capabilities of current automated grading methods in terms of their generalizability. In this preliminary work, we introduce the combined ASAG2024 benchmark to facilitate the comparison of automated grading systems. Combining seven commonly used short-answer grading datasets in a common structure and grading scale. For our benchmark, we evaluate a set of recent SAG methods, revealing that while LLM-based approaches reach new high scores, they still are far from reaching human performance. This opens up avenues for future research on human-machine SAG systems.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted at SIGCSE-Virtual 2024"
    },
    {
        "paper id": "2409.18653",
        "abstract url": "https://arxiv.org/abs/2409.18653",
        "title": "When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This study investigates the application and performance of the Segment Anything Model 2 (SAM2) in the challenging task of video camouflaged object segmentation (VCOS). VCOS involves detecting objects that blend seamlessly in the surroundings for videos, due to similar colors and textures, poor light conditions, etc. Compared to the objects in normal scenes, camouflaged objects are much more difficult to detect. SAM2, a video foundation model, has shown potential in various tasks. But its effectiveness in dynamic camouflaged scenarios remains under-explored. This study presents a comprehensive study on SAM2's ability in VCOS. First, we assess SAM2's performance on camouflaged video datasets using different models and prompts (click, box, and mask). Second, we explore the integration of SAM2 with existing multimodal large language models (MLLMs) and VCOS methods. Third, we specifically adapt SAM2 by fine-tuning it on the video camouflaged dataset. Our comprehensive experiments demonstrate that SAM2 has excellent zero-shot ability of detecting camouflaged objects in videos. We also show that this ability could be further improved by specifically adjusting SAM2's parameters for VCOS. The code will be available at https://github.com/zhoustan/SAM2-VCOS",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Technical report"
    },
    {
        "paper id": "2409.18654",
        "abstract url": "https://arxiv.org/abs/2409.18654",
        "title": "Speech-Mamba: Long-Context Speech Recognition with Selective State Spaces Models",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Current automatic speech recognition systems struggle with modeling long speech sequences due to high quadratic complexity of Transformer-based models. Selective state space models such as Mamba has performed well on long-sequence modeling in natural language processing and computer vision tasks. However, research endeavors in speech technology tasks has been under-explored. We propose Speech-Mamba, which incorporates selective state space modeling in Transformer neural architectures. Long sequence representations with selective state space models in Speech-Mamba is complemented with lower-level representations from Transformer-based modeling. Speech-mamba achieves better capacity to model long-range dependencies, as it scales near-linearly with sequence length.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "8 pages; SLT 2024"
    },
    {
        "paper id": "2409.18664",
        "abstract url": "https://arxiv.org/abs/2409.18664",
        "title": "How green is continual learning, really? Analyzing the energy consumption in continual training of vision foundation models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "With the ever-growing adoption of AI, its impact on the environment is no longer negligible. Despite the potential that continual learning could have towards Green AI, its environmental sustainability remains relatively uncharted. In this work we aim to gain a systematic understanding of the energy efficiency of continual learning algorithms. To that end, we conducted an extensive set of empirical experiments comparing the energy consumption of recent representation-, prompt-, and exemplar-based continual learning algorithms and two standard baseline (fine tuning and joint training) when used to continually adapt a pre-trained ViT-B/16 foundation model. We performed our experiments on three standard datasets: CIFAR-100, ImageNet-R, and DomainNet. Additionally, we propose a novel metric, the Energy NetScore, which we use measure the algorithm efficiency in terms of energy-accuracy trade-off. Through numerous evaluations varying the number and size of the incremental learning steps, our experiments demonstrate that different types of continual learning algorithms have very different impacts on energy consumption during both training and inference. Although often overlooked in the continual learning literature, we found that the energy consumed during the inference phase is crucial for evaluating the environmental sustainability of continual learning models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This manuscript has been accepted at the Green FOundation MOdels (GreenFOMO) ECCV 2024 Workshop"
    },
    {
        "paper id": "2409.18673",
        "abstract url": "https://arxiv.org/abs/2409.18673",
        "title": "Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Dashboard cameras (dashcams) record millions of driving videos daily, offering a valuable potential data source for various applications, including driving map production and updates. A necessary step for utilizing these dashcam data involves the estimation of camera poses. However, the low-quality images captured by dashcams, characterized by motion blurs and dynamic objects, pose challenges for existing image-matching methods in accurately estimating camera poses. In this study, we propose a precise pose estimation method for dashcam images, leveraging the inherent camera motion prior. Typically, image sequences captured by dash cameras exhibit pronounced motion prior, such as forward movement or lateral turns, which serve as essential cues for correspondence estimation. Building upon this observation, we devise a pose regression module aimed at learning camera motion prior, subsequently integrating these prior into both correspondences and pose estimation processes. The experiment shows that, in real dashcams dataset, our method is 22% better than the baseline for pose estimation in AUC5\\textdegree, and it can estimate poses for 19% more images with less reprojection error in Structure from Motion (SfM).",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18677",
        "abstract url": "https://arxiv.org/abs/2409.18677",
        "title": "Co-Trained Retriever-Generator Framework for Question Generation in Earnings Calls",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In diverse professional environments, ranging from academic conferences to corporate earnings calls, the ability to anticipate audience questions stands paramount. Traditional methods, which rely on manual assessment of an audience's background, interests, and subject knowledge, often fall short - particularly when facing large or heterogeneous groups, leading to imprecision and inefficiency. While NLP has made strides in text-based question generation, its primary focus remains on academic settings, leaving the intricate challenges of professional domains, especially earnings call conferences, underserved. Addressing this gap, our paper pioneers the multi-question generation (MQG) task specifically designed for earnings call contexts. Our methodology involves an exhaustive collection of earnings call transcripts and a novel annotation technique to classify potential questions. Furthermore, we introduce a retriever-enhanced strategy to extract relevant information. With a core aim of generating a spectrum of potential questions that analysts might pose, we derive these directly from earnings call content. Empirical evaluations underscore our approach's edge, revealing notable excellence in the accuracy, consistency, and perplexity of the questions generated.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18713",
        "abstract url": "https://arxiv.org/abs/2409.18713",
        "title": "Decoding Complexity-Rate-Quality Pareto-Front for Adaptive VVC Streaming",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Pareto-front optimization is crucial for addressing the multi-objective challenges in video streaming, enabling the identification of optimal trade-offs between conflicting goals such as bitrate, video quality, and decoding complexity. This paper explores the construction of efficient bitrate ladders for adaptive Versatile Video Coding (VVC) streaming, focusing on optimizing these trade-offs. We investigate various ladder construction methods based on Pareto-front optimization, including exhaustive Rate-Quality and fixed ladder approaches. We propose a joint decoding time-rate-quality Pareto-front, providing a comprehensive framework to balance bitrate, decoding time, and video quality in video streaming. This allows streaming services to tailor their encoding strategies to meet specific requirements, prioritizing low decoding latency, bandwidth efficiency, or a balanced approach, thus enhancing the overall user experience. The experimental results confirm and demonstrate these opportunities for navigating the decoding time-rate-quality space to support various use cases. For example, when prioritizing low decoding latency, the proposed method achieves decoding time reduction of 14.86% while providing Bjontegaard delta rate savings of 4.65% and 0.32dB improvement in the eXtended Peak Signal-to-Noise Ratio (XPSNR)-Rate domain over the traditional fixed ladder solution.",
        "subjects": [
            "eess.IV",
            "cs.MM"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2409.18724",
        "abstract url": "https://arxiv.org/abs/2409.18724",
        "title": "Cross-Domain Keyword Extraction with Keyness Patterns",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Domain dependence and annotation subjectivity pose challenges for supervised keyword extraction. Based on the premises that second-order keyness patterns are existent at the community level and learnable from annotated keyword extraction datasets, this paper proposes a supervised ranking approach to keyword extraction that ranks keywords with keyness patterns consisting of independent features (such as sublanguage domain and term length) and three categories of dependent features -- heuristic features, specificity features, and representavity features. The approach uses two convolutional-neural-network based models to learn keyness patterns from keyword datasets and overcomes annotation subjectivity by training the two models with bootstrap sampling strategy. Experiments demonstrate that the approach not only achieves state-of-the-art performance on ten keyword datasets in general supervised keyword extraction with an average top-10-F-measure of 0.316 , but also robust cross-domain performance with an average top-10-F-measure of 0.346 on four datasets that are excluded in the training process. Such cross-domain robustness is attributed to the fact that community-level keyness patterns are limited in number and temperately independent of language domains, the distinction between independent features and dependent features, and the sampling training strategy that balances excess risk and lack of negative training data.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.NE"
        ],
        "comment": "26 pages, 14 figures"
    },
    {
        "paper id": "2409.18770",
        "abstract url": "https://arxiv.org/abs/2409.18770",
        "title": "Relighting from a Single Image: Datasets and Deep Intrinsic-based Architecture",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Single image scene relighting aims to generate a realistic new version of an input image so that it appears to be illuminated by a new target light condition. Although existing works have explored this problem from various perspectives, generating relit images under arbitrary light conditions remains highly challenging, and related datasets are scarce. Our work addresses this problem from both the dataset and methodological perspectives. We propose two new datasets: a synthetic dataset with the ground truth of intrinsic components and a real dataset collected under laboratory conditions. These datasets alleviate the scarcity of existing datasets. To incorporate physical consistency in the relighting pipeline, we establish a two-stage network based on intrinsic decomposition, giving outputs at intermediate steps, thereby introducing physical constraints. When the training set lacks ground truth for intrinsic decomposition, we introduce an unsupervised module to ensure that the intrinsic outputs are satisfactory. Our method outperforms the state-of-the-art methods in performance, as tested on both existing datasets and our newly developed datasets. Furthermore, pretraining our method or other prior methods using our synthetic dataset can enhance their performance on other datasets. Since our method can accommodate any light conditions, it is capable of producing animated results. The dataset, method, and videos are publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted for publication as a Regular paper in the IEEE Transactions on Multimedia"
    },
    {
        "paper id": "2409.18785",
        "abstract url": "https://arxiv.org/abs/2409.18785",
        "title": "Student-Oriented Teacher Knowledge Refinement for Knowledge Distillation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Knowledge distillation has become widely recognized for its ability to transfer knowledge from a large teacher network to a compact and more streamlined student network. Traditional knowledge distillation methods primarily follow a teacher-oriented paradigm that imposes the task of learning the teacher's complex knowledge onto the student network. However, significant disparities in model capacity and architectural design hinder the student's comprehension of the complex knowledge imparted by the teacher, resulting in sub-optimal performance. This paper introduces a novel perspective emphasizing student-oriented and refining the teacher's knowledge to better align with the student's needs, thereby improving knowledge transfer effectiveness. Specifically, we present the Student-Oriented Knowledge Distillation (SoKD), which incorporates a learnable feature augmentation strategy during training to refine the teacher's knowledge of the student dynamically. Furthermore, we deploy the Distinctive Area Detection Module (DAM) to identify areas of mutual interest between the teacher and student, concentrating knowledge transfer within these critical areas to avoid transferring irrelevant information. This customized module ensures a more focused and effective knowledge distillation process. Our approach, functioning as a plug-in, could be integrated with various knowledge distillation methods. Extensive experimental results demonstrate the efficacy and generalizability of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18786",
        "abstract url": "https://arxiv.org/abs/2409.18786",
        "title": "A Survey on the Honesty of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Honesty is a fundamental principle for aligning large language models (LLMs) with human values, requiring these models to recognize what they know and don't know and be able to faithfully express their knowledge. Despite promising, current LLMs still exhibit significant dishonest behaviors, such as confidently presenting wrong answers or failing to express what they know. In addition, research on the honesty of LLMs also faces challenges, including varying definitions of honesty, difficulties in distinguishing between known and unknown knowledge, and a lack of comprehensive understanding of related research. To address these issues, we provide a survey on the honesty of LLMs, covering its clarification, evaluation approaches, and strategies for improvement. Moreover, we offer insights for future research, aiming to inspire further exploration in this important area.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Project Page: https://github.com/SihengLi99/LLM-Honesty-Survey"
    },
    {
        "paper id": "2409.18812",
        "abstract url": "https://arxiv.org/abs/2409.18812",
        "title": "LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In response to the growing complexity and volume of scientific literature, this paper introduces the LLMs4Synthesis framework, designed to enhance the capabilities of Large Language Models (LLMs) in generating high-quality scientific syntheses. This framework addresses the need for rapid, coherent, and contextually rich integration of scientific insights, leveraging both open-source and proprietary LLMs. It also examines the effectiveness of LLMs in evaluating the integrity and reliability of these syntheses, alleviating inadequacies in current quantitative metrics. Our study contributes to this field by developing a novel methodology for processing scientific papers, defining new synthesis types, and establishing nine detailed quality criteria for evaluating syntheses. The integration of LLMs with reinforcement learning and AI feedback is proposed to optimize synthesis quality, ensuring alignment with established criteria. The LLMs4Synthesis framework and its components are made available, promising to enhance both the generation and evaluation processes in scientific research synthesis.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DL"
        ],
        "comment": "12 pages, 3 figures, Accepted to JCDL 2024 Research Track"
    },
    {
        "paper id": "2409.18839",
        "abstract url": "https://arxiv.org/abs/2409.18839",
        "title": "MinerU: An Open-Source Solution for Precise Document Content Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Document content analysis has been a crucial research area in computer vision. Despite significant advancements in methods such as OCR, layout detection, and formula recognition, existing open-source solutions struggle to consistently deliver high-quality content extraction due to the diversity in document types and content. To address these challenges, we present MinerU, an open-source solution for high-precision document content extraction. MinerU leverages the sophisticated PDF-Extract-Kit models to extract content from diverse documents effectively and employs finely-tuned preprocessing and postprocessing rules to ensure the accuracy of the final results. Experimental results demonstrate that MinerU consistently achieves high performance across various document types, significantly enhancing the quality and consistency of content extraction. The MinerU open-source project is available at https://github.com/opendatalab/MinerU.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "MinerU Technical Report"
    },
    {
        "paper id": "2409.18860",
        "abstract url": "https://arxiv.org/abs/2409.18860",
        "title": "LW2G: Learning Whether to Grow for Prompt-based Continual Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Continual Learning (CL) aims to learn in non-stationary scenarios, progressively acquiring and maintaining knowledge from sequential tasks. Recent Prompt-based Continual Learning (PCL) has achieved remarkable performance with Pre-Trained Models (PTMs). These approaches grow a prompt sets pool by adding a new set of prompts when learning each new task (\\emph{prompt learning}) and adopt a matching mechanism to select the correct set for each testing sample (\\emph{prompt retrieval}). Previous studies focus on the latter stage by improving the matching mechanism to enhance Prompt Retrieval Accuracy (PRA). To promote cross-task knowledge facilitation and form an effective and efficient prompt sets pool, we propose a plug-in module in the former stage to \\textbf{Learn Whether to Grow (LW2G)} based on the disparities between tasks. Specifically, a shared set of prompts is utilized when several tasks share certain commonalities, and a new set is added when there are significant differences between the new task and previous tasks. Inspired by Gradient Projection Continual Learning, our LW2G develops a metric called Hinder Forward Capability (HFC) to measure the hindrance imposed on learning new tasks by surgically modifying the original gradient onto the orthogonal complement of the old feature space. With HFC, an automated scheme Dynamic Growing Approach adaptively learns whether to grow with a dynamic threshold. Furthermore, we design a gradient-based constraint to ensure the consistency between the updating prompts and pre-trained knowledge, and a prompts weights reusing strategy to enhance forward transfer. Extensive experiments show the effectiveness of our method. The source codes are available at \\url{https://github.com/RAIAN08/LW2G}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "submit to neurips2024"
    },
    {
        "paper id": "2409.18866",
        "abstract url": "https://arxiv.org/abs/2409.18866",
        "title": "MCUBench: A Benchmark of Tiny Object Detectors on MCUs",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce MCUBench, a benchmark featuring over 100 YOLO-based object detection models evaluated on the VOC dataset across seven different MCUs. This benchmark provides detailed data on average precision, latency, RAM, and Flash usage for various input resolutions and YOLO-based one-stage detectors. By conducting a controlled comparison with a fixed training pipeline, we collect comprehensive performance metrics. Our Pareto-optimal analysis shows that integrating modern detection heads and training techniques allows various YOLO architectures, including legacy models like YOLOv3, to achieve a highly efficient tradeoff between mean Average Precision (mAP) and latency. MCUBench serves as a valuable tool for benchmarking the MCU performance of contemporary object detectors and aids in model selection based on specific constraints.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Code and data are available at https://github.com/Deeplite/deeplite-torch-zoo"
    },
    {
        "paper id": "2409.18868",
        "abstract url": "https://arxiv.org/abs/2409.18868",
        "title": "Individuation in Neural Models with and without Visual Grounding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We show differences between a language-and-vision model CLIP and two text-only models - FastText and SBERT - when it comes to the encoding of individuation information. We study latent representations that CLIP provides for substrates, granular aggregates, and various numbers of objects. We demonstrate that CLIP embeddings capture quantitative differences in individuation better than models trained on text-only data. Moreover, the individuation hierarchy we deduce from the CLIP embeddings agrees with the hierarchies proposed in linguistics and cognitive science.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18901",
        "abstract url": "https://arxiv.org/abs/2409.18901",
        "title": "Improving Visual Object Tracking through Visual Prompting",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Learning a discriminative model to distinguish a target from its surrounding distractors is essential to generic visual object tracking. Dynamic target representation adaptation against distractors is challenging due to the limited discriminative capabilities of prevailing trackers. We present a new visual Prompting mechanism for generic Visual Object Tracking (PiVOT) to address this issue. PiVOT proposes a prompt generation network with the pre-trained foundation model CLIP to automatically generate and refine visual prompts, enabling the transfer of foundation model knowledge for tracking. While CLIP offers broad category-level knowledge, the tracker, trained on instance-specific data, excels at recognizing unique object instances. Thus, PiVOT first compiles a visual prompt highlighting potential target locations. To transfer the knowledge of CLIP to the tracker, PiVOT leverages CLIP to refine the visual prompt based on the similarities between candidate objects and the reference templates across potential targets. Once the visual prompt is refined, it can better highlight potential target locations, thereby reducing irrelevant prompt information. With the proposed prompting mechanism, the tracker can generate improved instance-aware feature maps through the guidance of the visual prompt, thus effectively reducing distractors. The proposed method does not involve CLIP during training, thereby keeping the same training complexity and preserving the generalization capability of the pretrained foundation model. Extensive experiments across multiple benchmarks indicate that PiVOT, using the proposed prompting method can suppress distracting objects and enhance the tracker.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM",
            "eess.IV"
        ],
        "comment": "Accepted and to appear in IEEE Transactions on Multimedia"
    },
    {
        "paper id": "2409.18922",
        "abstract url": "https://arxiv.org/abs/2409.18922",
        "title": "SurfaceAI: Automated creation of cohesive road surface quality datasets based on open street-level imagery",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces SurfaceAI, a pipeline designed to generate comprehensive georeferenced datasets on road surface type and quality from openly available street-level imagery. The motivation stems from the significant impact of road unevenness on the safety and comfort of traffic participants, especially vulnerable road users, emphasizing the need for detailed road surface data in infrastructure modeling and analysis. SurfaceAI addresses this gap by leveraging crowdsourced Mapillary data to train models that predict the type and quality of road surfaces visible in street-level images, which are then aggregated to provide cohesive information on entire road segment conditions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "4 pages, 2 figures; accepted at 2nd ACM SIGSPATIAL International Workshop on Advances in Urban-AI"
    },
    {
        "paper id": "2409.18938",
        "abstract url": "https://arxiv.org/abs/2409.18938",
        "title": "From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The integration of Large Language Models (LLMs) with visual encoders has recently shown promising performance in visual understanding tasks, leveraging their inherent capability to comprehend and generate human-like text for visual reasoning. Given the diverse nature of visual data, MultiModal Large Language Models (MM-LLMs) exhibit variations in model designing and training for understanding images, short videos, and long videos. Our paper focuses on the substantial differences and unique challenges posed by long video understanding compared to static image and short video understanding. Unlike static images, short videos encompass sequential frames with both spatial and within-event temporal information, while long videos consist of multiple events with between-event and long-term temporal information. In this survey, we aim to trace and summarize the advancements of MM-LLMs from image understanding to long video understanding. We review the differences among various visual understanding tasks and highlight the challenges in long video understanding, including more fine-grained spatiotemporal details, dynamic events, and long-term dependencies. We then provide a detailed summary of the advancements in MM-LLMs in terms of model design and training methodologies for understanding long videos. Finally, we compare the performance of existing MM-LLMs on video understanding benchmarks of various lengths and discuss potential future directions for MM-LLMs in long video understanding.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2409.18943",
        "abstract url": "https://arxiv.org/abs/2409.18943",
        "title": "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The instruction-following ability of large language models enables humans to interact with AI agents in a natural way. However, when required to generate responses of a specific length, large language models often struggle to meet users' needs due to their inherent difficulty in accurately perceiving numerical constraints. To explore the ability of large language models to control the length of generated responses, we propose the Target Length Generation Task (TLG) and design two metrics, Precise Match (PM) and Flexible Match (FM) to evaluate the model's performance in adhering to specified response lengths. Furthermore, we introduce a novel, model-agnostic approach called Ruler, which employs Meta Length Tokens (MLTs) to enhance the instruction-following ability of large language models under length-constrained instructions. Specifically, Ruler equips LLMs with the ability to generate responses of a specified length based on length constraints within the instructions. Moreover, Ruler can automatically generate appropriate MLT when length constraints are not explicitly provided, demonstrating excellent versatility and generalization. Comprehensive experiments show the effectiveness of Ruler across different LLMs on Target Length Generation Task, e.g., at All Level 27.97 average gain on PM, 29.57 average gain on FM. In addition, we conduct extensive ablation experiments to further substantiate the efficacy and generalization of Ruler. Our code and data is available at https://github.com/Geaming2002/Ruler.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18957",
        "abstract url": "https://arxiv.org/abs/2409.18957",
        "title": "LML: Language Model Learning a Dataset for Data-Augmented Prediction",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces a new approach to using Large Language Models (LLMs) for classification tasks, which are typically handled using Machine Learning (ML) models. Unlike ML models that rely heavily on data cleaning and feature engineering, this method streamlines the process using LLMs. This paper proposes a new concept called \"Language Model Learning (LML)\" powered by a new method called \"Data-Augmented Prediction (DAP)\". The classification is performed by LLMs using a method similar to humans manually exploring and understanding the data and deciding classifications using data as a reference. Training data is summarized and evaluated to determine the features that lead to the classification of each label the most. In the process of DAP, the system uses the data summary to automatically create a query, which is used to retrieve relevant rows from the dataset. A classification is generated by the LLM using data summary and relevant rows, ensuring satisfactory accuracy even with complex data. Usage of data summary and similar data in DAP ensures context-aware decision-making. The proposed method uses the words \"Act as an Explainable Machine Learning Model\" in the prompt to enhance the interpretability of the predictions by allowing users to review the logic behind each prediction. In some test cases, the system scored an accuracy above 90%, proving the effectiveness of the system and its potential to outperform conventional ML models in various scenarios. The code is available at https://github.com/Pro-GenAI/LML-DAP",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "First version"
    },
    {
        "paper id": "2409.19051",
        "abstract url": "https://arxiv.org/abs/2409.19051",
        "title": "Multimodal Markup Document Models for Graphic Design Completion",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents multimodal markup document models (MarkupDM) that can generate both markup language and images within interleaved multimodal documents. Unlike existing vision-and-language multimodal models, our MarkupDM tackles unique challenges critical to graphic design tasks: generating partial images that contribute to the overall appearance, often involving transparency and varying sizes, and understanding the syntax and semantics of markup languages, which play a fundamental role as a representational format of graphic designs. To address these challenges, we design an image quantizer to tokenize images of diverse sizes with transparency and modify a code language model to process markup languages and incorporate image modalities. We provide in-depth evaluations of our approach on three graphic design completion tasks: generating missing attribute values, images, and texts in graphic design templates. Results corroborate the effectiveness of our MarkupDM for graphic design tasks. We also discuss the strengths and weaknesses in detail, providing insights for future research on multimodal document generation.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": "Project page: https://cyberagentailab.github.io/MarkupDM/"
    },
    {
        "paper id": "2409.19075",
        "abstract url": "https://arxiv.org/abs/2409.19075",
        "title": "Meta-RTL: Reinforcement-Based Meta-Transfer Learning for Low-Resource Commonsense Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Meta learning has been widely used to exploit rich-resource source tasks to improve the performance of low-resource target tasks. Unfortunately, most existing meta learning approaches treat different source tasks equally, ignoring the relatedness of source tasks to the target task in knowledge transfer. To mitigate this issue, we propose a reinforcement-based multi-source meta-transfer learning framework (Meta-RTL) for low-resource commonsense reasoning. In this framework, we present a reinforcement-based approach to dynamically estimating source task weights that measure the contribution of the corresponding tasks to the target task in the meta-transfer learning. The differences between the general loss of the meta model and task-specific losses of source-specific temporal meta models on sampled target data are fed into the policy network of the reinforcement learning module as rewards. The policy network is built upon LSTMs that capture long-term dependencies on source task weight estimation across meta learning iterations. We evaluate the proposed Meta-RTL using both BERT and ALBERT as the backbone of the meta model on three commonsense reasoning benchmark datasets. Experimental results demonstrate that Meta-RTL substantially outperforms strong baselines and previous task selection strategies and achieves larger improvements on extremely low-resource settings.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19092",
        "abstract url": "https://arxiv.org/abs/2409.19092",
        "title": "Federated Online Prediction from Experts with Differential Privacy: Separations and Regret Speed-ups",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We study the problems of differentially private federated online prediction from experts against both stochastic adversaries and oblivious adversaries. We aim to minimize the average regret on $m$ clients working in parallel over time horizon $T$ with explicit differential privacy (DP) guarantees. With stochastic adversaries, we propose a Fed-DP-OPE-Stoch algorithm that achieves $\\sqrt{m}$-fold speed-up of the per-client regret compared to the single-player counterparts under both pure DP and approximate DP constraints, while maintaining logarithmic communication costs. With oblivious adversaries, we establish non-trivial lower bounds indicating that collaboration among clients does not lead to regret speed-up with general oblivious adversaries. We then consider a special case of the oblivious adversaries setting, where there exists a low-loss expert. We design a new algorithm Fed-SVT and show that it achieves an $m$-fold regret speed-up under both pure DP and approximate DP constraints over the single-player counterparts. Our lower bound indicates that Fed-SVT is nearly optimal up to logarithmic factors. Experiments demonstrate the effectiveness of our proposed algorithms. To the best of our knowledge, this is the first work examining the differentially private online prediction from experts in the federated setting.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "stat.ML"
        ],
        "comment": "Accepted to NeurIPS 2024"
    },
    {
        "paper id": "2409.19146",
        "abstract url": "https://arxiv.org/abs/2409.19146",
        "title": "Bound Tightening Network for Robust Crowd Counting",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Crowd Counting is a fundamental topic, aiming to estimate the number of individuals in the crowded images or videos fed from surveillance cameras. Recent works focus on improving counting accuracy, while ignoring the certified robustness of counting models. In this paper, we propose a novel Bound Tightening Network (BTN) for Robust Crowd Counting. It consists of three parts: base model, smooth regularization module and certify bound module. The core idea is to propagate the interval bound through the base model (certify bound module) and utilize the layer weights (smooth regularization module) to guide the network learning. Experiments on different benchmark datasets for counting demonstrate the effectiveness and efficiency of BTN.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "This work was done 2 years ago"
    },
    {
        "paper id": "2409.19148",
        "abstract url": "https://arxiv.org/abs/2409.19148",
        "title": "Uncovering Differences in Persuasive Language in Russian versus English Wikipedia",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We study how differences in persuasive language across Wikipedia articles, written in either English and Russian, can uncover each culture's distinct perspective on different subjects. We develop a large language model (LLM) powered system to identify instances of persuasive language in multilingual texts. Instead of directly prompting LLMs to detect persuasion, which is subjective and difficult, we propose to reframe the task to instead ask high-level questions (HLQs) which capture different persuasive aspects. Importantly, these HLQs are authored by LLMs themselves. LLMs over-generate a large set of HLQs, which are subsequently filtered to a small set aligned with human labels for the original task. We then apply our approach to a large-scale, bilingual dataset of Wikipedia articles (88K total), using a two-stage identify-then-extract prompting strategy to find instances of persuasion. We quantify the amount of persuasion per article, and explore the differences in persuasion through several experiments on the paired articles. Notably, we generate rankings of articles by persuasion in both languages. These rankings match our intuitions on the culturally-salient subjects; Russian Wikipedia highlights subjects on Ukraine, while English Wikipedia highlights the Middle East. Grouping subjects into larger topics, we find politically-related events contain more persuasion than others. We further demonstrate that HLQs obtain similar performance when posed in either English or Russian. Our methodology enables cross-lingual, cross-cultural understanding at scale, and we release our code, prompts, and data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19179",
        "abstract url": "https://arxiv.org/abs/2409.19179",
        "title": "A comprehensive review and new taxonomy on superpixel segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Superpixel segmentation consists of partitioning images into regions composed of similar and connected pixels. Its methods have been widely used in many computer vision applications since it allows for reducing the workload, removing redundant information, and preserving regions with meaningful features. Due to the rapid progress in this area, the literature fails to catch up on more recent works among the compared ones and to categorize the methods according to all existing strategies. This work fills this gap by presenting a comprehensive review with new taxonomy for superpixel segmentation, in which methods are classified according to their processing steps and processing levels of image features. We revisit the recent and popular literature according to our taxonomy and evaluate 20 strategies based on nine criteria: connectivity, compactness, delineation, control over the number of superpixels, color homogeneity, robustness, running time, stability, and visual quality. Our experiments show the trends of each approach in pixel clustering and discuss individual trade-offs. Finally, we provide a new benchmark for superpixel assessment, available at https://github.com/IMScience-PPGINF-PucMinas/superpixel-benchmark.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "54 pages. This is the author version of the manuscript of the same name published in ACM Computing Surveys"
    },
    {
        "paper id": "2409.19184",
        "abstract url": "https://arxiv.org/abs/2409.19184",
        "title": "Learning-Based Image Compression for Machines",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "While learning based compression techniques for images have outperformed traditional methods, they have not been widely adopted in machine learning pipelines. This is largely due to lack of standardization and lack of retention of salient features needed for such tasks. Decompression of images have taken a back seat in recent years while the focus has shifted to an image's utility in performing machine learning based analysis on top of them. Thus the demand for compression pipelines that incorporate such features from images has become ever present. The methods outlined in the report build on the recent work done on learning based image compression techniques to incorporate downstream tasks in them. We propose various methods of finetuning and enhancing different parts of pretrained compression encoding pipeline and present the results of our investigation regarding the performance of vision tasks using compression based pipelines.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19212",
        "abstract url": "https://arxiv.org/abs/2409.19212",
        "title": "An Accelerated Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "This paper investigates a class of stochastic bilevel optimization problems where the upper-level function is nonconvex with potentially unbounded smoothness and the lower-level problem is strongly convex. These problems have significant applications in sequential data learning, such as text classification using recurrent neural networks. The unbounded smoothness is characterized by the smoothness constant of the upper-level function scaling linearly with the gradient norm, lacking a uniform upper bound. Existing state-of-the-art algorithms require $\\widetilde{O}(1/\u03b5^4)$ oracle calls of stochastic gradient or Hessian/Jacobian-vector product to find an $\u03b5$-stationary point. However, it remains unclear if we can further improve the convergence rate when the assumptions for the function in the population level also hold for each random realization almost surely (e.g., Lipschitzness of each realization of the stochastic gradient). To address this issue, we propose a new Accelerated Bilevel Optimization algorithm named AccBO. The algorithm updates the upper-level variable by normalized stochastic gradient descent with recursive momentum and the lower-level variable by the stochastic Nesterov accelerated gradient descent algorithm with averaging. We prove that our algorithm achieves an oracle complexity of $\\widetilde{O}(1/\u03b5^3)$ to find an $\u03b5$-stationary point. Our proof relies on a novel lemma characterizing the dynamics of stochastic Nesterov accelerated gradient descent algorithm under distribution drift with high probability for the lower-level variable, which is of independent interest and also plays a crucial role in analyzing the hypergradient estimation error over time. Experimental results on various tasks confirm that our proposed algorithm achieves the predicted theoretical acceleration and significantly outperforms baselines in bilevel optimization.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": "Accepted by NeurIPS 2024. The code is available at https://github.com/MingruiLiu-ML-Lab/Accelerated-Bilevel-Optimization-Unbounded-Smoothness"
    },
    {
        "paper id": "2409.18470",
        "abstract url": "https://arxiv.org/abs/2409.18470",
        "title": "Fairness without Sensitive Attributes via Knowledge Sharing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "While model fairness improvement has been explored previously, existing methods invariably rely on adjusting explicit sensitive attribute values in order to improve model fairness in downstream tasks. However, we observe a trend in which sensitive demographic information becomes inaccessible as public concerns around data privacy grow. In this paper, we propose a confidence-based hierarchical classifier structure called \"Reckoner\" for reliable fair model learning under the assumption of missing sensitive attributes. We first present results showing that if the dataset contains biased labels or other hidden biases, classifiers significantly increase the bias gap across different demographic groups in the subset with higher prediction confidence. Inspired by these findings, we devised a dual-model system in which a version of the model initialised with a high-confidence data subset learns from a version of the model initialised with a low-confidence data subset, enabling it to avoid biased predictions. Our experimental results show that Reckoner consistently outperforms state-of-the-art baselines in COMPAS dataset and New Adult dataset, considering both accuracy and fairness metrics.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18475",
        "abstract url": "https://arxiv.org/abs/2409.18475",
        "title": "Data Analysis in the Era of Generative AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper explores the potential of AI-powered tools to reshape data analysis, focusing on design considerations and challenges. We explore how the emergence of large language and multimodal models offers new opportunities to enhance various stages of data analysis workflow by translating high-level user intentions into executable code, charts, and insights. We then examine human-centered design principles that facilitate intuitive interactions, build user trust, and streamline the AI-assisted analysis workflow across multiple apps. Finally, we discuss the research challenges that impede the development of these AI-based systems such as enhancing model capabilities, evaluating and benchmarking, and understanding end-user needs.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18499",
        "abstract url": "https://arxiv.org/abs/2409.18499",
        "title": "Fairness-aware Multiobjective Evolutionary Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Multiobjective evolutionary learning (MOEL) has demonstrated its advantages of training fairer machine learning models considering a predefined set of conflicting objectives, including accuracy and different fairness measures. Recent works propose to construct a representative subset of fairness measures as optimisation objectives of MOEL throughout model training. However, the determination of a representative measure set relies on dataset, prior knowledge and requires substantial computational costs. What's more, those representative measures may differ across different model training processes. Instead of using a static predefined set determined before model training, this paper proposes to dynamically and adaptively determine a representative measure set online during model training. The dynamically determined representative set is then used as optimising objectives of the MOEL framework and can vary with time. Extensive experimental results on 12 well-known benchmark datasets demonstrate that our proposed framework achieves outstanding performance compared to state-of-the-art approaches for mitigating unfairness in terms of accuracy as well as 25 fairness measures although only a few of them were dynamically selected and used as optimisation objectives. The results indicate the importance of setting optimisation objectives dynamically during training.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.18504",
        "abstract url": "https://arxiv.org/abs/2409.18504",
        "title": "WHOMP: Optimizing Randomized Controlled Trials via Wasserstein Homogeneity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate methods for partitioning datasets into subgroups that maximize diversity within each subgroup while minimizing dissimilarity across subgroups. We introduce a novel partitioning method called the $\\textit{Wasserstein Homogeneity Partition}$ (WHOMP), which optimally minimizes type I and type II errors that often result from imbalanced group splitting or partitioning, commonly referred to as accidental bias, in comparative and controlled trials. We conduct an analytical comparison of WHOMP against existing partitioning methods, such as random subsampling, covariate-adaptive randomization, rerandomization, and anti-clustering, demonstrating its advantages. Moreover, we characterize the optimal solutions to the WHOMP problem and reveal an inherent trade-off between the stability of subgroup means and variances among these solutions. Based on our theoretical insights, we design algorithms that not only obtain these optimal solutions but also equip practitioners with tools to select the desired trade-off. Finally, we validate the effectiveness of WHOMP through numerical experiments, highlighting its superiority over traditional methods.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR",
            "math.ST"
        ],
        "comment": "46 pages, 3 figures"
    },
    {
        "paper id": "2409.18544",
        "abstract url": "https://arxiv.org/abs/2409.18544",
        "title": "Wasserstein Distance-Weighted Adversarial Network for Cross-Domain Credit Risk Assessment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper delves into the application of adversarial domain adaptation (ADA) for enhancing credit risk assessment in financial institutions. It addresses two critical challenges: the cold start problem, where historical lending data is scarce, and the data imbalance issue, where high-risk transactions are underrepresented. The paper introduces an improved ADA framework, the Wasserstein Distance Weighted Adversarial Domain Adaptation Network (WD-WADA), which leverages the Wasserstein distance to align source and target domains effectively. The proposed method includes an innovative weighted strategy to tackle data imbalance, adjusting for both the class distribution and the difficulty level of predictions. The paper demonstrates that WD-WADA not only mitigates the cold start problem but also provides a more accurate measure of domain differences, leading to improved cross-domain credit risk assessment. Extensive experiments on real-world credit datasets validate the model's effectiveness, showcasing superior performance in cross-domain learning, classification accuracy, and model stability compared to traditional methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18566",
        "abstract url": "https://arxiv.org/abs/2409.18566",
        "title": "Optimizing DNN Inference on Multi-Accelerator SoCs at Training-time",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The demand for executing Deep Neural Networks (DNNs) with low latency and minimal power consumption at the edge has led to the development of advanced heterogeneous Systems-on-Chips (SoCs) that incorporate multiple specialized computing units (CUs), such as accelerators. Offloading DNN computations to a specific CU from the available set often exposes accuracy vs efficiency trade-offs, due to differences in their supported operations (e.g., standard vs. depthwise convolution) or data representations (e.g., more/less aggressively quantized). A challenging yet unresolved issue is how to map a DNN onto these multi-CU systems to maximally exploit the parallelization possibilities while taking accuracy into account. To address this problem, we present ODiMO, a hardware-aware tool that efficiently explores fine-grain mapping of DNNs among various on-chip CUs, during the training phase. ODiMO strategically splits individual layers of the neural network and executes them in parallel on the multiple available CUs, aiming to balance the total inference energy consumption or latency with the resulting accuracy, impacted by the unique features of the different hardware units. We test our approach on CIFAR-10, CIFAR-100, and ImageNet, targeting two open-source heterogeneous SoCs, i.e., DIANA and Darkside. We obtain a rich collection of Pareto-optimal networks in the accuracy vs. energy or latency space. We show that ODiMO reduces the latency of a DNN executed on the Darkside SoC by up to 8x at iso-accuracy, compared to manual heuristic mappings. When targeting energy, on the same SoC, ODiMO produced up to 50.8x more efficient mappings, with minimal accuracy drop (< 0.3%).",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.18568",
        "abstract url": "https://arxiv.org/abs/2409.18568",
        "title": "Experimental Evaluation of Machine Learning Models for Goal-oriented Customer Service Chatbot with Pipeline Architecture",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Integrating machine learning (ML) into customer service chatbots enhances their ability to understand and respond to user queries, ultimately improving service performance. However, they may appear artificial to some users and affecting customer experience. Hence, meticulous evaluation of ML models for each pipeline component is crucial for optimizing performance, though differences in functionalities can lead to unfair comparisons. In this paper, we present a tailored experimental evaluation approach for goal-oriented customer service chatbots with pipeline architecture, focusing on three key components: Natural Language Understanding (NLU), dialogue management (DM), and Natural Language Generation (NLG). Our methodology emphasizes individual assessment to determine optimal ML models. Specifically, we focus on optimizing hyperparameters and evaluating candidate models for NLU (utilizing BERT and LSTM), DM (employing DQN and DDQN), and NLG (leveraging GPT-2 and DialoGPT). The results show that for the NLU component, BERT excelled in intent detection whereas LSTM was superior for slot filling. For the DM component, the DDQN model outperformed DQN by achieving fewer turns, higher rewards, as well as greater success rates. For NLG, the large language model GPT-2 surpassed DialoGPT in BLEU, METEOR, and ROUGE metrics. These findings aim to provide a benchmark for future research in developing and optimizing customer service chatbots, offering valuable insights into model performance and optimal hyperparameters.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18569",
        "abstract url": "https://arxiv.org/abs/2409.18569",
        "title": "Cross-video Identity Correlating for Person Re-identification Pre-training",
        "rating": "0.5",
        "keywords": [
            [
                "Re-identification"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Recent researches have proven that pre-training on large-scale person images extracted from internet videos is an effective way in learning better representations for person re-identification. However, these researches are mostly confined to pre-training at the instance-level or single-video tracklet-level. They ignore the identity-invariance in images of the same person across different videos, which is a key focus in person re-identification. To address this issue, we propose a Cross-video Identity-cOrrelating pre-traiNing (CION) framework. Defining a noise concept that comprehensively considers both intra-identity consistency and inter-identity discrimination, CION seeks the identity correlation from cross-video images by modeling it as a progressive multi-level denoising problem. Furthermore, an identity-guided self-distillation loss is proposed to implement better large-scale pre-training by mining the identity-invariance within person images. We conduct extensive experiments to verify the superiority of our CION in terms of efficiency and performance. CION achieves significantly leading performance with even fewer training samples. For example, compared with the previous state-of-the-art~\\cite{ISR}, CION with the same ResNet50-IBN achieves higher mAP of 93.3\\% and 74.3\\% on Market1501 and MSMT17, while only utilizing 8\\% training samples. Finally, with CION demonstrating superior model-agnostic ability, we contribute a model zoo named ReIDZoo to meet diverse research and application needs in this field. It contains a series of CION pre-trained models with spanning structures and parameters, totaling 32 models with 10 different structures, including GhostNet, ConvNext, RepViT, FastViT and so on. The code and models will be made publicly available at https://github.com/Zplusdragon/CION_ReIDZoo.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "NeurIPS 2024 Accepted Paper"
    },
    {
        "paper id": "2409.18574",
        "abstract url": "https://arxiv.org/abs/2409.18574",
        "title": "Climate Adaptation with Reinforcement Learning: Experiments with Flooding and Transportation in Copenhagen",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Due to climate change the frequency and intensity of extreme rainfall events, which contribute to urban flooding, are expected to increase in many places. These floods can damage transport infrastructure and disrupt mobility, highlighting the need for cities to adapt to escalating risks. Reinforcement learning (RL) serves as a powerful tool for uncovering optimal adaptation strategies, determining how and where to deploy adaptation measures effectively, even under significant uncertainty. In this study, we leverage RL to identify the most effective timing and locations for implementing measures, aiming to reduce both direct and indirect impacts of flooding. Our framework integrates climate change projections of future rainfall events and floods, models city-wide motorized trips, and quantifies direct and indirect impacts on infrastructure and mobility. Preliminary results suggest that our RL-based approach can significantly enhance decision-making by prioritizing interventions in specific urban areas and identifying the optimal periods for their implementation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18581",
        "abstract url": "https://arxiv.org/abs/2409.18581",
        "title": "Using Deep Autoregressive Models as Causal Inference Engines",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Existing causal inference (CI) models are limited to primarily handling low-dimensional confounders and singleton actions. We propose an autoregressive (AR) CI framework capable of handling complex confounders and sequential actions common in modern applications. We accomplish this by {\\em sequencification}, transforming data from an underlying causal diagram into a sequence of tokens. This approach not only enables training with data generated from any DAG but also extends existing CI capabilities to accommodate estimating several statistical quantities using a {\\em single} model. We can directly predict interventional probabilities, simplifying inference and enhancing outcome prediction accuracy. We demonstrate that an AR model adapted for CI is efficient and effective in various complex applications such as navigating mazes, playing chess endgames, and evaluating the impact of certain keywords on paper acceptance rates.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18602",
        "abstract url": "https://arxiv.org/abs/2409.18602",
        "title": "Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations",
        "rating": "0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Assessing the performance of systems to classify Multi-Party Conversations (MPC) is challenging due to the interconnection between linguistic and structural characteristics of conversations. Conventional evaluation methods often overlook variances in model behavior across different levels of structural complexity on interaction graphs. In this work, we propose a methodological pipeline to investigate model performance across specific structural attributes of conversations. As a proof of concept we focus on Response Selection and Addressee Recognition tasks, to diagnose model weaknesses. To this end, we extract representative diagnostic subdatasets with a fixed number of users and a good structural variety from a large and open corpus of online MPCs. We further frame our work in terms of data minimization, avoiding the use of original usernames to preserve privacy, and propose alternatives to using original text messages. Results show that response selection relies more on the textual content of conversations, while addressee recognition requires capturing their structural dimension. Using an LLM in a zero-shot setting, we further highlight how sensitivity to prompt variations is task-dependent.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to EMNLP 2024 main conference"
    },
    {
        "paper id": "2409.18633",
        "abstract url": "https://arxiv.org/abs/2409.18633",
        "title": "Reducing Diversity to Generate Hierarchical Archetypes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The Artificial Intelligence field seldom address the development of a fundamental building piece: a framework, methodology or algorithm to automatically build hierarchies of abstractions. This is a key requirement in order to build intelligent behaviour, as recent neuroscience studies clearly expose. In this paper we present a primitive-based framework to automatically generate hierarchies of constructive archetypes, as a theory of how to generate hierarchies of abstractions. We assume the existence of a primitive with very specific characteristics, and we develop our framework over it. We prove the effectiveness of our framework through mathematical definitions and proofs. Finally, we give a few insights about potential uses of our framework and the expected results.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18660",
        "abstract url": "https://arxiv.org/abs/2409.18660",
        "title": "Effects of AI Feedback on Learning, the Skill Gap, and Intellectual Diversity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Can human decision-makers learn from AI feedback? Using data on 52,000 decision-makers from a large online chess platform, we investigate how their AI use affects three interrelated long-term outcomes: Learning, skill gap, and diversity of decision strategies. First, we show that individuals are far more likely to seek AI feedback in situations in which they experienced success rather than failure. This AI feedback seeking strategy turns out to be detrimental to learning: Feedback on successes decreases future performance, while feedback on failures increases it. Second, higher-skilled decision-makers seek AI feedback more often and are far more likely to seek AI feedback after a failure, and benefit more from AI feedback than lower-skilled individuals. As a result, access to AI feedback increases, rather than decreases, the skill gap between high- and low-skilled individuals. Finally, we leverage 42 major platform updates as natural experiments to show that access to AI feedback causes a decrease in intellectual diversity of the population as individuals tend to specialize in the same areas. Together, those results indicate that learning from AI feedback is not automatic and using AI correctly seems to be a skill itself. Furthermore, despite its individual-level benefits, access to AI feedback can have significant population-level downsides including loss of intellectual diversity and an increasing skill gap.",
        "subjects": [
            "econ.GN",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18661",
        "abstract url": "https://arxiv.org/abs/2409.18661",
        "title": "Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages -- for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with $n$ = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students' time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": "To appear in the proceedings of the 2024 UK and Ireland Computing Education Research conference (UKICER '24)"
    },
    {
        "paper id": "2409.18665",
        "abstract url": "https://arxiv.org/abs/2409.18665",
        "title": "Kaleidoscopic reorganization of network communities across different scales",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The notion of structural heterogeneity is pervasive in real networks, and their community organization is no exception. Still, a vast majority of community detection methods assume neatly hierarchically organized communities of a characteristic scale for a given hierarchical level. In this work, we demonstrate that the reality of scale-dependent community reorganization is convoluted with simultaneous processes of community splitting and merging, challenging the conventional understanding of community-scale adjustment. We provide the mathematical argument on the modularity function, the results from the real-network analysis, and a simple network model for a comprehensive understanding of the nontrivial community reorganization process characterized by a local dip in the number of communities as the resolution parameter varies. This study suggests a need for a paradigm shift in the study of network communities, which emphasizes the importance of considering scale-dependent reorganization to better understand the genuine structural organization of networks.",
        "subjects": [
            "physics.soc-ph",
            "cond-mat.stat-mech",
            "cs.SI"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2409.18676",
        "abstract url": "https://arxiv.org/abs/2409.18676",
        "title": "Toward Universal and Interpretable World Models for Open-ended Learning Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce a generic, compositional and interpretable class of generative world models that supports open-ended learning agents. This is a sparse class of Bayesian networks capable of approximating a broad range of stochastic processes, which provide agents with the ability to learn world models in a manner that may be both interpretable and computationally scalable. This approach integrating Bayesian structure learning and intrinsically motivated (model-based) planning enables agents to actively develop and refine their world models, which may lead to open-ended learning and more robust, adaptive behavior.",
        "subjects": [
            "cs.AI",
            "cs.MA",
            "q-bio.NC"
        ],
        "comment": "4 pages including appendix, 6 including appendix and references; 2 figures"
    },
    {
        "paper id": "2409.18685",
        "abstract url": "https://arxiv.org/abs/2409.18685",
        "title": "Understanding the Benefits of SimCLR Pre-Training in Two-Layer Convolutional Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "SimCLR is one of the most popular contrastive learning methods for vision tasks. It pre-trains deep neural networks based on a large amount of unlabeled data by teaching the model to distinguish between positive and negative pairs of augmented images. It is believed that SimCLR can pre-train a deep neural network to learn efficient representations that can lead to a better performance of future supervised fine-tuning. Despite its effectiveness, our theoretical understanding of the underlying mechanisms of SimCLR is still limited. In this paper, we theoretically introduce a case study of the SimCLR method. Specifically, we consider training a two-layer convolutional neural network (CNN) to learn a toy image data model. We show that, under certain conditions on the number of labeled data, SimCLR pre-training combined with supervised fine-tuning achieves almost optimal test loss. Notably, the label complexity for SimCLR pre-training is far less demanding compared to direct training on supervised data. Our analysis sheds light on the benefits of SimCLR in learning with fewer labels.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "65 pages, 4 figures"
    },
    {
        "paper id": "2409.18705",
        "abstract url": "https://arxiv.org/abs/2409.18705",
        "title": "Speech Boosting: Low-Latency Live Speech Enhancement for TWS Earbuds",
        "rating": "0.5",
        "keywords": [
            [
                "Speech Enhancement"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ],
            [
                "Interspeech"
            ]
        ],
        "abstract": "This paper introduces a speech enhancement solution tailored for true wireless stereo (TWS) earbuds on-device usage. The solution was specifically designed to support conversations in noisy environments, with active noise cancellation (ANC) activated. The primary challenges for speech enhancement models in this context arise from computational complexity that limits on-device usage and latency that must be less than 3 ms to preserve a live conversation. To address these issues, we evaluated several crucial design elements, including the network architecture and domain, design of loss functions, pruning method, and hardware-specific optimization. Consequently, we demonstrated substantial improvements in speech enhancement quality compared with that in baseline models, while simultaneously reducing the computational complexity and algorithmic latency.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD",
            "eess.SP"
        ],
        "comment": "Accepted by Interspeech 2024"
    },
    {
        "paper id": "2409.18768",
        "abstract url": "https://arxiv.org/abs/2409.18768",
        "title": "Learning from Demonstration with Implicit Nonlinear Dynamics Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Learning from Demonstration (LfD) is a useful paradigm for training policies that solve tasks involving complex motions. In practice, the successful application of LfD requires overcoming error accumulation during policy execution, i.e. the problem of drift due to errors compounding over time and the consequent out-of-distribution behaviours. Existing works seek to address this problem through scaling data collection, correcting policy errors with a human-in-the-loop, temporally ensembling policy predictions or through learning the parameters of a dynamical system model. In this work, we propose and validate an alternative approach to overcoming this issue. Inspired by reservoir computing, we develop a novel neural network layer that includes a fixed nonlinear dynamical system with tunable dynamical properties. We validate the efficacy of our neural network layer on the task of reproducing human handwriting motions using the LASA Human Handwriting Dataset. Through empirical experiments we demonstrate that incorporating our layer into existing neural network architectures addresses the issue of compounding errors in LfD. Furthermore, we perform a comparative evaluation against existing approaches including a temporal ensemble of policy predictions and an Echo State Networks (ESNs) implementation. We find that our approach yields greater policy precision and robustness on the handwriting task while also generalising to multiple dynamics regimes and maintaining competitive latency scores.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.RO",
            "eess.SY"
        ],
        "comment": "21 pages, 9 figures"
    },
    {
        "paper id": "2409.18772",
        "abstract url": "https://arxiv.org/abs/2409.18772",
        "title": "A method of using RSVD in residual calculation of LowBit GEMM",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The advancements of hardware technology in recent years has brought many possibilities for low-precision applications. However, the use of low precision can introduce significant computational errors, posing a considerable challenge to maintaining the computational accuracy. We propose low-rank residuals quantized matrix multiplication(LRQMM) method which introduces low-rank approximation in residual compensation for dense low precision quantization matrix multiplication. It can bring several times accuracy improvement with only BLAS-2 level extra time overhead. Moreover, LRQMM is a completely data-free quantization method that does not require additional data for pre-training. And it only works with low precision GEMM operator, which is easy to couple with other methods. Through experimentation, LRQMM can reduce the error of direct quantized matrix multiplication by 1~2 orders of magnitude, when dealing with larger matrix sizes, the computational speed is only reduced by approximately 20\\%. In deep learning networks, LRQMM-4bit achieves 61.8% ImageNet Top-1 accuracy in Resnet-50, while the Direct Quant accuracy is only 8.3%.",
        "subjects": [
            "cs.MS",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18776",
        "abstract url": "https://arxiv.org/abs/2409.18776",
        "title": "Can AI Enhance its Creativity to Beat Humans ?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Creativity is a fundamental pillar of human expression and a driving force behind innovation, yet it now stands at a crossroads. As artificial intelligence advances at an astonishing pace, the question arises: can machines match and potentially surpass human creativity? This study investigates the creative performance of artificial intelligence (AI) compared to humans by analyzing the effects of two distinct prompting strategies (a Naive and an Expert AI) on AI and across three different tasks (Text, Draw and Alternative Uses tasks). Human external evaluators have scored creative outputs generated by humans and AI, and these subjective creative scores were complemented with objective measures based on quantitative measurements and NLP tools. The results reveal that AI generally outperforms humans in creative tasks, though this advantage is nuanced by the specific nature of each task and the chosen creativity criteria. Ultimately, while AI demonstrates superior performance in certain creative domains, our results suggest that integrating human feedback is crucial for maximizing AI's creative potential.",
        "subjects": [
            "econ.GN",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18798",
        "abstract url": "https://arxiv.org/abs/2409.18798",
        "title": "Esports Debut as a Medal Event at 2023 Asian Games: Exploring Public Perceptions with BERTopic and GPT-4 Topic Fine-Tuning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This study examined the public opinions of esports at the 2023 Asian Games and value co-creation during the event using an LLM-enhanced BERTopic modeling analysis. We identified five major themes representing public perceptions, as well as how major stakeholders co-created value within and beyond the esports ecosystem. Key findings highlighted the strategic use of social media marketing to influence public opinion and promote esports events and brands, emphasizing the importance of event logistics and infrastructure. Additionally, the study revealed the co-creation value contributed by stakeholders outside the traditional esports ecosystem, particularly in promoting national representation and performance. Our findings supported the ongoing efforts to legitimize esports as a sport, noting that mainstream recognition remains a challenge. The inclusion of esports as a medal event showcased broader acceptance and helped mitigate negative public perceptions. Moreover, contributions from non-traditional stakeholders underscored the value of cross-subcultural collaborations in esports.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18827",
        "abstract url": "https://arxiv.org/abs/2409.18827",
        "title": "ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hyperparameters are a critical factor in reliably training well-performing reinforcement learning (RL) agents. Unfortunately, developing and evaluating automated approaches for tuning such hyperparameters is both costly and time-consuming. As a result, such approaches are often only evaluated on a single domain or algorithm, making comparisons difficult and limiting insights into their generalizability. We propose ARLBench, a benchmark for hyperparameter optimization (HPO) in RL that allows comparisons of diverse HPO approaches while being highly efficient in evaluation. To enable research into HPO in RL, even in settings with low compute resources, we select a representative subset of HPO tasks spanning a variety of algorithm and environment combinations. This selection allows for generating a performance profile of an automated RL (AutoRL) method using only a fraction of the compute previously necessary, enabling a broader range of researchers to work on HPO in RL. With the extensive and large-scale dataset on hyperparameter landscapes that our selection is based on, ARLBench is an efficient, flexible, and future-oriented foundation for research on AutoRL. Both the benchmark and the dataset are available at https://github.com/automl/arlbench.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at the 17th European Workshop on Reinforcement Learning"
    },
    {
        "paper id": "2409.18842",
        "abstract url": "https://arxiv.org/abs/2409.18842",
        "title": "Classical Statistical (In-Sample) Intuitions Don't Generalize Well: A Note on Bias-Variance Tradeoffs, Overfitting and Moving from Fixed to Random Designs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The sudden appearance of modern machine learning (ML) phenomena like double descent and benign overfitting may leave many classically trained statisticians feeling uneasy -- these phenomena appear to go against the very core of statistical intuitions conveyed in any introductory class on learning from data. The historical lack of earlier observation of such phenomena is usually attributed to today's reliance on more complex ML methods, overparameterization, interpolation and/or higher data dimensionality. In this note, we show that there is another reason why we observe behaviors today that appear at odds with intuitions taught in classical statistics textbooks, which is much simpler to understand yet rarely discussed explicitly. In particular, many intuitions originate in fixed design settings, in which in-sample prediction error (under resampling of noisy outcomes) is of interest, while modern ML evaluates its predictions in terms of generalization error, i.e. out-of-sample prediction error in random designs. Here, we highlight that this simple move from fixed to random designs has (perhaps surprisingly) far-reaching consequences on textbook intuitions relating to the bias-variance tradeoff, and comment on the resulting (im)possibility of observing double descent and benign overfitting in fixed versus random designs.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18850",
        "abstract url": "https://arxiv.org/abs/2409.18850",
        "title": "Two Sparse Matrices are Better than One: Sparsifying Neural Networks with Double Sparse Factorization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural networks are often challenging to work with due to their large size and complexity. To address this, various methods aim to reduce model size by sparsifying or decomposing weight matrices, such as magnitude pruning and low-rank or block-diagonal factorization. In this work, we present Double Sparse Factorization (DSF), where we factorize each weight matrix into two sparse matrices. Although solving this problem exactly is computationally infeasible, we propose an efficient heuristic based on alternating minimization via ADMM that achieves state-of-the-art results, enabling unprecedented sparsification of neural networks. For instance, in a one-shot pruning setting, our method can reduce the size of the LLaMA2-13B model by 50% while maintaining better performance than the dense LLaMA2-7B model. We also compare favorably with Optimal Brain Compression, the state-of-the-art layer-wise pruning approach for convolutional neural networks. Furthermore, accuracy improvements of our method persist even after further model fine-tuning. Code available at: https://github.com/usamec/double_sparse.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18857",
        "abstract url": "https://arxiv.org/abs/2409.18857",
        "title": "Mitigating Selection Bias with Node Pruning and Auxiliary Options",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models (LLMs) often show unwarranted preference for certain choice options when responding to multiple-choice questions, posing significant reliability concerns in LLM-automated systems. To mitigate this selection bias problem, previous solutions utilized debiasing methods to adjust the model's input and/or output. Our work, in contrast, investigates the model's internal representation of the selection bias. Specifically, we introduce a novel debiasing approach, Bias Node Pruning (BNP), which eliminates the linear layer parameters that contribute to the bias. Furthermore, we present Auxiliary Option Injection (AOI), a simple yet effective input modification technique for debiasing, which is compatible even with black-box LLMs. To provide a more systematic evaluation of selection bias, we review existing metrics and introduce Choice Kullback-Leibler Divergence (CKLD), which addresses the insensitivity of the commonly used metrics to label imbalance. Experiments show that our methods are robust and adaptable across various datasets when applied to three LLMs.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18893",
        "abstract url": "https://arxiv.org/abs/2409.18893",
        "title": "HM3: Hierarchical Multi-Objective Model Merging for Pretrained Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Model merging is a technique that combines multiple large pretrained models into a single model with enhanced performance and broader task adaptability. It has gained popularity in large pretrained model development due to its ability to bypass the need for original training data and further training processes. However, most existing model merging approaches focus solely on exploring the parameter space, merging models with identical architectures. Merging within the architecture space, despite its potential, remains in its early stages due to the vast search space and the challenges of layer compatibility. This paper marks a significant advance toward more flexible and comprehensive model merging techniques by modeling the architecture-space merging process as a reinforcement learning task. We train policy and value networks using offline sampling of weight vectors, which are then employed for the online optimization of merging strategies. Moreover, a multi-objective optimization paradigm is introduced to accommodate users' diverse task preferences, learning the Pareto front of optimal models to offer customized merging suggestions. Experimental results across multiple tasks, including text translation, mathematical reasoning, and code generation, validate the effectiveness and superiority of the proposed framework in model merging. The code will be made publicly available after the review process.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18905",
        "abstract url": "https://arxiv.org/abs/2409.18905",
        "title": "Probabilistic Analysis of Least Squares, Orthogonal Projection, and QR Factorization Algorithms Subject to Gaussian Noise",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we extend the work of Liesen et al. (2002), which analyzes how the condition number of an orthonormal matrix Q changes when a column is added ([Q, c]), particularly focusing on the perpendicularity of c to the span of Q. Their result, presented in Theorem 2.3 of Liesen et al. (2002), assumes exact arithmetic and orthonormality of Q, which is a strong assumption when applying these results to numerical methods such as QR factorization algorithms. In our work, we address this gap by deriving bounds on the condition number increase for a matrix B without assuming perfect orthonormality, even when a column is not perfectly orthogonal to the span of B. This framework allows us to analyze QR factorization methods where orthogonalization is imperfect and subject to Gaussian noise. We also provide results on the performance of orthogonal projection and least squares under Gaussian noise, further supporting the development of this theory.",
        "subjects": [
            "math.NA",
            "cs.LG",
            "math.PR",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18909",
        "abstract url": "https://arxiv.org/abs/2409.18909",
        "title": "Best Arm Identification with Minimal Regret",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Motivated by real-world applications that necessitate responsible experimentation, we introduce the problem of best arm identification (BAI) with minimal regret. This innovative variant of the multi-armed bandit problem elegantly amalgamates two of its most ubiquitous objectives: regret minimization and BAI. More precisely, the agent's goal is to identify the best arm with a prescribed confidence level $\u03b4$, while minimizing the cumulative regret up to the stopping time. Focusing on single-parameter exponential families of distributions, we leverage information-theoretic techniques to establish an instance-dependent lower bound on the expected cumulative regret. Moreover, we present an intriguing impossibility result that underscores the tension between cumulative regret and sample complexity in fixed-confidence BAI. Complementarily, we design and analyze the Double KL-UCB algorithm, which achieves asymptotic optimality as the confidence level tends to zero. Notably, this algorithm employs two distinct confidence bounds to guide arm selection in a randomized manner. Our findings elucidate a fresh perspective on the inherent connections between regret minimization and BAI.",
        "subjects": [
            "cs.LG",
            "cs.IT",
            "stat.ML"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2409.18911",
        "abstract url": "https://arxiv.org/abs/2409.18911",
        "title": "Soft Measures for Extracting Causal Collective Intelligence",
        "rating": "0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.SI",
                "cs.CY",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Understanding and modeling collective intelligence is essential for addressing complex social systems. Directed graphs called fuzzy cognitive maps (FCMs) offer a powerful tool for encoding causal mental models, but extracting high-integrity FCMs from text is challenging. This study presents an approach using large language models (LLMs) to automate FCM extraction. We introduce novel graph-based similarity measures and evaluate them by correlating their outputs with human judgments through the Elo rating system. Results show positive correlations with human evaluations, but even the best-performing measure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs improves performance, but existing measures still fall short. This study highlights the need for soft similarity measures tailored to FCM extraction, advancing collective intelligence modeling with NLP.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.SI"
        ],
        "comment": "Camera-ready version accepted for publication in the EMNLP 2024 Workshop NLP4Science"
    },
    {
        "paper id": "2409.18931",
        "abstract url": "https://arxiv.org/abs/2409.18931",
        "title": "Social Media Bot Policies: Evaluating Passive and Active Enforcement",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "The emergence of Multimodal Foundation Models (MFMs) holds significant promise for transforming social media platforms. However, this advancement also introduces substantial security and ethical concerns, as it may facilitate malicious actors in the exploitation of online users. We aim to evaluate the strength of security protocols on prominent social media platforms in mitigating the deployment of MFM bots. We examined the bot and content policies of eight popular social media platforms: X (formerly Twitter), Instagram, Facebook, Threads, TikTok, Mastodon, Reddit, and LinkedIn. Using Selenium, we developed a web bot to test bot deployment and AI-generated content policies and their enforcement mechanisms. Our findings indicate significant vulnerabilities within the current enforcement mechanisms of these platforms. Despite having explicit policies against bot activity, all platforms failed to detect and prevent the operation of our MFM bots. This finding reveals a critical gap in the security measures employed by these social media platforms, underscoring the potential for malicious actors to exploit these weaknesses to disseminate misinformation, commit fraud, or manipulate users.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18941",
        "abstract url": "https://arxiv.org/abs/2409.18941",
        "title": "Building Trust Through Voice: How Vocal Tone Impacts User Perception of Attractiveness of Voice Assistants",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Voice Assistants (VAs) are popular for simple tasks, but users are often hesitant to use them for complex activities like online shopping. We explored whether the vocal characteristics like the VA's vocal tone, can make VAs perceived as more attractive and trustworthy to users for complex tasks. Our findings show that the tone of the VA voice significantly impacts its perceived attractiveness and trustworthiness. Participants in our experiment were more likely to be attracted to VAs with positive or neutral tones and ultimately trusted the VAs they found more attractive. We conclude that VA's perceived trustworthiness can be enhanced through thoughtful voice design, incorporating a variety of vocal tones.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "Extended Abstract"
    },
    {
        "paper id": "2409.18952",
        "abstract url": "https://arxiv.org/abs/2409.18952",
        "title": "RepairBench: Leaderboard of Frontier Models for Program Repair",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "AI-driven program repair uses AI models to repair buggy software by producing patches. Rapid advancements in AI surely impact state-of-the-art performance of program repair. Yet, grasping this progress requires frequent and standardized evaluations. We propose RepairBench, a novel leaderboard for AI-driven program repair. The key characteristics of RepairBench are: 1) it is execution-based: all patches are compiled and executed against a test suite, 2) it assesses frontier models in a frequent and standardized way. RepairBench leverages two high-quality benchmarks, Defects4J and GitBug-Java, to evaluate frontier models against real-world program repair tasks. We publicly release the evaluation framework of RepairBench. We will update the leaderboard as new frontier models are released.",
        "subjects": [
            "cs.SE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18953",
        "abstract url": "https://arxiv.org/abs/2409.18953",
        "title": "UniCal: Unified Neural Sensor Calibration",
        "rating": "0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Self-driving vehicles (SDVs) require accurate calibration of LiDARs and cameras to fuse sensor data accurately for autonomy. Traditional calibration methods typically leverage fiducials captured in a controlled and structured scene and compute correspondences to optimize over. These approaches are costly and require substantial infrastructure and operations, making it challenging to scale for vehicle fleets. In this work, we propose UniCal, a unified framework for effortlessly calibrating SDVs equipped with multiple LiDARs and cameras. Our approach is built upon a differentiable scene representation capable of rendering multi-view geometrically and photometrically consistent sensor observations. We jointly learn the sensor calibration and the underlying scene representation through differentiable volume rendering, utilizing outdoor sensor data without the need for specific calibration fiducials. This \"drive-and-calibrate\" approach significantly reduces costs and operational overhead compared to existing calibration systems, enabling efficient calibration for large SDV fleets at scale. To ensure geometric consistency across observations from different sensors, we introduce a novel surface alignment loss that combines feature-based registration with neural rendering. Comprehensive evaluations on multiple datasets demonstrate that UniCal outperforms or matches the accuracy of existing calibration approaches while being more efficient, demonstrating the value of UniCal for scalable calibration.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "ECCV 2024. Project page: https://waabi.ai/unical/"
    },
    {
        "paper id": "2409.18961",
        "abstract url": "https://arxiv.org/abs/2409.18961",
        "title": "ProMerge: Prompt and Merge for Unsupervised Instance Segmentation",
        "rating": "0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Unsupervised instance segmentation aims to segment distinct object instances in an image without relying on human-labeled data. This field has recently seen significant advancements, partly due to the strong local correspondences afforded by rich visual feature representations from self-supervised models (e.g., DINO). Recent state-of-the-art approaches use self-supervised features to represent images as graphs and solve a generalized eigenvalue system (i.e., normalized-cut) to generate foreground masks. While effective, this strategy is limited by its attendant computational demands, leading to slow inference speeds. In this paper, we propose Prompt and Merge (ProMerge), which leverages self-supervised visual features to obtain initial groupings of patches and applies a strategic merging to these segments, aided by a sophisticated background-based mask pruning technique. ProMerge not only yields competitive results but also offers a significant reduction in inference time compared to state-of-the-art normalized-cut-based approaches. Furthermore, when training an object detector using our mask predictions as pseudo-labels, the resulting detector surpasses the current leading unsupervised model on various challenging instance segmentation benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "ECCV2024 camera-ready"
    },
    {
        "paper id": "2409.19069",
        "abstract url": "https://arxiv.org/abs/2409.19069",
        "title": "Localizing Memorization in SSL Vision Encoders",
        "rating": "0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Recent work on studying memorization in self-supervised learning (SSL) suggests that even though SSL encoders are trained on millions of images, they still memorize individual data points. While effort has been put into characterizing the memorized data and linking encoder memorization to downstream utility, little is known about where the memorization happens inside SSL encoders. To close this gap, we propose two metrics for localizing memorization in SSL encoders on a per-layer (layermem) and per-unit basis (unitmem). Our localization methods are independent of the downstream task, do not require any label information, and can be performed in a forward pass. By localizing memorization in various encoder architectures (convolutional and transformer-based) trained on diverse datasets with contrastive and non-contrastive SSL frameworks, we find that (1) while SSL memorization increases with layer depth, highly memorizing units are distributed across the entire encoder, (2) a significant fraction of units in SSL encoders experiences surprisingly high memorization of individual data points, which is in contrast to models trained under supervision, (3) atypical (or outlier) data points cause much higher layer and unit memorization than standard data points, and (4) in vision transformers, most memorization happens in the fully-connected layers. Finally, we show that localizing memorization in SSL has the potential to improve fine-tuning and to inform pruning strategies.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted at NeurIPS 2024"
    },
    {
        "paper id": "2409.19104",
        "abstract url": "https://arxiv.org/abs/2409.19104",
        "title": "Responsible AI in Open Ecosystems: Reconciling Innovation with Risk Assessment and Disclosure",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "The rapid scaling of AI has spurred a growing emphasis on ethical considerations in both development and practice. This has led to the formulation of increasingly sophisticated model auditing and reporting requirements, as well as governance frameworks to mitigate potential risks to individuals and society. At this critical juncture, we review the practical challenges of promoting responsible AI and transparency in informal sectors like OSS that support vital infrastructure and see widespread use. We focus on how model performance evaluation may inform or inhibit probing of model limitations, biases, and other risks. Our controlled analysis of 7903 Hugging Face projects found that risk documentation is strongly associated with evaluation practices. Yet, submissions (N=789) from the platform's most popular competitive leaderboard showed less accountability among high performers. Our findings can inform AI providers and legal scholars in designing interventions and policies that preserve open-source innovation while incentivizing ethical uptake.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CY",
            "cs.ET",
            "cs.SE"
        ],
        "comment": "[Under Review][WIP]"
    },
    {
        "paper id": "2409.19135",
        "abstract url": "https://arxiv.org/abs/2409.19135",
        "title": "Chebyshev Feature Neural Network for Accurate Function Approximation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a new Deep Neural Network (DNN) architecture capable of approximating functions up to machine accuracy. Termed Chebyshev Feature Neural Network (CFNN), the new structure employs Chebyshev functions with learnable frequencies as the first hidden layer, followed by the standard fully connected hidden layers. The learnable frequencies of the Chebyshev layer are initialized with exponential distributions to cover a wide range of frequencies. Combined with a multi-stage training strategy, we demonstrate that this CFNN structure can achieve machine accuracy during training. A comprehensive set of numerical examples for dimensions up to $20$ are provided to demonstrate the effectiveness and scalability of the method.",
        "subjects": [
            "cs.LG",
            "cs.NE",
            "math.NA",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19150",
        "abstract url": "https://arxiv.org/abs/2409.19150",
        "title": "On the Power of Decision Trees in Auto-Regressive Language Modeling",
        "rating": "0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Originally proposed for handling time series data, Auto-regressive Decision Trees (ARDTs) have not yet been explored for language modeling. This paper delves into both the theoretical and practical applications of ARDTs in this new context. We theoretically demonstrate that ARDTs can compute complex functions, such as simulating automata, Turing machines, and sparse circuits, by leveraging \"chain-of-thought\" computations. Our analysis provides bounds on the size, depth, and computational efficiency of ARDTs, highlighting their surprising computational power. Empirically, we train ARDTs on simple language generation tasks, showing that they can learn to generate coherent and grammatically correct text on par with a smaller Transformer model. Additionally, we show that ARDTs can be used on top of transformer representations to solve complex reasoning tasks. This research reveals the unique computational abilities of ARDTs, aiming to broaden the architectural diversity in language model development.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to NeurIPS 2024"
    },
    {
        "paper id": "2409.19158",
        "abstract url": "https://arxiv.org/abs/2409.19158",
        "title": "bnRep: A repository of Bayesian networks from the academic literature",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Bayesian networks (BNs) are widely used for modeling complex systems with uncertainty, yet repositories of pre-built BNs remain limited. This paper introduces bnRep, an open-source R package offering a comprehensive collection of documented BNs, facilitating benchmarking, replicability, and education. With over 200 networks from academic publications, bnRep integrates seamlessly with bnlearn and other R packages, providing users with interactive tools for network exploration.",
        "subjects": [
            "cs.AI",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19166",
        "abstract url": "https://arxiv.org/abs/2409.19166",
        "title": "Understanding #vent Channels on Discord",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Vent channels on Discord, which are chat channels developed for people to express frustrations, can become an informal type of peer support system. This paper is a qualitative study of experiences with vent channels on Discord, examining the experiences of 13 participants through semi-structured interviews. We find that participants are able to meet their needs for social support via vent channels by receiving commiseration, advice, and validation from the responses of others. At the same time, vent channels can lead to frustration when participants have conflicting expectations for their interactions. We suggest ways that Discord or Discord server moderators can provide enhanced structure, clarity, and transparency in order to enable participants to have better experiences in vent channels.",
        "subjects": [
            "cs.SI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19182",
        "abstract url": "https://arxiv.org/abs/2409.19182",
        "title": "Artificial-Intelligence Generated Code Considered Harmful: A Road Map for Secure and High-Quality Code Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Generating code via a LLM (rather than writing code from scratch), has exploded in popularity. However, the security implications of LLM-generated code are still unknown. We performed a study that compared the security and quality of human-written code with that of LLM-generated code, for a wide range of programming tasks, including data structures, algorithms, cryptographic routines, and LeetCode questions. To assess code security we used unit testing, fuzzing, and static analysis. For code quality, we focused on complexity and size. We found that LLM can generate incorrect code that fails to implement the required functionality, especially for more complicated tasks; such errors can be subtle. For example, for the cryptographic algorithm SHA1, LLM generated an incorrect implementation that nevertheless compiles. In cases where its functionality was correct, we found that LLM-generated code is less secure, primarily due to the lack of defensive programming constructs, which invites a host of security issues such as buffer overflows or integer overflows. Fuzzing has revealed that LLM-generated code is more prone to hangs and crashes than human-written code. Quality-wise, we found that LLM generates bare-bones code that lacks defensive programming constructs, and is typically more complex (per line of code) compared to human-written code. Next, we constructed a feedback loop that asked the LLM to re-generate the code and eliminate the found issues (e.g., malloc overflow, array index out of bounds, null dereferences). We found that the LLM fails to eliminate such issues consistently: while succeeding in some cases, we found instances where the re-generated, supposedly more secure code, contains new issues; we also found that upon prompting, LLM can introduce issues in files that were issues-free before prompting.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19200",
        "abstract url": "https://arxiv.org/abs/2409.19200",
        "title": "Faster Acceleration for Steepest Descent",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a new accelerated first-order method for convex optimization under non-Euclidean smoothness assumptions. In contrast to standard acceleration techniques, our approach uses primal-dual iterate sequences taken with respect to differing norms, which are then coupled using an implicitly determined interpolation parameter. For $\\ell_p$ norm smooth problems in $d$ dimensions, our method provides an iteration complexity improvement of up to $O(d^{1-\\frac{2}{p}})$ in terms of calls to a first-order oracle, thereby allowing us to circumvent long-standing barriers in accelerated non-Euclidean steepest descent.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19209",
        "abstract url": "https://arxiv.org/abs/2409.19209",
        "title": "Boosting SISSO Performance on Small Sample Datasets by Using Random Forests Prescreening for Complex Feature Selection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In materials science, data-driven methods accelerate material discovery and optimization while reducing costs and improving success rates. Symbolic regression is a key to extracting material descriptors from large datasets, in particular the Sure Independence Screening and Sparsifying Operator (SISSO) method. While SISSO needs to store the entire expression space to impose heavy memory demands, it limits the performance in complex problems. To address this issue, we propose a RF-SISSO algorithm by combining Random Forests (RF) with SISSO. In this algorithm, the Random Forest algorithm is used for prescreening, capturing non-linear relationships and improving feature selection, which may enhance the quality of the input data and boost the accuracy and efficiency on regression and classification tasks. For a testing on the SISSO's verification problem for 299 materials, RF-SISSO demonstrates its robust performance and high accuracy. RF-SISSO can maintain the testing accuracy above 0.9 across all four training sample sizes and significantly enhancing regression efficiency, especially in training subsets with smaller sample sizes. For the training subset with 45 samples, the efficiency of RF-SISSO was 265 times higher than that of original SISSO. As collecting large datasets would be both costly and time-consuming in the practical experiments, it is thus believed that RF-SISSO may benefit scientific researches by offering a high predicting accuracy with limited data efficiently.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci",
            "physics.data-an"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19214",
        "abstract url": "https://arxiv.org/abs/2409.19214",
        "title": "Group Distributionally Robust Optimization can Suppress Class Imbalance Effect in Network Traffic Classification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Internet services have led to the eruption of traffic, and machine learning on these Internet data has become an indispensable tool, especially when the application is risk-sensitive. This paper focuses on network traffic classification in the presence of class imbalance, which fundamentally and ubiquitously exists in Internet data analysis. This existence of class imbalance mostly drifts the optimal decision boundary, resulting in a less optimal solution for machine learning models. To alleviate the effect, we propose to design strategies for alleviating the class imbalance through the lens of group distributionally robust optimization. Our approach iteratively updates the non-parametric weights for separate classes and optimizes the learning model by minimizing reweighted losses. We interpret the optimization steps from a Stackelberg game and perform extensive experiments on typical benchmarks. Results show that our approach can not only suppress the negative effect of class imbalance but also improve the comprehensive performance in prediction.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19218",
        "abstract url": "https://arxiv.org/abs/2409.19218",
        "title": "A Characterization of List Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "There has been a recent interest in understanding and characterizing the sample complexity of list learning tasks, where the learning algorithm is allowed to make a short list of $k$ predictions, and we simply require one of the predictions to be correct. This includes recent works characterizing the PAC sample complexity of standard list classification and online list classification. Adding to this theme, in this work, we provide a complete characterization of list PAC regression. We propose two combinatorial dimensions, namely the $k$-OIG dimension and the $k$-fat-shattering dimension, and show that they optimally characterize realizable and agnostic $k$-list regression respectively. These quantities generalize known dimensions for standard regression. Our work thus extends existing list learning characterizations from classification to regression.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19226",
        "abstract url": "https://arxiv.org/abs/2409.19226",
        "title": "Learning to Bridge the Gap: Efficient Novelty Recovery with Planning and Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The real world is unpredictable. Therefore, to solve long-horizon decision-making problems with autonomous robots, we must construct agents that are capable of adapting to changes in the environment during deployment. Model-based planning approaches can enable robots to solve complex, long-horizon tasks in a variety of environments. However, such approaches tend to be brittle when deployed into an environment featuring a novel situation that their underlying model does not account for. In this work, we propose to learn a ``bridge policy'' via Reinforcement Learning (RL) to adapt to such novelties. We introduce a simple formulation for such learning, where the RL problem is constructed with a special ``CallPlanner'' action that terminates the bridge policy and hands control of the agent back to the planner. This allows the RL policy to learn the set of states in which querying the planner and following the returned plan will achieve the goal. We show that this formulation enables the agent to rapidly learn by leveraging the planner's knowledge to avoid challenging long-horizon exploration caused by sparse reward. In experiments across three different simulated domains of varying complexity, we demonstrate that our approach is able to learn policies that adapt to novelty more efficiently than several baselines, including a pure RL baseline. We also demonstrate that the learned bridge policy is generalizable in that it can be combined with the planner to enable the agent to solve more complex tasks with multiple instances of the encountered novelty.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19231",
        "abstract url": "https://arxiv.org/abs/2409.19231",
        "title": "Double Actor-Critic with TD Error-Driven Regularization in Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "To obtain better value estimation in reinforcement learning, we propose a novel algorithm based on the double actor-critic framework with temporal difference error-driven regularization, abbreviated as TDDR. TDDR employs double actors, with each actor paired with a critic, thereby fully leveraging the advantages of double critics. Additionally, TDDR introduces an innovative critic regularization architecture. Compared to classical deterministic policy gradient-based algorithms that lack a double actor-critic structure, TDDR provides superior estimation. Moreover, unlike existing algorithms with double actor-critic frameworks, TDDR does not introduce any additional hyperparameters, significantly simplifying the design and implementation process. Experiments demonstrate that TDDR exhibits strong competitiveness compared to benchmark algorithms in challenging continuous control tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19237",
        "abstract url": "https://arxiv.org/abs/2409.19237",
        "title": "The Price of Pessimism for Automated Defense",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The well-worn George Box aphorism ``all models are wrong, but some are useful'' is particularly salient in the cybersecurity domain, where the assumptions built into a model can have substantial financial or even national security impacts. Computer scientists are often asked to optimize for worst-case outcomes, and since security is largely focused on risk mitigation, preparing for the worst-case scenario appears rational. In this work, we demonstrate that preparing for the worst case rather than the most probable case may yield suboptimal outcomes for learning agents. Through the lens of stochastic Bayesian games, we first explore different attacker knowledge modeling assumptions that impact the usefulness of models to cybersecurity practitioners. By considering different models of attacker knowledge about the state of the game and a defender's hidden information, we find that there is a cost to the defender for optimizing against the worst case.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "Accepted to GameSec 2024"
    },
    {
        "paper id": "2409.18448",
        "abstract url": "https://arxiv.org/abs/2409.18448",
        "title": "Hierarchical Federated Learning with Multi-Timescale Gradient Correction",
        "rating": "0",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "While traditional federated learning (FL) typically focuses on a star topology where clients are directly connected to a central server, real-world distributed systems often exhibit hierarchical architectures. Hierarchical FL (HFL) has emerged as a promising solution to bridge this gap, leveraging aggregation points at multiple levels of the system. However, existing algorithms for HFL encounter challenges in dealing with multi-timescale model drift, i.e., model drift occurring across hierarchical levels of data heterogeneity. In this paper, we propose a multi-timescale gradient correction (MTGC) methodology to resolve this issue. Our key idea is to introduce distinct control variables to (i) correct the client gradient towards the group gradient, i.e., to reduce client model drift caused by local updates based on individual datasets, and (ii) correct the group gradient towards the global gradient, i.e., to reduce group model drift caused by FL over clients within the group. We analytically characterize the convergence behavior of MTGC under general non-convex settings, overcoming challenges associated with couplings between correction terms. We show that our convergence bound is immune to the extent of data heterogeneity, confirming the stability of the proposed algorithm against multi-level non-i.i.d. data. Through extensive experiments on various datasets and models, we validate the effectiveness of MTGC in diverse HFL settings. The code for this project is available at \\href{https://github.com/wenzhifang/MTGC}{https://github.com/wenzhifang/MTGC}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to NeurIPS 2024"
    },
    {
        "paper id": "2409.18523",
        "abstract url": "https://arxiv.org/abs/2409.18523",
        "title": "Token Caching for Diffusion Transformer Acceleration",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion transformers have gained substantial interest in diffusion generative modeling due to their outstanding performance. However, their high computational cost, arising from the quadratic computational complexity of attention mechanisms and multi-step inference, presents a significant bottleneck. To address this challenge, we propose TokenCache, a novel post-training acceleration method that leverages the token-based multi-block architecture of transformers to reduce redundant computations among tokens across inference steps. TokenCache specifically addresses three critical questions in the context of diffusion transformers: (1) which tokens should be pruned to eliminate redundancy, (2) which blocks should be targeted for efficient pruning, and (3) at which time steps caching should be applied to balance speed and quality. In response to these challenges, TokenCache introduces a Cache Predictor that assigns importance scores to tokens, enabling selective pruning without compromising model performance. Furthermore, we propose an adaptive block selection strategy to focus on blocks with minimal impact on the network's output, along with a Two-Phase Round-Robin (TPRR) scheduling policy to optimize caching intervals throughout the denoising process. Experimental results across various models demonstrate that TokenCache achieves an effective trade-off between generation quality and inference speed for diffusion transformers. Our code will be publicly available.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18558",
        "abstract url": "https://arxiv.org/abs/2409.18558",
        "title": "XWSB: A Blend System Utilizing XLS-R and WavLM with SLS Classifier detection system for SVDD 2024 Challenge",
        "rating": "0",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces the model structure used in the SVDD 2024 Challenge. The SVDD 2024 challenge has been introduced this year for the first time. Singing voice deepfake detection (SVDD) which faces complexities due to informal speech intonations and varying speech rates. In this paper, we propose the XWSB system, which achieved SOTA per-formance in the SVDD challenge. XWSB stands for XLS-R, WavLM, and SLS Blend, representing the integration of these technologies for the purpose of SVDD. Specifically, we used the best performing model structure XLS-R&SLS from the ASVspoof DF dataset, and applied SLS to WavLM to form the WavLM&SLS structure. Finally, we integrated two models to form the XWSB system. Experimental results show that our system demonstrates advanced recognition capabilities in the SVDD challenge, specifically achieving an EER of 2.32% in the CtrSVDD track. The code and data can be found at https://github.com/QiShanZhang/XWSB_for_ SVDD2024.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18592",
        "abstract url": "https://arxiv.org/abs/2409.18592",
        "title": "From One to the Power of Many: Augmentations for Invariance to Multi-LiDAR Perception from Single-Sensor Datasets",
        "rating": "0",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, LiDAR perception methods for autonomous vehicles, powered by deep neural networks have experienced steep growth in performance on classic benchmarks, such as nuScenes and SemanticKITTI. However, there are still large gaps in performance when deploying models trained on such single-sensor setups to modern multi-sensor vehicles. In this work, we investigate if a lack of invariance may be responsible for these performance gaps, and propose some initial solutions in the form of application-specific data augmentations, which can facilitate better transfer to multi-sensor LiDAR setups. We provide experimental evidence that our proposed augmentations improve generalization across LiDAR sensor setups, and investigate how these augmentations affect the models' invariance properties on simulations of different LiDAR sensor setups.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18678",
        "abstract url": "https://arxiv.org/abs/2409.18678",
        "title": "Rehearsing Answers to Probable Questions with Perspective-Taking",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Question answering (QA) has been a long-standing focus in the NLP field, predominantly addressing reading comprehension and common sense QA. However, scenarios involving the preparation of answers to probable questions during professional oral presentations remain underexplored. In this paper, we pioneer the examination of this crucial yet overlooked topic by utilizing real-world QA conversation transcripts between company managers and professional analysts. We explore the proposed task using three causal knowledge graphs (KGs) and three large language models (LLMs). This work provides foundational insights into the application of LLMs in professional QA scenarios, highlighting the importance of causal KGs and perspective-taking in generating effective responses.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18679",
        "abstract url": "https://arxiv.org/abs/2409.18679",
        "title": "\"Why\" Has the Least Side Effect on Model Editing",
        "rating": "0",
        "keywords": [
            [
                "Model Editing"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Training large language models (LLMs) from scratch is an expensive endeavor, particularly as world knowledge continually evolves. To maintain relevance and accuracy of LLMs, model editing has emerged as a pivotal research area. While these methods hold promise, they can also produce unintended side effects. Their underlying factors and causes remain largely unexplored. This paper delves into a critical factor-question type-by categorizing model editing questions. Our findings reveal that the extent of performance degradation varies significantly across different question types, providing new insights for experimental design in knowledge editing. Furthermore, we investigate whether insights from smaller models can be extrapolated to larger models. Our results indicate discrepancies in findings between models of different sizes, suggesting that insights from smaller models may not necessarily apply to larger models. Additionally, we examine the impact of batch size on side effects, discovering that increasing the batch size can mitigate performance drops.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18694",
        "abstract url": "https://arxiv.org/abs/2409.18694",
        "title": "Learning from Pattern Completion: Self-supervised Controllable Generation",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The human brain exhibits a strong ability to spontaneously associate different visual attributes of the same or similar visual scene, such as associating sketches and graffiti with real-world visual objects, usually without supervising information. In contrast, in the field of artificial intelligence, controllable generation methods like ControlNet heavily rely on annotated training datasets such as depth maps, semantic segmentation maps, and poses, which limits the method's scalability. Inspired by the neural mechanisms that may contribute to the brain's associative power, specifically the cortical modularization and hippocampal pattern completion, here we propose a self-supervised controllable generation (SCG) framework. Firstly, we introduce an equivariant constraint to promote inter-module independence and intra-module correlation in a modular autoencoder network, thereby achieving functional specialization. Subsequently, based on these specialized modules, we employ a self-supervised pattern completion approach for controllable generation training. Experimental results demonstrate that the proposed modular autoencoder effectively achieves functional specialization, including the modular processing of color, brightness, and edge detection, and exhibits brain-like features including orientation selectivity, color antagonism, and center-surround receptive fields. Through self-supervised training, associative generation capabilities spontaneously emerge in SCG, demonstrating excellent generalization ability to various tasks such as associative generation on painting, sketches, and ancient graffiti. Compared to the previous representative method ControlNet, our proposed approach not only demonstrates superior robustness in more challenging high-noise scenarios but also possesses more promising scalability potential due to its self-supervised manner.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18708",
        "abstract url": "https://arxiv.org/abs/2409.18708",
        "title": "Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce a novel family of adversarial attacks that exploit the inability of language models to interpret ASCII art. To evaluate these attacks, we propose the ToxASCII benchmark and develop two custom ASCII art fonts: one leveraging special tokens and another using text-filled letter shapes. Our attacks achieve a perfect 1.0 Attack Success Rate across ten models, including OpenAI's o1-preview and LLaMA 3.1. Warning: this paper contains examples of toxic language used for research purposes.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18764",
        "abstract url": "https://arxiv.org/abs/2409.18764",
        "title": "Charting the Future: Using Chart Question-Answering for Scalable Evaluation of LLM-Driven Data Visualizations",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "We propose a novel framework that leverages Visual Question Answering (VQA) models to automate the evaluation of LLM-generated data visualizations. Traditional evaluation methods often rely on human judgment, which is costly and unscalable, or focus solely on data accuracy, neglecting the effectiveness of visual communication. By employing VQA models, we assess data representation quality and the general communicative clarity of charts. Experiments were conducted using two leading VQA benchmark datasets, ChartQA and PlotQA, with visualizations generated by OpenAI's GPT-3.5 Turbo and Meta's Llama 3.1 70B-Instruct models. Our results indicate that LLM-generated charts do not match the accuracy of the original non-LLM-generated charts based on VQA performance measures. Moreover, while our results demonstrate that few-shot prompting significantly boosts the accuracy of chart generation, considerable progress remains to be made before LLMs can fully match the precision of human-generated graphs. This underscores the importance of our work, which expedites the research process by enabling rapid iteration without the need for human annotation, thus accelerating advancements in this field.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18800",
        "abstract url": "https://arxiv.org/abs/2409.18800",
        "title": "MiniVLN: Efficient Vision-and-Language Navigation by Progressive Knowledge Distillation",
        "rating": "0",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, Embodied Artificial Intelligence (Embodied AI) has advanced rapidly, yet the increasing size of models conflicts with the limited computational capabilities of Embodied AI platforms. To address this challenge, we aim to achieve both high model performance and practical deployability. Specifically, we focus on Vision-and-Language Navigation (VLN), a core task in Embodied AI. This paper introduces a two-stage knowledge distillation framework, producing a student model, MiniVLN, and showcasing the significant potential of distillation techniques in developing lightweight models. The proposed method aims to capture fine-grained knowledge during the pretraining phase and navigation-specific knowledge during the fine-tuning phase. Our findings indicate that the two-stage distillation approach is more effective in narrowing the performance gap between the teacher model and the student model compared to single-stage distillation. On the public R2R and REVERIE benchmarks, MiniVLN achieves performance on par with the teacher model while having only about 12% of the teacher model's parameter count.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18852",
        "abstract url": "https://arxiv.org/abs/2409.18852",
        "title": "Space-time 2D Gaussian Splatting for Accurate Surface Reconstruction under Complex Dynamic Scenes",
        "rating": "0",
        "keywords": [
            [
                "Gaussian Splatting",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Previous surface reconstruction methods either suffer from low geometric accuracy or lengthy training times when dealing with real-world complex dynamic scenes involving multi-person activities, and human-object interactions. To tackle the dynamic contents and the occlusions in complex scenes, we present a space-time 2D Gaussian Splatting approach. Specifically, to improve geometric quality in dynamic scenes, we learn canonical 2D Gaussian splats and deform these 2D Gaussian splats while enforcing the disks of the Gaussian located on the surface of the objects by introducing depth and normal regularizers. Further, to tackle the occlusion issues in complex scenes, we introduce a compositional opacity deformation strategy, which further reduces the surface recovery of those occluded areas. Experiments on real-world sparse-view video datasets and monocular dynamic datasets demonstrate that our reconstructions outperform state-of-the-art methods, especially for the surface of the details. The project page and more visualizations can be found at: https://tb2-sy.github.io/st-2dgs/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://tb2-sy.github.io/st-2dgs/"
    },
    {
        "paper id": "2409.18865",
        "abstract url": "https://arxiv.org/abs/2409.18865",
        "title": "Positional Encoder Graph Quantile Neural Networks for Geographic Data",
        "rating": "0",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "cs.CV"
            ]
        ],
        "abstract": "Positional Encoder Graph Neural Networks (PE-GNNs) are a leading approach for modeling continuous spatial data. However, they often fail to produce calibrated predictive distributions, limiting their effectiveness for uncertainty quantification. We introduce the Positional Encoder Graph Quantile Neural Network (PE-GQNN), a novel method that integrates PE-GNNs, Quantile Neural Networks, and recalibration techniques in a fully nonparametric framework, requiring minimal assumptions about the predictive distributions. We propose a new network architecture that, when combined with a quantile-based loss function, yields accurate and reliable probabilistic models without increasing computational complexity. Our approach provides a flexible, robust framework for conditional density estimation, applicable beyond spatial data contexts. We further introduce a structured method for incorporating a KNN predictor into the model while avoiding data leakage through the GNN layer operation. Experiments on benchmark datasets demonstrate that PE-GQNN significantly outperforms existing state-of-the-art methods in both predictive accuracy and uncertainty quantification.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.SI"
        ],
        "comment": "17 main text pages, 4 figures"
    },
    {
        "paper id": "2409.18869",
        "abstract url": "https://arxiv.org/abs/2409.18869",
        "title": "Emu3: Next-Token Prediction is All You Need",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While next-token prediction is considered a promising path towards artificial general intelligence, it has struggled to excel in multimodal tasks, which are still dominated by diffusion models (e.g., Stable Diffusion) and compositional approaches (e.g., CLIP combined with LLMs). In this paper, we introduce Emu3, a new suite of state-of-the-art multimodal models trained solely with next-token prediction. By tokenizing images, text, and videos into a discrete space, we train a single transformer from scratch on a mixture of multimodal sequences. Emu3 outperforms several well-established task-specific models in both generation and perception tasks, surpassing flagship models such as SDXL and LLaVA-1.6, while eliminating the need for diffusion or compositional architectures. Emu3 is also capable of generating high-fidelity video via predicting the next token in a video sequence. We simplify complex multimodal model designs by converging on a singular focus: tokens, unlocking great potential for scaling both during training and inference. Our results demonstrate that next-token prediction is a promising path towards building general multimodal intelligence beyond language. We open-source key techniques and models to support further research in this direction.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://emu.baai.ac.cn"
    },
    {
        "paper id": "2409.18881",
        "abstract url": "https://arxiv.org/abs/2409.18881",
        "title": "Explainable Artifacts for Synthetic Western Blot Source Attribution",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in artificial intelligence have enabled generative models to produce synthetic scientific images that are indistinguishable from pristine ones, posing a challenge even for expert scientists habituated to working with such content. When exploited by organizations known as paper mills, which systematically generate fraudulent articles, these technologies can significantly contribute to the spread of misinformation about ungrounded science, potentially undermining trust in scientific research. While previous studies have explored black-box solutions, such as Convolutional Neural Networks, for identifying synthetic content, only some have addressed the challenge of generalizing across different models and providing insight into the artifacts in synthetic images that inform the detection process. This study aims to identify explainable artifacts generated by state-of-the-art generative models (e.g., Generative Adversarial Networks and Diffusion Models) and leverage them for open-set identification and source attribution (i.e., pointing to the model that created the image).",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in IEEE International Workshop on Information Forensics and Security - WIFS 2024, Rome, Italy"
    },
    {
        "paper id": "2409.18896",
        "abstract url": "https://arxiv.org/abs/2409.18896",
        "title": "S2O: Static to Openable Enhancement for Articulated 3D Objects",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite much progress in large 3D datasets there are currently few interactive 3D object datasets, and their scale is limited due to the manual effort required in their construction. We introduce the static to openable (S2O) task which creates interactive articulated 3D objects from static counterparts through openable part detection, motion prediction, and interior geometry completion. We formulate a unified framework to tackle this task, and curate a challenging dataset of openable 3D objects that serves as a test bed for systematic evaluation. Our experiments benchmark methods from prior work and simple yet effective heuristics for the S2O task. We find that turning static 3D objects into interactively openable counterparts is possible but that all methods struggle to generalize to realistic settings of the task, and we highlight promising future work directions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18932",
        "abstract url": "https://arxiv.org/abs/2409.18932",
        "title": "ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Images captured in challenging environments--such as nighttime, foggy, rainy weather, and underwater--often suffer from significant degradation, resulting in a substantial loss of visual quality. Effective restoration of these degraded images is critical for the subsequent vision tasks. While many existing approaches have successfully incorporated specific priors for individual tasks, these tailored solutions limit their applicability to other degradations. In this work, we propose a universal network architecture, dubbed \"ReviveDiff\", which can address a wide range of degradations and bring images back to life by enhancing and restoring their quality. Our approach is inspired by the observation that, unlike degradation caused by movement or electronic issues, quality degradation under adverse conditions primarily stems from natural media (such as fog, water, and low luminance), which generally preserves the original structures of objects. To restore the quality of such images, we leveraged the latest advancements in diffusion models and developed ReviveDiff to restore image quality from both macro and micro levels across some key factors determining image quality, such as sharpness, distortion, noise level, dynamic range, and color accuracy. We rigorously evaluated ReviveDiff on seven benchmark datasets covering five types of degrading conditions: Rainy, Underwater, Low-light, Smoke, and Nighttime Hazy. Our experimental results demonstrate that ReviveDiff outperforms the state-of-the-art methods both quantitatively and visually.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19039",
        "abstract url": "https://arxiv.org/abs/2409.19039",
        "title": "Gaussian Heritage: 3D Digitization of Cultural Heritage with Integrated Object Segmentation",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The creation of digital replicas of physical objects has valuable applications for the preservation and dissemination of tangible cultural heritage. However, existing methods are often slow, expensive, and require expert knowledge. We propose a pipeline to generate a 3D replica of a scene using only RGB images (e.g. photos of a museum) and then extract a model for each item of interest (e.g. pieces in the exhibit). We do this by leveraging the advancements in novel view synthesis and Gaussian Splatting, modified to enable efficient 3D segmentation. This approach does not need manual annotation, and the visual inputs can be captured using a standard smartphone, making it both affordable and easy to deploy. We provide an overview of the method and baseline evaluation of the accuracy of object segmentation. The code is available at https://mahtaabdn.github.io/gaussian_heritage.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19128",
        "abstract url": "https://arxiv.org/abs/2409.19128",
        "title": "Pruning then Reweighting: Towards Data-Efficient Training of Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite the remarkable generation capabilities of Diffusion Models (DMs), conducting training and inference remains computationally expensive. Previous works have been devoted to accelerating diffusion sampling, but achieving data-efficient diffusion training has often been overlooked. In this work, we investigate efficient diffusion training from the perspective of dataset pruning. Inspired by the principles of data-efficient training for generative models such as generative adversarial networks (GANs), we first extend the data selection scheme used in GANs to DM training, where data features are encoded by a surrogate model, and a score criterion is then applied to select the coreset. To further improve the generation performance, we employ a class-wise reweighting approach, which derives class weights through distributionally robust optimization (DRO) over a pre-trained reference DM. For a pixel-wise DM (DDPM) on CIFAR-10, experiments demonstrate the superiority of our methodology over existing approaches and its effectiveness in image synthesis comparable to that of the original full-data model while achieving the speed-up between 2.34 times and 8.32 times. Additionally, our method could be generalized to latent DMs (LDMs), e.g., Masked Diffusion Transformer (MDT) and Stable Diffusion (SD), and achieves competitive generation capability on ImageNet.Code is available here (https://github.com/Yeez-lee/Data-Selection-and-Reweighting-for-Diffusion-Models).",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under Review. Code is available here (https://github.com/Yeez-lee/Data-Selection-and-Reweighting-for-Diffusion-Models)"
    },
    {
        "paper id": "2409.19149",
        "abstract url": "https://arxiv.org/abs/2409.19149",
        "title": "Multimodal Pragmatic Jailbreak on Text-to-image Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-image"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have recently achieved remarkable advancements in terms of image quality and fidelity to textual prompts. Concurrently, the safety of such generative models has become an area of growing concern. This work introduces a novel type of jailbreak, which triggers T2I models to generate the image with visual text, where the image and the text, although considered to be safe in isolation, combine to form unsafe content. To systematically explore this phenomenon, we propose a dataset to evaluate the current diffusion-based text-to-image (T2I) models under such jailbreak. We benchmark nine representative T2I models, including two close-source commercial models. Experimental results reveal a concerning tendency to produce unsafe content: all tested models suffer from such type of jailbreak, with rates of unsafe generation ranging from 8\\% to 74\\%. In real-world scenarios, various filters such as keyword blocklists, customized prompt filters, and NSFW image filters, are commonly employed to mitigate these risks. We evaluate the effectiveness of such filters against our jailbreak and found that, while current classifiers may be effective for single modality detection, they fail to work against our jailbreak. Our work provides a foundation for further development towards more secure and reliable T2I models.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19152",
        "abstract url": "https://arxiv.org/abs/2409.19152",
        "title": "MASt3R-SfM: a Fully-Integrated Solution for Unconstrained Structure-from-Motion",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Structure-from-Motion (SfM), a task aiming at jointly recovering camera poses and 3D geometry of a scene given a set of images, remains a hard problem with still many open challenges despite decades of significant progress. The traditional solution for SfM consists of a complex pipeline of minimal solvers which tends to propagate errors and fails when images do not sufficiently overlap, have too little motion, etc. Recent methods have attempted to revisit this paradigm, but we empirically show that they fall short of fixing these core issues. In this paper, we propose instead to build upon a recently released foundation model for 3D vision that can robustly produce local 3D reconstructions and accurate matches. We introduce a low-memory approach to accurately align these local reconstructions in a global coordinate system. We further show that such foundation models can serve as efficient image retrievers without any overhead, reducing the overall complexity from quadratic to linear. Overall, our novel SfM pipeline is simple, scalable, fast and truly unconstrained, i.e. it can handle any collection of images, ordered or not. Extensive experiments on multiple benchmarks show that our method provides steady performance across diverse settings, especially outperforming existing methods in small- and medium-scale settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19178",
        "abstract url": "https://arxiv.org/abs/2409.19178",
        "title": "FLINT: Learning-based Flow Estimation and Temporal Interpolation for Scientific Ensemble Visualization",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present FLINT (learning-based FLow estimation and temporal INTerpolation), a novel deep learning-based approach to estimate flow fields for 2D+time and 3D+time scientific ensemble data. FLINT can flexibly handle different types of scenarios with (1) a flow field being partially available for some members (e.g., omitted due to space constraints) or (2) no flow field being available at all (e.g., because it could not be acquired during an experiment). The design of our architecture allows to flexibly cater to both cases simply by adapting our modular loss functions, effectively treating the different scenarios as flow-supervised and flow-unsupervised problems, respectively (with respect to the presence or absence of ground-truth flow). To the best of our knowledge, FLINT is the first approach to perform flow estimation from scientific ensembles, generating a corresponding flow field for each discrete timestep, even in the absence of original flow information. Additionally, FLINT produces high-quality temporal interpolants between scalar fields. FLINT employs several neural blocks, each featuring several convolutional and deconvolutional layers. We demonstrate performance and accuracy for different usage scenarios with scientific ensembles from both simulations and experiments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages (with Appendix), 17 figures"
    },
    {
        "paper id": "2409.19215",
        "abstract url": "https://arxiv.org/abs/2409.19215",
        "title": "1st Place Solution to the 8th HANDS Workshop Challenge -- ARCTIC Track: 3DGS-based Bimanual Category-agnostic Interaction Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This report describes our 1st place solution to the 8th HANDS workshop challenge (ARCTIC track) in conjunction with ECCV 2024. In this challenge, we address the task of bimanual category-agnostic hand-object interaction reconstruction, which aims to generate 3D reconstructions of both hands and the object from a monocular video, without relying on predefined templates. This task is particularly challenging due to the significant occlusion and dynamic contact between the hands and the object during bimanual manipulation. We worked to resolve these issues by introducing a mask loss and a 3D contact loss, respectively. Moreover, we applied 3D Gaussian Splatting (3DGS) to this task. As a result, our method achieved a value of 38.69 in the main metric, CD$_h$, on the ARCTIC test set.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19220",
        "abstract url": "https://arxiv.org/abs/2409.19220",
        "title": "Extending Depth of Field for Varifocal Multiview Images",
        "rating": "0",
        "keywords": [
            [
                "Depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Optical imaging systems are generally limited by the depth of field because of the nature of the optics. Therefore, extending depth of field (EDoF) is a fundamental task for meeting the requirements of emerging visual applications. To solve this task, the common practice is using multi-focus images from a single viewpoint. This method can obtain acceptable quality of EDoF under the condition of fixed field of view, but it is only applicable to static scenes and the field of view is limited and fixed. An emerging data type, varifocal multiview images have the potential to become a new paradigm for solving the EDoF, because the data contains more field of view information than multi-focus images. To realize EDoF of varifocal multiview images, we propose an end-to-end method for the EDoF, including image alignment, image optimization and image fusion. Experimental results demonstrate the efficiency of the proposed method.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19228",
        "abstract url": "https://arxiv.org/abs/2409.19228",
        "title": "GS-EVT: Cross-Modal Event Camera Tracking based on Gaussian Splatting",
        "rating": "0",
        "keywords": [
            [
                "Gaussian Splatting",
                "Event Camera"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reliable self-localization is a foundational skill for many intelligent mobile platforms. This paper explores the use of event cameras for motion tracking thereby providing a solution with inherent robustness under difficult dynamics and illumination. In order to circumvent the challenge of event camera-based mapping, the solution is framed in a cross-modal way. It tracks a map representation that comes directly from frame-based cameras. Specifically, the proposed method operates on top of gaussian splatting, a state-of-the-art representation that permits highly efficient and realistic novel view synthesis. The key of our approach consists of a novel pose parametrization that uses a reference pose plus first order dynamics for local differential image rendering. The latter is then compared against images of integrated events in a staggered coarse-to-fine optimization scheme. As demonstrated by our results, the realistic view rendering ability of gaussian splatting leads to stable and accurate tracking across a variety of both publicly available and newly recorded data sequences.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18481",
        "abstract url": "https://arxiv.org/abs/2409.18481",
        "title": "Deep Heterogeneous Contrastive Hyper-Graph Learning for In-the-Wild Context-Aware Human Activity Recognition",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Human Activity Recognition (HAR) is a challenging, multi-label classification problem as activities may co-occur and sensor signals corresponding to the same activity may vary in different contexts (e.g., different device placements). This paper proposes a Deep Heterogeneous Contrastive Hyper-Graph Learning (DHC-HGL) framework that captures heterogenous Context-Aware HAR (CA-HAR) hypergraph properties in a message-passing and neighborhood-aggregation fashion. Prior work only explored homogeneous or shallow-node-heterogeneous graphs. DHC-HGL handles heterogeneous CA-HAR data by innovatively 1) Constructing three different types of sub-hypergraphs that are each passed through different custom HyperGraph Convolution (HGC) layers designed to handle edge-heterogeneity and 2) Adopting a contrastive loss function to ensure node-heterogeneity. In rigorous evaluation on two CA-HAR datasets, DHC-HGL significantly outperformed state-of-the-art baselines by 5.8% to 16.7% on Matthews Correlation Coefficient (MCC) and 3.0% to 8.4% on Macro F1 scores. UMAP visualizations of learned CA-HAR node embeddings are also presented to enhance model explainability.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "IMWUT 2023"
    },
    {
        "paper id": "2409.18545",
        "abstract url": "https://arxiv.org/abs/2409.18545",
        "title": "An Epistemic Human-Aware Task Planner which Anticipates Human Beliefs and Decisions",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present a substantial extension of our Human-Aware Task Planning framework, tailored for scenarios with intermittent shared execution experiences and significant belief divergence between humans and robots, particularly due to the uncontrollable nature of humans. Our objective is to build a robot policy that accounts for uncontrollable human behaviors, thus enabling the anticipation of possible advancements achieved by the robot when the execution is not shared, e.g. when humans are briefly absent from the shared environment to complete a subtask. But, this anticipation is considered from the perspective of humans who have access to an estimated model for the robot. To this end, we propose a novel planning framework and build a solver based on AND-OR search, which integrates knowledge reasoning, including situation assessment by perspective taking. Our approach dynamically models and manages the expansion and contraction of potential advances while precisely keeping track of when (and when not) agents share the task execution experience. The planner systematically assesses the situation and ignores worlds that it has reason to think are impossible for humans. Overall, our new solver can estimate the distinct beliefs of the human and the robot along potential courses of action, enabling the synthesis of plans where the robot selects the right moment for communication, i.e. informing, or replying to an inquiry, or defers ontic actions until the execution experiences can be shared. Preliminary experiments in two domains, one novel and one adapted, demonstrate the effectiveness of the framework.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "15 pages, 4 figures, 1 table"
    },
    {
        "paper id": "2409.18578",
        "abstract url": "https://arxiv.org/abs/2409.18578",
        "title": "An Enhanced Federated Prototype Learning Method under Domain Shift",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) allows collaborative machine learning training without sharing private data. Numerous studies have shown that one significant factor affecting the performance of federated learning models is the heterogeneity of data across different clients, especially when the data is sampled from various domains. A recent paper introduces variance-aware dual-level prototype clustering and uses a novel $\u03b1$-sparsity prototype loss, which increases intra-class similarity and reduces inter-class similarity. To ensure that the features converge within specific clusters, we introduce an improved algorithm, Federated Prototype Learning with Convergent Clusters, abbreviated as FedPLCC. To increase inter-class distances, we weight each prototype with the size of the cluster it represents. To reduce intra-class distances, considering that prototypes with larger distances might come from different domains, we select only a certain proportion of prototypes for the loss function calculation. Evaluations on the Digit-5, Office-10, and DomainNet datasets show that our method performs better than existing approaches.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2409.18582",
        "abstract url": "https://arxiv.org/abs/2409.18582",
        "title": "Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design",
        "rating": "-0.5",
        "keywords": [
            [
                "architecture search"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian optimization (BO) is a powerful framework to optimize black-box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over large $\\textit{combinatorial and unstructured}$ spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function over these domains. To address this issue, we propose $\\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO. $\\textbf{GameOpt}$ establishes a cooperative game between the different optimization variables, and selects points that are game $\\textit{equilibria}$ of an upper confidence bound acquisition function. These are stable configurations from which no variable has an incentive to deviate$-$ analog to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making $\\textbf{GameOpt}$ scalable to large combinatorial spaces. We demonstrate the application of $\\textbf{GameOpt}$ to the challenging $\\textit{protein design}$ problem and validate its performance on four real-world protein datasets. Each protein can take up to $20^{X}$ possible configurations, where $X$ is the length of a protein, making standard BO methods infeasible. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18586",
        "abstract url": "https://arxiv.org/abs/2409.18586",
        "title": "Analysis of Truncated Singular Value Decomposition for Koopman Operator-Based Lane Change Model",
        "rating": "-0.5",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Understanding and modeling complex dynamic systems is crucial for enhancing vehicle performance and safety, especially in the context of autonomous driving. Recently, popular methods such as Koopman operators and their approximators, known as Extended Dynamic Mode Decomposition (EDMD), have emerged for their effectiveness in transforming strongly nonlinear system behavior into linear representations. This allows them to be integrated with conventional linear controllers. To achieve this, Singular Value Decomposition (SVD), specifically truncated SVD, is employed to approximate Koopman operators from extensive datasets efficiently. This study evaluates different basis functions used in EDMD and ranks for truncated SVD for representing lane change behavior models, aiming to balance computational efficiency with information loss. The findings, however, suggest that the technique of truncated SVD does not necessarily achieve substantial reductions in computational training time and results in significant information loss.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Submitted to the 21st International Conference on Informatics in Control, Automation and Robotics (ICINCO 2024)"
    },
    {
        "paper id": "2409.18591",
        "abstract url": "https://arxiv.org/abs/2409.18591",
        "title": "Off to new Shores: A Dataset & Benchmark for (near-)coastal Flood Inundation Forecasting",
        "rating": "-0.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Floods are among the most common and devastating natural hazards, imposing immense costs on our society and economy due to their disastrous consequences. Recent progress in weather prediction and spaceborne flood mapping demonstrated the feasibility of anticipating extreme events and reliably detecting their catastrophic effects afterwards. However, these efforts are rarely linked to one another and there is a critical lack of datasets and benchmarks to enable the direct forecasting of flood extent. To resolve this issue, we curate a novel dataset enabling a timely prediction of flood extent. Furthermore, we provide a representative evaluation of state-of-the-art methods, structured into two benchmark tracks for forecasting flood inundation maps i) in general and ii) focused on coastal regions. Altogether, our dataset and benchmark provide a comprehensive platform for evaluating flood forecasts, enabling future solutions for this critical challenge. Data, code & models are shared at https://github.com/Multihuntr/GFF under a CC0 license.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at NeurIPS 2024 Datasets & Benchmarks"
    },
    {
        "paper id": "2409.18622",
        "abstract url": "https://arxiv.org/abs/2409.18622",
        "title": "Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech",
        "rating": "-0.5",
        "keywords": [
            [
                "Text-to-Speech"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "The difficulty of acquiring abundant, high-quality data, especially in multi-lingual contexts, has sparked interest in addressing low-resource scenarios. Moreover, current literature rely on fixed expressions from language IDs, which results in the inadequate learning of language representations, and the failure to generate speech in unseen languages. To address these challenges, we propose a novel method that directly extracts linguistic features from audio input while effectively filtering out miscellaneous acoustic information including speaker-specific attributes like timbre. Subjective and objective evaluations affirm the effectiveness of our approach for multi-lingual text-to-speech, and highlight its superiority in low-resource transfer learning for previously unseen language.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "EMNLP 2024 Findings"
    },
    {
        "paper id": "2409.18626",
        "abstract url": "https://arxiv.org/abs/2409.18626",
        "title": "Refutation of Spectral Graph Theory Conjectures with Search Algorithms)",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We are interested in the automatic refutation of spectral graph theory conjectures. Most existing works address this problem either with the exhaustive generation of graphs with a limited size or with deep reinforcement learning. Exhaustive generation is limited by the size of the generated graphs and deep reinforcement learning takes hours or days to refute a conjecture. We propose to use search algorithms to address these shortcomings to find potentially large counter-examples to spectral graph theory conjectures in seconds. We apply a wide range of search algorithms to a selection of conjectures from Graffiti. Out of 13 already refuted conjectures from Graffiti, our algorithms are able to refute 12 in seconds. We also refute conjecture 197 from Graffiti which was open until now.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18704",
        "abstract url": "https://arxiv.org/abs/2409.18704",
        "title": "Semantic Model Component Implementation for Model-driven Semantic Communications",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The key feature of model-driven semantic communication is the propagation of the model. The semantic model component (SMC) is designed to drive the intelligent model to transmit in the physical channel, allowing the intelligence to flow through the networks. According to the characteristics of neural networks with common and individual model parameters, this paper designs the cross-source-domain and cross-task semantic component model. Considering that the basic model is deployed on the edge node, the large server node updates the edge node by transmitting only the semantic component model to the edge node so that the edge node can handle different sources and different tasks. In addition, this paper also discusses how channel noise affects the performance of the model and proposes methods of injection noise and regularization to improve the noise resistance of the model. Experiments show that SMCs use smaller model parameters to achieve cross-source, cross-task functionality while maintaining performance and improving the model's tolerance to noise. Finally, a component transfer-based unmanned vehicle tracking prototype was implemented to verify the feasibility of model components in practical applications.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18743",
        "abstract url": "https://arxiv.org/abs/2409.18743",
        "title": "OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph",
        "rating": "-0.5",
        "keywords": [
            [
                "visual-language"
            ],
            [
                "robot",
                "Navigation"
            ],
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In everyday life, frequently used objects like cups often have unfixed positions and multiple instances within the same category, and their carriers frequently change as well. As a result, it becomes challenging for a robot to efficiently navigate to a specific instance. To tackle this challenge, the robot must capture and update scene changes and plans continuously. However, current object navigation approaches primarily focus on semantic-level and lack the ability to dynamically update scene representation. This paper captures the relationships between frequently used objects and their static carriers. It constructs an open-vocabulary Carrier-Relationship Scene Graph (CRSG) and updates the carrying status during robot navigation to reflect the dynamic changes of the scene. Based on the CRSG, we further propose an instance navigation strategy that models the navigation process as a Markov Decision Process. At each step, decisions are informed by Large Language Model's commonsense knowledge and visual-language feature similarity. We designed a series of long-sequence navigation tasks for frequently used everyday items in the Habitat simulator. The results demonstrate that by updating the CRSG, the robot can efficiently navigate to moved targets. Additionally, we deployed our algorithm on a real robot and validated its practical effectiveness.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "Project website: https://openobject-nav.github.io/"
    },
    {
        "paper id": "2409.18749",
        "abstract url": "https://arxiv.org/abs/2409.18749",
        "title": "TensorSocket: Shared Data Loading for Deep Learning Training",
        "rating": "-0.5",
        "keywords": [
            [
                "architecture search"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training deep learning models is a repetitive and resource-intensive process. Data scientists often train several models before landing on set of parameters (e.g., hyper-parameter tuning), model architecture (e.g., neural architecture search), among other things that yields the highest accuracy. The computational efficiency of these training tasks depends highly on how well we can supply the training process with training data. The repetitive nature of these tasks results in the same data processing pipelines running over and over exacerbating the need for and costs of computational resources. In this paper, we present Tensorsocket to reduce the computational needs of deep learning training by enabling simultaneous training processes to share the same data loader. Tensorsocket mitigates CPU-side bottlenecks in cases where the collocated training workloads have high throughput on GPU, but are held back by lower data-loading throughput on CPU. Tensorsocket achieves this by reducing redundant computations across collocated training processes and leveraging modern GPU-GPU interconnects. We demonstrate the hardware- and pipeline-agnostic nature of Tensorsocket and evaluate it using a variety of training scenarios. Our evaluation shows that Tensorsocket enables scenarios that are infeasible without data sharing, increases training throughput by up to $100\\%$, and when utilizing cloud instances, Tensorsocket achieves cost savings of $50\\%$ by reducing the hardware resource needs on the CPU side. Furthermore, Tensorsocket outperforms the state-of-the-art solutions for shared data loading such as CoorDL and Joader. It is easier to use, maintain, and deploy, and either achieves higher or matches the throughput of other solutions while requiring less CPU resources.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18796",
        "abstract url": "https://arxiv.org/abs/2409.18796",
        "title": "Hierarchical Federated ADMM",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we depart from the widely-used gradient descent-based hierarchical federated learning (FL) algorithms to develop a novel hierarchical FL framework based on the alternating direction method of multipliers (ADMM). Within this framework, we propose two novel FL algorithms, which both use ADMM in the top layer: one that employs ADMM in the lower layer and another that uses the conventional gradient descent-based approach. The proposed framework enhances privacy, and experiments demonstrate the superiority of the proposed algorithms compared to the conventional algorithms in terms of learning convergence and accuracy. Additionally, gradient descent on the lower layer performs well even if the number of local steps is very limited, while ADMM on both layers lead to better performance otherwise.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC",
            "cs.IT",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18804",
        "abstract url": "https://arxiv.org/abs/2409.18804",
        "title": "Convergence of Diffusion Models Under the Manifold Hypothesis in High-Dimensions",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Denoising Diffusion Probabilistic Models (DDPM) are powerful state-of-the-art methods used to generate synthetic data from high-dimensional data distributions and are widely used for image, audio and video generation as well as many more applications in science and beyond. The manifold hypothesis states that high-dimensional data often lie on lower-dimensional manifolds within the ambient space, and is widely believed to hold in provided examples. While recent results has provided invaluable insight into how diffusion models adapt to the manifold hypothesis, they do not capture the great empirical success of these models, making this a very fruitful research direction. In this work, we study DDPMs under the manifold hypothesis and prove that they achieve rates independent of the ambient dimension in terms of learning the score. In terms of sampling, we obtain rates independent of the ambient dimension w.r.t. the Kullback-Leibler divergence, and $O(\\sqrt{D})$ w.r.t. the Wasserstein distance. We do this by developing a new framework connecting diffusion models to the well-studied theory of extrema of Gaussian Processes.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18847",
        "abstract url": "https://arxiv.org/abs/2409.18847",
        "title": "Text2FX: Harnessing CLAP Embeddings for Text-Guided Audio Effects",
        "rating": "-0.5",
        "keywords": [
            [
                "text to audio"
            ],
            [
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "This work introduces Text2FX, a method that leverages CLAP embeddings and differentiable digital signal processing to control audio effects, such as equalization and reverberation, using open-vocabulary natural language prompts (e.g., \"make this sound in-your-face and bold\"). Text2FX operates without retraining any models, relying instead on single-instance optimization within the existing embedding space. We show that CLAP encodes valuable information for controlling audio effects and propose two optimization approaches using CLAP to map text to audio effect parameters. While we demonstrate with CLAP, this approach is applicable to any shared text-audio embedding space. Similarly, while we demonstrate with equalization and reverberation, any differentiable audio effect may be controlled. We conduct a listener study with diverse text prompts and source audio to evaluate the quality and alignment of these methods with human perception.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2409.18859",
        "abstract url": "https://arxiv.org/abs/2409.18859",
        "title": "Challenges of Generating Structurally Diverse Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "For many graph-related problems, it can be essential to have a set of structurally diverse graphs. For instance, such graphs can be used for testing graph algorithms or their neural approximations. However, to the best of our knowledge, the problem of generating structurally diverse graphs has not been explored in the literature. In this paper, we fill this gap. First, we discuss how to define diversity for a set of graphs, why this task is non-trivial, and how one can choose a proper diversity measure. Then, for a given diversity measure, we propose and compare several algorithms optimizing it: we consider approaches based on standard random graph models, local graph optimization, genetic algorithms, and neural generative models. We show that it is possible to significantly improve diversity over basic random graph generators. Additionally, our analysis of generated graphs allows us to better understand the properties of graph distances: depending on which diversity measure is used for optimization, the obtained graphs may possess very different structural properties which gives insights about the sensitivity of the graph distance underlying the diversity measure.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18915",
        "abstract url": "https://arxiv.org/abs/2409.18915",
        "title": "A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As a popular paradigm for juggling data privacy and collaborative training, federated learning (FL) is flourishing to distributively process the large scale of heterogeneous datasets on edged clients. Due to bandwidth limitations and security considerations, it ingeniously splits the original problem into multiple subproblems to be solved in parallel, which empowers primal dual solutions to great application values in FL. In this paper, we review the recent development of classical federated primal dual methods and point out a serious common defect of such methods in non-convex scenarios, which we say is a \"dual drift\" caused by dual hysteresis of those longstanding inactive clients under partial participation training. To further address this problem, we propose a novel Aligned Federated Primal Dual (A-FedPD) method, which constructs virtual dual updates to align global consensus and local dual variables for those protracted unparticipated local clients. Meanwhile, we provide a comprehensive analysis of the optimization and generalization efficiency for the A-FedPD method on smooth non-convex objectives, which confirms its high efficiency and practicality. Extensive experiments are conducted on several classical FL setups to validate the effectiveness of our proposed method.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18959",
        "abstract url": "https://arxiv.org/abs/2409.18959",
        "title": "$O(d/T)$ Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Score-based diffusion models, which generate new data by learning to reverse a diffusion process that perturbs data from the target distribution into noise, have achieved remarkable success across various generative tasks. Despite their superior empirical performance, existing theoretical guarantees are often constrained by stringent assumptions or suboptimal convergence rates. In this paper, we establish a fast convergence theory for a popular SDE-based sampler under minimal assumptions. Our analysis shows that, provided $\\ell_{2}$-accurate estimates of the score functions, the total variation distance between the target and generated distributions is upper bounded by $O(d/T)$ (ignoring logarithmic factors), where $d$ is the data dimensionality and $T$ is the number of steps. This result holds for any target distribution with finite first-order moment. To our knowledge, this improves upon existing convergence theory for both the SDE-based sampler and another ODE-based sampler, while imposing minimal assumptions on the target data distribution and score estimates. This is achieved through a novel set of analytical tools that provides a fine-grained characterization of how the error propagates at each step of the reverse process.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19038",
        "abstract url": "https://arxiv.org/abs/2409.19038",
        "title": "Intention-aware policy graphs: answering what, how, and why in opaque agents",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Agents are a special kind of AI-based software in that they interact in complex environments and have increased potential for emergent behaviour. Explaining such emergent behaviour is key to deploying trustworthy AI, but the increasing complexity and opaque nature of many agent implementations makes this hard. In this work, we propose a Probabilistic Graphical Model along with a pipeline for designing such model -- by which the behaviour of an agent can be deliberated about -- and for computing a robust numerical value for the intentions the agent has at any moment. We contribute measurements that evaluate the interpretability and reliability of explanations provided, and enables explainability questions such as `what do you want to do now?' (e.g. deliver soup) `how do you plan to do it?' (e.g. returning a plan that considers its skills and the world), and `why would you take this action at this state?' (e.g. explaining how that furthers or hinders its own goals). This model can be constructed by taking partial observations of the agent's actions and world states, and we provide an iterative workflow for increasing the proposed measurements through better design and/or pointing out irrational agent behaviour.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ],
        "comment": "57 pages, 8 figures, 5 tables"
    },
    {
        "paper id": "2409.19060",
        "abstract url": "https://arxiv.org/abs/2409.19060",
        "title": "CURATE: Scaling-up Differentially Private Causal Graph Discovery",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causal Graph Discovery (CGD) is the process of estimating the underlying probabilistic graphical model that represents joint distribution of features of a dataset. CGD-algorithms are broadly classified into two categories: (i) Constraint-based algorithms (outcome depends on conditional independence (CI) tests), (ii) Score-based algorithms (outcome depends on optimized score-function). Since, sensitive features of observational data is prone to privacy-leakage, Differential Privacy (DP) has been adopted to ensure user privacy in CGD. Adding same amount of noise in this sequential-natured estimation process affects the predictive performance of the algorithms. As initial CI tests in constraint-based algorithms and later iterations of the optimization process of score-based algorithms are crucial, they need to be more accurate, less noisy. Based on this key observation, we present CURATE (CaUsal gRaph AdapTivE privacy), a DP-CGD framework with adaptive privacy budgeting. In contrast to existing DP-CGD algorithms with uniform privacy budgeting across all iterations, CURATE allows adaptive privacy budgeting by minimizing error probability (for constraint-based), maximizing iterations of the optimization problem (for score-based) while keeping the cumulative leakage bounded. To validate our framework, we present a comprehensive set of experiments on several datasets and show that CURATE achieves higher utility compared to existing DP-CGD algorithms with less privacy-leakage.",
        "subjects": [
            "cs.CR",
            "cs.IT",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19117",
        "abstract url": "https://arxiv.org/abs/2409.19117",
        "title": "Range-aware Positional Encoding via High-order Pretraining: Theory and Practice",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Unsupervised pre-training on vast amounts of graph data is critical in real-world applications wherein labeled data is limited, such as molecule properties prediction or materials science. Existing approaches pre-train models for specific graph domains, neglecting the inherent connections within networks. This limits their ability to transfer knowledge to various supervised tasks. In this work, we propose a novel pre-training strategy on graphs that focuses on modeling their multi-resolution structural information, allowing us to capture global information of the whole graph while preserving local structures around its nodes. We extend the work of Wave}let Positional Encoding (WavePE) from (Ngo et al., 2023) by pretraining a High-Order Permutation-Equivariant Autoencoder (HOPE-WavePE) to reconstruct node connectivities from their multi-resolution wavelet signals. Unlike existing positional encodings, our method is designed to become sensitivity to the input graph size in downstream tasks, which efficiently capture global structure on graphs. Since our approach relies solely on the graph structure, it is also domain-agnostic and adaptable to datasets from various domains, therefore paving the wave for developing general graph structure encoders and graph foundation models. We theoretically demonstrate that there exists a parametrization of such architecture that it can predict the output adjacency up to arbitrarily low error. We also evaluate HOPE-WavePE on graph-level prediction tasks of different areas and show its superiority compared to other methods.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19234",
        "abstract url": "https://arxiv.org/abs/2409.19234",
        "title": "Decoding Android Malware with a Fraction of Features: An Attention-Enhanced MLP-SVM Approach",
        "rating": "-0.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The escalating sophistication of Android malware poses significant challenges to traditional detection methods, necessitating innovative approaches that can efficiently identify and classify threats with high precision. This paper introduces a novel framework that synergistically integrates an attention-enhanced Multi-Layer Perceptron (MLP) with a Support Vector Machine (SVM) to make Android malware detection and classification more effective. By carefully analyzing a mere 47 features out of over 9,760 available in the comprehensive CCCS-CIC-AndMal-2020 dataset, our MLP-SVM model achieves an impressive accuracy over 99% in identifying malicious applications. The MLP, enhanced with an attention mechanism, focuses on the most discriminative features and further reduces the 47 features to only 14 components using Linear Discriminant Analysis (LDA). Despite this significant reduction in dimensionality, the SVM component, equipped with an RBF kernel, excels in mapping these components to a high-dimensional space, facilitating precise classification of malware into their respective families. Rigorous evaluations, encompassing accuracy, precision, recall, and F1-score metrics, confirm the superiority of our approach compared to existing state-of-the-art techniques. The proposed framework not only significantly reduces the computational complexity by leveraging a compact feature set but also exhibits resilience against the evolving Android malware landscape.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "Accepted for NSS-SocialSec 2024, Lecture Notes in Computer Science (LNCS)"
    },
    {
        "paper id": "2409.18449",
        "abstract url": "https://arxiv.org/abs/2409.18449",
        "title": "Towards Personal Data Sharing Autonomy:A Task-driven Data Capsule Sharing System",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Personal data custodian services enable data owners to share their data with data consumers in a convenient manner, anytime and anywhere. However, with data hosted in these services being beyond the control of the data owners, it raises significant concerns about privacy in personal data sharing. Many schemes have been proposed to realize fine-grained access control and privacy protection in data sharing. However, they fail to protect the rights of data owners to their data under the law, since their designs focus on the management of system administrators rather than enhancing the data owners' privacy. In this paper, we introduce a novel task-driven personal data sharing system based on the data capsule paradigm realizing personal data sharing autonomy. It enables data owners in our system to fully control their data, and share it autonomously. Specifically, we present a tamper-resistant data capsule encapsulation method, where the data capsule is the minimal unit for independent and secure personal data storage and sharing. Additionally, to realize selective sharing and informed-consent based authorization, we propose a task-driven data sharing mechanism that is resistant to collusion and EDoS attacks. Furthermore, by updating parts of the data capsules, the permissions granted to data consumers can be immediately revoked. Finally, we conduct a security and performance analysis, proving that our scheme is correct, sound, and secure, as well as revealing more advantageous features in practicality, compared with the state-of-the-art schemes.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18452",
        "abstract url": "https://arxiv.org/abs/2409.18452",
        "title": "Exploiting Physical Human-Robot Interaction to Provide a Unique Rolling Experience with a Riding Ballbot",
        "rating": "-1",
        "keywords": [
            [
                "Robot",
                "navigation"
            ]
        ],
        "abstract": "This study introduces the development of hands-free control schemes for a riding ballbot, designed to allow riders including manual wheelchair users to control its movement through torso leaning and twisting. The hardware platform, Personal Unique Rolling Experience (PURE), utilizes a ballbot drivetrain, a dynamically stable mobile robot that uses a ball as its wheel to provide omnidirectional maneuverability. To accommodate users with varying torso motion functions, the hanads-free control scheme should be adjustable based on the rider's torso function and personal preferences. Therefore, concepts of (a) impedance control and (b) admittance control were integrated into the control scheme. A duo-agent optimization framework was utilized to assess the efficiency of this rider-ballbot system for a safety-critical task: braking from 1.4 m/s. The candidate control schemes were further implemented in the physical robot hardware and validated with two experienced users, demonstrating the efficiency and robustness of the hands-free admittance control scheme (HACS). This interface, which utilized physical human-robot interaction (pHRI) as the input, resulted in lower braking effort and shorter braking distance and time. Subsequently, 12 novice participants (six able-bodied users and six manual wheelchair users) with different levels of torso motion capability were then recruited to benchmark the braking performance with HACS. The indoor navigation capability of PURE was further demonstrated with these participants in courses simulating narrow hallways, tight turns, and navigation through static and dynamic obstacles. By exploiting pHRI, the proposed admittance-style control scheme provided effective control of the ballbot via torso motions. This interface enables PURE to provide a personal unique rolling experience to manual wheelchair users for safe and agile indoor navigation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18454",
        "abstract url": "https://arxiv.org/abs/2409.18454",
        "title": "Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid increase in unstructured data across various fields has made multi-document comprehension and summarization a critical task. Traditional approaches often fail to capture relevant context, maintain logical consistency, and extract essential information from lengthy documents. This paper explores the use of Long-context Large Language Models (LLMs) for multi-document summarization, demonstrating their exceptional capacity to grasp extensive connections, provide cohesive summaries, and adapt to various industry domains and integration with enterprise applications/systems. The paper discusses the workflow of multi-document summarization for effectively deploying long-context LLMs, supported by case studies in legal applications, enterprise functions such as HR, finance, and sourcing, as well as in the medical and news domains. These case studies show notable enhancements in both efficiency and accuracy. Technical obstacles, such as dataset diversity, model scalability, and ethical considerations like bias mitigation and factual accuracy, are carefully analyzed. Prospective research avenues are suggested to augment the functionalities and applications of long-context LLMs, establishing them as pivotal tools for transforming information processing across diverse sectors and enterprise applications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18457",
        "abstract url": "https://arxiv.org/abs/2409.18457",
        "title": "DynaWeightPnP: Toward global real-time 3D-2D solver in PnP without correspondences",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper addresses a special Perspective-n-Point (PnP) problem: estimating the optimal pose to align 3D and 2D shapes in real-time without correspondences, termed as correspondence-free PnP. While several studies have focused on 3D and 2D shape registration, achieving both real-time and accurate performance remains challenging. This study specifically targets the 3D-2D geometric shape registration tasks, applying the recently developed Reproducing Kernel Hilbert Space (RKHS) to address the \"big-to-small\" issue. An iterative reweighted least squares method is employed to solve the RKHS-based formulation efficiently. Moreover, our work identifies a unique and interesting observability issue in correspondence-free PnP: the numerical ambiguity between rotation and translation. To address this, we proposed DynaWeightPnP, introducing a dynamic weighting sub-problem and an alternative searching algorithm designed to enhance pose estimation and alignment accuracy. Experiments were conducted on a typical case, that is, a 3D-2D vascular centerline registration task within Endovascular Image-Guided Interventions (EIGIs). Results demonstrated that the proposed algorithm achieves registration processing rates of 60 Hz (without post-refinement) and 31 Hz (with post-refinement) on modern single-core CPUs, with competitive accuracy comparable to existing methods. These results underscore the suitability of DynaWeightPnP for future robot navigation tasks like EIGIs.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18468",
        "abstract url": "https://arxiv.org/abs/2409.18468",
        "title": "SmartReco: Detecting Read-Only Reentrancy via Fine-Grained Cross-DApp Analysis",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "Despite the increasing popularity of Decentralized Applications (DApps), they are suffering from various vulnerabilities that can be exploited by adversaries for profits. Among such vulnerabilities, Read-Only Reentrancy (called ROR in this paper), is an emerging type of vulnerability that arises from the complex interactions between DApps. In the recent three years, attack incidents of ROR have already caused around 30M USD losses to the DApp ecosystem. Existing techniques for vulnerability detection in smart contracts can hardly detect Read-Only Reentrancy attacks, due to the lack of tracking and analyzing the complex interactions between multiple DApps. In this paper, we propose SmartReco, a new framework for detecting Read-Only Reentrancy vulnerability in DApps through a novel combination of static and dynamic analysis (i.e., fuzzing) over smart contracts. The key design behind SmartReco is threefold: (1) SmartReco identifies the boundary between different DApps from the heavy-coupled cross-contract interactions. (2) SmartReco performs fine-grained static analysis to locate points of interest (i.e., entry functions) that may lead to ROR. (3) SmartReco utilizes the on-chain transaction data and performs multi-function fuzzing (i.e., the entry function and victim function) across different DApps to verify the existence of ROR. Our evaluation of a manual-labeled dataset with 45 RORs shows that SmartReco achieves a precision of 88.63% and a recall of 86.36%. In addition, SmartReco successfully detects 43 new RORs from 123 popular DApps. The total assets affected by such RORs reach around 520,000 USD.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18473",
        "abstract url": "https://arxiv.org/abs/2409.18473",
        "title": "Efficient Top-k s-Biplexes Search over Large Bipartite Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "In a bipartite graph, a subgraph is an $s$-biplex if each vertex of the subgraph is adjacent to all but at most $s$ vertices on the opposite set. The enumeration of $s$-biplexes from a given graph is a fundamental problem in bipartite graph analysis. However, in real-world data engineering, finding all $s$-biplexes is neither necessary nor computationally affordable. A more realistic problem is to identify some of the largest $s$-biplexes from the large input graph. We formulate the problem as the {\\em top-$k$ $s$-biplex search (TBS) problem}, which aims to find the top-$k$ maximal $s$-biplexes with the most vertices, where $k$ is an input parameter. We prove that the TBS problem is NP-hard for any fixed $k\\ge 1$. Then, we propose a branching algorithm, named MVBP, that breaks the simple $2^n$ enumeration algorithm. Furthermore, from a practical perspective, we investigate three techniques to improve the performance of MVBP: 2-hop decomposition, single-side bounds, and progressive search. Complexity analysis shows that the improved algorithm, named FastMVBP, has a running time $O^*(\u03b3_s^{d_2})$, where $\u03b3_s<2$, and $d_2$ is a parameter much smaller than the number of vertex in the sparse real-world graphs, e.g. $d_2$ is only $67$ in the AmazonRatings dataset which has more than $3$ million vertices. Finally, we conducted extensive experiments on eight real-world and synthetic datasets to demonstrate the empirical efficiency of the proposed algorithms. In particular, FastMVBP outperforms the benchmark algorithms by up to three orders of magnitude in several instances.",
        "subjects": [
            "cs.IR",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18486",
        "abstract url": "https://arxiv.org/abs/2409.18486",
        "title": "Evaluation of OpenAI o1: Opportunities and Challenges of AGI",
        "rating": "-1",
        "keywords": [
            [
                "radiology"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This comprehensive study evaluates the performance of OpenAI's o1-preview large language model across a diverse array of complex reasoning tasks, spanning multiple domains, including computer science, mathematics, natural sciences, medicine, linguistics, and social sciences. Through rigorous testing, o1-preview demonstrated remarkable capabilities, often achieving human-level or superior performance in areas ranging from coding challenges to scientific reasoning and from language processing to creative problem-solving. Key findings include: -83.3% success rate in solving complex competitive programming problems, surpassing many human experts. -Superior ability in generating coherent and accurate radiology reports, outperforming other evaluated models. -100% accuracy in high school-level mathematical reasoning tasks, providing detailed step-by-step solutions. -Advanced natural language inference capabilities across general and specialized domains like medicine. -Impressive performance in chip design tasks, outperforming specialized models in areas such as EDA script generation and bug analysis. -Remarkable proficiency in anthropology and geology, demonstrating deep understanding and reasoning in these specialized fields. -Strong capabilities in quantitative investing. O1 has comprehensive financial knowledge and statistical modeling skills. -Effective performance in social media analysis, including sentiment analysis and emotion recognition. The model excelled particularly in tasks requiring intricate reasoning and knowledge integration across various fields. While some limitations were observed, including occasional errors on simpler problems and challenges with certain highly specialized concepts, the overall results indicate significant progress towards artificial general intelligence.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18506",
        "abstract url": "https://arxiv.org/abs/2409.18506",
        "title": "Med-IC: Fusing a Single Layer Involution with Convolutions for Enhanced Medical Image Classification and Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "organ"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The majority of medical images, especially those that resemble cells, have similar characteristics. These images, which occur in a variety of shapes, often show abnormalities in the organ or cell region. The convolution operation possesses a restricted capability to extract visual patterns across several spatial regions of an image. The involution process, which is the inverse operation of convolution, complements this inherent lack of spatial information extraction present in convolutions. In this study, we investigate how applying a single layer of involution prior to a convolutional neural network (CNN) architecture can significantly improve classification and segmentation performance, with a comparatively negligible amount of weight parameters. The study additionally shows how excessive use of involution layers might result in inaccurate predictions in a particular type of medical image. According to our findings from experiments, the strategy of adding only a single involution layer before a CNN-based model outperforms most of the previous works.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "13 pages, 5 figures, 4 tables, preprint submitted to an Elsevier journal"
    },
    {
        "paper id": "2409.18524",
        "abstract url": "https://arxiv.org/abs/2409.18524",
        "title": "Adaptive Knowledge-based Multi-Objective Evolutionary Algorithm for Hybrid Flow Shop Scheduling Problems with Multiple Parallel Batch Processing Stages",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Parallel batch processing machines have extensive applications in the semiconductor manufacturing process. However, the problem models in previous studies regard parallel batch processing as a fixed processing stage in the machining process. This study generalizes the problem model, in which users can arbitrarily set certain stages as parallel batch processing stages according to their needs. A Hybrid Flow Shop Scheduling Problem with Parallel Batch Processing Machines (PBHFSP) is solved in this paper. Furthermore, an Adaptive Knowledge-based Multi-Objective Evolutionary Algorithm (AMOEA/D) is designed to simultaneously optimize both makespan and Total Energy Consumption (TEC). Firstly, a hybrid initialization strategy with heuristic rules based on knowledge of PBHFSP is proposed to generate promising solutions. Secondly, the disjunctive graph model has been established based on the knowledge to find the critical-path of PBHFS. Then, a critical-path based neighborhood search is proposed to enhance the exploitation ability of AMOEA/D. Moreover, the search time is adaptively adjusted based on learning experience from Q-learning and Decay Law. Afterward, to enhance the exploration capability of the algorithm, AMOEA/D designs an improved population updating strategy with a weight vector updating strategy. These strategies rematch individuals with weight vectors, thereby maintaining the diversity of the population. Finally, the proposed algorithm is compared with state-of-the-art algorithms. The experimental results show that the AMOEA/D is superior to the comparison algorithms in solving the PBHFSP.",
        "subjects": [
            "cs.NE",
            "eess.SY"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2409.18531",
        "abstract url": "https://arxiv.org/abs/2409.18531",
        "title": "An Overview of Multi-Object Estimation via Labeled Random Finite Set",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "This article presents the Labeled Random Finite Set (LRFS) framework for multi-object systems-systems in which the number of objects and their states are unknown and vary randomly with time. In particular, we focus on state and trajectory estimation via a multi-object State Space Model (SSM) that admits principled tractable multi-object tracking filters/smoothers. Unlike the single-object counterpart, a time sequence of states does not necessarily represent the trajectory of a multi-object system. The LRFS formulation enables a time sequence of multi-object states to represent the multi-object trajectory that accommodates trajectory crossings and fragmentations. We present the basics of LRFS, covering a suite of commonly used models and mathematical apparatus (including the latest results not published elsewhere). Building on this, we outline the fundamentals of multi-object state space modeling and estimation using LRFS, which formally address object identities/trajectories, ancestries for spawning objects, and characterization of the uncertainty on the ensemble of objects (and their trajectories). Numerical solutions to multi-object SSM problems are inherently far more challenging than those in standard SSM. To bridge the gap between theory and practice, we discuss state-of-the-art implementations that address key computational bottlenecks in the number of objects, measurements, sensors, and scans.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "To appear in IEEE Transactions on Signal Processing"
    },
    {
        "paper id": "2409.18533",
        "abstract url": "https://arxiv.org/abs/2409.18533",
        "title": "Prompt-Driven Temporal Domain Adaptation for Nighttime UAV Tracking",
        "rating": "-1",
        "keywords": [
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Nighttime UAV tracking under low-illuminated scenarios has achieved great progress by domain adaptation (DA). However, previous DA training-based works are deficient in narrowing the discrepancy of temporal contexts for UAV trackers. To address the issue, this work proposes a prompt-driven temporal domain adaptation training framework to fully utilize temporal contexts for challenging nighttime UAV tracking, i.e., TDA. Specifically, the proposed framework aligns the distribution of temporal contexts from daytime and nighttime domains by training the temporal feature generator against the discriminator. The temporal-consistent discriminator progressively extracts shared domain-specific features to generate coherent domain discrimination results in the time series. Additionally, to obtain high-quality training samples, a prompt-driven object miner is employed to precisely locate objects in unannotated nighttime videos. Moreover, a new benchmark for long-term nighttime UAV tracking is constructed. Exhaustive evaluations on both public and self-constructed nighttime benchmarks demonstrate the remarkable performance of the tracker trained in TDA framework, i.e., TDA-Track. Real-world tests at nighttime also show its practicality. The code and demo videos are available at https://github.com/vision4robotics/TDA-Track.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IROS2024"
    },
    {
        "paper id": "2409.18542",
        "abstract url": "https://arxiv.org/abs/2409.18542",
        "title": "MIMII-Gen: Generative Modeling Approach for Simulated Evaluation of Anomalous Sound Detection System",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Insufficient recordings and the scarcity of anomalies present significant challenges in developing and validating robust anomaly detection systems for machine sounds. To address these limitations, we propose a novel approach for generating diverse anomalies in machine sound using a latent diffusion-based model that integrates an encoder-decoder framework. Our method utilizes the Flan-T5 model to encode captions derived from audio file metadata, enabling conditional generation through a carefully designed U-Net architecture. This approach aids our model in generating audio signals within the EnCodec latent space, ensuring high contextual relevance and quality. We objectively evaluated the quality of our generated sounds using the Fr\u00e9chet Audio Distance (FAD) score and other metrics, demonstrating that our approach surpasses existing models in generating reliable machine audio that closely resembles actual abnormal conditions. The evaluation of the anomaly detection system using our generated data revealed a strong correlation, with the area under the curve (AUC) score differing by 4.8\\% from the original, validating the effectiveness of our generated data. These results demonstrate the potential of our approach to enhance the evaluation and robustness of anomaly detection systems across varied and previously unseen conditions. Audio samples can be found at \\url{https://hpworkhub.github.io/MIMII-Gen.github.io/}.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18564",
        "abstract url": "https://arxiv.org/abs/2409.18564",
        "title": "The IEEE-IS2 2024 Music Packet Loss Concealment Challenge",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We present the IEEE-IS2 2024 Music Packet Loss Concealment Challenge. We begin by detailing the challenge rules, followed by an overview of the provided baseline system, the blind test set, and the evaluation methodology used to determine the final ranking. This inaugural edition aimed to foster collaboration between researchers and practitioners from the fields of signal processing, machine learning, and networked music performance, while also laying the groundwork for future advancements in packet loss concealment for music signals.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "8 pages, 4 figures, 3 tables. Official report of the IEEE-IS2 2024 Music Packet Loss Concealment Challenge, part of the 2nd International Workshop on Networked Immersive Audio"
    },
    {
        "paper id": "2409.18585",
        "abstract url": "https://arxiv.org/abs/2409.18585",
        "title": "Unscented Transform-based Pure Pursuit Path-Tracking Algorithm under Uncertainty",
        "rating": "-1",
        "keywords": [
            [
                "Automated driving"
            ]
        ],
        "abstract": "Automated driving has become more and more popular due to its potential to eliminate road accidents by taking over driving tasks from humans. One of the remaining challenges is to follow a planned path autonomously, especially when uncertainties in self-localizing or understanding the surroundings can influence the decisions made by autonomous vehicles, such as calculating how much they need to steer to minimize tracking errors. In this paper, a modified geometric pure pursuit path-tracking algorithm is proposed, taking into consideration such uncertainties using the unscented transform. The algorithm is tested through simulations for typical road geometries, such as straight and circular lines.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Submitted to the 21st International Conference on Informatics in Control, Automation and Robotics (ICINCO 2024)"
    },
    {
        "paper id": "2409.18594",
        "abstract url": "https://arxiv.org/abs/2409.18594",
        "title": "\"Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree\": Zero-Shot Decision Tree Induction and Embedding with Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) provide powerful means to leverage prior knowledge for predictive modeling when data is limited. In this work, we demonstrate how LLMs can use their compressed world knowledge to generate intrinsically interpretable machine learning models, i.e., decision trees, without any training data. We find that these zero-shot decision trees can surpass data-driven trees on some small-sized tabular datasets and that embeddings derived from these trees perform on par with data-driven tree-based embeddings on average. Our knowledge-driven decision tree induction and embedding approaches therefore serve as strong new baselines for data-driven machine learning methods in the low-data regime.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18614",
        "abstract url": "https://arxiv.org/abs/2409.18614",
        "title": "Metasurface-generated large and arbitrary analog convolution kernels for accelerated machine vision",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the rapidly evolving field of artificial intelligence, convolutional neural networks are essential for tackling complex challenges such as machine vision and medical diagnosis. Recently, to address the challenges in processing speed and power consumption of conventional digital convolution operations, many optical components have been suggested to replace the digital convolution layer in the neural network, accelerating various machine vision tasks. Nonetheless, the analog nature of the optical convolution kernel has not been fully explored. Here, we develop a spatial frequency domain training method to create arbitrarily shaped analog convolution kernels using an optical metasurface as the convolution layer, with its receptive field largely surpassing digital convolution kernels. By employing spatial multiplexing, the multiple parallel convolution kernels with both positive and negative weights are generated under the incoherent illumination condition. We experimentally demonstrate a 98.59% classification accuracy on the MNIST dataset, with simulations showing 92.63% and 68.67% accuracy on the Fashion-MNIST and CIFAR-10 datasets with additional digital layers. This work underscores the unique advantage of analog optical convolution, offering a promising avenue to accelerate machine vision tasks, especially in edge devices.",
        "subjects": [
            "physics.optics",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18616",
        "abstract url": "https://arxiv.org/abs/2409.18616",
        "title": "Enhanced Drug Delivery via Localization-Enabled Relaying in Molecular Communication Nanonetworks",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "Intra-body nanonetworks hold promise for advancing targeted drug delivery (TDD) systems through molecular communications (MC). In the baseline MC-TDD system, drug-loaded nanomachines (DgNs) are positioned near the infected tissues to deliver drug molecules directly. To mitigate the decline in drug delivery efficiency caused by diffusion, we propose an enhanced MC-TDD system with a relay network. This network employs a novel localization-enabled relaying mechanism, where a nano-controller broadcasts a localization signal. DgNs then measure the received signal strength against thresholds to determine their clusters relative to the infected tissue. Additionally, our study considers the effect of multiple absorbing DgNs on the channel impulse response (CIR), a factor overlooked in previous works. Our approach improves drug delivery efficiency by $17\\%$ compared to the baseline system. Importantly, we find that optimizing CIR is crucial for enhancing drug delivery efficiency. These findings pave the way for further research into optimizing CIR-based relay selection, as well as investigating the impact of factors such as drug molecule lifespan, obstruction probabilities, and flow dynamics.",
        "subjects": [
            "cs.ET"
        ],
        "comment": "Accepted at ACM NanoCom October 2024"
    },
    {
        "paper id": "2409.18620",
        "abstract url": "https://arxiv.org/abs/2409.18620",
        "title": "Toward Greener Matrix Operations by Lossless Compressed Formats",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Sparse matrix-vector multiplication (SpMV) is a fundamental operation in machine learning, scientific computing, and graph algorithms. In this paper, we investigate the space, time, and energy efficiency of SpMV using various compressed formats for large sparse matrices, focusing specifically on Boolean matrices and real-valued vectors. Through extensive analysis and experiments conducted on server and edge devices, we found that different matrix compression formats offer distinct trade-offs among space usage, execution time, and energy consumption. Notably, by employing the appropriate compressed format, we can reduce energy consumption by an order of magnitude on both server and single-board computers. Furthermore, our experiments indicate that while data parallelism can enhance execution speed and energy efficiency, achieving simultaneous time and energy efficiency presents partially distinct challenges. Specifically, we show that for certain compression schemes, the optimal degree of parallelism for time does not align with that for energy, thereby challenging prevailing assumptions about a straightforward linear correlation between execution time and energy consumption. Our results have significant implications for software engineers in all domains where SpMV operations are prevalent. They also suggest that similar studies exploring the trade-offs between time, space, and energy for other compressed data structures can substantially contribute to designing more energy-efficient software components.",
        "subjects": [
            "cs.DS",
            "cs.PF"
        ],
        "comment": "19 pages, 10 figures,2 tables"
    },
    {
        "paper id": "2409.18628",
        "abstract url": "https://arxiv.org/abs/2409.18628",
        "title": "Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The precision of contouring target structures and organs-at-risk (OAR) in radiotherapy planning is crucial for ensuring treatment efficacy and patient safety. Recent advancements in deep learning (DL) have significantly improved OAR contouring performance, yet the reliability of these models, especially in the presence of out-of-distribution (OOD) scenarios, remains a concern in clinical settings. This application study explores the integration of epistemic uncertainty estimation within the OAR contouring workflow to enable OOD detection in clinically relevant scenarios, using specifically compiled data. Furthermore, we introduce an advanced statistical method for OOD detection to enhance the methodological framework of uncertainty estimation. Our empirical evaluation demonstrates that epistemic uncertainty estimation is effective in identifying instances where model predictions are unreliable and may require an expert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD detection, with a specificity of 0.95 and a sensitivity of 0.92 for implant cases, underscoring its efficacy. This study addresses significant gaps in the current research landscape, such as the lack of ground truth for uncertainty estimation and limited empirical evaluations. Additionally, it provides a clinically relevant application of epistemic uncertainty estimation in an FDA-approved and widely used clinical solution for OAR segmentation from Varian, a Siemens Healthineers company, highlighting its practical benefits.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Keywords: Epistemic Uncertainty - Out-of-Distribution Detection - CT Segmentation - OAR contouring - Radiotherapy"
    },
    {
        "paper id": "2409.18642",
        "abstract url": "https://arxiv.org/abs/2409.18642",
        "title": "Enhanced Convolution Neural Network with Optimized Pooling and Hyperparameter Tuning for Network Intrusion Detection",
        "rating": "-1",
        "keywords": [
            [
                "SVM"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Network Intrusion Detection Systems (NIDS) are essential for protecting computer networks from malicious activities, including Denial of Service (DoS), Probing, User-to-Root (U2R), and Remote-to-Local (R2L) attacks. Without effective NIDS, networks are vulnerable to significant security breaches and data loss. Machine learning techniques provide a promising approach to enhance NIDS by automating threat detection and improving accuracy. In this research, we propose an Enhanced Convolutional Neural Network (EnCNN) for NIDS and evaluate its performance using the KDDCUP'99 dataset. Our methodology includes comprehensive data preprocessing, exploratory data analysis (EDA), and feature engineering. We compare EnCNN with various machine learning algorithms, including Logistic Regression, Decision Trees, Support Vector Machines (SVM), and ensemble methods like Random Forest, AdaBoost, and Voting Ensemble. The results show that EnCNN significantly improves detection accuracy, with a notable 10% increase over state-of-art approaches. This demonstrates the effectiveness of EnCNN in real-time network intrusion detection, offering a robust solution for identifying and mitigating security threats, and enhancing overall network resilience.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "7 Pages , 2 figures , 4 Tables , Conference paper"
    },
    {
        "paper id": "2409.18649",
        "abstract url": "https://arxiv.org/abs/2409.18649",
        "title": "Automatic Gain Tuning for Humanoid Robots Walking Architectures Using Gradient-Free Optimization Techniques",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Developing sophisticated control architectures has endowed robots, particularly humanoid robots, with numerous capabilities. However, tuning these architectures remains a challenging and time-consuming task that requires expert intervention. In this work, we propose a methodology to automatically tune the gains of all layers of a hierarchical control architecture for walking humanoids. We tested our methodology by employing different gradient-free optimization methods: Genetic Algorithm (GA), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), Evolution Strategy (ES), and Differential Evolution (DE). We validated the parameter found both in simulation and on the real ergoCub humanoid robot. Our results show that GA achieves the fastest convergence (10 x 10^3 function evaluations vs 25 x 10^3 needed by the other algorithms) and 100% success rate in completing the task both in simulation and when transferred on the real robotic platform. These findings highlight the potential of our proposed method to automate the tuning process, reducing the need for manual intervention.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18681",
        "abstract url": "https://arxiv.org/abs/2409.18681",
        "title": "Pseudometrics for scalable data-driven comparisons of nonlinear dynamical systems",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Novel solutions for pseudometrics quantifying deviation from topological conjugacy between dynamical systems are presented. Deviation from conjugacy is quantified in a Pareto optimal sense that accounts for spectral properties of Koopman operators as well as trajectory geometry. Theoretical justification is provided for computing such pseudometrics in Koopman eigenfunction space rather than observable space. Furthermore, it is shown deriving the pseudometrics from unitary transformations is sufficient to recover a value of zero if two systems are topologically conjugate. Therefore the pseudometrics for quantifying deviation from conjugacy are based on analytical solutions for unitary transformations in Koopman eigenfunction space. Finally, geometric considerations for the Pareto optimality problem associated with deviation from conjugacy are used to develop pseudometrics that account for all possible solutions given just two Pareto points based on analytical solutions.",
        "subjects": [
            "math.DS",
            "eess.SY",
            "math-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18695",
        "abstract url": "https://arxiv.org/abs/2409.18695",
        "title": "KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic Enhanced Large Model",
        "rating": "-1",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Artificial intelligence is gradually demonstrating its immense potential, and increasing attention is being given to how AI can be harnessed to advance scientific research. In this vision paper, we present our perspectives on how AI can better assist scientific inquiry and explore corresponding technical approach. We have proposed and open-sourced a large model of our KALE-LM model series, Llama3-KALE-LM-Chem-8B, which has achieved outstanding performance in tasks related to the field of chemistry. We hope that our work serves as a strong starting point, helping to realize more intelligent AI and promoting the advancement of human science and technology, as well as societal development.",
        "subjects": [
            "cs.AI",
            "cs.CE",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18715",
        "abstract url": "https://arxiv.org/abs/2409.18715",
        "title": "Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "health",
                "CT",
                "Cancer",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The early detection and nuanced subtype classification of non-small cell lung cancer (NSCLC), a predominant cause of cancer mortality worldwide, is a critical and complex issue. In this paper, we introduce an innovative integration of multi-modal data, synthesizing fused medical imaging (CT and PET scans) with clinical health records and genomic data. This unique fusion methodology leverages advanced machine learning models, notably MedClip and BEiT, for sophisticated image feature extraction, setting a new standard in computational oncology. Our research surpasses existing approaches, as evidenced by a substantial enhancement in NSCLC detection and classification precision. The results showcase notable improvements across key performance metrics, including accuracy, precision, recall, and F1-score. Specifically, our leading multi-modal classifier model records an impressive accuracy of 94.04%. We believe that our approach has the potential to transform NSCLC diagnostics, facilitating earlier detection and more effective treatment planning and, ultimately, leading to superior patient outcomes in lung cancer care.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18730",
        "abstract url": "https://arxiv.org/abs/2409.18730",
        "title": "Effectiveness of learning-based image codecs on fingerprint storage",
        "rating": "-1",
        "keywords": [
            [
                "biometric"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The success of learning-based coding techniques and the development of learning-based image coding standards, such as JPEG-AI, point towards the adoption of such solutions in different fields, including the storage of biometric data, like fingerprints. However, the peculiar nature of learning-based compression artifacts poses several issues concerning their impact and effectiveness on extracting biometric features and landmarks, e.g., minutiae. This problem is utterly stressed by the fact that most models are trained on natural color images, whose characteristics are very different from usual biometric images, e.g, fingerprint or iris pictures. As a matter of fact, these issues are deemed to be accurately questioned and investigated, being such analysis still largely unexplored. This study represents the first investigation about the adaptability of learning-based image codecs in the storage of fingerprint images by measuring its impact on the extraction and characterization of minutiae. Experimental results show that at a fixed rate point, learned solutions considerably outperform previous fingerprint coding standards, like JPEG2000, both in terms of distortion and minutiae preservation. Indeed, experimental results prove that the peculiarities of learned compression artifacts do not prevent automatic fingerprint identification (since minutiae types and locations are not significantly altered), nor do compromise image quality for human visual inspection (as they gain in terms of BD rate and PSNR of 47.8% and +3.97dB respectively).",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted ad Wifs 2024"
    },
    {
        "paper id": "2409.18735",
        "abstract url": "https://arxiv.org/abs/2409.18735",
        "title": "Autoregressive Policy Optimization for Constrained Allocation Tasks",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Allocation tasks represent a class of problems where a limited amount of resources must be allocated to a set of entities at each time step. Prominent examples of this task include portfolio optimization or distributing computational workloads across servers. Allocation tasks are typically bound by linear constraints describing practical requirements that have to be strictly fulfilled at all times. In portfolio optimization, for example, investors may be obligated to allocate less than 30\\% of the funds into a certain industrial sector in any investment period. Such constraints restrict the action space of allowed allocations in intricate ways, which makes learning a policy that avoids constraint violations difficult. In this paper, we propose a new method for constrained allocation tasks based on an autoregressive process to sequentially sample allocations for each entity. In addition, we introduce a novel de-biasing mechanism to counter the initial bias caused by sequential sampling. We demonstrate the superior performance of our approach compared to a variety of Constrained Reinforcement Learning (CRL) methods on three distinct constrained allocation tasks: portfolio optimization, computational workload distribution, and a synthetic allocation benchmark. Our code is available at: https://github.com/niklasdbs/paspo",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at NeurIPS 2024"
    },
    {
        "paper id": "2409.18736",
        "abstract url": "https://arxiv.org/abs/2409.18736",
        "title": "Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Machine learning has brought significant advances in cybersecurity, particularly in the area of intrusion detection systems. This improvements can be mostly attributed to the ability of machine learning algorithms to identify complex relations between features in the data and to generalize well to unseen samples. Deep neural networks in particular contributed to this progress by enabling the analysis of large amounts of training data, significantly enhancing detection performance. However, machine learning models are vulnerable to adversarial attacks: manipulations of input data designed to mislead the models into making incorrect predictions. While much attention has been given to adversarial threats in unstructured data such as text and images, their effectiveness in structured data such as network traffic has not been as thoroughly explored. This survey seeks to fill this gap by providing an critical review of machine learning-based Network Intrusion Detection Systems (NIDS) and a thorough analysis of their vulnerability to adversarial attacks. We critically review existing NIDS research, highlighting key trends, strengths, and limitations, and we identify gaps in understanding that require further exploration. We further discuss emerging challenges and offer insights for developing more robust and resilient NIDS models. In summary, this paper aims to enhance understanding of adversarial attacks and defenses in NIDS and guide future research in improving the robustness of machine learning models in cybersecurity applications.",
        "subjects": [
            "cs.CR",
            "cs.ET",
            "cs.NI"
        ],
        "comment": "35 pages"
    },
    {
        "paper id": "2409.18750",
        "abstract url": "https://arxiv.org/abs/2409.18750",
        "title": "Temporal queries for dynamic temporal forests",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "In a temporal forest each edge has an associated set of time labels that specify the time instants in which the edges are available. A temporal path from vertex $u$ to vertex $v$ in the forest is a selection of a label for each edge in the unique path from $u$ to $v$, assuming it exists, such that the labels selected for any two consecutive edges are non-decreasing. We design linear-size data structures that maintain a temporal forest of rooted trees under addition and deletion of both edge labels and singleton vertices, insertion of root-to-node edges, and removal of edges with no labels. Such data structures can answer temporal reachability, earliest arrival, and latest departure queries. All queries and updates are handled in polylogarithmic worst-case time. Our results can be adapted to deal with latencies. More precisely, all the worst-case time bounds are asymptotically unaffected when latencies are uniform. For arbitrary latencies, the update time becomes amortized in the incremental case where only label additions and edge/singleton insertions are allowed as well as in the decremental case in which only label deletions and edge/singleton removals are allowed. To the best of our knowledge, the only previously known data structure supporting temporal reachability queries is due to Brito, Albertini, Casteigts, and Traven\u00e7olo [Social Network Analysis and Mining, 2021], which can handle general temporal graphs, answers queries in logarithmic time in the worst case, but requires an amortized update time that is quadratic in the number of vertices, up to polylogarithmic factors.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "ISAAC 2024"
    },
    {
        "paper id": "2409.18753",
        "abstract url": "https://arxiv.org/abs/2409.18753",
        "title": "Enhancing Explainability in Multimodal Large Language Models Using Ontological Context",
        "rating": "-1",
        "keywords": [
            [
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, there has been a growing interest in Multimodal Large Language Models (MLLMs) due to their remarkable potential in various tasks integrating different modalities, such as image and text, as well as applications such as image captioning and visual question answering. However, such models still face challenges in accurately captioning and interpreting specific visual concepts and classes, particularly in domain-specific applications. We argue that integrating domain knowledge in the form of an ontology can significantly address these issues. In this work, as a proof of concept, we propose a new framework that combines ontology with MLLMs to classify images of plant diseases. Our method uses concepts about plant diseases from an existing disease ontology to query MLLMs and extract relevant visual concepts from images. Then, we use the reasoning capabilities of the ontology to classify the disease according to the identified concepts. Ensuring that the model accurately uses the concepts describing the disease is crucial in domain-specific applications. By employing an ontology, we can assist in verifying this alignment. Additionally, using the ontology's inference capabilities increases transparency, explainability, and trust in the decision-making process while serving as a judge by checking if the annotations of the concepts by MLLMs are aligned with those in the ontology and displaying the rationales behind their errors. Our framework offers a new direction for synergizing ontologies and MLLMs, supported by an empirical study using different well-known MLLMs.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18769",
        "abstract url": "https://arxiv.org/abs/2409.18769",
        "title": "State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "surgical",
                "surgery",
                "Disease"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Periorbital distances and features around the eyes and lids hold valuable information for disease quantification and monitoring of surgical and medical intervention. These distances are commonly measured manually, a process that is both subjective and highly time-consuming. Here, we set out to developed three deep-learning methods for segmentation and periorbital distance prediction, and also evaluate the utility of periorbital distances for disease classification. The MAE of our deep learning predicted distances was less than or very close to the error observed between trained human annotators. We compared our models to the current state-of-the-art (SOTA) method for periorbital distance prediction and found that our methods outperformed SOTA on all of our datasets on all but one periorbital measurement. We also show that robust segmentation can be achieved on diseased eyes using models trained on open-source, healthy eyes, and that periorbital distances have can be used as high-quality features in downstream classification models. Leveraging segmentation networks as intermediary steps in classification has broad implications for increasing the generalizability of classification models in ophthalmic plastic and craniofacial surgery by avoiding the out-of-distribution problem observed in traditional convolutional neural networks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "16 pages, 4 figures, 4 tables"
    },
    {
        "paper id": "2409.18775",
        "abstract url": "https://arxiv.org/abs/2409.18775",
        "title": "A POMDP-based hierarchical planning framework for manipulation under pose uncertainty",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Robots often face challenges in domestic environments where visual feedback is ineffective, such as retrieving objects obstructed by occlusions or finding a light switch in the dark. In these cases, utilizing contacts to localize the target object can be effective. We propose an online planning framework using binary contact signals for manipulation tasks with pose uncertainty, formulated as a Partially Observable Markov Decision Process (POMDP). Naively representing the belief as a particle set makes planning infeasible due to the large uncertainties in domestic settings, as identifying the best sequence of actions requires rolling out thousands of actions across millions of particles, taking significant compute time. To address this, we propose a hierarchical belief representation. Initially, we represent the uncertainty coarsely in a 3D volumetric space. Policies that refine uncertainty in this space are computed and executed, and once uncertainty is sufficiently reduced, the problem is translated back into the particle space for further refinement before task completion. We utilize a closed-loop planning and execution framework with a heuristic-search-based anytime solver that computes partial policies within a limited time budget. The performance of the framework is demonstrated both in real world and in simulation on the high-precision task of inserting a plug into a port using a UR10e manipulator, resolving positional uncertainties up to 50 centimeters and angular uncertainties close to $2\u03c0$. Experimental results highlight the framework's effectiveness, achieving a 93\\% success rate in the real world and over 50\\% improvement in solution quality compared to greedy baselines, significantly accelerating planning and enabling real-time solutions for complex problems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Under review (2025 IEEE International Conference on Robotics & Automation)"
    },
    {
        "paper id": "2409.18788",
        "abstract url": "https://arxiv.org/abs/2409.18788",
        "title": "Excavating in the Wild: The GOOSE-Ex Dataset for Semantic Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The successful deployment of deep learning-based techniques for autonomous systems is highly dependent on the data availability for the respective system in its deployment environment. Especially for unstructured outdoor environments, very few datasets exist for even fewer robotic platforms and scenarios. In an earlier work, we presented the German Outdoor and Offroad Dataset (GOOSE) framework along with 10000 multimodal frames from an offroad vehicle to enhance the perception capabilities in unstructured environments. In this work, we address the generalizability of the GOOSE framework. To accomplish this, we open-source the GOOSE-Ex dataset, which contains additional 5000 labeled multimodal frames from various completely different environments, recorded on a robotic excavator and a quadruped platform. We perform a comprehensive analysis of the semantic segmentation performance on different platforms and sensor modalities in unseen environments. In addition, we demonstrate how the combined datasets can be utilized for different downstream applications or competitions such as offroad navigation, object manipulation or scene completion. The dataset, its platform documentation and pre-trained state-of-the-art models for offroad perception will be made available on https://goose-dataset.de/. \\",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Submitted to IEEE for review"
    },
    {
        "paper id": "2409.18794",
        "abstract url": "https://arxiv.org/abs/2409.18794",
        "title": "Open-Nav: Exploring Zero-Shot Vision-and-Language Navigation in Continuous Environment with Open-Source LLMs",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-and-Language Navigation (VLN) tasks require an agent to follow textual instructions to navigate through 3D environments. Traditional approaches use supervised learning methods, relying heavily on domain-specific datasets to train VLN models. Recent methods try to utilize closed-source large language models (LLMs) like GPT-4 to solve VLN tasks in zero-shot manners, but face challenges related to expensive token costs and potential data breaches in real-world applications. In this work, we introduce Open-Nav, a novel study that explores open-source LLMs for zero-shot VLN in the continuous environment. Open-Nav employs a spatial-temporal chain-of-thought (CoT) reasoning approach to break down tasks into instruction comprehension, progress estimation, and decision-making. It enhances scene perceptions with fine-grained object and spatial knowledge to improve LLM's reasoning in navigation. Our extensive experiments in both simulated and real-world environments demonstrate that Open-Nav achieves competitive performance compared to using closed-source LLMs.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18814",
        "abstract url": "https://arxiv.org/abs/2409.18814",
        "title": "Early diagnosis of Alzheimer's disease from MRI images with deep learning model",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "MRI",
                "disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "It is acknowledged that the most common cause of dementia worldwide is Alzheimer's disease (AD). This condition progresses in severity from mild to severe and interferes with people's everyday routines. Early diagnosis plays a critical role in patient care and clinical trials. Convolutional neural networks (CNN) are used to create a framework for identifying specific disease features from MRI scans Classification of dementia involves approaches such as medical history review, neuropsychological tests, and magnetic resonance imaging (MRI). However, the image dataset obtained from Kaggle faces a significant issue of class imbalance, which requires equal distribution of samples from each class to address. In this article, to address this imbalance, the Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore, a pre-trained convolutional neural network has been applied to the DEMNET dementia network to extract key features from AD images. The proposed model achieved an impressive accuracy of 98.67%.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "7 pages, 3 figures, Presented at the 20-th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP) 21-22 February, 2024, Mazandaran University of Science and Technology, Babol, Iran"
    },
    {
        "paper id": "2409.18819",
        "abstract url": "https://arxiv.org/abs/2409.18819",
        "title": "Local Transcription Models in Home Care Nursing in Switzerland: an Interdisciplinary Case Study",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Latest advances in the field of natural language processing (NLP) enable new use cases for different domains, including the medical sector. In particular, transcription can be used to support automation in the nursing documentation process and give nurses more time to interact with the patients. However, different challenges including (a) data privacy, (b) local languages and dialects, and (c) domain-specific vocabulary need to be addressed. In this case study, we investigate the case of home care nursing documentation in Switzerland. We assessed different transcription tools and models, and conducted several experiments with OpenAI Whisper, involving different variations of German (i.e., dialects, foreign accent) and manually curated example texts by a domain expert of home care nursing. Our results indicate that even the used out-of-the-box model performs sufficiently well to be a good starting point for future research in the field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18820",
        "abstract url": "https://arxiv.org/abs/2409.18820",
        "title": "An $11/6$-Approximation Algorithm for Vertex Cover on String Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "We present a 1.8334-approximation algorithm for Vertex Cover on string graphs given with a representation, which takes polynomial time in the size of the representation; the exact approximation factor is $11/6$. Recently, the barrier of 2 was broken by Lokshtanov et al. [SoGC '24] with a 1.9999-approximation algorithm. Thus we increase by three orders of magnitude the distance of the approximation ratio to the trivial bound of 2. Our algorithm is very simple. The intricacies reside in its analysis, where we mainly establish that string graphs without odd cycles of length at most 11 are 8-colorable. Previously, Chudnovsky, Scott, and Seymour [JCTB '21] showed that string graphs without odd cycles of length at most 7 are 80-colorable, and string graphs without odd cycles of length at most 5 have bounded chromatic number.",
        "subjects": [
            "cs.DS",
            "cs.CG",
            "cs.DM",
            "math.CO"
        ],
        "comment": "16 pages, 4 figures"
    },
    {
        "paper id": "2409.18826",
        "abstract url": "https://arxiv.org/abs/2409.18826",
        "title": "YOLOv8-ResCBAM: YOLOv8 Based on An Effective Attention Module for Pediatric Wrist Fracture Detection",
        "rating": "-1",
        "keywords": [
            [
                "surgery",
                "Diagnosis",
                "X-ray"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Wrist trauma and even fractures occur frequently in daily life, particularly among children who account for a significant proportion of fracture cases. Before performing surgery, surgeons often request patients to undergo X-ray imaging first, and prepare for the surgery based on the analysis of the X-ray images. With the development of neural networks, You Only Look Once (YOLO) series models have been widely used in fracture detection for Computer-Assisted Diagnosis, where the YOLOv8 model has obtained the satisfactory results. Applying the attention modules to neural networks is one of the effective methods to improve the model performance. This paper proposes YOLOv8-ResCBAM, which incorporates Convolutional Block Attention Module integrated with resblock (ResCBAM) into the original YOLOv8 network architecture. The experimental results on the GRAZPEDWRI-DX dataset demonstrate that the mean Average Precision calculated at Intersection over Union threshold of 0.5 (mAP 50) of the proposed model increased from 63.6% of the original YOLOv8 model to 65.8%, which achieves the state-of-the-art performance. The implementation code is available at https://github.com/RuiyangJu/Fracture_Detection_Improved_YOLOv8.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by ICONIP 2024. arXiv admin note: substantial text overlap with arXiv:2402.09329"
    },
    {
        "paper id": "2409.18835",
        "abstract url": "https://arxiv.org/abs/2409.18835",
        "title": "Accelerating stencils on the Tenstorrent Grayskull RISC-V accelerator",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "The RISC-V Instruction Set Architecture (ISA) has enjoyed phenomenal growth in recent years, however it still to gain popularity in HPC. Whilst adopting RISC-V CPU solutions in HPC might be some way off, RISC-V based PCIe accelerators offer a middle ground where vendors benefit from the flexibility of RISC-V yet fit into existing systems. In this paper we focus on the Tenstorrent Grayskull PCIe RISC-V based accelerator which, built upon Tensix cores, decouples data movement from compute. Using the Jacobi iterative method as a vehicle, we explore the suitability of stencils on the Grayskull e150. We explore best practice in structuring these codes for the accelerator and demonstrate that the e150 provides similar performance to a Xeon Platinum CPU (albeit BF16 vs FP32) but the e150 uses around five times less energy. Over four e150s we obtain around four times the CPU performance, again at around five times less energy.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Author accepted version, to appear in proceedings of the international workshop on RISC-V for HPC"
    },
    {
        "paper id": "2409.18841",
        "abstract url": "https://arxiv.org/abs/2409.18841",
        "title": "RNC: Efficient RRAM-aware NAS and Compilation for DNNs on Resource-Constrained Edge Devices",
        "rating": "-1",
        "keywords": [
            [
                "architecture search",
                "NAS"
            ]
        ],
        "abstract": "Computing-in-memory (CIM) is an emerging computing paradigm, offering noteworthy potential for accelerating neural networks with high parallelism, low latency, and energy efficiency compared to conventional von Neumann architectures. However, existing research has primarily focused on hardware architecture and network co-design for large-scale neural networks, without considering resource constraints. In this study, we aim to develop edge-friendly deep neural networks (DNNs) for accelerators based on resistive random-access memory (RRAM). To achieve this, we propose an edge compilation and resource-constrained RRAM-aware neural architecture search (NAS) framework to search for optimized neural networks meeting specific hardware constraints. Our compilation approach integrates layer partitioning, duplication, and network packing to maximize the utilization of computation units. The resulting network architecture can be optimized for either high accuracy or low latency using a one-shot neural network approach with Pareto optimality achieved through the Non-dominated Sorted Genetic Algorithm II (NSGA-II). The compilation of mobile-friendly networks, like Squeezenet and MobilenetV3 small can achieve over 80% of utilization and over 6x speedup compared to ISAAC-like framework with different crossbar resources. The resulting model from NAS optimized for speed achieved 5x-30x speedup. The code for this paper is available at https://github.com/ArChiiii/rram_nas_comp_pack.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "The 42nd IEEE International Conference on Computer Design (ICCD 2024)"
    },
    {
        "paper id": "2409.18872",
        "abstract url": "https://arxiv.org/abs/2409.18872",
        "title": "Simulating Dynamic Tumor Contrast Enhancement in Breast MRI using Conditional Generative Adversarial Networks",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "diagnosis",
                "MRI",
                "cancer",
                "Tumor"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This paper presents a method for virtual contrast enhancement in breast MRI, offering a promising non-invasive alternative to traditional contrast agent-based DCE-MRI acquisition. Using a conditional generative adversarial network, we predict DCE-MRI images, including jointly-generated sequences of multiple corresponding DCE-MRI timepoints, from non-contrast-enhanced MRIs, enabling tumor localization and characterization without the associated health risks. Furthermore, we qualitatively and quantitatively evaluate the synthetic DCE-MRI images, proposing a multi-metric Scaled Aggregate Measure (SAMe), assessing their utility in a tumor segmentation downstream task, and conclude with an analysis of the temporal patterns in multi-sequence DCE-MRI generation. Our approach demonstrates promising results in generating realistic and useful DCE-MRI sequences, highlighting the potential of virtual contrast enhancement for improving breast cancer diagnosis and treatment, particularly for patients where contrast agent administration is contraindicated.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18877",
        "abstract url": "https://arxiv.org/abs/2409.18877",
        "title": "UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception",
        "rating": "-1",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Visual emotion analysis holds significant research value in both computer vision and psychology. However, existing methods for visual emotion analysis suffer from limited generalizability due to the ambiguity of emotion perception and the diversity of data scenarios. To tackle this issue, we introduce UniEmoX, a cross-modal semantic-guided large-scale pretraining framework. Inspired by psychological research emphasizing the inseparability of the emotional exploration process from the interaction between individuals and their environment, UniEmoX integrates scene-centric and person-centric low-level image spatial structural information, aiming to derive more nuanced and discriminative emotional representations. By exploiting the similarity between paired and unpaired image-text samples, UniEmoX distills rich semantic knowledge from the CLIP model to enhance emotional embedding representations more effectively. To the best of our knowledge, this is the first large-scale pretraining framework that integrates psychological theories with contemporary contrastive learning and masked image modeling techniques for emotion analysis across diverse scenarios. Additionally, we develop a visual emotional dataset titled Emo8. Emo8 samples cover a range of domains, including cartoon, natural, realistic, science fiction and advertising cover styles, covering nearly all common emotional scenes. Comprehensive experiments conducted on six benchmark datasets across two downstream tasks validate the effectiveness of UniEmoX. The source code is available at https://github.com/chincharles/u-emo.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"
    },
    {
        "paper id": "2409.18878",
        "abstract url": "https://arxiv.org/abs/2409.18878",
        "title": "Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models",
        "rating": "-1",
        "keywords": [
            [
                "BioClinicalBERT",
                "Health",
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Accurate identification and categorization of suicidal events can yield better suicide precautions, reducing operational burden, and improving care quality in high-acuity psychiatric settings. Pre-trained language models offer promise for identifying suicidality from unstructured clinical narratives. We evaluated the performance of four BERT-based models using two fine-tuning strategies (multiple single-label and single multi-label) for detecting coexisting suicidal events from 500 annotated psychiatric evaluation notes. The notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed other models using binary relevance (acc=0.86, F1=0.78). MentalBERT (F1=0.74) also exceeded BioClinicalBERT (F1=0.72). RoBERTa fine-tuned with a single multi-label classifier further improved performance (acc=0.88, F1=0.81), highlighting that models pre-trained on domain-relevant data and the single multi-label classification strategy enhance efficiency and performance. Keywords: EHR-based Phynotyping; Natural Language Processing; Secondary Use of EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.IR"
        ],
        "comment": "submitted to AMIA Informatics Summit 2025 as a conference paper"
    },
    {
        "paper id": "2409.18937",
        "abstract url": "https://arxiv.org/abs/2409.18937",
        "title": "Robust Deep Reinforcement Learning for Volt-VAR Optimization in Active Distribution System under Uncertainty",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The deep reinforcement learning (DRL) based Volt-VAR optimization (VVO) methods have been widely studied for active distribution networks (ADNs). However, most of them lack safety guarantees in terms of power injection uncertainties due to the increase in distributed energy resources (DERs) and load demand, such as electric vehicles. This article proposes a robust deep reinforcement learning (RDRL) framework for VVO via a robust deep deterministic policy gradient (DDPG) algorithm. This algorithm can effectively manage hybrid action spaces, considering control devices like capacitors, voltage regulators, and smart inverters. Additionally, it is designed to handle uncertainties by quantifying uncertainty sets with conformal prediction and modeling uncertainties as adversarial attacks to guarantee safe exploration across action spaces. Numerical results on three IEEE test cases demonstrate the sample efficiency and safety of the proposed robust DDPG against uncertainties compared to the benchmark algorithms.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18939",
        "abstract url": "https://arxiv.org/abs/2409.18939",
        "title": "Towards Super-Nominal Payload Handling: Inverse Dynamics Analysis for Multi-Skill Robotic Manipulation",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "Robotic Manipulation"
            ]
        ],
        "abstract": "Motion planning for articulated robots has traditionally been governed by algorithms that operate within manufacturer-defined payload limits. Our empirical analysis of the Franka Emika Panda robot demonstrates that this approach unnecessarily restricts the robot's dynamically-reachable task space. These results establish an expanded operational envelope for such robots, showing that they can handle payloads of more than twice their rated capacity. Additionally, our preliminary findings indicate that integrating non-prehensile motion primitives with grasping-based manipulation has the potential to further increase the success rates of manipulation tasks involving payloads exceeding nominal limits.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted as an extended abstract to ICRA@40"
    },
    {
        "paper id": "2409.19037",
        "abstract url": "https://arxiv.org/abs/2409.19037",
        "title": "Self-Replicating Mechanical Universal Turing Machine",
        "rating": "-1",
        "keywords": [
            [
                "bio-inspired"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents the implementation of a self-replicating finite-state machine (FSM) and a self-replicating Turing Machine (TM) using bio-inspired mechanisms. Building on previous work that introduced self-replicating structures capable of sorting, copying, and reading information, this study demonstrates the computational power of these mechanisms by explicitly constructing a functioning FSM and TM. This study demonstrates the universality of the system by emulating the UTM(5,5) of Neary and Woods.",
        "subjects": [
            "cs.FL",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19042",
        "abstract url": "https://arxiv.org/abs/2409.19042",
        "title": "Probing mental health information in speech foundation models",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "diagnosing"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Non-invasive methods for diagnosing mental health conditions, such as speech analysis, offer promising potential in modern medicine. Recent advancements in machine learning, particularly speech foundation models, have shown significant promise in detecting mental health states by capturing diverse features. This study investigates which pretext tasks in these models best transfer to mental health detection and examines how different model layers encode features relevant to mental health conditions. We also probed the optimal length of audio segments and the best pooling strategies to improve detection accuracy. Using the Callyope-GP and Androids datasets, we evaluated the models' effectiveness across different languages and speech tasks, aiming to enhance the generalizability of speech-based mental health diagnostics. Our approach achieved SOTA scores in depression detection on the Androids dataset.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "6 pages, 4 figures"
    },
    {
        "paper id": "2409.19062",
        "abstract url": "https://arxiv.org/abs/2409.19062",
        "title": "Robust Proximity Operations using Probabilistic Markov Models",
        "rating": "-1",
        "keywords": [
            [
                "radar",
                "vehicle"
            ]
        ],
        "abstract": "A Markov decision process-based state switching is devised, implemented, and analyzed for proximity operations of various autonomous vehicles. The framework contains a pose estimator along with a multi-state guidance algorithm. The unified pose estimator leverages the extended Kalman filter for the fusion of measurements from rate gyroscopes, monocular vision, and ultra-wideband radar sensors. It is also equipped with Mahalonobis distance-based outlier rejection and under-weighting of measurements for robust performance. The use of probabilistic Markov models to transition between various guidance modes is proposed to enable robust and efficient proximity operations. Finally, the framework is validated through an experimental analysis of the docking of two small satellites and the precision landing of an aerial vehicle.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "This work has been submitted to the IEEE ICRA 2025 for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Accompanying video : https://youtu.be/8-fetyf_SrM. arXiv admin note: text overlap with arXiv:2409.09665"
    },
    {
        "paper id": "2409.19067",
        "abstract url": "https://arxiv.org/abs/2409.19067",
        "title": "Algorithms and complexity for monitoring edge-geodetic sets in graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "A monitoring edge-geodetic set of a graph is a subset $M$ of its vertices such that for every edge $e$ in the graph, deleting $e$ increases the distance between at least one pair of vertices in $M$. We study the following computational problem \\textsc{MEG-set}: given a graph $G$ and an integer $k$, decide whether $G$ has a monitoring edge geodetic set of size at most $k$. We prove that the problem is NP-hard even for 2-apex 3-degenerate graphs, improving a result by Haslegrave (Discrete Applied Mathematics 2023). Additionally, we prove that the problem cannot be solved in subexponential-time, assuming the Exponential-Time Hypothesis, even for 3-degenerate graphs. Further, we prove that the optimization version of the problem is APX-hard, even for 4-degenerate graphs. Complementing these hardness results, we prove that the problem admits a polynomial-time algorithm for interval graphs, a fixed-parameter tractable algorithm for general graphs with clique-width plus diameter as the parameter, and a fixed-parameter tractable algorithm for chordal graphs with treewidth as the parameter. We also provide an approximation algorithm with factor $\\ln m\\cdot OPT$ and $\\sqrt{n\\ln m}$ for the optimization version of the problem, where $m$ is the number of edges, $n$ the number of vertices, and $OPT$ is the size of a minimum monitoring edge-geodetic set of the input graph.",
        "subjects": [
            "cs.CC",
            "cs.DM"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2409.19068",
        "abstract url": "https://arxiv.org/abs/2409.19068",
        "title": "Joint Optimization of Pattern, Headway, and Fleet Size of Multiple Urban Transit Lines with Perceived Headway Consideration and Passenger Flow Allocation",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "This study addresses the urban transit pattern design problem, optimizing stop sequences, headways, and fleet sizes across multiple routes simultaneously to minimize user costs (composed of riding, waiting, and transfer times) under operational constraints (e.g., vehicle capacity and fleet size). A destination-labeled multi-commodity network flow (MCNF) formulation is developed to solve the problem at a large scale more efficiently compared to the previous literature. The model allows for flexible pattern options without relying on pre-defined candidate sets and simultaneously considers multiple operational strategies such as express/local services, short-turning, and deadheading. It evaluates perceived headways of joint patterns for passengers, assigns passenger flows to each pattern accordingly, and allows transfers across patterns in different directions. The mixed-integer linear programming (MILP) model is demonstrated with a city-sized network of metro lines in Chicago, USA, achieving near-optimal solutions in hours. The total weighted journey times are reduced by 0.61% and 4.13% under single-route and multi-route scenarios respectively. The model provides transit agencies with an efficient tool for comprehensive service design and resource allocation, improving service quality and resource utilization without additional operational costs.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "23 pages, 3 figures, a previous version accepted for presentation in the 104th Transportation Research Board Annual Meeting in Washington, D.C. in January 2025"
    },
    {
        "paper id": "2409.19077",
        "abstract url": "https://arxiv.org/abs/2409.19077",
        "title": "Voxel-CIM: An Efficient Compute-in-Memory Accelerator for Voxel-based Point Cloud Neural Networks",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Voxel",
                "Point Cloud",
                "depth"
            ]
        ],
        "abstract": "The 3D point cloud perception has emerged as a fundamental role for a wide range of applications. In particular, with the rapid development of neural networks, the voxel-based networks attract great attention due to their excellent performance. Various accelerator designs have been proposed to improve the hardware performance of voxel-based networks, especially to speed up the map search process. However, several challenges still exist including: (1) massive off-chip data access volume caused by map search operations, notably for high resolution and dense distribution cases, (2) frequent data movement for data-intensive convolution operations, (3) imbalanced workload caused by irregular sparsity of point data. To address the above challenges, we propose Voxel-CIM, an efficient Compute-in-Memory based accelerator for voxel-based neural network processing. To reduce off-chip memory access for map search, a depth-encoding-based output major search approach is introduced to maximize data reuse, achieving stable $O(N)$-level data access volume in various situations. Voxel-CIM also employs the in-memory computing paradigm and designs innovative weight mapping strategies to efficiently process Sparse 3D convolutions and 2D convolutions. Implemented on 22 nm technology and evaluated on representative benchmarks, the Voxel-CIM achieves averagely 4.5~7.0$\\times$ higher energy efficiency (10.8 TOPS/w), and 2.4~5.4$\\times$ speed up in detection task and 1.2~8.1$\\times$ speed up in segmentation task compared to the state-of-the-art point cloud accelerators and powerful GPUs.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19078",
        "abstract url": "https://arxiv.org/abs/2409.19078",
        "title": "Differential privacy for protecting patient data in speech disorder detection using deep learning",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosing",
                "disease",
                "pathological"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech pathology has impacts on communication abilities and quality of life. While deep learning-based models have shown potential in diagnosing these disorders, the use of sensitive data raises critical privacy concerns. Although differential privacy (DP) has been explored in the medical imaging domain, its application in pathological speech analysis remains largely unexplored despite the equally critical privacy concerns. This study is the first to investigate DP's impact on pathological speech data, focusing on the trade-offs between privacy, diagnostic accuracy, and fairness. Using a large, real-world dataset of 200 hours of recordings from 2,839 German-speaking participants, we observed a maximum accuracy reduction of 3.85% when training with DP with a privacy budget, denoted by \u03b5, of 7.51. To generalize our findings, we validated our approach on a smaller dataset of Spanish-speaking Parkinson's disease patients, demonstrating that careful pretraining on large-scale task-specific datasets can maintain or even improve model accuracy under DP constraints. We also conducted a comprehensive fairness analysis, revealing that reasonable privacy levels (2<\u03b5<10) do not introduce significant gender bias, though age-related disparities may require further attention. Our results suggest that DP can effectively balance privacy and utility in speech disorder detection, but also highlight the unique challenges in the speech domain, particularly regarding the privacy-fairness trade-off. This provides a foundation for future work to refine DP methodologies and address fairness across diverse patient groups in real-world deployments.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19091",
        "abstract url": "https://arxiv.org/abs/2409.19091",
        "title": "System-Level Defense against Indirect Prompt Injection Attacks: An Information Flow Control Perspective",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Large Language Model-based systems (LLM systems) are information and query processing systems that use LLMs to plan operations from natural-language prompts and feed the output of each successive step into the LLM to plan the next. This structure results in powerful tools that can process complex information from diverse sources but raises critical security concerns. Malicious information from any source may be processed by the LLM and can compromise the query processing, resulting in nearly arbitrary misbehavior. To tackle this problem, we present a system-level defense based on the principles of information flow control that we call an f-secure LLM system. An f-secure LLM system disaggregates the components of an LLM system into a context-aware pipeline with dynamically generated structured executable plans, and a security monitor filters out untrusted input into the planning process. This structure prevents compromise while maximizing flexibility. We provide formal models for both existing LLM systems and our f-secure LLM system, allowing analysis of critical security guarantees. We further evaluate case studies and benchmarks showing that f-secure LLM systems provide robust security while preserving functionality and efficiency. Our code is released at https://github.com/fzwark/Secure_LLM_System.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2409.19125",
        "abstract url": "https://arxiv.org/abs/2409.19125",
        "title": "TRACES: TEE-based Runtime Auditing for Commodity Embedded Systems",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Control Flow Attestation (CFA) offers a means to detect control flow hijacking attacks on remote devices, enabling verification of their runtime trustworthiness. CFA generates a trace (CFLog) containing the destination of all branching instructions executed. This allows a remote Verifier (Vrf) to inspect the execution control flow on a potentially compromised Prover (Prv) before trusting that a value/action was correctly produced/performed by Prv. However, while CFA can be used to detect runtime compromises, it cannot guarantee the eventual delivery of the execution evidence (CFLog) to Vrf. In turn, a compromised Prv may refuse to send CFLog to Vrf, preventing its analysis to determine the exploit's root cause and appropriate remediation actions. In this work, we propose TRACES: TEE-based Runtime Auditing for Commodity Embedded Systems. TRACES guarantees reliable delivery of periodic runtime reports even when Prv is compromised. This enables secure runtime auditing in addition to best-effort delivery of evidence in CFA. TRACES also supports a guaranteed remediation phase, triggered upon compromise detection to ensure that identified runtime vulnerabilities can be reliably patched. To the best of our knowledge, TRACES is the first system to provide this functionality on commodity devices (i.e., without requiring custom hardware modifications). To that end, TRACES leverages support from the ARM TrustZone-M Trusted Execution Environment (TEE). To assess practicality, we implement and evaluate a fully functional (open-source) prototype of TRACES atop the commodity ARM Cortex-M33 micro-controller unit.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19130",
        "abstract url": "https://arxiv.org/abs/2409.19130",
        "title": "Multi-modal Cross-domain Self-supervised Pre-training for fMRI and EEG Fusion",
        "rating": "-1",
        "keywords": [
            [
                "fMRI",
                "EEG"
            ],
            [
                "cs.AI",
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Neuroimaging techniques including functional magnetic resonance imaging (fMRI) and electroencephalogram (EEG) have shown promise in detecting functional abnormalities in various brain disorders. However, existing studies often focus on a single domain or modality, neglecting the valuable complementary information offered by multiple domains from both fMRI and EEG, which is crucial for a comprehensive representation of disorder pathology. This limitation poses a challenge in effectively leveraging the synergistic information derived from these modalities. To address this, we propose a Multi-modal Cross-domain Self-supervised Pre-training Model (MCSP), a novel approach that leverages self-supervised learning to synergize multi-modal information across spatial, temporal, and spectral domains. Our model employs cross-domain self-supervised loss that bridges domain differences by implementing domain-specific data augmentation and contrastive loss, enhancing feature discrimination. Furthermore, MCSP introduces cross-modal self-supervised loss to capitalize on the complementary information of fMRI and EEG, facilitating knowledge distillation within domains and maximizing cross-modal feature convergence. We constructed a large-scale pre-training dataset and pretrained MCSP model by leveraging proposed self-supervised paradigms to fully harness multimodal neuroimaging data. Through comprehensive experiments, we have demonstrated the superior performance and generalizability of our model on multiple classification tasks. Our study contributes a significant advancement in the fusion of fMRI and EEG, marking a novel integration of cross-domain features, which enriches the existing landscape of neuroimaging research, particularly within the context of mental disorder studies.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19131",
        "abstract url": "https://arxiv.org/abs/2409.19131",
        "title": "Signal Temporal Logic Planning with Time-Varying Robustness",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "This letter aims to generate a continuous-time trajectory consisting of piecewise B\u00e9zier curves that satisfy signal temporal logic (STL) specifications with piecewise time-varying robustness. Our time-varying robustness is less conservative than the real-valued robustness, which enables more effective tracking in practical applications. Specifically, our continuous-time trajectories account for dynamic feasibility, leading to smaller tracking errors and ensuring that the STL specifications can be met by the tracking trajectory. Comparative experiments demonstrate the efficiency and effectiveness of the proposed approach.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19151",
        "abstract url": "https://arxiv.org/abs/2409.19151",
        "title": "Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?",
        "rating": "-1",
        "keywords": [
            [
                "Grammar",
                "grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Extremely low-resource (XLR) languages lack substantial corpora for training NLP models, motivating the use of all available resources such as dictionaries and grammar books. Machine Translation from One Book (Tanzer et al., 2024) suggests prompting long-context LLMs with one grammar book enables English-Kalamang translation, an unseen XLR language - a noteworthy case of linguistic knowledge helping an NLP task. We investigate whether the book's grammatical explanations or its parallel examples are most effective for learning XLR translation, finding almost all improvement stems from the parallel examples. Further, we find similar results for Nepali, a seen low-resource language, and achieve performance comparable to an LLM with a grammar book by simply fine-tuning an encoder-decoder translation model. We then investigate where grammar books help by testing two linguistic tasks, grammaticality judgment and gloss prediction, and we explore what kind of grammatical knowledge helps by introducing a typological feature prompt that achieves leading results on these more relevant tasks. We thus emphasise the importance of task-appropriate data for XLR languages: parallel examples for translation, and grammatical data for linguistic tasks. As we find no evidence that long-context LLMs can make effective use of grammatical explanations for XLR translation, we suggest data collection for multilingual XLR tasks such as translation is best focused on parallel data over linguistic description.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19168",
        "abstract url": "https://arxiv.org/abs/2409.19168",
        "title": "Optimization-based Task and Motion Planning under Signal Temporal Logic Specifications using Logic Network Flow",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This paper proposes an optimization-based task and motion planning framework, named ``Logic Network Flow\", to integrate signal temporal logic (STL) specifications into efficient mixed-binary linear programmings. In this framework, temporal predicates are encoded as polyhedron constraints on each edge of the network flow, instead of as constraints between the nodes as in the traditional Logic Tree formulation. Synthesized with Dynamic Network Flows, Logic Network Flows render a tighter convex relaxation compared to Logic Trees derived from these STL specifications. Our formulation is evaluated on several multi-robot motion planning case studies. Empirical results demonstrate that our formulation outperforms Logic Tree formulation in terms of computation time for several planning problems. As the problem size scales up, our method still discovers better lower and upper bounds by exploring fewer number of nodes during the branch-and-bound process, although this comes at the cost of increased computational load for each node when exploring branches.",
        "subjects": [
            "cs.RO",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19170",
        "abstract url": "https://arxiv.org/abs/2409.19170",
        "title": "An Interactive Hands-Free Controller for a Riding Ballbot to Enable Simple Shared Control Tasks",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Our team developed a riding ballbot (called PURE) that is dynamically stable, omnidirectional, and driven by lean-to-steer control. A hands-free admittance control scheme (HACS) was previously integrated to allow riders with different torso functions to control the robot's movements via torso leaning and twisting. Such an interface requires motor coordination skills and could result in collisions with obstacles due to low proficiency. Hence, a shared controller (SC) that limits the speed of PURE could be helpful to ensure the safety of riders. However, the self-balancing dynamics of PURE could result in a weak control authority of its motion, in which the torso motion of the rider could easily result in poor tracking of the command speed dictated by the shared controller. Thus, we proposed an interactive hands-free admittance control scheme (iHACS), which added two modules to HACS to improve the speed-tracking performance of PURE: control gain personalization module and interaction compensation module. Human riding tests of simple tasks, idle-keeping and speed-limiting, were conducted to compare the performance of HACS and iHACS. Two manual wheelchair users and two able-bodied individuals participated in this study. They were instructed to use \"adversarial\" torso motions that would tax the SC's ability to keep the ballbot idling or below a set speed. In the idle-keeping tasks, iHACS demonstrated minimal translational motion and low command speed tracking RMSE, even with significant torso lean angles. During the speed-limiting task with command speed saturated at 0.5 m/s, the system achieved an average maximum speed of 1.1 m/s with iHACS, compared with that of over 1.9 m/s with HACS. These results suggest that iHACS can enhance PURE's control authority over the rider, which enables PURE to provide physical interactions back to the rider and results in a collaborative rider-robot synergy.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19171",
        "abstract url": "https://arxiv.org/abs/2409.19171",
        "title": "Reducing Overtreatment of Indeterminate Thyroid Nodules Using a Multimodal Deep Learning Model",
        "rating": "-1",
        "keywords": [
            [
                "biopsy",
                "medical"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Objective: Molecular testing (MT) classifies cytologically indeterminate thyroid nodules as benign or malignant with high sensitivity but low positive predictive value (PPV), only using molecular profiles, ignoring ultrasound (US) imaging and biopsy. We address this limitation by applying attention multiple instance learning (AMIL) to US images. Methods: We retrospectively reviewed 333 patients with indeterminate thyroid nodules at UCLA medical center (259 benign, 74 malignant). A multi-modal deep learning AMIL model was developed, combining US images and MT to classify the nodules as benign or malignant and enhance the malignancy risk stratification of MT. Results: The final AMIL model matched MT sensitivity (0.946) while significantly improving PPV (0.477 vs 0.448 for MT alone), indicating fewer false positives while maintaining high sensitivity. Conclusion: Our approach reduces false positives compared to MT while maintaining the same ability to identify positive cases, potentially reducing unnecessary benign thyroid resections in patients with indeterminate nodules.",
        "subjects": [
            "q-bio.QM",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "9 pages, 3 figures"
    },
    {
        "paper id": "2409.19174",
        "abstract url": "https://arxiv.org/abs/2409.19174",
        "title": "Feature Estimation of Global Language Processing in EEG Using Attention Maps",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "fMRI",
                "EEG",
                "disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding the correlation between EEG features and cognitive tasks is crucial for elucidating brain function. Brain activity synchronizes during speaking and listening tasks. However, it is challenging to estimate task-dependent brain activity characteristics with methods with low spatial resolution but high temporal resolution, such as EEG, rather than methods with high spatial resolution, like fMRI. This study introduces a novel approach to EEG feature estimation that utilizes the weights of deep learning models to explore this association. We demonstrate that attention maps generated from Vision Transformers and EEGNet effectively identify features that align with findings from prior studies. EEGNet emerged as the most accurate model regarding subject independence and the classification of Listening and Speaking tasks. The application of Mel-Spectrogram with ViTs enhances the resolution of temporal and frequency-related EEG characteristics. Our findings reveal that the characteristics discerned through attention maps vary significantly based on the input data, allowing for tailored feature extraction from EEG signals. By estimating features, our study reinforces known attributes and predicts new ones, potentially offering fresh perspectives in utilizing EEG for medical purposes, such as early disease detection. These techniques will make substantial contributions to cognitive neuroscience.",
        "subjects": [
            "q-bio.NC",
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19177",
        "abstract url": "https://arxiv.org/abs/2409.19177",
        "title": "Evidence Is All You Need: Ordering Imaging Studies via Language Model Alignment with the ACR Appropriateness Criteria",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "healthcare",
                "clinical",
                "Radiology"
            ],
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Diagnostic imaging studies are an increasingly important component of the workup and management of acutely presenting patients. However, ordering appropriate imaging studies according to evidence-based medical guidelines is a challenging task with a high degree of variability between healthcare providers. To address this issue, recent work has investigated if generative AI and large language models can be leveraged to help clinicians order relevant imaging studies for patients. However, it is challenging to ensure that these tools are correctly aligned with medical guidelines, such as the American College of Radiology's Appropriateness Criteria (ACR AC). In this study, we introduce a framework to intelligently leverage language models by recommending imaging studies for patient cases that are aligned with evidence-based guidelines. We make available a novel dataset of patient \"one-liner\" scenarios to power our experiments, and optimize state-of-the-art language models to achieve an accuracy on par with clinicians in image ordering. Finally, we demonstrate that our language model-based pipeline can be used as intelligent assistants by clinicians to support image ordering workflows and improve the accuracy of imaging study ordering according to the ACR AC. Our work demonstrates and validates a strategy to leverage AI-based software to improve trustworthy clinical decision making in alignment with expert evidence-based guidelines.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CY"
        ],
        "comment": "38 pages main text, 5 figures, 1 table"
    },
    {
        "paper id": "2409.19190",
        "abstract url": "https://arxiv.org/abs/2409.19190",
        "title": "RAIL: Reachability-Aided Imitation Learning for Safe Policy Execution",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Imitation learning (IL) has shown great success in learning complex robot manipulation tasks. However, there remains a need for practical safety methods to justify widespread deployment. In particular, it is important to certify that a system obeys hard constraints on unsafe behavior in settings when it is unacceptable to design a tradeoff between performance and safety via tuning the policy (i.e. soft constraints). This leads to the question, how does enforcing hard constraints impact the performance (meaning safely completing tasks) of an IL policy? To answer this question, this paper builds a reachability-based safety filter to enforce hard constraints on IL, which we call Reachability-Aided Imitation Learning (RAIL). Through evaluations with state-of-the-art IL policies in mobile robots and manipulation tasks, we make two key findings. First, the highest-performing policies are sometimes only so because they frequently violate constraints, and significantly lose performance under hard constraints. Second, surprisingly, hard constraints on the lower-performing policies can occasionally increase their ability to perform tasks safely. Finally, hardware evaluation confirms the method can operate in real time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "* denotes equal contribution"
    },
    {
        "paper id": "2409.19194",
        "abstract url": "https://arxiv.org/abs/2409.19194",
        "title": "An In-depth Analysis of a Nation-Sponsored Attack: Case Study and Cybersecurity Insights",
        "rating": "-1",
        "keywords": [
            [
                "Attack"
            ]
        ],
        "abstract": "Nation-sponsored cyberattacks pose a significant threat to national security by targeting critical infrastructure and disrupting essential services. One of the most impactful cyber threats affecting South Korea's banking sector and infrastructure was the Dark Seoul cyberattack, which occurred several years ago. Believed to have been orchestrated by North Korean state-sponsored hackers, the attack employed spear phishing, DNS poisoning, and malware to compromise systems, causing widespread disruption. In this paper, we conduct an in-depth analysis of the Dark Seoul attack, examining the techniques used and providing insights and defense recommendations for the global cybersecurity community. The motivations behind the attack are explored, along with an assessment of South Korea's response and the broader implications for cybersecurity policy. Our analysis highlights the vulnerabilities exploited and underscores the need for more proactive defenses against state-sponsored cyber threats. This paper, therefore, emphasizes the critical need for stronger national cybersecurity defenses in the face of such threats.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19201",
        "abstract url": "https://arxiv.org/abs/2409.19201",
        "title": "Dynamic Adaptive Resource Scheduling for Phased Array Radar: Enhancing Efficiency through Synthesis Priorities and Pulse Interleaving",
        "rating": "-1",
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "To enhance the resource scheduling performance of phased array radar, we propose a dynamic adaptive resource scheduling algorithm based on synthesis priorities and pulse interleaving. This approach addresses the challenges of low efficiency, high loss ratios, and significant subjectivity in task assignment within phased array radar systems. We introduce a task synthesis priority design method that considers the working mode priority, deadlines, and time shift ratios. By implementing this method, we can increase the flexibility of task scheduling and improve the efficiency of radar processing tasks. Additionally, our proposed pulse interleaving method effectively utilizes the waiting periods between receiving and transmitting pulses to process other beams, thereby enhancing resource utilization. Simulation results demonstrate that the proposed scheduling algorithm significantly reduces time deviation ratios and scheduling failure rates while improving scheduling yield and time utilization ratios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19202",
        "abstract url": "https://arxiv.org/abs/2409.19202",
        "title": "Safe Delay-Adaptive Control of Strict-Feedback Nonlinear Systems with Application in Vehicle Platooning",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "Vehicle"
            ]
        ],
        "abstract": "This paper presents a safe delay-adaptive control for a strict-feedback nonlinear ODE with a delayed actuator, whose dynamic is also a strict-feedback nonlinear ODE and the delay length is unknown. By formulating the delay as a transport PDE, the plant becomes a sandwich configuration consisting of nonlinear ODE-transport PDE-nonlinear ODE, where the transport speed in the PDE is unknown. We propose a predictor-based nonovershooting backstepping transformation to build the nominal safe delay-compensated control, guaranteeing that the output of the distal ODE safely tracks the target trajectory from one side without undershooting. To address the uncertainty in the delay, we incorporate recent delay-adaptive and safe adaptive technologies to build a safe adaptive-delay controller. The adaptive closed-loop system ensures 1) the exact identification of the unknown delay in finite time; 2) the output state stays in the safe region all the time, especially in the original safe region, instead of a subset, after a finite time; 3) all states are bounded, and moreover, they will converge to zero if the target trajectory is identically zero. In the simulation, the proposed control design is verified in the application of safe vehicle platooning. It regulates the spacing between adjacent vehicles to converge to a small distance and avoids collisions by ensuring they do not breach the safe distance at any time, even in the presence of large unknown delays and at a relatively high speed.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19221",
        "abstract url": "https://arxiv.org/abs/2409.19221",
        "title": "Cauchy activation function and XNet",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We have developed a novel activation function, named the Cauchy Activation Function. This function is derived from the Cauchy Integral Theorem in complex analysis and is specifically tailored for problems requiring high precision. This innovation has led to the creation of a new class of neural networks, which we call (Comple)XNet, or simply XNet. We will demonstrate that XNet is particularly effective for high-dimensional challenges such as image classification and solving Partial Differential Equations (PDEs). Our evaluations show that XNet significantly outperforms established benchmarks like MNIST and CIFAR-10 in computer vision, and offers substantial advantages over Physics-Informed Neural Networks (PINNs) in both low-dimensional and high-dimensional PDE scenarios.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19223",
        "abstract url": "https://arxiv.org/abs/2409.19223",
        "title": "Summit Vitals: Multi-Camera and Multi-Signal Biosensing at High Altitudes",
        "rating": "-1",
        "keywords": [
            [
                "Biosensing",
                "facial",
                "physiological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video photoplethysmography (vPPG) is an emerging method for non-invasive and convenient measurement of physiological signals, utilizing two primary approaches: remote video PPG (rPPG) and contact video PPG (cPPG). Monitoring vitals in high-altitude environments, where heart rates tend to increase and blood oxygen levels often decrease, presents significant challenges. To address these issues, we introduce the SUMS dataset comprising 80 synchronized non-contact facial and contact finger videos from 10 subjects during exercise and oxygen recovery scenarios, capturing PPG, respiration rate (RR), and SpO2. This dataset is designed to validate video vitals estimation algorithms and compare facial rPPG with finger cPPG. Additionally, fusing videos from different positions (i.e., face and finger) reduces the mean absolute error (MAE) of SpO2 predictions by 7.6\\% and 10.6\\% compared to only face and only finger, respectively. In cross-subject evaluation, we achieve an MAE of less than 0.5 BPM for HR estimation and 2.5\\% for SpO2 estimation, demonstrating the precision of our multi-camera fusion techniques. Our findings suggest that simultaneous training on multiple indicators, such as PPG and blood oxygen, can reduce MAE in SpO2 estimation by 17.8\\%.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": "Accepted by UIC'24, 8 pages, 5 figures. Ke Liu and Jiankai Tang are co-first authors. Yuntao Wang and Xiaojing Liu are co-corresponding authors"
    },
    {
        "paper id": "2409.18455",
        "abstract url": "https://arxiv.org/abs/2409.18455",
        "title": "Review of Digital Asset Development with Graph Neural Network Unlearning",
        "rating": "-1.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In the rapidly evolving landscape of digital assets, the imperative for robust data privacy and compliance with regulatory frameworks has intensified. This paper investigates the critical role of Graph Neural Networks (GNNs) in the management of digital assets and introduces innovative unlearning techniques specifically tailored to GNN architectures. We categorize unlearning strategies into two primary classes: data-driven approximation, which manipulates the graph structure to isolate and remove the influence of specific nodes, and model-driven approximation, which modifies the internal parameters and architecture of the GNN itself. By examining recent advancements in these unlearning methodologies, we highlight their applicability in various use cases, including fraud detection, risk assessment, token relationship prediction, and decentralized governance. We discuss the challenges inherent in balancing model performance with the requirements for data unlearning, particularly in the context of real-time financial applications. Furthermore, we propose a hybrid approach that combines the strengths of both unlearning strategies to enhance the efficiency and effectiveness of GNNs in digital asset ecosystems. Ultimately, this paper aims to provide a comprehensive framework for understanding and implementing GNN unlearning techniques, paving the way for secure and compliant deployment of machine learning in the digital asset domain.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18461",
        "abstract url": "https://arxiv.org/abs/2409.18461",
        "title": "Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "IoT"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Federated Learning has emerged as a promising paradigm for collaborative machine learning, while preserving user data privacy. Despite its potential, standard FL lacks support for diverse heterogeneous device prototypes, which vary significantly in model and dataset sizes -- from small IoT devices to large workstations. This limitation is only partially addressed by existing knowledge distillation techniques, which often fail to transfer knowledge effectively across a broad spectrum of device prototypes with varied capabilities. This failure primarily stems from two issues: the dilution of informative logits from more capable devices by those from less capable ones, and the use of a single integrated logits as the distillation target across all devices, which neglects their individual learning capacities and and the unique contributions of each. To address these challenges, we introduce TAKFL, a novel KD-based framework that treats the knowledge transfer from each device prototype's ensemble as a separate task, independently distilling each to preserve its unique contributions and avoid dilution. TAKFL also incorporates a KD-based self-regularization technique to mitigate the issues related to the noisy and unsupervised ensemble distillation process. To integrate the separately distilled knowledge, we introduce an adaptive task arithmetic knowledge integration process, allowing each student model to customize the knowledge integration for optimal performance. Additionally, we present theoretical results demonstrating the effectiveness of task arithmetic in transferring knowledge across heterogeneous devices with varying capacities. Comprehensive evaluations of our method across both CV and NLP tasks demonstrate that TAKFL achieves SOTA results in a variety of datasets and settings, significantly outperforming existing KD-based methods. Code is released at https://github.com/MMorafah/TAKFL",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.DC"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2409.18479",
        "abstract url": "https://arxiv.org/abs/2409.18479",
        "title": "CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The stable periodic patterns present in time series data serve as the foundation for conducting long-horizon forecasts. In this paper, we pioneer the exploration of explicitly modeling this periodicity to enhance the performance of models in long-term time series forecasting (LTSF) tasks. Specifically, we introduce the Residual Cycle Forecasting (RCF) technique, which utilizes learnable recurrent cycles to model the inherent periodic patterns within sequences, and then performs predictions on the residual components of the modeled cycles. Combining RCF with a Linear layer or a shallow MLP forms the simple yet powerful method proposed in this paper, called CycleNet. CycleNet achieves state-of-the-art prediction accuracy in multiple domains including electricity, weather, and energy, while offering significant efficiency advantages by reducing over 90% of the required parameter quantity. Furthermore, as a novel plug-and-play technique, the RCF can also significantly improve the prediction accuracy of existing models, including PatchTST and iTransformer. The source code is available at: https://github.com/ACAT-SCUT/CycleNet.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18541",
        "abstract url": "https://arxiv.org/abs/2409.18541",
        "title": "Align$^2$LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation",
        "rating": "-1.5",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advances in Multi-modal Large Language Models (MLLMs), such as LLaVA-series models, are driven by massive machine-generated instruction-following data tuning. Such automatic instruction collection pipelines, however, inadvertently introduce significant variability in data quality. This paper introduces a novel instruction curation algorithm, derived from two unique perspectives, human and LLM preference alignment, to compress this vast corpus of machine-generated multimodal instructions to a compact and high-quality form: (i) For human preference alignment, we have collected a machine-generated multimodal instruction dataset and established a comprehensive set of both subjective and objective criteria to guide the data quality assessment critically from human experts. By doing so, a reward model was trained on the annotated dataset to internalize the nuanced human understanding of instruction alignment. (ii) For LLM preference alignment, given the instruction selected by the reward model, we propose leveraging the inner LLM used in MLLM to align the writing style of visual instructions with that of the inner LLM itself, resulting in LLM-aligned instruction improvement. Extensive experiments demonstrate that we can maintain or even improve model performance by compressing synthetic multimodal instructions by up to 90%. Impressively, by aggressively reducing the total training sample size from 158k to 14k (9$\\times$ smaller), our model consistently outperforms its full-size dataset counterpart across various MLLM benchmarks. Our project is available at https://github.com/DCDmllm/Align2LLaVA.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18572",
        "abstract url": "https://arxiv.org/abs/2409.18572",
        "title": "Towards an active-learning approach to resource allocation for population-based damage prognosis",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Damage prognosis is, arguably, one of the most difficult tasks of structural health monitoring (SHM). To address common problems of damage prognosis, a population-based SHM (PBSHM) approach is adopted in the current work. In this approach the prognosis problem is considered as an information-sharing problem where data from past structures are exploited to make more accurate inferences regarding currently-degrading structures. For a given population, there may exist restrictions on the resources available to conduct monitoring; thus, the current work studies the problem of allocating such resources within a population of degrading structures with a view to maximising the damage-prognosis accuracy. The challenges of the current framework are mainly associated with the inference of outliers on the level of damage evolution, given partial data from the damage-evolution phenomenon. The current approach considers an initial population of structures for which damage evolution is extensively observed. Subsequently, a second population of structures with evolving damage is considered for which two monitoring systems are available, a low-availability and high-fidelity (low-uncertainty) one, and a widely-available and low-fidelity (high-uncertainty) one. The task of the current work is to follow an active-learning approach to identify the structures to which the high-fidelity system should be assigned in order to enhance the predictive capabilities of the machine-learning model throughout the population.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18597",
        "abstract url": "https://arxiv.org/abs/2409.18597",
        "title": "TemporalPaD: a reinforcement-learning framework for temporal feature representation and dimension reduction",
        "rating": "-1.5",
        "keywords": [
            [
                "DNA"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in feature representation and dimension reduction have highlighted their crucial role in enhancing the efficacy of predictive modeling. This work introduces TemporalPaD, a novel end-to-end deep learning framework designed for temporal pattern datasets. TemporalPaD integrates reinforcement learning (RL) with neural networks to achieve concurrent feature representation and feature reduction. The framework consists of three cooperative modules: a Policy Module, a Representation Module, and a Classification Module, structured based on the Actor-Critic (AC) framework. The Policy Module, responsible for dimensionality reduction through RL, functions as the actor, while the Representation Module for feature extraction and the Classification Module collectively serve as the critic. We comprehensively evaluate TemporalPaD using 29 UCI datasets, a well-known benchmark for validating feature reduction algorithms, through 10 independent tests and 10-fold cross-validation. Additionally, given that TemporalPaD is specifically designed for time series data, we apply it to a real-world DNA classification problem involving enhancer category and enhancer strength. The results demonstrate that TemporalPaD is an efficient and effective framework for achieving feature reduction, applicable to both structured data and sequence datasets. The source code of the proposed TemporalPaD is freely available as supplementary material to this article and at http://www.healthinformaticslab.org/supp/.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18624",
        "abstract url": "https://arxiv.org/abs/2409.18624",
        "title": "Unsupervised Cognition",
        "rating": "-1.5",
        "keywords": [
            [
                "cancer"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Unsupervised learning methods have a soft inspiration in cognition models. To this day, the most successful unsupervised learning methods revolve around clustering samples in a mathematical space. In this paper we propose a state-of-the-art primitive-based unsupervised learning approach for decision-making inspired by novel cognition models. This representation-centric approach models the input space constructively as a distributed hierarchical structure in an input-agnostic way. We compared our approach with current state-of-the-art in unsupervised learning classification, and with current state-of-the-art in cancer type classification. We show how our proposal outperforms previous state-of-the-art. We also evaluate some cognition-like properties of our proposal where it not only outperforms the compared algorithms (even supervised learning ones), but it also shows a different, more cognition-like, behaviour.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18630",
        "abstract url": "https://arxiv.org/abs/2409.18630",
        "title": "Entropy, concentration, and learning: a statistical mechanics primer",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Artificial intelligence models trained through loss minimization have demonstrated significant success, grounded in principles from fields like information theory and statistical physics. This work explores these established connections through the lens of statistical mechanics, starting from first-principles sample concentration behaviors that underpin AI and machine learning. Our development of statistical mechanics for modeling highlights the key role of exponential families, and quantities of statistics, physics, and information theory.",
        "subjects": [
            "cs.LG",
            "cond-mat.stat-mech",
            "cs.AI",
            "cs.IT",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18836",
        "abstract url": "https://arxiv.org/abs/2409.18836",
        "title": "Constructing Confidence Intervals for 'the' Generalization Error -- a Comprehensive Benchmark Study",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "When assessing the quality of prediction models in machine learning, confidence intervals (CIs) for the generalization error, which measures predictive performance, are a crucial tool. Luckily, there exist many methods for computing such CIs and new promising approaches are continuously being proposed. Typically, these methods combine various resampling procedures, most popular among them cross-validation and bootstrapping, with different variance estimation techniques. Unfortunately, however, there is currently no consensus on when any of these combinations may be most reliably employed and how they generally compare. In this work, we conduct the first large-scale study comparing CIs for the generalization error - empirically evaluating 13 different methods on a total of 18 tabular regression and classification problems, using four different inducers and a total of eight loss functions. We give an overview of the methodological foundations and inherent challenges of constructing CIs for the generalization error and provide a concise review of all 13 methods in a unified framework. Finally, the CI methods are evaluated in terms of their relative coverage frequency, width, and runtime. Based on these findings, we are able to identify a subset of methods that we would recommend. We also publish the datasets as a benchmarking suite on OpenML and our code on GitHub to serve as a basis for further studies.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18876",
        "abstract url": "https://arxiv.org/abs/2409.18876",
        "title": "CemiFace: Center-based Semi-hard Synthetic Face Generation for Face Recognition",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Privacy issue is a main concern in developing face recognition techniques. Although synthetic face images can partially mitigate potential legal risks while maintaining effective face recognition (FR) performance, FR models trained by face images synthesized by existing generative approaches frequently suffer from performance degradation problems due to the insufficient discriminative quality of these synthesized samples. In this paper, we systematically investigate what contributes to solid face recognition model training, and reveal that face images with certain degree of similarities to their identity centers show great effectiveness in the performance of trained FR models. Inspired by this, we propose a novel diffusion-based approach (namely Center-based Semi-hard Synthetic Face Generation (CemiFace)) which produces facial samples with various levels of similarity to the subject center, thus allowing to generate face datasets containing effective discriminative samples for training face recognition. Experimental results show that with a modest degree of similarity, training on the generated dataset can produce competitive performance compared to previous generation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted to NeurIPS 2024. We are preparing the camera-ready version according to the reviews"
    },
    {
        "paper id": "2409.18885",
        "abstract url": "https://arxiv.org/abs/2409.18885",
        "title": "HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The application of large deep learning models in weather forecasting has led to significant advancements in the field, including higher-resolution forecasting and extended prediction periods exemplified by models such as Pangu and Fuxi. Despite these successes, previous research has largely been characterized by the neglect of extreme weather events, and the availability of datasets specifically curated for such events remains limited. Given the critical importance of accurately forecasting extreme weather, this study introduces a comprehensive dataset that incorporates high-resolution extreme weather cases derived from the High-Resolution Rapid Refresh (HRRR) data, a 3-km real-time dataset provided by NOAA. We also evaluate the current state-of-the-art deep learning models and Numerical Weather Prediction (NWP) systems on HR-Extreme, and provide a improved baseline deep learning model called HR-Heim which has superior performance on both general loss and HR-Extreme compared to others. Our results reveal that the errors of extreme weather cases are significantly larger than overall forecast error, highlighting them as an crucial source of loss in weather prediction. These findings underscore the necessity for future research to focus on improving the accuracy of extreme weather forecasts to enhance their practical utility.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, under review"
    },
    {
        "paper id": "2409.18895",
        "abstract url": "https://arxiv.org/abs/2409.18895",
        "title": "Multi-Source Hard and Soft Information Fusion Approach for Accurate Cryptocurrency Price Movement Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "One of the most important challenges in the financial and cryptocurrency field is accurately predicting cryptocurrency price trends. Leveraging artificial intelligence (AI) is beneficial in addressing this challenge. Cryptocurrency markets, marked by substantial growth and volatility, attract investors and scholars keen on deciphering and forecasting cryptocurrency price movements. The vast and diverse array of data available for such predictions increases the complexity of the task. In our study, we introduce a novel approach termed hard and soft information fusion (HSIF) to enhance the accuracy of cryptocurrency price movement forecasts. The hard information component of our approach encompasses historical price records alongside technical indicators. Complementing this, the soft data component extracts from X (formerly Twitter), encompassing news headlines and tweets about the cryptocurrency. To use this data, we use the Bidirectional Encoder Representations from Transformers (BERT)-based sentiment analysis method, financial BERT (FinBERT), which performs best. Finally, our model feeds on the information set including processed hard and soft data. We employ the bidirectional long short-term memory (BiLSTM) model because processing information in both forward and backward directions can capture long-term dependencies in sequential information. Our empirical findings emphasize the superiority of the HSIF approach over models dependent on single-source data by testing on Bitcoin-related data. By fusing hard and soft information on Bitcoin dataset, our model has about 96.8\\% accuracy in predicting price movement. Incorporating information enables our model to grasp the influence of social sentiment on price fluctuations, thereby supplementing the technical analysis-based predictions derived from hard information.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18946",
        "abstract url": "https://arxiv.org/abs/2409.18946",
        "title": "Unconditional stability of a recurrent neural circuit implementing divisive normalization",
        "rating": "-1.5",
        "keywords": [
            [
                "biologically"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Stability in recurrent neural models poses a significant challenge, particularly in developing biologically plausible neurodynamical models that can be seamlessly trained. Traditional cortical circuit models are notoriously difficult to train due to expansive nonlinearities in the dynamical system, leading to an optimization problem with nonlinear stability constraints that are difficult to impose. Conversely, recurrent neural networks (RNNs) excel in tasks involving sequential data but lack biological plausibility and interpretability. In this work, we address these challenges by linking dynamic divisive normalization (DN) to the stability of ORGaNICs, a biologically plausible recurrent cortical circuit model that dynamically achieves DN and has been shown to simulate a wide range of neurophysiological phenomena. By using the indirect method of Lyapunov, we prove the remarkable property of unconditional local stability for an arbitrary-dimensional ORGaNICs circuit when the recurrent weight matrix is the identity. We thus connect ORGaNICs to a system of coupled damped harmonic oscillators, which enables us to derive the circuit's energy function, providing a normative principle of what the circuit, and individual neurons, aim to accomplish. Further, for a generic recurrent weight matrix, we prove the stability of the 2D model and demonstrate empirically that stability holds in higher dimensions. Finally, we show that ORGaNICs can be trained by backpropagation through time without gradient clipping/scaling, thanks to its intrinsic stability property and adaptive time constants, which address the problems of exploding, vanishing, and oscillating gradients. By evaluating the model's performance on RNN benchmarks, we find that ORGaNICs outperform alternative neurodynamical models on static image classification tasks and perform comparably to LSTMs on sequential tasks.",
        "subjects": [
            "q-bio.NC",
            "cs.AI",
            "cs.LG",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18964",
        "abstract url": "https://arxiv.org/abs/2409.18964",
        "title": "PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "We present PhysGen, a novel image-to-video generation method that converts a single image and an input condition (e.g., force and torque applied to an object in the image) to produce a realistic, physically plausible, and temporally consistent video. Our key insight is to integrate model-based physical simulation with a data-driven video generation process, enabling plausible image-space dynamics. At the heart of our system are three core components: (i) an image understanding module that effectively captures the geometry, materials, and physical parameters of the image; (ii) an image-space dynamics simulation model that utilizes rigid-body physics and inferred parameters to simulate realistic behaviors; and (iii) an image-based rendering and refinement module that leverages generative video diffusion to produce realistic video footage featuring the simulated motion. The resulting videos are realistic in both physics and appearance and are even precisely controllable, showcasing superior results over existing data-driven image-to-video generation works through quantitative comparison and comprehensive user study. PhysGen's resulting videos can be used for various downstream applications, such as turning an image into a realistic animation or allowing users to interact with the image and create various dynamics. Project page: https://stevenlsw.github.io/physgen/",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted to ECCV 2024. Project page: https://stevenlsw.github.io/physgen/"
    },
    {
        "paper id": "2409.19097",
        "abstract url": "https://arxiv.org/abs/2409.19097",
        "title": "Implementing LLMs in industrial process modeling: Addressing Categorical Variables",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Important variables of processes are, in many occasions, categorical, i.e. names or labels representing, e.g. categories of inputs, or types of reactors or a sequence of steps. In this work, we use Large Language Models (LLMs) to derive embeddings of such inputs that represent their actual meaning, or reflect the ``distances\" between categories, i.e. how similar or dissimilar they are. This is a marked difference from the current standard practice of using binary, or one-hot encoding to replace categorical variables with sequences of ones and zeros. Combined with dimensionality reduction techniques, either linear such as Principal Components Analysis (PCA), or nonlinear such as Uniform Manifold Approximation and Projection (UMAP), the proposed approach leads to a \\textit{meaningful}, low-dimensional feature space. The significance of obtaining meaningful embeddings is illustrated in the context of an industrial coating process for cutting tools that includes both numerical and categorical inputs. The proposed approach enables feature importance which is a marked improvement compared to the current state-of-the-art (SotA) in the encoding of categorical variables.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19120",
        "abstract url": "https://arxiv.org/abs/2409.19120",
        "title": "Secure Multiparty Generative AI",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "As usage of generative AI tools skyrockets, the amount of sensitive information being exposed to these models and centralized model providers is alarming. For example, confidential source code from Samsung suffered a data leak as the text prompt to ChatGPT encountered data leakage. An increasing number of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan Chase, etc.) due to data leakage or confidentiality issues. Also, an increasing number of centralized generative model providers are restricting, filtering, aligning, or censoring what can be used. Midjourney and RunwayML, two of the major image generation platforms, restrict the prompts to their system via prompt filtering. Certain political figures are restricted from image generation, as well as words associated with women's health care, rights, and abortion. In our research, we present a secure and private methodology for generative artificial intelligence that does not expose sensitive data or models to third-party AI providers. Our work modifies the key building block of modern generative AI algorithms, e.g. the transformer, and introduces confidential and verifiable multiparty computations in a decentralized network to maintain the 1) privacy of the user input and obfuscation to the output of the model, and 2) introduce privacy to the model itself. Additionally, the sharding process reduces the computational burden on any one node, enabling the distribution of resources of large generative AI processes across multiple, smaller nodes. We show that as long as there exists one honest node in the decentralized computation, security is maintained. We also show that the inference process will still succeed if only a majority of the nodes in the computation are successful. Thus, our method offers both secure and verifiable computation in a decentralized network.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19136",
        "abstract url": "https://arxiv.org/abs/2409.19136",
        "title": "Kinematic Detection of Anomalies in Human Trajectory Data",
        "rating": "-1.5",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "anomaly detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Historically, much of the research in understanding, modeling, and mining human trajectory data has focused on where an individual stays. Thus, the focus of existing research has been on where a user goes. On the other hand, the study of how a user moves between locations has great potential for new research opportunities. Kinematic features describe how an individual moves between locations and can be used for tasks such as identification of individuals or anomaly detection. Unfortunately, data availability and quality challenges make kinematic trajectory mining difficult. In this paper, we leverage the Geolife dataset of human trajectories to investigate the viability of using kinematic features to identify individuals and detect anomalies. We show that humans have an individual \"kinematic profile\" which can be used as a strong signal to identify individual humans. We experimentally show that, for the two use-cases of individual identification and anomaly detection, simple kinematic features fed to standard classification and anomaly detection algorithms significantly improve results.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19138",
        "abstract url": "https://arxiv.org/abs/2409.19138",
        "title": "Sequencing the Neurome: Towards Scalable Exact Parameter Reconstruction of Black-Box Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Inferring the exact parameters of a neural network with only query access is an NP-Hard problem, with few practical existing algorithms. Solutions would have major implications for security, verification, interpretability, and understanding biological networks. The key challenges are the massive parameter space, and complex non-linear relationships between neurons. We resolve these challenges using two insights. First, we observe that almost all networks used in practice are produced by random initialization and first order optimization, an inductive bias that drastically reduces the practical parameter space. Second, we present a novel query generation algorithm that produces maximally informative samples, letting us untangle the non-linear relationships efficiently. We demonstrate reconstruction of a hidden network containing over 1.5 million parameters, and of one 7 layers deep, the largest and deepest reconstructions to date, with max parameter difference less than 0.0001, and illustrate robustness and scalability across a variety of architectures, datasets, and training procedures.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.IT",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19140",
        "abstract url": "https://arxiv.org/abs/2409.19140",
        "title": "Physics-Informed Echo State Networks for Modeling Controllable Dynamical Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Echo State Networks (ESNs) are recurrent neural networks usually employed for modeling nonlinear dynamic systems with relatively ease of training. By incorporating physical laws into the training of ESNs, Physics-Informed ESNs (PI-ESNs) were proposed initially to model chaotic dynamic systems without external inputs. They require less data for training since Ordinary Differential Equations (ODEs) of the considered system help to regularize the ESN. In this work, the PI-ESN is extended with external inputs to model controllable nonlinear dynamic systems. Additionally, an existing self-adaptive balancing loss method is employed to balance the contributions of the residual regression term and the physics-informed loss term in the total loss function. The experiments with two nonlinear systems modeled by ODEs, the Van der Pol oscillator and the four-tank system, and with one differential-algebraic (DAE) system, an electric submersible pump, revealed that the proposed PI-ESN outperforms the conventional ESN, especially in scenarios with limited data availability, showing that PI-ESNs can regularize an ESN model with external inputs previously trained on just a few datapoints, reducing its overfitting and improving its generalization error (up to 92% relative reduction in the test error). Further experiments demonstrated that the proposed PI-ESN is robust to parametric uncertainties in the ODE equations and that model predictive control using PI-ESN outperforms the one using plain ESN, particularly when training data is scarce.",
        "subjects": [
            "cs.LG",
            "cs.NE",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19142",
        "abstract url": "https://arxiv.org/abs/2409.19142",
        "title": "TTT4Rec: A Test-Time Training Approach for Rapid Adaption in Sequential Recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Sequential recommendation tasks, which aim to predict the next item a user will interact with, typically rely on models trained solely on historical data. However, in real-world scenarios, user behavior can fluctuate in the long interaction sequences, and training data may be limited to model this dynamics. To address this, Test-Time Training (TTT) offers a novel approach by using self-supervised learning during inference to dynamically update model parameters. This allows the model to adapt to new user interactions in real-time, leading to more accurate recommendations. In this paper, we propose TTT4Rec, a sequential recommendation framework that integrates TTT to better capture dynamic user behavior. By continuously updating model parameters during inference, TTT4Rec is particularly effective in scenarios where user interaction sequences are long, training data is limited, or user behavior is highly variable. We evaluate TTT4Rec on three widely-used recommendation datasets, demonstrating that it achieves performance on par with or exceeding state-of-the-art models. The codes are available at https://github.com/ZhaoqiZachYang/TTT4Rec.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19157",
        "abstract url": "https://arxiv.org/abs/2409.19157",
        "title": "Calibrated Probabilistic Forecasts for Arbitrary Sequences",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Real-world data streams can change unpredictably due to distribution shifts, feedback loops and adversarial actors, which challenges the validity of forecasts. We present a forecasting framework ensuring valid uncertainty estimates regardless of how data evolves. Leveraging the concept of Blackwell approachability from game theory, we introduce a forecasting framework that guarantees calibrated uncertainties for outcomes in any compact space (e.g., classification or bounded regression). We extend this framework to recalibrate existing forecasters, guaranteeing accurate uncertainties without sacrificing predictive performance. We implement both general-purpose gradient-based algorithms and algorithms optimized for popular special cases of our framework. Empirically, our algorithms improve calibration and downstream decision-making for energy systems.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18469",
        "abstract url": "https://arxiv.org/abs/2409.18469",
        "title": "Deciding Reachability in a Directed Graph given its Path Decomposition",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "Deciding if there exists a path from one vertex to another in a graph is known as the s-t connectivity or the reachability problem. Reachability can be solved using graph traversal algorithms like Depth First Search(DFS) or Breadth First Search(BFS) in linear time but these algorithms also take linear space. On the other hand, Savitch's algorithm solves the same problem using O(log^2 n) space but takes quasipolynomial time. A path decomposition P of a directed graph G is a collection of simple directed paths such that every edge of G lies on exactly one path in P. A minimal path decomposition of G is a path decomposition of G having the smallest number of paths possible and the number of paths in a minimal path decomposition of G is called the path number of G. We show that if a path decomposition P of a directed graph G consisting of k directed paths is provided, then reachability in G can be decided simultaneously in O(klog n) space and polynomial time. In fact, our result holds even when a walk decomposition is provided (instead of a path decomposition) where the graph is decomposed into k directed walks (instead of paths) and the walks are not necessarily edge-disjoint. We further show that a minimal path decomposition can be computed in logspace for directed acyclic graphs. This leads to the conclusion that reachability in directed acyclic graphs having bounded path number is logspace computable.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18476",
        "abstract url": "https://arxiv.org/abs/2409.18476",
        "title": "Underwater Image Enhancement with Physical-based Denoising Diffusion Implicit Models",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Underwater vision is crucial for autonomous underwater vehicles (AUVs), and enhancing degraded underwater images in real-time on a resource-constrained AUV is a key challenge due to factors like light absorption and scattering, or the sufficient model computational complexity to resolve such factors. Traditional image enhancement techniques lack adaptability to varying underwater conditions, while learning-based methods, particularly those using convolutional neural networks (CNNs) and generative adversarial networks (GANs), offer more robust solutions but face limitations such as inadequate enhancement, unstable training, or mode collapse. Denoising diffusion probabilistic models (DDPMs) have emerged as a state-of-the-art approach in image-to-image tasks but require intensive computational complexity to achieve the desired underwater image enhancement (UIE) using the recent UW-DDPM solution. To address these challenges, this paper introduces UW-DiffPhys, a novel physical-based and diffusion-based UIE approach. UW-DiffPhys combines light-computation physical-based UIE network components with a denoising U-Net to replace the computationally intensive distribution transformation U-Net in the existing UW-DDPM framework, reducing complexity while maintaining performance. Additionally, the Denoising Diffusion Implicit Model (DDIM) is employed to accelerate the inference process through non-Markovian sampling. Experimental results demonstrate that UW-DiffPhys achieved a substantial reduction in computational complexity and inference time compared to UW-DDPM, with competitive performance in key metrics such as PSNR, SSIM, UCIQE, and an improvement in the overall underwater image quality UIQM metric. The implementation code can be found at the following repository: https://github.com/bachzz/UW-DiffPhys",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18528",
        "abstract url": "https://arxiv.org/abs/2409.18528",
        "title": "Security Analysis of Top-Ranked mHealth Fitness Apps: An Empirical Study",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "Mobile health applications (mHealth apps), particularly in the health and fitness category, have experienced an increase in popularity due to their convenience and availability. However, this widespread adoption raises concerns regarding the security of the user's data. In this study, we investigate the security vulnerabilities of ten top-ranked Android health and fitness apps, a set that accounts for 237 million downloads. We performed several static and dynamic security analyses using tools such as the Mobile Security Framework (MobSF) and Android emulators. We also checked the server's security levels with Qualys SSL, which allowed us to gain insights into the security posture of the servers communicating with the mHealth fitness apps. Our findings revealed many vulnerabilities, such as insecure coding, hardcoded sensitive information, over-privileged permissions, misconfiguration, and excessive communication with third-party domains. For instance, some apps store their database API key directly in the code while also exposing their database URL. We found insecure encryption methods in six apps, such as using AES with ECB mode. Two apps communicated with an alarming number of approximately 230 domains each, and a third app with over 100 domains, exacerbating privacy linkability threats. The study underscores the importance of continuous security assessments of top-ranked mHealth fitness apps to better understand the threat landscape and inform app developers.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "19 pages, 2 figures, 8 tables, NordSec 2024"
    },
    {
        "paper id": "2409.18534",
        "abstract url": "https://arxiv.org/abs/2409.18534",
        "title": "Transformation of the discrete logarithm problem over $\\mathbb F_{2^n}$ to the QUBO problem using normal bases",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum computations are very important branch of modern cryptology. According to the number of working physical qubits available in general-purpose quantum computers and in quantum annealers, there is no coincidence, that nowadays quantum annealers allow to solve larger problems. In this paper we focus on solving discrete logarithm problem (DLP) over binary fields using quantum annealing. It is worth to note, that however solving DLP over prime fields using quantum annealing has been considered before, no author, until now, has considered DLP over binary fields using quantum annealing. Therefore, in this paper, we aim to bridge this gap. We present a polynomial transformation of the discrete logarithm problem over binary fields to the Quadratic Unconstrained Binary Optimization (QUBO) problem, using approximately $3n^2$ logical variables for the binary field $\\mathbb{F}_{2^n}$. In our estimations, we assume the existence of an optimal normal base of II type in the given fields. Such a QUBO instance can then be solved using quantum annealing.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This is the author's version of a post-conference paper from the CECC 2024 conference. The paper has been submitted for consideration to the International Journal of Electronics and Telecommunications"
    },
    {
        "paper id": "2409.18601",
        "abstract url": "https://arxiv.org/abs/2409.18601",
        "title": "Privacy-Preserving Quantum Annealing for Quadratic Unconstrained Binary Optimization (QUBO) Problems",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum annealers offer a promising approach to solve Quadratic Unconstrained Binary Optimization (QUBO) problems, which have a wide range of applications. However, when a user submits its QUBO problem to a third-party quantum annealer, the problem itself may disclose the user's private information to the quantum annealing service provider. To mitigate this risk, we introduce a privacy-preserving QUBO framework and propose a novel solution method. Our approach employs a combination of digit-wise splitting and matrix permutation to obfuscate the QUBO problem's model matrix $Q$, effectively concealing the matrix elements. In addition, based on the solution to the obfuscated version of the QUBO problem, we can reconstruct the solution to the original problem with high accuracy. Theoretical analysis and empirical tests confirm the efficacy and efficiency of our proposed technique, demonstrating its potential for preserving user privacy in quantum annealing services.",
        "subjects": [
            "cs.CR",
            "quant-ph"
        ],
        "comment": "8 pages, 3 figures, QCE 2024"
    },
    {
        "paper id": "2409.18612",
        "abstract url": "https://arxiv.org/abs/2409.18612",
        "title": "Libros en abierto de las editoriales universitarias espa\u00f1olas",
        "rating": "-2",
        "keywords": [
            [
                "diagnosis"
            ]
        ],
        "abstract": "This paper analyses the set of scientific publications in open access, other than journals (monographs, conferences proceedings, teaching materials and grey literature), published by Spanish public universities, studying their volume, documentary typology, level of description and open access policies with the aim of measuring their degree of incorporation and compliance with the principles of Open Science. An exhaustive review of the disposed material in open access by these publishers has been carried out, which has allowed to make a diagnosis of their level of open access publishing. Grey literature is the most common documentary type followed by the monograph, in the open publication of these publishers that does not reach even 5% of the average editorial production. The results allow us to conclude that the academic publishing, and more specifically the academic books in open access, still has a very reduced presence within the editorial production of these institutions.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "10 pages, in Spanish language, 3 figures, 4 tables"
    },
    {
        "paper id": "2409.18641",
        "abstract url": "https://arxiv.org/abs/2409.18641",
        "title": "Pseudo-kinematic trajectory control of tracked vehicles",
        "rating": "-2",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Tracked vehicles are used in complex scenarios, where motion planning and navigation can be very complex. They have complex dynamics, with many parameters that are difficult to identify and that change significantly based on the operating conditions. We propose a simple pseudo-kinematic model, where the intricate dynamic effects underlying the vehicle's motion are captured in a small set of velocity-dependent parameters. This choice enables the development of a Lyapunov-based trajectory controller with guaranteed performance and small computation time. We demonstrate the correctness of our approach with both simulation and experimental data.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18675",
        "abstract url": "https://arxiv.org/abs/2409.18675",
        "title": "Online and Utility-Power Efficient Task Scheduling in Homogeneous Fog Networks",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Fog computing is of particular interest to Internet of Things (IoT), where inexpensive simple devices can offload their computation tasks to nearby Fog Nodes. Online scheduling in such fog networks is challenging due to stochastic network states such as task arrivals, wireless channels and location of nodes. In this paper, we focus on the problem of optimizing computation offloading management, arrival data admission control and resource scheduling, in order to improve the overall system performance, in terms of throughput fairness, power efficiency, and average mean of queue backlogs. We investigate this problem for a fog network with homogeneous mobile Fog Nodes, serving multiple wireless devices, controlled by a Fog Control Node. By formulating the problem as a stochastic optimization problem, maximizing utility-power efficiency, defined as achievable utility per-unit power consumption, subject to queue backlog stability, we modify Lyapunov optimization techniques to deal with the fractional form of utility-power efficiency function. Then we propose an online utility-power efficient task scheduling algorithm, which is asymptotically optimal. Our online task scheduling algorithm can achieve the theoretical [O(1/V), O(V)] trade-off between utility-power efficiency and average mean of queue backlogs,",
        "subjects": [
            "cs.NI"
        ],
        "comment": "11 pages, 6 figures"
    },
    {
        "paper id": "2409.18690",
        "abstract url": "https://arxiv.org/abs/2409.18690",
        "title": "Less is More: Towards Sustainability-Aware Persuasive Explanations in Recommender Systems",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Recommender systems play an important role in supporting the achievement of the United Nations sustainable development goals (SDGs). In recommender systems, explanations can support different goals, such as increasing a user's trust in a recommendation, persuading a user to purchase specific items, or increasing the understanding of the reasons behind a recommendation. In this paper, we discuss the concept of \"sustainability-aware persuasive explanations\" which we regard as a major concept to support the achievement of the mentioned SDGs. Such explanations are orthogonal to most existing explanation approaches since they focus on a \"less is more\" principle, which per se is not included in existing e-commerce platforms. Based on a user study in three item domains, we analyze the potential impacts of sustainability-aware persuasive explanations. The study results are promising regarding user acceptance and the potential impacts of such explanations.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "The paper was accepted for publication and will be presented in the LBR track of RecSys 2024, 14.- 18. October 2024, Bari, Italy"
    },
    {
        "paper id": "2409.18701",
        "abstract url": "https://arxiv.org/abs/2409.18701",
        "title": "3DPX: Single Panoramic X-ray Analysis Guided by 3D Oral Structure Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "diagnosis",
                "X-ray",
                "lesion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Panoramic X-ray (PX) is a prevalent modality in dentistry practice owing to its wide availability and low cost. However, as a 2D projection of a 3D structure, PX suffers from anatomical information loss and PX diagnosis is limited compared to that with 3D imaging modalities. 2D-to-3D reconstruction methods have been explored for the ability to synthesize the absent 3D anatomical information from 2D PX for use in PX image analysis. However, there are challenges in leveraging such 3D synthesized reconstructions. First, inferring 3D depth from 2D images remains a challenging task with limited accuracy. The second challenge is the joint analysis of 2D PX with its 3D synthesized counterpart, with the aim to maximize the 2D-3D synergy while minimizing the errors arising from the synthesized image. In this study, we propose a new method termed 3DPX - PX image analysis guided by 2D-to-3D reconstruction, to overcome these challenges. 3DPX consists of (i) a novel progressive reconstruction network to improve 2D-to-3D reconstruction and, (ii) a contrastive-guided bidirectional multimodality alignment module for 3D-guided 2D PX classification and segmentation tasks. The reconstruction network progressively reconstructs 3D images with knowledge imposed on the intermediate reconstructions at multiple pyramid levels and incorporates Multilayer Perceptrons to improve semantic understanding. The downstream networks leverage the reconstructed images as 3D anatomical guidance to the PX analysis through feature alignment, which increases the 2D-3D synergy with bidirectional feature projection and decease the impact of potential errors with contrastive guidance. Extensive experiments on two oral datasets involving 464 studies demonstrate that 3DPX outperforms the state-of-the-art methods in various tasks including 2D-to-3D reconstruction, PX classification and lesion segmentation.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18707",
        "abstract url": "https://arxiv.org/abs/2409.18707",
        "title": "Discrete Policy: Learning Disentangled Action Space for Multi-Task Robotic Manipulation",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robotics",
                "robot",
                "Robotic Manipulation"
            ]
        ],
        "abstract": "Learning visuomotor policy for multi-task robotic manipulation has been a long-standing challenge for the robotics community. The difficulty lies in the diversity of action space: typically, a goal can be accomplished in multiple ways, resulting in a multimodal action distribution for a single task. The complexity of action distribution escalates as the number of tasks increases. In this work, we propose \\textbf{Discrete Policy}, a robot learning method for training universal agents capable of multi-task manipulation skills. Discrete Policy employs vector quantization to map action sequences into a discrete latent space, facilitating the learning of task-specific codes. These codes are then reconstructed into the action space conditioned on observations and language instruction. We evaluate our method on both simulation and multiple real-world embodiments, including both single-arm and bimanual robot settings. We demonstrate that our proposed Discrete Policy outperforms a well-established Diffusion Policy baseline and many state-of-the-art approaches, including ACT, Octo, and OpenVLA. For example, in a real-world multi-task training setting with five tasks, Discrete Policy achieves an average success rate that is 26\\% higher than Diffusion Policy and 15\\% higher than OpenVLA. As the number of tasks increases to 12, the performance gap between Discrete Policy and Diffusion Policy widens to 32.5\\%, further showcasing the advantages of our approach. Our work empirically demonstrates that learning multi-task policies within the latent space is a vital step toward achieving general-purpose agents.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18731",
        "abstract url": "https://arxiv.org/abs/2409.18731",
        "title": "A Generalized Tensor Formulation for Hyperspectral Image Super-Resolution Under General Spatial Blurring",
        "rating": "-2",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "Hyperspectral Image"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Hyperspectral super-resolution is commonly accomplished by the fusing of a hyperspectral imaging of low spatial resolution with a multispectral image of high spatial resolution, and many tensor-based approaches to this task have been recently proposed. Yet, it is assumed in such tensor-based methods that the spatial-blurring operation that creates the observed hyperspectral image from the desired super-resolved image is separable into independent horizontal and vertical blurring. Recent work has argued that such separable spatial degradation is ill-equipped to model the operation of real sensors which may exhibit, for example, anisotropic blurring. To accommodate this fact, a generalized tensor formulation based on a Kronecker decomposition is proposed to handle any general spatial-degradation matrix, including those that are not separable as previously assumed. Analysis of the generalized formulation reveals conditions under which exact recovery of the desired super-resolved image is guaranteed, and a practical algorithm for such recovery, driven by a blockwise-group-sparsity regularization, is proposed. Extensive experimental results demonstrate that the proposed generalized tensor approach outperforms not only traditional matrix-based techniques but also state-of-the-art tensor-based methods; the gains with respect to the latter are especially significant in cases of anisotropic spatial blurring.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18745",
        "abstract url": "https://arxiv.org/abs/2409.18745",
        "title": "A study on the effects of mixed explicit and implicit communications in human-virtual-agent interactions",
        "rating": "-2",
        "keywords": [
            [
                "facial"
            ]
        ],
        "abstract": "Communication between humans and robots (or virtual agents) is essential for interaction and often inspired by human communication, which uses gestures, facial expressions, gaze direction, and other explicit and implicit means. This work presents an interaction experiment where humans and virtual agents interact through explicit (gestures, manual entries using mouse and keyboard, voice, sound, and information on screen) and implicit (gaze direction, location, facial expressions, and raise of eyebrows) communication to evaluate the effect of mixed explicit-implicit communication against purely explicit communication. Results obtained using Bayesian parameter estimation show that the number of errors and task execution time did not significantly change when mixed explicit and implicit communications were used, and neither the perceived efficiency of the interaction. In contrast, acceptance, sociability, and transparency of the virtual agent increased when using mixed communication modalities (88.3%, 92%, and 92.9% of the effect size posterior distribution of each variable, respectively, were above the upper limit of the region of practical equivalence). This suggests that task-related measures, such as time, number of errors, and perceived efficiency of the interaction, have not been influenced by the communication type in our particular experiment. However, the improvement of subjective measures related to the virtual agent, such as acceptance, sociability, and transparency, suggests that humans are more receptive to mixed explicit and implicit communications.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Main paper with 22 pages, 12 figures, 4 tables. Added supplementary material with 17 pages, 16 figures. Submitted to International Journal of Social Robotics"
    },
    {
        "paper id": "2409.18752",
        "abstract url": "https://arxiv.org/abs/2409.18752",
        "title": "Royal Reveals: LiDAR Mapping of Kronborg Castle, Echoes of Hamlet's Halls",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "LiDAR",
                "SLAM"
            ]
        ],
        "abstract": "This paper presents a large scale dataset from a meticulous 360-degree LiDAR (Light Detection and Ranging) scan conducted on Kronborg Castle, a renowned Renaissance fortress located in Elsinore (Helsing\u00f8r), Denmark, famously associated with Shakespeare's \"Hamlet.\" Utilising a vertical mounted, gimbal stabilised, 16 channel, 360-degree Velodyne VLP-16 LiDAR scanner, paired with an Intel RealSense L515 depth camera. This research offers an unparalleled digital representation of the castle's intricate architectural details and structural nuances, enabling fellow researchers to conduct experiments utilising the data for SLAM (Simultaneous Localisation and Mapping) as well as floorplan generation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "4 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2409.18806",
        "abstract url": "https://arxiv.org/abs/2409.18806",
        "title": "Path Following Model Predictive Control of a Coupled Autonomous Underwater Vehicle",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Vehicle"
            ]
        ],
        "abstract": "The operation of an autonomous underwater vehicle (AUV) faces challenges in following predetermined waypoints due to coupled motions under environmental disturbances. To address this, a 3D path following guidance and control system is developed in this work based on the line-of-sight (LOS) guidance method. Conventionally, the 3D path following problem is transformed into heading and depth control problems, assuming that the motion of the vehicle is decoupled in horizontal and depth coordinates. The proposed control system design avoids this simplifying assumption by transforming the problem into a 3D position and orientation tracking problem. This design is achieved by computing a 2D horizontal coordinate based on the desired heading and then computing a corresponding LOS depth coordinate. A model predictive controller (MPC) is then implemented using the 3D LOS coordinate and the computed orientation vector. The MPC obtains a robust control by solving a minimax optimisation problem considering the effects of unknown ocean disturbances. The effectiveness of the proposed guidance and control system is demonstrated through the simulation of a prototype AUV system. Numerical results show that the AUV can follow predetermined waypoints in the presence of time-varying disturbances, and the system is steered at a constant surge speed that is proportional to the radius of the circle of acceptance used to implement the guidance system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages, 4 figures, Presented at the IFAC CAMS 2024, Virginia, USA"
    },
    {
        "paper id": "2409.18811",
        "abstract url": "https://arxiv.org/abs/2409.18811",
        "title": "Moldable Development Patterns",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Moldable development supports decision-making by making software systems explainable. This is done by making it cheap to add numerous custom tools to your software, turning it into a live, explorable domain model. Based on several years of experience of applying moldable development to both open-source and industrial systems, we have identified several mutually supporting patterns to explain how moldable development works in practice. This paper targets (i) readers curious to learn about moldable development, (ii) current users of the Glamorous Toolkit moldable IDE wanting to learn best practices, and (iii) developers interested in applying moldable development using other platforms and technology.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18813",
        "abstract url": "https://arxiv.org/abs/2409.18813",
        "title": "EyeTrAES: Fine-grained, Low-Latency Eye Tracking via Adaptive Event Slicing",
        "rating": "-2",
        "keywords": [
            [
                "event cameras"
            ],
            [
                "biometric",
                "health"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Eye-tracking technology has gained significant attention in recent years due to its wide range of applications in human-computer interaction, virtual and augmented reality, and wearable health. Traditional RGB camera-based eye-tracking systems often struggle with poor temporal resolution and computational constraints, limiting their effectiveness in capturing rapid eye movements. To address these limitations, we propose EyeTrAES, a novel approach using neuromorphic event cameras for high-fidelity tracking of natural pupillary movement that shows significant kinematic variance. One of EyeTrAES's highlights is the use of a novel adaptive windowing/slicing algorithm that ensures just the right amount of descriptive asynchronous event data accumulation within an event frame, across a wide range of eye movement patterns. EyeTrAES then applies lightweight image processing functions over accumulated event frames from just a single eye to perform pupil segmentation and tracking. We show that these methods boost pupil tracking fidelity by 6+%, achieving IoU~=92%, while incurring at least 3x lower latency than competing pure event-based eye tracking alternatives [38]. We additionally demonstrate that the microscopic pupillary motion captured by EyeTrAES exhibits distinctive variations across individuals and can thus serve as a biometric fingerprint. For robust user authentication, we train a lightweight per-user Random Forest classifier using a novel feature vector of short-term pupillary kinematics, comprising a sliding window of pupil (location, velocity, acceleration) triples. Experimental studies with two different datasets demonstrate that the EyeTrAES-based authentication technique can simultaneously achieve high authentication accuracy (~=0.82) and low processing latency (~=12ms), and significantly outperform multiple state-of-the-art competitive baselines.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "comment": "32 pages,15 figures,"
    },
    {
        "paper id": "2409.18821",
        "abstract url": "https://arxiv.org/abs/2409.18821",
        "title": "Data Generation for Testing Complex Queries",
        "rating": "-2",
        "keywords": [
            [
                "SQL"
            ]
        ],
        "abstract": "Generation of sample data for testing SQL queries has been an important task for many years, with applications such as testing of SQL queries used for data analytics and in application software, as well as student SQL queries. More recently, with the increasing use of text-to-SQL systems, test data is key for the validation of generated queries. Earlier work for test data generation handled basic single block SQL queries, as well as simple nested SQL queries, but could not handle more complex queries. In this paper, we present a novel data generation approach that is designed to handle complex queries, and show its effectiveness on queries for which the earlier XData approach is not as effective. We also show that it can outperform the state-of-the-art VeriEQL system in showing non-equivalence of queries.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18897",
        "abstract url": "https://arxiv.org/abs/2409.18897",
        "title": "Detecting Dataset Abuse in Fine-Tuning Stable Diffusion Models for Text-to-Image Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "watermarking"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image synthesis has become highly popular for generating realistic and stylized images, often requiring fine-tuning generative models with domain-specific datasets for specialized tasks. However, these valuable datasets face risks of unauthorized usage and unapproved sharing, compromising the rights of the owners. In this paper, we address the issue of dataset abuse during the fine-tuning of Stable Diffusion models for text-to-image synthesis. We present a dataset watermarking framework designed to detect unauthorized usage and trace data leaks. The framework employs two key strategies across multiple watermarking schemes and is effective for large-scale dataset authorization. Extensive experiments demonstrate the framework's effectiveness, minimal impact on the dataset (only 2% of the data required to be modified for high detection accuracy), and ability to trace data leaks. Our results also highlight the robustness and transferability of the framework, proving its practical applicability in detecting dataset abuse.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18899",
        "abstract url": "https://arxiv.org/abs/2409.18899",
        "title": "Unsupervised Low-light Image Enhancement with Lookup Tables and Diffusion Priors",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Image Enhancement"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Low-light image enhancement (LIE) aims at precisely and efficiently recovering an image degraded in poor illumination environments. Recent advanced LIE techniques are using deep neural networks, which require lots of low-normal light image pairs, network parameters, and computational resources. As a result, their practicality is limited. In this work, we devise a novel unsupervised LIE framework based on diffusion priors and lookup tables (DPLUT) to achieve efficient low-light image recovery. The proposed approach comprises two critical components: a light adjustment lookup table (LLUT) and a noise suppression lookup table (NLUT). LLUT is optimized with a set of unsupervised losses. It aims at predicting pixel-wise curve parameters for the dynamic range adjustment of a specific image. NLUT is designed to remove the amplified noise after the light brightens. As diffusion models are sensitive to noise, diffusion priors are introduced to achieve high-performance noise suppression. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods in terms of visual quality and efficiency.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "13 pages, 10 figures"
    },
    {
        "paper id": "2409.19058",
        "abstract url": "https://arxiv.org/abs/2409.19058",
        "title": "CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Forecasting weather and climate events is crucial for making appropriate measures to mitigate environmental hazards and minimize associated losses. Previous research on environmental forecasting focuses on predicting numerical meteorological variables related to closed-set events rather than forecasting open-set events directly, which limits the comprehensiveness of event forecasting. We propose Weather and Climate Event Forecasting (WCEF), a new task that leverages meteorological raster data and textual event data to predict potential weather and climate events. However, due to difficulties in aligning multimodal data and the lack of sufficient supervised datasets, this task is challenging to accomplish. Therefore, we first propose a framework to align historical meteorological data with past weather and climate events using the large language model (LLM). In this framework, we construct a knowledge graph by using LLM to extract information about weather and climate events from a corpus of over 41k highly environment-focused news articles. Subsequently, we mapped these events with meteorological raster data, creating a supervised dataset, which is the largest and most novel for LLM tuning on the WCEF task. Finally, we introduced our aligned models, CLLMate (LLM for climate), a multimodal LLM to forecast weather and climate events using meteorological raster data. In evaluating CLLMate, we conducted extensive experiments. The results indicate that CLLMate surpasses both the baselines and other multimodal LLMs, showcasing the potential of utilizing LLM to align weather and climate events with meteorological data and highlighting the promising future for research on the WCEF task.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19100",
        "abstract url": "https://arxiv.org/abs/2409.19100",
        "title": "Outlining the Borders for LLM Applications in Patient Education: Developing an Expert-in-the-Loop LLM-Powered Chatbot for Prostate Cancer Patient Education",
        "rating": "-2",
        "keywords": [
            [
                "health",
                "healthcare",
                "Cancer"
            ]
        ],
        "abstract": "Cancer patients often struggle to transition swiftly to treatment due to limited institutional resources, lack of sophisticated professional guidance, and low health literacy. The emergence of Large Language Models (LLMs) offers new opportunities for such patients to access the wealth of existing patient education materials. The current paper presents the development process for an LLM-based chatbot focused on prostate cancer education, including needs assessment, co-design, and usability studies. The resulting application, MedEduChat, integrates with patients' electronic health record data and features a closed-domain, semi-structured, patient-centered approach to address real-world needs. This paper contributes to the growing field of patient-LLM interaction by demonstrating the potential of LLM-based chatbots to enhance prostate cancer patient education and by offering co-design guidelines for future LLM-based healthcare downstream applications.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19110",
        "abstract url": "https://arxiv.org/abs/2409.19110",
        "title": "S-RRT*-based Obstacle Avoidance Autonomous Motion Planner for Continuum-rigid Manipulator",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "Continuum robots are compact and flexible, making them suitable for use in the industries and in medical surgeries. Rapidly-exploring random trees (RRT) are a highly efficient path planning method, and its variant, S-RRT, can generate smooth feasible paths for the end-effector. By combining RRT with inverse instantaneous kinematics (IIK), complete motion planning for the continuum arm can be achieved. Due to the high degrees of freedom of continuum arms, the null space in IIK can be utilized for obstacle avoidance. In this work, we propose a novel approach that uses the S-RRT* algorithm to create paths for the continuum-rigid manipulator. By employing IIK and null space techniques, continuous joint configurations are generated that not only track the path but also enable obstacle avoidance. Simulation results demonstrate that our method effectively handles motion planning and obstacle avoidance while generating high-quality end-effector paths in complex environments. Furthermore, compared to similar IIK methods, our approach exhibits superior computation time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19111",
        "abstract url": "https://arxiv.org/abs/2409.19111",
        "title": "Fusion is all you need: Face Fusion for Customized Identity-Preserving Image Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "Text-to-image"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image (T2I) models have significantly advanced the development of artificial intelligence, enabling the generation of high-quality images in diverse contexts based on specific text prompts. However, existing T2I-based methods often struggle to accurately reproduce the appearance of individuals from a reference image and to create novel representations of those individuals in various settings. To address this, we leverage the pre-trained UNet from Stable Diffusion to incorporate the target face image directly into the generation process. Our approach diverges from prior methods that depend on fixed encoders or static face embeddings, which often fail to bridge encoding gaps. Instead, we capitalize on UNet's sophisticated encoding capabilities to process reference images across multiple scales. By innovatively altering the cross-attention layers of the UNet, we effectively fuse individual identities into the generative process. This strategic integration of facial features across various scales not only enhances the robustness and consistency of the generated images but also facilitates efficient multi-reference and multi-identity generation. Our method sets a new benchmark in identity-preserving image generation, delivering state-of-the-art results in similarity metrics while maintaining prompt alignment.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19115",
        "abstract url": "https://arxiv.org/abs/2409.19115",
        "title": "Identifying Key Genes in Cancer Networks Using Persistent Homology",
        "rating": "-2",
        "keywords": [
            [
                "biological",
                "Cancer",
                "DNA"
            ]
        ],
        "abstract": "Identifying driver genes is crucial for understanding oncogenesis and developing targeted cancer therapies. Driver discovery methods using protein or pathway networks rely on traditional network science measures, focusing on nodes, edges, or community metrics. These methods can overlook the high-dimensional interactions that cancer genes have within cancer networks. This study presents a novel method using Persistent Homology to analyze the role of driver genes in higher-order structures within Cancer Consensus Networks derived from main cellular pathways. We integrate mutation data from six cancer types and three biological functions: DNA Repair, Chromatin Organization, and Programmed Cell Death. We systematically evaluated the impact of gene removal on topological voids ($\u03b2_2$ structures) within the Cancer Consensus Networks. Our results reveal that only known driver genes and cancer-associated genes influence these structures, while passenger genes do not. Although centrality measures alone proved insufficient to fully characterize impact genes, combining higher-order topological analysis with traditional network metrics can improve the precision of distinguishing between drivers and passengers. This work shows that cancer genes play an important role in higher-order structures, going beyond pairwise measures, and provides an approach to distinguish drivers and cancer-associated genes from passenger genes.",
        "subjects": [
            "q-bio.MN",
            "cs.OH"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19121",
        "abstract url": "https://arxiv.org/abs/2409.19121",
        "title": "Towards Energy- and Cost-Efficient 6G Networks",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "As the world enters the journey toward the 6th generation (6G) of wireless technology, the promises of ultra-high data rates, unprecedented low latency, and a massive surge in connected devices require crucial exploration of network energy saving (NES) solutions to minimize the carbon footprint and overall energy usage of future cellular networks. On the other hand, network-controlled repeaters (NCRs) have been introduced by 3rd generation partnership project (3GPP) as a cost-effective solution to improve network coverage. However, their impact on network power consumption and energy efficiency has not been thoroughly investigated. This paper studies NES schemes for next-generation 6G networks aided by NCRs and proposes optimal NES strategies aiming at maximizing the overall energy efficiency of the network. Repeaters are shown to allow for power savings at next-generation nodeB (gNB), and offer higher overall energy efficiency (EE) and spectral efficiency (SE), thus providing an energy-efficient and cost-efficient alternative to increase the performance of future 6G networks",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": "7 pages, conference"
    },
    {
        "paper id": "2409.19134",
        "abstract url": "https://arxiv.org/abs/2409.19134",
        "title": "Confidential Prompting: Protecting User Prompts from Cloud LLM Providers",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Our work tackles the challenge of securing user inputs in cloud-based large language model (LLM) services while ensuring output consistency, model confidentiality, and compute efficiency. We introduce Secure Multi-party Decoding (SMD), which leverages confidential computing to confine user prompts to a trusted execution environment, namely a confidential virtual machine (CVM), while allowing service providers to generate tokens efficiently. We also introduce a novel cryptographic method, Prompt Obfuscation (PO), to ensure robustness against reconstruction attacks on SMD. We demonstrate that our approach preserves both prompt confidentiality and LLM serving efficiency. Our solution can enable privacy-preserving cloud LLM services that handle sensitive prompts, such as clinical records, financial data, and personal information.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19143",
        "abstract url": "https://arxiv.org/abs/2409.19143",
        "title": "Diverse Code Query Learning for Speech-Driven Facial Animation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Speech-driven facial animation aims to synthesize lip-synchronized 3D talking faces following the given speech signal. Prior methods to this task mostly focus on pursuing realism with deterministic systems, yet characterizing the potentially stochastic nature of facial motions has been to date rarely studied. While generative modeling approaches can easily handle the one-to-many mapping by repeatedly drawing samples, ensuring a diverse mode coverage of plausible facial motions on small-scale datasets remains challenging and less explored. In this paper, we propose predicting multiple samples conditioned on the same audio signal and then explicitly encouraging sample diversity to address diverse facial animation synthesis. Our core insight is to guide our model to explore the expressive facial latent space with a diversity-promoting loss such that the desired latent codes for diversification can be ideally identified. To this end, building upon the rich facial prior learned with vector-quantized variational auto-encoding mechanism, our model temporally queries multiple stochastic codes which can be flexibly decoded into a diverse yet plausible set of speech-faithful facial motions. To further allow for control over different facial parts during generation, the proposed model is designed to predict different facial portions of interest in a sequential manner, and compose them to eventually form full-face motions. Our paradigm realizes both diverse and controllable facial animation synthesis in a unified formulation. We experimentally demonstrate that our method yields state-of-the-art performance both quantitatively and qualitatively, especially regarding sample diversity.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19169",
        "abstract url": "https://arxiv.org/abs/2409.19169",
        "title": "TwinCL: A Twin Graph Contrastive Learning Model for Collaborative Filtering",
        "rating": "-2",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Graph"
            ],
            [
                "recommendation"
            ]
        ],
        "abstract": "In the domain of recommendation and collaborative filtering, Graph Contrastive Learning (GCL) has become an influential approach. Nevertheless, the reasons for the effectiveness of contrastive learning are still not well understood. In this paper, we challenge the conventional use of random augmentations on graph structure or embedding space in GCL, which may disrupt the structural and semantic information inherent in Graph Neural Networks. Moreover, fixed-rate data augmentation proves to be less effective compared to augmentation with an adaptive rate. In the initial training phases, significant perturbations are more suitable, while as the training approaches convergence, milder perturbations yield better results. We introduce a twin encoder in place of random augmentations, demonstrating the redundancy of traditional augmentation techniques. The twin encoder updating mechanism ensures the generation of more diverse contrastive views in the early stages, transitioning to views with greater similarity as training progresses. In addition, we investigate the learned representations from the perspective of alignment and uniformity on a hypersphere to optimize more efficiently. Our proposed Twin Graph Contrastive Learning model -- TwinCL -- aligns positive pairs of user and item embeddings and the representations from the twin encoder while maintaining the uniformity of the embeddings on the hypersphere. Our theoretical analysis and experimental results show that the proposed model optimizing alignment and uniformity with the twin encoder contributes to better recommendation accuracy and training efficiency performance. In comprehensive experiments on three public datasets, our proposed TwinCL achieves an average improvement of 5.6% (NDCG@10) in recommendation accuracy with faster training speed, while effectively mitigating popularity bias.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19213",
        "abstract url": "https://arxiv.org/abs/2409.19213",
        "title": "Feature-Prescribed Iterative Learning Control of Waggle Dance Movement for Social Motor Coordination in Joint Actions",
        "rating": "-2",
        "keywords": [
            [
                "clinical"
            ]
        ],
        "abstract": "Extensive experiments suggest that motor coordination among human participants may contribute to social affinity and emotional attachment, which has great potential in the clinical treatment of social disorders or schizophrenia. Mirror game provides an effective experimental paradigm for studying social motor coordination. Nevertheless, the lack of movement richness prevents the emergence of high-level coordination in the existing one-dimensional experiments. To tackle this problem, this work develops a two-dimensional experimental paradigm of mirror game by playing waggle dance between two participants. In particular, an online control architecture of customized virtual player is created to coordinate with human player. Therein, an iterative learning control algorithm is proposed by integrating position tracking and behavior imitation with prescribed kinematic feature. Moreover, convergence analysis of control algorithm is conducted to guarantee the online performance of virtual player. Finally, the proposed control strategy is validated by matching experimental data and compared with other control methods using a set of performance indexes.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18462",
        "abstract url": "https://arxiv.org/abs/2409.18462",
        "title": "Latent Representation Learning for Multimodal Brain Activity Translation",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "fMRI",
                "EEG",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neuroscience employs diverse neuroimaging techniques, each offering distinct insights into brain activity, from electrophysiological recordings such as EEG, which have high temporal resolution, to hemodynamic modalities such as fMRI, which have increased spatial precision. However, integrating these heterogeneous data sources remains a challenge, which limits a comprehensive understanding of brain function. We present the Spatiotemporal Alignment of Multimodal Brain Activity (SAMBA) framework, which bridges the spatial and temporal resolution gaps across modalities by learning a unified latent space free of modality-specific biases. SAMBA introduces a novel attention-based wavelet decomposition for spectral filtering of electrophysiological recordings, graph attention networks to model functional connectivity between functional brain units, and recurrent layers to capture temporal autocorrelations in brain signal. We show that the training of SAMBA, aside from achieving translation, also learns a rich representation of brain information processing. We showcase this classify external stimuli driving brain activity from the representation learned in hidden layers of SAMBA, paving the way for broad downstream applications in neuroscience research and clinical contexts.",
        "subjects": [
            "cs.LG",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18467",
        "abstract url": "https://arxiv.org/abs/2409.18467",
        "title": "A TextGCN-Based Decoding Approach for Improving Remote Sensing Image Captioning",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Remote sensing images are highly valued for their ability to address complex real-world issues such as risk management, security, and meteorology. However, manually captioning these images is challenging and requires specialized knowledge across various domains. This letter presents an approach for automatically describing (captioning) remote sensing images. We propose a novel encoder-decoder setup that deploys a Text Graph Convolutional Network (TextGCN) and multi-layer LSTMs. The embeddings generated by TextGCN enhance the decoder's understanding by capturing the semantic relationships among words at both the sentence and corpus levels. Furthermore, we advance our approach with a comparison-based beam search method to ensure fairness in the search strategy for generating the final caption. We present an extensive evaluation of our approach against various other state-of-the-art encoder-decoder frameworks. We evaluated our method across three datasets using seven metrics: BLEU-1 to BLEU-4, METEOR, ROUGE-L, and CIDEr. The results demonstrate that our approach significantly outperforms other state-of-the-art encoder-decoder methods.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2409.18491",
        "abstract url": "https://arxiv.org/abs/2409.18491",
        "title": "Treating Brain-inspired Memories as Priors for Diffusion Model to Forecast Multivariate Time Series",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Forecast"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Forecasting Multivariate Time Series (MTS) involves significant challenges in various application domains. One immediate challenge is modeling temporal patterns with the finite length of the input. These temporal patterns usually involve periodic and sudden events that recur across different channels. To better capture temporal patterns, we get inspiration from humans' memory mechanisms and propose a channel-shared, brain-inspired memory module for MTS. Specifically, brain-inspired memory comprises semantic and episodic memory, where the former is used to capture general patterns, such as periodic events, and the latter is employed to capture special patterns, such as sudden events, respectively. Meanwhile, we design corresponding recall and update mechanisms to better utilize these patterns. Furthermore, acknowledging the capacity of diffusion models to leverage memory as a prior, we present a brain-inspired memory-augmented diffusion model. This innovative model retrieves relevant memories for different channels, utilizing them as distinct priors for MTS predictions. This incorporation significantly enhances the accuracy and robustness of predictions. Experimental results on eight datasets consistently validate the superiority of our approach in capturing and leveraging diverse recurrent temporal patterns across different channels.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18611",
        "abstract url": "https://arxiv.org/abs/2409.18611",
        "title": "Differentially Private Non Parametric Copulas: Generating synthetic data with non parametric copulas under privacy guarantees",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Creation of synthetic data models has represented a significant advancement across diverse scientific fields, but this technology also brings important privacy considerations for users. This work focuses on enhancing a non-parametric copula-based synthetic data generation model, DPNPC, by incorporating Differential Privacy through an Enhanced Fourier Perturbation method. The model generates synthetic data for mixed tabular databases while preserving privacy. We compare DPNPC with three other models (PrivBayes, DP-Copula, and DP-Histogram) across three public datasets, evaluating privacy, utility, and execution time. DPNPC outperforms others in modeling multivariate dependencies, maintaining privacy for small $\u03b5$ values, and reducing training times. However, limitations include the need to assess the model's performance with different encoding methods and consider additional privacy attacks. Future research should address these areas to enhance privacy-preserving synthetic data generation.",
        "subjects": [
            "cs.LG",
            "cs.DB"
        ],
        "comment": "12 pages, 5 figures, deciding 2025 conference to which to submit"
    },
    {
        "paper id": "2409.18692",
        "abstract url": "https://arxiv.org/abs/2409.18692",
        "title": "MG-Net: Learn to Customize QAOA with Circuit Depth Awareness",
        "rating": "-2.5",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Quantum Approximate Optimization Algorithm (QAOA) and its variants exhibit immense potential in tackling combinatorial optimization challenges. However, their practical realization confronts a dilemma: the requisite circuit depth for satisfactory performance is problem-specific and often exceeds the maximum capability of current quantum devices. To address this dilemma, here we first analyze the convergence behavior of QAOA, uncovering the origins of this dilemma and elucidating the intricate relationship between the employed mixer Hamiltonian, the specific problem at hand, and the permissible maximum circuit depth. Harnessing this understanding, we introduce the Mixer Generator Network (MG-Net), a unified deep learning framework adept at dynamically formulating optimal mixer Hamiltonians tailored to distinct tasks and circuit depths. Systematic simulations, encompassing Ising models and weighted Max-Cut instances with up to 64 qubits, substantiate our theoretical findings, highlighting MG-Net's superior performance in terms of both approximation ratio and efficiency.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "29 pages, 16 figures"
    },
    {
        "paper id": "2409.18778",
        "abstract url": "https://arxiv.org/abs/2409.18778",
        "title": "HardCore Generation: Generating Hard UNSAT Problems for Data Augmentation",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Efficiently determining the satisfiability of a boolean equation -- known as the SAT problem for brevity -- is crucial in various industrial problems. Recently, the advent of deep learning methods has introduced significant potential for enhancing SAT solving. However, a major barrier to the advancement of this field has been the scarcity of large, realistic datasets. The majority of current public datasets are either randomly generated or extremely limited, containing only a few examples from unrelated problem families. These datasets are inadequate for meaningful training of deep learning methods. In light of this, researchers have started exploring generative techniques to create data that more accurately reflect SAT problems encountered in practical situations. These methods have so far suffered from either the inability to produce challenging SAT problems or time-scalability obstacles. In this paper we address both by identifying and manipulating the key contributors to a problem's ``hardness'', known as cores. Although some previous work has addressed cores, the time costs are unacceptably high due to the expense of traditional heuristic core detection techniques. We introduce a fast core detection procedure that uses a graph neural network. Our empirical results demonstrate that we can efficiently generate problems that remain hard to solve and retain key attributes of the original example problems. We show via experiment that the generated synthetic SAT problems can be used in a data augmentation setting to provide improved prediction of solver runtimes.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18828",
        "abstract url": "https://arxiv.org/abs/2409.18828",
        "title": "MECG-E: Mamba-based ECG Enhancer for Baseline Wander Removal",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "diagnosing",
                "disease"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Electrocardiogram (ECG) is an important non-invasive method for diagnosing cardiovascular disease. However, ECG signals are susceptible to noise contamination, such as electrical interference or signal wandering, which reduces diagnostic accuracy. Various ECG denoising methods have been proposed, but most existing methods yield suboptimal performance under very noisy conditions or require several steps during inference, leading to latency during online processing. In this paper, we propose a novel ECG denoising model, namely Mamba-based ECG Enhancer (MECG-E), which leverages the Mamba architecture known for its fast inference and outstanding nonlinear mapping capabilities. Experimental results indicate that MECG-E surpasses several well-known existing models across multiple metrics under different noise conditions. Additionally, MECG-E requires less inference time than state-of-the-art diffusion-based ECG denoisers, demonstrating the model's functionality and efficiency.",
        "subjects": [
            "eess.SP",
            "cs.AI"
        ],
        "comment": "7 pages, 5 figures"
    },
    {
        "paper id": "2409.18874",
        "abstract url": "https://arxiv.org/abs/2409.18874",
        "title": "CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting",
        "rating": "-2.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Anomaly detection in network traffic is crucial for maintaining the security of computer networks and identifying malicious activities. One of the primary approaches to anomaly detection are methods based on forecasting. Nevertheless, extensive real-world network datasets for forecasting and anomaly detection techniques are missing, potentially causing performance overestimation of anomaly detection algorithms. This manuscript addresses this gap by introducing a dataset comprising time series data of network entities' behavior, collected from the CESNET3 network. The dataset was created from 40 weeks of network traffic of 275 thousand active IP addresses. The ISP origin of the presented data ensures a high level of variability among network entities, which forms a unique and authentic challenge for forecasting and anomaly detection models. It provides valuable insights into the practical deployment of forecast-based anomaly detection approaches.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18458",
        "abstract url": "https://arxiv.org/abs/2409.18458",
        "title": "Enhancing Crime Scene Investigations through Virtual Reality and Deep Learning Techniques",
        "rating": "-3",
        "keywords": [
            [
                "health"
            ],
            [
                "Crime"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The analysis of a crime scene is a pivotal activity in forensic investigations. Crime Scene Investigators and forensic science practitioners rely on best practices, standard operating procedures, and critical thinking, to produce rigorous scientific reports to document the scenes of interest and meet the quality standards expected in the courts. However, crime scene examination is a complex and multifaceted task often performed in environments susceptible to deterioration, contamination, and alteration, despite the use of contact-free and non-destructive methods of analysis. In this context, the documentation of the sites, and the identification and isolation of traces of evidential value remain challenging endeavours. In this paper, we propose a photogrammetric reconstruction of the crime scene for inspection in virtual reality (VR) and focus on fully automatic object recognition with deep learning (DL) algorithms through a client-server architecture. A pre-trained Faster-RCNN model was chosen as the best method that can best categorize relevant objects at the scene, selected by experts in the VR environment. These operations can considerably improve and accelerate crime scene analysis and help the forensic expert in extracting measurements and analysing in detail the objects under analysis. Experimental results on a simulated crime scene have shown that the proposed method can be effective in finding and recognizing objects with potential evidentiary value, enabling timely analyses of crime scenes, particularly those with health and safety risks (e.g. fires, explosions, chemicals, etc.), while minimizing subjective bias and contamination of the scene.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18471",
        "abstract url": "https://arxiv.org/abs/2409.18471",
        "title": "Unveiling Hidden Vulnerabilities in Quantum Systems by Expanding Attack Vectors through Heisenberg's Uncertainty Principle",
        "rating": "-3",
        "keywords": [
            [
                "Attack"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "This study uncovers novel vulnerabilities within Quantum Key Distribution (QKD) protocols that extend beyond traditional implementation flaws, such as loopholes. These newly identified vulnerabilities arise from the complex interaction between Bell Inequalities (BIs) and Hidden Variable Theories (HVTs), further exacerbated by the Heisenberg Uncertainty Principle (HUP). Through a combination of theoretical analysis, simulations, and quantum experiments, we reveal critical security weaknesses that challenge the core assumptions of today's quantum cryptography. While these vulnerabilities differ from known loopholes, when considered alongside them and traditional cyberattacks, they present a significant threat to the robustness of QKD and quantum integrity systems. These results provide a new perspective to rethink current quantum security frameworks to ensure the robustness of future quantum cryptographic and quantum integrity protocols.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18498",
        "abstract url": "https://arxiv.org/abs/2409.18498",
        "title": "Improved Approximation Algorithms for Relational Clustering",
        "rating": "-3",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "recommendation"
            ]
        ],
        "abstract": "Clustering plays a crucial role in computer science, facilitating data analysis and problem-solving across numerous fields. By partitioning large datasets into meaningful groups, clustering reveals hidden structures and relationships within the data, aiding tasks such as unsupervised learning, classification, anomaly detection, and recommendation systems. Particularly in relational databases, where data is distributed across multiple tables, efficient clustering is essential yet challenging due to the computational complexity of joining tables. This paper addresses this challenge by introducing efficient algorithms for $k$-median and $k$-means clustering on relational data without the need for pre-computing the join query results. For the relational $k$-median clustering, we propose the first efficient relative approximation algorithm. For the relational $k$-means clustering, our algorithm significantly improves both the approximation factor and the running time of the known relational $k$-means clustering algorithms, which suffer either from large constant approximation factors, or expensive running time. Given a join query $Q$ and a database instance $D$ of $O(N)$ tuples, for both $k$-median and $k$-means clustering on the results of $Q$ on $D$, we propose randomized $(1+\\varepsilon)\u03b3$-approximation algorithms that run in roughly $O(k^2N^{\\mathsf{fhw}})+T_\u03b3(k^2)$ time, where $\\varepsilon\\in (0,1)$ is a constant parameter decided by the user, $\\mathsf{fhw}$ is the fractional hyper-tree width of $Q$, while $\u03b3$ and $T_\u03b3(x)$ are respectively the approximation factor and the running time of a traditional clustering algorithm in the standard computational setting over $x$ points.",
        "subjects": [
            "cs.DB",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18589",
        "abstract url": "https://arxiv.org/abs/2409.18589",
        "title": "Towards Event-Triggered NMPC for Efficient 6G Communications: Experimental Results and Open Problems",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "5G",
                "6G",
                "industrial"
            ]
        ],
        "abstract": "Networked control systems enable real-time control and coordination of distributed systems, leveraging the low latency, high reliability, and massive connectivity offered by 5G and future 6G networks. Applications include autonomous vehicles, robotics, industrial automation, and smart grids. Despite networked control algorithms admitting nominal stability guarantees even in the presence of delays and packet dropouts, their practical performance still heavily depends on the specific characteristics and conditions of the underlying network. To achieve the desired performance while efficiently using communication resources, co-design of control and communication is pivotal. Although periodic schemes, where communication instances are fixed, can provide reliable control performance, unnecessary transmissions, when updates are not needed, result in inefficient usage of network resources. In this paper, we investigate the potential for co-design of model predictive control and network communication. To this end, we design and implement an event-triggered nonlinear model predictive controller for stabilizing a Furuta pendulum communicating over a tailored open radio access network 6G research platform. We analyze the control performance as well as network utilization under varying channel conditions and event-triggering criteria. Our results show that the event-triggered control scheme achieves similar performance to periodic control with reduced communication demand.",
        "subjects": [
            "eess.SY",
            "cs.NI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18636",
        "abstract url": "https://arxiv.org/abs/2409.18636",
        "title": "Unsupervised Fingerphoto Presentation Attack Detection With Diffusion Models",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Attack"
            ],
            [
                "biometric"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Smartphone-based contactless fingerphoto authentication has become a reliable alternative to traditional contact-based fingerprint biometric systems owing to rapid advances in smartphone camera technology. Despite its convenience, fingerprint authentication through fingerphotos is more vulnerable to presentation attacks, which has motivated recent research efforts towards developing fingerphoto Presentation Attack Detection (PAD) techniques. However, prior PAD approaches utilized supervised learning methods that require labeled training data for both bona fide and attack samples. This can suffer from two key issues, namely (i) generalization:the detection of novel presentation attack instruments (PAIs) unseen in the training data, and (ii) scalability:the collection of a large dataset of attack samples using different PAIs. To address these challenges, we propose a novel unsupervised approach based on a state-of-the-art deep-learning-based diffusion model, the Denoising Diffusion Probabilistic Model (DDPM), which is trained solely on bona fide samples. The proposed approach detects Presentation Attacks (PA) by calculating the reconstruction similarity between the input and output pairs of the DDPM. We present extensive experiments across three PAI datasets to test the accuracy and generalization capability of our approach. The results show that the proposed DDPM-based PAD method achieves significantly better detection error rates on several PAI classes compared to other baseline unsupervised approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IJCB 2024"
    },
    {
        "paper id": "2409.18659",
        "abstract url": "https://arxiv.org/abs/2409.18659",
        "title": "Explainable Enrichment-Driven GrAph Reasoner (EDGAR) for Large Knowledge Graphs with Applications in Drug Repurposing",
        "rating": "-3",
        "keywords": [
            [
                "GrAph"
            ],
            [
                "biomedical",
                "medical",
                "disease"
            ]
        ],
        "abstract": "Knowledge graphs (KGs) represent connections and relationships between real-world entities. We propose a link prediction framework for KGs named Enrichment-Driven GrAph Reasoner (EDGAR), which infers new edges by mining entity-local rules. This approach leverages enrichment analysis, a well-established statistical method used to identify mechanisms common to sets of differentially expressed genes. EDGAR's inference results are inherently explainable and rankable, with p-values indicating the statistical significance of each enrichment-based rule. We demonstrate the framework's effectiveness on a large-scale biomedical KG, ROBOKOP, focusing on drug repurposing for Alzheimer disease (AD) as a case study. Initially, we extracted 14 known drugs from the KG and identified 20 contextual biomarkers through enrichment analysis, revealing functional pathways relevant to shared drug efficacy for AD. Subsequently, using the top 1000 enrichment results, our system identified 1246 additional drug candidates for AD treatment. The top 10 candidates were validated using evidence from medical literature. EDGAR is deployed within ROBOKOP, complete with a web user interface. This is the first study to apply enrichment analysis to large graph completion and drug repurposing.",
        "subjects": [
            "cs.IT",
            "cs.IR"
        ],
        "comment": "10 pages, 5 figures, 4 tables"
    },
    {
        "paper id": "2409.18696",
        "abstract url": "https://arxiv.org/abs/2409.18696",
        "title": "Rethinking the Power of Timestamps for Robust Time Series Forecasting: A Global-Local Fusion Perspective",
        "rating": "-3",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Time series forecasting has played a pivotal role across various industries, including finance, transportation, energy, healthcare, and climate. Due to the abundant seasonal information they contain, timestamps possess the potential to offer robust global guidance for forecasting techniques. However, existing works primarily focus on local observations, with timestamps being treated merely as an optional supplement that remains underutilized. When data gathered from the real world is polluted, the absence of global information will damage the robust prediction capability of these algorithms. To address these problems, we propose a novel framework named GLAFF. Within this framework, the timestamps are modeled individually to capture the global dependencies. Working as a plugin, GLAFF adaptively adjusts the combined weights for global and local information, enabling seamless collaboration with any time series forecasting backbone. Extensive experiments conducted on nine real-world datasets demonstrate that GLAFF significantly enhances the average performance of widely used mainstream forecasting models by 12.5%, surpassing the previous state-of-the-art method by 5.5%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2409.18725",
        "abstract url": "https://arxiv.org/abs/2409.18725",
        "title": "Electro-Mechanical Contact Interactions Between Human Finger and Touchscreen Under Electroadhesion",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Electroadhesion (EA) has potential in robotics, automation, space missions, textiles, and tactile displays, but its physics remains underexplored due to limited models and experimental data. This thesis develops an electro-mechanical model to estimate electrostatic forces between human finger and touchscreen under EA and compares it to experimentally measured friction forces. The model aligns well with the data, showing that the electrostatic force changes mainly due to charge leakage from the Stratum Corneum at frequencies below 250 Hz and its electrical properties above 250 Hz. Additionally, a novel approach using electrical impedance measurements estimates electrostatic forces by subtracting skin and touchscreen impedances from the total impedance. This method is the first to experimentally estimate the average air gap between finger and voltage-induced capacitive touchscreen. The effect of electrode polarization impedance, particularly at low frequencies, was also studied, revealing its role in the charge leakage phenomenon. Tactile perception via EA was investigated using DC and AC voltage signals on a touchscreen with 10 participants of varying finger moisture levels. Results showed that AC voltage detection thresholds were significantly lower than for DC, explained by charge leakage at lower frequencies. Participants with moist fingers exhibited higher threshold levels, supported by impedance measurements. The thesis also investigated how touchscreen top coatings influence tactile perception, focusing on EA-free interactions. Psychophysical experiments and physical measurements demonstrated that coating materials significantly affect tactile perception, likely due to molecular interactions. These findings offer insights into finger-touchscreen interactions under EA and have potential applications in designing robotic systems and haptic interfaces using this technology.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18832",
        "abstract url": "https://arxiv.org/abs/2409.18832",
        "title": "Classification and regression of trajectories rendered as images via 2D Convolutional Neural Networks",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "trajectory"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Trajectories can be regarded as time-series of coordinates, typically arising from motile objects. Methods for trajectory classification are particularly important to detect different movement patterns, while methods for regression to compute motility metrics and forecasting. Recent advances in computer vision have facilitated the processing of trajectories rendered as images via artificial neural networks with 2d convolutional layers (CNNs). This approach leverages the capability of CNNs to learn spatial hierarchies of features from images, necessary to recognize complex shapes. Moreover, it overcomes the limitation of other machine learning methods that require input trajectories with a fixed number of points. However, rendering trajectories as images can introduce poorly investigated artifacts such as information loss due to the plotting of coordinates on a discrete grid, and spectral changes due to line thickness and aliasing. In this study, we investigate the effectiveness of CNNs for solving classification and regression problems from synthetic trajectories that have been rendered as images using different modalities. The parameters considered in this study include line thickness, image resolution, usage of motion history (color-coding of the temporal component) and anti-aliasing. Results highlight the importance of choosing an appropriate image resolution according to model depth and motion history in applications where movement direction is critical.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "13 pages, 5 figures"
    },
    {
        "paper id": "2409.18862",
        "abstract url": "https://arxiv.org/abs/2409.18862",
        "title": "Safe Decentralized Multi-Agent Control using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "Drone"
            ]
        ],
        "abstract": "We address the challenge of safe control in decentralized multi-agent robotic settings, where agents use uncertain black-box models to predict other agents' trajectories. We use the recently proposed conformal decision theory to adapt the restrictiveness of control barrier functions-based safety constraints based on observed prediction errors. We use these constraints to synthesize controllers that balance between the objectives of safety and task accomplishment, despite the prediction errors. We provide an upper bound on the average over time of the value of a monotonic function of the difference between the safety constraint based on the predicted trajectories and the constraint based on the ground truth ones. We validate our theory through experimental results showing the performance of our controllers when navigating a robot in the multi-agent scenes in the Stanford Drone Dataset.",
        "subjects": [
            "eess.SY",
            "cs.MA",
            "cs.RO"
        ],
        "comment": "6 pages, 1 figure, submitted for ICRA 2025"
    },
    {
        "paper id": "2409.18921",
        "abstract url": "https://arxiv.org/abs/2409.18921",
        "title": "Cluster-BPI: Efficient Fine-Grain Blind Power Identification for Defending against Hardware Thermal Trojans in Multicore SoCs",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Thermal"
            ]
        ],
        "abstract": "Modern multicore System-on-Chips (SoCs) feature hardware monitoring mechanisms that measure total power consumption. However, these aggregate measurements are often insufficient for fine-grained thermal and power management. This paper presents an enhanced Clustering Blind Power Identification (ICBPI) approach, designed to improve the sensitivity and robustness of the traditional Blind Power Identification (BPI) method. BPI estimates the power consumption of individual cores and models the thermal behavior of an SoC using only thermal sensor data and total power measurements. The proposed ICBPI approach refines BPI's initialization process, particularly improving the non-negative matrix factorization (NNMF) step, which is critical to the accuracy of BPI. ICBPI introduces density-based spatial clustering of applications with noise (DBSCAN) to better align temperature and power consumption data, thereby providing more accurate power consumption estimates. We validate the ICBPI method through two key tasks. The first task evaluates power estimation accuracy across four different multicore architectures, including a heterogeneous processor. Results show that ICBPI significantly enhances accuracy, reducing error rates by 77.56% compared to the original BPI and by 68.44% compared to the state-of-the-art BPISS method. The second task focuses on improving the detection and localization of malicious thermal sensor attacks in heterogeneous processors. The results demonstrate that ICBPI enhances the security and robustness of multicore SoCs against such attacks.",
        "subjects": [
            "cs.CR",
            "cs.PF",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18924",
        "abstract url": "https://arxiv.org/abs/2409.18924",
        "title": "AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Graph"
            ],
            [
                "medical",
                "Health",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Simulated patient systems play a crucial role in modern medical education and research, providing safe, integrative learning environments and enabling clinical decision-making simulations. Large Language Models (LLM) could advance simulated patient systems by replicating medical conditions and patient-doctor interactions with high fidelity and low cost. However, ensuring the effectiveness and trustworthiness of these systems remains a challenge, as they require a large, diverse, and precise patient knowledgebase, along with a robust and stable knowledge diffusion to users. Here, we developed AIPatient, an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning RAG) agentic workflow as the generation backbone. AIPatient KG samples data from Electronic Health Records (EHRs) in the Medical Information Mart for Intensive Care (MIMIC)-III database, producing a clinically diverse and relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89). Reasoning RAG leverages six LLM powered agents spanning tasks including retrieval, KG query generation, abstraction, checker, rewrite, and summarization. This agentic framework reaches an overall accuracy of 94.15% in EHR-based medical Question Answering (QA), outperforming benchmarks that use either no agent or only partial agent integration. Our system also presents high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade 5.6), robustness (ANOVA F-value 0.6126, p<0.1), and stability (ANOVA F-value 0.782, p<0.1). The promising performance of the AIPatient system highlights its potential to support a wide range of applications, including medical education, model evaluation, and system integration.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "42 pages, 6 figures, 7 tables"
    },
    {
        "paper id": "2409.19187",
        "abstract url": "https://arxiv.org/abs/2409.19187",
        "title": "Efficient Dual-Blind Deconvolution for Joint Radar-Communication Systems Using ADMM: Enhancing Channel Estimation and Signal Recovery in 5G mmWave Networks",
        "rating": "-3",
        "keywords": [
            [
                "Radar"
            ],
            [
                "5G"
            ]
        ],
        "abstract": "This paper introduces an innovative framework to address the dual-blind deconvolution challenge within joint radar-communication (JRC) systems, leveraging the Alternating Direction Method of Multipliers (ADMM) to estimate unknown radar channels G (or communication channel H) and transmitted signals X under convex constraints. The approach iteratively refines G (or H) and X estimates alongside auxiliary and dual variables, employing proximal operators to manage potential non-smoothness in the constraint functions. This method stands out for its computational efficiency and adaptability to a wide array of signal processing and communication problems where blind deconvolution is pivotal. Performance analysis reveals a notable reduction in communication mismatch and demonstrates significant improvements in key system metrics such as the Signal-to-Interference-plus-Noise Ratio (SINR), spectrum efficiency, and radar mutual information, particularly within the context of 5G millimeter-wave (mmWave) systems. These results underscore the proposed framework's potential to enhance the synergy between radar and communication functions, promoting more effective spectrum utilisation and environmental sensing capabilities in next-generation wireless technologies.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19217",
        "abstract url": "https://arxiv.org/abs/2409.19217",
        "title": "Detection of Sleep Apnea-Hypopnea Events Using Millimeter-wave Radar and Pulse Oximeter",
        "rating": "-3",
        "keywords": [
            [
                "Radar"
            ],
            [
                "diagnosis"
            ]
        ],
        "abstract": "Obstructive Sleep Apnea-Hypopnea Syndrome (OSAHS) is a sleep-related breathing disorder associated with significant morbidity and mortality worldwide. The gold standard for OSAHS diagnosis, polysomnography (PSG), faces challenges in popularization due to its high cost and complexity. Recently, radar has shown potential in detecting sleep apnea-hypopnea events (SAE) with the advantages of low cost and non-contact monitoring. However, existing studies, especially those using deep learning, employ segment-based classification approach for SAE detection, making the task of event quantity estimation difficult. Additionally, radar-based SAE detection is susceptible to interference from body movements and the environment. Oxygen saturation (SpO2) can offer valuable information about OSAHS, but it also has certain limitations and cannot be used alone for diagnosis. In this study, we propose a method using millimeter-wave radar and pulse oximeter to detect SAE, called ROSA. It fuses information from both sensors, and directly predicts the temporal localization of SAE. Experimental results demonstrate a high degree of consistency (ICC=0.9864) between AHI from ROSA and PSG. This study presents an effective method with low-load device for the diagnosis of OSAHS.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18482",
        "abstract url": "https://arxiv.org/abs/2409.18482",
        "title": "HSTFL: A Heterogeneous Federated Learning Framework for Misaligned Spatiotemporal Forecasting",
        "rating": "-3.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spatiotemporal forecasting has emerged as an indispensable building block of diverse smart city applications, such as intelligent transportation and smart energy management. Recent advancements have uncovered that the performance of spatiotemporal forecasting can be significantly improved by integrating knowledge in geo-distributed time series data from different domains, \\eg enhancing real-estate appraisal with human mobility data; joint taxi and bike demand predictions. While effective, existing approaches assume a centralized data collection and exploitation environment, overlooking the privacy and commercial interest concerns associated with data owned by different parties. In this paper, we investigate multi-party collaborative spatiotemporal forecasting without direct access to multi-source private data. However, this task is challenging due to 1) cross-domain feature heterogeneity and 2) cross-client geographical heterogeneity, where standard horizontal or vertical federated learning is inapplicable. To this end, we propose a Heterogeneous SpatioTemporal Federated Learning (HSTFL) framework to enable multiple clients to collaboratively harness geo-distributed time series data from different domains while preserving privacy. Specifically, we first devise vertical federated spatiotemporal representation learning to locally preserve spatiotemporal dependencies among individual participants and generate effective representations for heterogeneous data. Then we propose a cross-client virtual node alignment block to incorporate cross-client spatiotemporal dependencies via a multi-level knowledge fusion scheme. Extensive privacy analysis and experimental evaluations demonstrate that HSTFL not only effectively resists inference attacks but also provides a significant improvement against various baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2409.18631",
        "abstract url": "https://arxiv.org/abs/2409.18631",
        "title": "Quantum Algorithms for Drone Mission Planning",
        "rating": "-3.5",
        "keywords": [
            [
                "Drone"
            ],
            [
                "Quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Mission planning often involves optimising the use of ISR (Intelligence, Surveillance and Reconnaissance) assets in order to achieve a set of mission objectives within allowed parameters subject to constraints. The missions of interest here, involve routing multiple UAVs visiting multiple targets, utilising sensors to capture data relating to each target. Finding such solutions is often an NP-Hard problem and cannot be solved efficiently on classical computers. Furthermore, during the mission new constraints and objectives may arise, requiring a new solution to be computed within a short time period. To achieve this we investigate near term quantum algorithms that have the potential to offer speed-ups against current classical methods. We demonstrate how a large family of these problems can be formulated as a Mixed Integer Linear Program (MILP) and then converted to a Quadratic Unconstrained Binary Optimisation (QUBO). The formulation provided is versatile and can be adapted for many different constraints with clear qubit scaling provided. We discuss the results of solving the QUBO formulation using commercial quantum annealers and compare the solutions to current edge classical solvers. We also analyse the results from solving the QUBO using Quantum Approximate Optimisation Algorithms (QAOA) and discuss their results. Finally, we also provide efficient methods to encode to the problem into the Variational Quantum Eigensolver (VQE) formalism, where we have tailored the ansatz to the problem making efficient use of the qubits available.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "math.OC"
        ],
        "comment": "14 pages, 7 figures"
    },
    {
        "paper id": "2409.18718",
        "abstract url": "https://arxiv.org/abs/2409.18718",
        "title": "Enhancing Spectrum Efficiency in 6G Satellite Networks: A GAIL-Powered Policy Learning via Asynchronous Federated Inverse Reinforcement Learning",
        "rating": "-3.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "federated learning"
            ],
            [
                "6G"
            ],
            [
                "Satellite"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, a novel generative adversarial imitation learning (GAIL)-powered policy learning approach is proposed for optimizing beamforming, spectrum allocation, and remote user equipment (RUE) association in NTNs. Traditional reinforcement learning (RL) methods for wireless network optimization often rely on manually designed reward functions, which can require extensive parameter tuning. To overcome these limitations, we employ inverse RL (IRL), specifically leveraging the GAIL framework, to automatically learn reward functions without manual design. We augment this framework with an asynchronous federated learning approach, enabling decentralized multi-satellite systems to collaboratively derive optimal policies. The proposed method aims to maximize spectrum efficiency (SE) while meeting minimum information rate requirements for RUEs. To address the non-convex, NP-hard nature of this problem, we combine the many-to-one matching theory with a multi-agent asynchronous federated IRL (MA-AFIRL) framework. This allows agents to learn through asynchronous environmental interactions, improving training efficiency and scalability. The expert policy is generated using the Whale optimization algorithm (WOA), providing data to train the automatic reward function within GAIL. Simulation results show that the proposed MA-AFIRL method outperforms traditional RL approaches, achieving a $14.6\\%$ improvement in convergence and reward value. The novel GAIL-driven policy learning establishes a novel benchmark for 6G NTN optimization.",
        "subjects": [
            "cs.NI",
            "cs.LG"
        ],
        "comment": "Submitted to IEEE Transactions on Mobile Computing (16 pages, 10 figures)"
    },
    {
        "paper id": "2409.18907",
        "abstract url": "https://arxiv.org/abs/2409.18907",
        "title": "In-depth Analysis of Privacy Threats in Federated Learning for Medical Data",
        "rating": "-3.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "Medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning is emerging as a promising machine learning technique in the medical field for analyzing medical images, as it is considered an effective method to safeguard sensitive patient data and comply with privacy regulations. However, recent studies have revealed that the default settings of federated learning may inadvertently expose private training data to privacy attacks. Thus, the intensity of such privacy risks and potential mitigation strategies in the medical domain remain unclear. In this paper, we make three original contributions to privacy risk analysis and mitigation in federated learning for medical data. First, we propose a holistic framework, MedPFL, for analyzing privacy risks in processing medical data in the federated learning environment and developing effective mitigation strategies for protecting privacy. Second, through our empirical analysis, we demonstrate the severe privacy risks in federated learning to process medical images, where adversaries can accurately reconstruct private medical images by performing privacy attacks. Third, we illustrate that the prevalent defense mechanism of adding random noises may not always be effective in protecting medical images against privacy attacks in federated learning, which poses unique and pressing challenges related to protecting the privacy of medical data. Furthermore, the paper discusses several unique research questions related to the privacy protection of medical data in the federated learning environment. We conduct extensive experiments on several benchmark medical image datasets to analyze and mitigate the privacy risks associated with federated learning for medical data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19096",
        "abstract url": "https://arxiv.org/abs/2409.19096",
        "title": "Enhancing Robustness of Graph Neural Networks through p-Laplacian",
        "rating": "-3.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the increase of data in day-to-day life, businesses and different stakeholders need to analyze the data for better predictions. Traditionally, relational data has been a source of various insights, but with the increase in computational power and the need to understand deeper relationships between entities, the need to design new techniques has arisen. For this graph data analysis has become an extraordinary tool for understanding the data, which reveals more realistic and flexible modelling of complex relationships. Recently, Graph Neural Networks (GNNs) have shown great promise in various applications, such as social network analysis, recommendation systems, drug discovery, and more. However, many adversarial attacks can happen over the data, whether during training (poisoning attack) or during testing (evasion attack), which can adversely manipulate the desired outcome from the GNN model. Therefore, it is crucial to make the GNNs robust to such attacks. The existing robustness methods are computationally demanding and perform poorly when the intensity of attack increases. This paper presents a computationally efficient framework, namely, pLapGNN, based on weighted p-Laplacian for making GNNs robust. Empirical evaluation on real datasets establishes the efficacy and efficiency of the proposed method.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "5 pages, 2 figures"
    },
    {
        "paper id": "2409.19185",
        "abstract url": "https://arxiv.org/abs/2409.19185",
        "title": "Semi-Supervised Bone Marrow Lesion Detection from Knee MRI Segmentation Using Mask Inpainting Models",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "Inpainting"
            ],
            [
                "anomaly detection"
            ],
            [
                "diagnosis",
                "MRI",
                "Lesion"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Bone marrow lesions (BMLs) are critical indicators of knee osteoarthritis (OA). Since they often appear as small, irregular structures with indistinguishable edges in knee magnetic resonance images (MRIs), effective detection of BMLs in MRI is vital for OA diagnosis and treatment. This paper proposes a semi-supervised local anomaly detection method using mask inpainting models for identification of BMLs in high-resolution knee MRI, effectively integrating a 3D femur bone segmentation model, a large mask inpainting model, and a series of post-processing techniques. The method was evaluated using MRIs at various resolutions from a subset of the public Osteoarthritis Initiative database. Dice score, Intersection over Union (IoU), and pixel-level sensitivity, specificity, and accuracy showed an advantage over the multiresolution knowledge distillation method-a state-of-the-art global anomaly detection method. Especially, segmentation performance is enhanced on higher-resolution images, achieving an over two times performance increase on the Dice score and the IoU score at a 448x448 resolution level. We also demonstrate that with increasing size of the BML region, both the Dice and IoU scores improve as the proportion of distinguishable boundary decreases. The identified BML masks can serve as markers for downstream tasks such as segmentation and classification. The proposed method has shown a potential in improving BML detection, laying a foundation for further advances in imaging-based OA research.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "5 pages, 3 figures, submitted to SPIE Conference on Image Processing"
    },
    {
        "paper id": "2409.18761",
        "abstract url": "https://arxiv.org/abs/2409.18761",
        "title": "Geometric deep learning for galaxy-halo connection: a case study for galaxy intrinsic alignments",
        "rating": "-4.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "graphs"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Forthcoming cosmological imaging surveys, such as the Rubin Observatory LSST, require large-scale simulations encompassing realistic galaxy populations for a variety of scientific applications. Of particular concern is the phenomenon of intrinsic alignments (IA), whereby galaxies orient themselves towards overdensities, potentially introducing significant systematic biases in weak gravitational lensing analyses if they are not properly modeled. Due to computational constraints, simulating the intricate details of galaxy formation and evolution relevant to IA across vast volumes is impractical. As an alternative, we propose a Deep Generative Model trained on the IllustrisTNG-100 simulation to sample 3D galaxy shapes and orientations to accurately reproduce intrinsic alignments along with correlated scalar features. We model the cosmic web as a set of graphs, each graph representing a halo with nodes representing the subhalos/galaxies. The architecture consists of a SO(3) $\\times$ $\\mathbb{R}^n$ diffusion generative model, for galaxy orientations and $n$ scalars, implemented with E(3) equivariant Graph Neural Networks that explicitly respect the Euclidean symmetries of our Universe. The model is able to learn and predict features such as galaxy orientations that are statistically consistent with the reference simulation. Notably, our model demonstrates the ability to jointly model Euclidean-valued scalars (galaxy sizes, shapes, and colors) along with non-Euclidean valued SO(3) quantities (galaxy orientations) that are governed by highly complex galactic physics at non-linear scales.",
        "subjects": [
            "astro-ph.GA",
            "cs.LG"
        ],
        "comment": "12 pages, 5 figures. submitted to MNRAS"
    },
    {
        "paper id": "2409.18529",
        "abstract url": "https://arxiv.org/abs/2409.18529",
        "title": "Robustness of AI-based weather forecasts in a changing climate",
        "rating": "-5.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "forecasting"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data-driven machine learning models for weather forecasting have made transformational progress in the last 1-2 years, with state-of-the-art ones now outperforming the best physics-based models for a wide range of skill scores. Given the strong links between weather and climate modelling, this raises the question whether machine learning models could also revolutionize climate science, for example by informing mitigation and adaptation to climate change or to generate larger ensembles for more robust uncertainty estimates. Here, we show that current state-of-the-art machine learning models trained for weather forecasting in present-day climate produce skillful forecasts across different climate states corresponding to pre-industrial, present-day, and future 2.9K warmer climates. This indicates that the dynamics shaping the weather on short timescales may not differ fundamentally in a changing climate. It also demonstrates out-of-distribution generalization capabilities of the machine learning models that are a critical prerequisite for climate applications. Nonetheless, two of the models show a global-mean cold bias in the forecasts for the future warmer climate state, i.e. they drift towards the colder present-day climate they have been trained for. A similar result is obtained for the pre-industrial case where two out of three models show a warming. We discuss possible remedies for these biases and analyze their spatial distribution, revealing complex warming and cooling patterns that are partly related to missing ocean-sea ice and land surface information in the training data. Despite these current limitations, our results suggest that data-driven machine learning models will provide powerful tools for climate science and transform established approaches by complementing conventional physics-based models.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": "14 pages, 4 figures"
    },
    {
        "paper id": "2409.18465",
        "abstract url": "https://arxiv.org/abs/2409.18465",
        "title": "RIS-Enabled Cellular Systems Operated by Different Service Providers",
        "rating": "-10",
        "keywords": [],
        "abstract": "In realistic cellular communication systems, multiple service providers will operate within different frequency ranges. Each serving cell, which is managed by a distinct service provider, is designed individually due to the orthogonal frequencies. However, when a reconfigurable intelligent surface (RIS) is deployed for a certain cell, the RIS still incurs reflective channels for the overall system since the RIS reflects signals across all frequency ranges. This may cause severe undesired performance degradation for the other cells unless the reflection coefficients are properly designed. To tackle this issue, by utilizing the Riemannian manifold optimization method, an RIS reflection coefficients design is proposed in this paper to maximize the performance improvements of the cell that deploys the RIS while minimizing the undesired performance degradation for the other cells simultaneously. Numerical results demonstrate that the proposed design can effectively balance the two objectives for practical scenarios.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 4 figures, accepted to IEEE Transactions on Vehicular Technology"
    },
    {
        "paper id": "2409.18488",
        "abstract url": "https://arxiv.org/abs/2409.18488",
        "title": "An Error-Code Perspective on Metzner--Kapturowski-like Decoders",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we consider a Metzner-Kapturowski-like decoding algorithm for high-order interleaved sum-rank-metric codes, offering a novel perspective on the decoding process through the concept of an error code. The error code, defined as the linear code spanned by the vectors forming the error matrix, provides a more intuitive understanding of the decoder's functionality and new insights. The proposed algorithm can correct errors of sum-rank weight up to $d-2$, where $d$ is the minimum distance of the constituent code, given a sufficiently large interleaving order. The decoder's versatility is highlighted by its applicability to any linear constituent code, including unstructured or random codes. The computational complexity is $O(\\max\\{n^3, n^2 s\\})$ operations over $\\mathbb{F}_{q^m}$, where $n$ is the code length and $s$ is the interleaving order. We further explore the success probability of the decoder for random errors, providing an efficient algorithm to compute an upper bound on this probability. Additionally, we derive bounds and approximations for the success probability when the error weight exceeds the unique decoding radius, showing that the decoder maintains a high success probability in this regime. Our findings suggest that this decoder could be a valuable tool for the design and security analysis of code-based cryptosystems using interleaved sum-rank-metric codes. The new insights into the decoding process and the high success probability of the algorithm even beyond the unique decoding radius underscore its potential to contribute to various coding-related applications.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Submitted to IEEE Transactions on Information Theory"
    },
    {
        "paper id": "2409.18522",
        "abstract url": "https://arxiv.org/abs/2409.18522",
        "title": "Decomposing the Jaccard Distance and the Jaccard Index in ABCDE",
        "rating": "-10",
        "keywords": [],
        "abstract": "ABCDE is a sophisticated technique for evaluating differences between very large clusterings. Its main metric that characterizes the magnitude of the difference between two clusterings is the JaccardDistance, which is a true distance metric in the space of all clusterings of a fixed set of (weighted) items. The JaccardIndex is the complementary metric that characterizes the similarity of two clusterings. Its relationship with the JaccardDistance is simple: JaccardDistance + JaccardIndex = 1. This paper decomposes the JaccardDistance and the JaccardIndex further. In each case, the decomposition yields Impact and Quality metrics. The Impact metrics measure aspects of the magnitude of the clustering diff, while Quality metrics use human judgements to measure how much the clustering diff improves the quality of the clustering. The decompositions of this paper offer more and deeper insight into a clustering change. They also unlock new techniques for debugging and exploring the nature of the clustering diff. The new metrics are mathematically well-behaved and they are interrelated via simple equations. While the work can be seen as an alternative formal framework for ABCDE, we prefer to view it as complementary. It certainly offers a different perspective on the magnitude and the quality of a clustering change, and users can use whatever they want from each approach to gain more insight into a change.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18530",
        "abstract url": "https://arxiv.org/abs/2409.18530",
        "title": "A Static Analysis of Popular C Packages in Linux",
        "rating": "-10",
        "keywords": [],
        "abstract": "Static analysis is a classical technique for improving software security and software quality in general. Fairly recently, a new static analyzer was implemented in the GNU Compiler Collection (GCC). The present paper uses the GCC's analyzer to empirically examine popular Linux packages. The dataset used is based on those packages in the Gentoo Linux distribution that are either written in C or contain C code. In total, $3,538$ such packages are covered. According to the results, uninitialized variables and NULL pointer dereference issues are the most common problems according to the analyzer. Classical memory management issues are relatively rare. The warnings also follow a long-tailed probability distribution across the packages; a few packages are highly warning-prone, whereas no warnings are present for as much as 89% of the packages. Furthermore, the warnings do not vary across different application domains. With these results, the paper contributes to the domain of large-scale empirical research on software quality and security. In addition, a discussion is presented about practical implications of the results.",
        "subjects": [
            "cs.SE",
            "cs.CR"
        ],
        "comment": "Submitted"
    },
    {
        "paper id": "2409.18549",
        "abstract url": "https://arxiv.org/abs/2409.18549",
        "title": "Ca\u03a3oS: A nonlinear sum-of-squares optimization suite",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present Ca\u03a3oS, the first MATLAB software specifically designed for nonlinear sum-of-squares optimization. A symbolic polynomial algebra system allows to formulate parametrized sum-of-squares optimization problems and facilitates their fast, repeated evaluations. To that extent, we make use of CasADi's symbolic framework and realize concepts of monomial sparsity, linear operators (including duals), and functions between polynomials. Ca\u03a3oS currently provides interfaces to the conic solvers SeDuMi, Mosek, and SCS as well as methods to solve quasiconvex optimization problems (via bisection) and nonconvex optimization problems (via sequential convexification). Numerical examples for benchmark problems including region-of-attraction and reachable set estimation for nonlinear dynamic systems demonstrate significant improvements in computation time compared to existing toolboxes.. Ca\u03a3oS is available open-source at https://github.com/ ifr-acso/casos.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "Submitted to 2025 American Control Conference"
    },
    {
        "paper id": "2409.18557",
        "abstract url": "https://arxiv.org/abs/2409.18557",
        "title": "Balanced Splitting: A Framework for Achieving Zero-wait in the Multiserver-job Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a new framework for designing nonpreemptive and job-size oblivious scheduling policies in the multiserver-job queueing model. The main requirement is to identify a static and balanced sub-partition of the server set and ensure that the servers in each set of that sub-partition can only handle jobs of a given class and in a first-come first-served order. A job class is determined by the number of servers to which it has exclusive access during its entire execution and the probability distribution of its service time. This approach aims to reduce delays by preventing small jobs from being blocked by larger ones that arrived first, and it is particularly beneficial when the job size variability intra resp. inter classes is small resp. large. In this setting, we propose a new scheduling policy, Balanced-Splitting. We provide a sufficient condition for the stability of Balanced-Splitting and show that the resulting queueing probability, i.e., the probability that an arriving job needs to wait for processing upon arrival, vanishes in both the subcritical (the load is kept fixed to a constant less than one) and critical (the load approaches one from below) many-server limiting regimes. Crucial to our analysis is a connection with the M/GI/s/s queue and Erlang's loss formula, which allows our analysis to rely on fundamental results from queueing theory. Numerical simulations show that the proposed policy performs better than several preemptive/nonpreemptive size-aware/oblivious policies in various practical scenarios. This is also confirmed by simulations running on real traces from High Performance Computing (HPC) workloads. The delays induced by Balanced-Splitting are also competitive with those induced by state-of-the-art policies such as First-Fit-SRPT and ServerFilling-SRPT, though our approach has the advantage of not requiring preemption, nor the knowledge of job sizes.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18563",
        "abstract url": "https://arxiv.org/abs/2409.18563",
        "title": "Revisiting Weighted Information Extraction: A Simpler and Faster Algorithm for Ranked Enumeration",
        "rating": "-10",
        "keywords": [],
        "abstract": "Information extraction from textual data, where the query is represented by a finite transducer and the task is to enumerate all results without repetition, and its extension to the weighted case, where each output element has a weight and the output elements are to be enumerated sorted by their weights, are important and well studied problems in database theory. On the one hand, the first framework already covers the well-known case of regular document spanners, while the latter setting covers several practically relevant tasks that cannot be described in the unweighted setting. It is known that in the unweighted case this problem can be solved with linear time preprocessing O(|D|) and output-linear delay O(|s|) in data complexity, where D is the input data and s is the current output element. For the weighted case, Bourhis, Grez, Jachiet, and Riveros [ICDT 2021] recently designed an algorithm with linear time preprocessing, but the delay of O(|s| log(|D|)) depends on the size of the data. We first show how to leverage the existing results on enumerating shortest paths to obtain a simple alternative algorithm with linear preprocessing and a delay of O(|s_i| + min{ log(i), \\log(|D|)}) for the i^{th} output element s_i (in data complexity); thus, substantially improving the previous algorithm. Next, we develop a technically involved rounding technique that allows us to devise an algorithm with linear time preprocessing and output-linear delay O(|s|) with high probability. To this end, we combine tools from algebra, high-dimensional geometry, and linear programming.",
        "subjects": [
            "cs.DS",
            "cs.DB",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18573",
        "abstract url": "https://arxiv.org/abs/2409.18573",
        "title": "Optimal Tree-Based Mechanisms for Differentially Private Approximate CDFs",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers the $\\varepsilon$-differentially private (DP) release of an approximate cumulative distribution function (CDF) of the samples in a dataset. We assume that the true (approximate) CDF is obtained after lumping the data samples into a fixed number $K$ of bins. In this work, we extend the well-known binary tree mechanism to the class of \\emph{level-uniform tree-based} mechanisms and identify $\\varepsilon$-DP mechanisms that have a small $\\ell_2$-error. We identify optimal or close-to-optimal tree structures when either of the parameters, which are the branching factors or the privacy budgets at each tree level, are given, and when the algorithm designer is free to choose both sets of parameters. Interestingly, when we allow the branching factors to take on real values, under certain mild restrictions, the optimal level-uniform tree-based mechanism is obtained by choosing equal branching factors \\emph{independent} of $K$, and equal privacy budgets at all levels. Furthermore, for selected $K$ values, we explicitly identify the optimal \\emph{integer} branching factors and tree height, assuming equal privacy budgets at all levels. Finally, we describe general strategies for improving the private CDF estimates further, by combining multiple noisy estimates and by post-processing the estimates for consistency.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "13 pages, 1 figure, to be submitted to the IEEE"
    },
    {
        "paper id": "2409.18575",
        "abstract url": "https://arxiv.org/abs/2409.18575",
        "title": "Corpus-informed Retrieval Augmented Generation of Clarifying Questions",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study aims to develop models that generate corpus informed clarifying questions for web search, in a way that ensures the questions align with the available information in the retrieval corpus. We demonstrate the effectiveness of Retrieval Augmented Language Models (RAG) in this process, emphasising their ability to (i) jointly model the user query and retrieval corpus to pinpoint the uncertainty and ask for clarifications end-to-end and (ii) model more evidence documents, which can be used towards increasing the breadth of the questions asked. However, we observe that in current datasets search intents are largely unsupported by the corpus, which is problematic both for training and evaluation. This causes question generation models to ``hallucinate'', ie. suggest intents that are not in the corpus, which can have detrimental effects in performance. To address this, we propose dataset augmentation methods that align the ground truth clarifications with the retrieval corpus. Additionally, we explore techniques to enhance the relevance of the evidence pool during inference, but find that identifying ground truth intents within the corpus remains challenging. Our analysis suggests that this challenge is partly due to the bias of current datasets towards clarification taxonomies and calls for data that can support generating corpus-informed clarifications.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18590",
        "abstract url": "https://arxiv.org/abs/2409.18590",
        "title": "Accessibility Issues in Ad-Driven Web Applications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Website accessibility is essential for inclusiveness and regulatory compliance. Although third-party advertisements (ads) are a vital revenue source for free web services, they introduce significant accessibility challenges. Leasing a website\u015b space to ad-serving technologies like DoubleClick results in developers losing control over ad content accessibility. Even on highly accessible websites, third-party ads can undermine adherence to Web Content Accessibility Guidelines (WCAG). We conduct the first large-scale investigation of 430K website elements, including nearly 100K ad elements, to understand the accessibility of ads on websites. We seek to understand the prevalence of inaccessible ads and their overall impact on the accessibility of websites. Our findings show that 67% of websites experience increased accessibility violations due to ads, with common violations including Focus Visible and On Input. Popular ad-serving technologies like Taboola, DoubleClick, and RevContent often serve ads that fail to comply with WCAG standards. Even when ads are WCAG compliant, 27% of them have alternative text in ad images that misrepresents information, potentially deceiving users. Manual inspection of a sample of these misleading ads revealed that user-identifiable data is collected on 94% of websites through interactions, such as hovering or pressing enter. Since users with disabilities often rely on tools like screen readers that require hover events to access website content, they have no choice but to compromise their privacy in order to navigate website ads. Based on our findings, we further dissect the root cause of these violations and provide design guidelines to both website developers and ad-serving technologies to achieve WCAG-compliant ad integration.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18621",
        "abstract url": "https://arxiv.org/abs/2409.18621",
        "title": "A New Bound on the Cumulant Generating Function of Dirichlet Processes",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we introduce a novel approach for bounding the cumulant generating function (CGF) of a Dirichlet process (DP) $X \\sim \\text{DP}(\u03b1\u03bd_0)$, using superadditivity. In particular, our key technical contribution is the demonstration of the superadditivity of $\u03b1\\mapsto \\log \\mathbb{E}_{X \\sim \\text{DP}(\u03b1\u03bd_0)}[\\exp( \\mathbb{E}_X[\u03b1f])]$, where $\\mathbb{E}_X[f] = \\int f dX$. This result, combined with Fekete's lemma and Varadhan's integral lemma, converts the known asymptotic large deviation principle into a practical upper bound on the CGF $ \\log\\mathbb{E}_{X\\sim \\text{DP}(\u03b1\u03bd_0)}{\\exp(\\mathbb{E}_{X}{[f]})} $ for any $\u03b1> 0$. The bound is given by the convex conjugate of the scaled reversed Kullback-Leibler divergence $\u03b1\\mathrm{KL}(\u03bd_0\\Vert \\cdot)$. This new bound provides particularly effective confidence regions for sums of independent DPs, making it applicable across various fields.",
        "subjects": [
            "math.PR",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18634",
        "abstract url": "https://arxiv.org/abs/2409.18634",
        "title": "Split-or-decompose: Improved FPT branching algorithms for maximum agreement forests",
        "rating": "-10",
        "keywords": [],
        "abstract": "Phylogenetic trees are leaf-labelled trees used to model the evolution of species. In practice it is not uncommon to obtain two topologically distinct trees for the same set of species, and this motivates the use of distance measures to quantify dissimilarity. A well-known measure is the maximum agreement forest (MAF): a minimum-size partition of the leaf labels which splits both trees into the same set of disjoint, leaf-labelled subtrees (up to isomorphism after suppressing degree-2 vertices). Computing such a MAF is NP-hard and so considerable effort has been invested in finding FPT algorithms, parameterised by $k$, the number of components of a MAF. The state of the art has been unchanged since 2015, with running times of $O^*(3^k)$ for unrooted trees and $O^*(2.3431^k)$ for rooted trees. In this work we present improved algorithms for both the unrooted and rooted cases, with runtimes $O^*(2.846^k)$ and $O^*(2.3391^k)$ respectively. The key to our improvement is a novel branching strategy in which we show that any overlapping components obtained on the way to a MAF can be `split' by a branching rule with favourable branching factor, and then the problem can be decomposed into disjoint subproblems to be solved separately. We expect that this technique may be more widely applicable to other problems in algorithmic phylogenetics.",
        "subjects": [
            "cs.DS",
            "q-bio.PE"
        ],
        "comment": "26 pages"
    },
    {
        "paper id": "2409.18657",
        "abstract url": "https://arxiv.org/abs/2409.18657",
        "title": "Impact of number of elements on the directivity of planar array of monopole antenna",
        "rating": "-10",
        "keywords": [],
        "abstract": "This research investigates how the number of elements affects the monopole antenna's planar array's directivity. This study also takes into account the antenna's effect on the whole field it radiates. The monopole antennas are arranged in a planar configuration with all the components in their proper locations using the Hadamard matrix approach. Each matrix's directivities and array factors were calculated, and a MATLAB tool was used to simulate the radiation pattern. A range of elements from 4 X 4 to 50 X 50 planar layouts were taken into consideration during the investigation. Increasing the number of elements improves the directivity. Increasing the number of elements in the planar array resulted in a great improvement in directivity, as seen by the computed and simulated results. Consequently, by increasing the antenna's directivity, a greater number of elements influences the overall field emitted.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 19 Figures, article"
    },
    {
        "paper id": "2409.18658",
        "abstract url": "https://arxiv.org/abs/2409.18658",
        "title": "SEART Data Hub: Streamlining Large-Scale Source Code Mining and Pre-Processing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large-scale code datasets have acquired an increasingly central role in software engineering (SE) research. This is the result of (i) the success of the mining software repositories (MSR) community, that pushed the standards of empirical studies in SE; and (ii) the recent advent of deep learning (DL) in software engineering, with models trained and tested on large source code datasets. While there exist some ready-to-use datasets in the literature, researchers often need to build and pre-process their own dataset to meet specific requirements of the study/technique they are working on. This implies a substantial cost in terms of time and computational resources. In this work we present the SEART Data Hub, a web application that allows to easily build and pre-process large-scale datasets featuring code mined from public GitHub repositories. Through a simple web interface, researchers can specify a set of mining criteria (e.g., only collect code from repositories having more than 100 contributors and more than 1,000 commits) as well as specific pre-processing steps they want to perform (e.g., remove duplicates, test code, instances with syntax errors). After submitting the request, the user will receive an email with a download link for the required dataset within a few hours. A video showcasing the SEART Data Hub is available at https://youtu.be/lCgQaA7CYWA.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18667",
        "abstract url": "https://arxiv.org/abs/2409.18667",
        "title": "Synchronous Team Semantics for Temporal Logics",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present team semantics for two of the most important linear and branching time specification languages, Linear Temporal Logic (LTL) and Computation Tree Logic (CTL). With team semantics, LTL is able to express hyperproperties, which have in the last decade been identified as a key concept in the verification of information flow properties. We study basic properties of the logic and classify the computational complexity of its satisfiability, path, and model checking problem. Further, we examine how extensions of the basic logic react to adding additional atomic operators. Finally, we compare its expressivity to the one of HyperLTL, another recently introduced logic for hyperproperties. Our results show that LTL with team semantics is a viable alternative to HyperLTL, which complements the expressivity of HyperLTL and has partially better algorithmic properties. For CTL with team semantics, we investigate the computational complexity of the satisfiability and model checking problem. The satisfiability problem is shown to be EXPTIME-complete while we show that model checking is PSPACE-complete.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18670",
        "abstract url": "https://arxiv.org/abs/2409.18670",
        "title": "Beyond Decisiveness of Infinite Markov Chains",
        "rating": "-10",
        "keywords": [],
        "abstract": "Verification of infinite-state Markov chains is still a challenge despite several fruitful numerical or statistical approaches. For decisive Markov chains, there is a simple numerical algorithm that frames the reachability probability as accurately as required (however with an unknown complexity). On the other hand when applicable, statistical model checking is in most of the cases very efficient. Here we study the relation between these two approaches showing first that decisiveness is a necessary and sufficient condition for almost sure termination of statistical model checking. Afterwards we develop an approach with application to both methods that substitutes to a non decisive Markov chain a decisive Markov chain with the same reachability probability. This approach combines two key ingredients: abstraction and importance sampling (a technique that was formerly used for efficiency). We develop this approach on a generic formalism called layered Markov chain (LMC). Afterwards we perform an empirical study on probabilistic pushdown automata (an instance of LMC) to understand the complexity factors of the statistical and numerical algorithms. To the best of our knowledge, this prototype is the first implementation of the deterministic algorithm for decisive Markov chains and required us to solve several qualitative and numerical issues.",
        "subjects": [
            "cs.LO",
            "cs.FL"
        ],
        "comment": "26 pages, 3 figures, to appear in proceeding of FSTTCS24"
    },
    {
        "paper id": "2409.18682",
        "abstract url": "https://arxiv.org/abs/2409.18682",
        "title": "Exploring DAOS Interfaces and Performance",
        "rating": "-10",
        "keywords": [],
        "abstract": "Distributed Asynchronous Object Store (DAOS) is a novel software-defined object store leveraging Non-Volatile Memory (NVM) devices, designed for high performance. It provides a number of interfaces for applications to undertake I/O, ranging from a native object storage API to a DAOS FUSE module for seamless compatibility with existing applications using POSIX file system APIs. In this paper we discuss these interfaces and the options they provide, exercise DAOS through them with various I/O benchmarks, and analyse the observed performance. We also briefly compare the performance with a distributed file system and another object storage system deployed on the same hardware, and showcase DAOS' potential and increased flexibility to support high-performance I/O.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "9 pages, 38 figures, PDSW'24"
    },
    {
        "paper id": "2409.18709",
        "abstract url": "https://arxiv.org/abs/2409.18709",
        "title": "Interaction Equivalence",
        "rating": "-10",
        "keywords": [],
        "abstract": "Contextual equivalence is the de facto standard notion of program equivalence. A key theorem is that contextual equivalence is an equational theory. Making contextual equivalence more intensional, for example taking into account the time cost of the computation, seems a natural refinement. Such a change, however, does not induce an equational theory, for an apparently essential reason: cost is not invariant under reduction. In the paradigmatic case of the untyped $\u03bb$-calculus, we introduce interaction equivalence. Inspired by game semantics, we observe the number of interaction steps between terms and contexts but -- crucially -- ignore their own internal steps. We prove that interaction equivalence is an equational theory and we characterize it as $B$, the well-known theory induced by B\u00f6hm tree equality. Ours is the first observational characterization of $B$ obtained without enriching the discriminating power of contexts with extra features such as non-determinism. To prove our results, we develop interaction-based refinements of the B\u00f6hm-out technique and of intersection types.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18712",
        "abstract url": "https://arxiv.org/abs/2409.18712",
        "title": "Computational and Numerical Properties of a Broadband Subspace-Based Likelihood Ratio Test",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates the performance of a likelihood ratio test in combination with a polynomial subspace projection approach to detect weak transient signals in broadband array data. Based on previous empirical evidence that a likelihood ratio test is advantageously applied in a lower-dimensional subspace, we present analysis that highlights how the polynomial subspace projection whitens a crucial part of the signals, enabling a detector to operate with a shortened temporal window. This reduction in temporal correlation, together with a spatial compaction of the data, also leads to both computational and numerical advantages over a likelihood ratio test that is directly applied to the array data. The results of our analysis are illustrated by examples and simulations.",
        "subjects": [
            "stat.ME",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18717",
        "abstract url": "https://arxiv.org/abs/2409.18717",
        "title": "Improved Hardness Results for the Clearing Problem in Financial Networks with Credit Default Swaps",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study computational problems in financial networks of banks connected by debt contracts and credit default swaps (CDSs). A main problem is to determine \\emph{clearing} payments, for instance right after some banks have been exposed to a financial shock. Previous works have shown the $\\varepsilon$-approximate version of the problem to be $\\mathrm{PPAD}$-complete and the exact problem $\\mathrm{FIXP}$-complete. We show that $\\mathrm{PPAD}$-hardness hold when $\\varepsilon \\approx 0.101$, improving the previously best bound significantly. Due to the fact that the clearing problem typically does not have a unique solution, or that it may not have a solution at all in the presence of default costs, several natural decision problems are also of great interest. We show two such problems to be $\\exists\\mathbb{R}$-complete, complementing previous $\\mathrm{NP}$-hardness results for the approximate setting.",
        "subjects": [
            "cs.GT",
            "q-fin.RM"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18732",
        "abstract url": "https://arxiv.org/abs/2409.18732",
        "title": "Verification of Quantitative Temporal Properties in RealTime-DEVS",
        "rating": "-10",
        "keywords": [],
        "abstract": "Real-Time DEVS (RT-DEVS) can model systems with quantitative temporal requirements. Ensuring that such models verify some temporal properties requires to use something beyond simulation. In this work we use the model checker Uppaal to verify a class of recurrent quantitative temporal properties appearing in RT-DEVS models. Secondly, by introducing mutations to quantitative temporal properties we are able to find errors in RT-DEVS models and their implementations. A case study from the railway domain is presented.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18734",
        "abstract url": "https://arxiv.org/abs/2409.18734",
        "title": "On Adaptive Frequency Sampling for Data-driven MOR Applied to Antenna Responses",
        "rating": "-10",
        "keywords": [],
        "abstract": "Frequency domain sweeps of array antennas are well-known to be time-intensive, and different surrogate models have been used to improve the performance. Data-driven model order reduction algorithms, such as the Loewner framework and vector fitting, can be integrated with these adaptive error estimates, in an iterative algorithm, to reduce the number of full-wave simulations required to accurately capture the requested frequency behavior of multiport array antennas. In this work, we propose two novel adaptive methods exploiting a block matrix function which is a key part of the Loewner framework generating system approach. The first algorithm leverages an inherent matrix parameter freedom in the block matrix function to identify frequency points with large errors, whereas the second utilizes the condition number of the block matrix function. Both methods effectively provide frequency domain error estimates, essential for improved performance. Numerical experiments on multiport array antenna S-parameters demonstrate the effectiveness of our proposed algorithms within the Loewner framework.",
        "subjects": [
            "eess.SY",
            "physics.comp-ph"
        ],
        "comment": "10 pages, 12 figures"
    },
    {
        "paper id": "2409.18741",
        "abstract url": "https://arxiv.org/abs/2409.18741",
        "title": "Optimum Configuration for Hovering n-Quadrotors carrying a Slung Payload",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work proposes a strategy for organising quadrotors around a payload to enable hovering without external stimuli, together with a MATLAB software for modelling the dynamics of a quadrotor-payload system. Based on geometric concepts, the proposed design keeps the payload and system centre of mass aligned. Hovering tests that are successful confirm the method's efficiency. Moreover, the algorithm is improved to take thrust capacities and propeller distances into account, calculating the minimum number of quadrotors needed for hovering. The algorithm's effectiveness is demonstrated by numerical examples, which reveal that larger quadrotors may require fewer units while smaller ones give greater flexibility. Our code can be found at: \\href{https://github.com/Hosnooo/Swarm-Slung-Payload}{https://github.com/Hosnooo/Swarm-Slung-Payload}",
        "subjects": [
            "cs.RO",
            "math.DS"
        ],
        "comment": "accepted for publication at AIAA SCITECH 2025"
    },
    {
        "paper id": "2409.18742",
        "abstract url": "https://arxiv.org/abs/2409.18742",
        "title": "A History-Guided Regional Partitioning Evolutionary Optimization for Solving the Flexible Job Shop Problem with Limited Multi-load Automated Guided Vehicles",
        "rating": "-10",
        "keywords": [],
        "abstract": "In a flexible job shop environment, using Automated Guided Vehicles (AGVs) to transport jobs and process materials is an important way to promote the intelligence of the workshop. Compared with single-load AGVs, multi-load AGVs can improve AGV utilization, reduce path conflicts, etc. Therefore, this study proposes a history-guided regional partitioning algorithm (HRPEO) for the flexible job shop scheduling problem with limited multi-load AGVs (FJSPMA). First, the encoding and decoding rules are designed according to the characteristics of multi-load AGVs, and then the initialization rule based on the branch and bound method is used to generate the initial population. Second, to prevent the algorithm from falling into a local optimum, the algorithm adopts a regional partitioning strategy. This strategy divides the solution space into multiple regions and measures the potential of the regions. After that, cluster the regions into multiple clusters in each iteration, and selects individuals for evolutionary search based on the set of clusters. Third, a local search strategy is designed to improve the exploitation ability of the algorithm, which uses a greedy approach to optimize machines selection and transportation sequence according to the characteristics of FJSPMA. Finally, a large number of experiments are carried out on the benchmarks to test the performance of the algorithm. Compared with multiple advanced algorithms, the results show that the HRPEO has a better advantage in solving FJSPMA.",
        "subjects": [
            "eess.SY",
            "cs.NE"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2409.18755",
        "abstract url": "https://arxiv.org/abs/2409.18755",
        "title": "Transparency evaluation for the Kinematic Design of the Harnesses through Human-Exoskeleton Interaction Modeling",
        "rating": "-10",
        "keywords": [],
        "abstract": "Lower Limb Exoskeletons (LLEs) are wearable robots that provide mechanical power to the user. Human-exoskeleton (HE) connections must preserve the user's natural behavior during the interaction, avoiding undesired forces. Therefore, numerous works focus on their minimization. Given the inherent complications of repeatedly prototyping and experimentally testing a device, modeling the exoskeleton and its physical interaction with the user emerges as a valuable approach for assessing the design effects. This paper proposes a novel method to compare different exoskeleton configurations with a flexible simulation tool. This approach contemplates simulating the dynamics of the device, including its interaction with the wearer, to evaluate multiple connection mechanism designs along with the kinematics and actuation of the LLE. This evaluation is based on the minimization of the interaction wrenches through an optimization process that includes the impedance parameters at the interfaces as optimization variables and the similarity of the LLE's joint variables trajectories with the motion of the wearer's articulations. Exploratory tests are conducted using the Wearable Walker LLE in different configurations and measuring the interaction forces. Experimental data are then compared to the optimization outcomes, proving that the proposed method provides contact wrench estimations consistent with the collected measurements and previous outcomes from the literature. Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18766",
        "abstract url": "https://arxiv.org/abs/2409.18766",
        "title": "Dual Pricing to Prioritize Renewable Energy and Consumer Preferences in Electricity Markets",
        "rating": "-10",
        "keywords": [],
        "abstract": "Electricity markets currently fail to incorporate preferences of buyers, treating polluting and renewable energy sources as having equal social benefit under a system of uniform clearing prices. Meanwhile, renewable energy is prone to curtailment due to transmission constraints, forcing grid operators to reduce or shut down renewable energy production despite its availability and need. This paper proposes a ``dual pricing mechanism\" which allows buyers to bid both their willingness to pay for electricity, and additionally, their preference for green energy. Designed for use in deregulated electricity markets, this mechanism prioritizes the dispatch of more renewable energy sources according to consumer preferences. Traditional uniform clearing prices, which treat all energy sources equally, do not reflect the growing share of green energy in the power grid and the environmental values of consumers. By allowing load-serving entities to bid their willingness to pay for renewable energy directly into the clearing market, our proposed framework generates distinct pricing signals for green and ``black\" electricity.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18779",
        "abstract url": "https://arxiv.org/abs/2409.18779",
        "title": "Hello SME! Generating Fast Matrix Multiplication Kernels Using the Scalable Matrix Extension",
        "rating": "-10",
        "keywords": [],
        "abstract": "Modern central processing units (CPUs) feature single-instruction, multiple-data pipelines to accelerate compute-intensive floating-point and fixed-point workloads. Traditionally, these pipelines and corresponding instruction set architectures (ISAs) were designed for vector parallelism. In recent years, major hardware vendors have further increased the throughput of their CPUs by introducing matrix units with corresponding ISA extensions. The Scalable Matrix Extension (SME) has been announced for the Arm architecture in 2021 and Apple's M4 chip is the first to support SME. This paper presents an in-depth study of SME on M4. Our microbenchmarks determine the maximum floating-point and fixed-point throughput of M4's SME acceleration and study the achievable bandwidth for transfers to and from the matrix registers. Furthermore, we used the insights gained to design a just-in-time code generator for SME-based small matrix multiplications. The results presented show that M4's SME support is FP32-centric, with an achievable throughput of over 2.3 FP32 TFLOPS. To maximize read and write bandwidth, loading and storing to and from the matrix registers must be done in two steps. Our just-in-time generated small matrix multiplication kernels outperform the vendor-optimized BLAS implementation in almost all tested configurations.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18787",
        "abstract url": "https://arxiv.org/abs/2409.18787",
        "title": "Asymptotic tracking control of dynamic reference over homomorphically encrypted data with finite modulus",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers a tracking control problem, in which the dynamic controller is encrypted with an additively homomorphic encryption scheme and the output of a process tracks a dynamic reference asymptotically. Our paper is motivated by the following problem: When dealing with both asymptotic tracking and dynamic reference, we find that the control input is generally subject to overflow issues under a finite modulus, though the dynamic controller consists of only integer coefficients. First, we provide a new controller design method such that the coefficients of the tracking controller can be transformed into integers leveraging the zooming-in factor of dynamic quantization. By the Cayley-Hamilton theorem, we represent the control input as linear combination of the previous control inputs. Leveraging the property above, we design an algorithm on the actuator side such that it can restore the control input from the lower bits under a finite modulus. A lower bound of the modulus is also provided. As an extension of the first result, we further solve the problem of unbounded internal state taking place in the actuator. In particular, the actuator can restore the correct control input under the same modulus. A simulation example is provided to verify the control schemes proposed in our paper.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18817",
        "abstract url": "https://arxiv.org/abs/2409.18817",
        "title": "Facility Location Problem with Aleatory Agents",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we introduce and study the Facility Location Problem with Aleatory Agents (FLPAA), where the facility accommodates n agents larger than the number of agents reporting their preferences, namely n_r. The spare capacity is used by n_u=n-n_r aleatory agents sampled from a probability distribution \u03bc. The goal of FLPAA is to find a location that minimizes the ex-ante social cost, which is the expected cost of the n_u agents sampled from \u03bcplus the cost incurred by the agents reporting their position. We investigate the mechanism design aspects of the FLPAA under the assumption that the Mechanism Designer (MD) lacks knowledge of the distribution $\u03bc$ but can query k quantiles of \u03bc. We explore the trade-off between acquiring more insights into the probability distribution and designing a better-performing mechanism, which we describe through the strong approximation ratio (SAR). The SAR of a mechanism measures the highest ratio between the cost of the mechanisms and the cost of the optimal solution on the worst-case input x and worst-case distribution \u03bc, offering a metric for efficiency that does not depend on \u03bc. We divide our study into four different information settings: the zero information case, in which the MD has access to no quantiles; the median information case, in which the MD has access to the median of \u03bc; the n_u-quantile information case, in which the MD has access to n_u quantiles of its choice, and the k-quantile information case, in which the MD has access to k<n_u quantiles of its choice. For all frameworks, we propose a mechanism that is optimal or achieves a small constant SAR and pairs it with a lower bound on the SAR. In most cases, the lower bound matches the upper bound, thus no truthful mechanism can achieve a lower SAR. Lastly, we extend the FLPAA to include instances in which we must locate two facilities.",
        "subjects": [
            "cs.GT",
            "cs.MA"
        ],
        "comment": "27 pages, 2 figures"
    },
    {
        "paper id": "2409.18824",
        "abstract url": "https://arxiv.org/abs/2409.18824",
        "title": "Fully integrating the Flang Fortran compiler with standard MLIR",
        "rating": "-10",
        "keywords": [],
        "abstract": "Fortran is the lingua franca of HPC code development and as such it is crucial that we as a community have open source Fortran compilers capable of generating high performance executables. Flang is LLVM's Fortran compiler and leverages MLIR which is a reusable compiler infrastructure which, as part of LLVM, has become popular in recent years. However, whilst Flang leverages MLIR it does not fully integrate with it and instead provides bespoke translation and optimisation passes to target LLVM-IR. In this paper we first explore the performance of Flang against other compilers popular in HPC for a range of benchmarks before describing a mapping between Fortran and standard MLIR, exploring the performance of this. The result of this work is an up to three times speed up compared with Flang's existing approach across the benchmarks and experiments run, demonstrating that the Flang community should seriously consider leveraging standard MLIR.",
        "subjects": [
            "cs.DC",
            "cs.PL"
        ],
        "comment": "Author accepted version, to appear in proceedings of the tenth annual workshop on the LLVM compiler infrastructure in HPC"
    },
    {
        "paper id": "2409.18858",
        "abstract url": "https://arxiv.org/abs/2409.18858",
        "title": "Predicting and analyzing memorization within fine-tuned Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large Language Models have received significant attention due to their abilities to solve a wide range of complex tasks. However these models memorize a significant proportion of their training data, posing a serious threat when disclosed at inference time. To mitigate this unintended memorization, it is crucial to understand what elements are memorized and why. Most existing works provide a posteriori explanations, which has a limited interest in practice. To address this gap, we propose a new approach based on sliced mutual information to detect memorized samples a priori, in a classification setting. It is efficient from the early stages of training, and is readily adaptable to practical scenarios. Our method is supported by new theoretical results that we demonstrate, and requires a low computational budget. We obtain strong empirical results, paving the way for systematic inspection and protection of these vulnerable samples before memorization happens.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2409.18867",
        "abstract url": "https://arxiv.org/abs/2409.18867",
        "title": "Robust and efficient data-driven predictive control",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a robust and efficient data-driven predictive control (eDDPC) scheme which is more sample efficient (requires less offline data) compared to existing schemes, and is also computationally efficient. This is done by leveraging an alternative data-based representation of the trajectories of linear time-invariant (LTI) systems. The proposed scheme relies only on using (short and potentially irregularly measured) noisy input-output data, the amount of which is independent of the prediction horizon. To account for measurement noise, we provide a novel result that quantifies the uncertainty between the true (unknown) restricted behavior of the system and the estimated one from noisy data. Furthermore, we show that the robust eDDPC scheme is recursively feasible and that the resulting closed-loop system is practically stable. Finally, we compare the performance of this scheme to existing ones on a case study of a four tank system.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "17 pages, 2 figures, submitted for Automatica"
    },
    {
        "paper id": "2409.18884",
        "abstract url": "https://arxiv.org/abs/2409.18884",
        "title": "An Overview and Catalogue of Dependency Challenges in Open Source Software Package Registries",
        "rating": "-10",
        "keywords": [],
        "abstract": "While open-source software has enabled significant levels of reuse to speed up software development, it has also given rise to the dreadful dependency hell that all software practitioners face on a regular basis. This article provides a catalogue of dependency-related challenges that come with relying on OSS packages or libraries. The catalogue is based on a review of the abundant scientific literature on empirical research that has been conducted to understand, quantify and overcome these challenges. Our results can be used as a starting point for junior and senior researchers as well as practitioners that would like to learn more about research advances in dealing with the challenges that come with the dependency networks of large OSS package registries.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Submitted to the BENEVOL24 23rd Belgium-Netherlands Software Evolution Workshop"
    },
    {
        "paper id": "2409.19071",
        "abstract url": "https://arxiv.org/abs/2409.19071",
        "title": "Analog fast Fourier transforms for scalable and efficient signal processing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Edge devices are being deployed at increasing volumes to sense and act on information from the physical world. The discrete Fourier transform (DFT) is often necessary to make this sensed data suitable for further processing $\\unicode{x2013}$ such as by artificial intelligence (AI) algorithms $\\unicode{x2013}$ and for transmission over communication networks. Analog in-memory computing has been shown to be a fast and energy-efficient solution for processing edge AI workloads, but not for Fourier transforms. This is because of the existence of the fast Fourier transform (FFT) algorithm, which enormously reduces the complexity of the DFT but has so far belonged only to digital processors. Here, we show that the FFT can be mapped to analog in-memory computing systems, enabling them to efficiently scale to arbitrarily large Fourier transforms without requiring large sizes or large numbers of non-volatile memory arrays. We experimentally demonstrate analog FFTs on 1D audio and 2D image signals, using a large-scale charge-trapping memory array with precisely tunable, low-conductance analog states. The scalability of both the new analog FFT approach and the charge-trapping memory device is leveraged to compute a 65,536-point analog DFT, a scale that is otherwise inaccessible by analog systems and which is $>$1000$\\times$ larger than any previous analog DFT demonstration. The analog FFT also provides more numerically precise DFTs with greater tolerance to device and circuit non-idealities than a direct matrix-vector multiplication approach. We show that the extension of the FFT algorithm to analog in-memory processors leads to design considerations that differ markedly from digital implementations, and that analog Fourier transforms have a substantial power efficiency advantage at all size scales over FFTs implemented on state-of-the-art digital hardware.",
        "subjects": [
            "cs.ET",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19079",
        "abstract url": "https://arxiv.org/abs/2409.19079",
        "title": "Improved formulation for long-duration storage in capacity expansion models using representative periods",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the increasing complexity and size of capacity expansion models, temporal aggregation has emerged as a common method to improve computational tractability. However, this approach inherently complicates the inclusion of long-duration storage (LDS) systems, whose operation involves the entire time horizon connecting all time steps. This work presents a detailed investigation of LDS modelling with temporal aggregation. A novel compact formulation is proposed to reduce the number of constraints while effectively tracking the storage content and enforcing limits on the state of charge throughout the entire time horizon. The developed method is compared with two leading state-of-the-art formulations. All three methods are implemented in the Dolphyn capacity expansion model and tested on a case study for the continental United States, considering different configurations in terms of spatial resolutions and representative periods. The performance is assessed with both the commercial solver Gurobi and the open-source solver HiGHS. Results show that the developed compact formulation consistently outperforms the other methods in terms of both runtime (30%-70% faster than other methods) and memory usage (1%-9% lower than other methods).",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19087",
        "abstract url": "https://arxiv.org/abs/2409.19087",
        "title": "Mechanism Design with Delegated Bidding",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider the problem of a designer who wants to allocate resources to representatives, that then distribute the resources they receive among the individuals they represent. Motivated by the way Feeding America, one of the largest U.S. charities, allocates donations to food banks, which then further distribute the donations to food-insecure individuals, we focus on mechanisms that use artificial currencies. We compare auctions through the lens of the Price of Anarchy, with respect to three canonical welfare objectives: utilitarian social welfare (sum of individuals' utilities), Nash social welfare (product of individuals' utilities), and egalitarian social welfare (minimum of individuals' utilities). We prove strong lower bounds on the Price of Anarchy of all auctions that allocate each item to the highest bidder, subject to a mild technical constraint; this includes Feeding America's current auction, the First-Price auction. In sharp contrast, our main result shows that adapting the classic Trading Post mechanism of Shapley and Shubik to this setting, and coupled with Feeding America's choice of budget rule (each representative gets an amount of artificial currency equal to the number of individuals it represents), achieves a small Price of Anarchy for all generalized $p$-mean objectives simultaneously. Our bound on the Price of Anarchy of the Trading Post mechanism depends on $\\ell$: the product of the rank and the ``incoherence'' of the underlying valuation matrix, which together capture a notion of how ``spread out'' the values of a matrix are. This notion has been extremely influential in the matrix completion literature, and, to the best of our knowledge, has never been used in auction theory prior to our work. Perhaps surprisingly, we prove that the dependence on $\\ell$ is necessary: the Price of Anarchy of the Trading Post mechanism is $\u03a9(\\sqrt{\\ell})$.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "The 20th Conference on Web and Internet Economics (WINE 2024)"
    },
    {
        "paper id": "2409.19088",
        "abstract url": "https://arxiv.org/abs/2409.19088",
        "title": "Solving FDR-Controlled Sparse Regression Problems with Five Million Variables on a Laptop",
        "rating": "-10",
        "keywords": [],
        "abstract": "Currently, there is an urgent demand for scalable multivariate and high-dimensional false discovery rate (FDR)-controlling variable selection methods to ensure the repro-ducibility of discoveries. However, among existing methods, only the recently proposed Terminating-Random Experiments (T-Rex) selector scales to problems with millions of variables, as encountered in, e.g., genomics research. The T-Rex selector is a new learning framework based on early terminated random experiments with computer-generated dummy variables. In this work, we propose the Big T-Rex, a new implementation of T-Rex that drastically reduces its Random Access Memory (RAM) consumption to enable solving FDR-controlled sparse regression problems with millions of variables on a laptop. We incorporate advanced memory-mapping techniques to work with matrices that reside on solid-state drive and two new dummy generation strategies based on permutations of a reference matrix. Our nu-merical experiments demonstrate a drastic reduction in memory demand and computation time. We showcase that the Big T-Rex can efficiently solve FDR-controlled Lasso-type problems with five million variables on a laptop in thirty minutes. Our work empowers researchers without access to high-performance clusters to make reproducible discoveries in large-scale high-dimensional data.",
        "subjects": [
            "eess.SP",
            "stat.ML"
        ],
        "comment": "Conference article (IEEE CAMSAP 2023), 5 pages, 7 figures"
    },
    {
        "paper id": "2409.19090",
        "abstract url": "https://arxiv.org/abs/2409.19090",
        "title": "Calibrating microscopic traffic models with macroscopic data",
        "rating": "-10",
        "keywords": [],
        "abstract": "Traffic microsimulation is a crucial tool that uses microscopic traffic models, such as car-following and lane-change models, to simulate the trajectories of individual agents. This digital platform allows for the assessment of the impact of emerging technologies on transportation system performance. While these microscopic models are based on mathematical structures, their parameters must be fitted to real-world data through a process called model calibration. Despite extensive studies on calibration, the focus has predominantly been on fitting microscopic data, such as trajectories, rather than evaluating how well the models reproduce macroscopic traffic patterns, such as congestion, bottlenecks, and traffic waves. In this work, we address this gap by calibrating microscopic traffic flow models using macroscopic (aggregated) data, which is more readily accessible. We designed a SUMO-in-the-loop calibration framework with the goal of replicating observed macroscopic traffic features. To assess calibration accuracy, we developed a set of performance measures that evaluate the models' ability to replicate traffic states across the entire spatiotemporal domain and other qualitative characteristics of traffic flow. The calibration method was applied to both a synthetic scenario and a real-world scenario on a segment of Interstate 24, to demonstrate its effectiveness in reproducing observed traffic patterns.",
        "subjects": [
            "stat.AP",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19107",
        "abstract url": "https://arxiv.org/abs/2409.19107",
        "title": "Measuring Software Development Waste in Open-Source Software Projects",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software Development Waste (SDW) is defined as any resource-consuming activity that does not add value to the client or the organization developing the software. SDW impacts the overall efficiency and productivity of a software project as the scale and size of the project grows. Although engineering leaders usually put in effort to minimize waste, the lack of definitive measures to track and manage SDW is a cause of concern. To address this gap, we propose five measures, namely Stale Forks, Project Diversification Index, PR Rejection Rate, Backlog Inversion Index, and Feature Fulfillment Rate to potentially identify unused artifacts, building the wrong feature/product, mismanagement of backlog types of SDW. We apply these measures on ten open-source projects and share our observations to apply them in practice for managing SDW.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "9 pages, This manuscript is a pre-publication version of the paper that was published at IEEE SEAA 2024"
    },
    {
        "paper id": "2409.19109",
        "abstract url": "https://arxiv.org/abs/2409.19109",
        "title": "Trust, But Verify, Operator-Reported Geolocation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Geolocation plays a critical role in understanding the Internet. In this work, we provide an in-depth analysis of operator-misreported geolocation. Using a bandwidth-efficient methodology, we find in May 2024 that only a small percentage (1.5%) of vantage points in the largest community-vantage point collection, RIPE Atlas, do not respond from their operator-reported geolocation. However, misreported geolocations disproportionately affect areas with limited coverage and cause entire countries to be left with no vantage points. Furthermore, the problem is escalating: within the past five years, the number of probes reporting the wrong location has increased ten-fold. To increase the accuracy of future methodologies and studies that rely upon operator-reported geolocation, we open source our methodology and release a continually updated dataset of RIPE Atlas vantage points that misreport geolocation.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19119",
        "abstract url": "https://arxiv.org/abs/2409.19119",
        "title": "Exascale Simulations of Fusion and Fission Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We discuss pioneering heat and fluid flow simulations of fusion and fission energy systems with NekRS on exascale computing facilities, including Frontier and Aurora. The Argonne-based code, NekRS, is a highly-performant open-source code for the simulation of incompressible and low-Mach fluid flow, heat transfer, and combustion with a particular focus on turbulent flows in complex domains. It is based on rapidly convergent high-order spectral element discretizations that feature minimal numerical dissipation and dispersion. State-of-the-art multilevel preconditioners, efficient high-order time-splitting methods, and runtime-adaptive communication strategies are built on a fast OCCA-based kernel library, libParanumal, to provide scalability and portability across the spectrum of current and future high-performance computing platforms. On Frontier, Nek5000/RS has achieved an unprecedented milestone in breaching over 1 trillion degrees of freedom with the spectral element methods for the simulation of the CHIMERA fusion technology testing platform. We also demonstrate for the first time the use of high-order overset grids at scale.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "10 pages, 3 figures, 3 tables"
    },
    {
        "paper id": "2409.19139",
        "abstract url": "https://arxiv.org/abs/2409.19139",
        "title": "Gaze-informed Signatures of Trust and Collaboration in Human-Autonomy Teams",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the evolving landscape of human-autonomy teaming (HAT), fostering effective collaboration and trust between human and autonomous agents is increasingly important. To explore this, we used the game Overcooked AI to create dynamic teaming scenarios featuring varying agent behaviors (clumsy, rigid, adaptive) and environmental complexities (low, medium, high). Our objectives were to assess the performance of adaptive AI agents designed with hierarchical reinforcement learning for better teamwork and measure eye tracking signals related to changes in trust and collaboration. The results indicate that the adaptive agent was more effective in managing teaming and creating an equitable task distribution across environments compared to the other agents. Working with the adaptive agent resulted in better coordination, reduced collisions, more balanced task contributions, and higher trust ratings. Reduced gaze allocation, across all agents, was associated with higher trust levels, while blink count, scan path length, agent revisits and trust were predictive of the humans contribution to the team. Notably, fixation revisits on the agent increased with environmental complexity and decreased with agent versatility, offering a unique metric for measuring teammate performance monitoring. These findings underscore the importance of designing autonomous teammates that not only excel in task performance but also enhance teamwork by being more predictable and reducing the cognitive load on human team members. Additionally, this study highlights the potential of eye-tracking as an unobtrusive measure for evaluating and improving human-autonomy teams, suggesting eye gaze could be used by agents to dynamically adapt their behaviors.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19154",
        "abstract url": "https://arxiv.org/abs/2409.19154",
        "title": "SAMBA: Scalable Approximate Forwarding For NDN Implicit FIB Aggregation",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Internet landscape has witnessed a significant shift toward Information Centric Networking (ICN) due to the exponential growth of data-driven applications. Similar to routing tables in TCP/IP architectures, ICN uses Forward Information Base (FIB) tables. However, FIB tables can grow exponentially due to their URL-like naming scheme, introducing major delays in the prefix lookup process. Existing explicit FIB aggregation solutions are very complex to run, and ICN on-demand routing schemes, which use a discovery mechanism to help reduce the number of FIB records and thus have shorter lookup times, rely on flooding-based mechanisms and building routes for all requests, introducing additional scalability challenges. In this paper, we propose SAMBA, an Approximate Forwarding-based Self Learning, that uses the nearest FIB trie record to the given prefix for reducing the number of discoveries thus keeping the FIB table small. By choosing the nearest prefix to a given name prefix, SAMBA uses Implicit Prefix Aggregation (IPA) which implicitly aggregates the FIB records and reduces the number of Self Learning discoveries required. Coupled with the approximate forwarding, SAMBA can achieve efficient and scalable forwarding",
        "subjects": [
            "cs.NI"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2409.19155",
        "abstract url": "https://arxiv.org/abs/2409.19155",
        "title": "SensoPatch: A Reconfigurable Haptic Feedback with High-Density Tactile Sensing Glove",
        "rating": "-10",
        "keywords": [],
        "abstract": "Haptic feedback is integral to the improved experience of prosthetic users and the reduction in prosthesis rejection. Prior studies have explored various methods to encode tactile information and deliver vibration feedback. However, a comprehensive study comparing performance across different stimulation locations and feedback modalities for wearable devices is absent and there is no test platform. This paper proposes an open-source reconfigurable haptic feedback system which incorporates 25 sensors and wireless communication to allow customized number of vibration motors, adjustable motor placement, and programmable encoding of tactile data to change feedback modalities. To demonstrate potential studies that can be investigated using SensoPatch, we conducted two experiments: 1) to assess the vibration discrimination accuracy on 3 body parts 2) to assess the effect of 6 methods of mapping tactile data to varying number of motors on object manipulation. SensoPatch utilizes low-cost off-the-shelf components, enabling large-scale comparative studies of feedback modalities and stimulation sites to optimize vibrotactile feedback and facilitate its deployment in upper limb prostheses.",
        "subjects": [
            "cs.HC",
            "eess.SY"
        ],
        "comment": "5 pages, 5 figures, 1 table, to be published in 2024 IEEE Biomedical Circuits and Systems Conference (BioCAS)"
    },
    {
        "paper id": "2409.19156",
        "abstract url": "https://arxiv.org/abs/2409.19156",
        "title": "ZERNIPAX: A Fast and Accurate Zernike Polynomial Calculator in Python",
        "rating": "-10",
        "keywords": [],
        "abstract": "Zernike Polynomials serve as an orthogonal basis on the unit disc, and have been proven to be effective in optics simulations, astrophysics, and more recently in plasma simulations. Unlike Bessel functions, they maintain finite values at the disc center, ensuring inherent analyticity along the axis. We developed ZERNIPAX, an open-source Python package capable of utilizing CPU/GPUs, leveraging Google's JAX package and available on https://github.com/PlasmaControl/FastZernike.git as well as PyPI. Our implementation of the recursion relation between Jacobi polynomials significantly improves computation time compared to alternative methods by use of parallel computing while still preserving accuracy for mode numbers n>100.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19172",
        "abstract url": "https://arxiv.org/abs/2409.19172",
        "title": "Completely Reachable Almost Group Automata",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider finite deterministic automata such that their alphabets consist of exactly one letter of defect 1 and a set of permutations of the state set. We study under which conditions such an automaton is completely reachable. We focus our attention on the case when the set of permutations generates a transitive imprimitive group.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19176",
        "abstract url": "https://arxiv.org/abs/2409.19176",
        "title": "Polynomial Universes and Dependent Types",
        "rating": "-10",
        "keywords": [],
        "abstract": "Awodey, later with Newstead, showed how polynomial pseudomonads $(u,1,\u03a3)$ with extra structure (termed \"natural models\" by Awodey) hold within them the categorical semantics for dependent type theory. Their work presented these ideas clearly but ultimately led them outside of the category of polynomial functors in order to explain all of the structure possessed by such models of type theory. This paper builds off that work -- explicating the categorical semantics of dependent type theory by axiomatizing them \\emph{entirely} in the language of polynomial functors. In order to handle the higher-categorical coherences required for such an explanation, we work with polynomial functors internally in the language of Homotopy Type Theory, which allows for higher-dimensional structures such as pseudomonads, etc. to be expressed purely in terms of the structure of a suitably-chosen $\\infty$-category of polynomial functors. The move from set theory to Homotopy Type Theory thus has a twofold effect of enabling a simpler exposition of natural models, which is at the same time amenable to formalization in a proof assistant, such as Agda. Moreover, the choice to remain firmly within the setting of polynomial functors reveals many additional structures of natural models that were otherwise left implicit or not considered by Awodey \\& Newstead. Chief among these, we highlight the fact that every polynomial pseudomonad $(u,1,\u03a3)$ as above that is also equipped with structure to interpret dependent product types gives rise to a self-distributive law $u \\triangleleft u\\to u \\triangleleft u$, which witnesses the usual distributive law of dependent products over dependent sums.",
        "subjects": [
            "cs.LO",
            "cs.PL",
            "math.CT"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19180",
        "abstract url": "https://arxiv.org/abs/2409.19180",
        "title": "Esports Training, Periodization, and Tools -- a Scoping Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "Electronic sports (esports) and research on this emerging field are interdisciplinary in nature. By extension, it is essential to understand how to standardize and structure training with the help of existing tools developed by years of research in sports sciences and informatics. Our goal in this article was to verify if the current body of research contains substantial evidence of the training systems applied to training esports players. To verify the existing sources, we have applied a framework of scoping review to address the search from multiple scientific databases with further local processing. We conclude that the current research on esports dealt mainly with describing and modeling performance metrics spanned over multiple fragmented research areas (psychology, nutrition, informatics), and yet these building blocks were not assembled into an existing well-functioning theory of performance in esports by providing exercise regimes, and ways of periodization for esports.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19189",
        "abstract url": "https://arxiv.org/abs/2409.19189",
        "title": "State estimation for parallel-connected batteries via inverse dynamic modeling",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper examines the problem of estimating the states, including state of charge, of battery cells connected in parallel. Previous research highlights the importance of this problem, and presents multiple approaches for solving it. Algorithm scalability and observability analysis can both be challenging, particularly because the underlying pack dynamics are governed by differential algebraic equations. Our work addresses these challenges from a novel perspective that begins by inverting the causality of parallel pack dynamics, which breaks the pack model's underlying algebraic loop. This simplifies observability analysis and observer design significantly, leading to three novel contributions. First, the paper derives mathematical conditions for state observability that apply regardless of the number of battery cells and the order of their individual dynamics. Second, the paper presents an approach for grouping battery cells such that their lumped dynamics are observable. Finally, the paper presents a novel pack state estimator that achieves computational tractability by employing inverse dynamic modeling. We conclude by presenting a Monte Carlo simulation study of this estimator using experimentally-parameterized models of two battery chemistries. The simulation results highlight the computational benefits of both the clustering strategy and inverse dynamics approach for state estimation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "27 pages, 7 figures"
    },
    {
        "paper id": "2409.19211",
        "abstract url": "https://arxiv.org/abs/2409.19211",
        "title": "Programming with High-Level Abstractions, Proceedings of the 3rd Workshop on Logic and Practice of Programming",
        "rating": "-10",
        "keywords": [],
        "abstract": "This proceedings contains abstracts and position papers for the work presented at the third Logic and Practice of Programming (LPOP) Workshop. The workshop was held online, using zoom, at stonybrook.zoom.us, on December 13, 2022. The workshop focused on core high-level abstractions around sets and logic rules, to help bring them to the general practice of programming.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2409.19219",
        "abstract url": "https://arxiv.org/abs/2409.19219",
        "title": "Sharing-Based Channel Access Procedure For Next Generation of Wireless LAN",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper proposes a new channel access procedure to mitigate the channel access contention in next generation of Wireless Local-Area Networks (WLANs) by allowing cooperation among devices belonging to same network, while maintaining high flexibility in terms of how each device may contend the medium. After introducing the details of the proposed procedure, which is here referred to as sharing-based protocol, an analytical analysis is provided to compare it with the two state-of-art protocols currently adopted in IEEE 802.11 standard, i.e, Enhanced Distributed Channel Access (EDCA)-based and trigger-based protocol. In this regards, closed form expressions are derived to evaluate the success probability of channel access for each protocol. In order to show the merit of the proposed procedure, a comprehensive system level analysis is also provided, which highlights that the proposed procedure outperforms the two state-of-art protocols in terms of mitigating the End-to-End (E2E) delay and allowing a better spectrum utilization by reducing the overall congestion in the system.",
        "subjects": [
            "cs.NI",
            "cs.ET",
            "cs.IT"
        ],
        "comment": "6 pages, 8 figures, and 1 Table. Accepted for publication in IEEE Globecom 2024"
    },
    {
        "paper id": "2409.19222",
        "abstract url": "https://arxiv.org/abs/2409.19222",
        "title": "How do Practitioners Perceive Energy Consumption on Stack Overflow?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Energy consumption of software applications has emerged as a critical issue for practitioners to contemplate in their daily development processes. Previous studies have performed user surveys with a limited number of practitioners to comprehend practitioners' viewpoints on energy consumption. In this paper, we complement prior studies by conducting an empirical analysis of a meticulously curated dataset comprising 985 Stack Overflow (SO) questions concerning energy consumption. These questions reflect real-world energy-related predicaments faced by practitioners in their daily development activities. To understand practitioners' perception of energy consumption, we investigate the intentions behind these questions, their semantic topics, as well as the tag categories associated with these questions. Our empirical study results reveal that (i) the intentions that drive the questioners to initiate posts and ask questions are primarily associated with understanding a concept or how to use an API; (ii) the most prevalent topic related to energy consumption concerns computing resources; (iii) monitoring energy usage poses a challenging issue, and it takes the longest response time to receive a community response to the questions; and (iv) practitioners are apprehensive about energy consumption from different levels, i.e., hardware, operating systems, and programming languages, during the development of the applications. Our work furnishes insights into the issues related to energy consumption faced by practitioners. Our observations raise awareness among practitioners about the impact of energy consumption on developing software systems from different perspectives, such as coding efficiency and energy monitoring, and shed light on future research opportunities to assist practitioners in developing energy-efficient software systems.",
        "subjects": [
            "cs.SE",
            "cs.PF"
        ],
        "comment": null
    }
]