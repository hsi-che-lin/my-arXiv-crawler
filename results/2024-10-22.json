[
    {
        "paper id": "2410.17385",
        "abstract url": "https://arxiv.org/abs/2410.17385",
        "title": "Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities",
        "rating": "2.5",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.CV",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Spatial expressions in situated communication can be ambiguous, as their meanings vary depending on the frames of reference (FoR) adopted by speakers and listeners. While spatial language understanding and reasoning by vision-language models (VLMs) have gained increasing attention, potential ambiguities in these models are still under-explored. To address this issue, we present the COnsistent Multilingual Frame Of Reference Test (COMFORT), an evaluation protocol to systematically assess the spatial reasoning capabilities of VLMs. We evaluate nine state-of-the-art VLMs using COMFORT. Despite showing some alignment with English conventions in resolving ambiguities, our experiments reveal significant shortcomings of VLMs: notably, the models (1) exhibit poor robustness and consistency, (2) lack the flexibility to accommodate multiple FoRs, and (3) fail to adhere to language-specific or culture-specific conventions in cross-lingual tests, as English tends to dominate other languages. With a growing effort to align vision-language models with human cognitive intuitions, we call for more attention to the ambiguous nature and cross-cultural diversity of spatial reasoning.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": "Accepted to Pluralistic Alignment @ NeurIPS 2024 | Project page: https://spatial-comfort.github.io/"
    },
    {
        "paper id": "2410.16801",
        "abstract url": "https://arxiv.org/abs/2410.16801",
        "title": "Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "efficient finetuning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) exhibit remarkable capabilities in natural language processing but face catastrophic forgetting when learning new tasks, where adaptation to a new domain leads to a substantial decline in performance on previous tasks. In this paper, we propose Controlled LoRA (CLoRA), a subspace regularization method on LoRA structure. Aiming to reduce the scale of output change while introduce minimal constraint on model capacity, CLoRA imposes constraint on the direction of updating matrix null space. Experimental results on commonly used LLM finetuning tasks reveal that CLoRA significantly outperforms existing LoRA subsequent methods on both in-domain and outdomain evaluations, highlighting the superority of CLoRA as a effective parameter-efficient finetuning method with catastrophic forgetting mitigating. Further investigation for model parameters indicates that CLoRA effectively balances the trade-off between model capacity and degree of forgetting.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16953",
        "abstract url": "https://arxiv.org/abs/2410.16953",
        "title": "Towards Real Zero-Shot Camouflaged Object Segmentation without Camouflaged Annotations",
        "rating": "2",
        "keywords": [
            [
                "Parameter-Efficient",
                "PEFT",
                "Efficient Fine-Tuning"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Camouflaged Object Segmentation (COS) faces significant challenges due to the scarcity of annotated data, where meticulous pixel-level annotation is both labor-intensive and costly, primarily due to the intricate object-background boundaries. Addressing the core question, \"Can COS be effectively achieved in a zero-shot manner without manual annotations for any camouflaged object?\" we affirmatively respond and introduce a robust zero-shot COS framework. This framework leverages the inherent local pattern bias of COS and employs a broad semantic feature space derived from salient object segmentation (SOS) for efficient zero-shot transfer. We incorporate an Masked Image Modeling (MIM) based image encoder optimized for Parameter-Efficient Fine-Tuning (PEFT), a Multimodal Large Language Model (M-LLM), and a Multi-scale Fine-grained Alignment (MFA) mechanism. The MIM pre-trained image encoder focuses on capturing essential low-level features, while the M-LLM generates caption embeddings processed alongside these visual cues. These embeddings are precisely aligned using MFA, enabling our framework to accurately interpret and navigate complex semantic contexts. To optimize operational efficiency, we introduce a learnable codebook that represents the M-LLM during inference, significantly reducing computational overhead. Our framework demonstrates its versatility and efficacy through rigorous experimentation, achieving state-of-the-art performance in zero-shot COS with $F_\u03b2^w$ scores of 72.9\\% on CAMO and 71.7\\% on COD10K. By removing the M-LLM during inference, we achieve an inference speed comparable to that of traditional end-to-end models, reaching 18.1 FPS. Code: https://github.com/R-LEI360725/ZSCOS-CaMF",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17152",
        "abstract url": "https://arxiv.org/abs/2410.17152",
        "title": "Improving Pinterest Search Relevance Using Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "visual language"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "To improve relevance scoring on Pinterest Search, we integrate Large Language Models (LLMs) into our search relevance model, leveraging carefully designed text representations to predict the relevance of Pins effectively. Our approach uses search queries alongside content representations that include captions extracted from a generative visual language model. These are further enriched with link-based text data, historically high-quality engaged queries, user-curated boards, Pin titles and Pin descriptions, creating robust models for predicting search relevance. We use a semi-supervised learning approach to efficiently scale up the amount of training data, expanding beyond the expensive human labeled data available. By utilizing multilingual LLMs, our system extends training data to include unseen languages and domains, despite initial data and annotator expertise being confined to English. Furthermore, we distill from the LLM-based model into real-time servable model architectures and features. We provide comprehensive offline experimental validation for our proposed techniques and demonstrate the gains achieved through the final deployed system at scale.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": "CIKM 2024 Workshop on Industrial Recommendation Systems"
    },
    {
        "paper id": "2410.17243",
        "abstract url": "https://arxiv.org/abs/2410.17243",
        "title": "Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss",
        "rating": "2",
        "keywords": [
            [
                "memory-efficient",
                "GPU memory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Contrastive loss is a powerful approach for representation learning, where larger batch sizes enhance performance by providing more negative samples to better distinguish between similar and dissimilar data. However, scaling batch sizes is constrained by the quadratic growth in GPU memory consumption, primarily due to the full instantiation of the similarity matrix. To address this, we propose a tile-based computation strategy that partitions the contrastive loss calculation into arbitrary small blocks, avoiding full materialization of the similarity matrix. Furthermore, we introduce a multi-level tiling strategy to leverage the hierarchical structure of distributed systems, employing ring-based communication at the GPU level to optimize synchronization and fused kernels at the CUDA core level to reduce I/O overhead. Experimental results show that the proposed method scales batch sizes to unprecedented levels. For instance, it enables contrastive training of a CLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GB without sacrificing any accuracy. Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed. The code will be made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17247",
        "abstract url": "https://arxiv.org/abs/2410.17247",
        "title": "PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "In large vision-language models (LVLMs), images serve as inputs that carry a wealth of information. As the idiom \"A picture is worth a thousand words\" implies, representing a single image in current LVLMs can require hundreds or even thousands of tokens. This results in significant computational costs, which grow quadratically as input image resolution increases, thereby severely impacting the efficiency of both training and inference. Previous approaches have attempted to reduce the number of image tokens either before or within the early layers of LVLMs. However, these strategies inevitably result in the loss of crucial image information, ultimately diminishing model performance. To address this challenge, we conduct an empirical study revealing that all visual tokens are necessary for LVLMs in the shallow layers, and token redundancy progressively increases in the deeper layers of the model. To this end, we propose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost their efficiency in both training and inference with neglectable performance loss. Specifically, we partition the LVLM into several stages and drop part of the image tokens at the end of each stage with a pre-defined ratio, creating pyramid-like visual tokens across model layers. The dropping is based on a lightweight similarity calculation with a negligible time overhead. Extensive experiments demonstrate that PyramidDrop can achieve a 40% training time and 55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance. Besides, the PyramidDrop could also serve as a plug-and-play strategy for inference acceleration without training, with better performance and lower inference cost than counterparts. We hope that the insights and approach introduced by PyramidDrop will inspire future research to further investigate the role of image tokens in LVLMs.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2410.16744",
        "abstract url": "https://arxiv.org/abs/2410.16744",
        "title": "Time-Resolved MNIST Dataset for Single-Photon Recognition",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Time-resolved single photon imaging is a promising imaging modality characterized by the unique capability of timestamping the arrivals of single photons. Single-Photon Avalanche Diodes (SPADs) are the leading technology for implementing modern time-resolved pixels, suitable for passive imaging with asynchronous readout. However, they are currently limited to small sized arrays, thus there is a lack of datasets for passive time-resolved SPAD imaging, which in turn hinders research on this peculiar imaging data. In this paper we describe a realistic simulation process for SPAD imaging, which takes into account both the stochastic nature of photon arrivals and all the noise sources involved in the acquisition process of time-resolved SPAD arrays. We have implemented this simulator in a software prototype able to generate arbitrary-sized time-resolved SPAD arrays operating in passive mode. Starting from a reference image, our simulator generates a realistic stream of timestamped photon detections. We use our simulator to generate a time-resolved version of MNIST, which we make publicly available. Our dataset has the purpose of encouraging novel research directions in time-resolved SPAD imaging, as well as investigating the performance of CNN classifiers in extremely low-light conditions.",
        "subjects": [
            "cs.CV",
            "physics.ins-det"
        ],
        "comment": "12 pages, 4 figures. Accepted for Workshop on Synthetic Data for Computer Vision at ECCV 2024"
    },
    {
        "paper id": "2410.16788",
        "abstract url": "https://arxiv.org/abs/2410.16788",
        "title": "Correct after Answer: Enhancing Multi-Span Question Answering with Post-Processing Method",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Multi-Span Question Answering (MSQA) requires models to extract one or multiple answer spans from a given context to answer a question. Prior work mainly focuses on designing specific methods or applying heuristic strategies to encourage models to predict more correct predictions. However, these models are trained on gold answers and fail to consider the incorrect predictions. Through a statistical analysis, we observe that models with stronger abilities do not predict less incorrect predictions compared with other models. In this work, we propose Answering-Classifying-Correcting (ACC) framework, which employs a post-processing strategy to handle incorrect predictions. Specifically, the ACC framework first introduces a classifier to classify the predictions into three types and exclude \"wrong predictions\", then introduces a corrector to modify \"partially correct predictions\". Experiments on several MSQA datasets show that ACC framework significantly improves the Exact Match (EM) scores, and further analysis demostrates that ACC framework efficiently reduces the number of incorrect predictions, improving the quality of predictions.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted by EMNLP 2024 Findings"
    },
    {
        "paper id": "2410.16843",
        "abstract url": "https://arxiv.org/abs/2410.16843",
        "title": "Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Trustworthiness is an essential prerequisite for the real-world application of large language models. In this paper, we focus on the trustworthiness of language models with respect to retrieval augmentation. Despite being supported with external evidence, retrieval-augmented generation still suffers from hallucinations, one primary cause of which is the conflict between contextual and parametric knowledge. We deem that retrieval-augmented language models have the inherent capabilities of supplying response according to both contextual and parametric knowledge. Inspired by aligning language models with human preference, we take the first step towards aligning retrieval-augmented language models to a status where it responds relying merely on the external evidence and disregards the interference of parametric knowledge. Specifically, we propose a reinforcement learning based algorithm Trustworthy-Alignment, theoretically and experimentally demonstrating large language models' capability of reaching a trustworthy status without explicit supervision on how to respond. Our work highlights the potential of large language models on exploring its intrinsic abilities by its own and expands the application scenarios of alignment from fulfilling human preference to creating trustworthy agents.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "ICML 2024"
    },
    {
        "paper id": "2410.16973",
        "abstract url": "https://arxiv.org/abs/2410.16973",
        "title": "Learning Mathematical Rules with Large Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In this paper, we study the ability of large language models to learn specific mathematical rules such as distributivity or simplifying equations. We present an empirical analysis of their ability to generalize these rules, as well as to reuse them in the context of word problems. For this purpose, we provide a rigorous methodology to build synthetic data incorporating such rules, and perform fine-tuning of large language models on such data. Our experiments show that our model can learn and generalize these rules to some extent, as well as suitably reuse them in the context of word problems.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "NeurIPS'24 MATH-AI, the 4th Workshop on Mathematical Reasoning and AI"
    },
    {
        "paper id": "2410.17020",
        "abstract url": "https://arxiv.org/abs/2410.17020",
        "title": "LFME: A Simple Framework for Learning from Multiple Experts in Domain Generalization",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Domain generalization (DG) methods aim to maintain good performance in an unseen target domain by using training data from multiple source domains. While success on certain occasions are observed, enhancing the baseline across most scenarios remains challenging. This work introduces a simple yet effective framework, dubbed learning from multiple experts (LFME), that aims to make the target model an expert in all source domains to improve DG. Specifically, besides learning the target model used in inference, LFME will also train multiple experts specialized in different domains, whose output probabilities provide professional guidance by simply regularizing the logit of the target model. Delving deep into the framework, we reveal that the introduced logit regularization term implicitly provides effects of enabling the target model to harness more information, and mining hard samples from the experts during training. Extensive experiments on benchmarks from different DG tasks demonstrate that LFME is consistently beneficial to the baseline and can achieve comparable performance to existing arts. Code is available at~\\url{https://github.com/liangchen527/LFME}.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2410.17099",
        "abstract url": "https://arxiv.org/abs/2410.17099",
        "title": "Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "The quality is a crucial issue for crowd annotations. Answer aggregation is an important type of solution. The aggregated answers estimated from multiple crowd answers to the same instance are the eventually collected annotations, rather than the individual crowd answers themselves. Recently, the capability of Large Language Models (LLMs) on data annotation tasks has attracted interest from researchers. Most of the existing studies mainly focus on the average performance of individual crowd workers; several recent works studied the scenarios of aggregation on categorical labels and LLMs used as label creators. However, the scenario of aggregation on text answers and the role of LLMs as aggregators are not yet well-studied. In this paper, we investigate the capability of LLMs as aggregators in the scenario of close-ended crowd text answer aggregation. We propose a human-LLM hybrid text answer aggregation method with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. We make the experiments based on public crowdsourcing datasets. The results show the effectiveness of our approach based on the collaboration of crowd workers and LLMs.",
        "subjects": [
            "cs.CL",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "Accepted in EMNLP 2024"
    },
    {
        "paper id": "2410.17145",
        "abstract url": "https://arxiv.org/abs/2410.17145",
        "title": "Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation ?",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Large language models (LLMs) perform well on common tasks but struggle with generalization in low-resource and low-computation settings. We examine this limitation by testing various LLMs and specialized translation models on English-Thai machine translation and code-switching datasets. Our findings reveal that under more strict computational constraints, such as 4-bit quantization, LLMs fail to translate effectively. In contrast, specialized models, with comparable or lower computational requirements, consistently outperform LLMs. This underscores the importance of specialized models for maintaining performance under resource constraints.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted in GenBench EMNLP 2024"
    },
    {
        "paper id": "2410.17234",
        "abstract url": "https://arxiv.org/abs/2410.17234",
        "title": "Fine-Tuning Large Language Models to Appropriately Abstain with Semantic Entropy",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are known to hallucinate, whereby they generate plausible but inaccurate text. This phenomenon poses significant risks in critical applications, such as medicine or law, necessitating robust hallucination mitigation strategies. While recent works have proposed fine-tuning methods to teach LLMs to abstain from answering questions beyond their knowledge or capabilities, these methods rely on the existence of ground-truth labels or are limited to short-form responses. To address these limitations, we propose fine-tuning using semantic entropy, an uncertainty measure derived from introspection into the model which does not require external labels. We demonstrate that our approach matches or outperforms models fine-tuned using prior work and achieves strong performance for both short and long-form generations on a range of datasets.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted to NeurIPS Safe Generative AI Workshop 2024"
    },
    {
        "paper id": "2410.17245",
        "abstract url": "https://arxiv.org/abs/2410.17245",
        "title": "Towards Reliable Evaluation of Behavior Steering Interventions in LLMs",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Representation engineering methods have recently shown promise for enabling efficient steering of model behavior. However, evaluation pipelines for these methods have primarily relied on subjective demonstrations, instead of quantitative, objective metrics. We aim to take a step towards addressing this issue by advocating for four properties missing from current evaluations: (i) contexts sufficiently similar to downstream tasks should be used for assessing intervention quality; (ii) model likelihoods should be accounted for; (iii) evaluations should allow for standardized comparisons across different target behaviors; and (iv) baseline comparisons should be offered. We introduce an evaluation pipeline grounded in these criteria, offering both a quantitative and visual analysis of how effectively a given method works. We use this pipeline to evaluate two representation engineering methods on how effectively they can steer behaviors such as truthfulness and corrigibility, finding that some interventions are less effective than previously reported.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Accepted to the NeurIPS 2024 - Workshop on Foundation Model Interventions"
    },
    {
        "paper id": "2410.17358",
        "abstract url": "https://arxiv.org/abs/2410.17358",
        "title": "FairLoRA: Unpacking Bias Mitigation in Vision Models with Fairness-Driven Low-Rank Adaptation",
        "rating": "1.5",
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advances in parameter-efficient fine-tuning methods, such as Low Rank Adaptation (LoRA), have gained significant attention for their ability to efficiently adapt large foundational models to various downstream tasks. These methods are appreciated for achieving performance comparable to full fine-tuning on aggregate-level metrics, while significantly reducing computational costs. To systematically address fairness in LLMs previous studies fine-tune on fairness specific data using a larger LoRA rank than typically used. In this paper, we introduce FairLoRA, a novel fairness-specific regularizer for LoRA aimed at reducing performance disparities across data subgroups by minimizing per-class variance in loss. To the best of our knowledge, we are the first to introduce a fairness based finetuning through LoRA. Our results demonstrate that the need for higher ranks to mitigate bias is not universal; it depends on factors such as the pre-trained model, dataset, and task. More importantly, we systematically evaluate FairLoRA across various vision models, including ViT, DiNO, and CLIP, in scenarios involving distribution shifts. We further emphasize the necessity of using multiple fairness metrics to obtain a holistic assessment of fairness, rather than relying solely on the metric optimized during training.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17534",
        "abstract url": "https://arxiv.org/abs/2410.17534",
        "title": "OVT-B: A New Large-Scale Benchmark for Open-Vocabulary Multi-Object Tracking",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Open-vocabulary object perception has become an important topic in artificial intelligence, which aims to identify objects with novel classes that have not been seen during training. Under this setting, open-vocabulary object detection (OVD) in a single image has been studied in many literature. However, open-vocabulary object tracking (OVT) from a video has been studied less, and one reason is the shortage of benchmarks. In this work, we have built a new large-scale benchmark for open-vocabulary multi-object tracking namely OVT-B. OVT-B contains 1,048 categories of objects and 1,973 videos with 637,608 bounding box annotations, which is much larger than the sole open-vocabulary tracking dataset, i.e., OVTAO-val dataset (200+ categories, 900+ videos). The proposed OVT-B can be used as a new benchmark to pave the way for OVT research. We also develop a simple yet effective baseline method for OVT. It integrates the motion features for object tracking, which is an important feature for MOT but is ignored in previous OVT methods. Experimental results have verified the usefulness of the proposed benchmark and the effectiveness of our method. We have released the benchmark to the public at https://github.com/Coo1Sea/OVT-B-Dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15 pages, 6 figures, accepted at NeurIPS 2024 Dataset and Benchmark Track"
    },
    {
        "paper id": "2410.16695",
        "abstract url": "https://arxiv.org/abs/2410.16695",
        "title": "MPT: A Large-scale Multi-Phytoplankton Tracking Benchmark",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Phytoplankton are a crucial component of aquatic ecosystems, and effective monitoring of them can provide valuable insights into ocean environments and ecosystem changes. Traditional phytoplankton monitoring methods are often complex and lack timely analysis. Therefore, deep learning algorithms offer a promising approach for automated phytoplankton monitoring. However, the lack of large-scale, high-quality training samples has become a major bottleneck in advancing phytoplankton tracking. In this paper, we propose a challenging benchmark dataset, Multiple Phytoplankton Tracking (MPT), which covers diverse background information and variations in motion during observation. The dataset includes 27 species of phytoplankton and zooplankton, 14 different backgrounds to simulate diverse and complex underwater environments, and a total of 140 videos. To enable accurate real-time observation of phytoplankton, we introduce a multi-object tracking method, Deviation-Corrected Multi-Scale Feature Fusion Tracker(DSFT), which addresses issues such as focus shifts during tracking and the loss of small target information when computing frame-to-frame similarity. Specifically, we introduce an additional feature extractor to predict the residuals of the standard feature extractor's output, and compute multi-scale frame-to-frame similarity based on features from different layers of the extractor. Extensive experiments on the MPT have demonstrated the validity of the dataset and the superiority of DSFT in tracking phytoplankton, providing an effective solution for phytoplankton monitoring.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16707",
        "abstract url": "https://arxiv.org/abs/2410.16707",
        "title": "DI-MaskDINO: A Joint Object Detection and Instance Segmentation Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper is motivated by an interesting phenomenon: the performance of object detection lags behind that of instance segmentation (i.e., performance imbalance) when investigating the intermediate results from the beginning transformer decoder layer of MaskDINO (i.e., the SOTA model for joint detection and segmentation). This phenomenon inspires us to think about a question: will the performance imbalance at the beginning layer of transformer decoder constrain the upper bound of the final performance? With this question in mind, we further conduct qualitative and quantitative pre-experiments, which validate the negative impact of detection-segmentation imbalance issue on the model performance. To address this issue, this paper proposes DI-MaskDINO model, the core idea of which is to improve the final performance by alleviating the detection-segmentation imbalance. DI-MaskDINO is implemented by configuring our proposed De-Imbalance (DI) module and Balance-Aware Tokens Optimization (BATO) module to MaskDINO. DI is responsible for generating balance-aware query, and BATO uses the balance-aware query to guide the optimization of the initial feature tokens. The balance-aware query and optimized feature tokens are respectively taken as the Query and Key&Value of transformer decoder to perform joint object detection and instance segmentation. DI-MaskDINO outperforms existing joint object detection and instance segmentation models on COCO and BDD100K benchmarks, achieving +1.2 $AP^{box}$ and +0.9 $AP^{mask}$ improvements compared to SOTA joint detection and segmentation model MaskDINO. In addition, DI-MaskDINO also obtains +1.0 $AP^{box}$ improvement compared to SOTA object detection model DINO and +3.0 $AP^{mask}$ improvement compared to SOTA segmentation model Mask2Former.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, 3 figures, Conference on Neural Information Processing Systems"
    },
    {
        "paper id": "2410.16712",
        "abstract url": "https://arxiv.org/abs/2410.16712",
        "title": "DENOASR: Debiasing ASRs through Selective Denoising",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Automatic Speech Recognition (ASR) systems have been examined and shown to exhibit biases toward particular groups of individuals, influenced by factors such as demographic traits, accents, and speech styles. Noise can disproportionately impact speakers with certain accents, dialects, or speaking styles, leading to biased error rates. In this work, we introduce a novel framework DENOASR, which is a selective denoising technique to reduce the disparity in the word error rates between the two gender groups, male and female. We find that a combination of two popular speech denoising techniques, viz. DEMUCS and LE, can be effectively used to mitigate ASR disparity without compromising their overall performance. Experiments using two state-of-the-art open-source ASRs - OpenAI WHISPER and NVIDIA NEMO - on multiple benchmark datasets, including TIE, VOX-POPULI, TEDLIUM, and FLEURS, show that there is a promising reduction in the average word error rate gap across the two gender groups. For a given dataset, the denoising is selectively applied on speech samples having speech intelligibility below a certain threshold, estimated using a small validation sample, thus ameliorating the need for large-scale human-written ground-truth transcripts. Our findings suggest that selective denoising can be an elegant approach to mitigate biases in present-day ASR systems.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "Paper accepted at IEEE ICKG 2024"
    },
    {
        "paper id": "2410.16714",
        "abstract url": "https://arxiv.org/abs/2410.16714",
        "title": "Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Models Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Self-play methods have demonstrated remarkable success in enhancing model capabilities across various domains. In the context of Reinforcement Learning from Human Feedback (RLHF), self-play not only boosts Large Language Model (LLM) performance but also overcomes the limitations of traditional Bradley-Terry (BT) model assumptions by finding the Nash equilibrium (NE) of a preference-based, two-player constant-sum game. However, existing methods either guarantee only average-iterate convergence, incurring high storage and inference costs, or converge to the NE of a regularized game, failing to accurately reflect true human preferences. In this paper, we introduce Magnetic Preference Optimization (MPO), a novel approach capable of achieving last-iterate convergence to the NE of the original game, effectively overcoming the limitations of existing methods. Building upon Magnetic Mirror Descent (MMD), MPO attains a linear convergence rate, making it particularly suitable for fine-tuning LLMs. To ensure our algorithm is both theoretically sound and practically viable, we present a simple yet effective implementation that adapts the theoretical insights to the RLHF setting. Empirical results demonstrate that MPO can significantly enhance the performance of LLMs, highlighting the potential of self-play methods in alignment.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2410.16736",
        "abstract url": "https://arxiv.org/abs/2410.16736",
        "title": "Forewarned is Forearmed: Leveraging LLMs for Data Synthesis through Failure-Inducing Exploration",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have significantly benefited from training on diverse, high-quality task-specific data, leading to impressive performance across a range of downstream applications. Current methods often rely on human-annotated data or predefined task templates to direct powerful LLMs in synthesizing task-relevant data for effective model training. However, this dependence on manually designed components may constrain the scope of generated data, potentially overlooking critical edge cases or novel scenarios that could challenge the model. In this paper, we present a novel approach, ReverseGen, designed to automatically generate effective training samples that expose the weaknesses of LLMs. Specifically, we introduce a dedicated proposer trained to produce queries that lead target models to generate unsatisfactory responses. These failure-inducing queries are then used to construct training data, helping to address the models' shortcomings and improve overall performance. Our approach is flexible and can be applied to models of various scales (3B, 7B, and 8B). We evaluate ReverseGen on three key applications (safety, honesty, and math), demonstrating that our generated data is both highly effective and diverse. Models fine-tuned with ReverseGen-generated data consistently outperform those trained on human-annotated or general model-generated data, offering a new perspective on data synthesis for task-specific LLM enhancement.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16775",
        "abstract url": "https://arxiv.org/abs/2410.16775",
        "title": "Context-Aware LLM Translation System Using Conversation Summarization and Dialogue History",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Translating conversational text, particularly in customer support contexts, presents unique challenges due to its informal and unstructured nature. We propose a context-aware LLM translation system that leverages conversation summarization and dialogue history to enhance translation quality for the English-Korean language pair. Our approach incorporates the two most recent dialogues as raw data and a summary of earlier conversations to manage context length effectively. We demonstrate that this method significantly improves translation accuracy, maintaining coherence and consistency across conversations. This system offers a practical solution for customer support translation tasks, addressing the complexities of conversational text.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to WMT 2024"
    },
    {
        "paper id": "2410.16812",
        "abstract url": "https://arxiv.org/abs/2410.16812",
        "title": "Optimizing Chain-of-Thought Reasoning: Tackling Arranging Bottleneck via Plan Augmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Multi-step reasoning ability of large language models is crucial in tasks such as math and tool utilization. Current researches predominantly focus on enhancing model performance in these multi-step reasoning tasks through fine-tuning with Chain-of-Thought (CoT) steps, yet these methods tend to be heuristic, without exploring nor resolving the bottleneck. In this study, we subdivide CoT reasoning into two parts: arranging and executing, and identify that the bottleneck of models mainly lies in arranging rather than executing. Based on this finding, we propose a plan-based training and reasoning method that guides models to generate arranging steps through abstract plans. We experiment on both math (GSM8k) and tool utilization (ToolBench) benchmarks. Results show that compared to fine-tuning directly with CoT data, our approach achieves a better performance on alleviating arranging bottleneck, particularly excelling in long-distance reasoning generalization.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16813",
        "abstract url": "https://arxiv.org/abs/2410.16813",
        "title": "Klein Model for Hyperbolic Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Hyperbolic neural networks (HNNs) have been proved effective in modeling complex data structures. However, previous works mainly focused on the Poincar\u00e9 ball model and the hyperboloid model as coordinate representations of the hyperbolic space, often neglecting the Klein model. Despite this, the Klein model offers its distinct advantages thanks to its straight-line geodesics, which facilitates the well-known Einstein midpoint construction, previously leveraged to accompany HNNs in other models. In this work, we introduce a framework for hyperbolic neural networks based on the Klein model. We provide detailed formulation for representing useful operations using the Klein model. We further study the Klein linear layer and prove that the \"tangent space construction\" of the scalar multiplication and parallel transport are exactly the Einstein scalar multiplication and the Einstein addition, analogous to the M\u00f6bius operations used in the Poincar\u00e9 ball model. We show numerically that the Klein HNN performs on par with the Poincar\u00e9 ball model, providing a third option for HNN that works as a building block for more complicated architectures.",
        "subjects": [
            "cs.LG",
            "cs.IT",
            "stat.ML"
        ],
        "comment": "Accepted to NeurIPS 2024 Symmetry and Geometry in Neural Representations Workshop"
    },
    {
        "paper id": "2410.16824",
        "abstract url": "https://arxiv.org/abs/2410.16824",
        "title": "PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Generating detailed descriptions from multiple cameras and viewpoints is challenging due to the complex and inconsistent nature of visual data. In this paper, we introduce PerspectiveNet, a lightweight yet efficient model for generating long descriptions across multiple camera views. Our approach utilizes a vision encoder, a compact connector module to convert visual features into a fixed-size tensor, and large language models (LLMs) to harness the strong natural language generation capabilities of LLMs. The connector module is designed with three main goals: mapping visual features onto LLM embeddings, emphasizing key information needed for description generation, and producing a fixed-size feature matrix. Additionally, we augment our solution with a secondary task, the correct frame sequence detection, enabling the model to search for the correct sequence of frames to generate descriptions. Finally, we integrate the connector module, the secondary task, the LLM, and a visual feature extraction model into a single architecture, which is trained for the Traffic Safety Description and Analysis task. This task requires generating detailed, fine-grained descriptions of events from multiple cameras and viewpoints. The resulting model is lightweight, ensuring efficient training and inference, while remaining highly effective.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "6 pages, 2 figures"
    },
    {
        "paper id": "2410.16834",
        "abstract url": "https://arxiv.org/abs/2410.16834",
        "title": "Analyzing and Evaluating Correlation Measures in NLG Meta-Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The correlation between NLG automatic evaluation metrics and human evaluation is often regarded as a critical criterion for assessing the capability of an evaluation metric. However, different grouping methods and correlation coefficients result in various types of correlation measures used in meta-evaluation. In specific evaluation scenarios, prior work often directly follows conventional measure settings, but the characteristics and differences between these measures have not gotten sufficient attention. Therefore, this paper analyzes 12 common correlation measures using a large amount of real-world data from six widely-used NLG evaluation datasets and 32 evaluation metrics, revealing that different measures indeed impact the meta-evaluation results. Furthermore, we propose three perspectives that reflect the capability of meta-evaluation and find that the measure using global grouping and Pearson correlation exhibits the best overall performance, involving the discriminative power, ranking consistency, and sensitivity to score granularity.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16840",
        "abstract url": "https://arxiv.org/abs/2410.16840",
        "title": "MPDS: A Movie Posters Dataset for Image Generation with Diffusion Model",
        "rating": "1",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Movie posters are vital for captivating audiences, conveying themes, and driving market competition in the film industry. While traditional designs are laborious, intelligent generation technology offers efficiency gains and design enhancements. Despite exciting progress in image generation, current models often fall short in producing satisfactory poster results. The primary issue lies in the absence of specialized poster datasets for targeted model training. In this work, we propose a Movie Posters DataSet (MPDS), tailored for text-to-image generation models to revolutionize poster production. As dedicated to posters, MPDS stands out as the first image-text pair dataset to our knowledge, composing of 373k+ image-text pairs and 8k+ actor images (covering 4k+ actors). Detailed poster descriptions, such as movie titles, genres, casts, and synopses, are meticulously organized and standardized based on public movie synopsis, also named movie-synopsis prompt. To bolster poster descriptions as well as reduce differences from movie synopsis, further, we leverage a large-scale vision-language model to automatically produce vision-perceptive prompts for each poster, then perform manual rectification and integration with movie-synopsis prompt. In addition, we introduce a prompt of poster captions to exhibit text elements in posters like actor names and movie titles. For movie poster generation, we develop a multi-condition diffusion framework that takes poster prompt, poster caption, and actor image (for personalization) as inputs, yielding excellent results through the learning of a diffusion model. Experiments demonstrate the valuable role of our proposed MPDS dataset in advancing personalized movie poster generation. MPDS is available at https://anonymous.4open.science/r/MPDS-373k-BD3B.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16842",
        "abstract url": "https://arxiv.org/abs/2410.16842",
        "title": "Assessment of Transformer-Based Encoder-Decoder Model for Human-Like Summarization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In recent times, extracting valuable information from large text is making significant progress. Especially in the current era of social media, people expect quick bites of information. Automatic text summarization seeks to tackle this by slimming large texts down into more manageable summaries. This important research area can aid in decision-making by digging out salient content from large text. With the progress in deep learning models, significant work in language models has emerged. The encoder-decoder framework in deep learning has become the central approach for automatic text summarization. This work leverages transformer-based BART model for human-like summarization which is an open-ended problem with many challenges. On training and fine-tuning the encoder-decoder model, it is tested with diverse sample articles and the quality of summaries of diverse samples is assessed based on human evaluation parameters. Further, the finetuned model performance is compared with the baseline pretrained model based on evaluation metrics like ROUGE score and BERTScore. Additionally, domain adaptation of the model is required for improved performance of abstractive summarization of dialogues between interlocutors. On investigating, the above popular evaluation metrics are found to be insensitive to factual errors. Further investigation of the summaries generated by finetuned model is done using the contemporary evaluation metrics of factual consistency like WeCheck and SummaC. Empirical results on BBC News articles highlight that the gold standard summaries written by humans are more factually consistent by 17% than the abstractive summaries generated by finetuned model.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Pre-print"
    },
    {
        "paper id": "2410.16845",
        "abstract url": "https://arxiv.org/abs/2410.16845",
        "title": "Fast Graph Sharpness-Aware Minimization for Enhancing and Accelerating Few-Shot Node Classification",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have shown superior performance in node classification. However, GNNs perform poorly in the Few-Shot Node Classification (FSNC) task that requires robust generalization to make accurate predictions for unseen classes with limited labels. To tackle the challenge, we propose the integration of Sharpness-Aware Minimization (SAM)--a technique designed to enhance model generalization by finding a flat minimum of the loss landscape--into GNN training. The standard SAM approach, however, consists of two forward-backward steps in each training iteration, doubling the computational cost compared to the base optimizer (e.g., Adam). To mitigate this drawback, we introduce a novel algorithm, Fast Graph Sharpness-Aware Minimization (FGSAM), that integrates the rapid training of Multi-Layer Perceptrons (MLPs) with the superior performance of GNNs. Specifically, we utilize GNNs for parameter perturbation while employing MLPs to minimize the perturbed loss so that we can find a flat minimum with good generalization more efficiently. Moreover, our method reutilizes the gradient from the perturbation phase to incorporate graph topology into the minimization process at almost zero additional cost. To further enhance training efficiency, we develop FGSAM+ that executes exact perturbations periodically. Extensive experiments demonstrate that our proposed algorithm outperforms the standard SAM with lower computational costs in FSNC tasks. In particular, our FGSAM+ as a SAM variant offers a faster optimization than the base optimizer in most cases. In addition to FSNC, our proposed methods also demonstrate competitive performance in the standard node classification task for heterophilic graphs, highlighting the broad applicability. The code is available at https://github.com/draym28/FGSAM_NeurIPS24.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "NeurIPS24; The first two authors contributed equally to this work"
    },
    {
        "paper id": "2410.16848",
        "abstract url": "https://arxiv.org/abs/2410.16848",
        "title": "ETHIC: Evaluating Large Language Models on Long-Context Tasks with High Information Coverage",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLM) capable of processing extremely long texts highlight the need for a dedicated evaluation benchmark to assess their long-context capabilities. However, existing methods, like the needle-in-a-haystack test, do not effectively assess whether these models fully utilize contextual information, raising concerns about the reliability of current evaluation techniques. To thoroughly examine the effectiveness of existing benchmarks, we introduce a new metric called information coverage (IC), which quantifies the proportion of the input context necessary for answering queries. Our findings indicate that current benchmarks exhibit low IC; although the input context may be extensive, the actual usable context is often limited. To address this, we present ETHIC, a novel benchmark designed to assess LLMs' ability to leverage the entire context. Our benchmark comprises 2,648 test instances spanning four long-context tasks with high IC scores in the domains of books, debates, medicine, and law. Our evaluations reveal significant performance drops in contemporary LLMs, highlighting a critical challenge in managing long contexts. Our benchmark is available at https://github.com/dmis-lab/ETHIC.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "15 pages, 5 figures"
    },
    {
        "paper id": "2410.16853",
        "abstract url": "https://arxiv.org/abs/2410.16853",
        "title": "Bridging the Modality Gap: Dimension Information Alignment and Sparse Spatial Constraint for Image-Text Matching",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Many contrastive learning based models have achieved advanced performance in image-text matching tasks. The key of these models lies in analyzing the correlation between image-text pairs, which involves cross-modal interaction of embeddings in corresponding dimensions. However, the embeddings of different modalities are from different models or modules, and there is a significant modality gap. Directly interacting such embeddings lacks rationality and may capture inaccurate correlation. Therefore, we propose a novel method called DIAS to bridge the modality gap from two aspects: (1) We align the information representation of embeddings from different modalities in corresponding dimension to ensure the correlation calculation is based on interactions of similar information. (2) The spatial constraints of inter- and intra-modalities unmatched pairs are introduced to ensure the effectiveness of semantic alignment of the model. Besides, a sparse correlation algorithm is proposed to select strong correlated spatial relationships, enabling the model to learn more significant features and avoid being misled by weak correlation. Extensive experiments demonstrate the superiority of DIAS, achieving 4.3\\%-10.2\\% rSum improvements on Flickr30k and MSCOCO benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16857",
        "abstract url": "https://arxiv.org/abs/2410.16857",
        "title": "Nash Meets Wertheimer: Using Good Continuation in Jigsaw Puzzles",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Jigsaw puzzle solving is a challenging task for computer vision since it requires high-level spatial and semantic reasoning. To solve the problem, existing approaches invariably use color and/or shape information but in many real-world scenarios, such as in archaeological fresco reconstruction, this kind of clues is often unreliable due to severe physical and pictorial deterioration of the individual fragments. This makes state-of-the-art approaches entirely unusable in practice. On the other hand, in such cases, simple geometrical patterns such as lines or curves offer a powerful yet unexplored clue. In an attempt to fill in this gap, in this paper we introduce a new challenging version of the puzzle solving problem in which one deliberately ignores conventional color and shape features and relies solely on the presence of linear geometrical patterns. The reconstruction process is then only driven by one of the most fundamental principles of Gestalt perceptual organization, namely Wertheimer's {\\em law of good continuation}. In order to tackle this problem, we formulate the puzzle solving problem as the problem of finding a Nash equilibrium of a (noncooperative) multiplayer game and use classical multi-population replicator dynamics to solve it. The proposed approach is general and allows us to deal with pieces of arbitrary shape, size and orientation. We evaluate our approach on both synthetic and real-world data and compare it with state-of-the-art algorithms. The results show the intrinsic complexity of our purely line-based puzzle problem as well as the relative effectiveness of our game-theoretic formulation.",
        "subjects": [
            "cs.GT",
            "cs.CV"
        ],
        "comment": "to be published in ACCV2024"
    },
    {
        "paper id": "2410.16868",
        "abstract url": "https://arxiv.org/abs/2410.16868",
        "title": "Rethinking generalization of classifiers in separable classes scenarios and over-parameterized regimes",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We investigate the learning dynamics of classifiers in scenarios where classes are separable or classifiers are over-parameterized. In both cases, Empirical Risk Minimization (ERM) results in zero training error. However, there are many global minima with a training error of zero, some of which generalize well and some of which do not. We show that in separable classes scenarios the proportion of \"bad\" global minima diminishes exponentially with the number of training data n. Our analysis provides bounds and learning curves dependent solely on the density distribution of the true error for the given classifier function set, irrespective of the set's size or complexity (e.g., number of parameters). This observation may shed light on the unexpectedly good generalization of over-parameterized Neural Networks. For the over-parameterized scenario, we propose a model for the density distribution of the true error, yielding learning curves that align with experiments on MNIST and CIFAR-10.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16884",
        "abstract url": "https://arxiv.org/abs/2410.16884",
        "title": "Network Inversion for Training-Like Data Reconstruction",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Machine Learning models are often trained on proprietary and private data that cannot be shared, though the trained models themselves are distributed openly assuming that sharing model weights is privacy preserving, as training data is not expected to be inferred from the model weights. In this paper, we present Training-Like Data Reconstruction (TLDR), a network inversion-based approach to reconstruct training-like data from trained models. To begin with, we introduce a comprehensive network inversion technique that learns the input space corresponding to different classes in the classifier using a single conditioned generator. While inversion may typically return random and arbitrary input images for a given output label, we modify the inversion process to incentivize the generator to reconstruct training-like data by exploiting key properties of the classifier with respect to the training data along with some prior knowledge about the images. To validate our approach, we conduct empirical evaluations on multiple standard vision classification datasets, thereby highlighting the potential privacy risks involved in sharing machine learning models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16897",
        "abstract url": "https://arxiv.org/abs/2410.16897",
        "title": "Enhancing Generalization in Convolutional Neural Networks through Regularization with Edge and Line Features",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper proposes a novel regularization approach to bias Convolutional Neural Networks (CNNs) toward utilizing edge and line features in their hidden layers. Rather than learning arbitrary kernels, we constrain the convolution layers to edge and line detection kernels. This intentional bias regularizes the models, improving generalization performance, especially on small datasets. As a result, test accuracies improve by margins of 5-11 percentage points across four challenging fine-grained classification datasets with limited training data and an identical number of trainable parameters. Instead of traditional convolutional layers, we use Pre-defined Filter Modules, which convolve input data using a fixed set of 3x3 pre-defined edge and line filters. A subsequent ReLU erases information that did not trigger any positive response. Next, a 1x1 convolutional layer generates linear combinations. Notably, the pre-defined filters are a fixed component of the architecture, remaining unchanged during the training phase. Our findings reveal that the number of dimensions spanned by the set of pre-defined filters has a low impact on recognition performance. However, the size of the set of filters matters, with nine or more filters providing optimal results.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16908",
        "abstract url": "https://arxiv.org/abs/2410.16908",
        "title": "Mitigating Vanishing Activations in Deep CapsNets Using Channel Pruning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Capsule Networks outperform Convolutional Neural Networks in learning the part-whole relationships with viewpoint invariance, and the credit goes to their multidimensional capsules. It was assumed that increasing the number of capsule layers in the capsule networks would enhance the model performance. However, recent studies found that Capsule Networks lack scalability due to vanishing activations in the capsules of deeper layers. This paper thoroughly investigates the vanishing activation problem in deep Capsule Networks. To analyze this issue and understand how increasing capsule dimensions can facilitate deeper networks, various Capsule Network models are constructed and evaluated with different numbers of capsules, capsule dimensions, and intermediate layers for this paper. Unlike traditional model pruning, which reduces the number of model parameters and expedites model training, this study uses pruning to mitigate the vanishing activations in the deeper capsule layers. In addition, the backbone network and capsule layers are pruned with different pruning ratios to reduce the number of inactive capsules and achieve better model accuracy than the unpruned models.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16930",
        "abstract url": "https://arxiv.org/abs/2410.16930",
        "title": "Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Math reasoning is a highly active area of Large Language Model (LLM) research because it is a hallmark of artificial intelligence. However, few works have explored how math reasoning is encoded within LLM parameters and if it is a skill that can be isolated within a model. Doing so could allow targeted intervention to improve math performance without altering non-math behavior and foster understanding of how models encode math reasoning. We introduce Math Neurosurgery (MathNeuro), a method for isolating math-specific parameters in LLMs using only forward passes. MathNeuro builds on existing work by using weights and activations to calculate parameter importance, but isolates math-specific parameters by removing those important for general language tasks. Pruning parameters MathNeuro identifies deletes a LLM's math reasoning ability without destroying its general language ability. Scaling these parameters by a small constant improves a pretrained or instruction-tuned LLM's performance by 4-17% on GSM8K while leaving non-math behavior unaltered. MathNeuro is also data efficient: most of its effectiveness holds when identifying math-specific parameters using a single sample. MathNeuro highlights the potential for future work to intervene on math-specific parameters.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "21 pages, 29 figures"
    },
    {
        "paper id": "2410.16958",
        "abstract url": "https://arxiv.org/abs/2410.16958",
        "title": "Leaky ReLUs That Differ in Forward and Backward Pass Facilitate Activation Maximization in Deep Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Activation maximization (AM) strives to generate optimal input stimuli, revealing features that trigger high responses in trained deep neural networks. AM is an important method of explainable AI. We demonstrate that AM fails to produce optimal input stimuli for simple functions containing ReLUs or Leaky ReLUs, casting doubt on the practical usefulness of AM and the visual interpretation of the generated images. This paper proposes a solution based on using Leaky ReLUs with a high negative slope in the backward pass while keeping the original, usually zero, slope in the forward pass. The approach significantly increases the maxima found by AM. The resulting ProxyGrad algorithm implements a novel optimization technique for neural networks that employs a secondary network as a proxy for gradient computation. This proxy network is designed to have a simpler loss landscape with fewer local maxima than the original network. Our chosen proxy network is an identical copy of the original network, including its weights, with distinct negative slopes in the Leaky ReLUs. Moreover, we show that ProxyGrad can be used to train the weights of Convolutional Neural Networks for classification such that, on some of the tested benchmarks, they outperform traditional networks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16972",
        "abstract url": "https://arxiv.org/abs/2410.16972",
        "title": "Sample-efficient Bayesian Optimisation Using Known Invariances",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Bayesian optimisation (BO) is a powerful framework for global optimisation of costly functions, using predictions from Gaussian process models (GPs). In this work, we apply BO to functions that exhibit invariance to a known group of transformations. We show that vanilla and constrained BO algorithms are inefficient when optimising such invariant objectives, and provide a method for incorporating group invariances into the kernel of the GP to produce invariance-aware algorithms that achieve significant improvements in sample efficiency. We derive a bound on the maximum information gain of these invariant kernels, and provide novel upper and lower bounds on the number of observations required for invariance-aware BO algorithms to achieve $\u03b5$-optimality. We demonstrate our method's improved performance on a range of synthetic invariant and quasi-invariant functions. We also apply our method in the case where only some of the invariance is incorporated into the kernel, and find that these kernels achieve similar gains in sample efficiency at significantly reduced computational cost. Finally, we use invariant BO to design a current drive system for a nuclear fusion reactor, finding a high-performance solution where non-invariant methods failed.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted as a poster at NeurIPS 2024"
    },
    {
        "paper id": "2410.16977",
        "abstract url": "https://arxiv.org/abs/2410.16977",
        "title": "IPL: Leveraging Multimodal Large Language Models for Intelligent Product Listing",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Unlike professional Business-to-Consumer (B2C) e-commerce platforms (e.g., Amazon), Consumer-to-Consumer (C2C) platforms (e.g., Facebook marketplace) are mainly targeting individual sellers who usually lack sufficient experience in e-commerce. Individual sellers often struggle to compose proper descriptions for selling products. With the recent advancement of Multimodal Large Language Models (MLLMs), we attempt to integrate such state-of-the-art generative AI technologies into the product listing process. To this end, we develop IPL, an Intelligent Product Listing tool tailored to generate descriptions using various product attributes such as category, brand, color, condition, etc. IPL enables users to compose product descriptions by merely uploading photos of the selling product. More importantly, it can imitate the content style of our C2C platform Xianyu. This is achieved by employing domain-specific instruction tuning on MLLMs and adopting the multi-modal Retrieval-Augmented Generation (RAG) process. A comprehensive empirical evaluation demonstrates that the underlying model of IPL significantly outperforms the base model in domain-specific tasks while producing less hallucination. IPL has been successfully deployed in our production system, where 72% of users have their published product listings based on the generated content, and those product listings are shown to have a quality score 5.6% higher than those without AI assistance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16999",
        "abstract url": "https://arxiv.org/abs/2410.16999",
        "title": "AGSENet: A Robust Road Ponding Detection Method for Proactive Traffic Safety",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Road ponding, a prevalent traffic hazard, poses a serious threat to road safety by causing vehicles to lose control and leading to accidents ranging from minor fender benders to severe collisions. Existing technologies struggle to accurately identify road ponding due to complex road textures and variable ponding coloration influenced by reflection characteristics. To address this challenge, we propose a novel approach called Self-Attention-based Global Saliency-Enhanced Network (AGSENet) for proactive road ponding detection and traffic safety improvement. AGSENet incorporates saliency detection techniques through the Channel Saliency Information Focus (CSIF) and Spatial Saliency Information Enhancement (SSIE) modules. The CSIF module, integrated into the encoder, employs self-attention to highlight similar features by fusing spatial and channel information. The SSIE module, embedded in the decoder, refines edge features and reduces noise by leveraging correlations across different feature levels. To ensure accurate and reliable evaluation, we corrected significant mislabeling and missing annotations in the Puddle-1000 dataset. Additionally, we constructed the Foggy-Puddle and Night-Puddle datasets for road ponding detection in low-light and foggy conditions, respectively. Experimental results demonstrate that AGSENet outperforms existing methods, achieving IoU improvements of 2.03\\%, 0.62\\%, and 1.06\\% on the Puddle-1000, Foggy-Puddle, and Night-Puddle datasets, respectively, setting a new state-of-the-art in this field. Finally, we verified the algorithm's reliability on edge computing devices. This work provides a valuable reference for proactive warning research in road traffic safety.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "21 pages, 15 figures"
    },
    {
        "paper id": "2410.17018",
        "abstract url": "https://arxiv.org/abs/2410.17018",
        "title": "Exploring Forgetting in Large Language Model Pre-Training",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Catastrophic forgetting remains a formidable obstacle to building an omniscient model in large language models (LLMs). Despite the pioneering research on task-level forgetting in LLM fine-tuning, there is scant focus on forgetting during pre-training. We systematically explored the existence and measurement of forgetting in pre-training, questioning traditional metrics such as perplexity (PPL) and introducing new metrics to better detect entity memory retention. Based on our revised assessment of forgetting metrics, we explored low-cost, straightforward methods to mitigate forgetting during the pre-training phase. Further, we carefully analyzed the learning curves, offering insights into the dynamics of forgetting. Extensive evaluations and analyses on forgetting of pre-training could facilitate future research on LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17021",
        "abstract url": "https://arxiv.org/abs/2410.17021",
        "title": "SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop Question Answering Based on Finite State Machine",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models with chain-of-thought prompting, such as OpenAI-o1, have shown impressive capabilities in natural language inference tasks. However, Multi-hop Question Answering (MHQA) remains challenging for many existing models due to issues like hallucination, error propagation, and limited context length. To address these challenges and enhance LLMs' performance on MHQA, we propose the Self-Guiding prompting Finite State Machine (SG-FSM), designed to strengthen multi-hop reasoning abilities. Unlike traditional chain-of-thought methods, SG-FSM tackles MHQA by iteratively breaking down complex questions into sub-questions, correcting itself to improve accuracy. It processes one sub-question at a time, dynamically deciding the next step based on the current context and results, functioning much like an automaton. Experiments across various benchmarks demonstrate the effectiveness of our approach, outperforming strong baselines on challenging datasets such as Musique. SG-FSM reduces hallucination, enabling recovery of the correct final answer despite intermediate errors. It also improves adherence to specified output formats, simplifying evaluation significantly.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17028",
        "abstract url": "https://arxiv.org/abs/2410.17028",
        "title": "Can a Machine Distinguish High and Low Amount of Social Creak in Speech?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Objectives: ncreased prevalence of social creak particularly among female speakers has been reported in several studies. The study of social creak has been previously conducted by combining perceptual evaluation of speech with conventional acoustical parameters such as the harmonic-to-noise ratio and cepstral peak prominence. In the current study, machine learning (ML) was used to automatically distinguish speech of low amount of social creak from speech of high amount of social creak. Methods: The amount of creak in continuous speech samples produced in Finnish by 90 female speakers was first perceptually assessed by two voice specialists. Based on their assessments, the speech samples were divided into two categories (low $vs$. high amount of creak). Using the speech signals and their creak labels, seven different ML models were trained. Three spectral representations were used as feature for each model. Results: The results show that the best performance (accuracy of 71.1\\%) was obtained by the following two systems: an Adaboost classifier using the mel-spectrogram feature and a decision tree classifier using the mel-frequency cepstral coefficient feature. Conclusions: The study of social creak is becoming increasingly popular in sociolinguistic and vocological research. The conventional human perceptual assessment of the amount of creak is laborious and therefore ML technology could be used to assist researchers studying social creak. The classification systems reported in this study could be considered as baselines in future ML-based studies on social creak.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "Accepted in Journal of Voice"
    },
    {
        "paper id": "2410.17033",
        "abstract url": "https://arxiv.org/abs/2410.17033",
        "title": "Prototype and Instance Contrastive Learning for Unsupervised Domain Adaptation in Speaker Verification",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speaker verification system trained on one domain usually suffers performance degradation when applied to another domain. To address this challenge, researchers commonly use feature distribution matching-based methods in unsupervised domain adaptation scenarios where some unlabeled target domain data is available. However, these methods often have limited performance improvement and lack generalization in various mismatch situations. In this paper, we propose Prototype and Instance Contrastive Learning (PICL), a novel method for unsupervised domain adaptation in speaker verification through dual-level contrastive learning. For prototype contrastive learning, we generate pseudo labels via clustering to create dynamically updated prototype representations, aligning instances with their corresponding class or cluster prototypes. For instance contrastive learning, we minimize the distance between different views or augmentations of the same instance, ensuring robust and invariant representations resilient to variations like noise. This dual-level approach provides both high-level and low-level supervision, leading to improved generalization and robustness of the speaker verification model. Unlike previous studies that only evaluated mismatches in one situation, we have conducted relevant explorations on various datasets and achieved state-of-the-art performance currently, which also proves the generalization of our method.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": "Accepted to ISCSLP 2024"
    },
    {
        "paper id": "2410.17066",
        "abstract url": "https://arxiv.org/abs/2410.17066",
        "title": "Neuronal Competition Groups with Supervised STDP for Spike-Based Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Spike Timing-Dependent Plasticity (STDP) is a promising substitute to backpropagation for local training of Spiking Neural Networks (SNNs) on neuromorphic hardware. STDP allows SNNs to address classification tasks by combining unsupervised STDP for feature extraction and supervised STDP for classification. Unsupervised STDP is usually employed with Winner-Takes-All (WTA) competition to learn distinct patterns. However, WTA for supervised STDP classification faces unbalanced competition challenges. In this paper, we propose a method to effectively implement WTA competition in a spiking classification layer employing first-spike coding and supervised STDP training. We introduce the Neuronal Competition Group (NCG), an architecture that improves classification capabilities by promoting the learning of various patterns per class. An NCG is a group of neurons mapped to a specific class, implementing intra-class WTA and a novel competition regulation mechanism based on two-compartment thresholds. We incorporate our proposed architecture into spiking classification layers trained with state-of-the-art supervised STDP rules. On top of two different unsupervised feature extractors, we obtain significant accuracy improvements on image recognition datasets such as CIFAR-10 and CIFAR-100. We show that our competition regulation mechanism is crucial for ensuring balanced competition and improved class separation.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17082",
        "abstract url": "https://arxiv.org/abs/2410.17082",
        "title": "A Survey on Deep Learning-based Gaze Direction Regression: Searching for the State-of-the-art",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we present a survey of deep learning-based methods for the regression of gaze direction vector from head and eye images. We describe in detail numerous published methods with a focus on the input data, architecture of the model, and loss function used to supervise the model. Additionally, we present a list of datasets that can be used to train and evaluate gaze direction regression methods. Furthermore, we noticed that the results reported in the literature are often not comparable one to another due to differences in the validation or even test subsets used. To address this problem, we re-evaluated several methods on the commonly used in-the-wild Gaze360 dataset using the same validation setup. The experimental results show that the latest methods, although claiming state-of-the-art results, significantly underperform compared with some older methods. Finally, we show that the temporal models outperform the static models under static test conditions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted on SPRA 2024 (Istanbul, Turkey)"
    },
    {
        "paper id": "2410.17088",
        "abstract url": "https://arxiv.org/abs/2410.17088",
        "title": "Science Out of Its Ivory Tower: Improving Accessibility with Reinforcement Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "A vast amount of scholarly work is published daily, yet much of it remains inaccessible to the general public due to dense jargon and complex language. To address this challenge in science communication, we introduce a reinforcement learning framework that fine-tunes a language model to rewrite scholarly abstracts into more comprehensible versions. Guided by a carefully balanced combination of word- and sentence-level accessibility rewards, our language model effectively substitutes technical terms with more accessible alternatives, a task which models supervised fine-tuned or guided by conventional readability measures struggle to accomplish. Our best model adjusts the readability level of scholarly abstracts by approximately six U.S. grade levels -- in other words, from a postgraduate to a high school level. This translates to roughly a 90% relative boost over the supervised fine-tuning baseline, all while maintaining factual accuracy and high-quality language. An in-depth analysis of our approach shows that balanced rewards lead to systematic modifications in the base model, likely contributing to smoother optimization and superior performance. We envision this work as a step toward bridging the gap between scholarly research and the general public, particularly younger readers and those without a college degree.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17098",
        "abstract url": "https://arxiv.org/abs/2410.17098",
        "title": "Masked Differential Privacy",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Privacy-preserving computer vision is an important emerging problem in machine learning and artificial intelligence. The prevalent methods tackling this problem use differential privacy or anonymization and obfuscation techniques to protect the privacy of individuals. In both cases, the utility of the trained model is sacrificed heavily in this process. In this work, we propose an effective approach called masked differential privacy (MaskDP), which allows for controlling sensitive regions where differential privacy is applied, in contrast to applying DP on the entire input. Our method operates selectively on the data and allows for defining non-sensitive spatio-temporal regions without DP application or combining differential privacy with other privacy techniques within data samples. Experiments on four challenging action recognition datasets demonstrate that our proposed techniques result in better utility-privacy trade-offs compared to standard differentially private training in the especially demanding $\u03b5<1$ regime.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17112",
        "abstract url": "https://arxiv.org/abs/2410.17112",
        "title": "Enhancing Answer Attribution for Faithful Text Generation with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The increasing popularity of Large Language Models (LLMs) in recent years has changed the way users interact with and pose questions to AI-based conversational systems. An essential aspect for increasing the trustworthiness of generated LLM answers is the ability to trace the individual claims from responses back to relevant sources that support them, the process known as answer attribution. While recent work has started exploring the task of answer attribution in LLMs, some challenges still remain. In this work, we first perform a case study analyzing the effectiveness of existing answer attribution methods, with a focus on subtasks of answer segmentation and evidence retrieval. Based on the observed shortcomings, we propose new methods for producing more independent and contextualized claims for better retrieval and attribution. The new methods are evaluated and shown to improve the performance of answer attribution components. We end with a discussion and outline of future directions for the task.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "comment": "Accepted to KDIR 2024 (part of IC3K 2024)"
    },
    {
        "paper id": "2410.17126",
        "abstract url": "https://arxiv.org/abs/2410.17126",
        "title": "Exploring RL-based LLM Training for Formal Language Tasks with Programmed Rewards",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning from Human Feedback to align large language models (LLMs) with downstream tasks. This paper investigates the feasibility of using PPO for direct reinforcement learning (RL) from explicitly programmed reward signals, as opposed to indirect learning from human feedback via an intermediary reward model. We focus on tasks expressed through formal languages, such as mathematics and programming, where explicit reward functions can be programmed to automatically assess the quality of generated outputs. We apply this approach to a sentiment alignment task, a simple arithmetic task, and a more complex game synthesis task. The sentiment alignment task replicates prior research and serves to validate our experimental setup. Our results show that pure RL-based training for the two formal language tasks is challenging, with success being limited even for the simple arithmetic task. We propose a novel batch-entropy regularization term to aid exploration, although training is not yet entirely stable. Our findings suggest that direct RL training of LLMs may be more suitable for relatively minor changes, such as alignment, than for learning new tasks altogether, even if an informative reward signal can be expressed programmatically.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at BNAIC 2024"
    },
    {
        "paper id": "2410.17127",
        "abstract url": "https://arxiv.org/abs/2410.17127",
        "title": "PAPILLON: PrivAcy Preservation from Internet-based and Local Language MOdel ENsembles",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Users can divulge sensitive information to proprietary LLM providers, raising significant privacy concerns. While open-source models, hosted locally on the user's machine, alleviate some concerns, models that users can host locally are often less capable than proprietary frontier models. Toward preserving user privacy while retaining the best quality, we propose Privacy-Conscious Delegation, a novel task for chaining API-based and local models. We utilize recent public collections of user-LLM interactions to construct a natural benchmark called PUPA, which contains personally identifiable information (PII). To study potential approaches, we devise PAPILLON, a multi-stage LLM pipeline that uses prompt optimization to address a simpler version of our task. Our best pipeline maintains high response quality for 85.5% of user queries while restricting privacy leakage to only 7.5%. We still leave a large margin to the generation quality of proprietary LLMs for future work. Our data and code will be available at https://github.com/siyan-sylvia-li/PAPILLON.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17131",
        "abstract url": "https://arxiv.org/abs/2410.17131",
        "title": "Aligning Large Language Models via Self-Steering Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Automated alignment develops alignment systems with minimal human intervention. The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation. In this paper, we introduce Self-Steering Optimization ($SSO$), an algorithm that autonomously generates high-quality preference signals based on predefined principles during iterative training, eliminating the need for manual annotation. $SSO$ maintains the accuracy of signals by ensuring a consistent gap between chosen and rejected responses while keeping them both on-policy to suit the current policy model's learning capacity. $SSO$ can benefit the online and offline training of the policy model, as well as enhance the training of reward models. We validate the effectiveness of $SSO$ with two foundation models, Qwen2 and Llama3.1, indicating that it provides accurate, on-policy preference signals throughout iterative training. Without any manual annotation or external models, $SSO$ leads to significant performance improvements across six subjective or objective benchmarks. Besides, the preference data generated by $SSO$ significantly enhanced the performance of the reward model on Rewardbench. Our work presents a scalable approach to preference optimization, paving the way for more efficient and effective automated alignment.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17136",
        "abstract url": "https://arxiv.org/abs/2410.17136",
        "title": "AlphaChimp: Tracking and Behavior Recognition of Chimpanzees",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding non-human primate behavior is crucial for improving animal welfare, modeling social behavior, and gaining insights into both distinctly human and shared behaviors. Despite recent advances in computer vision, automated analysis of primate behavior remains challenging due to the complexity of their social interactions and the lack of specialized algorithms. Existing methods often struggle with the nuanced behaviors and frequent occlusions characteristic of primate social dynamics. This study aims to develop an effective method for automated detection, tracking, and recognition of chimpanzee behaviors in video footage. Here we show that our proposed method, AlphaChimp, an end-to-end approach that simultaneously detects chimpanzee positions and estimates behavior categories from videos, significantly outperforms existing methods in behavior recognition. AlphaChimp achieves approximately 10% higher tracking accuracy and a 20% improvement in behavior recognition compared to state-of-the-art methods, particularly excelling in the recognition of social behaviors. This superior performance stems from AlphaChimp's innovative architecture, which integrates temporal feature fusion with a Transformer-based self-attention mechanism, enabling more effective capture and interpretation of complex social interactions among chimpanzees. Our approach bridges the gap between computer vision and primatology, enhancing technical capabilities and deepening our understanding of primate communication and sociality. We release our code and models and hope this will facilitate future research in animal social dynamics. This work contributes to ethology, cognitive science, and artificial intelligence, offering new perspectives on social intelligence.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "An eXpressive extension of ChimpACT [arXiv:2310.16447], proposes AlphaChimp for tracking and behavior recognition of chimpanzees. arXiv admin note: substantial text overlap with arXiv:2310.16447"
    },
    {
        "paper id": "2410.17161",
        "abstract url": "https://arxiv.org/abs/2410.17161",
        "title": "Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We propose a novel approach for learning interchangeable tokens in language models to obtain an extendable vocabulary that can generalize to new tokens. Our method is designed to address alpha-equivalence, the principle that renaming bound variables in a syntactic expression preserves semantics. This property arises in many formal languages such as temporal logics, in which all proposition symbols represent the same concept but are distinguishable from each other. To handle such tokens, we develop a dual-part embedding approach. The first part is shared across all interchangeable tokens, thereby enforcing that they represent the same core concept. The second part is randomly generated for each token, which enables distinguishability. We evaluate our method in a Transformer encoder-decoder model on two tasks: solving linear temporal logic formulae and copying with extendable vocabulary. Our method demonstrates promising generalization capabilities in addition to introducing a favorable inductive bias for alpha-equivalence.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "cs.LO"
        ],
        "comment": "14 pages, 5 figures"
    },
    {
        "paper id": "2410.17170",
        "abstract url": "https://arxiv.org/abs/2410.17170",
        "title": "Self-calibration for Language Model Quantization and Pruning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Quantization and pruning are fundamental approaches for model compression, enabling efficient inference for language models. In a post-training setting, state-of-the-art quantization and pruning methods require calibration data, a small set of unlabeled examples. Conventionally, randomly sampled web text is used, aiming to reflect the model training data. However, this poses two key problems: (1) unrepresentative calibration examples can harm model performance, and (2) organizations increasingly avoid releasing model training data. In this paper, we propose self-calibration as a solution. Our approach requires no external data, instead leveraging the model itself to generate synthetic calibration data as a better approximation of the pre-training data distribution. We extensively compare the performance of self-calibration with several baselines, across a variety of models, compression methods, and tasks. Our approach proves consistently competitive in maximizing downstream task performance, frequently outperforming even using real data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2410.17172",
        "abstract url": "https://arxiv.org/abs/2410.17172",
        "title": "KANICE: Kolmogorov-Arnold Networks with Interactive Convolutional Elements",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We introduce KANICE (Kolmogorov-Arnold Networks with Interactive Convolutional Elements), a novel neural architecture that combines Convolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN) principles. KANICE integrates Interactive Convolutional Blocks (ICBs) and KAN linear layers into a CNN framework. This leverages KANs' universal approximation capabilities and ICBs' adaptive feature learning. KANICE captures complex, non-linear data relationships while enabling dynamic, context-dependent feature extraction based on the Kolmogorov-Arnold representation theorem. We evaluated KANICE on four datasets: MNIST, Fashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KAN hybrids, and ICB variants. KANICE consistently outperformed baseline models, achieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset. Furthermore, we introduce KANICE-mini, a compact variant designed for efficiency. A comprehensive ablation study demonstrates that KANICE-mini achieves comparable performance to KANICE with significantly fewer parameters. KANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, compared to KANICE's 25,432,000. This study highlights the potential of KAN-based architectures in balancing performance and computational efficiency in image classification tasks. Our work contributes to research in adaptive neural networks, integrates mathematical theorems into deep learning architectures, and explores the trade-offs between model complexity and performance, advancing computer vision and pattern recognition. The source code for this paper is publicly accessible through our GitHub repository (https://github.com/m-ferdaus/kanice).",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17174",
        "abstract url": "https://arxiv.org/abs/2410.17174",
        "title": "From Attention to Activation: Unravelling the Enigmas of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We study two strange phenomena in auto-regressive Transformers: (1) the dominance of the first token in attention heads; (2) the occurrence of large outlier activations in the hidden states. We find that popular large language models, such as Llama attend maximally to the first token in 98% of attention heads, a behaviour we attribute to the softmax function. To mitigate this issue, we propose a reformulation of softmax to softmax-1. Furthermore, we identify adaptive optimisers, e.g. Adam, as the primary contributor to the large outlier activations and introduce OrthoAdam, a novel optimiser that utilises orthogonal matrices to transform gradients, to address this issue. Finally, not only do our methods prevent these phenomena from occurring, but additionally, they enable Transformers to sustain their performance when quantised using basic algorithms, something that standard methods are unable to do. In summary, our methods reduce the attention proportion on the first token from 65% to 3.3%, the activation kurtosis in the hidden states from 1657 to 3.1, and perplexity penalty under 4-bit weight quantisation from 3565 to 0.3.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2410.17193",
        "abstract url": "https://arxiv.org/abs/2410.17193",
        "title": "Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Dataset distillation has demonstrated strong performance on simple datasets like CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in more complex scenarios. In this paper, we propose EDF (emphasizes the discriminative features), a dataset distillation method that enhances key discriminative regions in synthetic images using Grad-CAM activation maps. Our approach is inspired by a key observation: in simple datasets, high-activation areas typically occupy most of the image, whereas in complex scenarios, the size of these areas is much smaller. Unlike previous methods that treat all pixels equally when synthesizing images, EDF uses Grad-CAM activation maps to enhance high-activation areas. From a supervision perspective, we downplay supervision signals that have lower losses, as they contain common patterns. Additionally, to help the DD community better explore complex scenarios, we build the Complex Dataset Distillation (Comp-DD) benchmark by meticulously selecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In particular, EDF consistently outperforms SOTA results in complex scenarios, such as ImageNet-1K subsets. Hopefully, more researchers will be inspired and encouraged to improve the practicality and efficacy of DD. Our code and benchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "24 pages, 13 figures"
    },
    {
        "paper id": "2410.17195",
        "abstract url": "https://arxiv.org/abs/2410.17195",
        "title": "Non-myopic Generation of Language Models for Reasoning and Planning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models have demonstrated remarkable abilities in reasoning and planning by breaking down complex problems into sequential steps. Despite their success in various domains like mathematical problem-solving and coding, LLMs face challenges in ensuring reliable and optimal planning due to their inherent myopic nature of autoregressive decoding. This paper revisits LLM reasoning from an optimal-control perspective, proposing a novel method, Predictive-Decoding, that leverages Model Predictive Control to enhance planning accuracy. By re-weighting LLM distributions based on foresight trajectories, Predictive-Decoding aims to mitigate early errors and promote non-myopic planning. Our experiments show significant improvements in a wide range of tasks for math, coding, and agents. Furthermore, Predictive-Decoding demonstrates computational efficiency, outperforming search baselines with reduced computational resources. This study provides insights into optimizing LLM planning capabilities.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17196",
        "abstract url": "https://arxiv.org/abs/2410.17196",
        "title": "VoiceBench: Benchmarking LLM-Based Voice Assistants",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Building on the success of large language models (LLMs), recent advancements such as GPT-4o have enabled real-time speech interactions through LLM-based voice assistants, offering a significantly improved user experience compared to traditional text-based interactions. However, the absence of benchmarks designed to evaluate these speech interaction capabilities has hindered progress of LLM-based voice assistants development. Current evaluations focus primarily on automatic speech recognition (ASR) or general knowledge evaluation with clean speeches, neglecting the more intricate, real-world scenarios that involve diverse speaker characteristics, environmental and content factors. To address this, we introduce VoiceBench, the first benchmark designed to provide a multi-faceted evaluation of LLM-based voice assistants. VoiceBench also includes both real and synthetic spoken instructions that incorporate the above three key real-world variations. Extensive experiments reveal the limitations of current LLM-based voice assistant models and offer valuable insights for future research and development in this field.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Work in progress. Data is available at https://github.com/MatthewCYM/VoiceBench"
    },
    {
        "paper id": "2410.17210",
        "abstract url": "https://arxiv.org/abs/2410.17210",
        "title": "Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh through Large Language Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Purpose: Bangladesh's legal system struggles with major challenges like delays, complexity, high costs, and millions of unresolved cases, which deter many from pursuing legal action due to lack of knowledge or financial constraints. This research seeks to develop a specialized Large Language Model (LLM) to assist in the Bangladeshi legal system. Methods: We created UKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting and scraping data on various legal acts. We fine-tuned the GPT-2 model on this dataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistance in English. Results: The model was rigorously evaluated using semantic assessments, including case studies supported by expert opinions. The evaluation provided promising results, demonstrating the potential for the model to assist in legal matters within Bangladesh. Conclusion: Our work represents the first structured effort toward building an AI-based legal assistant for Bangladesh. While the results are encouraging, further refinements are necessary to improve the model's accuracy, credibility, and safety. This is a significant step toward creating a legal AI capable of serving the needs of a population of 180 million.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "In Review"
    },
    {
        "paper id": "2410.17215",
        "abstract url": "https://arxiv.org/abs/2410.17215",
        "title": "MiniPLM: Knowledge Distillation for Pre-Training Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness. Existing methods either incur high computational costs due to online teacher inference, require tokenization matching between teacher and student LMs, or risk losing the difficulty and diversity of the teacher-generated training data. To address these issues, we propose MiniPLM, a KD framework for pre-training LMs by refining the training data distribution with the teacher's knowledge. For efficiency, MiniPLM performs offline teacher LM inference, allowing KD for multiple student LMs without adding training-time costs. For flexibility, MiniPLM operates solely on the training corpus, enabling KD across model families. For effectiveness, MiniPLM leverages the differences between large and small LMs to enhance the difficulty and diversity of the training data, helping student LMs acquire versatile and sophisticated knowledge. Extensive experiments demonstrate that MiniPLM boosts the student LMs' performance on 9 widely used downstream tasks, improves the language modeling capabilities, and reduces pre-training computation. The benefit of MiniPLM extends to large pre-training scales, evidenced by the extrapolation of the scaling curves. Further analysis reveals that MiniPLM supports KD across model families and enhances the utilization of pre-training data. Our model, code, and data are available at https://github.com/thu-coai/MiniPLM.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17218",
        "abstract url": "https://arxiv.org/abs/2410.17218",
        "title": "Creativity in AI: Progresses and Challenges",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Creativity is the ability to produce novel, useful, and surprising ideas, and has been widely studied as a crucial aspect of human cognition. Machine creativity on the other hand has been a long-standing challenge. With the rise of advanced generative AI, there has been renewed interest and debate regarding AI's creative capabilities. Therefore, it is imperative to revisit the state of creativity in AI and identify key progresses and remaining challenges. In this work, we survey leading works studying the creative capabilities of AI systems, focusing on creative problem-solving, linguistic, artistic, and scientific creativity. Our review suggests that while the latest AI models are largely capable of producing linguistically and artistically creative outputs such as poems, images, and musical pieces, they struggle with tasks that require creative problem-solving, abstract thinking and compositionality and their generations suffer from a lack of diversity, originality, long-range incoherence and hallucinations. We also discuss key questions concerning copyright and authorship issues with generative models. Furthermore, we highlight the need for a comprehensive evaluation of creativity that is process-driven and considers several dimensions of creativity. Finally, we propose future research directions to improve the creativity of AI outputs, drawing inspiration from cognitive science and psychology.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "44 pages"
    },
    {
        "paper id": "2410.17222",
        "abstract url": "https://arxiv.org/abs/2410.17222",
        "title": "Context-aware Prompt Tuning: Advancing In-Context Learning with Adversarial Methods",
        "rating": "1",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Fine-tuning Large Language Models (LLMs) typically involves updating at least a few billions of parameters. A more parameter-efficient approach is Prompt Tuning (PT), which updates only a few learnable tokens, and differently, In-Context Learning (ICL) adapts the model to a new task by simply including examples in the input without any training. When applying optimization-based methods, such as fine-tuning and PT for few-shot learning, the model is specifically adapted to the small set of training examples, whereas ICL leaves the model unchanged. This distinction makes traditional learning methods more prone to overfitting; in contrast, ICL is less sensitive to the few-shot scenario. While ICL is not prone to overfitting, it does not fully extract the information that exists in the training examples. This work introduces Context-aware Prompt Tuning (CPT), a method inspired by ICL, PT, and adversarial attacks. We build on the ICL strategy of concatenating examples before the input, but we extend this by PT-like learning, refining the context embedding through iterative optimization to extract deeper insights from the training examples. We carefully modify specific context tokens, considering the unique structure of input and output formats. Inspired by adversarial attacks, we adjust the input based on the labels present in the context, focusing on minimizing, rather than maximizing, the loss. Moreover, we apply a projected gradient descent algorithm to keep token embeddings close to their original values, under the assumption that the user-provided data is inherently valuable. Our method has been shown to achieve superior accuracy across multiple classification tasks using various LLM models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17225",
        "abstract url": "https://arxiv.org/abs/2410.17225",
        "title": "Dhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Climate change poses critical challenges globally, disproportionately affecting low-income countries that often lack resources and linguistic representation on the international stage. Despite Bangladesh's status as one of the most vulnerable nations to climate impacts, research gaps persist in Bengali-language studies related to climate change and NLP. To address this disparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and environmental news dataset, comprising a 2300 annotated Bangla news articles, offering multiple perspectives such as political influence, scientific/statistical data, authenticity, stance detection, and stakeholder involvement. Furthermore, we present an in-depth exploratory analysis of Dhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family for climate and environmental opinion detection in Bangla, fine-tuned on our dataset. This research contributes significantly to enhancing accessibility and analysis of climate discourse in Bengali (Bangla), addressing crucial communication and research gaps in climate-impacted regions like Bangladesh with 180 million people.",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "cs.LG",
            "stat.AP"
        ],
        "comment": "In Review"
    },
    {
        "paper id": "2410.17236",
        "abstract url": "https://arxiv.org/abs/2410.17236",
        "title": "Large Language Models Empowered Personalized Web Agents",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Web agents have emerged as a promising direction to automate Web task completion based on user instructions, significantly enhancing user experience. Recently, Web agents have evolved from traditional agents to Large Language Models (LLMs)-based Web agents. Despite their success, existing LLM-based Web agents overlook the importance of personalized data (e.g., user profiles and historical Web behaviors) in assisting the understanding of users' personalized instructions and executing customized actions. To overcome the limitation, we first formulate the task of LLM-empowered personalized Web agents, which integrate personalized data and user instructions to personalize instruction comprehension and action execution. To address the absence of a comprehensive evaluation benchmark, we construct a Personalized Web Agent Benchmark (PersonalWAB), featuring user instructions, personalized user data, Web functions, and two evaluation paradigms across three personalized Web tasks. Moreover, we propose a Personalized User Memory-enhanced Alignment (PUMA) framework to adapt LLMs to the personalized Web agent task. PUMA utilizes a memory bank with a task-specific retrieval strategy to filter relevant historical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for personalized action execution through fine-tuning and direct preference optimization. Extensive experiments validate the superiority of PUMA over existing Web agents on PersonalWAB.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "The code and data are available on the project website https://hongrucai.github.io/PersonalWAB/"
    },
    {
        "paper id": "2410.17238",
        "abstract url": "https://arxiv.org/abs/2410.17238",
        "title": "SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Automated Machine Learning (AutoML) approaches encompass traditional methods that optimize fixed pipelines for model selection and ensembling, as well as newer LLM-based frameworks that autonomously build pipelines. While LLM-based agents have shown promise in automating machine learning tasks, they often generate low-diversity and suboptimal code, even after multiple iterations. To overcome these limitations, we introduce Tree-Search Enhanced LLM Agents (SELA), an innovative agent-based system that leverages Monte Carlo Tree Search (MCTS) to optimize the AutoML process. By representing pipeline configurations as trees, our framework enables agents to conduct experiments intelligently and iteratively refine their strategies, facilitating a more effective exploration of the machine learning solution space. This novel approach allows SELA to discover optimal pathways based on experimental feedback, improving the overall quality of the solutions. In an extensive evaluation across 20 machine learning datasets, we compare the performance of traditional and agent-based AutoML methods, demonstrating that SELA achieves a win rate of 65% to 80% against each baseline across all datasets. These results underscore the significant potential of agent-based strategies in AutoML, offering a fresh perspective on tackling complex machine learning challenges.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SE"
        ],
        "comment": "The code is available at https://github.com/geekan/MetaGPT"
    },
    {
        "paper id": "2410.17309",
        "abstract url": "https://arxiv.org/abs/2410.17309",
        "title": "Literature Meets Data: A Synergistic Approach to Hypothesis Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "AI holds promise for transforming scientific processes, including hypothesis generation. Prior work on hypothesis generation can be broadly categorized into theory-driven and data-driven approaches. While both have proven effective in generating novel and plausible hypotheses, it remains an open question whether they can complement each other. To address this, we develop the first method that combines literature-based insights with data to perform LLM-powered hypothesis generation. We apply our method on five different datasets and demonstrate that integrating literature and data outperforms other baselines (8.97\\% over few-shot, 15.75\\% over literature-based alone, and 3.37\\% over data-driven alone). Additionally, we conduct the first human evaluation to assess the utility of LLM-generated hypotheses in assisting human decision-making on two challenging tasks: deception detection and AI generated content detection. Our results show that human accuracy improves significantly by 7.44\\% and 14.19\\% on these tasks, respectively. These findings suggest that integrating literature-based and data-driven approaches provides a comprehensive and nuanced framework for hypothesis generation and could open new avenues for scientific inquiry.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "30 pages, 7 figures, code link: https://github.com/ChicagoHAI/hypothesis-generation"
    },
    {
        "paper id": "2410.17333",
        "abstract url": "https://arxiv.org/abs/2410.17333",
        "title": "Are Large Language Models Ready for Travel Planning?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "While large language models (LLMs) show promise in hospitality and tourism, their ability to provide unbiased service across demographic groups remains unclear. This paper explores gender and ethnic biases when LLMs are utilized as travel planning assistants. To investigate this issue, we apply machine learning techniques to analyze travel suggestions generated from three open-source LLMs. Our findings reveal that the performance of race and gender classifiers substantially exceeds random chance, indicating differences in how LLMs engage with varied subgroups. Specifically, outputs align with cultural expectations tied to certain races and genders. To minimize the effect of these stereotypes, we used a stop-word classification strategy, which decreased identifiable differences, with no disrespectful terms found. However, hallucinations related to African American and gender minority groups were noted. In conclusion, while LLMs can generate travel plans seemingly free from bias, it remains essential to verify the accuracy and appropriateness of their recommendations.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17337",
        "abstract url": "https://arxiv.org/abs/2410.17337",
        "title": "Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Leveraging multimodal data to drive breakthroughs in e-commerce applications through Multimodal Foundation Models (MFMs) is gaining increasing attention from the research community. However, there are significant challenges that hinder the optimal use of multimodal e-commerce data by foundation models: (1) the scarcity of large-scale, high-quality multimodal benchmark datasets; and (2) the lack of effective multimodal information integration methods. To address these challenges, in this paper, we introduce MMECInstruct, the first-ever, large-scale, and high-quality multimodal instruction dataset for e-commerce. We also develop CASLIE, a simple, lightweight, yet effective framework for integrating multimodal information for e-commerce. Leveraging MMECInstruct, we fine-tune a series of e-commerce MFMs within CASLIE, denoted as CASLIE models. Our comprehensive evaluation demonstrates that CASLIE models substantially outperform 5 categories of advanced baseline models in the in-domain evaluation. Moreover, CASLIE models show strong generalizability to out-of-domain settings. MMECInstruct and CASLIE models are publicly accessible through https://ninglab.github.io/CASLIE/.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "Xinyi Ling and Bo Peng contributed equally to this paper"
    },
    {
        "paper id": "2410.17355",
        "abstract url": "https://arxiv.org/abs/2410.17355",
        "title": "All Entities are Not Created Equal: Examining the Long Tail for Fine-Grained Entity Typing",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Pre-trained language models (PLMs) are trained on large amounts of data, which helps capture world knowledge alongside linguistic competence. Due to this, they are extensively used for ultra-fine entity typing tasks, where they provide the entity knowledge held in its parameter space. Given that PLMs learn from co-occurrence patterns, they likely contain more knowledge or less knowledge about entities depending on their how frequent they are in the pre-training data. In this work, we probe PLMs to elicit encoded entity probabilities and demonstrate that they highly correlate with their frequency in large-scale internet data. Then, we demonstrate that entity-typing approaches that rely on PLMs struggle with entities at the long tail on the distribution. Our findings suggests that we need to go beyond PLMs to produce solutions that perform well for rare, new or infrequent entities.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17375",
        "abstract url": "https://arxiv.org/abs/2410.17375",
        "title": "AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM Acceleration",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models typically generate tokens autoregressively, using each token as input for the next. Recent work on Speculative Decoding has sought to accelerate this process by employing a smaller, faster draft model to more quickly generate candidate tokens. These candidates are then verified in parallel by the larger (original) verify model, resulting in overall speedup compared to using the larger model by itself in an autoregressive fashion. In this work, we introduce AMUSD (Asynchronous Multi-device Speculative Decoding), a system that further accelerates generation by decoupling the draft and verify phases into a continuous, asynchronous approach. Unlike conventional speculative decoding, where only one model (draft or verify) performs token generation at a time, AMUSD enables both models to perform predictions independently on separate devices (e.g., GPUs). We evaluate our approach over multiple datasets and show that AMUSD achieves an average 29% improvement over speculative decoding and up to 1.96$\\times$ speedup over conventional autoregressive decoding, while achieving identical output quality. Our system is open-source and available at https://github.com/BradMcDanel/AMUSD/.",
        "subjects": [
            "cs.CL",
            "cs.DC",
            "cs.LG"
        ],
        "comment": "4 pages, 5 figures, 1 table, 1 algorithm"
    },
    {
        "paper id": "2410.17377",
        "abstract url": "https://arxiv.org/abs/2410.17377",
        "title": "PtychoFormer: A Transformer-based Model for Ptychographic Phase Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Ptychography is a computational method of microscopy that recovers high-resolution transmission images of samples from a series of diffraction patterns. While conventional phase retrieval algorithms can iteratively recover the images, they require oversampled diffraction patterns, incur significant computational costs, and struggle to recover the absolute phase of the sample's transmission function. Deep learning algorithms for ptychography are a promising approach to resolving the limitations of iterative algorithms. We present PtychoFormer, a hierarchical transformer-based model for data-driven single-shot ptychographic phase retrieval. PtychoFormer processes subsets of diffraction patterns, generating local inferences that are seamlessly stitched together to produce a high-quality reconstruction. Our model exhibits tolerance to sparsely scanned diffraction patterns and achieves up to 3600 times faster imaging speed than the extended ptychographic iterative engine (ePIE). We also propose the extended-PtychoFormer (ePF), a hybrid approach that combines the benefits of PtychoFormer with the ePIE. ePF minimizes global phase shifts and significantly enhances reconstruction quality, achieving state-of-the-art phase retrieval in ptychography.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "20 pages, 12 figures"
    },
    {
        "paper id": "2410.17393",
        "abstract url": "https://arxiv.org/abs/2410.17393",
        "title": "Denoise-I2W: Mapping Images to Denoising Words for Accurate Zero-Shot Composed Image Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Zero-Shot Composed Image Retrieval (ZS-CIR) supports diverse tasks with a broad range of visual content manipulation intentions that can be related to domain, scene, object, and attribute. A key challenge for ZS-CIR is to accurately map image representation to a pseudo-word token that captures the manipulation intention relevant image information for generalized CIR. However, existing methods between the retrieval and pre-training stages lead to significant redundancy in the pseudo-word tokens. In this paper, we propose a novel denoising image-to-word mapping approach, named Denoise-I2W, for mapping images into denoising pseudo-word tokens that, without intention-irrelevant visual information, enhance accurate ZS-CIR. Specifically, a pseudo triplet construction module first automatically constructs pseudo triples (\\textit{i.e.,} a pseudo-reference image, a pseudo-manipulation text, and a target image) for pre-training the denoising mapping network. Then, a pseudo-composed mapping module maps the pseudo-reference image to a pseudo-word token and combines it with the pseudo-manipulation text with manipulation intention. This combination aligns with the target image, facilitating denoising intention-irrelevant visual information for mapping. Our proposed Denoise-I2W is a model-agnostic and annotation-free approach. It demonstrates strong generalization capabilities across three state-of-the-art ZS-CIR models on four benchmark datasets. By integrating Denoise-I2W with existing best models, we obtain consistent and significant performance boosts ranging from 1.45\\% to 4.17\\% over the best methods without increasing inference costs. and achieve new state-of-the-art results on ZS-CIR. Our code is available at \\url{https://github.com/Pter61/denoise-i2w-tmm}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This work was submitted to IJCAI 2024, with a score of weak accept and borderline accept"
    },
    {
        "paper id": "2410.17401",
        "abstract url": "https://arxiv.org/abs/2410.17401",
        "title": "AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents",
        "rating": "1",
        "keywords": [
            [
                "Vision Language",
                "VLM"
            ],
            [
                "Attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Vision Language Models (VLMs) have revolutionized the creation of generalist web agents, empowering them to autonomously complete diverse tasks on real-world websites, thereby boosting human efficiency and productivity. However, despite their remarkable capabilities, the safety and security of these agents against malicious attacks remain critically underexplored, raising significant concerns about their safe deployment. To uncover and exploit such vulnerabilities in web agents, we provide AdvWeb, a novel black-box attack framework designed against web agents. AdvWeb trains an adversarial prompter model that generates and injects adversarial prompts into web pages, misleading web agents into executing targeted adversarial actions such as inappropriate stock purchases or incorrect bank transactions, actions that could lead to severe real-world consequences. With only black-box access to the web agent, we train and optimize the adversarial prompter model using DPO, leveraging both successful and failed attack strings against the target agent. Unlike prior approaches, our adversarial string injection maintains stealth and control: (1) the appearance of the website remains unchanged before and after the attack, making it nearly impossible for users to detect tampering, and (2) attackers can modify specific substrings within the generated adversarial string to seamlessly change the attack objective (e.g., purchasing stocks from a different company), enhancing attack flexibility and efficiency. We conduct extensive evaluations, demonstrating that AdvWeb achieves high success rates in attacking SOTA GPT-4V-based VLM agent across various web tasks. Our findings expose critical vulnerabilities in current LLM/VLM-based agents, emphasizing the urgent need for developing more reliable web agents and effective defenses. Our code and data are available at https://ai-secure.github.io/AdvWeb/ .",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2410.17413",
        "abstract url": "https://arxiv.org/abs/2410.17413",
        "title": "Scalable Influence and Fact Tracing for Large Language Model Pretraining",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Training data attribution (TDA) methods aim to attribute model outputs back to specific training examples, and the application of these methods to large language model (LLM) outputs could significantly advance model transparency and data curation. However, it has been challenging to date to apply these methods to the full scale of LLM pretraining. In this paper, we refine existing gradient-based methods to work effectively at scale, allowing us to retrieve influential examples for an 8B-parameter language model from a pretraining corpus of over 160B tokens with no need for subsampling or pre-filtering. Our method combines several techniques, including optimizer state correction, a task-specific Hessian approximation, and normalized encodings, which we find to be critical for performance at scale. In quantitative evaluations on a fact tracing task, our method performs best at identifying examples that influence model predictions, but classical, model-agnostic retrieval methods such as BM25 still perform better at finding passages which explicitly contain relevant facts. These results demonstrate a misalignment between factual attribution and causal influence. With increasing model size and training tokens, we find that influence more closely aligns with attribution. Finally, we examine different types of examples identified as influential by our method, finding that while many directly entail a particular fact, others support the same output by reinforcing priors on relation types, common entities, and names.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17423",
        "abstract url": "https://arxiv.org/abs/2410.17423",
        "title": "Artificial Intelligence in Brazilian News: A Mixed-Methods Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "The current surge in Artificial Intelligence (AI) interest, reflected in heightened media coverage since 2009, has sparked significant debate on AI's implications for privacy, social justice, workers' rights, and democracy. The media plays a crucial role in shaping public perception and acceptance of AI technologies. However, research into how AI appears in media has primarily focused on anglophone contexts, leaving a gap in understanding how AI is represented globally. This study addresses this gap by analyzing 3,560 news articles from Brazilian media published between July 1, 2023, and February 29, 2024, from 13 popular online news outlets. Using Computational Grounded Theory (CGT), the study applies Latent Dirichlet Allocation (LDA), BERTopic, and Named-Entity Recognition to investigate the main topics in AI coverage and the entities represented. The findings reveal that Brazilian news coverage of AI is dominated by topics related to applications in the workplace and product launches, with limited space for societal concerns, which mostly focus on deepfakes and electoral integrity. The analysis also highlights a significant presence of industry-related entities, indicating a strong influence of corporate agendas in the country's news. This study underscores the need for a more critical and nuanced discussion of AI's societal impacts in Brazilian media.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "18 pages, 8 figures, 3 tables"
    },
    {
        "paper id": "2410.17427",
        "abstract url": "https://arxiv.org/abs/2410.17427",
        "title": "SigCLR: Sigmoid Contrastive Learning of Visual Representations",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We propose SigCLR: Sigmoid Contrastive Learning of Visual Representations. SigCLR utilizes the logistic loss that only operates on pairs and does not require a global view as in the cross-entropy loss used in SimCLR. We show that logistic loss shows competitive performance on CIFAR-10, CIFAR-100, and Tiny-IN compared to other established SSL objectives. Our findings verify the importance of learnable bias as in the case of SigLUP, however, it requires a fixed temperature as in the SimCLR to excel. Overall, SigCLR is a promising replacement for the SimCLR which is ubiquitous and has shown tremendous success in various domains.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Neurips 2024 SSL Workshop"
    },
    {
        "paper id": "2410.17434",
        "abstract url": "https://arxiv.org/abs/2410.17434",
        "title": "LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have shown promising progress in understanding and analyzing video content. However, processing long videos remains a significant challenge constrained by LLM's context size. To address this limitation, we propose LongVU, a spatiotemporal adaptive compression mechanism thats reduces the number of video tokens while preserving visual details of long videos. Our idea is based on leveraging cross-modal query and inter-frame dependencies to adaptively reduce temporal and spatial redundancy in videos. Specifically, we leverage DINOv2 features to remove redundant frames that exhibit high similarity. Then we utilize text-guided cross-modal query for selective frame feature reduction. Further, we perform spatial token reduction across frames based on their temporal dependencies. Our adaptive compression strategy effectively processes a large number of frames with little visual information loss within given context length. Our LongVU consistently surpass existing methods across a variety of video understanding benchmarks, especially on hour-long video understanding tasks such as VideoMME and MLVU. Given a light-weight LLM, our LongVU also scales effectively into a smaller size with state-of-the-art video understanding performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://vision-cair.github.io/LongVU"
    },
    {
        "paper id": "2410.17437",
        "abstract url": "https://arxiv.org/abs/2410.17437",
        "title": "Improving Automatic Speech Recognition with Decoder-Centric Regularisation in Encoder-Decoder Models",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "This paper proposes a simple yet effective way of regularising the encoder-decoder-based automatic speech recognition (ASR) models that enhance the robustness of the model and improve the generalisation to out-of-domain scenarios. The proposed approach is dubbed as $\\textbf{De}$coder-$\\textbf{C}$entric $\\textbf{R}$egularisation in $\\textbf{E}$ncoder-$\\textbf{D}$ecoder (DeCRED) architecture for ASR, where auxiliary classifier(s) is introduced in layers of the decoder module. Leveraging these classifiers, we propose two decoding strategies that re-estimate the next token probabilities. Using the recent E-branchformer architecture, we build strong ASR systems that obtained competitive WERs as compared to Whisper-medium and outperformed OWSM v3; while relying only on a fraction of training data and model size. On top of such a strong baseline, we show that DeCRED can further improve the results and, moreover, generalise much better to out-of-domain scenarios, where we show an absolute reduction of 2.7 and 2.9 WERs on AMI and Gigaspeech datasets, respectively. We provide extensive analysis and accompanying experiments that support the benefits of the proposed regularisation scheme.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17439",
        "abstract url": "https://arxiv.org/abs/2410.17439",
        "title": "Evaluating AI-Generated Essays with GRE Analytical Writing Assessment",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The recent revolutionary advance in generative AI enables the generation of realistic and coherent texts by large language models (LLMs). Despite many existing evaluation metrics on the quality of the generated texts, there is still a lack of rigorous assessment of how well LLMs perform in complex and demanding writing assessments. This study examines essays generated by ten leading LLMs for the analytical writing assessment of the Graduate Record Exam (GRE). We assessed these essays using both human raters and the e-rater automated scoring engine as used in the GRE scoring pipeline. Notably, the top-performing Gemini and GPT-4o received an average score of 4.78 and 4.67, respectively, falling between \"generally thoughtful, well-developed analysis of the issue and conveys meaning clearly\" and \"presents a competent analysis of the issue and conveys meaning with acceptable clarity\" according to the GRE scoring guideline. We also evaluated the detection accuracy of these essays, with detectors trained on essays generated by the same and different LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "20 pages, 6 figures"
    },
    {
        "paper id": "2410.17448",
        "abstract url": "https://arxiv.org/abs/2410.17448",
        "title": "In Context Learning and Reasoning for Symbolic Regression with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are transformer-based machine learning models that have shown remarkable performance in tasks for which they were not explicitly trained. Here, we explore the potential of LLMs to perform symbolic regression -- a machine-learning method for finding simple and accurate equations from datasets. We prompt GPT-4 to suggest expressions from data, which are then optimized and evaluated using external Python tools. These results are fed back to GPT-4, which proposes improved expressions while optimizing for complexity and loss. Using chain-of-thought prompting, we instruct GPT-4 to analyze the data, prior expressions, and the scientific context (expressed in natural language) for each problem before generating new expressions. We evaluated the workflow in rediscovery of five well-known scientific equations from experimental data, and on an additional dataset without a known equation. GPT-4 successfully rediscovered all five equations, and in general, performed better when prompted to use a scratchpad and consider scientific context. We also demonstrate how strategic prompting improves the model's performance and how the natural language interface simplifies integrating theory with data. Although this approach does not outperform established SR programs where target equations are more complex, LLMs can nonetheless iterate toward improved solutions while following instructions and incorporating scientific context in natural language.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17482",
        "abstract url": "https://arxiv.org/abs/2410.17482",
        "title": "Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Inferences from adjective-noun combinations like \"Is artificial intelligence still intelligence?\" provide a good test bed for LLMs' understanding of meaning and compositional generalization capability, since there are many combinations which are novel to both humans and LLMs but nevertheless elicit convergent human judgments. We study a range of LLMs and find that the largest models we tested are able to draw human-like inferences when the inference is determined by context and can generalize to unseen adjective-noun combinations. We also propose three methods to evaluate LLMs on these inferences out of context, where there is a distribution of human-like answers rather than a single correct answer. We find that LLMs show a human-like distribution on at most 75\\% of our dataset, which is promising but still leaves room for improvement.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "9 pages (23 pages with appendix). Accepted to GenBench 2024"
    },
    {
        "paper id": "2410.17485",
        "abstract url": "https://arxiv.org/abs/2410.17485",
        "title": "VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "Recent studies have augmented large language models (LLMs) with speech capabilities, leading to the development of speech language models (SpeechLMs). Earlier SpeechLMs focused on single-turn speech-based question answering (QA), where user input comprised a speech context and a text question. More recent studies have extended this to multi-turn conversations, though they often require complex, multi-stage supervised fine-tuning (SFT) with diverse data. Another critical challenge with SpeechLMs is catastrophic forgetting-where models optimized for speech tasks suffer significant degradation in text-only performance. To mitigate these issues, we propose a novel single-stage joint speech-text SFT approach on the low-rank adaptation (LoRA) of the LLM backbone. Our joint SFT combines text-only SFT data with three types of speech-related data: speech recognition and translation, speech-based QA, and mixed-modal SFT. Compared to previous SpeechLMs with 7B or 13B parameters, our 3B model demonstrates superior performance across various speech benchmarks while preserving the original capabilities on text-only tasks. Furthermore, our model shows emergent abilities of effectively handling previously unseen prompts and tasks, including multi-turn, mixed-modal inputs.",
        "subjects": [
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17489",
        "abstract url": "https://arxiv.org/abs/2410.17489",
        "title": "Unsupervised Domain Adaptation for Action Recognition via Self-Ensembling and Conditional Embedding Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in deep learning-based wearable human action recognition (wHAR) have improved the capture and classification of complex motions, but adoption remains limited due to the lack of expert annotations and domain discrepancies from user variations. Limited annotations hinder the model's ability to generalize to out-of-distribution samples. While data augmentation can improve generalizability, unsupervised augmentation techniques must be applied carefully to avoid introducing noise. Unsupervised domain adaptation (UDA) addresses domain discrepancies by aligning conditional distributions with labeled target samples, but vanilla pseudo-labeling can lead to error propagation. To address these challenges, we propose $\u03bc$DAR, a novel joint optimization architecture comprised of three functions: (i) consistency regularizer between augmented samples to improve model classification generalizability, (ii) temporal ensemble for robust pseudo-label generation and (iii) conditional distribution alignment to improve domain generalizability. The temporal ensemble works by aggregating predictions from past epochs to smooth out noisy pseudo-label predictions, which are then used in the conditional distribution alignment module to minimize kernel-based class-wise conditional maximum mean discrepancy ($k$CMMD) between the source and target feature space to learn a domain invariant embedding. The consistency-regularized augmentations ensure that multiple augmentations of the same sample share the same labels; this results in (a) strong generalization with limited source domain samples and (b) consistent pseudo-label generation in target samples. The novel integration of these three modules in $\u03bc$DAR results in a range of $\\approx$ 4-12% average macro-F1 score improvement over six state-of-the-art UDA methods in four benchmark wHAR datasets",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "This work has been accepted to the Proceedings of the IEEE International Conference on Data Mining, 2024"
    },
    {
        "paper id": "2410.17498",
        "abstract url": "https://arxiv.org/abs/2410.17498",
        "title": "Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated impressive abilities in symbol processing through in-context learning (ICL). This success flies in the face of decades of predictions that artificial neural networks cannot master abstract symbol manipulation. We seek to understand the mechanisms that can enable robust symbol processing in transformer networks, illuminating both the unanticipated success, and the significant limitations, of transformers in symbol processing. Borrowing insights from symbolic AI on the power of Production System architectures, we develop a high-level language, PSL, that allows us to write symbolic programs to do complex, abstract symbol processing, and create compilers that precisely implement PSL programs in transformer networks which are, by construction, 100% mechanistically interpretable. We demonstrate that PSL is Turing Universal, so the work can inform the understanding of transformer ICL in general. The type of transformer architecture that we compile from PSL programs suggests a number of paths for enhancing transformers' capabilities at symbol processing. (Note: The first section of the paper gives an extended synopsis of the entire paper.)",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.NE",
            "cs.SC"
        ],
        "comment": "101 pages (including 30 pages of Appendices), 18 figures"
    },
    {
        "paper id": "2410.17513",
        "abstract url": "https://arxiv.org/abs/2410.17513",
        "title": "HCDN: A Change Detection Network for Construction Housekeeping Using Feature Fusion and Large Vision Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Workplace safety has received increasing attention as millions of workers worldwide suffer from work-related accidents. Despite poor housekeeping is a significant contributor to construction accidents, there remains a significant lack of technological research focused on improving housekeeping practices in construction sites. Recognizing and locating poor housekeeping in a dynamic construction site is an important task that can be improved through computer vision approaches. Despite advances in AI and computer vision, existing methods for detecting poor housekeeping conditions face many challenges, including limited explanations, lack of locating of poor housekeeping, and lack of annotated datasets. On the other hand, change detection which aims to detect the changed environmental conditions (e.g., changing from good to poor housekeeping) and 'where' the change has occurred (e.g., location of objects causing poor housekeeping), has not been explored to the problem of housekeeping management. To address these challenges, we propose the Housekeeping Change Detection Network (HCDN), an advanced change detection neural network that integrates a feature fusion module and a large vision model, achieving state-of-the-art performance. Additionally, we introduce the approach to establish a novel change detection dataset (named Housekeeping-CCD) focused on housekeeping in construction sites, along with a housekeeping segmentation dataset. Our contributions include significant performance improvements compared to existing methods, providing an effective tool for enhancing construction housekeeping and safety. To promote further development, we share our source code and trained models for global researchers: https://github.com/NUS-DBE/Housekeeping-CD.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17514",
        "abstract url": "https://arxiv.org/abs/2410.17514",
        "title": "SRA: A Novel Method to Improve Feature Embedding in Self-supervised Learning for Histopathological Images",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Self-supervised learning has become a cornerstone in various areas, particularly histopathological image analysis. Image augmentation plays a crucial role in self-supervised learning, as it generates variations in image samples. However, traditional image augmentation techniques often overlook the unique characteristics of histopathological images. In this paper, we propose a new histopathology-specific image augmentation method called stain reconstruction augmentation (SRA). We integrate our SRA with MoCo v3, a leading model in self-supervised contrastive learning, along with our additional contrastive loss terms, and call the new model SRA-MoCo v3. We demonstrate that our SRA-MoCo v3 always outperforms the standard MoCo v3 across various downstream tasks and achieves comparable or superior performance to other foundation models pre-trained on significantly larger histopathology datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Hamid Manoochehri and Bodong Zhang contributed equally to this work"
    },
    {
        "paper id": "2410.17519",
        "abstract url": "https://arxiv.org/abs/2410.17519",
        "title": "Large Language Models Still Exhibit Bias in Long Text",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Existing fairness benchmarks for large language models (LLMs) primarily focus on simple tasks, such as multiple-choice questions, overlooking biases that may arise in more complex scenarios like long-text generation. To address this gap, we introduce the Long Text Fairness Test (LTF-TEST), a framework that evaluates biases in LLMs through essay-style prompts. LTF-TEST covers 14 topics and 10 demographic axes, including gender and race, resulting in 11,948 samples. By assessing both model responses and the reasoning behind them, LTF-TEST uncovers subtle biases that are difficult to detect in simple responses. In our evaluation of five recent LLMs, including GPT-4o and LLaMa3, we identify two key patterns of bias. First, these models frequently favor certain demographic groups in their responses. Second, they show excessive sensitivity toward traditionally disadvantaged groups, often providing overly protective responses while neglecting others. To mitigate these biases, we propose FT-REGARD, a finetuning approach that pairs biased prompts with neutral responses. FT-REGARD reduces gender bias by 34.6% and improves performance by 1.4 percentage points on the BBQ benchmark, offering a promising approach to addressing biases in long-text generation tasks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "22 page, 38 figures, Neurips (SoLaR Workshop)"
    },
    {
        "paper id": "2410.17520",
        "abstract url": "https://arxiv.org/abs/2410.17520",
        "title": "MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Autonomous agents powered by large language models (LLMs) show promising potential in assistive tasks across various domains, including mobile device control. As these agents interact directly with personal information and device settings, ensuring their safe and reliable behavior is crucial to prevent undesirable outcomes. However, no benchmark exists for standardized evaluation of the safety of mobile device-control agents. In this work, we introduce MobileSafetyBench, a benchmark designed to evaluate the safety of device-control agents within a realistic mobile environment based on Android emulators. We develop a diverse set of tasks involving interactions with various mobile applications, including messaging and banking applications. To clearly evaluate safety apart from general capabilities, we design separate tasks measuring safety and tasks evaluating helpfulness. The safety tasks challenge agents with managing potential risks prevalent in daily life and include tests to evaluate robustness against indirect prompt injections. Our experiments demonstrate that while baseline agents, based on state-of-the-art LLMs, perform well in executing helpful tasks, they show poor performance in safety tasks. To mitigate these safety concerns, we propose a prompting method that encourages agents to prioritize safety considerations. While this method shows promise in promoting safer behaviors, there is still considerable room for improvement to fully earn user trust. This highlights the urgent need for continued research to develop more robust safety mechanisms in mobile environments. We open-source our benchmark at: https://mobilesafetybench.github.io/.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17536",
        "abstract url": "https://arxiv.org/abs/2410.17536",
        "title": "Adaptive Wireless Image Semantic Transmission: Design, Simulation, and Prototype Validation",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "The rapid development of artificial intelligence has significantly advanced semantic communications, particularly in wireless image transmission. However, most existing approaches struggle to precisely distinguish and prioritize image content, and they do not sufficiently incorporate semantic priorities into system design. In this study, we propose an adaptive wireless image semantic transmission scheme called ASCViT-JSCC, which utilizes vision transformer-based joint source-channel coding (JSCC). This scheme prioritizes different image regions based on their importance, identified through object and feature point detection. Unimportant background sections are masked, enabling them to be recovered at the receiver, while the freed resources are allocated to enhance object protection via the JSCC network. We also integrate quantization modules to enable compatibility with quadrature amplitude modulation, commonly used in modern wireless communications. To address frequency-selective fading channels, we introduce CSIPA-Net, which allocates power based on channel information, further improving performance. Notably, we conduct over-the-air testing on a prototype platform composed of a software-defined radio and embedded graphics processing unit systems, validating our methods. Both simulations and real-world measurements demonstrate that ASCViT-JSCC effectively prioritizes object protection according to channel conditions, significantly enhancing image reconstruction quality, especially in challenging channel environments.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17546",
        "abstract url": "https://arxiv.org/abs/2410.17546",
        "title": "Advancing Interpretability in Text Classification through Prototype Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Deep neural networks have achieved remarkable performance in various text-based tasks but often lack interpretability, making them less suitable for applications where transparency is critical. To address this, we propose ProtoLens, a novel prototype-based model that provides fine-grained, sub-sentence level interpretability for text classification. ProtoLens uses a Prototype-aware Span Extraction module to identify relevant text spans associated with learned prototypes and a Prototype Alignment mechanism to ensure prototypes are semantically meaningful throughout training. By aligning the prototype embeddings with human-understandable examples, ProtoLens provides interpretable predictions while maintaining competitive accuracy. Extensive experiments demonstrate that ProtoLens outperforms both prototype-based and non-interpretable baselines on multiple text classification benchmarks. Code and data are available at \\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.18140",
        "abstract url": "https://arxiv.org/abs/2410.18140",
        "title": "Tethering Broken Themes: Aligning Neural Topic Models with Labels and Authors",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Topic models are a popular approach for extracting semantic information from large document collections. However, recent studies suggest that the topics generated by these models often do not align well with human intentions. While metadata such as labels and authorship information is available, it has not yet been effectively incorporated into neural topic models. To address this gap, we introduce FANToM, a novel method for aligning neural topic models with both labels and authorship information. FANToM allows for the inclusion of this metadata when available, producing interpretable topics and author distributions for each topic. Our approach demonstrates greater expressiveness than conventional topic models by learning the alignment between labels, topics, and authors. Experimental results show that FANToM improves upon existing models in terms of both topic quality and alignment. Additionally, it identifies author interests and similarities.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.18141",
        "abstract url": "https://arxiv.org/abs/2410.18141",
        "title": "SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "RAG systems consist of multiple modules to work together. However, these modules are usually separately trained. We argue that a system like RAG that incorporates multiple modules should be jointly optimized to achieve optimal performance. To demonstrate this, we design a specific pipeline called \\textbf{SmartRAG} that includes a policy network and a retriever. The policy network can serve as 1) a decision maker that decides when to retrieve, 2) a query rewriter to generate a query most suited to the retriever, and 3) an answer generator that produces the final response with/without the observations. We then propose to jointly optimize the whole system using a reinforcement learning algorithm, with the reward designed to encourage the system to achieve the best performance with minimal retrieval cost. When jointly optimized, all the modules can be aware of how other modules are working and thus find the best way to work together as a complete system. Empirical results demonstrate that the jointly optimized SmartRAG can achieve better performance than separately optimized counterparts.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.18142",
        "abstract url": "https://arxiv.org/abs/2410.18142",
        "title": "Analyzing Nobel Prize Literature with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study examines the capabilities of advanced Large Language Models (LLMs), particularly the o1 model, in the context of literary analysis. The outputs of these models are compared directly to those produced by graduate-level human participants. By focusing on two Nobel Prize-winning short stories, 'Nine Chapters' by Han Kang, the 2024 laureate, and 'Friendship' by Jon Fosse, the 2023 laureate, the research explores the extent to which AI can engage with complex literary elements such as thematic analysis, intertextuality, cultural and historical contexts, linguistic and structural innovations, and character development. Given the Nobel Prize's prestige and its emphasis on cultural, historical, and linguistic richness, applying LLMs to these works provides a deeper understanding of both human and AI approaches to interpretation. The study uses qualitative and quantitative evaluations of coherence, creativity, and fidelity to the text, revealing the strengths and limitations of AI in tasks typically reserved for human expertise. While LLMs demonstrate strong analytical capabilities, particularly in structured tasks, they often fall short in emotional nuance and coherence, areas where human interpretation excels. This research underscores the potential for human-AI collaboration in the humanities, opening new opportunities in literary studies and beyond.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.18146",
        "abstract url": "https://arxiv.org/abs/2410.18146",
        "title": "Meaning Typed Prompting: A Technique for Efficient, Reliable Structured Output Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Extending Large Language Models (LLMs) to advanced applications requires reliable structured output generation. Existing methods which often rely on rigid JSON schemas, can lead to unreliable outputs, diminished reasoning capabilities, and increased computational overhead, limiting LLMs' adaptability for complex tasks. We introduce Meaning Typed Prompting (MTP), a technique for efficient structured output generation that integrates types, meanings, and abstractions, such as variables and classes, into the prompting process. By utilizing expressive type definitions, MTP enhances output clarity and reduces dependence on complex abstractions, simplifying development, and improving implementation efficiency. This enables LLMs to understand relationships and generate structured data more effectively. Empirical evaluations on multiple benchmarks demonstrate that MTP outperforms existing frameworks in accuracy, reliability, consistency, and token efficiency. We present Semantix, a framework that implements MTP, providing practical insights into its application.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19856",
        "abstract url": "https://arxiv.org/abs/2410.19856",
        "title": "Prototype-Based Methods in Explainable AI and Emerging Opportunities in the Geosciences",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "Prototype-based methods are intrinsically interpretable XAI methods that produce predictions and explanations by comparing input data with a set of learned prototypical examples that are representative of the training data. In this work, we discuss a series of developments in the field of prototype-based XAI that show potential for scientific learning tasks, with a focus on the geosciences. We organize the prototype-based XAI literature into three themes: the development and visualization of prototypes, types of prototypes, and the use of prototypes in various learning tasks. We discuss how the authors use prototype-based methods, their novel contributions, and any limitations or challenges that may arise when adapting these methods for geoscientific learning tasks. We highlight differences between geoscientific data sets and the standard benchmarks used to develop XAI methods, and discuss how specific geoscientific applications may benefit from using or modifying existing prototype-based XAI techniques.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph"
        ],
        "comment": "Accepted at AI for Science Workshop-Oral (Attention Track), Proceedings of 41st International Conference on Machine Learning (ICML) 2024"
    },
    {
        "paper id": "2410.21303",
        "abstract url": "https://arxiv.org/abs/2410.21303",
        "title": "VEMOCLAP: A video emotion classification web application",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We introduce VEMOCLAP: Video EMOtion Classifier using Pretrained features, the first readily available and open-source web application that analyzes the emotional content of any user-provided video. We improve our previous work, which exploits open-source pretrained models that work on video frames and audio, and then efficiently fuse the resulting pretrained features using multi-head cross-attention. Our approach increases the state-of-the-art classification accuracy on the Ekman-6 video emotion dataset by 4.3% and offers an online application for users to run our model on their own videos or YouTube videos. We invite the readers to try our application at serkansulun.com/app.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM",
            "eess.IV"
        ],
        "comment": "Accepted to 2024 IEEE International Symposium on Multimedia (ISM), Tokyo, Japan"
    },
    {
        "paper id": "2411.04129",
        "abstract url": "https://arxiv.org/abs/2411.04129",
        "title": "AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Query Autocomplete (QAC) is a critical feature in modern search engines, facilitating user interaction by predicting search queries based on input prefixes. Despite its widespread adoption, the absence of large-scale, realistic datasets has hindered advancements in QAC system development. This paper addresses this gap by introducing AmazonQAC, a new QAC dataset sourced from Amazon Search logs, comprising 395M samples. The dataset includes actual sequences of user-typed prefixes leading to final search terms, as well as session IDs and timestamps that support modeling the context-dependent aspects of QAC. We assess Prefix Trees, semantic retrieval, and Large Language Models (LLMs) with and without finetuning. We find that finetuned LLMs perform best, particularly when incorporating contextual information. However, even our best system achieves only half of what we calculate is theoretically possible on our test data, which implies QAC is a challenging problem that is far from solved with existing systems. This contribution aims to stimulate further research on QAC systems to better serve user needs in diverse environments. We open-source this data on Hugging Face at https://huggingface.co/datasets/amazon/AmazonQAC.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "EMNLP 2024"
    },
    {
        "paper id": "2410.16698",
        "abstract url": "https://arxiv.org/abs/2410.16698",
        "title": "Hyperboloid GPLVM for Discovering Continuous Hierarchies via Nonparametric Estimation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Dimensionality reduction (DR) offers a useful representation of complex high-dimensional data. Recent DR methods focus on hyperbolic geometry to derive a faithful low-dimensional representation of hierarchical data. However, existing methods are based on neighbor embedding, frequently ruining the continual relation of the hierarchies. This paper presents hyperboloid Gaussian process (GP) latent variable models (hGP-LVMs) to embed high-dimensional hierarchical data with implicit continuity via nonparametric estimation. We adopt generative modeling using the GP, which brings effective hierarchical embedding and executes ill-posed hyperparameter tuning. This paper presents three variants that employ original point, sparse point, and Bayesian estimations. We establish their learning algorithms by incorporating the Riemannian optimization and active approximation scheme of GP-LVM. For Bayesian inference, we further introduce the reparameterization trick to realize Bayesian latent variable learning. In the last part of this paper, we apply hGP-LVMs to several datasets and show their ability to represent high-dimensional hierarchies in low-dimensional spaces.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16701",
        "abstract url": "https://arxiv.org/abs/2410.16701",
        "title": "ClimaQA: An Automated Evaluation Framework for Climate Foundation Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The use of foundation models in climate science has recently gained significant attention. However, a critical issue remains: the lack of a comprehensive evaluation framework capable of assessing the quality and scientific validity of model outputs. To address this issue, we develop ClimaGen (Climate QA Generator), an automated algorithmic framework that generates question-answer pairs from graduate textbooks with climate scientists in the loop. As a result, we present ClimaQA-Gold, an expert-annotated benchmark dataset alongside ClimaQA-Silver, a large-scale, comprehensive synthetic QA dataset for climate science. Finally, we develop evaluation strategies and compare different Large Language Models (LLMs) on our benchmarks. Our results offer novel insights into various approaches used to enhance climate foundation models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16709",
        "abstract url": "https://arxiv.org/abs/2410.16709",
        "title": "Universal approximation property of ODENet and ResNet with a single activation function",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We study a universal approximation property of ODENet and ResNet. The ODENet is a map from an initial value to the final value of an ODE system in a finite interval. It is considered a mathematical model of a ResNet-type deep learning system. We consider dynamical systems with vector fields given by a single composition of the activation function and an affine mapping, which is the most common choice of the ODENet or ResNet vector field in actual machine learning systems. We show that such an ODENet and ResNet with a restricted vector field can uniformly approximate ODENet with a general vector field.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.NA",
            "stat.ML"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2410.16738",
        "abstract url": "https://arxiv.org/abs/2410.16738",
        "title": "LLM-Assisted Red Teaming of Diffusion Models through \"Failures Are Fated, But Can Be Faded\"",
        "rating": "0.5",
        "keywords": [
            [
                "social biases"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In large deep neural networks that seem to perform surprisingly well on many tasks, we also observe a few failures related to accuracy, social biases, and alignment with human values, among others. Therefore, before deploying these models, it is crucial to characterize this failure landscape for engineers to debug or audit models. Nevertheless, it is infeasible to exhaustively test for all possible combinations of factors that could lead to a model's failure. In this paper, we improve the \"Failures are fated, but can be faded\" framework (arXiv:2406.07145)--a post-hoc method to explore and construct the failure landscape in pre-trained generative models--with a variety of deep reinforcement learning algorithms, screening tests, and LLM-based rewards and state generation. With the aid of limited human feedback, we then demonstrate how to restructure the failure landscape to be more desirable by moving away from the discovered failure modes. We empirically demonstrate the effectiveness of the proposed method on diffusion models. We also highlight the strengths and weaknesses of each algorithm in identifying failure modes.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "13 pages, 11 figures. arXiv admin note: substantial text overlap with arXiv:2406.07145"
    },
    {
        "paper id": "2410.16739",
        "abstract url": "https://arxiv.org/abs/2410.16739",
        "title": "Corrected Soft Actor Critic for Continuous Control",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The Soft Actor-Critic (SAC) algorithm is known for its stability and high sample efficiency in deep reinforcement learning. However, the tanh transformation applied to sampled actions in SAC distorts the action distribution, hindering the selection of the most probable actions. This paper presents a novel action sampling method that directly identifies and selects the most probable actions within the transformed distribution, thereby addressing this issue. Extensive experiments on standard continuous control benchmarks demonstrate that the proposed method significantly enhances SAC's performance, resulting in faster convergence and higher cumulative rewards compared to the original algorithm.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16748",
        "abstract url": "https://arxiv.org/abs/2410.16748",
        "title": "Uncovering Key Trends in Industry 5.0 through Advanced AI Techniques",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This article analyzes around 200 online articles to identify trends within Industry 5.0 using artificial intelligence techniques. Specifically, it applies algorithms such as LDA, BERTopic, LSA, and K-means, in various configurations, to extract and compare the central themes present in the literature. The results reveal a convergence around a core set of themes while also highlighting that Industry 5.0 spans a wide range of topics. The study concludes that Industry 5.0, as an evolution of Industry 4.0, is a broad concept that lacks a clear definition, making it difficult to focus on and apply effectively. Therefore, for Industry 5.0 to be useful, it needs to be refined and more clearly defined. Furthermore, the findings demonstrate that well-known AI techniques can be effectively utilized for trend identification, particularly when the available literature is extensive and the subject matter lacks precise boundaries. This study showcases the potential of AI in extracting meaningful insights from large and diverse datasets, even in cases where the thematic structure of the domain is not clearly delineated.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16750",
        "abstract url": "https://arxiv.org/abs/2410.16750",
        "title": "Theoretical Convergence Guarantees for Variational Autoencoders",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Variational Autoencoders (VAE) are popular generative models used to sample from complex data distributions. Despite their empirical success in various machine learning tasks, significant gaps remain in understanding their theoretical properties, particularly regarding convergence guarantees. This paper aims to bridge that gap by providing non-asymptotic convergence guarantees for VAE trained using both Stochastic Gradient Descent and Adam algorithms.We derive a convergence rate of $\\mathcal{O}(\\log n / \\sqrt{n})$, where $n$ is the number of iterations of the optimization algorithm, with explicit dependencies on the batch size, the number of variational samples, and other key hyperparameters. Our theoretical analysis applies to both Linear VAE and Deep Gaussian VAE, as well as several VAE variants, including $\u03b2$-VAE and IWAE. Additionally, we empirically illustrate the impact of hyperparameters on convergence, offering new insights into the theoretical understanding of VAE training.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16759",
        "abstract url": "https://arxiv.org/abs/2410.16759",
        "title": "Towards Efficient IMC Accelerator Design Through Joint Hardware-Workload Co-optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Designing generalized in-memory computing (IMC) hardware that efficiently supports a variety of workloads requires extensive design space exploration, which is infeasible to perform manually. Optimizing hardware individually for each workload or solely for the largest workload often fails to yield the most efficient generalized solutions. To address this, we propose a joint hardware-workload optimization framework that identifies optimised IMC chip architecture parameters, enabling more efficient, workload-flexible hardware. We show that joint optimization achieves 36%, 36%, 20%, and 69% better energy-latency-area scores for VGG16, ResNet18, AlexNet, and MobileNetV3, respectively, compared to the separate architecture parameters search optimizing for a single largest workload. Additionally, we quantify the performance trade-offs and losses of the resulting generalized IMC hardware compared to workload-specific IMC designs.",
        "subjects": [
            "cs.AR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16760",
        "abstract url": "https://arxiv.org/abs/2410.16760",
        "title": "Efficient Frequency Selective Surface Analysis via End-to-End Model-Based Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces an innovative end-to-end model-based deep learning approach for efficient electromagnetic analysis of high-dimensional frequency selective surfaces (FSS). Unlike traditional data-driven methods that require large datasets, this approach combines physical insights from equivalent circuit models with deep learning techniques to significantly reduce model complexity and enhance prediction accuracy. Compared to previously introduced model-based learning approaches, the proposed method is trained end-to-end from the physical structure of the FSS (geometric parameters) to its electromagnetic response (S-parameters). Additionally, an improvement in phase prediction accuracy through a modified loss function is presented. Comparisons with direct models, including deep neural networks (DNN) and radial basis function networks (RBFN), demonstrate the superiority of the model-based approach in terms of computational efficiency, model size, and generalization capability.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16794",
        "abstract url": "https://arxiv.org/abs/2410.16794",
        "title": "One-Step Diffusion Distillation through Score Implicit Matching",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Despite their strong performances on many generative tasks, diffusion models require a large number of sampling steps in order to generate realistic samples. This has motivated the community to develop effective methods to distill pre-trained diffusion models into more efficient models, but these methods still typically require few-step inference or perform substantially worse than the underlying model. In this paper, we present Score Implicit Matching (SIM) a new approach to distilling pre-trained diffusion models into single-step generator models, while maintaining almost the same sample generation ability as the original model as well as being data-free with no need of training samples for distillation. The method rests upon the fact that, although the traditional score-based loss is intractable to minimize for generator models, under certain conditions we can efficiently compute the gradients for a wide class of score-based divergences between a diffusion model and a generator. SIM shows strong empirical performances for one-step generators: on the CIFAR10 dataset, it achieves an FID of 2.06 for unconditional generation and 1.96 for class-conditional generation. Moreover, by applying SIM to a leading transformer-based diffusion model, we distill a single-step generator for text-to-image (T2I) generation that attains an aesthetic score of 6.42 with no performance decline over the original multi-step counterpart, clearly outperforming the other one-step generators including SDXL-TURBO of 5.33, SDXL-LIGHTNING of 5.34 and HYPER-SDXL of 5.85. We will release this industry-ready one-step transformer-based T2I generator along with this paper.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2410.16826",
        "abstract url": "https://arxiv.org/abs/2410.16826",
        "title": "Guarantees of a Preconditioned Subgradient Algorithm for Overparameterized Asymmetric Low-rank Matrix Recovery",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we focus on a matrix factorization-based approach for robust low-rank and asymmetric matrix recovery from corrupted measurements. We address the challenging scenario where the rank of the sought matrix is unknown and employ an overparameterized approach using the variational form of the nuclear norm as a regularizer. We propose a subgradient algorithm that inherits the merits of preconditioned algorithms, whose rate of convergence does not depend on the condition number of the sought matrix, and addresses their current limitation, i.e., the lack of convergence guarantees in the case of asymmetric matrices with unknown rank. In this setting, we provide, for the first time in the literature, linear convergence guarantees for the derived overparameterized preconditioned subgradient algorithm in the presence of gross corruptions. Additionally, by applying our approach to matrix sensing, we highlight its merits when the measurement operator satisfies the mixed-norm restricted isometry properties. Lastly, we present numerical experiments that validate our theoretical results and demonstrate the effectiveness of our approach.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16846",
        "abstract url": "https://arxiv.org/abs/2410.16846",
        "title": "Safe Load Balancing in Software-Defined-Networking",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "High performance, reliability and safety are crucial properties of any Software-Defined-Networking (SDN) system. Although the use of Deep Reinforcement Learning (DRL) algorithms has been widely studied to improve performance, their practical applications are still limited as they fail to ensure safe operations in exploration and decision-making. To fill this gap, we explore the design of a Control Barrier Function (CBF) on top of Deep Reinforcement Learning (DRL) algorithms for load-balancing. We show that our DRL-CBF approach is capable of meeting safety requirements during training and testing while achieving near-optimal performance in testing. We provide results using two simulators: a flow-based simulator, which is used for proof-of-concept and benchmarking, and a packet-based simulator that implements real protocols and scheduling. Thanks to the flow-based simulator, we compared the performance against the optimal policy, solving a Non Linear Programming (NLP) problem with the SCIP solver. Furthermore, we showed that pre-trained models in the flow-based simulator, which is faster, can be transferred to the packet simulator, which is slower but more accurate, with some fine-tuning. Overall, the results suggest that near-optimal Quality-of-Service (QoS) performance in terms of end-to-end delay can be achieved while safety requirements related to link capacity constraints are guaranteed. In the packet-based simulator, we also show that our DRL-CBF algorithms outperform non-RL baseline algorithms. When the models are fine-tuned over a few episodes, we achieved smoother QoS and safety in training, and similar performance in testing compared to the case where models have been trained from scratch.",
        "subjects": [
            "cs.NI",
            "cs.LG"
        ],
        "comment": "Accepted to Computer Communications 2024. arXiv admin note: text overlap with arXiv:2401.05525"
    },
    {
        "paper id": "2410.16849",
        "abstract url": "https://arxiv.org/abs/2410.16849",
        "title": "Polyak's Heavy Ball Method Achieves Accelerated Local Rate of Convergence under Polyak-Lojasiewicz Inequality",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we consider the convergence of Polyak's heavy ball method, both in continuous and discrete time, on a non-convex objective function. We recover the convergence rates derived in [Polyak, U.S.S.R. Comput. Math. and Math. Phys., 1964] for strongly convex objective functions, assuming only validity of the Polyak-Lojasiewicz inequality. In continuous time our result holds for all initializations, whereas in the discrete time setting we conduct a local analysis around the global minima. Our results demonstrate that the heavy ball method does, in fact, accelerate on the class of objective functions satisfying the Polyak-Lojasiewicz inequality. This holds even in the discrete time setting, provided the method reaches a neighborhood of the global minima. Instead of the usually employed Lyapunov-type arguments, our approach leverages a new differential geometric perspective of the Polyak-Lojasiewicz inequality proposed in [Rebjock and Boumal, Math. Program., 2024].",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16871",
        "abstract url": "https://arxiv.org/abs/2410.16871",
        "title": "Error Feedback under $(L_0,L_1)$-Smoothness: Normalization and Momentum",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We provide the first proof of convergence for normalized error feedback algorithms across a wide range of machine learning problems. Despite their popularity and efficiency in training deep neural networks, traditional analyses of error feedback algorithms rely on the smoothness assumption that does not capture the properties of objective functions in these problems. Rather, these problems have recently been shown to satisfy generalized smoothness assumptions, and the theoretical understanding of error feedback algorithms under these assumptions remains largely unexplored. Moreover, to the best of our knowledge, all existing analyses under generalized smoothness either i) focus on single-node settings or ii) make unrealistically strong assumptions for distributed settings, such as requiring data heterogeneity, and almost surely bounded stochastic gradient noise variance. In this paper, we propose distributed error feedback algorithms that utilize normalization to achieve the $O(1/\\sqrt{K})$ convergence rate for nonconvex problems under generalized smoothness. Our analyses apply for distributed settings without data heterogeneity conditions, and enable stepsize tuning that is independent of problem parameters. Additionally, we provide strong convergence guarantees of normalized error feedback algorithms for stochastic settings. Finally, we show that due to their larger allowable stepsizes, our new normalized error feedback algorithms outperform their non-normalized counterparts on various tasks, including the minimization of polynomial functions, logistic regression, and ResNet-20 training.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16888",
        "abstract url": "https://arxiv.org/abs/2410.16888",
        "title": "Unsupervised Time Series Anomaly Prediction with Importance-based Generative Contrastive Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Time series anomaly prediction plays an essential role in many real-world scenarios, such as environmental prevention and prompt maintenance of cyber-physical systems. However, existing time series anomaly prediction methods mainly require supervised training with plenty of manually labeled data, which are difficult to obtain in practice. Besides, unseen anomalies can occur during inference, which could differ from the labeled training data and make these models fail to predict such new anomalies. In this paper, we study a novel problem of unsupervised time series anomaly prediction. We provide a theoretical analysis and propose Importance-based Generative Contrastive Learning (IGCL) to address the aforementioned problems. IGCL distinguishes between normal and anomaly precursors, which are generated by our anomaly precursor pattern generation module. To address the efficiency issues caused by the potential complex anomaly precursor combinations, we propose a memory bank with importance-based scores to adaptively store representative anomaly precursors and generate more complicated anomaly precursors. Extensive experiments on seven benchmark datasets show our method outperforms state-of-the-art baselines on unsupervised time series anomaly prediction problems.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2410.16893",
        "abstract url": "https://arxiv.org/abs/2410.16893",
        "title": "Global Optimization of Gaussian Process Acquisition Functions Using a Piecewise-Linear Kernel Approximation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian optimization relies on iteratively constructing and optimizing an acquisition function. The latter turns out to be a challenging, non-convex optimization problem itself. Despite the relative importance of this step, most algorithms employ sampling- or gradient-based methods, which do not provably converge to global optima. This work investigates mixed-integer programming (MIP) as a paradigm for \\textit{global} acquisition function optimization. Specifically, our Piecewise-linear Kernel Mixed Integer Quadratic Programming (PK-MIQP) formulation introduces a piecewise-linear approximation for Gaussian process kernels and admits a corresponding MIQP representation for acquisition functions. We analyze the theoretical regret bounds of the proposed approximation, and empirically demonstrate the framework on synthetic functions, constrained benchmarks, and a hyperparameter tuning task.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": "16 pages, 3 figures, 2 tables"
    },
    {
        "paper id": "2410.16901",
        "abstract url": "https://arxiv.org/abs/2410.16901",
        "title": "Bayes without Underfitting: Fully Correlated Deep Learning Posteriors via Alternating Projections",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayesian deep learning all too often underfits so that the Bayesian prediction is less accurate than a simple point estimate. Uncertainty quantification then comes at the cost of accuracy. For linearized models, the null space of the generalized Gauss-Newton matrix corresponds to parameters that preserve the training predictions of the point estimate. We propose to build Bayesian approximations in this null space, thereby guaranteeing that the Bayesian predictive does not underfit. We suggest a matrix-free algorithm for projecting onto this null space, which scales linearly with the number of parameters and quadratically with the number of output dimensions. We further propose an approximation that only scales linearly with parameters to make the method applicable to generative models. An extensive empirical evaluation shows that the approach scales to large models, including vision transformers with 28 million parameters.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16910",
        "abstract url": "https://arxiv.org/abs/2410.16910",
        "title": "Hierarchical Clustering for Conditional Diffusion in Image Generation",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Finding clusters of data points with similar characteristics and generating new cluster-specific samples can significantly enhance our understanding of complex data distributions. While clustering has been widely explored using Variational Autoencoders, these models often lack generation quality in real-world datasets. This paper addresses this gap by introducing TreeDiffusion, a deep generative model that conditions Diffusion Models on hierarchical clusters to obtain high-quality, cluster-specific generations. The proposed pipeline consists of two steps: a VAE-based clustering model that learns the hierarchical structure of the data, and a conditional diffusion model that generates realistic images for each cluster. We propose this two-stage process to ensure that the generated samples remain representative of their respective clusters and enhance image fidelity to the level of diffusion models. A key strength of our method is its ability to create images for each cluster, providing better visualization of the learned representations by the clustering model, as demonstrated through qualitative results. This method effectively addresses the generative limitations of VAE-based approaches while preserving their clustering performance. Empirically, we demonstrate that conditioning diffusion models on hierarchical clusters significantly enhances generative performance, thereby advancing the state of generative clustering models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "25 pages, submitted to ICLR 2025"
    },
    {
        "paper id": "2410.16926",
        "abstract url": "https://arxiv.org/abs/2410.16926",
        "title": "Pyramid Vector Quantization for LLMs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent works on compression of large language models (LLM) using quantization considered reparameterizing the architecture such that weights are distributed on the sphere. This demonstratively improves the ability to quantize by increasing the mathematical notion of coherence, resulting in fewer weight outliers without affecting the network output. In this work, we aim to further exploit this spherical geometry of the weights when performing quantization by considering Pyramid Vector Quantization (PVQ) for large language models. Arranging points evenly on the sphere is notoriously difficult, especially in high dimensions, and in case approximate solutions exists, representing points explicitly in a codebook is typically not feasible due to its additional memory cost. Instead, PVQ uses a fixed integer lattice on the sphere by projecting points onto the 1-sphere, which allows for efficient encoding and decoding without requiring an explicit codebook in memory. To obtain a practical algorithm, we propose to combine PVQ with scale quantization for which we derive theoretically optimal quantizations, under empirically verified assumptions. Further, we extend pyramid vector quantization to use Hessian information to minimize quantization error under expected feature activations, instead of only relying on weight magnitudes. Experimentally, we achieves state-of-the-art quantization performance with pareto-optimal trade-off between performance and bits per weight and bits per activation, compared to compared methods. On weight-only, we find that we can quantize a Llama-3 70B model to 3.25 bits per weight and retain 98\\% accuracy on downstream tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16927",
        "abstract url": "https://arxiv.org/abs/2410.16927",
        "title": "Revealing Hidden Bias in AI: Lessons from Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "As large language models (LLMs) become integral to recruitment processes, concerns about AI-induced bias have intensified. This study examines biases in candidate interview reports generated by Claude 3.5 Sonnet, GPT-4o, Gemini 1.5, and Llama 3.1 405B, focusing on characteristics such as gender, race, and age. We evaluate the effectiveness of LLM-based anonymization in reducing these biases. Findings indicate that while anonymization reduces certain biases, particularly gender bias, the degree of effectiveness varies across models and bias types. Notably, Llama 3.1 405B exhibited the lowest overall bias. Moreover, our methodology of comparing anonymized and non-anonymized data reveals a novel approach to assessing inherent biases in LLMs beyond recruitment applications. This study underscores the importance of careful LLM selection and suggests best practices for minimizing bias in AI applications, promoting fairness and inclusivity.",
        "subjects": [
            "cs.AI",
            "cs.CY"
        ],
        "comment": "13 pages, 18 figures. This paper presents a technical analysis of bias in large language models, focusing on bias detection and mitigation"
    },
    {
        "paper id": "2410.16941",
        "abstract url": "https://arxiv.org/abs/2410.16941",
        "title": "Business Process Simulation: Probabilistic Modeling of Intermittent Resource Availability and Multitasking Behavior",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In business process simulation, resource availability is typically modeled by assigning a calendar to each resource, e.g., Monday-Friday, 9:00-18:00. Resources are assumed to be always available during each time slot in their availability calendar. This assumption often becomes invalid due to interruptions, breaks, or time-sharing across processes. In other words, existing approaches fail to capture intermittent availability. Another limitation of existing approaches is that they either do not consider multitasking behavior, or if they do, they assume that resources always multitask (up to a maximum capacity) whenever available. However, studies have shown that the multitasking patterns vary across days. This paper introduces a probabilistic approach to model resource availability and multitasking behavior for business process simulation. In this approach, each time slot in a resource calendar has an associated availability probability and a multitasking probability per multitasking level. For example, a resource may be available on Fridays between 14:00-15:00 with 90\\% probability, and given that they are performing one task during this slot, they may take on a second concurrent task with 60\\% probability. We propose algorithms to discover probabilistic calendars and probabilistic multitasking capacities from event logs. An evaluation shows that, with these enhancements, simulation models discovered from event logs better replicate the distribution of activities and cycle times, relative to approaches with crisp calendars and monotasking assumptions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16946",
        "abstract url": "https://arxiv.org/abs/2410.16946",
        "title": "Self-Evolving Multi-Agent Collaboration Networks for Software Development",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "LLM-driven multi-agent collaboration (MAC) systems have demonstrated impressive capabilities in automatic software development at the function level. However, their heavy reliance on human design limits their adaptability to the diverse demands of real-world software development. To address this limitation, we introduce EvoMAC, a novel self-evolving paradigm for MAC networks. Inspired by traditional neural network training, EvoMAC obtains text-based environmental feedback by verifying the MAC network's output against a target proxy and leverages a novel textual backpropagation to update the network. To extend coding capabilities beyond function-level tasks to more challenging software-level development, we further propose rSDE-Bench, a requirement-oriented software development benchmark, which features complex and diverse software requirements along with automatic evaluation of requirement correctness. Our experiments show that: i) The automatic requirement-aware evaluation in rSDE-Bench closely aligns with human evaluations, validating its reliability as a software-level coding benchmark. ii) EvoMAC outperforms previous SOTA methods on both the software-level rSDE-Bench and the function-level HumanEval benchmarks, reflecting its superior coding capabilities. The benchmark can be downloaded at https://yuzhu-cai.github.io/rSDE-Bench/.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2410.16982",
        "abstract url": "https://arxiv.org/abs/2410.16982",
        "title": "Sample-Efficient Geometry Reconstruction from Euclidean Distances using Non-Convex Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The problem of finding suitable point embedding or geometric configurations given only Euclidean distance information of point pairs arises both as a core task and as a sub-problem in a variety of machine learning applications. In this paper, we aim to solve this problem given a minimal number of distance samples. To this end, we leverage continuous and non-convex rank minimization formulations of the problem and establish a local convergence guarantee for a variant of iteratively reweighted least squares (IRLS), which applies if a minimal random set of observed distances is provided. As a technical tool, we establish a restricted isometry property (RIP) restricted to a tangent space of the manifold of symmetric rank-$r$ matrices given random Euclidean distance measurements, which might be of independent interest for the analysis of other non-convex approaches. Furthermore, we assess data efficiency, scalability and generalizability of different reconstruction algorithms through numerical experiments with simulated data as well as real-world data, demonstrating the proposed algorithm's ability to identify the underlying geometry from fewer distance samples compared to the state-of-the-art.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16983",
        "abstract url": "https://arxiv.org/abs/2410.16983",
        "title": "Order Matters: Exploring Order Sensitivity in Multimodal Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) utilize multimodal contexts consisting of text, images, or videos to solve various multimodal tasks. However, we find that changing the order of multimodal input can cause the model's performance to fluctuate between advanced performance and random guessing. This phenomenon exists in both single-modality (text-only or image-only) and mixed-modality (image-text-pair) contexts. Furthermore, we demonstrate that popular MLLMs pay special attention to certain multimodal context positions, particularly the beginning and end. Leveraging this special attention, we place key video frames and important image/text content in special positions within the context and submit them to the MLLM for inference. This method results in average performance gains of 14.7% for video-caption matching and 17.8% for visual question answering tasks. Additionally, we propose a new metric, Position-Invariant Accuracy (PIA), to address order bias in MLLM evaluation. Our research findings contribute to a better understanding of Multi-Modal In-Context Learning (MMICL) and provide practical strategies for enhancing MLLM performance without increasing computational costs.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16991",
        "abstract url": "https://arxiv.org/abs/2410.16991",
        "title": "An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching. In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.",
        "subjects": [
            "cs.AI",
            "cs.GR"
        ],
        "comment": "8 pages, 8 figures, 1 table, to be published in SIGGRAPH Asia 2024 Educator's Forum"
    },
    {
        "paper id": "2410.17031",
        "abstract url": "https://arxiv.org/abs/2410.17031",
        "title": "GeoCode-GPT: A Large Language Model for Geospatial Code Generation Tasks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The increasing demand for spatiotemporal data and modeling tasks in geosciences has made geospatial code generation technology a critical factor in enhancing productivity. Although large language models (LLMs) have demonstrated potential in code generation tasks, they often encounter issues such as refusal to code or hallucination in geospatial code generation due to a lack of domain-specific knowledge and code corpora. To address these challenges, this paper presents and open-sources the GeoCode-PT and GeoCode-SFT corpora, along with the GeoCode-Eval evaluation dataset. Additionally, by leveraging QLoRA and LoRA for pretraining and fine-tuning, we introduce GeoCode-GPT-7B, the first LLM focused on geospatial code generation, fine-tuned from Code Llama-7B. Furthermore, we establish a comprehensive geospatial code evaluation framework, incorporating option matching, expert validation, and prompt engineering scoring for LLMs, and systematically evaluate GeoCode-GPT-7B using the GeoCode-Eval dataset. Experimental results show that GeoCode-GPT outperforms other models in multiple-choice accuracy by 9.1% to 32.1%, in code summarization ability by 1.7% to 25.4%, and in code generation capability by 1.2% to 25.1%. This paper provides a solution and empirical validation for enhancing LLMs' performance in geospatial code generation, extends the boundaries of domain-specific model applications, and offers valuable insights into unlocking their potential in geospatial code generation.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17042",
        "abstract url": "https://arxiv.org/abs/2410.17042",
        "title": "Deep Memory Search: A Metaheuristic Approach for Optimizing Heuristic Search",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Metaheuristic search methods have proven to be essential tools for tackling complex optimization challenges, but their full potential is often constrained by conventional algorithmic frameworks. In this paper, we introduce a novel approach called Deep Heuristic Search (DHS), which models metaheuristic search as a memory-driven process. DHS employs multiple search layers and memory-based exploration-exploitation mechanisms to navigate large, dynamic search spaces. By utilizing model-free memory representations, DHS enhances the ability to traverse temporal trajectories without relying on probabilistic transition models. The proposed method demonstrates significant improvements in search efficiency and performance across a range of heuristic optimization problems.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "10 pages, 6 figures"
    },
    {
        "paper id": "2410.17043",
        "abstract url": "https://arxiv.org/abs/2410.17043",
        "title": "Optimizing Mixture-of-Experts Inference Time Combining Model Deployment and Communication Scheduling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As machine learning models scale in size and complexity, their computational requirements become a significant barrier. Mixture-of-Experts (MoE) models alleviate this issue by selectively activating relevant experts. Despite this, MoE models are hindered by high communication overhead from all-to-all operations, low GPU utilization due to the synchronous communication constraint, and complications from heterogeneous GPU environments. This paper presents Aurora, which optimizes both model deployment and all-to-all communication scheduling to address these challenges in MoE inference. Aurora achieves minimal communication times by strategically ordering token transmissions in all-to-all communications. It improves GPU utilization by colocating experts from different models on the same device, avoiding the limitations of synchronous all-to-all communication. We analyze Aurora's optimization strategies theoretically across four common GPU cluster settings: exclusive vs. colocated models on GPUs, and homogeneous vs. heterogeneous GPUs. Aurora provides optimal solutions for three cases, and for the remaining NP-hard scenario, it offers a polynomial-time sub-optimal solution with only a 1.07x degradation from the optimal. Aurora is the first approach to minimize MoE inference time via optimal model deployment and communication scheduling across various scenarios. Evaluations demonstrate that Aurora significantly accelerates inference, achieving speedups of up to 2.38x in homogeneous clusters and 3.54x in heterogeneous environments. Moreover, Aurora enhances GPU utilization by up to 1.5x compared to existing methods.",
        "subjects": [
            "cs.LG",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17049",
        "abstract url": "https://arxiv.org/abs/2410.17049",
        "title": "A Comparison of Baseline Models and a Transformer Network for SOC Prediction in Lithium-Ion Batteries",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Accurately predicting the state of charge of Lithium-ion batteries is essential to the performance of battery management systems of electric vehicles. One of the main reasons for the slow global adoption of electric cars is driving range anxiety. The ability of a battery management system to accurately estimate the state of charge can help alleviate this problem. In this paper, a comparison between data-driven state-of-charge estimation methods is conducted. The paper compares different neural network-based models and common regression models for SOC estimation. These models include several ablated transformer networks, a neural network, a lasso regression model, a linear regression model and a decision tree. Results of various experiments conducted on data obtained from natural driving cycles of the BMW i3 battery show that the decision tree outperformed all other models including the more complex transformer network with self-attention and positional encoding.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17055",
        "abstract url": "https://arxiv.org/abs/2410.17055",
        "title": "Optimal Design for Reward Modeling in RLHF",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become a popular approach to align language models (LMs) with human preferences. This method involves collecting a large dataset of human pairwise preferences across various text generations and using it to infer (implicitly or explicitly) a reward model. Numerous methods have been proposed to learn the reward model and align a LM with it. However, the costly process of collecting human preferences has received little attention and could benefit from theoretical insights. This paper addresses this issue and aims to formalize the reward training model in RLHF. We frame the selection of an effective dataset as a simple regret minimization task, using a linear contextual dueling bandit method. Given the potentially large number of arms, this approach is more coherent than the best-arm identification setting. We then propose an offline framework for solving this problem. Under appropriate assumptions - linearity of the reward model in the embedding space, and boundedness of the reward parameter - we derive bounds on the simple regret. Finally, we provide a lower bound that matches our upper bound up to constant and logarithmic terms. To our knowledge, this is the first theoretical contribution in this area to provide an offline approach as well as worst-case guarantees.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17075",
        "abstract url": "https://arxiv.org/abs/2410.17075",
        "title": "Combinatorial Logistic Bandits",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a novel framework called combinatorial logistic bandits (CLogB), where in each round, a subset of base arms (called the super arm) is selected, with the outcome of each base arm being binary and its expectation following a logistic parametric model. The feedback is governed by a general arm triggering process. Our study covers CLogB with reward functions satisfying two smoothness conditions, capturing application scenarios such as online content delivery, online learning to rank, and dynamic channel allocation. We first propose a simple yet efficient algorithm, CLogUCB, utilizing a variance-agnostic exploration bonus. Under the 1-norm triggering probability modulated (TPM) smoothness condition, CLogUCB achieves a regret bound of $\\tilde{O}(d\\sqrt{\u03baKT})$, where $\\tilde{O}$ ignores logarithmic factors, $d$ is the dimension of the feature vector, $\u03ba$ represents the nonlinearity of the logistic model, and $K$ is the maximum number of base arms a super arm can trigger. This result improves on prior work by a factor of $\\tilde{O}(\\sqrt\u03ba)$. We then enhance CLogUCB with a variance-adaptive version, VA-CLogUCB, which attains a regret bound of $\\tilde{O}(d\\sqrt{KT})$ under the same 1-norm TPM condition, improving another $\\tilde{O}(\\sqrt\u03ba)$ factor. VA-CLogUCB shows even greater promise under the stronger triggering probability and variance modulated (TPVM) condition, achieving a leading $\\tilde{O}(d\\sqrt{T})$ regret, thus removing the additional dependency on the action-size $K$. Furthermore, we enhance the computational efficiency of VA-CLogUCB by eliminating the nonconvex optimization process when the context feature map is time-invariant while maintaining the tight $\\tilde{O}(d\\sqrt{T})$ regret. Finally, experiments on synthetic and real-world datasets demonstrate the superior performance of our algorithms compared to benchmark algorithms.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to ACM SIGMETRICS 2025"
    },
    {
        "paper id": "2410.17128",
        "abstract url": "https://arxiv.org/abs/2410.17128",
        "title": "Understanding Transfer Learning via Mean-field Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel framework for exploring generalization errors of transfer learning through the lens of differential calculus on the space of probability measures. In particular, we consider two main transfer learning scenarios, $\u03b1$-ERM and fine-tuning with the KL-regularized empirical risk minimization and establish generic conditions under which the generalization error and the population risk convergence rates for these scenarios are studied. Based on our theoretical results, we show the benefits of transfer learning with a one-hidden-layer neural network in the mean-field regime under some suitable integrability and regularity assumptions on the loss and activation functions.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.FA"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2410.17135",
        "abstract url": "https://arxiv.org/abs/2410.17135",
        "title": "Reinforcement Learning for Data-Driven Workflows in Radio Interferometry. I. Principal Demonstration in Calibration",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Radio interferometry is an observational technique used to study astrophysical phenomena. Data gathered by an interferometer requires substantial processing before astronomers can extract the scientific information from it. Data processing consists of a sequence of calibration and analysis procedures where choices must be made about the sequence of procedures as well as the specific configuration of the procedure itself. These choices are typically based on a combination of measurable data characteristics, an understanding of the instrument itself, an appreciation of the trade-offs between compute cost and accuracy, and a learned understanding of what is considered \"best practice\". A metric of absolute correctness is not always available and validity is often subject to human judgment. The underlying principles and software configurations to discern a reasonable workflow for a given dataset is the subject of training workshops for students and scientists. Our goal is to use objective metrics that quantify best practice, and numerically map out the decision space with respect to our metrics. With these objective metrics we demonstrate an automated, data-driven, decision system that is capable of sequencing the optimal action(s) for processing interferometric data. This paper introduces a simplified description of the principles behind interferometry and the procedures required for data processing. We highlight the issues with current automation approaches and propose our ideas for solving these bottlenecks. A prototype is demonstrated and the results are discussed.",
        "subjects": [
            "astro-ph.IM",
            "cs.LG"
        ],
        "comment": "22 pages, 13 figures; accepted for publication in The Astronomical Journal October 18, 2024"
    },
    {
        "paper id": "2410.17139",
        "abstract url": "https://arxiv.org/abs/2410.17139",
        "title": "Trustworthy XAI and Application",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "One of today's most significant and transformative technologies is the rapidly developing field of artificial intelligence (AI). Deined as a computer system that simulates human cognitive processes, AI is present in many aspects of our daily lives, from the self-driving cars on the road to the intelligence (AI) because some AI systems are so complex and opaque. With millions of parameters and layers, these system-deep neural networks in particular-make it difficult for humans to comprehend accountability, prejudice, and justice are raised by the opaqueness of its decision-making process. AI has a lot of potential, but it also comes with a lot of difficulties and moral dilemmas. In the context of explainable artificial intelligence (XAI), trust is crucial as it ensures that AI systems behave consistently, fairly, and ethically. In the present article, we explore XAI, reliable XAI, and several practical uses for reliable XAI. Once more, we go over the three main components-transparency, explainability, and trustworthiness of XAI-that we determined are pertinent in this situation. We present an overview of recent scientific studies that employ trustworthy XAI in various application fields. In the end, trustworthiness is crucial for establishing and maintaining trust between humans and AI systems, facilitating the integration of AI systems into various applications and domains for the benefit of society.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "28 pages, 14 figures"
    },
    {
        "paper id": "2410.17141",
        "abstract url": "https://arxiv.org/abs/2410.17141",
        "title": "Towards Automated Penetration Testing: Introducing LLM Benchmark, Analysis, and Improvements",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Hacking poses a significant threat to cybersecurity, inflicting billions of dollars in damages annually. To mitigate these risks, ethical hacking, or penetration testing, is employed to identify vulnerabilities in systems and networks. Recent advancements in large language models (LLMs) have shown potential across various domains, including cybersecurity. However, there is currently no comprehensive, open, end-to-end automated penetration testing benchmark to drive progress and evaluate the capabilities of these models in security contexts. This paper introduces a novel open benchmark for LLM-based automated penetration testing, addressing this critical gap. We first evaluate the performance of LLMs, including GPT-4o and Llama 3.1-405B, using the state-of-the-art PentestGPT tool. Our findings reveal that while Llama 3.1 demonstrates an edge over GPT-4o, both models currently fall short of performing fully automated, end-to-end penetration testing. Next, we advance the state-of-the-art and present ablation studies that provide insights into improving the PentestGPT tool. Our research illuminates the challenges LLMs face in each aspect of Pentesting, e.g. enumeration, exploitation, and privilege escalation. This work contributes to the growing body of knowledge on AI-assisted cybersecurity and lays the foundation for future research in automated penetration testing using large language models.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "Main Paper 1-9 pages, Supplementary Materials: 10-17, 13 figures"
    },
    {
        "paper id": "2410.17147",
        "abstract url": "https://arxiv.org/abs/2410.17147",
        "title": "Covariance estimation using Markov chain Monte Carlo",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate the complexity of covariance matrix estimation for Gibbs distributions based on dependent samples from a Markov chain. We show that when $\u03c0$ satisfies a Poincar\u00e9 inequality and the chain possesses a spectral gap, we can achieve similar sample complexity using MCMC as compared to an estimator constructed using i.i.d. samples, with potentially much better query complexity. As an application of our methods, we show improvements for the query complexity in both constrained and unconstrained settings for concrete instances of MCMC. In particular, we provide guarantees regarding isotropic rounding procedures for sampling uniformly on convex bodies.",
        "subjects": [
            "math.ST",
            "cs.DS",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "30 pages"
    },
    {
        "paper id": "2410.17155",
        "abstract url": "https://arxiv.org/abs/2410.17155",
        "title": "AI Future Envisioning with PLACARD",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "At EuroPLoP 2024 Mary Tedeschi led the \"AI Future Envisioning with PLACARD\" focus group in Germany. Three conference attendees joined in the room while Sridevi, Paola, and Charles co-facilitated remotely via a web conference. The participants were introduced to a Futures Studies technique with the goal of capturing envisionments of Artificial Intelligence (AI) going forward. To set an atmosphere a technology focused card game was used to make the session more interactive. To close everyone co-created a Project Action Review to recap of the event to capture learnings that has been summarized in this paper. The Focus Group was structured based on lessons learned over six earlier iterations.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "7 pages; To appear in 29th European Conference on Pattern Languages of Programs, People, and Practices"
    },
    {
        "paper id": "2410.17160",
        "abstract url": "https://arxiv.org/abs/2410.17160",
        "title": "Layered LA-MAPF: a decomposition of large agent MAPF instance to accelerate solving without compromising solvability",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multi-Agent Path Finding (MAPF) has been widely studied in recent years. However, most existing MAPF algorithms assume that an agent occupies only a single grid in a grid-based map. This assumption limits their applicability in many real-world domains where agents have geometric shapes, rather than being point-like. Such agents, which can occupy multiple cells simultaneously, are referred to as ``large'' agents. When considering the shape and size of agents in MAPF, the computational complexity increases significantly as the number of agents grows, primarily due to the increased overhead in conflict detection between geometric agents. In this paper, we propose two types of subproblems for the LA-MAPF (Large-Agent MAPF) problem: \\textbf{cluster} (which has no constraints on the order of solution) and \\textbf{level} (which imposes constraints on the solution order). We introduce \\textbf{Layered LA-MAPF}, a method that decomposes a MAPF instance involving geometric agents into clusters, and then further decomposes each cluster into levels. This approach aims to reduce time complexity when solving LA-MAPF problems. Our results demonstrate the performance of our method as the number of agents increases across various maps, and how it accelerates LA-MAPF methods, such as LA-CBS and LA-LaCAM. Experiments show that our LA-MAPF method with instance decomposition \\textbf{halves the time cost (reducing from an average of 40s to 20s) and triples the success rate (from an average of 0.27 to 0.80)} in finding a solution within 60 seconds. To facilitate further research, we have made the source code for Layered LA-MAPF publicly available at \\url{https://github.com/JoeYao-bit/LayeredMAPF/algorithm/LA-MAPF}.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17186",
        "abstract url": "https://arxiv.org/abs/2410.17186",
        "title": "DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative Path Planning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Informative path planning (IPP) is an important planning paradigm for various real-world robotic applications such as environment monitoring. IPP involves planning a path that can learn an accurate belief of the quantity of interest, while adhering to planning constraints. Traditional IPP methods typically require high computation time during execution, giving rise to reinforcement learning (RL) based IPP methods. However, the existing RL-based methods do not consider spatio-temporal environments which involve their own challenges due to variations in environment characteristics. In this paper, we propose DyPNIPP, a robust RL-based IPP framework, designed to operate effectively across spatio-temporal environments with varying dynamics. To achieve this, DyPNIPP incorporates domain randomization to train the agent across diverse environments and introduces a dynamics prediction model to capture and adapt the agent actions to specific environment dynamics. Our extensive experiments in a wildfire environment demonstrate that DyPNIPP outperforms existing RL-based IPP algorithms by significantly improving robustness and performing across diverse environment conditions.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "8 pages, 4 figures, submitted to IEEE RA-L"
    },
    {
        "paper id": "2410.17191",
        "abstract url": "https://arxiv.org/abs/2410.17191",
        "title": "On Functional Dimension and Persistent Pseudodimension",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "For any fixed feedforward ReLU neural network architecture, it is well-known that many different parameter settings can determine the same function. It is less well-known that the degree of this redundancy is inhomogeneous across parameter space. In this work, we discuss two locally applicable complexity measures for ReLU network classes and what we know about the relationship between them: (1) the local functional dimension [14, 18], and (2) a local version of VC dimension that we call persistent pseudodimension. The former is easy to compute on finite batches of points; the latter should give local bounds on the generalization gap, which would inform an understanding of the mechanics of the double descent phenomenon [7].",
        "subjects": [
            "cs.LG",
            "math.AG",
            "math.CO"
        ],
        "comment": "41 pages"
    },
    {
        "paper id": "2410.17221",
        "abstract url": "https://arxiv.org/abs/2410.17221",
        "title": "Scalable spectral representations for network multiagent control",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Network Markov Decision Processes (MDPs), a popular model for multi-agent control, pose a significant challenge to efficient learning due to the exponential growth of the global state-action space with the number of agents. In this work, utilizing the exponential decay property of network dynamics, we first derive scalable spectral local representations for network MDPs, which induces a network linear subspace for the local $Q$-function of each agent. Building on these local spectral representations, we design a scalable algorithmic framework for continuous state-action network MDPs, and provide end-to-end guarantees for the convergence of our algorithm. Empirically, we validate the effectiveness of our scalable representation-based approach on two benchmark problems, and demonstrate the advantages of our approach over generic function approximation approaches to representing the local $Q$-functions.",
        "subjects": [
            "cs.MA",
            "cs.LG",
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17229",
        "abstract url": "https://arxiv.org/abs/2410.17229",
        "title": "Responsibility in a Multi-Value Strategic Setting",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Responsibility is a key notion in multi-agent systems and in creating safe, reliable and ethical AI. However, most previous work on responsibility has only considered responsibility for single outcomes. In this paper we present a model for responsibility attribution in a multi-agent, multi-value setting. We also expand our model to cover responsibility anticipation, demonstrating how considerations of responsibility can help an agent to select strategies that are in line with its values. In particular we show that non-dominated regret-minimising strategies reliably minimise an agent's expected degree of responsibility.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17230",
        "abstract url": "https://arxiv.org/abs/2410.17230",
        "title": "Optimal Robust Estimation under Local and Global Corruptions: Stronger Adversary and Smaller Error",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Algorithmic robust statistics has traditionally focused on the contamination model where a small fraction of the samples are arbitrarily corrupted. We consider a recent contamination model that combines two kinds of corruptions: (i) small fraction of arbitrary outliers, as in classical robust statistics, and (ii) local perturbations, where samples may undergo bounded shifts on average. While each noise model is well understood individually, the combined contamination model poses new algorithmic challenges, with only partial results known. Existing efficient algorithms are limited in two ways: (i) they work only for a weak notion of local perturbations, and (ii) they obtain suboptimal error for isotropic subgaussian distributions (among others). The latter limitation led [NGS24, COLT'24] to hypothesize that improving the error might, in fact, be computationally hard. Perhaps surprisingly, we show that information theoretically optimal error can indeed be achieved in polynomial time, under an even \\emph{stronger} local perturbation model (the sliced-Wasserstein metric as opposed to the Wasserstein metric). Notably, our analysis reveals that the entire family of stability-based robust mean estimators continues to work optimally in a black-box manner for the combined contamination model. This generalization is particularly useful in real-world scenarios where the specific form of data corruption is not known in advance. We also present efficient algorithms for distribution learning and principal component analysis in the combined contamination model.",
        "subjects": [
            "cs.DS",
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17233",
        "abstract url": "https://arxiv.org/abs/2410.17233",
        "title": "Few-shot In-Context Preference Learning Using Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Designing reward functions is a core component of reinforcement learning but can be challenging for truly complex behavior. Reinforcement Learning from Human Feedback (RLHF) has been used to alleviate this challenge by replacing a hand-coded reward function with a reward function learned from preferences. However, it can be exceedingly inefficient to learn these rewards as they are often learned tabula rasa. We investigate whether Large Language Models (LLMs) can reduce this query inefficiency by converting an iterative series of human preferences into code representing the rewards. We propose In-Context Preference Learning (ICPL), a method that uses the grounding of an LLM to accelerate learning reward functions from preferences. ICPL takes the environment context and task description, synthesizes a set of reward functions, and then repeatedly updates the reward functions using human rankings of videos of the resultant policies. Using synthetic preferences, we demonstrate that ICPL is orders of magnitude more efficient than RLHF and is even competitive with methods that use ground-truth reward functions instead of preferences. Finally, we perform a series of human preference-learning trials and observe that ICPL extends beyond synthetic settings and can work effectively with humans-in-the-loop. Additional information and videos are provided at https://sites.google.com/view/few-shot-icpl/home.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17251",
        "abstract url": "https://arxiv.org/abs/2410.17251",
        "title": "Altogether: Image Captioning via Re-aligning Alt-text",
        "rating": "0.5",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.CV",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "This paper focuses on creating synthetic data to improve the quality of image captions. Existing works typically have two shortcomings. First, they caption images from scratch, ignoring existing alt-text metadata, and second, lack transparency if the captioners' training data (e.g. GPT) is unknown. In this paper, we study a principled approach Altogether based on the key idea to edit and re-align existing alt-texts associated with the images. To generate training data, we perform human annotation where annotators start with the existing alt-text and re-align it to the image content in multiple rounds, consequently constructing captions with rich visual concepts. This differs from prior work that carries out human annotation as a one-time description task solely based on images and annotator knowledge. We train a captioner on this data that generalizes the process of re-aligning alt-texts at scale. Our results show our Altogether approach leads to richer image captions that also improve text-to-image generation and zero-shot image classification tasks.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "accepted by EMNLP 2024; MetaCLIPv2"
    },
    {
        "paper id": "2410.17336",
        "abstract url": "https://arxiv.org/abs/2410.17336",
        "title": "Computing Optimal Regularizers for Online Linear Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Follow-the-Regularized-Leader (FTRL) algorithms are a popular class of learning algorithms for online linear optimization (OLO) that guarantee sub-linear regret, but the choice of regularizer can significantly impact dimension-dependent factors in the regret bound. We present an algorithm that takes as input convex and symmetric action sets and loss sets for a specific OLO instance, and outputs a regularizer such that running FTRL with this regularizer guarantees regret within a universal constant factor of the best possible regret bound. In particular, for any choice of (convex, symmetric) action set and loss set we prove that there exists an instantiation of FTRL which achieves regret within a constant factor of the best possible learning algorithm, strengthening the universality result of Srebro et al., 2011. Our algorithm requires preprocessing time and space exponential in the dimension $d$ of the OLO instance, but can be run efficiently online assuming a membership and linear optimization oracle for the action and loss sets, respectively (and is fully polynomial time for the case of constant dimension $d$). We complement this with a lower bound showing that even deciding whether a given regularizer is $\u03b1$-strongly-convex with respect to a given norm is NP-hard.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "cs.GT",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17351",
        "abstract url": "https://arxiv.org/abs/2410.17351",
        "title": "Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in multi-agent reinforcement learning (MARL) have created opportunities to solve complex real-world tasks. Cybersecurity is a notable application area, where defending networks against sophisticated adversaries remains a challenging task typically performed by teams of security operators. In this work, we explore novel MARL strategies for building autonomous cyber network defenses that address challenges such as large policy spaces, partial observability, and stealthy, deceptive adversarial strategies. To facilitate efficient and generalized learning, we propose a hierarchical Proximal Policy Optimization (PPO) architecture that decomposes the cyber defense task into specific sub-tasks like network investigation and host recovery. Our approach involves training sub-policies for each sub-task using PPO enhanced with domain expertise. These sub-policies are then leveraged by a master defense policy that coordinates their selection to solve complex network defense tasks. Furthermore, the sub-policies can be fine-tuned and transferred with minimal cost to defend against shifts in adversarial behavior or changes in network settings. We conduct extensive experiments using CybORG Cage 4, the state-of-the-art MARL environment for cyber defense. Comparisons with multiple baselines across different adversaries show that our hierarchical learning approach achieves top performance in terms of convergence speed, episodic return, and several interpretable metrics relevant to cybersecurity, including the fraction of clean machines on the network, precision, and false positives on recoveries.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.MA"
        ],
        "comment": "9 pages, 7 figures, AAMAS preprint"
    },
    {
        "paper id": "2410.17361",
        "abstract url": "https://arxiv.org/abs/2410.17361",
        "title": "Characterizing Robocalls with Multiple Vantage Points",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Telephone spam has been among the highest network security concerns for users for many years. In response, industry and government have deployed new technologies and regulations to curb the problem, and academic and industry researchers have provided methods and measurements to characterize robocalls. Have these efforts borne fruit? Are the research characterizations reliable, and have the prevention and deterrence mechanisms succeeded? In this paper, we address these questions through analysis of data from several independently-operated vantage points, ranging from industry and academic voice honeypots to public enforcement and consumer complaints, some with over 5 years of historic data. We first describe how we address the non-trivial methodological challenges of comparing disparate data sources, including comparing audio and transcripts from about 3 million voice calls. We also detail the substantial coherency of these diverse perspectives, which dramatically strengthens the evidence for the conclusions we draw about robocall characterization and mitigation while highlighting advantages of each approach. Among our many findings, we find that unsolicited calls are in slow decline, though complaints and call volumes remain high. We also find that robocallers have managed to adapt to STIR/SHAKEN, a mandatory call authentication scheme. In total, our findings highlight the most promising directions for future efforts to characterize and stop telephone spam.",
        "subjects": [
            "cs.CR",
            "cs.LG",
            "cs.NI"
        ],
        "comment": "Accepted for publication at the 46th IEEE Symposium on Security and Privacy, 2025"
    },
    {
        "paper id": "2410.17382",
        "abstract url": "https://arxiv.org/abs/2410.17382",
        "title": "Cooperative Multi-Agent Constrained Stochastic Linear Bandits",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we explore a collaborative multi-agent stochastic linear bandit setting involving a network of $N$ agents that communicate locally to minimize their collective regret while keeping their expected cost under a specified threshold $\u03c4$. Each agent encounters a distinct linear bandit problem characterized by its own reward and cost parameters, i.e., local parameters. The goal of the agents is to determine the best overall action corresponding to the average of these parameters, or so-called global parameters. In each round, an agent is randomly chosen to select an action based on its current knowledge of the system. This chosen action is then executed by all agents, then they observe their individual rewards and costs. We propose a safe distributed upper confidence bound algorithm, so called \\textit{MA-OPLB}, and establish a high probability bound on its $T$-round regret. MA-OPLB utilizes an accelerated consensus method, where agents can compute an estimate of the average rewards and costs across the network by communicating the proper information with their neighbors. We show that our regret bound is of order $ \\mathcal{O}\\left(\\frac{d}{\u03c4-c_0}\\frac{\\log(NT)^2}{\\sqrt{N}}\\sqrt{\\frac{T}{\\log(1/|\u03bb_2|)}}\\right)$, where $\u03bb_2$ is the second largest (in absolute value) eigenvalue of the communication matrix, and $\u03c4-c_0$ is the known cost gap of a feasible action. We also experimentally show the performance of our proposed algorithm in different network structures.",
        "subjects": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17388",
        "abstract url": "https://arxiv.org/abs/2410.17388",
        "title": "ICT Sector Greenhouse Gas Emissions -- Issues and Trends",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "As Information and Communication Technology (ICT) use has become more prevalent, there has been a growing concern in how its associated greenhouse gas emissions will impact the climate. Estimating such ICT emissions is a difficult undertaking due to its complexity, its rapidly changing nature, and the lack of accurate and up-to-date data on individual stakeholder emissions. In this paper we provide a framework for estimating ICT's carbon footprint and identify some of the issues that impede the task. We attempt to gain greater insight into the factors affecting the ICT sector by drawing on a number of interviews with industry experts. We conclude that more accurate emissions estimates will only be possible with a more more detailed, industry informed, understanding of the whole ICT landscape and much more transparent reporting of energy usage and emissions data by ICT stakeholders.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17389",
        "abstract url": "https://arxiv.org/abs/2410.17389",
        "title": "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The correct specification of reward models is a well-known challenge in reinforcement learning. Hand-crafted reward functions often lead to inefficient or suboptimal policies and may not be aligned with user values. Reinforcement learning from human feedback is a successful technique that can mitigate such issues, however, the collection of human feedback can be laborious. Recent works have solicited feedback from pre-trained large language models rather than humans to reduce or eliminate human effort, however, these approaches yield poor performance in the presence of hallucination and other errors. This paper studies the advantages and limitations of reinforcement learning from large language model feedback and proposes a simple yet effective method for soliciting and applying feedback as a potential-based shaping function. We theoretically show that inconsistent rankings, which approximate ranking errors, lead to uninformative rewards with our approach. Our method empirically improves convergence speed and policy returns over commonly used baselines even with significant ranking errors, and eliminates the need for complex post-processing of reward functions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "13 pages, 8 figures, The 2024 Conference on Empirical Methods in Natural Language Processing"
    },
    {
        "paper id": "2410.17394",
        "abstract url": "https://arxiv.org/abs/2410.17394",
        "title": "packetLSTM: Dynamic LSTM Framework for Streaming Data with Varying Feature Space",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We study the online learning problem characterized by the varying input feature space of streaming data. Although LSTMs have been employed to effectively capture the temporal nature of streaming data, they cannot handle the dimension-varying streams in an online learning setting. Therefore, we propose a dynamic LSTM-based novel method, called packetLSTM, to model the dimension-varying streams. The packetLSTM's dynamic framework consists of an evolving packet of LSTMs, each dedicated to processing one input feature. Each LSTM retains the local information of its corresponding feature, while a shared common memory consolidates global information. This configuration facilitates continuous learning and mitigates the issue of forgetting, even when certain features are absent for extended time periods. The idea of utilizing one LSTM per feature coupled with a dimension-invariant operator for information aggregation enhances the dynamic nature of packetLSTM. This dynamic nature is evidenced by the model's ability to activate, deactivate, and add new LSTMs as required, thus seamlessly accommodating varying input dimensions. The packetLSTM achieves state-of-the-art results on five datasets, and its underlying principle is extended to other RNN types, like GRU and vanilla RNN.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17415",
        "abstract url": "https://arxiv.org/abs/2410.17415",
        "title": "End-to-End Optimization and Learning of Fair Court Schedules",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Criminal courts across the United States handle millions of cases every year, and the scheduling of those cases must accommodate a diverse set of constraints, including the preferences and availability of courts, prosecutors, and defense teams. When criminal court schedules are formed, defendants' scheduling preferences often take the least priority, although defendants may face significant consequences (including arrest or detention) for missed court dates. Additionally, studies indicate that defendants' nonappearances impose costs on the courts and other system stakeholders. To address these issues, courts and commentators have begun to recognize that pretrial outcomes for defendants and for the system would be improved with greater attention to court processes, including \\emph{court scheduling practices}. There is thus a need for fair criminal court pretrial scheduling systems that account for defendants' preferences and availability, but the collection of such data poses logistical challenges. Furthermore, optimizing schedules fairly across various parties' preferences is a complex optimization problem, even when such data is available. In an effort to construct such a fair scheduling system under data uncertainty, this paper proposes a joint optimization and learning framework that combines machine learning models trained end-to-end with efficient matching algorithms. This framework aims to produce court scheduling schedules that optimize a principled measure of fairness, balancing the availability and preferences of all parties.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17421",
        "abstract url": "https://arxiv.org/abs/2410.17421",
        "title": "From an attention economy to an ecology of attending. A manifesto",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "As the signatories of this manifesto, we denounce the attention economy as inhumane and a threat to our sociopolitical and ecological well-being. We endorse policymakers' efforts to address the negative consequences of the attention economy's technology, but add that these approaches are often limited in their criticism of the systemic context of human attention. Starting from Buddhist philosophy, we advocate a broader approach: an ecology of attending, that centers on conceptualizing, designing, and using attention (1) in an embedded way and (2) focused on the alleviating of suffering. With 'embedded' we mean that attention is not a neutral, isolated mechanism but a meaning-engendering part of an 'ecology' of bodily, sociotechnical and moral frameworks. With 'focused on the alleviation of suffering' we explicitly move away from the (often implicit) conception of attention as a tool for gratifying desires.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "21 pages, 1 figure"
    },
    {
        "paper id": "2410.17428",
        "abstract url": "https://arxiv.org/abs/2410.17428",
        "title": "Uncovering RL Integration in SSL Loss: Objective-Specific Implications for Data-Efficient RL",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this study, we investigate the effect of SSL objective modifications within the SPR framework, focusing on specific adjustments such as terminal state masking and prioritized replay weighting, which were not explicitly addressed in the original design. While these modifications are specific to RL, they are not universally applicable across all RL algorithms. Therefore, we aim to assess their impact on performance and explore other SSL objectives that do not accommodate these adjustments like Barlow Twins and VICReg. We evaluate six SPR variants on the Atari 100k benchmark, including versions both with and without these modifications. Additionally, we test the performance of these objectives on the DeepMind Control Suite, where such modifications are absent. Our findings reveal that incorporating specific SSL modifications within SPR significantly enhances performance, and this influence extends to subsequent frameworks like SR-SPR and BBF, highlighting the critical importance of SSL objective selection and related adaptations in achieving data efficiency in self-predictive reinforcement learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under Review AISTATS 2025,accepted to Neurips 2024 SSL Workshop"
    },
    {
        "paper id": "2410.17438",
        "abstract url": "https://arxiv.org/abs/2410.17438",
        "title": "Interpreting Affine Recurrence Learning in GPT-style Transformers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Understanding the internal mechanisms of GPT-style transformers, particularly their capacity to perform in-context learning (ICL), is critical for advancing AI alignment and interpretability. In-context learning allows transformers to generalize during inference without modifying their weights, yet the precise operations driving this capability remain largely opaque. This paper presents an investigation into the mechanistic interpretability of these transformers, focusing specifically on their ability to learn and predict affine recurrences as an ICL task. To address this, we trained a custom three-layer transformer to predict affine recurrences and analyzed the model's internal operations using both empirical and theoretical approaches. Our findings reveal that the model forms an initial estimate of the target sequence using a copying mechanism in the zeroth layer, which is subsequently refined through negative similarity heads in the second layer. These insights contribute to a deeper understanding of transformer behaviors in recursive tasks and offer potential avenues for improving AI alignment through mechanistic interpretability. Finally, we discuss the implications of our results for future work, including extensions to higher-dimensional recurrences and the exploration of polynomial sequences.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "21 pages, 18 figures"
    },
    {
        "paper id": "2410.17466",
        "abstract url": "https://arxiv.org/abs/2410.17466",
        "title": "Evolution with Opponent-Learning Awareness",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The universe involves many independent co-learning agents as an ever-evolving part of our observed environment. Yet, in practice, Multi-Agent Reinforcement Learning (MARL) applications are usually constrained to small, homogeneous populations and remain computationally intensive. In this paper, we study how large heterogeneous populations of learning agents evolve in normal-form games. We show how, under assumptions commonly made in the multi-armed bandit literature, Multi-Agent Policy Gradient closely resembles the Replicator Dynamic, and we further derive a fast, parallelizable implementation of Opponent-Learning Awareness tailored for evolutionary simulations. This enables us to simulate the evolution of very large populations made of heterogeneous co-learning agents, under both naive and advanced learning strategies. We demonstrate our approach in simulations of 200,000 agents, evolving in the classic games of Hawk-Dove, Stag-Hunt, and Rock-Paper-Scissors. Each game highlights distinct ways in which Opponent-Learning Awareness affects evolution.",
        "subjects": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "q-bio.PE",
            "q-fin.GN"
        ],
        "comment": "12 pages, 10 figures"
    },
    {
        "paper id": "2410.17469",
        "abstract url": "https://arxiv.org/abs/2410.17469",
        "title": "AdaptoML-UX: An Adaptive User-centered GUI-based AutoML Toolkit for Non-AI Experts and HCI Researchers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The increasing integration of machine learning across various domains has underscored the necessity for accessible systems that non-experts can utilize effectively. To address this need, the field of automated machine learning (AutoML) has developed tools to simplify the construction and optimization of ML pipelines. However, existing AutoML solutions often lack efficiency in creating online pipelines and ease of use for Human-Computer Interaction (HCI) applications. Therefore, in this paper, we introduce AdaptoML-UX, an adaptive framework that incorporates automated feature engineering, machine learning, and incremental learning to assist non-AI experts in developing robust, user-centered ML models. Our toolkit demonstrates the capability to adapt efficiently to diverse problem domains and datasets, particularly in HCI, thereby reducing the necessity for manual experimentation and conserving time and resources. Furthermore, it supports model personalization through incremental learning, customizing models to individual user behaviors. HCI researchers can employ AdaptoML-UX (\\url{https://github.com/MichaelSargious/AdaptoML_UX}) without requiring specialized expertise, as it automates the selection of algorithms, feature engineering, and hyperparameter tuning based on the unique characteristics of the data.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17481",
        "abstract url": "https://arxiv.org/abs/2410.17481",
        "title": "AI, Global Governance, and Digital Sovereignty",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This essay examines how Artificial Intelligence (AI) systems are becoming more integral to international affairs by affecting how global governors exert power and pursue digital sovereignty. We first introduce a taxonomy of multifaceted AI payoffs for governments and corporations related to instrumental, structural, and discursive power in the domains of violence, markets, and rights. We next leverage different institutional and practice perspectives on sovereignty to assess how digital sovereignty is variously implicated in AI-empowered global governance. States both seek sovereign control over AI infrastructures in the institutional approach, while establishing sovereign competence through AI infrastructures in the practice approach. Overall, we present the digital sovereignty stakes of AI as related to entanglements of public and private power. Rather than foreseeing technology companies as replacing states, we argue that AI systems will embed in global governance to create dueling dynamics of public/private cooperation and contestation. We conclude with sketching future directions for IR research on AI and global governance.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "21 pages, 2 tables"
    },
    {
        "paper id": "2410.17500",
        "abstract url": "https://arxiv.org/abs/2410.17500",
        "title": "Learning Fair and Preferable Allocations through Neural Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The fair allocation of indivisible resources is a fundamental problem. Existing research has developed various allocation mechanisms or algorithms to satisfy different fairness notions. For example, round robin (RR) was proposed to meet the fairness criterion known as envy-freeness up to one good (EF1). Expert algorithms without mathematical formulations are used in real-world resource allocation problems to find preferable outcomes for users. Therefore, we aim to design mechanisms that strictly satisfy good properties with replicating expert knowledge. However, this problem is challenging because such heuristic rules are often difficult to formalize mathematically, complicating their integration into theoretical frameworks. Additionally, formal algorithms struggle to find preferable outcomes, and directly replicating these implicit rules can result in unfair allocations because human decision-making can introduce biases. In this paper, we aim to learn implicit allocation mechanisms from examples while strictly satisfying fairness constraints, specifically focusing on learning EF1 allocation mechanisms through supervised learning on examples of reported valuations and corresponding allocation outcomes produced by implicit rules. To address this, we developed a neural RR (NRR), a novel neural network that parameterizes RR. NRR is built from a differentiable relaxation of RR and can be trained to learn the agent ordering used for RR. We conducted experiments to learn EF1 allocation mechanisms from examples, demonstrating that our method outperforms baselines in terms of the proximity of predicted allocations and other metrics.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17507",
        "abstract url": "https://arxiv.org/abs/2410.17507",
        "title": "Detecting fake review buyers using network structure: Direct evidence from Amazon",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Online reviews significantly impact consumers' decision-making process and firms' economic outcomes and are widely seen as crucial to the success of online markets. Firms, therefore, have a strong incentive to manipulate ratings using fake reviews. This presents a problem that academic researchers have tried to solve over two decades and on which platforms expend a large amount of resources. Nevertheless, the prevalence of fake reviews is arguably higher than ever. To combat this, we collect a dataset of reviews for thousands of Amazon products and develop a general and highly accurate method for detecting fake reviews. A unique difference between previous datasets and ours is that we directly observe which sellers buy fake reviews. Thus, while prior research has trained models using lab-generated reviews or proxies for fake reviews, we are able to train a model using actual fake reviews. We show that products that buy fake reviews are highly clustered in the product-reviewer network. Therefore, features constructed from this network are highly predictive of which products buy fake reviews. We show that our network-based approach is also successful at detecting fake reviews even without ground truth data, as unsupervised clustering methods can accurately identify fake review buyers by identifying clusters of products that are closely connected in the network. While text or metadata can be manipulated to evade detection, network-based features are more costly to manipulate because these features result directly from the inherent limitations of buying reviews from online review marketplaces, making our detection approach more robust to manipulation.",
        "subjects": [
            "cs.SI",
            "econ.GN",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17511",
        "abstract url": "https://arxiv.org/abs/2410.17511",
        "title": "Time and Frequency Synergy for Source-Free Time-Series Domain Adaptations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The issue of source-free time-series domain adaptations still gains scarce research attentions. On the other hand, existing approaches rely solely on time-domain features ignoring frequency components providing complementary information. This paper proposes Time Frequency Domain Adaptation (TFDA), a method to cope with the source-free time-series domain adaptation problems. TFDA is developed with a dual branch network structure fully utilizing both time and frequency features in delivering final predictions. It induces pseudo-labels based on a neighborhood concept where predictions of a sample group are aggregated to generate reliable pseudo labels. The concept of contrastive learning is carried out in both time and frequency domains with pseudo label information and a negative pair exclusion strategy to make valid neighborhood assumptions. In addition, the time-frequency consistency technique is proposed using the self-distillation strategy while the uncertainty reduction strategy is implemented to alleviate uncertainties due to the domain shift problem. Last but not least, the curriculum learning strategy is integrated to combat noisy pseudo labels. Our experiments demonstrate the advantage of our approach over prior arts with noticeable margins in benchmark problems.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17517",
        "abstract url": "https://arxiv.org/abs/2410.17517",
        "title": "Bridging Swarm Intelligence and Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Swarm intelligence (SI) explores how large groups of simple individuals (e.g., insects, fish, birds) collaborate to produce complex behaviors, exemplifying that the whole is greater than the sum of its parts. A fundamental task in SI is Collective Decision-Making (CDM), where a group selects the best option among several alternatives, such as choosing an optimal foraging site. In this work, we demonstrate a theoretical and empirical equivalence between CDM and single-agent reinforcement learning (RL) in multi-armed bandit problems, utilizing concepts from opinion dynamics, evolutionary game theory, and RL. This equivalence bridges the gap between SI and RL and leads us to introduce a novel abstract RL update rule called Maynard-Cross Learning. Additionally, it provides a new population-based perspective on common RL practices like learning rate adjustment and batching. Our findings enable cross-disciplinary fertilization between RL and SI, allowing techniques from one field to enhance the understanding and methodologies of the other.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17538",
        "abstract url": "https://arxiv.org/abs/2410.17538",
        "title": "Primal-Dual Spectral Representation for Off-policy Evaluation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Off-policy evaluation (OPE) is one of the most fundamental problems in reinforcement learning (RL) to estimate the expected long-term payoff of a given target policy with only experiences from another behavior policy that is potentially unknown. The distribution correction estimation (DICE) family of estimators have advanced the state of the art in OPE by breaking the curse of horizon. However, the major bottleneck of applying DICE estimators lies in the difficulty of solving the saddle-point optimization involved, especially with neural network implementations. In this paper, we tackle this challenge by establishing a linear representation of value function and stationary distribution correction ratio, i.e., primal and dual variables in the DICE framework, using the spectral decomposition of the transition operator. Such primal-dual representation not only bypasses the non-convex non-concave optimization in vanilla DICE, therefore enabling an computational efficient algorithm, but also paves the way for more efficient utilization of historical data. We highlight that our algorithm, SpectralDICE, is the first to leverage the linear representation of primal-dual variables that is both computation and sample efficient, the performance of which is supported by a rigorous theoretical sample complexity guarantee and a thorough empirical evaluation on various benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": "29 pages, 5 figures"
    },
    {
        "paper id": "2410.17551",
        "abstract url": "https://arxiv.org/abs/2410.17551",
        "title": "Multimodal Information Bottleneck for Deep Reinforcement Learning with Multiple Sensors",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning has achieved promising results on robotic control tasks but struggles to leverage information effectively from multiple sensory modalities that differ in many characteristics. Recent works construct auxiliary losses based on reconstruction or mutual information to extract joint representations from multiple sensory inputs to improve the sample efficiency and performance of reinforcement learning algorithms. However, the representations learned by these methods could capture information irrelevant to learning a policy and may degrade the performance. We argue that compressing information in the learned joint representations about raw multimodal observations is helpful, and propose a multimodal information bottleneck model to learn task-relevant joint representations from egocentric images and proprioception. Our model compresses and retains the predictive information in multimodal observations for learning a compressed joint representation, which fuses complementary information from visual and proprioceptive feedback and meanwhile filters out task-irrelevant information in raw multimodal observations. We propose to minimize the upper bound of our multimodal information bottleneck objective for computationally tractable optimization. Experimental evaluations on several challenging locomotion tasks with egocentric images and proprioception show that our method achieves better sample efficiency and zero-shot robustness to unseen white noise than leading baselines. We also empirically demonstrate that leveraging information from egocentric images and proprioception is more helpful for learning policies on locomotion tasks than solely using one single modality.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2410.17554",
        "abstract url": "https://arxiv.org/abs/2410.17554",
        "title": "LEADS: Lightweight Embedded Assisted Driving System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the rapid development of electric vehicles, formula races that face high school and university students have become more popular than ever as the threshold for design and manufacturing has been lowered. In many cases, we see teams inspired by or directly using toolkits and technologies inherited from standardized commercial vehicles. These architectures are usually overly complicated for amateur applications like the races. In order to improve the efficiency and simplify the development of instrumentation, control, and analysis systems, we propose LEADS (Lightweight Embedded Assisted Driving System), a dedicated solution for such scenarios.",
        "subjects": [
            "cs.SE",
            "cs.LG",
            "eess.SY"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2410.17558",
        "abstract url": "https://arxiv.org/abs/2410.17558",
        "title": "CLR-Bench: Evaluating Large Language Models in College-level Reasoning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated their remarkable performance across various language understanding tasks. While emerging benchmarks have been proposed to evaluate LLMs in various domains such as mathematics and computer science, they merely measure the accuracy in terms of the final prediction on multi-choice questions. However, it remains insufficient to verify the essential understanding of LLMs given a chosen choice. To fill this gap, we present CLR-Bench to comprehensively evaluate the LLMs in complex college-level reasoning. Specifically, (i) we prioritize 16 challenging college disciplines in computer science and artificial intelligence. The dataset contains 5 types of questions, while each question is associated with detailed explanations from experts. (ii) To quantify a fair evaluation of LLMs' reasoning ability, we formalize the criteria with two novel metrics. Q$\\rightarrow$A is utilized to measure the performance of direct answer prediction, and Q$\\rightarrow$AR effectively considers the joint ability to answer the question and provide rationale simultaneously. Extensive experiments are conducted with 40 LLMs over 1,018 discipline-specific questions. The results demonstrate the key insights that LLMs, even the best closed-source LLM, i.e., GPT-4 turbo, tend to `guess' the college-level answers. It shows a dramatic decrease in accuracy from 63.31% Q$\\rightarrow$A to 39.00% Q$\\rightarrow$AR, indicating an unsatisfactory reasoning ability.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "18 pages, 6 figures, dataset and evaluation framework will be opensourced"
    },
    {
        "paper id": "2410.18144",
        "abstract url": "https://arxiv.org/abs/2410.18144",
        "title": "Using Platt's scaling for calibration after undersampling -- limitations and how to address them",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "When modelling data where the response is dichotomous and highly imbalanced, response-based sampling where a subset of the majority class is retained (i.e., undersampling) is often used to create more balanced training datasets prior to modelling. However, the models fit to this undersampled data, which we refer to as base models, generate predictions that are severely biased. There are several calibration methods that can be used to combat this bias, one of which is Platt's scaling. Here, a logistic regression model is used to model the relationship between the base model's original predictions and the response. Despite its popularity for calibrating models after undersampling, Platt's scaling was not designed for this purpose. Our work presents what we believe is the first detailed study focused on the validity of using Platt's scaling to calibrate models after undersampling. We show analytically, as well as via a simulation study and a case study, that Platt's scaling should not be used for calibration after undersampling without critical thought. If Platt's scaling would have been able to successfully calibrate the base model had it been trained on the entire dataset (i.e., without undersampling), then Platt's scaling might be appropriate for calibration after undersampling. If this is not the case, we recommend a modified version of Platt's scaling that fits a logistic generalized additive model to the logit of the base model's predictions, as it is both theoretically motivated and performed well across the settings considered in our study.",
        "subjects": [
            "stat.ME",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.18148",
        "abstract url": "https://arxiv.org/abs/2410.18148",
        "title": "Deep Autoencoder with SVD-Like Convergence and Flat Minima",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Representation learning for high-dimensional, complex physical systems aims to identify a low-dimensional intrinsic latent space, which is crucial for reduced-order modeling and modal analysis. To overcome the well-known Kolmogorov barrier, deep autoencoders (AEs) have been introduced in recent years, but they often suffer from poor convergence behavior as the rank of the latent space increases. To address this issue, we propose the learnable weighted hybrid autoencoder, a hybrid approach that combines the strengths of singular value decomposition (SVD) with deep autoencoders through a learnable weighted framework. We find that the introduction of learnable weighting parameters is essential - without them, the resulting model would either collapse into a standard POD or fail to exhibit the desired convergence behavior. Additionally, we empirically find that our trained model has a sharpness thousands of times smaller compared to other models. Our experiments on classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky and forced isotropic turbulence datasets, demonstrate that our approach significantly improves generalization performance compared to several competing methods, paving the way for robust representation learning of high-dimensional, complex physical systems.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.comp-ph",
            "stat.ML"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2410.19012",
        "abstract url": "https://arxiv.org/abs/2410.19012",
        "title": "Privacy-Computation trade-offs in Private Repetition and Metaselection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A Private Repetition algorithm takes as input a differentially private algorithm with constant success probability and boosts it to one that succeeds with high probability. These algorithms are closely related to private metaselection algorithms that compete with the best of many private algorithms, and private hyperparameter tuning algorithms that compete with the best hyperparameter settings for a private learning algorithm. Existing algorithms for these tasks pay either a large overhead in privacy cost, or a large overhead in computational cost. In this work, we show strong lower bounds for problems of this kind, showing in particular that for any algorithm that preserves the privacy cost up to a constant factor, the failure probability can only fall polynomially in the computational overhead. This is in stark contrast with the non-private setting, where the failure probability falls exponentially in the computational overhead. By carefully combining existing algorithms for metaselection, we prove computation-privacy tradeoffs that nearly match our lower bounds.",
        "subjects": [
            "cs.CR",
            "cs.DS",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19849",
        "abstract url": "https://arxiv.org/abs/2410.19849",
        "title": "Deep Learning and Machine Learning -- Python Data Structures and Mathematics Fundamental: From Theory to Practice",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This book provides a comprehensive introduction to the foundational concepts of machine learning (ML) and deep learning (DL). It bridges the gap between theoretical mathematics and practical application, focusing on Python as the primary programming language for implementing key algorithms and data structures. The book covers a wide range of topics, including basic and advanced Python programming, fundamental mathematical operations, matrix operations, linear algebra, and optimization techniques crucial for training ML and DL models. Advanced subjects like neural networks, optimization algorithms, and frequency domain methods are also explored, along with real-world applications of large language models (LLMs) and artificial intelligence (AI) in big data management. Designed for both beginners and advanced learners, the book emphasizes the critical role of mathematical principles in developing scalable AI solutions. Practical examples and Python code are provided throughout, ensuring readers gain hands-on experience in applying theoretical knowledge to solve complex problems in ML, DL, and big data analytics.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "cs.PL"
        ],
        "comment": "298 pages"
    },
    {
        "paper id": "2410.19858",
        "abstract url": "https://arxiv.org/abs/2410.19858",
        "title": "Enhancing Deep Learning based RMT Data Inversion using Gaussian Random Field",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning (DL) methods have emerged as a powerful tool for the inversion of geophysical data. When applied to field data, these models often struggle without additional fine-tuning of the network. This is because they are built on the assumption that the statistical patterns in the training and test datasets are the same. To address this, we propose a DL-based inversion scheme for Radio Magnetotelluric data where the subsurface resistivity models are generated using Gaussian Random Fields (GRF). The network's generalization ability was tested with an out-of-distribution (OOD) dataset comprising a homogeneous background and various rectangular-shaped anomalous bodies. After end-to-end training with the GRF dataset, the pre-trained network successfully identified anomalies in the OOD dataset. Synthetic experiments confirmed that the GRF dataset enhances generalization compared to a homogeneous background OOD dataset. The network accurately recovered structures in a checkerboard resistivity model, and demonstrated robustness to noise, outperforming traditional gradient-based methods. Finally, the developed scheme is tested using exemplary field data from a waste site near Roorkee, India. The proposed scheme enhances generalization in a data-driven supervised learning framework, suggesting a promising direction for OOD generalization in DL methods.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "eess.SP",
            "physics.geo-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.00017",
        "abstract url": "https://arxiv.org/abs/2411.00017",
        "title": "Applying Data Driven Decision Making to rank Vocational and Educational Training Programs with TOPSIS",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper we present a multi-criteria classification of Vocational and Educational Programs in Extremadura (Spain) during the period 2009-2016. This ranking has been carried out through the integration into a complete database of the detailed information of individuals finishing such studies together with their labor data. The multicriteria method used is TOPSIS together with a new decision support method for assessing the influence of each criterion and its dependence on the weights assigned to them. This new method is based on a worst-best case scenario analysis and it is compared to a well known global sensitivity analysis technique based on the Pearson's correlation ratio.",
        "subjects": [
            "cs.AI",
            "math.NA"
        ],
        "comment": "18 pages, 7 figures"
    },
    {
        "paper id": "2411.03324",
        "abstract url": "https://arxiv.org/abs/2411.03324",
        "title": "A Surrogate Model for Quay Crane Scheduling Problem",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In ports, a variety of tasks are carried out, and scheduling these tasks is crucial due to its significant impact on productivity, making the generation of precise plans essential. This study proposes a method to solve the Quay Crane Scheduling Problem (QCSP), a representative task scheduling problem in ports known to be NP-Hard, more quickly and accurately. First, the study suggests a method to create more accurate work plans for Quay Cranes (QCs) by learning from actual port data to accurately predict the working speed of QCs. Next, a Surrogate Model is proposed by combining a Machine Learning (ML) model with a Genetic Algorithm (GA), which is widely used to solve complex optimization problems, enabling faster and more precise exploration of solutions. Unlike methods that use fixed-dimensional chromosome encoding, the proposed methodology can provide solutions for encodings of various dimensions. To validate the performance of the newly proposed methodology, comparative experiments were conducted, demonstrating faster search speeds and improved fitness scores. The method proposed in this study can be applied not only to QCSP but also to various NP-Hard problems, and it opens up possibilities for the further development of advanced search algorithms by combining heuristic algorithms with ML models.",
        "subjects": [
            "cs.NE",
            "cs.LG",
            "stat.AP",
            "stat.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.03327",
        "abstract url": "https://arxiv.org/abs/2411.03327",
        "title": "Maximal Extractable Value in Decentralized Finance: Taxonomy, Detection, and Mitigation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Decentralized Finance (DeFi) leverages blockchain-enabled smart contracts to deliver automated and trustless financial services without the need for intermediaries. However, the public visibility of financial transactions on the blockchain can be exploited, as participants can reorder, insert, or remove transactions to extract value, often at the expense of others. This extracted value is known as the Maximal Extractable Value (MEV). MEV causes financial losses and consensus instability, disrupting the security, efficiency, and decentralization goals of the DeFi ecosystem. Therefore, it is crucial to analyze, detect, and mitigate MEV to safeguard DeFi. Our comprehensive survey offers a holistic view of the MEV landscape in the DeFi ecosystem. We present an in-depth understanding of MEV through a novel taxonomy of MEV transactions supported by real transaction examples. We perform a critical comparative analysis of various MEV detection approaches, evaluating their effectiveness in identifying different transaction types. Furthermore, we assess different categories of MEV mitigation strategies and discuss their limitations. We identify the challenges of current mitigation and detection approaches and discuss potential solutions. This survey provides valuable insights for researchers, developers, stakeholders, and policymakers, helping to curb and democratize MEV for a more secure and efficient DeFi ecosystem.",
        "subjects": [
            "cs.CR",
            "cs.CE",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04128",
        "abstract url": "https://arxiv.org/abs/2411.04128",
        "title": "On the analysis of saturated pressure to detect fatigue",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper examines the saturation of pressure signals during various handwriting tasks, including drawings, cursive text, capital words text, and signature, under different levels of fatigue. Experimental results demonstrate a significant rise in the proportion of saturated samples following strenuous exercise in tasks performed without resting wrist. The analysis of saturation highlights significant differences when comparing the results to the baseline situation and strenuous fatigue.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "12 pages. arXiv admin note: substantial text overlap with arXiv:2203.14782"
    },
    {
        "paper id": "2410.16703",
        "abstract url": "https://arxiv.org/abs/2410.16703",
        "title": "PLDR-LLM: Large Language Model from Power Law Decoder Representations",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We present the Large Language Model from Power Law Decoder Representations (PLDR-LLM), a language model that leverages non-linear and linear transformations through Power Law Graph Attention mechanism to generate well-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of varying layer sizes with a small batch size of 32 and $\\sim$8B tokens from the RefinedWeb dataset, and show that they achieve competitive performance in zero-shot and few-shot settings compared to scaled dot-product LLMs of similar model size reported in the literature. We show that deductive outputs of PLDR-LLMs can be used to compare model characteristics or improve the performance by introducing the Directed Acyclic Graph (DAG) loss as a metric and regularizer. Our results indicate that the initial maximum learning rate and warm-up steps have a lasting impact on deductive outputs throughout the pretraining. We provide a detailed description of PLDR-LLM architecture, its implementation and the pretraining procedure.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "22 pages, 4 figures, 10 tables"
    },
    {
        "paper id": "2410.16708",
        "abstract url": "https://arxiv.org/abs/2410.16708",
        "title": "Atomic Fact Decomposition Helps Attributed Question Answering",
        "rating": "0",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Attributed Question Answering (AQA) aims to provide both a trustworthy answer and a reliable attribution report for a given question. Retrieval is a widely adopted approach, including two general paradigms: Retrieval-Then-Read (RTR) and post-hoc retrieval. Recently, Large Language Models (LLMs) have shown remarkable proficiency, prompting growing interest in AQA among researchers. However, RTR-based AQA often suffers from irrelevant knowledge and rapidly changing information, even when LLMs are adopted, while post-hoc retrieval-based AQA struggles with comprehending long-form answers with complex logic, and precisely identifying the content needing revision and preserving the original intent. To tackle these problems, this paper proposes an Atomic fact decomposition-based Retrieval and Editing (ARE) framework, which decomposes the generated long-form answers into molecular clauses and atomic facts by the instruction-tuned LLMs. Notably, the instruction-tuned LLMs are fine-tuned using a well-constructed dataset, generated from large scale Knowledge Graphs (KGs). This process involves extracting one-hop neighbors from a given set of entities and transforming the result into coherent long-form text. Subsequently, ARE leverages a search engine to retrieve evidences related to atomic facts, inputting these evidences into an LLM-based verifier to determine whether the facts require expansion for re-retrieval or editing. Furthermore, the edited facts are backtracked into the original answer, with evidence aggregated based on the relationship between molecular clauses and atomic facts. Extensive evaluations demonstrate the superior performance of our proposed method over the state-of-the-arts on several datasets, with an additionally proposed new metric $Attr_{p}$ for evaluating the precision of evidence attribution.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16710",
        "abstract url": "https://arxiv.org/abs/2410.16710",
        "title": "Influential Language Data Selection via Gradient Trajectory Pursuit",
        "rating": "0",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Curating a desirable dataset for training has been the core of building highly capable large language models (Touvron et al., 2023; Achiam et al., 2023; Team et al.,2024). Gradient influence scores (Pruthi et al., 2020; Xia et al., 2024) are shown to be correlated with model performance and are commonly used as the criterion for data selection. However, existing methods are built upon either individual sample rankings or inefficient matching process, leading to suboptimal performance or scaling up issues.In this paper, we propose Gradient Trajectory Pursuit (GTP), an algorithm that performs pursuit of gradient trajectories via jointly selecting data points under an L0-norm regularized objective. The proposed algorithm highlights: (1) joint selection instead of independent top-k selection, which automatically de-duplicates samples; (2) higher efficiency with compressive sampling processes, which can be further sped up using a distributed framework. In the experiments, we demonstrate the algorithm in both in-domain and target-domain selection benchmarks and show that it outperforms top-k selection and competitive algorithms consistently, for example, our algorithm chooses as low as 0.5% data to achieve full performance on the targeted instruction tuning tasks",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16719",
        "abstract url": "https://arxiv.org/abs/2410.16719",
        "title": "Progressive Compositionality In Text-to-Image Generative Models",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Text-to-Image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Despite the impressive text-to-image (T2I) synthesis capabilities of diffusion models, they often struggle to understand compositional relationships between objects and attributes, especially in complex settings. Existing solutions have tackled these challenges by optimizing the cross-attention mechanism or learning from the caption pairs with minimal semantic changes. However, can we generate high-quality complex contrastive images that diffusion models can directly discriminate based on visual representations? In this work, we leverage large-language models (LLMs) to compose realistic, complex scenarios and harness Visual-Question Answering (VQA) systems alongside diffusion models to automatically curate a contrastive dataset, ConPair, consisting of 15k pairs of high-quality contrastive images. These pairs feature minimal visual discrepancies and cover a wide range of attribute categories, especially complex and natural scenarios. To learn effectively from these error cases, i.e., hard negative images, we propose EvoGen, a new multi-stage curriculum for contrastive learning of diffusion models. Through extensive experiments across a wide range of compositional scenarios, we showcase the effectiveness of our proposed framework on compositional T2I benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16785",
        "abstract url": "https://arxiv.org/abs/2410.16785",
        "title": "Annotation-Free MIDI-to-Audio Synthesis via Concatenative Synthesis and Generative Refinement",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent MIDI-to-audio synthesis methods have employed deep neural networks to successfully generate high-quality and expressive instrumental tracks. However, these methods require MIDI annotations for supervised training, limiting the diversity of the output audio in terms of instrument timbres, and expression styles. We propose CoSaRef, a MIDI-to-audio synthesis method that can be developed without MIDI-audio paired datasets. CoSaRef first performs concatenative synthesis based on MIDI inputs and then refines the resulting audio into realistic tracks using a diffusion-based deep generative model trained on audio-only datasets. This approach enhances the diversity of audio timbres and expression styles. It also allows for control over the output timbre based on audio sample selection, similar to traditional functions in digital audio workstations. Experiments show that while inherently capable of generating general tracks with high control over timbre, CoSaRef can also perform comparably to conventional methods in generating realistic audio.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "Work in progress; 7 pages, 2 figures, 1 table"
    },
    {
        "paper id": "2410.16803",
        "abstract url": "https://arxiv.org/abs/2410.16803",
        "title": "Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Inductive knowledge graph completion (KGC) aims to predict missing triples with unseen entities. Recent works focus on modeling reasoning paths between the head and tail entity as direct supporting evidence. However, these methods depend heavily on the existence and quality of reasoning paths, which limits their general applicability in different scenarios. In addition, we observe that latent type constraints and neighboring facts inherent in KGs are also vital in inferring missing triples. To effectively utilize all useful information in KGs, we introduce CATS, a novel context-aware inductive KGC solution. With sufficient guidance from proper prompts and supervised fine-tuning, CATS activates the strong semantic understanding and reasoning capabilities of large language models to assess the existence of query triples, which consist of two modules. First, the type-aware reasoning module evaluates whether the candidate entity matches the latent entity type as required by the query relation. Then, the subgraph reasoning module selects relevant reasoning paths and neighboring facts, and evaluates their correlation to the query triple. Experiment results on three widely used datasets demonstrate that CATS significantly outperforms state-of-the-art methods in 16 out of 18 transductive, inductive, and few-shot settings with an average absolute MRR improvement of 7.2%.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16804",
        "abstract url": "https://arxiv.org/abs/2410.16804",
        "title": "Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots",
        "rating": "0",
        "keywords": [
            [
                "visual language",
                "VLMs"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "Lifestyle support through robotics is an increasingly promising field, with expectations for robots to take over or assist with chores like floor cleaning, table setting and clearing, and fetching items. The growth of AI, particularly foundation models, such as large language models (LLMs) and visual language models (VLMs), is significantly shaping this sector. LLMs, by facilitating natural interactions and providing vast general knowledge, are proving invaluable for robotic tasks. This paper zeroes in on the benefits of LLMs for \"bring-me\" tasks, where robots fetch specific items for users, often based on vague instructions. Our previous efforts utilized an ontology extended to handle environmental data to decipher such vagueness, but faced limitations when unresolvable ambiguities required user intervention for clarity. Here, we enhance our approach by integrating LLMs for providing additional commonsense knowledge, pairing it with ontological data to mitigate the issue of hallucinations and reduce the need for user queries, thus improving system usability. We present a system that merges these knowledge bases and assess its efficacy on \"bring-me\" tasks, aiming to provide a more seamless and efficient robotic assistance experience.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2024)"
    },
    {
        "paper id": "2410.16919",
        "abstract url": "https://arxiv.org/abs/2410.16919",
        "title": "EnvBridge: Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI",
        "rating": "0",
        "keywords": [
            [
                "robot",
                "robotic manipulation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, Large Language Models (LLMs) have demonstrated high reasoning capabilities, drawing attention for their applications as agents in various decision-making processes. One notably promising application of LLM agents is robotic manipulation. Recent research has shown that LLMs can generate text planning or control code for robots, providing substantial flexibility and interaction capabilities. However, these methods still face challenges in terms of flexibility and applicability across different environments, limiting their ability to adapt autonomously. Current approaches typically fall into two categories: those relying on environment-specific policy training, which restricts their transferability, and those generating code actions based on fixed prompts, which leads to diminished performance when confronted with new environments. These limitations significantly constrain the generalizability of agents in robotic manipulation. To address these limitations, we propose a novel method called EnvBridge. This approach involves the retention and transfer of successful robot control codes from source environments to target environments. EnvBridge enhances the agent's adaptability and performance across diverse settings by leveraging insights from multiple environments. Notably, our approach alleviates environmental constraints, offering a more flexible and generalizable solution for robotic manipulation tasks. We validated the effectiveness of our method using robotic manipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments demonstrate that LLM agents can successfully leverage diverse knowledge sources to solve complex tasks. Consequently, our approach significantly enhances the adaptability and robustness of robotic manipulation agents in planning across diverse environments.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16942",
        "abstract url": "https://arxiv.org/abs/2410.16942",
        "title": "DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have achieved remarkable progress in the field of image generation due to their outstanding capabilities. However, these models require substantial computing resources because of the multi-step denoising process during inference. While traditional pruning methods have been employed to optimize these models, the retraining process necessitates large-scale training datasets and extensive computational costs to maintain generalization ability, making it neither convenient nor efficient. Recent studies attempt to utilize the similarity of features across adjacent denoising stages to reduce computational costs through simple and static strategies. However, these strategies cannot fully harness the potential of the similar feature patterns across adjacent timesteps. In this work, we propose a novel pruning method that derives an efficient diffusion model via a more intelligent and differentiable pruner. At the core of our approach is casting the model pruning process into a SubNet search process. Specifically, we first introduce a SuperNet based on standard diffusion via adding some backup connections built upon the similar features. We then construct a plugin pruner network and design optimization losses to identify redundant computation. Finally, our method can identify an optimal SubNet through few-step gradient optimization and a simple post-processing procedure. We conduct extensive experiments on various diffusion models including Stable Diffusion series and DiTs. Our DiP-GO approach achieves 4.4 x speedup for SD-1.5 without any loss of accuracy, significantly outperforming the previous state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16945",
        "abstract url": "https://arxiv.org/abs/2410.16945",
        "title": "IdenBAT: Disentangled Representation Learning for Identity-Preserved Brain Age Transformation",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Brain age transformation aims to convert reference brain images into synthesized images that accurately reflect the age-specific features of a target age group. The primary objective of this task is to modify only the age-related attributes of the reference image while preserving all other age-irrelevant attributes. However, achieving this goal poses substantial challenges due to the inherent entanglement of various image attributes within features extracted from a backbone encoder, resulting in simultaneous alterations during the image generation. To address this challenge, we propose a novel architecture that employs disentangled representation learning for identity-preserved brain age transformation called IdenBAT. This approach facilitates the decomposition of image features, ensuring the preservation of individual traits while selectively transforming age-related characteristics to match those of the target age group. Through comprehensive experiments conducted on both 2D and full-size 3D brain datasets, our method adeptly converts input images to target age while retaining individual characteristics accurately. Furthermore, our approach demonstrates superiority over existing state-of-the-art regarding performance fidelity.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "q-bio.NC"
        ],
        "comment": "16 pages, 8 figures, 2 tables"
    },
    {
        "paper id": "2410.17001",
        "abstract url": "https://arxiv.org/abs/2410.17001",
        "title": "Joint Point Cloud Upsampling and Cleaning with Octree-based CNNs",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recovering dense and uniformly distributed point clouds from sparse or noisy data remains a significant challenge. Recently, great progress has been made on these tasks, but usually at the cost of increasingly intricate modules or complicated network architectures, leading to long inference time and huge resource consumption. Instead, we embrace simplicity and present a simple yet efficient method for jointly upsampling and cleaning point clouds. Our method leverages an off-the-shelf octree-based 3D U-Net (OUNet) with minor modifications, enabling the upsampling and cleaning tasks within a single network. Our network directly processes each input point cloud as a whole instead of processing each point cloud patch as in previous works, which significantly eases the implementation and brings at least 47 times faster inference. Extensive experiments demonstrate that our method achieves state-of-the-art performances under huge efficiency advantages on a series of benchmarks. We expect our method to serve simple baselines and inspire researchers to rethink the method design on point cloud upsampling and cleaning.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by Computational Visual Media"
    },
    {
        "paper id": "2410.17040",
        "abstract url": "https://arxiv.org/abs/2410.17040",
        "title": "Arabic Dataset for LLM Safeguard Evaluation",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The growing use of large language models (LLMs) has raised concerns regarding their safety. While many studies have focused on English, the safety of LLMs in Arabic, with its linguistic and cultural complexities, remains under-explored. Here, we aim to bridge this gap. In particular, we present an Arab-region-specific safety evaluation dataset consisting of 5,799 questions, including direct attacks, indirect attacks, and harmless requests with sensitive words, adapted to reflect the socio-cultural context of the Arab world. To uncover the impact of different stances in handling sensitive and controversial topics, we propose a dual-perspective evaluation framework. It assesses the LLM responses from both governmental and opposition viewpoints. Experiments over five leading Arabic-centric and multilingual LLMs reveal substantial disparities in their safety performance. This reinforces the need for culturally specific datasets to ensure the responsible deployment of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "17 pages, 6 figures, 10 tables"
    },
    {
        "paper id": "2410.17050",
        "abstract url": "https://arxiv.org/abs/2410.17050",
        "title": "UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs",
        "rating": "0",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The key components of machine learning are data samples for training, model for learning patterns, and loss function for optimizing accuracy. Analogously, unlearning can potentially be achieved through anti-data samples (or anti-samples), unlearning method, and reversed loss function. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. In this paper, we introduce UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language models (LLMs). Our contributions are threefold; first, we propose a novel concept of anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge - something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17064",
        "abstract url": "https://arxiv.org/abs/2410.17064",
        "title": "Multi Kernel Estimation based Object Segmentation",
        "rating": "0",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a novel approach for multi-kernel estimation by enhancing the KernelGAN algorithm, which traditionally estimates a single kernel for the entire image. We introduce Multi-KernelGAN, which extends KernelGAN's capabilities by estimating two distinct kernels based on object segmentation masks. Our approach is validated through three distinct methods: texture-based patch Fast Fourier Transform (FFT) calculation, detail-based segmentation, and deep learning-based object segmentation using YOLOv8 and the Segment Anything Model (SAM). Among these methods, the combination of YOLO and SAM yields the best results for kernel estimation. Experimental results demonstrate that our multi-kernel estimation technique outperforms conventional single-kernel methods in super-resolution tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17101",
        "abstract url": "https://arxiv.org/abs/2410.17101",
        "title": "CLAP: Concave Linear APproximation for Quadratic Graph Matching",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Solving point-wise feature correspondence in visual data is a fundamental problem in computer vision. A powerful model that addresses this challenge is to formulate it as graph matching, which entails solving a Quadratic Assignment Problem (QAP) with node-wise and edge-wise constraints. However, solving such a QAP can be both expensive and difficult due to numerous local extreme points. In this work, we introduce a novel linear model and solver designed to accelerate the computation of graph matching. Specifically, we employ a positive semi-definite matrix approximation to establish the structural attribute constraint.We then transform the original QAP into a linear model that is concave for maximization. This model can subsequently be solved using the Sinkhorn optimal transport algorithm, known for its enhanced efficiency and numerical stability compared to existing approaches. Experimental results on the widely used benchmark PascalVOC showcase that our algorithm achieves state-of-the-art performance with significantly improved efficiency. Source code: https://github.com/xmlyqing00/clap",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted as an oral paper in International Symposium on Visual Computing (ISCV2024)"
    },
    {
        "paper id": "2410.17144",
        "abstract url": "https://arxiv.org/abs/2410.17144",
        "title": "YOLO-TS: Real-Time Traffic Sign Detection with Enhanced Accuracy Using Optimized Receptive Fields and Anchor-Free Fusion",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Ensuring safety in both autonomous driving and advanced driver-assistance systems (ADAS) depends critically on the efficient deployment of traffic sign recognition technology. While current methods show effectiveness, they often compromise between speed and accuracy. To address this issue, we present a novel real-time and efficient road sign detection network, YOLO-TS. This network significantly improves performance by optimizing the receptive fields of multi-scale feature maps to align more closely with the size distribution of traffic signs in various datasets. Moreover, our innovative feature-fusion strategy, leveraging the flexibility of Anchor-Free methods, allows for multi-scale object detection on a high-resolution feature map abundant in contextual information, achieving remarkable enhancements in both accuracy and speed. To mitigate the adverse effects of the grid pattern caused by dilated convolutions on the detection of smaller objects, we have devised a unique module that not only mitigates this grid effect but also widens the receptive field to encompass an extensive range of spatial contextual information, thus boosting the efficiency of information usage. Evaluation on challenging public datasets, TT100K and CCTSDB2021, demonstrates that YOLO-TS surpasses existing state-of-the-art methods in terms of both accuracy and speed. The code for our method will be available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 9 figures and 7 tables"
    },
    {
        "paper id": "2410.17146",
        "abstract url": "https://arxiv.org/abs/2410.17146",
        "title": "LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Large pre-trained models exhibit impressive zero-shot performance across diverse tasks, but fine-tuning often leads to catastrophic forgetting, where improvements on a target domain degrade generalization on other tasks. To address this challenge, we introduce LiNeS, Layer-increasing Network Scaling, a post-training editing technique designed to preserve pre-trained generalization while enhancing fine-tuned task performance. LiNeS scales parameter updates linearly based on their layer depth within the network, maintaining shallow layers close to their pre-trained values to preserve general features while allowing deeper layers to retain task-specific representations. We further extend this approach to multi-task model merging scenarios, where layer-wise scaling of merged parameters reduces negative task interference. LiNeS demonstrates significant improvements in both single-task and multi-task settings across various benchmarks in vision and natural language processing. It mitigates forgetting, enhances out-of-distribution generalization, integrates seamlessly with existing multi-task model merging baselines improving their performance across benchmarks and model sizes, and can boost generalization when merging LLM policies aligned with different rewards via RLHF. Importantly, our method is simple to implement and complementary to many existing techniques.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "The first two authors contributed equally to this work; Project website: \\url{https://lines-merging.github.io/}"
    },
    {
        "paper id": "2410.17149",
        "abstract url": "https://arxiv.org/abs/2410.17149",
        "title": "Are Visual-Language Models Effective in Action Recognition? A Comparative Study",
        "rating": "0",
        "keywords": [
            [
                "Visual-Language"
            ],
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current vision-language foundation models, such as CLIP, have recently shown significant improvement in performance across various downstream tasks. However, whether such foundation models significantly improve more complex fine-grained action recognition tasks is still an open question. To answer this question and better find out the future research direction on human behavior analysis in-the-wild, this paper provides a large-scale study and insight on current state-of-the-art vision foundation models by comparing their transfer ability onto zero-shot and frame-wise action recognition tasks. Extensive experiments are conducted on recent fine-grained, human-centric action recognition datasets (e.g., Toyota Smarthome, Penn Action, UAV-Human, TSU, Charades) including action classification and segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17207",
        "abstract url": "https://arxiv.org/abs/2410.17207",
        "title": "EPContrast: Effective Point-level Contrastive Learning for Large-scale Point Cloud Understanding",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The acquisition of inductive bias through point-level contrastive learning holds paramount significance in point cloud pre-training. However, the square growth in computational requirements with the scale of the point cloud poses a substantial impediment to the practical deployment and execution. To address this challenge, this paper proposes an Effective Point-level Contrastive Learning method for large-scale point cloud understanding dubbed \\textbf{EPContrast}, which consists of AGContrast and ChannelContrast. In practice, AGContrast constructs positive and negative pairs based on asymmetric granularity embedding, while ChannelContrast imposes contrastive supervision between channel feature maps. EPContrast offers point-level contrastive loss while concurrently mitigating the computational resource burden. The efficacy of EPContrast is substantiated through comprehensive validation on S3DIS and ScanNetV2, encompassing tasks such as semantic segmentation, instance segmentation, and object detection. In addition, rich ablation experiments demonstrate remarkable bias induction capabilities under label-efficient and one-epoch training settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17241",
        "abstract url": "https://arxiv.org/abs/2410.17241",
        "title": "Frontiers in Intelligent Colonoscopy",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "medical",
                "cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Colonoscopy is currently one of the most sensitive screening methods for colorectal cancer. This study investigates the frontiers of intelligent colonoscopy techniques and their prospective implications for multimodal medical applications. With this goal, we begin by assessing the current data-centric and model-centric landscapes through four tasks for colonoscopic scene perception, including classification, detection, segmentation, and vision-language understanding. This assessment enables us to identify domain-specific challenges and reveals that multimodal research in colonoscopy remains open for further exploration. To embrace the coming multimodal era, we establish three foundational initiatives: a large-scale multimodal instruction tuning dataset ColonINST, a colonoscopy-designed multimodal language model ColonGPT, and a multimodal benchmark. To facilitate ongoing monitoring of this rapidly evolving field, we provide a public website for the latest updates: https://github.com/ai4colonoscopy/IntelliScope.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "[work in progress] A comprehensive survey of intelligent colonoscopy in the multimodal era"
    },
    {
        "paper id": "2410.17242",
        "abstract url": "https://arxiv.org/abs/2410.17242",
        "title": "LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We propose the Large View Synthesis Model (LVSM), a novel transformer-based approach for scalable and generalizable novel view synthesis from sparse-view inputs. We introduce two architectures: (1) an encoder-decoder LVSM, which encodes input image tokens into a fixed number of 1D latent tokens, functioning as a fully learned scene representation, and decodes novel-view images from them; and (2) a decoder-only LVSM, which directly maps input images to novel-view outputs, completely eliminating intermediate scene representations. Both models bypass the 3D inductive biases used in previous methods -- from 3D representations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar projections, plane sweeps) -- addressing novel view synthesis with a fully data-driven approach. While the encoder-decoder model offers faster inference due to its independent latent representation, the decoder-only LVSM achieves superior quality, scalability, and zero-shot generalization, outperforming previous state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive evaluations across multiple datasets demonstrate that both LVSM variants achieve state-of-the-art novel view synthesis quality. Notably, our models surpass all previous methods even with reduced computational resources (1-2 GPUs). Please see our website for more details: https://haian-jin.github.io/projects/LVSM/ .",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ],
        "comment": "project page: https://haian-jin.github.io/projects/LVSM/"
    },
    {
        "paper id": "2410.17249",
        "abstract url": "https://arxiv.org/abs/2410.17249",
        "title": "SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present SpectroMotion, a novel approach that combines 3D Gaussian Splatting (3DGS) with physically-based rendering (PBR) and deformation fields to reconstruct dynamic specular scenes. Previous methods extending 3DGS to model dynamic scenes have struggled to accurately represent specular surfaces. Our method addresses this limitation by introducing a residual correction technique for accurate surface normal computation during deformation, complemented by a deformable environment map that adapts to time-varying lighting conditions. We implement a coarse-to-fine training strategy that significantly enhances both scene geometry and specular color prediction. We demonstrate that our model outperforms prior methods for view synthesis of scenes containing dynamic specular objects and that it is the only existing 3DGS method capable of synthesizing photorealistic real-world dynamic specular scenes, outperforming state-of-the-art methods in rendering complex, dynamic, and specular scenes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://cdfan0627.github.io/spectromotion/"
    },
    {
        "paper id": "2410.17250",
        "abstract url": "https://arxiv.org/abs/2410.17250",
        "title": "JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Accelerating research on Large Multimodal Models (LMMs) in non-English languages is crucial for enhancing user experiences across broader populations. In this paper, we introduce JMMMU (Japanese MMMU), the first large-scale Japanese benchmark designed to evaluate LMMs on expert-level tasks based on the Japanese cultural context. To facilitate comprehensive culture-aware evaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA) subset, where the culture-independent subjects (e.g., Math) are selected and translated into Japanese, enabling one-to-one comparison with its English counterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly crafted subjects that reflect Japanese cultural context. Using the CA subset, we observe performance drop in many LMMs when evaluated in Japanese, which is purely attributable to language variation. Using the CS subset, we reveal their inadequate Japanese cultural understanding. Further, by combining both subsets, we identify that some LMMs perform well on the CA subset but not on the CS subset, exposing a shallow understanding of the Japanese language that lacks depth in cultural understanding. We hope this work will not only help advance LMM performance in Japanese but also serve as a guideline to create high-standard, culturally diverse benchmarks for multilingual LMM development. The project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Project page: https://mmmu-japanese-benchmark.github.io/JMMMU/"
    },
    {
        "paper id": "2410.17331",
        "abstract url": "https://arxiv.org/abs/2410.17331",
        "title": "Offline Evaluation of Set-Based Text-to-Image Generation",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-Image (TTI) systems often support people during ideation, the early stages of a creative process when exposure to a broad set of relevant images can help explore the design space. Since ideation is an important subclass of TTI tasks, understanding how to quantitatively evaluate TTI systems according to how well they support ideation is crucial to promoting research and development for these users. However, existing evaluation metrics for TTI remain focused on distributional similarity metrics like Fr\u00e9chet Inception Distance (FID). We take an alternative approach and, based on established methods from ranking evaluation, develop TTI evaluation metrics with explicit models of how users browse and interact with sets of spatially arranged generated images. Our proposed offline evaluation metrics for TTI not only capture how relevant generated images are with respect to the user's ideation need but also take into consideration the diversity and arrangement of the set of generated images. We analyze our proposed family of TTI metrics using human studies on image grids generated by three different TTI systems based on subsets of the widely used benchmarks such as MS-COCO captions and Localized Narratives as well as prompts used in naturalistic settings. Our results demonstrate that grounding metrics in how people use systems is an important and understudied area of benchmark design.",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17373",
        "abstract url": "https://arxiv.org/abs/2410.17373",
        "title": "Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Understanding cognitive processes in multi-agent interactions is a primary goal in cognitive science. It can guide the direction of artificial intelligence (AI) research toward social decision-making in multi-agent systems, which includes uncertainty from character heterogeneity. In this paper, we introduce an episodic future thinking (EFT) mechanism for a reinforcement learning (RL) agent, inspired by cognitive processes observed in animals. To enable future thinking functionality, we first develop a multi-character policy that captures diverse characters with an ensemble of heterogeneous policies. Here, the character of an agent is defined as a different weight combination on reward components, representing distinct behavioral preferences. The future thinking agent collects observation-action trajectories of the target agents and uses the pre-trained multi-character policy to infer their characters. Once the character is inferred, the agent predicts the upcoming actions of target agents and simulates the potential future scenario. This capability allows the agent to adaptively select the optimal action, considering the predicted future scenario in multi-agent interactions. To evaluate the proposed mechanism, we consider the multi-agent autonomous driving scenario with diverse driving traits and multiple particle environments. Simulation results demonstrate that the EFT mechanism with accurate character inference leads to a higher reward than existing multi-agent solutions. We also confirm that the effect of reward improvement remains valid across societies with different levels of character diversity.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "NeurIPS 2024 (Web: https://sites.google.com/view/eftm-neurips2024)"
    },
    {
        "paper id": "2410.17450",
        "abstract url": "https://arxiv.org/abs/2410.17450",
        "title": "Intera\u00e7\u00e3o entre rob\u00f4s humanoides: desenvolvendo a colabora\u00e7\u00e3o e comunica\u00e7\u00e3o aut\u00f4noma",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study investigates the interaction between humanoid robots NAO and Pepper, emphasizing their potential applications in educational settings. NAO, widely used in education, and Pepper, designed for social interactions, of er new opportunities for autonomous communication and collaboration. Through a series of programmed interactions, the robots demonstrated their ability to communicate and coordinate actions autonomously, highlighting their potential as tools for enhancing learning environments. The research also explores the integration of emerging technologies, such as artificial intelligence, into these systems, allowing robots to learn from each other and adapt their behavior. The findings suggest that NAO and Pepper can significantly contribute to both technical learning and the development of social and emotional skills in students, of ering innovative pedagogical approaches through the use of humanoid robotics.",
        "subjects": [
            "cs.RO",
            "cs.CL"
        ],
        "comment": "in Portuguese language"
    },
    {
        "paper id": "2410.17457",
        "abstract url": "https://arxiv.org/abs/2410.17457",
        "title": "mmWave-Whisper: Phone Call Eavesdropping and Transcription Using Millimeter-Wave Radar",
        "rating": "0",
        "keywords": [
            [
                "Radar"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces mmWave-Whisper, a system that demonstrates the feasibility of full-corpus automated speech recognition (ASR) on phone calls eavesdropped remotely using off-the-shelf frequency modulated continuous wave (FMCW) millimeter-wave radars. Operating in the 77-81 GHz range, mmWave-Whisper captures earpiece vibrations from smartphones, converts them into audio, and processes the audio to produce speech transcriptions automatically. Unlike previous work that focused on loudspeakers or limited vocabulary, this is the first work to perform such a speech recognition by handling large vocabulary and full sentences on earpiece vibrations from smartphones. This approach expands the potential of radar-audio eavesdropping. mmWave-Whisper addresses challenges such as the lack of large scale training datasets, low SNR, and limited frequency information in radar data through a systematic pipeline designed to leverage synthetic training data, domain adaptation, and inference by incorporating OpenAI's Whisper automatic speech recognition model. The system achieves a word accuracy rate of 44.74% and a character accuracy rate of 62.52% over a range of 25 cm to 125 cm. The paper highlights emerging misuse modalities of AI as the technology evolves rapidly.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "5 pages, 4 figures, 1 table"
    },
    {
        "paper id": "2410.17477",
        "abstract url": "https://arxiv.org/abs/2410.17477",
        "title": "Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination",
        "rating": "0",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The growth in prominence of large language models (LLMs) in everyday life can be largely attributed to their generative abilities, yet some of this is also owed to the risks and costs associated with their use. On one front is their tendency to \\textit{hallucinate} false or misleading information, limiting their reliability. On another is the increasing focus on the computational limitations associated with traditional self-attention based LLMs, which has brought about new alternatives, in particular recurrent models, meant to overcome them. Yet it remains uncommon to consider these two concerns simultaneously. Do changes in architecture exacerbate/alleviate existing concerns about hallucinations? Do they affect how and where they occur? Through an extensive evaluation, we study how these architecture-based inductive biases affect the propensity to hallucinate. While hallucination remains a general phenomenon not limited to specific architectures, the situations in which they occur and the ease with which specific types of hallucinations can be induced can significantly differ based on the model architecture. These findings highlight the need for better understanding both these problems in conjunction with each other, as well as consider how to design more universal techniques for handling hallucinations.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17505",
        "abstract url": "https://arxiv.org/abs/2410.17505",
        "title": "PLGS: Robust Panoptic Lifting with 3D Gaussian Splatting",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Previous methods utilize the Neural Radiance Field (NeRF) for panoptic lifting, while their training and rendering speed are unsatisfactory. In contrast, 3D Gaussian Splatting (3DGS) has emerged as a prominent technique due to its rapid training and rendering speed. However, unlike NeRF, the conventional 3DGS may not satisfy the basic smoothness assumption as it does not rely on any parameterized structures to render (e.g., MLPs). Consequently, the conventional 3DGS is, in nature, more susceptible to noisy 2D mask supervision. In this paper, we propose a new method called PLGS that enables 3DGS to generate consistent panoptic segmentation masks from noisy 2D segmentation masks while maintaining superior efficiency compared to NeRF-based methods. Specifically, we build a panoptic-aware structured 3D Gaussian model to introduce smoothness and design effective noise reduction strategies. For the semantic field, instead of initialization with structure from motion, we construct reliable semantic anchor points to initialize the 3D Gaussians. We then use these anchor points as smooth regularization during training. Additionally, we present a self-training approach using pseudo labels generated by merging the rendered masks with the noisy masks to enhance the robustness of PLGS. For the instance field, we project the 2D instance masks into 3D space and match them with oriented bounding boxes to generate cross-view consistent instance masks for supervision. Experiments on various benchmarks demonstrate that our method outperforms previous state-of-the-art methods in terms of both segmentation quality and speed.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17529",
        "abstract url": "https://arxiv.org/abs/2410.17529",
        "title": "Navigate Complex Physical Worlds via Geometrically Constrained LLM",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study investigates the potential of Large Language Models (LLMs) for reconstructing and constructing the physical world solely based on textual knowledge. It explores the impact of model performance on spatial understanding abilities. To enhance the comprehension of geometric and spatial relationships in the complex physical world, the study introduces a set of geometric conventions and develops a workflow based on multi-layer graphs and multi-agent system frameworks. It examines how LLMs achieve multi-step and multi-objective geometric inference in a spatial environment using multi-layer graphs under unified geometric conventions. Additionally, the study employs a genetic algorithm, inspired by large-scale model knowledge, to solve geometric constraint problems. In summary, this work innovatively explores the feasibility of using text-based LLMs as physical world builders and designs a workflow to enhance their capabilities.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16699",
        "abstract url": "https://arxiv.org/abs/2410.16699",
        "title": "Graph Transformers Dream of Electric Flow",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We show theoretically and empirically that the linear Transformer, when applied to graph data, can implement algorithms that solve canonical problems such as electric flow and eigenvector decomposition. The input to the Transformer is simply the graph incidence matrix; no other explicit positional encoding information is provided. We present explicit weight configurations for implementing each such graph algorithm, and we bound the errors of the constructed Transformers by the errors of the underlying algorithms. Our theoretical findings are corroborated by experiments on synthetic data. Additionally, on a real-world molecular regression task, we observe that the linear Transformer is capable of learning a more effective positional encoding than the default one based on Laplacian eigenvectors. Our work is an initial step towards elucidating the inner-workings of the Transformer for graph data.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16718",
        "abstract url": "https://arxiv.org/abs/2410.16718",
        "title": "Optimal Partial Graph Matching",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Partial graph matching addresses the limitations of traditional graph matching by allowing some nodes to remain unmatched, making it applicable to more complex scenarios. However, this flexibility introduces additional complexity, as both the subset of nodes to match and the optimal mapping must be determined. While recent studies have explored deep learning techniques for partial graph matching, a significant limitation remains: the absence of an optimization objective that fully captures the problem's intrinsic nature while enabling efficient solutions. In this paper, we propose a novel optimization framework for partial graph matching, inspired by optimal partial transport. Our approach formulates an objective that enables partial assignments while incorporating matching biases, using weighted total variation as the divergence function to guarantee optimal partial assignments. We employ the Hungarian algorithm to achieve efficient, exact solutions with cubic time complexity. Our contributions are threefold: (i) we introduce a robust optimization objective that balances matched and unmatched nodes; (ii) we establish a connection between partial graph matching and the linear sum assignment problem, enabling efficient solutions; (iii) we propose a deep graph matching architecture with a novel partial matching loss, providing an end-to-end solution. The empirical evaluations on standard graph matching benchmarks demonstrate the efficacy of the proposed approach.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16723",
        "abstract url": "https://arxiv.org/abs/2410.16723",
        "title": "Resource-Efficient Sensor Fusion via System-Wide Dynamic Gated Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "LiDAR",
                "Radar"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Mobile systems will have to support multiple AI-based applications, each leveraging heterogeneous data sources through DNN architectures collaboratively executed within the network. To minimize the cost of the AI inference task subject to requirements on latency, quality, and - crucially - reliability of the inference process, it is vital to optimize (i) the set of sensors/data sources and (ii) the DNN architecture, (iii) the network nodes executing sections of the DNN, and (iv) the resources to use. To this end, we leverage dynamic gated neural networks with branches, and propose a novel algorithmic strategy called Quantile-constrained Inference (QIC), based upon quantile-Constrained policy optimization. QIC makes joint, high-quality, swift decisions on all the above aspects of the system, with the aim to minimize inference energy cost. We remark that this is the first contribution connecting gated dynamic DNNs with infrastructure-level decision making. We evaluate QIC using a dynamic gated DNN with stems and branches for optimal sensor fusion and inference, trained on the RADIATE dataset offering Radar, LiDAR, and Camera data, and real-world wireless measurements. Our results confirm that QIC matches the optimum and outperforms its alternatives by over 80%.",
        "subjects": [
            "cs.AI",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16790",
        "abstract url": "https://arxiv.org/abs/2410.16790",
        "title": "Sample-Efficient Curriculum Reinforcement Learning for Complex Reward Functions",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics",
                "robot",
                "navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning (RL) shows promise in control problems, but its practical application is often hindered by the complexity arising from intricate reward functions with constraints. While the reward hypothesis suggests these competing demands can be encapsulated in a single scalar reward function, designing such functions remains challenging. Building on existing work, we start by formulating preferences over trajectories to derive a realistic reward function that balances goal achievement with constraint satisfaction in the application of mobile robotics with dynamic obstacles. To mitigate reward exploitation in such complex settings, we propose a novel two-stage reward curriculum combined with a flexible replay buffer that adaptively samples experiences. Our approach first learns on a subset of rewards before transitioning to the full reward, allowing the agent to learn trade-offs between objectives and constraints. After transitioning to a new stage, our method continues to make use of past experiences by updating their rewards for sample-efficient learning. We investigate the efficacy of our approach in robot navigation tasks and demonstrate superior performance compared to baselines in terms of true reward achievement and task completion, underlining its effectiveness.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16822",
        "abstract url": "https://arxiv.org/abs/2410.16822",
        "title": "Can Large Language Models Act as Ensembler for Multi-GNNs?",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have emerged as powerful models for learning from graph-structured data. However, GNNs lack the inherent semantic understanding capability of rich textual nodesattributes, limiting their effectiveness in applications. On the other hand, we empirically observe that for existing GNN models, no one can consistently outperforms others across diverse datasets. In this paper, we study whether LLMs can act as an ensembler for multi-GNNs and propose the LensGNN model. The model first aligns multiple GNNs, mapping the representations of different GNNs into the same space. Then, through LoRA fine-tuning, it aligns the space between the GNN and the LLM, injecting graph tokens and textual information into LLMs. This allows LensGNN to integrate multiple GNNs and leverage LLM's strengths, resulting in better performance. Experimental results show that LensGNN outperforms existing models. This research advances text-attributed graph ensemble learning by providing a robust, superior solution for integrating semantic and structural information. We provide our code and data here: https://anonymous.4open.science/r/EnsemGNN-E267/.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16870",
        "abstract url": "https://arxiv.org/abs/2410.16870",
        "title": "Federated Causal Inference: Multi-Centric ATE Estimation beyond Meta-Analysis",
        "rating": "-0.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study Federated Causal Inference, an approach to estimate treatment effects from decentralized data across centers. We compare three classes of Average Treatment Effect (ATE) estimators derived from the Plug-in G-Formula, ranging from simple meta-analysis to one-shot and multi-shot federated learning, the latter leveraging the full data to learn the outcome model (albeit requiring more communication). Focusing on Randomized Controlled Trials (RCTs), we derive the asymptotic variance of these estimators for linear models. Our results provide practical guidance on selecting the appropriate estimator for various scenarios, including heterogeneity in sample sizes, covariate distributions, treatment assignment schemes, and center effects. We validate these findings with a simulation study.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16882",
        "abstract url": "https://arxiv.org/abs/2410.16882",
        "title": "Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Node classification on graphs frequently encounters the challenge of class imbalance, leading to biased performance and posing significant risks in real-world applications. Although several data-centric solutions have been proposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore overlook the potential of leveraging the rich semantics encoded in textual features for boosting the classification of minority nodes. Given this crucial gap, we investigate the possibility of augmenting graph data in the text space, leveraging the textual generation power of Large Language Models (LLMs) to handle imbalanced node classification on TAGs. Specifically, we propose a novel approach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs), which prompts LLMs to generate synthetic texts based on existing node texts in the graph. Furthermore, to integrate these synthetic text-attributed nodes into the graph, we introduce a text-based link predictor to connect the synthesized nodes with the existing nodes. Our experiments across multiple datasets and evaluation metrics show that our framework significantly outperforms traditional non-textual-based data augmentation strategies and specific node imbalance solutions. This highlights the promise of using LLMs to resolve imbalance issues on TAGs.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.SI"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2410.16935",
        "abstract url": "https://arxiv.org/abs/2410.16935",
        "title": "Graph Neural Networks for Edge Signals: Orientation Equivariance and Invariance",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many applications in traffic, civil engineering, or electrical engineering revolve around edge-level signals. Such signals can be categorized as inherently directed, for example, the water flow in a pipe network, and undirected, like the diameter of a pipe. Topological methods model edge signals with inherent direction by representing them relative to a so-called orientation assigned to each edge. These approaches can neither model undirected edge signals nor distinguish if an edge itself is directed or undirected. We address these shortcomings by (i) revising the notion of orientation equivariance to enable edge direction-aware topological models, (ii) proposing orientation invariance as an additional requirement to describe signals without inherent direction, and (iii) developing EIGN, an architecture composed of novel direction-aware edge-level graph shift operators, that provably fulfills the aforementioned desiderata. It is the first general-purpose topological GNN for edge-level signals that can model directed and undirected signals while distinguishing between directed and undirected edges. A comprehensive evaluation shows that EIGN outperforms prior work in edge-level tasks, for example, improving in RMSE on flow simulation tasks by up to 43.5%.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16950",
        "abstract url": "https://arxiv.org/abs/2410.16950",
        "title": "Breaking ReAct Agents: Foot-in-the-Door Attack Will Get You In",
        "rating": "-0.5",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Following the advancement of large language models (LLMs), the development of LLM-based autonomous agents has become increasingly prevalent. As a result, the need to understand the security vulnerabilities of these agents has become a critical task. We examine how ReAct agents can be exploited using a straightforward yet effective method we refer to as the foot-in-the-door attack. Our experiments show that indirect prompt injection attacks, prompted by harmless and unrelated requests (such as basic calculations) can significantly increase the likelihood of the agent performing subsequent malicious actions. Our results show that once a ReAct agents thought includes a specific tool or action, the likelihood of executing this tool in the subsequent steps increases significantly, as the agent seldom re-evaluates its actions. Consequently, even random, harmless requests can establish a foot-in-the-door, allowing an attacker to embed malicious instructions into the agents thought process, making it more susceptible to harmful directives. To mitigate this vulnerability, we propose implementing a simple reflection mechanism that prompts the agent to reassess the safety of its actions during execution, which can help reduce the success of such attacks.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17032",
        "abstract url": "https://arxiv.org/abs/2410.17032",
        "title": "Insights on Disagreement Patterns in Multimodal Safety Perception across Diverse Rater Groups",
        "rating": "-0.5",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "AI systems crucially rely on human ratings, but these ratings are often aggregated, obscuring the inherent diversity of perspectives in real-world phenomenon. This is particularly concerning when evaluating the safety of generative AI, where perceptions and associated harms can vary significantly across socio-cultural contexts. While recent research has studied the impact of demographic differences on annotating text, there is limited understanding of how these subjective variations affect multimodal safety in generative AI. To address this, we conduct a large-scale study employing highly-parallel safety ratings of about 1000 text-to-image (T2I) generations from a demographically diverse rater pool of 630 raters balanced across 30 intersectional groups across age, gender, and ethnicity. Our study shows that (1) there are significant differences across demographic groups (including intersectional groups) on how severe they assess the harm to be, and that these differences vary across different types of safety violations, (2) the diverse rater pool captures annotation patterns that are substantially different from expert raters trained on specific set of safety policies, and (3) the differences we observe in T2I safety are distinct from previously documented group level differences in text-based safety tasks. To further understand these varying perspectives, we conduct a qualitative analysis of the open-ended explanations provided by raters. This analysis reveals core differences into the reasons why different groups perceive harms in T2I generations. Our findings underscore the critical need for incorporating diverse perspectives into safety evaluation of generative AI ensuring these systems are truly inclusive and reflect the values of all users.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "20 pages, 7 figures"
    },
    {
        "paper id": "2410.17111",
        "abstract url": "https://arxiv.org/abs/2410.17111",
        "title": "Permutation Picture of Graph Combinatorial Optimization Problems",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes a framework that formulates a wide range of graph combinatorial optimization problems using permutation-based representations. These problems include the travelling salesman problem, maximum independent set, maximum cut, and various other related problems. This work potentially opens up new avenues for algorithm design in neural combinatorial optimization, bridging the gap between discrete and continuous optimization techniques.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "15 pages, 2 figures"
    },
    {
        "paper id": "2410.17118",
        "abstract url": "https://arxiv.org/abs/2410.17118",
        "title": "Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a promising paradigm of heterogeneous network (HetNet), attributed to the complementary physical properties of optical spectra and radio frequency. However, the current development of such HetNets is mostly bottlenecked by the existing transmission control protocol (TCP), which restricts the user equipment (UE) to connecting one access point (AP) at a time. While the ongoing investigation on multipath TCP (MPTCP) can bring significant benefits, it complicates the network topology of HetNets, making the existing load balancing (LB) learning models less effective. Driven by this, we propose a graph neural network (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets, which results in a partial mesh topology. Such a topology can be modeled as a graph, with the channel state information and data rate requirement embedded as node features, while the LB solutions are deemed as edge labels. Compared to the conventional deep neural network (DNN), the proposed GNN-based model exhibits two key strengths: i) it can better interpret a complex network topology; and ii) it can handle various numbers of APs and UEs with a single trained model. Simulation results show that against the traditional optimisation method, the proposed learning model can achieve near-optimal throughput within a gap of 11.5%, while reducing the inference time by 4 orders of magnitude. In contrast to the DNN model, the new method can improve the network throughput by up to 21.7%, at a similar inference time level.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17142",
        "abstract url": "https://arxiv.org/abs/2410.17142",
        "title": "Coniferest: a complete active anomaly detection framework",
        "rating": "-0.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present coniferest, an open source generic purpose active anomaly detection framework written in Python. The package design and implemented algorithms are described. Currently, static outlier detection analysis is supported via the Isolation forest algorithm. Moreover, Active Anomaly Discovery (AAD) and Pineforest algorithms are available to tackle active anomaly detection problems. The algorithms and package performance are evaluated on a series of synthetic datasets. We also describe a few success cases which resulted from applying the package to real astronomical data in active anomaly detection tasks within the SNAD project.",
        "subjects": [
            "astro-ph.IM",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "13 pages, 1 figure"
    },
    {
        "paper id": "2410.17246",
        "abstract url": "https://arxiv.org/abs/2410.17246",
        "title": "Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile Skins",
        "rating": "-0.5",
        "keywords": [
            [
                "robotic manipulation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "While visuomotor policy learning has advanced robotic manipulation, precisely executing contact-rich tasks remains challenging due to the limitations of vision in reasoning about physical interactions. To address this, recent work has sought to integrate tactile sensing into policy learning. However, many existing approaches rely on optical tactile sensors that are either restricted to recognition tasks or require complex dimensionality reduction steps for policy learning. In this work, we explore learning policies with magnetic skin sensors, which are inherently low-dimensional, highly sensitive, and inexpensive to integrate with robotic platforms. To leverage these sensors effectively, we present the Visuo-Skin (ViSk) framework, a simple approach that uses a transformer-based policy and treats skin sensor data as additional tokens alongside visual information. Evaluated on four complex real-world tasks involving credit card swiping, plug insertion, USB insertion, and bookshelf retrieval, ViSk significantly outperforms both vision-only and optical tactile sensing based policies. Further analysis reveals that combining tactile and visual modalities enhances policy performance and spatial generalization, achieving an average improvement of 27.5% across tasks. https://visuoskin.github.io/",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17297",
        "abstract url": "https://arxiv.org/abs/2410.17297",
        "title": "Error estimates between SGD with momentum and underdamped Langevin diffusion",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Stochastic gradient descent with momentum is a popular variant of stochastic gradient descent, which has recently been reported to have a close relationship with the underdamped Langevin diffusion. In this paper, we establish a quantitative error estimate between them in the 1-Wasserstein and total variation distances.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17338",
        "abstract url": "https://arxiv.org/abs/2410.17338",
        "title": "Enhancing Robustness and Efficiency of Least Square Twin SVM via Granular Computing",
        "rating": "-0.5",
        "keywords": [
            [
                "SVM",
                "support vector machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the domain of machine learning, least square twin support vector machine (LSTSVM) stands out as one of the state-of-the-art models. However, LSTSVM suffers from sensitivity to noise and outliers, overlooking the SRM principle and instability in resampling. Moreover, its computational complexity and reliance on matrix inversions hinder the efficient processing of large datasets. As a remedy to the aforementioned challenges, we propose the robust granular ball LSTSVM (GBLSTSVM). GBLSTSVM is trained using granular balls instead of original data points. The core of a granular ball is found at its center, where it encapsulates all the pertinent information of the data points within the ball of specified radius. To improve scalability and efficiency, we further introduce the large-scale GBLSTSVM (LS-GBLSTSVM), which incorporates the SRM principle through regularization terms. Experiments are performed on UCI, KEEL, and NDC benchmark datasets; both the proposed GBLSTSVM and LS-GBLSTSVM models consistently outperform the baseline models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17442",
        "abstract url": "https://arxiv.org/abs/2410.17442",
        "title": "Detecting Adversarial Examples",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Neural Networks (DNNs) have been shown to be vulnerable to adversarial examples. While numerous successful adversarial attacks have been proposed, defenses against these attacks remain relatively understudied. Existing defense approaches either focus on negating the effects of perturbations caused by the attacks to restore the DNNs' original predictions or use a secondary model to detect adversarial examples. However, these methods often become ineffective due to the continuous advancements in attack techniques. We propose a novel universal and lightweight method to detect adversarial examples by analyzing the layer outputs of DNNs. Through theoretical justification and extensive experiments, we demonstrate that our detection method is highly effective, compatible with any DNN architecture, and applicable across different domains, such as image, video, and audio.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17460",
        "abstract url": "https://arxiv.org/abs/2410.17460",
        "title": "Graph Neural Network-Accelerated Network-Reconfigured Optimal Power Flow",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Optimal power flow (OPF) has been used for real-time grid operations. Prior efforts demonstrated that utilizing flexibility from dynamic topologies will improve grid efficiency. However, this will convert the linear OPF into a mixed-integer linear programming network-reconfigured OPF (NR-OPF) problem, substantially increasing the computing time. Thus, a machine learning (ML)-based approach, particularly utilizing graph neural network (GNN), is proposed to accelerate the solution process. The GNN model is trained offline to predict the best topology before entering the optimization stage. In addition, this paper proposes an offline pre-ML filter layer to reduce GNN model size and training time while improving its accuracy. A fast online post-ML selection layer is also proposed to analyze GNN predictions and then select a subset of predicted NR solutions with high confidence. Case studies have demonstrated superior performance of the proposed GNN-accelerated NR-OPF method augmented with the proposed pre-ML and post-ML layers.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17464",
        "abstract url": "https://arxiv.org/abs/2410.17464",
        "title": "Scalable Implicit Graphon Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graphons are continuous models that represent the structure of graphs and allow the generation of graphs of varying sizes. We propose Scalable Implicit Graphon Learning (SIGL), a scalable method that combines implicit neural representations (INRs) and graph neural networks (GNNs) to estimate a graphon from observed graphs. Unlike existing methods, which face important limitations like fixed resolution and scalability issues, SIGL learns a continuous graphon at arbitrary resolutions. GNNs are used to determine the correct node ordering, improving graph alignment. Furthermore, we characterize the asymptotic consistency of our estimator, showing that more expressive INRs and GNNs lead to consistent estimators. We evaluate SIGL in synthetic and real-world graphs, showing that it outperforms existing methods and scales effectively to larger graphs, making it ideal for tasks like graph data augmentation.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17465",
        "abstract url": "https://arxiv.org/abs/2410.17465",
        "title": "Bauplan: zero-copy, scale-up FaaS for data pipelines",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Chaining functions for longer workloads is a key use case for FaaS platforms in data applications. However, modern data pipelines differ significantly from typical serverless use cases (e.g., webhooks and microservices); this makes it difficult to retrofit existing pipeline frameworks due to structural constraints. In this paper, we describe these limitations in detail and introduce bauplan, a novel FaaS programming model and serverless runtime designed for data practitioners. bauplan enables users to declaratively define functional Directed Acyclic Graphs (DAGs) along with their runtime environments, which are then efficiently executed on cloud-based workers. We show that bauplan achieves both better performance and a superior developer experience for data workloads by making the trade-off of reducing generality in favor of data-awareness",
        "subjects": [
            "cs.DB",
            "cs.LG",
            "cs.OS"
        ],
        "comment": "Accepted for the 10th International Workshop on Serverless Computing (pre-print)"
    },
    {
        "paper id": "2410.17506",
        "abstract url": "https://arxiv.org/abs/2410.17506",
        "title": "Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Distribution shifts between training and testing datasets significantly impair the model performance on graph learning. A commonly-taken causal view in graph invariant learning suggests that stable predictive features of graphs are causally associated with labels, whereas varying environmental features lead to distribution shifts. In particular, covariate shifts caused by unseen environments in test graphs underscore the critical need for out-of-distribution (OOD) generalization. Existing graph augmentation methods designed to address the covariate shift often disentangle the stable and environmental features in the input space, and selectively perturb or mixup the environmental features. However, such perturbation-based methods heavily rely on an accurate separation of stable and environmental features, and their exploration ability is confined to existing environmental features in the training distribution. To overcome these limitations, we introduce a novel approach using score-based graph generation strategies that synthesize unseen environmental features while preserving the validity and stable features of overall graph patterns. Our comprehensive empirical evaluations demonstrate the enhanced effectiveness of our method in improving graph OOD generalization.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "17 pages, 5 figures, 4 tables"
    },
    {
        "paper id": "2410.17509",
        "abstract url": "https://arxiv.org/abs/2410.17509",
        "title": "WAGLE: Strategic Weight Attribution for Effective and Modular Unlearning in Large Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The need for effective unlearning mechanisms in large language models (LLMs) is increasingly urgent, driven by the necessity to adhere to data regulations and foster ethical generative AI practices. Despite growing interest of LLM unlearning, much of the existing research has focused on varied unlearning method designs to boost effectiveness and efficiency. However, the inherent relationship between model weights and LLM unlearning has not been extensively examined. In this paper, we systematically explore how model weights interact with unlearning processes in LLMs and we design the weight attribution-guided LLM unlearning method, WAGLE, which unveils the interconnections between 'influence' of weights and 'influence' of data to forget and retain in LLM generation. By strategically guiding the LLM unlearning across different types of unlearning methods and tasks, WAGLE can erase the undesired content, while maintaining the performance of the original tasks. We refer to the weight attribution-guided LLM unlearning method as WAGLE, which unveils the interconnections between 'influence' of weights and 'influence' of data to forget and retain in LLM generation. Our extensive experiments show that WAGLE boosts unlearning performance across a range of LLM unlearning methods such as gradient difference and (negative) preference optimization, applications such as fictitious unlearning, malicious use prevention, and copyrighted information removal, and models including Zephyr-7b-beta and Llama2-7b. To the best of our knowledge, our work offers the first principled method for attributing and pinpointing the influential weights in enhancing LLM unlearning. It stands in contrast to previous methods that lack weight attribution and simpler weight attribution techniques.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.18147",
        "abstract url": "https://arxiv.org/abs/2410.18147",
        "title": "MEC-IP: Efficient Discovery of Markov Equivalent Classes via Integer Programming",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a novel Integer Programming (IP) approach for discovering the Markov Equivalent Class (MEC) of Bayesian Networks (BNs) through observational data. The MEC-IP algorithm utilizes a unique clique-focusing strategy and Extended Maximal Spanning Graphs (EMSG) to streamline the search for MEC, thus overcoming the computational limitations inherent in other existing algorithms. Our numerical results show that not only a remarkable reduction in computational time is achieved by our algorithm but also an improvement in causal discovery accuracy is seen across diverse datasets. These findings underscore this new algorithm's potential as a powerful tool for researchers and practitioners in causal discovery and BNSL, offering a significant leap forward toward the efficient and accurate analysis of complex data structures.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16711",
        "abstract url": "https://arxiv.org/abs/2410.16711",
        "title": "Development of CNN Architectures using Transfer Learning Methods for Medical Image Classification",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The application of deep learning-based architecture has seen a tremendous rise in recent years. For example, medical image classification using deep learning achieved breakthrough results. Convolutional Neural Networks (CNNs) are implemented predominantly in medical image classification and segmentation. On the other hand, transfer learning has emerged as a prominent supporting tool for enhancing the efficiency and accuracy of deep learning models. This paper investigates the development of CNN architectures using transfer learning techniques in the field of medical image classification using a timeline mapping model for key image classification challenges. Our findings help make an informed decision while selecting the optimum and state-of-the-art CNN architectures.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16724",
        "abstract url": "https://arxiv.org/abs/2410.16724",
        "title": "Efficient Scheduling of Vehicular Tasks on Edge Systems with Green Energy and Battery Storage",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "The autonomous vehicle industry is rapidly expanding, requiring significant computational resources for tasks like perception and decision-making. Vehicular edge computing has emerged to meet this need, utilizing roadside computational units (roadside edge servers) to support autonomous vehicles. Aligning with the trend of green cloud computing, these roadside edge servers often get energy from solar power. Additionally, each roadside computational unit is equipped with a battery for storing solar power, ensuring continuous computational operation during periods of low solar energy availability. In our research, we address the scheduling of computational tasks generated by autonomous vehicles to roadside units with power consumption proportional to the cube of the computational load of the server. Each computational task is associated with a revenue, dependent on its computational needs and deadline. Our objective is to maximize the total revenue of the system of roadside computational units. We propose an offline heuristics approach based on predicted solar energy and incoming task patterns for different time slots. Additionally, we present heuristics for real-time adaptation to varying solar energy and task patterns from predicted values for different time slots. Our comparative analysis shows that our methods outperform state-of-the-art approaches upto 40\\% for real-life datasets.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16726",
        "abstract url": "https://arxiv.org/abs/2410.16726",
        "title": "Enhancing Low-Resource ASR through Versatile TTS: Bridging the Data Gap",
        "rating": "-1",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "cs.AI",
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "While automatic speech recognition (ASR) systems have achieved remarkable performance with large-scale datasets, their efficacy remains inadequate in low-resource settings, encompassing dialects, accents, minority languages, and long-tail hotwords, domains with significant practical relevance. With the advent of versatile and powerful text-to-speech (TTS) models, capable of generating speech with human-level naturalness, expressiveness, and diverse speaker profiles, leveraging TTS for ASR data augmentation provides a cost-effective and practical approach to enhancing ASR performance. Comprehensive experiments on an unprecedentedly rich variety of low-resource datasets demonstrate consistent and substantial performance improvements, proving that the proposed method of enhancing low-resource ASR through a versatile TTS model is highly effective and has broad application prospects. Furthermore, we delve deeper into key characteristics of synthesized speech data that contribute to ASR improvement, examining factors such as text diversity, speaker diversity, and the volume of synthesized data, with text diversity being studied for the first time in this work. We hope our findings provide helpful guidance and reference for the practical application of TTS-based data augmentation and push the advancement of low-resource ASR one step further.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16769",
        "abstract url": "https://arxiv.org/abs/2410.16769",
        "title": "DSORT-MCU: Detecting Small Objects in Real-Time on Microcontroller Units",
        "rating": "-1",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Advances in lightweight neural networks have revolutionized computer vision in a broad range of IoT applications, encompassing remote monitoring and process automation. However, the detection of small objects, which is crucial for many of these applications, remains an underexplored area in current computer vision research, particularly for low-power embedded devices that host resource-constrained processors. To address said gap, this paper proposes an adaptive tiling method for lightweight and energy-efficient object detection networks, including YOLO-based models and the popular FOMO network. The proposed tiling enables object detection on low-power MCUs with no compromise on accuracy compared to large-scale detection models. The benefit of the proposed method is demonstrated by applying it to FOMO and TinyissimoYOLO networks on a novel RISC-V-based MCU with built-in ML accelerators. Extensive experimental results show that the proposed tiling method boosts the F1-score by up to 225% for both FOMO and TinyissimoYOLO networks while reducing the average object count error by up to 76% with FOMO and up to 89% for TinyissimoYOLO. Furthermore, the findings of this work indicate that using a soft F1 loss over the popular binary cross-entropy loss can serve as an implicit non-maximum suppression for the FOMO network. To evaluate the real-world performance, the networks are deployed on the RISC-V based GAP9 microcontroller from GreenWaves Technologies, showcasing the proposed method's ability to strike a balance between detection performance ($58% - 95%$ F1 score), low latency (0.6 ms/Inference - 16.2 ms/Inference}), and energy efficiency (31 uJ/Inference} - 1.27 mJ/Inference) while performing multiple predictions using high-resolution images on a MCU.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2311.07163"
    },
    {
        "paper id": "2410.16770",
        "abstract url": "https://arxiv.org/abs/2410.16770",
        "title": "The Scene Language: Representing Scenes with Programs, Words, and Embeddings",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We introduce the Scene Language, a visual scene representation that concisely and precisely describes the structure, semantics, and identity of visual scenes. It represents a scene with three key components: a program that specifies the hierarchical and relational structure of entities in the scene, words in natural language that summarize the semantic class of each entity, and embeddings that capture the visual identity of each entity. This representation can be inferred from pre-trained language models via a training-free inference technique, given text or image inputs. The resulting scene can be rendered into images using traditional, neural, or hybrid graphics renderers. Together, this forms a robust, automated system for high-quality 3D and 4D scene generation. Compared with existing representations like scene graphs, our proposed Scene Language generates complex scenes with higher fidelity, while explicitly modeling the scene structures to enable precise control and editing.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Project page: https://ai.stanford.edu/~yzzhang/projects/scene-language/"
    },
    {
        "paper id": "2410.16780",
        "abstract url": "https://arxiv.org/abs/2410.16780",
        "title": "Beyond Retrieval: Generating Narratives in Conversational Recommender Systems",
        "rating": "-1",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The recent advances in Large Language Model's generation and reasoning capabilities present an opportunity to develop truly conversational recommendation systems. However, effectively integrating recommender system knowledge into LLMs for natural language generation which is tailored towards recommendation tasks remains a challenge. This paper addresses this challenge by making two key contributions. First, we introduce a new dataset (REGEN) for natural language generation tasks in conversational recommendations. REGEN (Reviews Enhanced with GEnerative Narratives) extends the Amazon Product Reviews dataset with rich user narratives, including personalized explanations of product preferences, product endorsements for recommended items, and summaries of user purchase history. REGEN is made publicly available to facilitate further research. Furthermore, we establish benchmarks using well-known generative metrics, and perform an automated evaluation of the new dataset using a rater LLM. Second, the paper introduces a fusion architecture (CF model with an LLM) which serves as a baseline for REGEN. And to the best of our knowledge, represents the first attempt to analyze the capabilities of LLMs in understanding recommender signals and generating rich narratives. We demonstrate that LLMs can effectively learn from simple fusion architectures utilizing interaction-based CF embeddings, and this can be further enhanced using the metadata and personalization data associated with items. Our experiments show that combining CF and content embeddings leads to improvements of 4-12% in key language metrics compared to using either type of embedding individually. We also provide an analysis to interpret how CF and content embeddings contribute to this new generative task.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16817",
        "abstract url": "https://arxiv.org/abs/2410.16817",
        "title": "A Deep Learning-Based Method for Metal Artifact-Resistant Syn-MP-RAGE Contrast Synthesis",
        "rating": "-1",
        "keywords": [
            [
                "MRI"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "In certain brain volumetric studies, synthetic T1-weighted magnetization-prepared rapid gradient-echo (MP-RAGE) contrast, derived from quantitative T1 MRI (T1-qMRI), proves highly valuable due to its clear white/gray matter boundaries for brain segmentation. However, generating synthetic MP-RAGE (syn-MP-RAGE) typically requires pairs of high-quality, artifact-free, multi-modality inputs, which can be challenging in retrospective studies, where missing or corrupted data is common. To overcome this limitation, our research explores the feasibility of employing a deep learning-based approach to synthesize syn-MP-RAGE contrast directly from a single channel turbo spin-echo (TSE) input, renowned for its resistance to metal artifacts. We evaluated this deep learning-based synthetic MP-RAGE (DL-Syn-MPR) on 31 non-artifact and 11 metal-artifact subjects. The segmentation results, measured by the Dice Similarity Coefficient (DSC), consistently achieved high agreement (DSC values above 0.83), indicating a strong correlation with reference segmentations, with lower input requirements. Also, no significant difference in segmentation performance was observed between the artifact and non-artifact groups.",
        "subjects": [
            "physics.med-ph",
            "eess.IV"
        ],
        "comment": "11 pages, 8 figures, 2 tables"
    },
    {
        "paper id": "2410.16820",
        "abstract url": "https://arxiv.org/abs/2410.16820",
        "title": "AttriPrompter: Auto-Prompting with Attribute Semantics for Zero-shot Nuclei Detection via Visual-Language Pre-trained Models",
        "rating": "-1",
        "keywords": [
            [
                "Visual-Language"
            ],
            [
                "text-to-image"
            ],
            [
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large-scale visual-language pre-trained models (VLPMs) have demonstrated exceptional performance in downstream object detection through text prompts for natural scenes. However, their application to zero-shot nuclei detection on histopathology images remains relatively unexplored, mainly due to the significant gap between the characteristics of medical images and the web-originated text-image pairs used for pre-training. This paper aims to investigate the potential of the object-level VLPM, Grounded Language-Image Pre-training (GLIP), for zero-shot nuclei detection. Specifically, we propose an innovative auto-prompting pipeline, named AttriPrompter, comprising attribute generation, attribute augmentation, and relevance sorting, to avoid subjective manual prompt design. AttriPrompter utilizes VLPMs' text-to-image alignment to create semantically rich text prompts, which are then fed into GLIP for initial zero-shot nuclei detection. Additionally, we propose a self-trained knowledge distillation framework, where GLIP serves as the teacher with its initial predictions used as pseudo labels, to address the challenges posed by high nuclei density, including missed detections, false positives, and overlapping instances. Our method exhibits remarkable performance in label-free nuclei detection, outperforming all existing unsupervised methods and demonstrating excellent generality. Notably, this work highlights the astonishing potential of VLPMs pre-trained on natural image-text pairs for downstream tasks in the medical field as well. Code will be released at https://github.com/wuyongjianCODE/AttriPrompter.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This article has been accepted for publication in a future issue of IEEE Transactions on Medical Imaging (TMI), but has not been fully edited. Content may change prior to final publication. Citation information: DOI: https://doi.org/10.1109/TMI.2024.3473745 . Code: https://github.com/wuyongjianCODE/AttriPrompter"
    },
    {
        "paper id": "2410.16821",
        "abstract url": "https://arxiv.org/abs/2410.16821",
        "title": "Guiding Reinforcement Learning with Incomplete System Dynamics",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Model-free reinforcement learning (RL) is inherently a reactive method, operating under the assumption that it starts with no prior knowledge of the system and entirely depends on trial-and-error for learning. This approach faces several challenges, such as poor sample efficiency, generalization, and the need for well-designed reward functions to guide learning effectively. On the other hand, controllers based on complete system dynamics do not require data. This paper addresses the intermediate situation where there is not enough model information for complete controller design, but there is enough to suggest that a model-free approach is not the best approach either. By carefully decoupling known and unknown information about the system dynamics, we obtain an embedded controller guided by our partial model and thus improve the learning efficiency of an RL-enhanced approach. A modular design allows us to deploy mainstream RL algorithms to refine the policy. Simulation results show that our method significantly improves sample efficiency compared with standard RL methods on continuous control tasks, and also offers enhanced performance over traditional control approaches. Experiments on a real ground vehicle also validate the performance of our method, including generalization and robustness.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Accepted to IROS 2024"
    },
    {
        "paper id": "2410.16833",
        "abstract url": "https://arxiv.org/abs/2410.16833",
        "title": "Toroidal density-equalizing map for genus-one surfaces",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ]
        ],
        "abstract": "Density-equalizing map is a shape deformation technique originally developed for cartogram creation and sociological data visualization on planar geographical maps. In recent years, there has been an increasing interest in developing density-equalizing mapping methods for surface and volumetric domains and applying them to various problems in geometry processing and imaging science. However, the existing surface density-equalizing mapping methods are only applicable to surfaces with relatively simple topologies but not surfaces with topological holes. In this work, we develop a novel algorithm for computing density-equalizing maps for toroidal surfaces. In particular, different shape deformation effects can be easily achieved by prescribing different population functions on the torus and performing diffusion-based deformations on a planar domain with periodic boundary conditions. Furthermore, the proposed toroidal density-equalizing mapping method naturally leads to an effective method for computing toroidal parameterizations of genus-one surfaces with controllable shape changes, with the toroidal area-preserving parameterization being a prime example. Experimental results are presented to demonstrate the effectiveness of our proposed methods.",
        "subjects": [
            "cs.GR",
            "cs.CG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16851",
        "abstract url": "https://arxiv.org/abs/2410.16851",
        "title": "Toolpath Generation for High Density Spatial Fiber Printing Guided by Principal Stresses",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "While multi-axis 3D printing can align continuous fibers along principal stresses in continuous fiber-reinforced thermoplastic (CFRTP) composites to enhance mechanical strength, existing methods have difficulty generating toolpaths with high fiber coverage. This is mainly due to the orientation consistency constraints imposed by vector-field-based methods and the turbulent stress fields around stress concentration regions. This paper addresses these challenges by introducing a 2-RoSy representation for computing the direction field, which is then converted into a periodic scalar field to generate partial iso-curves for fiber toolpaths with nearly equal hatching distance. To improve fiber coverage in stress-concentrated regions, such as around holes, we extend the quaternion-based method for curved slicing by incorporating winding compatibility considerations. Our proposed method can achieve toolpaths coverage between 87.5% and 90.6% by continuous fibers with 1.1mm width. Models fabricated using our toolpaths show up to 84.6% improvement in failure load and 54.4% increase in stiffness when compared to the results obtained from multi-axis 3D printing with sparser fibers.",
        "subjects": [
            "cs.GR",
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16855",
        "abstract url": "https://arxiv.org/abs/2410.16855",
        "title": "Tracing the Development of the Virtual Particle Concept Using Semantic Change Detection",
        "rating": "-1",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Virtual particles are peculiar objects. They figure prominently in much of theoretical and experimental research in elementary particle physics. But exactly what they are is far from obvious. In particular, to what extent they should be considered \"real\" remains a matter of controversy in philosophy of science. Also their origin and development has only recently come into focus of scholarship in the history of science. In this study, we propose using the intriguing case of virtual particles to discuss the efficacy of Semantic Change Detection (SCD) based on contextualized word embeddings from a domain-adapted BERT model in studying specific scientific concepts. We find that the SCD metrics align well with qualitative research insights in the history and philosophy of science, as well as with the results obtained from Dependency Parsing to determine the frequency and connotations of the term \"virtual.\" Still, the metrics of SCD provide additional insights over and above the qualitative research and the Dependency Parsing. Among other things, the metrics suggest that the concept of the virtual particle became more stable after 1950 but at the same time also more polysemous.",
        "subjects": [
            "cs.CL",
            "physics.hist-ph"
        ],
        "comment": "CHR 2024: Computational Humanities Research Conference"
    },
    {
        "paper id": "2410.16892",
        "abstract url": "https://arxiv.org/abs/2410.16892",
        "title": "VistaDream: Sampling multiview consistent images for single-view scene reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "RGB-D",
                "depth"
            ],
            [
                "diffusion",
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we propose VistaDream a novel framework to reconstruct a 3D scene from a single-view image. Recent diffusion models enable generating high-quality novel-view images from a single-view input image. Most existing methods only concentrate on building the consistency between the input image and the generated images while losing the consistency between the generated images. VistaDream addresses this problem by a two-stage pipeline. In the first stage, VistaDream begins with building a global coarse 3D scaffold by zooming out a little step with inpainted boundaries and an estimated depth map. Then, on this global scaffold, we use iterative diffusion-based RGB-D inpainting to generate novel-view images to inpaint the holes of the scaffold. In the second stage, we further enhance the consistency between the generated novel-view images by a novel training-free Multiview Consistency Sampling (MCS) that introduces multi-view consistency constraints in the reverse sampling process of diffusion models. Experimental results demonstrate that without training or fine-tuning existing diffusion models, VistaDream achieves consistent and high-quality novel view synthesis using just single-view images and outperforms baseline methods by a large margin. The code, videos, and interactive demos are available at https://vistadream-project-page.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://vistadream-project-page.github.io/"
    },
    {
        "paper id": "2410.16922",
        "abstract url": "https://arxiv.org/abs/2410.16922",
        "title": "Direction-Constrained Control for Efficient Physical Human-Robot Interaction under Hierarchical Tasks",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "This paper proposes a control method to address the physical Human-Robot Interaction (pHRI) challenge in the context of hierarchical tasks. A common approach to managing hierarchical tasks is Hierarchical Quadratic Programming (HQP), which, however, cannot be directly applied to human interaction due to its allowance of arbitrary velocity direction adjustments. To resolve this limitation, we introduce the concept of directional constraints and develop a direction-constrained optimization algorithm to handle the nonlinearities induced by these constraints. The algorithm solves two sub-problems, minimizing the error and minimizing the deviation angle, in parallel, and combines the results of the two sub-problems to produce a final optimal outcome. The mutual influence between these two sub-problems is analyzed to determine the best parameter for combination. Additionally, the velocity objective in our control framework is computed using a variable admittance controller. Traditional admittance control does not account for constraints. To address this issue, we propose a variable admittance control method to adjust control objectives dynamically. The method helps reduce the deviation between robot velocity and human intention at the constraint boundaries, thereby enhancing interaction efficiency. We evaluate the proposed method in scenarios where a human operator physically interacts with a 7-degree-of-freedom robotic arm. The results highlight the importance of incorporating directional constraints in pHRI for hierarchical tasks. Compared to existing methods, our approach generates smoother robotic trajectories during interaction while avoiding interaction delays at the constraint boundaries.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16938",
        "abstract url": "https://arxiv.org/abs/2410.16938",
        "title": "Cooperative Trajectory Planning: Principles for Human-Machine System Design on Trajectory Level",
        "rating": "-1",
        "keywords": [
            [
                "Trajectory"
            ]
        ],
        "abstract": "This paper explores cooperative trajectory planning approaches within the context of human-machine shared control. In shared control research, it is typically assumed that the human and the automation use the same reference trajectory to stabilize the coupled system. However, this assumption is often incorrect, as they usually follow different trajectories, causing control conflicts at the action level that have not been widely researched. To address this, it is logical to extend shared control concepts to include human-machine interaction at the trajectory-level before action execution, resulting in a unified reference trajectory for both human and automation. This paper begins with a literature overview on approaches of cooperative trajectory planning. It then presents an approach of finding a joint trajectory by modelling cooperative trajectory planning as an agreement process. A generally valid system structure is proposed for this purpose. Finally, it proposes concepts to implement cooperative trajectory planning as an agreement process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16939",
        "abstract url": "https://arxiv.org/abs/2410.16939",
        "title": "LIMIS: Towards Language-based Interactive Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Within this work, we introduce LIMIS: The first purely language-based interactive medical image segmentation model. We achieve this by adapting Grounded SAM to the medical domain and designing a language-based model interaction strategy that allows radiologists to incorporate their knowledge into the segmentation process. LIMIS produces high-quality initial segmentation masks by leveraging medical foundation models and allows users to adapt segmentation masks using only language, opening up interactive segmentation to scenarios where physicians require using their hands for other tasks. We evaluate LIMIS on three publicly available medical datasets in terms of performance and usability with experts from the medical domain confirming its high-quality segmentation masks and its interactive usability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16947",
        "abstract url": "https://arxiv.org/abs/2410.16947",
        "title": "ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial Information in Medical Images",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper demonstrates that spatial information can be used to learn interpretable representations in medical images using Self-Supervised Learning (SSL). Our proposed method, ISImed, is based on the observation that medical images exhibit a much lower variability among different images compared to classic data vision benchmarks. By leveraging this resemblance of human body structures across multiple images, we establish a self-supervised objective that creates a latent representation capable of capturing its location in the physical realm. More specifically, our method involves sampling image crops and creating a distance matrix that compares the learned representation vectors of all possible combinations of these crops to the true distance between them. The intuition is, that the learned latent space is a positional encoding for a given image crop. We hypothesize, that by learning these positional encodings, comprehensive image representations have to be generated. To test this hypothesis and evaluate our method, we compare our learned representation with two state-of-the-art SSL benchmarking methods on two publicly available medical imaging datasets. We show that our method can efficiently learn representations that capture the underlying structure of the data and can be used to transfer to a downstream classification task.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2410.16954",
        "abstract url": "https://arxiv.org/abs/2410.16954",
        "title": "LoRA-C: Parameter-Efficient Fine-Tuning of Robust CNN for IoT Devices",
        "rating": "-1",
        "keywords": [
            [
                "Parameter-Efficient",
                "Efficient Fine-Tuning"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "Efficient fine-tuning of pre-trained convolutional neural network (CNN) models using local data is essential for providing high-quality services to users using ubiquitous and resource-limited Internet of Things (IoT) devices. Low-Rank Adaptation (LoRA) fine-tuning has attracted widespread attention from industry and academia because it is simple, efficient, and does not incur any additional reasoning burden. However, most of the existing advanced methods use LoRA to fine-tune Transformer, and there are few studies on using LoRA to fine-tune CNN. The CNN model is widely deployed on IoT devices for application due to its advantages in comprehensive resource occupancy and performance. Moreover, IoT devices are widely deployed outdoors and usually process data affected by the environment (such as fog, snow, rain, etc.). The goal of this paper is to use LoRA technology to efficiently improve the robustness of the CNN model. To this end, this paper first proposes a strong, robust CNN fine-tuning method for IoT devices, LoRA-C, which performs low-rank decomposition in convolutional layers rather than kernel units to reduce the number of fine-tuning parameters. Then, this paper analyzes two different rank settings in detail and observes that the best performance is usually achieved when $\u03b1/{r}$ is a constant in either standard data or corrupted data. This discovery provides experience for the widespread application of LoRA-C. Finally, this paper conducts many experiments based on pre-trained models. Experimental results on CIFAR-10, CIFAR-100, CIFAR-10-C, and Icons50 datasets show that the proposed LoRA-Cs outperforms standard ResNets. Specifically, on the CIFAR-10-C dataset, the accuracy of LoRA-C-ResNet-101 achieves 83.44% accuracy, surpassing the standard ResNet-101 result by +9.5%.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "14 pages, 13 figures"
    },
    {
        "paper id": "2410.16955",
        "abstract url": "https://arxiv.org/abs/2410.16955",
        "title": "PGCS: Physical Law embedded Generative Cloud Synthesis in Remote Sensing Images",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Data quantity and quality are both critical for information extraction and analyzation in remote sensing. However, the current remote sensing datasets often fail to meet these two requirements, for which cloud is a primary factor degrading the data quantity and quality. This limitation affects the precision of results in remote sensing application, particularly those derived from data-driven techniques. In this paper, a physical law embedded generative cloud synthesis method (PGCS) is proposed to generate diverse realistic cloud images to enhance real data and promote the development of algorithms for subsequent tasks, such as cloud correction, cloud detection, and data augmentation for classification, recognition, and segmentation. The PGCS method involves two key phases: spatial synthesis and spectral synthesis. In the spatial synthesis phase, a style-based generative adversarial network is utilized to simulate the spatial characteristics, generating an infinite number of single-channel clouds. In the spectral synthesis phase, the atmospheric scattering law is embedded through a local statistics and global fitting method, converting the single-channel clouds into multi-spectral clouds. The experimental results demonstrate that PGCS achieves a high accuracy in both phases and performs better than three other existing cloud synthesis methods. Two cloud correction methods are developed from PGCS and exhibits a superior performance compared to state-of-the-art methods in the cloud correction task. Furthermore, the application of PGCS with data from various sensors was investigated and successfully extended. Code will be provided at https://github.com/Liying-Xu/PGCS.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "20 pages, 16 figures"
    },
    {
        "paper id": "2410.16964",
        "abstract url": "https://arxiv.org/abs/2410.16964",
        "title": "The Parameterized Complexity Landscape of the Unsplittable Flow Problem",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We study the well-established problem of finding an optimal routing of unsplittable flows in a graph. While by now there is an extensive body of work targeting the problem on graph classes such as paths and trees, we aim at using the parameterized paradigm to identify its boundaries of tractability on general graphs. We develop novel algorithms and lower bounds which result in a full classification of the parameterized complexity of the problem with respect to natural structural parameterizations for the problem -- notably maximum capacity, treewidth, maximum degree, and maximum flow length. In particular, we obtain a fixed-parameter algorithm for the problem when parameterized by all four of these parameters, establish XP-tractability as well as W[1]-hardness with respect to the former three and latter three parameters, and all remaining cases remain paraNP-hard.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "In proceedings of WG 2024, 20 pages (excl. references), 3 figures"
    },
    {
        "paper id": "2410.16981",
        "abstract url": "https://arxiv.org/abs/2410.16981",
        "title": "Proleptic Temporal Ensemble for Improving the Speed of Robot Tasks Generated by Imitation Learning",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Imitation learning, which enables robots to learn behaviors from demonstrations by non-experts, has emerged as a promising solution for generating robot motions in such environments. The imitation learning based robot motion generation method, however, has the drawback of being limited by the demonstrators task execution speed. This paper presents a novel temporal ensemble approach applied to imitation learning algorithms, allowing for execution of future actions. The proposed method leverages existing demonstration data and pretrained policies, offering the advantages of requiring no additional computation and being easy to implement. The algorithms performance was validated through real world experiments involving robotic block color sorting, demonstrating up to 3x increase in task execution speed while maintaining a high success rate compared to the action chunking with transformer method. This study highlights the potential for significantly improving the performance of imitation learning-based policies, which were previously limited by the demonstrator's speed. It is expected to contribute substantially to future advancements in autonomous object manipulation technologies aimed at enhancing productivity.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This paper has been submitted to the Journal of Korea Robotics Society and is currently under review"
    },
    {
        "paper id": "2410.16995",
        "abstract url": "https://arxiv.org/abs/2410.16995",
        "title": "E-3DGS: Gaussian Splatting with Exposure and Motion Events",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Estimating Neural Radiance Fields (NeRFs) from images captured under optimal conditions has been extensively explored in the vision community. However, robotic applications often face challenges such as motion blur, insufficient illumination, and high computational overhead, which adversely affect downstream tasks like navigation, inspection, and scene visualization. To address these challenges, we propose E-3DGS, a novel event-based approach that partitions events into motion (from camera or object movement) and exposure (from camera exposure), using the former to handle fast-motion scenes and using the latter to reconstruct grayscale images for high-quality training and optimization of event-based 3D Gaussian Splatting (3DGS). We introduce a novel integration of 3DGS with exposure events for high-quality reconstruction of explicit scene representations. Our versatile framework can operate on motion events alone for 3D reconstruction, enhance quality using exposure events, or adopt a hybrid mode that balances quality and effectiveness by optimizing with initial exposure events followed by high-speed motion events. We also introduce EME-3D, a real-world 3D dataset with exposure events, motion events, camera calibration parameters, and sparse point clouds. Our method is faster and delivers better reconstruction quality than event-based NeRF while being more cost-effective than NeRF methods that combine event and RGB data by using a single event sensor. By combining motion and exposure events, E-3DGS sets a new benchmark for event-based 3D reconstruction with robust performance in challenging conditions and lower hardware demands. The source code and dataset will be available at https://github.com/MasterHow/E-3DGS.",
        "subjects": [
            "cs.CV",
            "cs.RO",
            "eess.IV"
        ],
        "comment": "The source code and dataset will be available at https://github.com/MasterHow/E-3DGS"
    },
    {
        "paper id": "2410.16997",
        "abstract url": "https://arxiv.org/abs/2410.16997",
        "title": "On Optimal Battery Sizing for Electric Vehicles",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "In this paper, we introduce a quantitative framework to optimize electric vehicle (EV) battery capacities, considering two criteria: upfront vehicle cost and charging inconvenience cost. For this purpose, we (1) develop a comprehensive model for charging inconvenience costs, incorporating both charging time and detours, improving on existing studies, (2) show, through extensive simulations and analytical models, how charging inconvenience cost is affected by different battery capacity and charging infrastructure configurations, (3) introduce an optimisation framework to determine optimal battery capacities based on charging inconvenience and vehicle cost, and (4) show that optimal battery capacities can be influenced by strategic investments in charging infrastructure and tax/incentive policies. The proposed framework provides actionable insights into the sustainable design of EV systems, supporting the development of cost-effective and convenient electric mobility solutions.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17000",
        "abstract url": "https://arxiv.org/abs/2410.17000",
        "title": "Beyond Yao's Millionaires: Secure Multi-Party Computation of Non-Polynomial Functions",
        "rating": "-1",
        "keywords": [
            [
                "federated learning"
            ]
        ],
        "abstract": "In this paper, we present an unconditionally secure $N$-party comparison scheme based on Shamir secret sharing, utilizing the binary representation of private inputs to determine the $\\max$ without disclosing any private inputs or intermediate results. Specifically, each party holds a private number and aims to ascertain the greatest number among the $N$ available private numbers without revealing its input, assuming that there are at most $T < \\frac{N}{2}$ honest-but-curious parties. The proposed scheme demonstrates a lower computational complexity compared to existing schemes that can only compare two secret numbers at a time. To the best of our knowledge, our scheme is the only information-theoretically secure method for comparing $N$ private numbers without revealing either the private inputs or any intermediate results. We demonstrate that by modifying the proposed scheme, we can compute other well-known non-polynomial functions of the inputs, including the minimum, median, and rank. Additionally, in the proposed scheme, before the final reveal phase, each party possesses a share of the result, enabling the nodes to compute any polynomial function of the comparison result. We also explore various applications of the proposed comparison scheme, including federated learning.",
        "subjects": [
            "cs.CR",
            "cs.IT"
        ],
        "comment": "11 pages, 4 figures"
    },
    {
        "paper id": "2410.17002",
        "abstract url": "https://arxiv.org/abs/2410.17002",
        "title": "EFX Allocations and Orientations on Bipartite Multi-graphs: A Complete Picture",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "We consider the fundamental problem of fairly allocating a set of indivisible items among agents having valuations that are represented by a multi-graph -- here, agents appear as the vertices and items as the edges between them and each vertex (agent) only values the set of its incident edges (items). The goal is to find a fair, i.e., envy-free up to any item (EFX) allocation. This model has recently been introduced by Christodoulou et al. (EC'23) where they show that EFX allocations always exist on simple graphs for monotone valuations, i.e., where any two agents can share at most one edge (item). A natural question arises as to what happens when we go beyond simple graphs and study various classes of multi-graphs? We answer the above question affirmatively for the valuation class of bipartite multi-graphs and multi-cycles. Our main positive result is that EFX allocations on bipartite multi-graphs (and multi-cycles) always exist and can be computed in polynomial time for additive valuations. We, therefore, push the frontiers of our understanding of EFX allocations and expand the scenarios where they are known to exist for an arbitrary number of agents. Next, we study EFX orientations (i.e., allocations where every item is allocated to one of its two endpoint agents) and give a complete picture of when they exist for bipartite multi-graphs dependent on two parameters -- the number of edges shared between any two agents and the diameter of the graph. Finally, we prove that it is NP-complete to determine whether a given fair division instance on a bipartite multi-graph admits an EFX orientation.",
        "subjects": [
            "cs.GT",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17006",
        "abstract url": "https://arxiv.org/abs/2410.17006",
        "title": "Variational autoencoders stabilise TCN performance when classifying weakly labelled bioacoustics data",
        "rating": "-1",
        "keywords": [
            [
                "bioacoustics"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Passive acoustic monitoring (PAM) data is often weakly labelled, audited at the scale of detection presence or absence on timescales of minutes to hours. Moreover, this data exhibits great variability from one deployment to the next, due to differences in ambient noise and the signals across sources and geographies. This study proposes a two-step solution to leverage weakly annotated data for training Deep Learning (DL) detection models. Our case study involves binary classification of the presence/absence of sperm whale (\\textit{Physeter macrocephalus}) click trains in 4-minute-long recordings from a dataset comprising diverse sources and deployment conditions to maximise generalisability. We tested methods for extracting acoustic features from lengthy audio segments and integrated Temporal Convolutional Networks (TCNs) trained on the extracted features for sequence classification. For feature extraction, we introduced a new approach using Variational AutoEncoders (VAEs) to extract information from both waveforms and spectrograms, which eliminates the necessity for manual threshold setting or time-consuming strong labelling. For classification, TCNs were trained separately on sequences of either VAE embeddings or handpicked acoustic features extracted from the waveform and spectrogram representations using classical methods, to compare the efficacy of the two approaches. The TCN demonstrated robust classification capabilities on a validation set, achieving accuracies exceeding 85\\% when applied to 4-minute acoustic recordings. Notably, TCNs trained on handpicked acoustic features exhibited greater variability in performance across recordings from diverse deployment conditions, whereas those trained on VAEs showed a more consistent performance, highlighting the robust transferability of VAEs for feature extraction across different deployment conditions.",
        "subjects": [
            "cs.SD",
            "eess.AS",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17052",
        "abstract url": "https://arxiv.org/abs/2410.17052",
        "title": "On the Vulnerability of Text Sanitization",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "Text sanitization, which employs differential privacy to replace sensitive tokens with new ones, represents a significant technique for privacy protection. Typically, its performance in preserving privacy is evaluated by measuring the attack success rate (ASR) of reconstruction attacks, where attackers attempt to recover the original tokens from the sanitized ones. However, current reconstruction attacks on text sanitization are developed empirically, making it challenging to accurately assess the effectiveness of sanitization. In this paper, we aim to provide a more accurate evaluation of sanitization effectiveness. Inspired by the works of Palamidessi et al., we implement theoretically optimal reconstruction attacks targeting text sanitization. We derive their bounds on ASR as benchmarks for evaluating sanitization performance. For real-world applications, we propose two practical reconstruction attacks based on these theoretical findings. Our experimental results underscore the necessity of reassessing these overlooked risks. Notably, one of our attacks achieves a 46.4% improvement in ASR over the state-of-the-art baseline, with a privacy budget of epsilon=4.0 on the SST-2 dataset. Our code is available at: https://github.com/mengtong0110/On-the-Vulnerability-of-Text-Sanitization.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17058",
        "abstract url": "https://arxiv.org/abs/2410.17058",
        "title": "Optimal gait design for nonlinear soft robotic crawlers",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "Soft robots offer a frontier in robotics with enormous potential for safe human-robot interaction and agility in uncertain environments. A steppingstone towards unlocking the potential of soft robotics is a tailored control theory, including a principled framework for gait design. We analyze the problem of optimal gait design for a soft crawling body, \"the crawler\". The crawler is an elastic body with the control signal defined as actuation forces between segments of the body. We consider the simplest such crawler: a two-segmented body with a passive mechanical connection modeling the viscoelastic body dynamics and a symmetric control force modeling actuation between the two body segments. The model accounts for the nonlinear asymmetric friction with the ground, which together with the symmetric actuation forces enable the crawler's locomotion. Using a describing-function analysis, we show that when the body is forced sinusoidally, the optimal actuator contraction frequency corresponds to the body's natural frequency when operating with only passive dynamics. We then use the framework of Optimal Periodic Control (OPC) to design optimal force cycles of arbitrary waveform and the corresponding crawling gaits. We provide a hill-climbing algorithm to solve the OPC problem numerically. Our proposed methods and results inform the design of optimal forcing and gaits for more complex and multi-segmented crawling bodies.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17081",
        "abstract url": "https://arxiv.org/abs/2410.17081",
        "title": "Continuous Speech Tokenizer in Text To Speech",
        "rating": "-1",
        "keywords": [
            [
                "Text To Speech"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "The fusion of speech and language in the era of large language models has garnered significant attention. Discrete speech token is often utilized in text-to-speech tasks for speech compression and portability, which is convenient for joint training with text and have good compression efficiency. However, we found that the discrete speech tokenizer still suffers from information loss. Therefore, we propose a simple yet effective continuous speech tokenizer and a text-to-speech model based on continuous speech tokens. Our results show that the speech language model based on the continuous speech tokenizer has better continuity and higher estimated Mean Opinion Scores (MoS). This enhancement is attributed to better information preservation rate of the continuous speech tokenizer across both low and high frequencies in the frequency domain.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": "4 pages. Under review"
    },
    {
        "paper id": "2410.17116",
        "abstract url": "https://arxiv.org/abs/2410.17116",
        "title": "Security and RAS in the Computing Continuum",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "Security and RAS are two non-functional requirements under focus for current systems developed for the computing continuum. Due to the increased number of interconnected computer systems across the continuum, security becomes especially pervasive at all levels, from the smallest edge device to the high-performance cloud at the other end. Similarly, RAS (Reliability, Availability, and Serviceability) ensures the robustness of a system towards hardware defects. Namely, making them reliable, with high availability and design for easy service. In this paper and as a result of the Vitamin-V EU project, the authors detail the comprehensive approach to malware and hardware attack detection; as well as, the RAS features envisioned for future systems across the computing continuum.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17179",
        "abstract url": "https://arxiv.org/abs/2410.17179",
        "title": "Faster Approximation Algorithms for Restricted Shortest Paths in Directed Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "In the restricted shortest paths problem, we are given a graph $G$ whose edges are assigned two non-negative weights: lengths and delays, a source $s$, and a delay threshold $D$. The goal is to find, for each target $t$, the length of the shortest $(s,t)$-path whose total delay is at most $D$. While this problem is known to be NP-hard [Garey and Johnson, 1979] $(1+\\varepsilon)$-approximate algorithms running in $\\tilde{O}(mn)$ time [Goel et al., INFOCOM'01; Lorenz and Raz, Oper. Res. Lett.'01] given more than twenty years ago have remained the state-of-the-art for directed graphs. An open problem posed by [Bernstein, SODA'12] -- who gave a randomized $m\\cdot n^{o(1)}$ time bicriteria $(1+\\varepsilon, 1+\\varepsilon)$-approximation algorithm for undirected graphs -- asks if there is similarly an $o(mn)$ time approximation scheme for directed graphs. We show two randomized bicriteria $(1+\\varepsilon, 1+\\varepsilon)$-approximation algorithms that give an affirmative answer to the problem: one suited to dense graphs, and the other that works better for sparse graphs. On directed graphs with a quasi-polynomial weights aspect ratio, our algorithms run in time $\\tilde{O}(n^2)$ and $\\tilde{O}(mn^{3/5})$ or better, respectively. More specifically, the algorithm for sparse digraphs runs in time $\\tilde{O}(mn^{(3 - \u03b1)/5})$ for graphs with $n^{1 + \u03b1}$ edges for any real $\u03b1\\in [0,1/2]$.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "To appear in SODA 2025"
    },
    {
        "paper id": "2410.17183",
        "abstract url": "https://arxiv.org/abs/2410.17183",
        "title": "Risk-Averse Model Predictive Control for Racing in Adverse Conditions",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Model predictive control (MPC) algorithms can be sensitive to model mismatch when used in challenging nonlinear control tasks. In particular, the performance of MPC for vehicle control at the limits of handling suffers when the underlying model overestimates the vehicle's capabilities. In this work, we propose a risk-averse MPC framework that explicitly accounts for uncertainty over friction limits and tire parameters. Our approach leverages a sample-based approximation of an optimal control problem with a conditional value at risk (CVaR) constraint. This sample-based formulation enables planning with a set of expressive vehicle dynamics models using different tire parameters. Moreover, this formulation enables efficient numerical resolution via sequential quadratic programming and GPU parallelization. Experiments on a Lexus LC 500 show that risk-averse MPC unlocks reliable performance, while a deterministic baseline that plans using a single dynamics model may lose control of the vehicle in adverse road conditions.",
        "subjects": [
            "cs.RO",
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17188",
        "abstract url": "https://arxiv.org/abs/2410.17188",
        "title": "Minimum-Violation Temporal Logic Planning for Heterogeneous Robots under Robot Skill Failures",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "In this paper, we consider teams of robots with heterogeneous skills (e.g., sensing and manipulation) tasked with collaborative missions described by Linear Temporal Logic (LTL) formulas. These LTL-encoded tasks require robots to apply their skills to specific regions and objects in a temporal and logical order. While existing temporal logic planning algorithms can synthesize correct-by-construction paths, they typically lack reactivity to unexpected failures of robot skills, which can compromise mission performance. This paper addresses this challenge by proposing a reactive LTL planning algorithm that adapts to unexpected failures during deployment. Specifically, the proposed algorithm reassigns sub-tasks to robots based on their functioning skills and locally revises team plans to accommodate these new assignments and ensure mission completion. The main novelty of the proposed algorithm is its ability to handle cases where mission completion becomes impossible due to limited functioning robots. Instead of reporting mission failure, the algorithm strategically prioritizes the most crucial sub-tasks and locally revises the team's plans, as per user-specified priorities, to minimize mission violations. We provide theoretical conditions under which the proposed framework computes the minimum violation task reassignments and team plans. We provide numerical and hardware experiments to demonstrate the efficiency of the proposed method.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17209",
        "abstract url": "https://arxiv.org/abs/2410.17209",
        "title": "Audio-to-Score Conversion Model Based on Whisper methodology",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This thesis develops a Transformer model based on Whisper, which extracts melodies and chords from music audio and records them into ABC notation. A comprehensive data processing workflow is customized for ABC notation, including data cleansing, formatting, and conversion, and a mutation mechanism is implemented to increase the diversity and quality of training data. This thesis innovatively introduces the \"Orpheus' Score\", a custom notation system that converts music information into tokens, designs a custom vocabulary library, and trains a corresponding custom tokenizer. Experiments show that compared to traditional algorithms, the model has significantly improved accuracy and performance. While providing a convenient audio-to-score tool for music enthusiasts, this work also provides new ideas and tools for research in music information processing.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "5 pages, 7 figures"
    },
    {
        "paper id": "2410.17226",
        "abstract url": "https://arxiv.org/abs/2410.17226",
        "title": "Parallel Cluster-BFS and Applications to Shortest Paths",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Breadth-first Search (BFS) is one of the most important graph processing subroutines, especially for computing the unweighted distance. Many applications may require running BFS from multiple sources. Sequentially, when running BFS on a cluster of nearby vertices, a known optimization is using bit-parallelism. Given a subset of vertices with size $k$ and the distance between any pair of them is no more than $d$, BFS can be applied to all of them in total work $O(dm(k/w+1))$, where $w$ is the length of a word in bits and $m$ is the number of edges. We will refer to this approach as cluster-BFS (C-BFS). Such an approach has been studied and shown effective both in theory and in practice in the sequential setting. However, it remains unknown how this can be combined with thread-level parallelism. In this paper, we focus on designing efficient parallel C-BFS based on BFS to answer unweighted distance queries. Our solution combines the strengths of bit-level parallelism and thread-level parallelism, and achieves significant speedup over the plain sequential solution. We also apply our algorithm to real-world applications. In particular, we identified another application (landmark-labeling for the approximate distance oracle) that can take advantage of parallel C-BFS. Under the same memory budget, our new solution improves accuracy and/or time on all the 18 tested graphs.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17235",
        "abstract url": "https://arxiv.org/abs/2410.17235",
        "title": "Automated Spinal MRI Labelling from Reports Using a Large Language Model",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "cancer",
                "radiology"
            ],
            [
                "cs.CV",
                "eess.IV",
                "cs.CL"
            ]
        ],
        "abstract": "We propose a general pipeline to automate the extraction of labels from radiology reports using large language models, which we validate on spinal MRI reports. The efficacy of our labelling method is measured on five distinct conditions: spinal cancer, stenosis, spondylolisthesis, cauda equina compression and herniation. Using open-source models, our method equals or surpasses GPT-4 on a held-out set of reports. Furthermore, we show that the extracted labels can be used to train imaging models to classify the identified conditions in the accompanying MR scans. All classifiers trained using automated labels achieve comparable performance to models trained using scans manually annotated by clinicians. Code can be found at https://github.com/robinyjpark/AutoLabelClassifier.",
        "subjects": [
            "eess.IV",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "Accepted to Medical Image Computing and Computer Assisted Intervention (MICCAI 2024, Spotlight). 11 pages plus appendix"
    },
    {
        "paper id": "2410.17357",
        "abstract url": "https://arxiv.org/abs/2410.17357",
        "title": "Image-aware Evaluation of Generated Medical Reports",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "diagnosis",
                "X-ray",
                "clinical",
                "radiology"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The paper proposes a novel evaluation metric for automatic medical report generation from X-ray images, VLScore. It aims to overcome the limitations of existing evaluation methods, which either focus solely on textual similarities, ignoring clinical aspects, or concentrate only on a single clinical aspect, the pathology, neglecting all other factors. The key idea of our metric is to measure the similarity between radiology reports while considering the corresponding image. We demonstrate the benefit of our metric through evaluation on a dataset where radiologists marked errors in pairs of reports, showing notable alignment with radiologists' judgments. In addition, we provide a new dataset for evaluating metrics. This dataset includes well-designed perturbations that distinguish between significant modifications (e.g., removal of a diagnosis) and insignificant ones. It highlights the weaknesses in current evaluation metrics and provides a clear framework for analysis.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17396",
        "abstract url": "https://arxiv.org/abs/2410.17396",
        "title": "Efficient Feature Extraction Using Light-Weight CNN Attention-Based Deep Learning Architectures for Ultrasound Fetal Plane Classification",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Ultrasound fetal imaging is beneficial to support prenatal development because it is affordable and non-intrusive. Nevertheless, fetal plane classification (FPC) remains challenging and time-consuming for obstetricians since it depends on nuanced clinical aspects, which increases the difficulty in identifying relevant features of the fetal anatomy. Thus, to assist with its accurate feature extraction, a lightweight artificial intelligence architecture leveraging convolutional neural networks and attention mechanisms is proposed to classify the largest benchmark ultrasound dataset. The approach fine-tunes from lightweight EfficientNet feature extraction backbones pre-trained on the ImageNet1k. to classify key fetal planes such as the brain, femur, thorax, cervix, and abdomen. Our methodology incorporates the attention mechanism to refine features and 3-layer perceptrons for classification, achieving superior performance with the highest Top-1 accuracy of 96.25%, Top-2 accuracy of 99.80% and F1-Score of 0.9576. Importantly, the model has 40x fewer trainable parameters than existing benchmark ensemble or transformer pipelines, facilitating easy deployment on edge devices to help clinical practitioners with real-time FPC. The findings are also interpreted using GradCAM to carry out clinical correlation to aid doctors with diagnostics and improve treatment plans for expectant mothers.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Submitted to Computers in Biology and Medicine journal"
    },
    {
        "paper id": "2410.17400",
        "abstract url": "https://arxiv.org/abs/2410.17400",
        "title": "Discogs-VI: A Musical Version Identification Dataset Based on Public Editorial Metadata",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Current version identification (VI) datasets often lack sufficient size and musical diversity to train robust neural networks (NNs). Additionally, their non-representative clique size distributions prevent realistic system evaluations. To address these challenges, we explore the untapped potential of the rich editorial metadata in the Discogs music database and create a large dataset of musical versions containing about 1,900,000 versions across 348,000 cliques. Utilizing a high-precision search algorithm, we map this dataset to official music uploads on YouTube, resulting in a dataset of approximately 493,000 versions across 98,000 cliques. This dataset offers over nine times the number of cliques and over four times the number of versions than existing datasets. We demonstrate the utility of our dataset by training a baseline NN without extensive model complexities or data augmentations, which achieves competitive results on the SHS100K and Da-TACOS datasets. Our dataset, along with the tools used for its creation, the extracted audio features, and a trained model, are all publicly available online.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17402",
        "abstract url": "https://arxiv.org/abs/2410.17402",
        "title": "Invisible Manipulation Deep Reinforcement Learning Enhanced Stealthy Attacks on Battery Energy Management Systems",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "This paper introduces \"invisible manipulation,\" an innovative cyber-attack mechanism achieved through strategically timed stealthy false data injection attacks (SFDIAs). By stealthily manipulating measurements of a critical asset prior to the target time period, the attacker can subtly guide the engineering system toward a predetermined operational state without detection. Using the battery energy management system (BEMS) as a case study, we employ deep reinforcement learning (DRL) to generate synthetic measurements, such as battery voltage and current, that align closely with actual measurements. These synthetic measurements, falling within the acceptable error margin of residual-based bad data detection algorithm provided by state estimation, can evade detection and mislead Extended Kalman-filter-based State of Charge estimation. Subsequently, considering the deceptive data as valid inputs, the BEMS will operate the BESS towards the attacker desired operational states when the targeted time period come. The use of the DRL-based scheme allows us to covert an online optimization problem into an offline training process, thereby alleviating the computational burden for real-time implementation. Comprehensive testing on a high-fidelity microgrid real-time simulation testbed validates the effectiveness and adaptability of the proposed methods in achieving different attack objectives.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17403",
        "abstract url": "https://arxiv.org/abs/2410.17403",
        "title": "A Polylogarithmic Approximation for Directed Steiner Forest in Planar Digraphs",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We consider Directed Steiner Forest (DSF), a fundamental problem in network design. The input to DSF is a directed edge-weighted graph $G = (V, E)$ and a collection of vertex pairs $\\{(s_i, t_i)\\}_{i \\in [k]}$. The goal is to find a minimum cost subgraph $H$ of $G$ such that $H$ contains an $s_i$-$t_i$ path for each $i \\in [k]$. DSF is NP-Hard and is known to be hard to approximate to a factor of $\u03a9(2^{\\log^{1 - \u03b5}(n)})$ for any fixed $\u03b5> 0$ [DK'99]. DSF admits approximation ratios of $O(k^{1/2 + \u03b5})$ [CEGS'11] and $O(n^{2/3 + \u03b5})$ [BBMRY'13]. In this work we show that in planar digraphs, an important and useful class of graphs in both theory and practice, DSF is much more tractable. We obtain an $O(\\log^6 k)$-approximation algorithm via the junction tree technique. Our main technical contribution is to prove the existence of a low density junction tree in planar digraphs. To find an approximate junction tree we rely on recent results on rooted directed network design problems [FM'23, CJKZZ'24], in particular, on an LP-based algorithm for the Directed Steiner Tree problem [CJKZZ'24]. Our work and several other recent ones on algorithms for planar digraphs [FM'23, KS'21, CJKZZ'24] are built upon structural insights on planar graph reachability and shortest path separators [Thorup'04].",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17404",
        "abstract url": "https://arxiv.org/abs/2410.17404",
        "title": "Deep Learning Aided Broadcast Codes with Feedback",
        "rating": "-1",
        "keywords": [
            [
                "federated learning"
            ]
        ],
        "abstract": "Deep learning aided codes have been shown to improve code performance in feedback codes in high noise regimes due to the ability to leverage non-linearity in code design. In the additive white Gaussian broadcast channel (AWGN-BC), the addition of feedback may allow the capacity region to extend far beyond the capacity region of the channel without feedback, enabling higher data rates. On the other hand, there are limited deep-learning aided implementations of broadcast codes. In this work, we extend two classes of deep-learning assisted feedback codes to the AWGN-BC channel; the first being an RNN-based architecture and the second being a lightweight MLP-based architecture. Both codes are trained using a global model, and then they are trained using a more realistic vertical federated learning based framework. We first show that in most cases, using an AWGN-BC code outperforms a linear-based concatenated scheme. Second, we show in some regimes, the lightweight architecture far exceeds the RNN-based code, but in especially unreliable conditions, the RNN-based code dominates. The results show the promise of deep-learning aided broadcast codes in unreliable channels, and future research directions are discussed.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17422",
        "abstract url": "https://arxiv.org/abs/2410.17422",
        "title": "AG-SLAM: Active Gaussian Splatting SLAM",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "trajectory",
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present AG-SLAM, the first active SLAM system utilizing 3D Gaussian Splatting (3DGS) for online scene reconstruction. In recent years, radiance field scene representations, including 3DGS have been widely used in SLAM and exploration, but actively planning trajectories for robotic exploration is still unvisited. In particular, many exploration methods assume precise localization and thus do not mitigate the significant risk of constructing a trajectory, which is difficult for a SLAM system to operate on. This can cause camera tracking failure and lead to failures in real-world robotic applications. Our method leverages Fisher Information to balance the dual objectives of maximizing the information gain for the environment while minimizing the cost of localization errors. Experiments conducted on the Gibson and Habitat-Matterport 3D datasets demonstrate state-of-the-art results of the proposed method.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17445",
        "abstract url": "https://arxiv.org/abs/2410.17445",
        "title": "Guaranteeing Conservation Laws with Projection in Physics-Informed Neural Networks",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Physics-informed neural networks (PINNs) incorporate physical laws into their training to efficiently solve partial differential equations (PDEs) with minimal data. However, PINNs fail to guarantee adherence to conservation laws, which are also important to consider in modeling physical systems. To address this, we proposed PINN-Proj, a PINN-based model that uses a novel projection method to enforce conservation laws. We found that PINN-Proj substantially outperformed PINN in conserving momentum and lowered prediction error by three to four orders of magnitude from the best benchmark tested. PINN-Proj also performed marginally better in the separate task of state prediction on three PDE datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to NeurIPS 2024 Workshop on Data-driven and Differentiable Simulations, Surrogates, and Solvers"
    },
    {
        "paper id": "2410.17453",
        "abstract url": "https://arxiv.org/abs/2410.17453",
        "title": "Configura\u00e7\u00e3o e opera\u00e7\u00e3o da plataforma Clearpath Husky A200 e manipulador Cobot UR5 2-finger gripper",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "This article presents initial configuration work and use of the robotic platform and manipulator in question. The development of the ideal configuration for using this robot serves as a guide for new users and also validates its functionality for use in projects. Husky is a large payload capacity and power systems robotics development platform that accommodates a wide variety of payloads, customized to meet research needs. Together with the Cobot UR5 Manipulator attached to its base, it expands the application area of its capacity in projects. Advances in robots and mobile manipulators have revolutionized industries by automating tasks that previously required human intervention. These innovations alone increase productivity but also reduce operating costs, which makes the company more competitive in an evolving global market. Therefore, this article investigates the functionalities of this robot to validate its execution in robotics projects.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "in Portuguese language"
    },
    {
        "paper id": "2410.17462",
        "abstract url": "https://arxiv.org/abs/2410.17462",
        "title": "Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Time series data is ubiquitous across various domains, including manufacturing, finance, and healthcare. High-quality annotations are essential for effectively understanding time series and facilitating downstream tasks; however, obtaining such annotations is challenging, particularly in mission-critical domains. In this paper, we propose TESSA, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data. TESSA introduces two agents: a general annotation agent and a domain-specific annotation agent. The general agent captures common patterns and knowledge across multiple source domains, leveraging both time-series-wise and text-wise features to generate general annotations. Meanwhile, the domain-specific agent utilizes limited annotations from the target domain to learn domain-specific terminology and generate targeted annotations. Extensive experiments on multiple synthetic and real-world datasets demonstrate that TESSA effectively generates high-quality annotations, outperforming existing methods.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "23 pages, 9 figures, 24 tables"
    },
    {
        "paper id": "2410.17491",
        "abstract url": "https://arxiv.org/abs/2410.17491",
        "title": "X-MOBILITY: End-To-End Generalizable Navigation via World Modeling",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "Navigation"
            ]
        ],
        "abstract": "General-purpose navigation in challenging environments remains a significant problem in robotics, with current state-of-the-art approaches facing myriad limitations. Classical approaches struggle with cluttered settings and require extensive tuning, while learning-based methods face difficulties generalizing to out-of-distribution environments. This paper introduces X-Mobility, an end-to-end generalizable navigation model that overcomes existing challenges by leveraging three key ideas. First, X-Mobility employs an auto-regressive world modeling architecture with a latent state space to capture world dynamics. Second, a diverse set of multi-head decoders enables the model to learn a rich state representation that correlates strongly with effective navigation skills. Third, by decoupling world modeling from action policy, our architecture can train effectively on a variety of data sources, both with and without expert policies: off-policy data allows the model to learn world dynamics, while on-policy data with supervisory control enables optimal action policy learning. Through extensive experiments, we demonstrate that X-Mobility not only generalizes effectively but also surpasses current state-of-the-art navigation approaches. Additionally, X-Mobility also achieves zero-shot Sim2Real transferability and shows strong potential for cross-embodiment generalization.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17502",
        "abstract url": "https://arxiv.org/abs/2410.17502",
        "title": "Bilateral Hippocampi Segmentation in Low Field MRIs Using Mutual Feature Learning via Dual-Views",
        "rating": "-1",
        "keywords": [
            [
                "BioNet",
                "healthcare",
                "diagnosing",
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Accurate hippocampus segmentation in brain MRI is critical for studying cognitive and memory functions and diagnosing neurodevelopmental disorders. While high-field MRIs provide detailed imaging, low-field MRIs are more accessible and cost-effective, which eliminates the need for sedation in children, though they often suffer from lower image quality. In this paper, we present a novel deep-learning approach for the automatic segmentation of bilateral hippocampi in low-field MRIs. Extending recent advancements in infant brain segmentation to underserved communities through the use of low-field MRIs ensures broader access to essential diagnostic tools, thereby supporting better healthcare outcomes for all children. Inspired by our previous work, Co-BioNet, the proposed model employs a dual-view structure to enable mutual feature learning via high-frequency masking, enhancing segmentation accuracy by leveraging complementary information from different perspectives. Extensive experiments demonstrate that our method provides reliable segmentation outcomes for hippocampal analysis in low-resource settings. The code is publicly available at: https://github.com/himashi92/LoFiHippSeg.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17508",
        "abstract url": "https://arxiv.org/abs/2410.17508",
        "title": "Validating a PTAS for Triangle-Free 2-Matching via a Simple Decomposition Theorem",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A triangle-free (simple) 2-matching is an edge set that has at most $2$ edges incident to each vertex and contains no cycle of length $3$. For the problem of finding a maximum cardinality triangle-free 2-matching in a given graph, a complicated exact algorithm was proposed by Hartvigsen. Recently, a simple PTAS using local search was presented by Bosch-Calvo, Grandoni, and Ameli, but its validity proof is not easy. In this paper, we show a natural and simple decomposition theorem for triangle-free 2-matchings, which leads to a simpler validity proof of the PTAS for the problem.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17524",
        "abstract url": "https://arxiv.org/abs/2410.17524",
        "title": "Mechanisms and Computational Design of Multi-Modal End-Effector with Force Sensing using Gated Networks",
        "rating": "-1",
        "keywords": [
            [
                "robotics"
            ]
        ],
        "abstract": "In limbed robotics, end-effectors must serve dual functions, such as both feet for locomotion and grippers for grasping, which presents design challenges. This paper introduces a multi-modal end-effector capable of transitioning between flat and line foot configurations while providing grasping capabilities. MAGPIE integrates 8-axis force sensing using proposed mechanisms with hall effect sensors, enabling both contact and tactile force measurements. We present a computational design framework for our sensing mechanism that accounts for noise and interference, allowing for desired sensitivity and force ranges and generating ideal inverse models. The hardware implementation of MAGPIE is validated through experiments, demonstrating its capability as a foot and verifying the performance of the sensing mechanisms, ideal models, and gated network-based models.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17532",
        "abstract url": "https://arxiv.org/abs/2410.17532",
        "title": "Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Multilingual Large Language Models (MLLMs) represent a pivotal advancement in democratizing artificial intelligence across linguistic boundaries. While theoretical foundations are well-established, practical implementation guidelines remain scattered. This work bridges this gap by providing a comprehensive end-to-end framework for developing and deploying MLLMs in production environments. We make three distinctive contributions: First, we present an actionable pipeline from data pre-processing through deployment, integrating insights from academic research and industrial applications. Second, using Llama2 as a case study, we provide detailed optimization strategies for enhancing multilingual capabilities, including curriculum learning approaches for balancing high-resource and low-resource languages, tokenization strategies, and effective sampling methods. Third, we offer an interdisciplinary analysis that considers technical, linguistic, and cultural perspectives in MLLM development. Our findings reveal critical challenges in supporting linguistic diversity, with 88.38% of world languages categorized as low-resource, affecting over a billion speakers. We examine practical solutions through real-world applications in customer service, search engines, and machine translation. By synthesizing theoretical frameworks with production-ready implementation strategies, this survey provides essential guidance for practitioners and researchers working to develop more inclusive and effective multilingual AI systems.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17542",
        "abstract url": "https://arxiv.org/abs/2410.17542",
        "title": "Collision-free Exploration by Mobile Agents Using Pebbles",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper, we study collision-free graph exploration in an anonymous pot labeled network. Two identical mobile agents, starting from different nodes in $G$ have to explore the nodes of $G$ in such a way that for every node $v$ in $G$, at least one mobile agent visits $v$ and no two agents are in the same node in any round and stop. The agents know the size of the graph but do not know its topology. If an agent arrives in the one-hop neighborhood of the other agent, both agents can detect the presence of the other agent but have no idea at which neighboring node the other agent resides. The agents may wake up in different rounds An agent, after waking up, has no knowledge about the wake-up time of the other agent. We study the problem of collision-free exploration where some pebbles are placed by an Oracle at the nodes of the graph to assist the agents in achieving collision-free exploration. The Oracle knows the graph, the starting positions of the agents, and their wake-up schedule, and it places some pebbles that may be of different colors, at most one at each node. The number of different colors of the pebbles placed by the Oracle is called the {\\it color index} of the corresponding pebble placement algorithm. The central question we study is as follows: \"What is the minimum number $z$ such that there exists a collision-free exploration of a given graph with pebble placement of color index $z$?\" For general graphs, we show that it is impossible to design an algorithm that achieves collision-free exploration with color index 1. We propose an exploration algorithm with color index 3. We also proposed a polynomial exploration algorithm for bipartite graphs with color index 2.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17543",
        "abstract url": "https://arxiv.org/abs/2410.17543",
        "title": "Unsupervised Low-dose CT Reconstruction with One-way Conditional Normalizing Flows",
        "rating": "-1",
        "keywords": [
            [
                "CT",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Deep-learning methods have shown promising performance for low-dose computed tomography (LDCT) reconstruction. However, supervised methods face the problem of lacking labeled data in clinical scenarios, and the CNN-based unsupervised denoising methods would cause excessive smoothing in the reconstructed image. Recently, the normalizing flows (NFs) based methods have shown advantages in producing detail-rich images and avoiding over-smoothing, however, there are still issues: (1) Although the alternating optimization in the data and latent space can well utilize the regularization and generation capabilities of NFs, the current two-way transformation strategy of noisy images and latent variables would cause detail loss and secondary artifacts; and (2) Training NFs on high-resolution CT images is hard due to huge computation. Though using conditional normalizing flows (CNFs) to learn conditional probability can reduce the computational burden, current methods require labeled data for conditionalization, and the unsupervised CNFs-based LDCT reconstruction remains a problem. To tackle these problems, we propose a novel CNFs-based unsupervised LDCT iterative reconstruction algorithm. It employs strict one-way transformation when performing alternating optimization in the dual spaces, thus effectively avoiding the problems of detail loss and secondary artifacts. By proposing a novel unsupervised conditionalization strategy, we train CNFs on high-resolution CT images, thus achieving fast and high-quality unsupervised reconstruction. Experiments on different datasets suggest that the performance of the proposed algorithm could surpass some state-of-the-art unsupervised and even supervised methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17553",
        "abstract url": "https://arxiv.org/abs/2410.17553",
        "title": "Electric Grid Topology and Admittance Estimation: Quantifying Phasor-based Measurement Requirements",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In this paper, we quantify voltage and current phasor-based measurement requirements for the unique identification of the electric grid topology and admittance parameters. Our approach is underpinned by the concept of a rigidity matrix that has been extensively studied in graph rigidity theory. Specifically, we show that the rank of the rigidity matrix is the same as that of a voltage coefficient matrix in a corresponding electric power system. Accordingly, we show that there is a minimum number of measurements required to uniquely identify the admittance matrix and corresponding grid topology. By means of a numerical example on the IEEE 4-node radial network, we demonstrate that our approach is suitable for applications in electric power grids.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17557",
        "abstract url": "https://arxiv.org/abs/2410.17557",
        "title": "BlurryScope: a cost-effective and compact scanning microscope for automated HER2 scoring using deep learning on blurry image data",
        "rating": "-1",
        "keywords": [
            [
                "cancer",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We developed a rapid scanning optical microscope, termed \"BlurryScope\", that leverages continuous image acquisition and deep learning to provide a cost-effective and compact solution for automated inspection and analysis of tissue sections. BlurryScope integrates specialized hardware with a neural network-based model to quickly process motion-blurred histological images and perform automated pathology classification. This device offers comparable speed to commercial digital pathology scanners, but at a significantly lower price point and smaller size/weight, making it ideal for fast triaging in small clinics, as well as for resource-limited settings. To demonstrate the proof-of-concept of BlurryScope, we implemented automated classification of human epidermal growth factor receptor 2 (HER2) scores on immunohistochemically (IHC) stained breast tissue sections, achieving concordant results with those obtained from a high-end digital scanning microscope. We evaluated this approach by scanning HER2-stained tissue microarrays (TMAs) at a continuous speed of 5 mm/s, which introduces bidirectional motion blur artifacts. These compromised images were then used to train our network models. Using a test set of 284 unique patient cores, we achieved blind testing accuracies of 79.3% and 89.7% for 4-class (0, 1+, 2+, 3+) and 2-class (0/1+ , 2+/3+) HER2 score classification, respectively. BlurryScope automates the entire workflow, from image scanning to stitching and cropping of regions of interest, as well as HER2 score classification. We believe BlurryScope has the potential to enhance the current pathology infrastructure in resource-scarce environments, save diagnostician time and bolster cancer identification and classification across various clinical environments.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "physics.med-ph"
        ],
        "comment": "18 Pages, 6 Figures"
    },
    {
        "paper id": "2410.18151",
        "abstract url": "https://arxiv.org/abs/2410.18151",
        "title": "Music102: An $D_{12}$-equivariant transformer for chord progression accompaniment",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We present Music102, an advanced model built upon the Music101 prototype, aimed at enhancing chord progression accompaniment through a D12-equivariant transformer. Inspired by group theory and symbolic music structures, Music102 leverages musical symmetry--such as transposition and reflection operations--integrating these properties into the transformer architecture. By encoding prior music knowledge, the model maintains equivariance across both melody and chord sequences. The POP909 dataset was employed to train and evaluate Music102, revealing significant improvements over Music101 in both weighted loss and exact accuracy metrics, despite using fewer parameters. This work showcases the adaptability of self-attention mechanisms and layer normalization to the discrete musical domain, addressing challenges in computational music analysis. With its stable and flexible neural framework, Music102 sets the stage for further exploration in equivariant music generation and computational composition tools, bridging mathematical theory with practical music performance.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "cs.MM",
            "eess.AS"
        ],
        "comment": "10 pages, 3 figures"
    },
    {
        "paper id": "2410.21304",
        "abstract url": "https://arxiv.org/abs/2410.21304",
        "title": "VideoSAM: A Large Vision Foundation Model for High-Speed Video Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "High-speed video (HSV) segmentation is essential for analyzing dynamic physical processes in scientific and industrial applications, such as boiling heat transfer. Existing models like U-Net struggle with generalization and accurately segmenting complex bubble formations. We present VideoSAM, a specialized adaptation of the Segment Anything Model (SAM), fine-tuned on a diverse HSV dataset for phase detection. Through diverse experiments, VideoSAM demonstrates superior performance across four fluid environments -- Water, FC-72, Nitrogen, and Argon -- significantly outperforming U-Net in complex segmentation tasks. In addition to introducing VideoSAM, we contribute an open-source HSV segmentation dataset designed for phase detection, enabling future research in this domain. Our findings underscore VideoSAM's potential to set new standards in robust and accurate HSV segmentation. The code and dataset used in this study are available online at https://github.com/chikap421/videosam .",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Under Review in IEEE SSD 2025"
    },
    {
        "paper id": "2411.03326",
        "abstract url": "https://arxiv.org/abs/2411.03326",
        "title": "xApp-Level Conflict Mitigation in O-RAN, a Mobility Driven Energy Saving Case",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "This paper investigates the emerging challenges of conflict detection and mitigation in Open Radio Access Network (O-RAN). Conflicts between xApps can arise that affect network performance and stability due to the disaggregated nature of O-RAN. This work provides a detailed theoretical framework of Extended Application (xApp)-level conflicts, i.e., direct, indirect, and implicit conflicts. Leveraging conflict graphs, we further highlight how conflicts impact Key Performance Indicators (KPIs) and explore strategies for conflict detection using Service Level Agreements (SLAs) and Quality of Service (QoS) thresholds. We evaluate the effectiveness of several mitigation strategies in a simulated environment with Mobility Robustness Optimization (MRO) and Energy Saving (ES) xApps and present experimental results showing comparisons among these strategies. The findings of this research provide significant insights for enhancing O-RAN deployments with flexible and efficient conflict management.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16700",
        "abstract url": "https://arxiv.org/abs/2410.16700",
        "title": "AskBeacon -- Performing genomic data exchange and analytics with natural language",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Enabling clinicians and researchers to directly interact with global genomic data resources by removing technological barriers is vital for medical genomics. AskBeacon enables Large Language Models to be applied to securely shared cohorts via the GA4GH Beacon protocol. By simply \"asking\" Beacon, actionable insights can be gained, analyzed and made publication-ready.",
        "subjects": [
            "cs.AI",
            "cs.CY",
            "q-bio.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16705",
        "abstract url": "https://arxiv.org/abs/2410.16705",
        "title": "Privacy-hardened and hallucination-resistant synthetic data generation with logic-solvers",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Machine-generated data is a valuable resource for training Artificial Intelligence algorithms, evaluating rare workflows, and sharing data under stricter data legislations. The challenge is to generate data that is accurate and private. Current statistical and deep learning methods struggle with large data volumes, are prone to hallucinating scenarios incompatible with reality, and seldom quantify privacy meaningfully. Here we introduce Genomator, a logic solving approach (SAT solving), which efficiently produces private and realistic representations of the original data. We demonstrate the method on genomic data, which arguably is the most complex and private information. Synthetic genomes hold great potential for balancing underrepresented populations in medical research and advancing global data exchange. We benchmark Genomator against state-of-the-art methodologies (Markov generation, Restricted Boltzmann Machine, Generative Adversarial Network and Conditional Restricted Boltzmann Machines), demonstrating an 84-93% accuracy improvement and 95-98% higher privacy. Genomator is also 1000-1600 times more efficient, making it the only tested method that scales to whole genomes. We show the universal trade-off between privacy and accuracy, and use Genomator's tuning capability to cater to all applications along the spectrum, from provable private representations of sensitive cohorts, to datasets with indistinguishable pharmacogenomic profiles. Demonstrating the production-scale generation of tuneable synthetic data can increase trust and pave the way into the clinic.",
        "subjects": [
            "cs.AI",
            "cs.CR",
            "cs.CY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16713",
        "abstract url": "https://arxiv.org/abs/2410.16713",
        "title": "Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The increasing presence of AI-generated content on the internet raises a critical question: What happens when generative machine learning models are pretrained on web-scale datasets containing data created by earlier models? Some authors prophesy $\\textit{model collapse}$ under a \"$\\textit{replace}$\" scenario: a sequence of models, the first trained with real data and each later one trained only on synthetic data from its preceding model. In this scenario, models successively degrade. Others see collapse as easily avoidable; in an \"$\\textit{accumulate}$' scenario, a sequence of models is trained, but each training uses all real and synthetic data generated so far. In this work, we deepen and extend the study of these contrasting scenarios. First, collapse versus avoidance of collapse is studied by comparing the replace and accumulate scenarios on each of three prominent generative modeling settings; we find the same contrast emerges in all three settings. Second, we study a compromise scenario; the available data remains the same as in the accumulate scenario -- but unlike $\\textit{accumulate}$ and like $\\textit{replace}$, each model is trained using a fixed compute budget; we demonstrate that model test loss on real data is larger than in the $\\textit{accumulate}$ scenario, but apparently plateaus, unlike the divergence seen with $\\textit{replace}$. Third, we study the relative importance of cardinality and proportion of real data for avoiding model collapse. Surprisingly, we find a non-trivial interaction between real and synthetic data, where the value of synthetic data for reducing test loss depends on the absolute quantity of real data. Our insights are particularly important when forecasting whether future frontier generative models will collapse or thrive, and our results open avenues for empirically and mathematically studying the context-dependent value of synthetic data.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16733",
        "abstract url": "https://arxiv.org/abs/2410.16733",
        "title": "50 questions on Active Assisted Living technologies. Global edition",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This booklet on Active Assisted Living (AAL) technologies has been created as part of the GoodBrother COST Action, which has run from 2020 to 2024. COST Actions are European research programs that promote collaboration across borders, uniting researchers, professionals, and institutions to address key societal challenges. GoodBrother focused on ethical and privacy concerns surrounding video and audio monitoring in care settings. The aim was to ensure that while AAL technologies help older adults and vulnerable individuals, their privacy and data protection rights remain a top priority. This booklet is designed to guide you through the role that AAL technologies play in improving the quality of life for older adults, caregivers, and people with disabilities. AAL technologies offer tools for those facing cognitive or physical challenges. They can enhance independence, assist with daily routines, and promote a safer living environment. However, the rise of these technologies also brings important questions about data protection and user autonomy. This resource is intended for a wide audience, including end users, caregivers, healthcare professionals, and policymakers. It provides practical guidance on integrating AAL technologies into care settings while safeguarding privacy and ensuring ethical use. The insights offered here aim to empower users and caregivers to make informed choices that enhance both the quality of care and respect for personal autonomy.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16762",
        "abstract url": "https://arxiv.org/abs/2410.16762",
        "title": "Deep-Sea A*+: An Advanced Path Planning Method Integrating Enhanced A* and Dynamic Window Approach for Autonomous Underwater Vehicles",
        "rating": "-1.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "As terrestrial resources become increasingly depleted, the demand for deep-sea resource exploration has intensified. However, the extreme conditions in the deep-sea environment pose significant challenges for underwater operations, necessitating the development of robust detection robots. In this paper, we propose an advanced path planning methodology that integrates an improved A* algorithm with the Dynamic Window Approach (DWA). By optimizing the search direction of the traditional A* algorithm and introducing an enhanced evaluation function, our improved A* algorithm accelerates path searching and reduces computational load. Additionally, the path-smoothing process has been refined to improve continuity and smoothness, minimizing sharp turns. This method also integrates global path planning with local dynamic obstacle avoidance via DWA, improving the real-time response of underwater robots in dynamic environments. Simulation results demonstrate that our proposed method surpasses the traditional A* algorithm in terms of path smoothness, obstacle avoidance, and real-time performance. The robustness of this approach in complex environments with both static and dynamic obstacles highlights its potential in autonomous underwater vehicle (AUV) navigation and obstacle avoidance.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "Accepted by 2024 International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE 2024)"
    },
    {
        "paper id": "2410.16765",
        "abstract url": "https://arxiv.org/abs/2410.16765",
        "title": "Survival Models: Proper Scoring Rule and Stochastic Optimization with Competing Risks",
        "rating": "-1.5",
        "keywords": [
            [
                "Survival"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "When dealing with right-censored data, where some outcomes are missing due to a limited observation period, survival analysis -- known as time-to-event analysis -- focuses on predicting the time until an event of interest occurs. Multiple classes of outcomes lead to a classification variant: predicting the most likely event, a less explored area known as competing risks. Classic competing risks models couple architecture and loss, limiting scalability.To address these issues, we design a strictly proper censoring-adjusted separable scoring rule, allowing optimization on a subset of the data as each observation is evaluated independently. The loss estimates outcome probabilities and enables stochastic optimization for competing risks, which we use for efficient gradient boosting trees. SurvivalBoost not only outperforms 12 state-of-the-art models across several metrics on 4 real-life datasets, both in competing risks and survival settings, but also provides great calibration, the ability to predict across any time horizon, and computation times faster than existing methods.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2406.14085"
    },
    {
        "paper id": "2410.16795",
        "abstract url": "https://arxiv.org/abs/2410.16795",
        "title": "Traj-Explainer: An Explainable and Robust Multi-modal Trajectory Prediction Approach",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Trajectory"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Navigating complex traffic environments has been significantly enhanced by advancements in intelligent technologies, enabling accurate environment perception and trajectory prediction for automated vehicles. However, existing research often neglects the consideration of the joint reasoning of scenario agents and lacks interpretability in trajectory prediction models, thereby limiting their practical application in real-world scenarios. To this purpose, an explainability-oriented trajectory prediction model is designed in this work, named Explainable Conditional Diffusion based Multimodal Trajectory Prediction Traj-Explainer, to retrieve the influencing factors of prediction and help understand the intrinsic mechanism of prediction. In Traj-Explainer, a modified conditional diffusion is well designed to capture the scenario multimodal trajectory pattern, and meanwhile, a modified Shapley Value model is assembled to rationally learn the importance of the global and scenario features. Numerical experiments are carried out by several trajectory prediction datasets, including Waymo, NGSIM, HighD, and MoCAD datasets. Furthermore, we evaluate the identified input factors which indicates that they are in agreement with the human driving experience, indicating the capability of the proposed model in appropriately learning the prediction. Code available in our open-source repository: \\url{https://anonymous.4open.science/r/Interpretable-Prediction}.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16805",
        "abstract url": "https://arxiv.org/abs/2410.16805",
        "title": "Test-time Adversarial Defense with Opposite Adversarial Path and High Attack Time Cost",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning models are known to be vulnerable to adversarial attacks by injecting sophisticated designed perturbations to input data. Training-time defenses still exhibit a significant performance gap between natural accuracy and robust accuracy. In this paper, we investigate a new test-time adversarial defense method via diffusion-based recovery along opposite adversarial paths (OAPs). We present a purifier that can be plugged into a pre-trained model to resist adversarial attacks. Different from prior arts, the key idea is excessive denoising or purification by integrating the opposite adversarial direction with reverse diffusion to push the input image further toward the opposite adversarial direction. For the first time, we also exemplify the pitfall of conducting AutoAttack (Rand) for diffusion-based defense methods. Through the lens of time complexity, we examine the trade-off between the effectiveness of adaptive attack and its computation complexity against our defense. Experimental evaluation along with time cost analysis verifies the effectiveness of the proposed method.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16811",
        "abstract url": "https://arxiv.org/abs/2410.16811",
        "title": "Masked Clinical Modelling: A Framework for Synthetic and Augmented Survival Data Generation",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "Survival",
                "Clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Access to real clinical data is often restricted due to privacy obligations, creating significant barriers for healthcare research. Synthetic datasets provide a promising solution, enabling secure data sharing and model development. However, most existing approaches focus on data realism rather than utility -- ensuring that models trained on synthetic data yield clinically meaningful insights comparable to those trained on real data. In this paper, we present Masked Clinical Modelling (MCM), a framework inspired by masked language modelling, designed for both data synthesis and conditional data augmentation. We evaluate this prototype on the WHAS500 dataset using Cox Proportional Hazards models, focusing on the preservation of hazard ratios as key clinical metrics. Our results show that data generated using the MCM framework improves both discrimination and calibration in survival analysis, outperforming existing methods. MCM demonstrates strong potential to support survival data analysis and broader healthcare applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Re-archived due to incorrect ORCiD. Last edited: 2024-10-23"
    },
    {
        "paper id": "2410.16864",
        "abstract url": "https://arxiv.org/abs/2410.16864",
        "title": "Pedestrian motion prediction evaluation for urban autonomous driving",
        "rating": "-1.5",
        "keywords": [
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Pedestrian motion prediction is a key part of the modular-based autonomous driving pipeline, ensuring safe, accurate, and timely awareness of human agents' possible future trajectories. The autonomous vehicle can use this information to prevent any possible accidents and create a comfortable and pleasant driving experience for the passengers and pedestrians. A wealth of research was done on the topic from the authors of robotics, computer vision, intelligent transportation systems, and other fields. However, a relatively unexplored angle is the integration of the state-of-art solutions into existing autonomous driving stacks and evaluating them in real-life conditions rather than sanitized datasets. We analyze selected publications with provided open-source solutions and provide a perspective obtained by integrating them into existing Autonomous Driving framework - Autoware Mini and performing experiments in natural urban conditions in Tartu, Estonia to determine valuability of traditional motion prediction metrics. This perspective should be valuable to any potential autonomous driving or robotics engineer looking for the real-world performance of the existing state-of-art pedestrian motion prediction problem. The code with instructions on accessing the dataset is available at https://github.com/dmytrozabolotnii/autoware_mini.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "7 pages, 2 figures, 4 tables This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2410.16872",
        "abstract url": "https://arxiv.org/abs/2410.16872",
        "title": "CK4Gen: A Knowledge Distillation Framework for Generating High-Utility Synthetic Survival Datasets in Healthcare",
        "rating": "-1.5",
        "keywords": [
            [
                "Healthcare",
                "Survival",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Access to real clinical data is heavily restricted by privacy regulations, hindering both healthcare research and education. These constraints slow progress in developing new treatments and data-driven healthcare solutions, while also limiting students' access to real-world datasets, leaving them without essential practical skills. High-utility synthetic datasets are therefore critical for advancing research and providing meaningful training material. However, current generative models -- such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) -- produce surface-level realism at the expense of healthcare utility, blending distinct patient profiles and producing synthetic data of limited practical relevance. To overcome these limitations, we introduce CK4Gen (Cox Knowledge for Generation), a novel framework that leverages knowledge distillation from Cox Proportional Hazards (CoxPH) models to create synthetic survival datasets that preserve key clinical characteristics, including hazard ratios and survival curves. CK4Gen avoids the interpolation issues seen in VAEs and GANs by maintaining distinct patient risk profiles, ensuring realistic and reliable outputs for research and educational use. Validated across four benchmark datasets -- GBSG2, ACTG320, WHAS500, and FLChain -- CK4Gen outperforms competing techniques by better aligning real and synthetic data, enhancing survival model performance in both discrimination and calibration via data augmentation. As CK4Gen is scalable across clinical conditions, and with code to be made publicly available, future researchers can apply it to their own datasets to generate synthetic versions suitable for open sharing.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16879",
        "abstract url": "https://arxiv.org/abs/2410.16879",
        "title": "Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study",
        "rating": "-1.5",
        "keywords": [
            [
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Objectives: To investigate clinicians' attitudes towards current automated interpretation of ECG and novel AI technologies and their perception of computer-assisted interpretation. Materials and Methods: We conducted a series of interviews with clinicians in the UK. Our study: (i) explores the potential for AI, specifically future 'human-like' computing approaches, to facilitate ECG interpretation and support clinical decision making, and (ii) elicits their opinions about the importance of explainability and trustworthiness of AI algorithms. Results: We performed inductive thematic analysis on interview transcriptions from 23 clinicians and identified the following themes: (i) a lack of trust in current systems, (ii) positive attitudes towards future AI applications and requirements for these, (iii) the relationship between the accuracy and explainability of algorithms, and (iv) opinions on education, possible deskilling, and the impact of AI on clinical competencies. Discussion: Clinicians do not trust current computerised methods, but welcome future 'AI' technologies. Where clinicians trust future AI interpretation to be accurate, they are less concerned that it is explainable. They also preferred ECG interpretation that demonstrated the results of the algorithm visually. Whilst clinicians do not fear job losses, they are concerned about deskilling and the need to educate the workforce to use AI responsibly. Conclusion: Clinicians are positive about the future application of AI in clinical decision-making. Accuracy is a key factor of uptake and visualisations are preferred over current computerised methods. This is viewed as a potential means of training and upskilling, in contrast to the deskilling that automation might be perceived to bring.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16881",
        "abstract url": "https://arxiv.org/abs/2410.16881",
        "title": "Just In Time Transformers",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Precise energy load forecasting in residential households is crucial for mitigating carbon emissions and enhancing energy efficiency; indeed, accurate forecasting enables utility companies and policymakers, who advocate sustainable energy practices, to optimize resource utilization. Moreover, smart meters provide valuable information by allowing for granular insights into consumption patterns. Building upon available smart meter data, our study aims to cluster consumers into distinct groups according to their energy usage behaviours, effectively capturing a diverse spectrum of consumption patterns. Next, we design JITtrans (Just In Time transformer), a novel transformer deep learning model that significantly improves energy consumption forecasting accuracy, with respect to traditional forecasting methods. Extensive experimental results validate our claims using proprietary smart meter data. Our findings highlight the potential of advanced predictive technologies to revolutionize energy management and advance sustainable power systems: the development of efficient and eco-friendly energy solutions critically depends on such technologies.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16917",
        "abstract url": "https://arxiv.org/abs/2410.16917",
        "title": "DNAHLM -- DNA sequence and Human Language mixed large language Model",
        "rating": "-1.5",
        "keywords": [
            [
                "DNA"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "There are already many DNA large language models, but most of them still follow traditional uses, such as extracting sequence features for classification tasks. More innovative applications of large language models, such as prompt engineering, RAG, and zero-shot or few-shot prediction, remain challenging for DNA-based models. The key issue lies in the fact that DNA models and human natural language models are entirely separate; however, techniques like prompt engineering require the use of natural language, thereby significantly limiting the application of DNA large language models. This paper introduces a pre-trained model trained on the GPT-2 network, combining DNA sequences and English text, and uses a unified BPE tokenization method. We then convert classification and other downstream tasks into Alpaca format instruction data, and perform instruction fine-tuning on this pre-trained model to create a fine-tuned model capable of handling multiple tasks. The model has demonstrated its effectiveness in DNA related zero-shot prediction and multitask application. This research provides a highly promising direction for building a unified DNA sequence task framework.",
        "subjects": [
            "q-bio.GN",
            "cs.LG"
        ],
        "comment": "18 pages, 7 figures"
    },
    {
        "paper id": "2410.16928",
        "abstract url": "https://arxiv.org/abs/2410.16928",
        "title": "xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar Memories",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Time series data is prevalent across numerous fields, necessitating the development of robust and accurate forecasting models. Capturing patterns both within and between temporal and multivariate components is crucial for reliable predictions. We introduce xLSTM-Mixer, a model designed to effectively integrate temporal sequences, joint time-variate information, and multiple perspectives for robust forecasting. Our approach begins with a linear forecast shared across variates, which is then refined by xLSTM blocks. These blocks serve as key elements for modeling the complex dynamics of challenging time series data. xLSTM-Mixer ultimately reconciles two distinct views to produce the final forecast. Our extensive evaluations demonstrate xLSTM-Mixer's superior long-term forecasting performance compared to recent state-of-the-art methods. A thorough model analysis provides further insights into its key components and confirms its robustness and effectiveness. This work contributes to the resurgence of recurrent models in time series forecasting.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17086",
        "abstract url": "https://arxiv.org/abs/2410.17086",
        "title": "Exploration and Persuasion",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "How to incentivize self-interested agents to explore when they prefer to exploit? Consider a population of self-interested agents that make decisions under uncertainty. They \"explore\" to acquire new information and \"exploit\" this information to make good decisions. Collectively they need to balance these two objectives, but their incentives are skewed toward exploitation. This is because exploration is costly, but its benefits are spread over many agents in the future. \"Incentivized Exploration\" addresses this issue via strategic communication. Consider a benign ``principal\" which can communicate with the agents and make recommendations, but cannot force the agents to comply. Moreover, suppose the principal can observe the agents' decisions and the outcomes of these decisions. The goal is to design a communication and recommendation policy which (i) achieves a desirable balance between exploration and exploitation, and (ii) incentivizes the agents to follow recommendations. What makes it feasible is \"information asymmetry\": the principal knows more than any one agent, as it collects information from many. It is essential that the principal does not fully reveal all its knowledge to the agents. Incentivized exploration combines two important problems in, resp., machine learning and theoretical economics. First, if agents always follow recommendations, the principal faces a multi-armed bandit problem: essentially, design an algorithm that balances exploration and exploitation. Second, interaction with a single agent corresponds to \"Bayesian persuasion\", where a principal leverages information asymmetry to convince an agent to take a particular action. We provide a brief but self-contained introduction to each problem through the lens of incentivized exploration, solving a key special case of the former as a sub-problem of the latter.",
        "subjects": [
            "cs.GT",
            "cs.LG",
            "econ.TH"
        ],
        "comment": "This is a chapter published in \"Online and Matching-Based Markets\", Cambridge University Press, 2023. It has been available from the author's website since 2021"
    },
    {
        "paper id": "2410.17124",
        "abstract url": "https://arxiv.org/abs/2410.17124",
        "title": "Automated neuroradiological support systems for multiple cerebrovascular disease markers -- A systematic review and meta-analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "MRI",
                "CT",
                "disease"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Cerebrovascular diseases (CVD) can lead to stroke and dementia. Stroke is the second leading cause of death world wide and dementia incidence is increasing by the year. There are several markers of CVD that are visible on brain imaging, including: white matter hyperintensities (WMH), acute and chronic ischaemic stroke lesions (ISL), lacunes, enlarged perivascular spaces (PVS), acute and chronic haemorrhagic lesions, and cerebral microbleeds (CMB). Brain atrophy also occurs in CVD. These markers are important for patient management and intervention, since they indicate elevated risk of future stroke and dementia. We systematically reviewed automated systems designed to support radiologists reporting on these CVD imaging findings. We considered commercially available software and research publications which identify at least two CVD markers. In total, we included 29 commercial products and 13 research publications. Two distinct types of commercial support system were available: those which identify acute stroke lesions (haemorrhagic and ischaemic) from computed tomography (CT) scans, mainly for the purpose of patient triage; and those which measure WMH and atrophy regionally and longitudinally. In research, WMH and ISL were the markers most frequently analysed together, from magnetic resonance imaging (MRI) scans; lacunes and PVS were each targeted only twice and CMB only once. For stroke, commercially available systems largely support the emergency setting, whilst research systems consider also follow-up and routine scans. The systems to quantify WMH and atrophy are focused on neurodegenerative disease support, where these CVD markers are also of significance. There are currently no openly validated systems, commercially, or in research, performing a comprehensive joint analysis of all CVD markers (WMH, ISL, lacunes, PVS, haemorrhagic lesions, CMB, and atrophy).",
        "subjects": [
            "physics.med-ph",
            "cs.AI"
        ],
        "comment": "62 pages, 10 figures"
    },
    {
        "paper id": "2410.17159",
        "abstract url": "https://arxiv.org/abs/2410.17159",
        "title": "LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear Patterns for Robust Time Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Forecasting models are pivotal in a data-driven world with vast volumes of time series data that appear as a compound of vast Linear and Nonlinear patterns. Recent deep time series forecasting models struggle to utilize seasonal and trend decomposition to separate the entangled components. Such a strategy only explicitly extracts simple linear patterns like trends, leaving the other linear modes and vast unexplored nonlinear patterns to the residual. Their flawed linear and nonlinear feature extraction models and shallow-level decomposition limit their adaptation to the diverse patterns present in real-world scenarios. Given this, we innovate Recursive Residual Decomposition by introducing explicit extraction of both linear and nonlinear patterns. This deeper-level decomposition framework, which is named LiNo, captures linear patterns using a Li block which can be a moving average kernel, and models nonlinear patterns using a No block which can be a Transformer encoder. The extraction of these two patterns is performed alternatively and recursively. To achieve the full potential of LiNo, we develop the current simple linear pattern extractor to a general learnable autoregressive model, and design a novel No block that can handle all essential nonlinear patterns. Remarkably, the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks under univariate and multivariate forecasting scenarios. Experiments show that current forecasting models can deliver more robust and precise results through this advanced Recursive Residual Decomposition. We hope this work could offer insight into designing more effective forecasting models. Code is available at this Repository: https://github.com/Levi-Ackman/LiNo.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17173",
        "abstract url": "https://arxiv.org/abs/2410.17173",
        "title": "Reinforcement learning on structure-conditioned categorical diffusion for protein inverse folding",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Protein inverse folding-that is, predicting an amino acid sequence that will fold into the desired 3D structure-is an important problem for structure-based protein design. Machine learning based methods for inverse folding typically use recovery of the original sequence as the optimization objective. However, inverse folding is a one-to-many problem where several sequences can fold to the same structure. Moreover, for many practical applications, it is often desirable to have multiple, diverse sequences that fold into the target structure since it allows for more candidate sequences for downstream optimizations. Here, we demonstrate that although recent inverse folding methods show increased sequence recovery, their \"foldable diversity\"-i.e. their ability to generate multiple non-similar sequences that fold into the structures consistent with the target-does not increase. To address this, we present RL-DIF, a categorical diffusion model for inverse folding that is pre-trained on sequence recovery and tuned via reinforcement learning on structural consistency. We find that RL-DIF achieves comparable sequence recovery and structural consistency to benchmark models but shows greater foldable diversity: experiments show RL-DIF can achieve an foldable diversity of 29% on CATH 4.2, compared to 23% from models trained on the same dataset. The PyTorch model weights and sampling code are available on GitHub.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17194",
        "abstract url": "https://arxiv.org/abs/2410.17194",
        "title": "Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing",
        "rating": "-1.5",
        "keywords": [
            [
                "Knowledge Editing"
            ],
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Knowledge Editing (KE) algorithms alter models' internal weights to perform targeted updates to incorrect, outdated, or otherwise unwanted factual associations. In order to better define the possibilities and limitations of these approaches, recent work has shown that applying KE can adversely affect models' factual recall accuracy and diminish their general reasoning abilities. While these studies give broad insights into the potential harms of KE algorithms, e.g., via performance evaluations on benchmarks, we argue little is understood as to why such destructive failures occur. Is it possible KE methods distort representations of concepts beyond the targeted fact, hence hampering abilities at broad? If so, what is the extent of this distortion? To take a step towards addressing such questions, we define a novel synthetic task wherein a Transformer is trained from scratch to internalize a ``structured'' knowledge graph. The structure enforces relationships between entities of the graph, such that editing a factual association has \"trickling effects\" on other entities in the graph (e.g., altering X's parent is Y to Z affects who X's siblings' parent is). Through evaluations of edited models and analysis of extracted representations, we show that KE inadvertently affects representations of entities beyond the targeted one, distorting relevant structures that allow a model to infer unseen knowledge about an entity. We call this phenomenon representation shattering and demonstrate that it results in degradation of factual recall and reasoning performance more broadly. To corroborate our findings in a more naturalistic setup, we perform preliminary experiments with a pretrained GPT-2-XL model and reproduce the representation shattering effect therein as well. Overall, our work yields a precise mechanistic hypothesis to explain why KE has adverse effects on model capabilities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2410.17216",
        "abstract url": "https://arxiv.org/abs/2410.17216",
        "title": "Hierarchical Upper Confidence Bounds for Constrained Online Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The multi-armed bandit (MAB) problem is a foundational framework in sequential decision-making under uncertainty, extensively studied for its applications in areas such as clinical trials, online advertising, and resource allocation. Traditional MAB formulations, however, do not adequately capture scenarios where decisions are structured hierarchically, involve multi-level constraints, or feature context-dependent action spaces. In this paper, we introduce the hierarchical constrained bandits (HCB) framework, which extends the contextual bandit problem to incorporate hierarchical decision structures and multi-level constraints. We propose the hierarchical constrained upper confidence bound (HC-UCB) algorithm, designed to address the complexities of the HCB problem by leveraging confidence bounds within a hierarchical setting. Our theoretical analysis establishes sublinear regret bounds for HC-UCB and provides high-probability guarantees for constraint satisfaction at all hierarchical levels. Furthermore, we derive a minimax lower bound on the regret for the HCB problem, demonstrating the near-optimality of our algorithm. The results are significant for real-world applications where decision-making processes are inherently hierarchical and constrained, offering a robust and efficient solution that balances exploration and exploitation across multiple levels of decision-making.",
        "subjects": [
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17248",
        "abstract url": "https://arxiv.org/abs/2410.17248",
        "title": "HyperspectralViTs: General Hyperspectral Models for On-board Remote Sensing",
        "rating": "-1.5",
        "keywords": [
            [
                "Remote Sensing",
                "satellite",
                "hyperspectral data",
                "mineral"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "On-board processing of hyperspectral data with machine learning models would enable unprecedented amount of autonomy for a wide range of tasks, for example methane detection or mineral identification. This can enable early warning system and could allow new capabilities such as automated scheduling across constellations of satellites. Classical methods suffer from high false positive rates and previous deep learning models exhibit prohibitive computational requirements. We propose fast and accurate machine learning architectures which support end-to-end training with data of high spectral dimension without relying on hand-crafted products or spectral band compression preprocessing. We evaluate our models on two tasks related to hyperspectral data processing. With our proposed general architectures, we improve the F1 score of the previous methane detection state-of-the-art models by 27% on a newly created synthetic dataset and by 13% on the previously released large benchmark dataset. We also demonstrate that training models on the synthetic dataset improves performance of models finetuned on the dataset of real events by 6.9% in F1 score in contrast with training from scratch. On a newly created dataset for mineral identification, our models provide 3.5% improvement in the F1 score in contrast to the default versions of the models. With our proposed models we improve the inference speed by 85% in contrast to previous classical and deep learning approaches by removing the dependency on classically computed features. With our architecture, one capture from the EMIT sensor can be processed within 30 seconds on realistic proxy of the ION-SCV 004 satellite.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "13 pages, This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2410.17296",
        "abstract url": "https://arxiv.org/abs/2410.17296",
        "title": "The Internet of Forgotten Things: European Cybersecurity Regulation and IoT Manufacturer Cessation",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Many modern consumer devices rely on network connections and cloud services to perform their core functions. This dependency is especially present in Internet of Things (IoT) devices, which combine hardware and software with network connections (e.g., a 'smart' doorbell with a camera). This paper argues that current European product legislation, which aims to protect consumers of, inter alia, IoT devices, has a blind spot for an increasing problem in the competitive IoT market: manufacturer cessation. Without the manufacturer's cloud servers, many IoT devices cannot perform core functions such as data analysis. If an IoT manufacturer ceases their operations, consumers of the manufacturer's devices are thus often left with a dysfunctional device and, as the paper shows, hardly any legal remedies. This paper therefore investigates three properties that could support legislators in finding a solution for IoT manufacturer cessation: i) pre-emptive measures, aimed at ii) manufacturer-independent iii) collective control. The paper finally shows how these three properties already align with current legislative processes surrounding 'interoperability' and open-source software development.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17363",
        "abstract url": "https://arxiv.org/abs/2410.17363",
        "title": "DeLLiriuM: A large language model for delirium prediction in the ICU using structured EHR",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "health"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Delirium is an acute confusional state that has been shown to affect up to 31% of patients in the intensive care unit (ICU). Early detection of this condition could lead to more timely interventions and improved health outcomes. While artificial intelligence (AI) models have shown great potential for ICU delirium prediction using structured electronic health records (EHR), most of them have not explored the use of state-of-the-art AI models, have been limited to single hospitals, or have been developed and validated on small cohorts. The use of large language models (LLM), models with hundreds of millions to billions of parameters, with structured EHR data could potentially lead to improved predictive performance. In this study, we propose DeLLiriuM, a novel LLM-based delirium prediction model using EHR data available in the first 24 hours of ICU admission to predict the probability of a patient developing delirium during the rest of their ICU admission. We develop and validate DeLLiriuM on ICU admissions from 104,303 patients pertaining to 195 hospitals across three large databases: the eICU Collaborative Research Database, the Medical Information Mart for Intensive Care (MIMIC)-IV, and the University of Florida Health's Integrated Data Repository. The performance measured by the area under the receiver operating characteristic curve (AUROC) showed that DeLLiriuM outperformed all baselines in two external validation sets, with 0.77 (95% confidence interval 0.76-0.78) and 0.84 (95% confidence interval 0.83-0.85) across 77,543 patients spanning 194 hospitals. To the best of our knowledge, DeLLiriuM is the first LLM-based delirium prediction tool for the ICU based on structured EHR data, outperforming deep learning baselines which employ structured features and can provide helpful information to clinicians for timely interventions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17390",
        "abstract url": "https://arxiv.org/abs/2410.17390",
        "title": "Revealing The Secret Power: How Algorithms Can Influence Content Visibility on Social Media",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Online social media platforms significantly influence public debates by shaping the information users encounter. Content visibility on these platforms is regulated by recommendation algorithms designed to maximize user engagement using individual-level data, including personal preferences and interactions. These algorithms play a crucial role in information dissemination, yet their inner workings are often undisclosed, raising concerns about potential manipulation of visibility. While algorithms may be intended to limit the spread of harmful content, they can also be exploited to suppress dissenting voices without users' awareness. The suspicion that platforms deliberately reduce the visibility of certain users or content - commonly known as shadow banning - has garnered significant public attention, with numerous figures advocating for greater transparency around this practice. In this study, we perform a quantitative study geared to identify suspicious changes in content visibility on Twitter (now known as X). We build and study a dataset of over 13 million tweets from more than 5 million users discussing the Ukraine conflict, including each tweet's number of views and metadata, aiming to detect reduced or inflated visibility patterns. We investigate how visibility correlates with factors such as authors' stance, role, interaction networks, and content narratives. Our findings reveal significant variations in visibility, likely driven by algorithmic interventions. These results highlight the need for greater transparency in regulating online information ecosystems to prevent algorithmic manipulation that could undermine public discourse and the fairness of debates.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17395",
        "abstract url": "https://arxiv.org/abs/2410.17395",
        "title": "A 10.60 $\u03bc$W 150 GOPS Mixed-Bit-Width Sparse CNN Accelerator for Life-Threatening Ventricular Arrhythmia Detection",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper proposes an ultra-low power, mixed-bit-width sparse convolutional neural network (CNN) accelerator to accelerate ventricular arrhythmia (VA) detection. The chip achieves 50% sparsity in a quantized 1D CNN using a sparse processing element (SPE) architecture. Measurement on the prototype chip TSMC 40nm CMOS low-power (LP) process for the VA classification task demonstrates that it consumes 10.60 $\u03bc$W of power while achieving a performance of 150 GOPS and a diagnostic accuracy of 99.95%. The computation power density is only 0.57 $\u03bc$W/mm$^2$, which is 14.23X smaller than state-of-the-art works, making it highly suitable for implantable and wearable medical devices.",
        "subjects": [
            "cs.AR",
            "cs.AI"
        ],
        "comment": "2 pages, accepted to The 30th Asia and South Pacific Design Automation Conference (ASP-DAC 2025)"
    },
    {
        "paper id": "2410.17397",
        "abstract url": "https://arxiv.org/abs/2410.17397",
        "title": "Quantum Large Language Models via Tensor Network Disentanglers",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We propose a method to enhance the performance of Large Language Models (LLMs) by integrating quantum computing and quantum-inspired techniques. Specifically, our approach involves replacing the weight matrices in the Self-Attention and Multi-layer Perceptron layers with a combination of two variational quantum circuits and a quantum-inspired tensor network, such as a Matrix Product Operator (MPO). This substitution enables the reproduction of classical LLM functionality by decomposing weight matrices through the application of tensor network disentanglers and MPOs, leveraging well-established tensor network techniques. By incorporating more complex and deeper quantum circuits, along with increasing the bond dimensions of the MPOs, our method captures additional correlations within the quantum-enhanced LLM, leading to improved accuracy beyond classical models while maintaining low memory overhead.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "4 pages, 2 figures"
    },
    {
        "paper id": "2410.17431",
        "abstract url": "https://arxiv.org/abs/2410.17431",
        "title": "Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) is susceptible to a range of security threats. Although various defense mechanisms have been proposed, they are typically non-adaptive and tailored to specific types of attacks, leaving them insufficient in the face of multiple uncertain, unknown, and adaptive attacks employing diverse strategies. This work formulates adversarial federated learning under a mixture of various attacks as a Bayesian Stackelberg Markov game, based on which we propose the meta-Stackelberg defense composed of pre-training and online adaptation. {The gist is to simulate strong attack behavior using reinforcement learning (RL-based attacks) in pre-training and then design meta-RL-based defense to combat diverse and adaptive attacks.} We develop an efficient meta-learning approach to solve the game, leading to a robust and adaptive FL defense. Theoretically, our meta-learning algorithm, meta-Stackelberg learning, provably converges to the first-order $\\varepsilon$-meta-equilibrium point in $O(\\varepsilon^{-2})$ gradient iterations with $O(\\varepsilon^{-4})$ samples per iteration. Experiments show that our meta-Stackelberg framework performs superbly against strong model poisoning and backdoor attacks of uncertain and unknown types.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.GT"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2410.17433",
        "abstract url": "https://arxiv.org/abs/2410.17433",
        "title": "Revisiting Technical Bias Mitigation Strategies",
        "rating": "-1.5",
        "keywords": [
            [
                "biomedical",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Efforts to mitigate bias and enhance fairness in the artificial intelligence (AI) community have predominantly focused on technical solutions. While numerous reviews have addressed bias in AI, this review uniquely focuses on the practical limitations of technical solutions in healthcare settings, providing a structured analysis across five key dimensions affecting their real-world implementation: who defines bias and fairness; which mitigation strategy to use and prioritize among dozens that are inconsistent and incompatible; when in the AI development stages the solutions are most effective; for which populations; and the context in which the solutions are designed. We illustrate each limitation with empirical studies focusing on healthcare and biomedical applications. Moreover, we discuss how value-sensitive AI, a framework derived from technology design, can engage stakeholders and ensure that their values are embodied in bias and fairness mitigation solutions. Finally, we discuss areas that require further investigation and provide practical recommendations to address the limitations covered in the study.",
        "subjects": [
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17473",
        "abstract url": "https://arxiv.org/abs/2410.17473",
        "title": "DROP: Distributional and Regular Optimism and Pessimism for Reinforcement Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In reinforcement learning (RL), temporal difference (TD) error is known to be related to the firing rate of dopamine neurons. It has been observed that each dopamine neuron does not behave uniformly, but each responds to the TD error in an optimistic or pessimistic manner, interpreted as a kind of distributional RL. To explain such a biological data, a heuristic model has also been designed with learning rates asymmetric for the positive and negative TD errors. However, this heuristic model is not theoretically-grounded and unknown whether it can work as a RL algorithm. This paper therefore introduces a novel theoretically-grounded model with optimism and pessimism, which is derived from control as inference. In combination with ensemble learning, a distributional value function as a critic is estimated from regularly introduced optimism and pessimism. Based on its central value, a policy in an actor is improved. This proposed algorithm, so-called DROP (distributional and regular optimism and pessimism), is compared on dynamic tasks. Although the heuristic model showed poor learning performance, DROP showed excellent one in all tasks with high generality. In other words, it was suggested that DROP is a new model that can elicit the potential contributions of optimism and pessimism.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "16 pages, 11 figures"
    },
    {
        "paper id": "2410.17479",
        "abstract url": "https://arxiv.org/abs/2410.17479",
        "title": "Composing Diffusion Policies for Few-shot Learning of Movement Trajectories",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Humans can perform various combinations of physical skills without having to relearn skills from scratch every single time. For example, we can swing a bat when walking without having to re-learn such a policy from scratch by composing the individual skills of walking and bat swinging. Enabling robots to combine or compose skills is essential so they can learn novel skills and tasks faster with fewer real world samples. To this end, we propose a novel compositional approach called DSE- Diffusion Score Equilibrium that enables few-shot learning for novel skills by utilizing a combination of base policy priors. Our method is based on probabilistically composing diffusion policies to better model the few-shot demonstration data-distribution than any individual policy. Our goal here is to learn robot motions few-shot and not necessarily goal oriented trajectories. Unfortunately we lack a general purpose metric to evaluate the error between a skill or motion and the provided demonstrations. Hence, we propose a probabilistic measure - Maximum Mean Discrepancy on the Forward Kinematics Kernel (MMD-FK), that is task and action space agnostic. By using our few-shot learning approach DSE, we show that we are able to achieve a reduction of over 30% in MMD-FK across skills and number of demonstrations. Moreover, we show the utility of our approach through real world experiments by teaching novel trajectories to a robot in 5 demonstrations.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "6(+1) pages, 6 figures"
    },
    {
        "paper id": "2410.17492",
        "abstract url": "https://arxiv.org/abs/2410.17492",
        "title": "BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers",
        "rating": "-1.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "healthcare"
            ],
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Attacking fairness is crucial because compromised models can introduce biased outcomes, undermining trust and amplifying inequalities in sensitive applications like hiring, healthcare, and law enforcement. This highlights the urgent need to understand how fairness mechanisms can be exploited and to develop defenses that ensure both fairness and robustness. We introduce BadFair, a novel backdoored fairness attack methodology. BadFair stealthily crafts a model that operates with accuracy and fairness under regular conditions but, when activated by certain triggers, discriminates and produces incorrect results for specific groups. This type of attack is particularly stealthy and dangerous, as it circumvents existing fairness detection methods, maintaining an appearance of fairness in normal use. Our findings reveal that BadFair achieves a more than 85% attack success rate in attacks aimed at target groups on average while only incurring a minimal accuracy loss. Moreover, it consistently exhibits a significant discrimination score, distinguishing between pre-defined target and non-target attacked groups across various datasets and models.",
        "subjects": [
            "cs.CR",
            "cs.CL",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "Accepted by EMNLP 2024"
    },
    {
        "paper id": "2410.17496",
        "abstract url": "https://arxiv.org/abs/2410.17496",
        "title": "Measuring Network Dynamics of Opioid Overdose Deaths in the United States",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "clinical"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "The US opioid overdose epidemic has been a major public health concern in recent decades. There has been increasing recognition that its etiology is rooted in part in the social contexts that mediate substance use and access; however, reliable statistical measures of social influence are lacking in the literature. We use Facebook's social connectedness index (SCI) as a proxy for real-life social networks across diverse spatial regions that help quantify social connectivity across different spatial units. This is a measure of the relative probability of connections between localities that offers a unique lens to understand the effects of social networks on health outcomes. We use SCI to develop a variable, called \"deaths in social proximity\", to measure the influence of social networks on opioid overdose deaths (OODs) in US counties. Our results show a statistically significant effect size for deaths in social proximity on OODs in counties in the United States, controlling for spatial proximity, as well as demographic and clinical covariates. The effect size of standardized deaths in social proximity in our cluster-robust linear regression model indicates that a one-standard-deviation increase, equal to 11.70 more deaths per 100,000 population in the social proximity of ego counties in the contiguous United States, is associated with thirteen more deaths per 100,000 population in ego counties. To further validate our findings, we performed a series of robustness checks using a network autocorrelation model to account for social network effects, a spatial autocorrelation model to capture spatial dependencies, and a two-way fixed-effect model to control for unobserved spatial and time-invariant characteristics. These checks consistently provide statistically robust evidence of positive social influence on OODs in US counties.",
        "subjects": [
            "cs.SI",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17504",
        "abstract url": "https://arxiv.org/abs/2410.17504",
        "title": "An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "disease",
                "clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Explainable Artificial Intelligence (AI) focuses on helping humans understand the working of AI systems or their decisions and has been a cornerstone of AI for decades. Recent research in explainability has focused on explaining the workings of AI models or model explainability. There have also been several position statements and review papers detailing the needs of end-users for user-centered explainability but fewer implementations. Hence, this thesis seeks to bridge some gaps between model and user-centered explainability. We create an explanation ontology (EO) to represent literature-derived explanation types via their supporting components. We implement a knowledge-augmented question-answering (QA) pipeline to support contextual explanations in a clinical setting. Finally, we are implementing a system to combine explanations from different AI methods and data modalities. Within the EO, we can represent fifteen different explanation types, and we have tested these representations in six exemplar use cases. We find that knowledge augmentations improve the performance of base large language models in the contextualized QA, and the performance is variable across disease groups. In the same setting, clinicians also indicated that they prefer to see actionability as one of the main foci in explanations. In our explanations combination method, we plan to use similarity metrics to determine the similarity of explanations in a chronic disease detection setting. Overall, through this thesis, we design methods that can support knowledge-enabled explanations across different use cases, accounting for the methods in today's AI era that can generate the supporting components of these explanations and domain knowledge sources that can enhance them.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Doctoral dissertation. Some chapters appeared as individual papers - arXiv:2302.05752 is one such chapters"
    },
    {
        "paper id": "2410.17521",
        "abstract url": "https://arxiv.org/abs/2410.17521",
        "title": "Diffusion Priors for Variational Likelihood Estimation and Image Denoising",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Real-world noise removal is crucial in low-level computer vision. Due to the remarkable generation capabilities of diffusion models, recent attention has shifted towards leveraging diffusion priors for image restoration tasks. However, existing diffusion priors-based methods either consider simple noise types or rely on approximate posterior estimation, limiting their effectiveness in addressing structured and signal-dependent noise commonly found in real-world images. In this paper, we build upon diffusion priors and propose adaptive likelihood estimation and MAP inference during the reverse diffusion process to tackle real-world noise. We introduce an independent, non-identically distributed likelihood combined with the noise precision (inverse variance) prior and dynamically infer the precision posterior using variational Bayes during the generation process. Meanwhile, we rectify the estimated noise variance through local Gaussian convolution. The final denoised image is obtained by propagating intermediate MAP solutions that balance the updated likelihood and diffusion prior. Additionally, we explore the local diffusion prior inherent in low-resolution diffusion models, enabling direct handling of high-resolution noisy images. Extensive experiments and analyses on diverse real-world datasets demonstrate the effectiveness of our method. Code is available at https://github.com/HUST-Tan/DiffusionVI.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by NeurIPS2024 as Spotlight"
    },
    {
        "paper id": "2410.17526",
        "abstract url": "https://arxiv.org/abs/2410.17526",
        "title": "GDDA: Semantic OOD Detection on Graphs under Covariate Shift via Score-Based Diffusion Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "GNNs",
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Out-of-distribution (OOD) detection poses a significant challenge for Graph Neural Networks (GNNs), particularly in open-world scenarios with varying distribution shifts. Most existing OOD detection methods on graphs primarily focus on identifying instances in test data domains caused by either semantic shifts (changes in data classes) or covariate shifts (changes in data features), while leaving the simultaneous occurrence of both distribution shifts under-explored. In this work, we address both types of shifts simultaneously and introduce a novel challenge for OOD detection on graphs: graph-level semantic OOD detection under covariate shift. In this scenario, variations between the training and test domains result from the concurrent presence of both covariate and semantic shifts, where only graphs associated with unknown classes are identified as OOD samples (OODs). To tackle this challenge, we propose a novel two-phase framework called Graph Disentangled Diffusion Augmentation (GDDA). The first phase focuses on disentangling graph representations into domain-invariant semantic factors and domain-specific style factors. In the second phase, we introduce a novel distribution-shift-controlled score-based generative diffusion model that generates latent factors outside the training semantic and style spaces. Additionally, auxiliary pseudo-in-distribution (InD) and pseudo-OOD graph representations are employed to enhance the effectiveness of the energy-based semantic OOD detector. Extensive empirical studies on three benchmark datasets demonstrate that our approach outperforms state-of-the-art baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "4 pages, 6 figures"
    },
    {
        "paper id": "2410.17545",
        "abstract url": "https://arxiv.org/abs/2410.17545",
        "title": "Predicting 30-Day Hospital Readmission in Medicare Patients: Insights from an LSTM Deep Learning Model",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "healthcare",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Readmissions among Medicare beneficiaries are a major problem for the US healthcare system from a perspective of both healthcare operations and patient caregiving outcomes. Our study analyzes Medicare hospital readmissions using LSTM networks with feature engineering to assess feature contributions. We selected variables from admission-level data, inpatient medical history and patient demography. The LSTM model is designed to capture temporal dynamics from admission-level and patient-level data. On a case study on the MIMIC dataset, the LSTM model outperformed the logistic regression baseline, accurately leveraging temporal features to predict readmission. The major features were the Charlson Comorbidity Index, hospital length of stay, the hospital admissions over the past 6 months, while demographic variables were less impactful. This work suggests that LSTM networks offers a more promising approach to improve Medicare patient readmission prediction. It captures temporal interactions in patient databases, enhancing current prediction models for healthcare providers. Adoption of predictive models into clinical practice may be more effective in identifying Medicare patients to provide early and targeted interventions to improve patient outcomes.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "5 pages, 1 table, 5 figures, Accepted by 2024 3rd International Conference on Cloud Computing, Big Data Application and Software Engineering(CBASE 2024), the final version will be published on on IEEE Conference proceeding"
    },
    {
        "paper id": "2410.19852",
        "abstract url": "https://arxiv.org/abs/2410.19852",
        "title": "Survival of the Fittest: Evolutionary Adaptation of Policies for Environmental Shifts",
        "rating": "-1.5",
        "keywords": [
            [
                "Survival"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning (RL) has been successfully applied to solve the problem of finding obstacle-free paths for autonomous agents operating in stochastic and uncertain environments. However, when the underlying stochastic dynamics of the environment experiences drastic distribution shifts, the optimal policy obtained in the trained environment may be sub-optimal or may entirely fail in helping find goal-reaching paths for the agent. Approaches like domain randomization and robust RL can provide robust policies, but typically assume minor (bounded) distribution shifts. For substantial distribution shifts, retraining (either with a warm-start policy or from scratch) is an alternative approach. In this paper, we develop a novel approach called {\\em Evolutionary Robust Policy Optimization} (ERPO), an adaptive re-training algorithm inspired by evolutionary game theory (EGT). ERPO learns an optimal policy for the shifted environment iteratively using a temperature parameter that controls the trade off between exploration and adherence to the old optimal policy. The policy update itself is an instantiation of the replicator dynamics used in EGT. We show that under fairly common sparsity assumptions on rewards in such environments, ERPO converges to the optimal policy in the shifted environment. We empirically demonstrate that for path finding tasks in a number of environments, ERPO outperforms several popular RL and deep RL algorithms (PPO, A3C, DQN) in many scenarios and popular environments. This includes scenarios where the RL algorithms are allowed to train from scratch in the new environment, when they are retrained on the new environment, or when they are used in conjunction with domain randomization. ERPO shows faster policy adaptation, higher average rewards, and reduced computational costs in policy adaptation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.NE"
        ],
        "comment": "Pubblished in ECAI 2024"
    },
    {
        "paper id": "2410.19854",
        "abstract url": "https://arxiv.org/abs/2410.19854",
        "title": "Dynamic User Grouping based on Location and Heading in 5G NR Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "5G"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "User grouping based on geographic location in fifth generation (5G) New Radio (NR) systems has several applications that can significantly improve network performance, user experience, and service delivery. We demonstrate how Sounding Reference Signals channel fingerprints can be used for dynamic user grouping in a 5G NR commercial deployment based on outdoor positions and heading direction employing machine learning methods such as neural networks combined with clustering methods.",
        "subjects": [
            "eess.SP",
            "cs.IT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19855",
        "abstract url": "https://arxiv.org/abs/2410.19855",
        "title": "Personalized Recommendation Systems using Multimodal, Autonomous, Multi Agent Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper describes a highly developed personalised recommendation system using multimodal, autonomous, multi-agent systems. The system focuses on the incorporation of futuristic AI tech and LLMs like Gemini-1.5- pro and LLaMA-70B to improve customer service experiences especially within e-commerce. Our approach uses multi agent, multimodal systems to provide best possible recommendations to its users. The system is made up of three agents as a whole. The first agent recommends products appropriate for answering the given question, while the second asks follow-up questions based on images that belong to these recommended products and is followed up with an autonomous search by the third agent. It also features a real-time data fetch, user preferences-based recommendations and is adaptive learning. During complicated queries the application processes with Symphony, and uses the Groq API to answer quickly with low response times. It uses a multimodal way to utilize text and images comprehensively, so as to optimize product recommendation and customer interaction.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19859",
        "abstract url": "https://arxiv.org/abs/2410.19859",
        "title": "Multi-Modal Transformer and Reinforcement Learning-based Beam Management",
        "rating": "-1.5",
        "keywords": [
            [
                "6G"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Beam management is an important technique to improve signal strength and reduce interference in wireless communication systems. Recently, there has been increasing interest in using diverse sensing modalities for beam management. However, it remains a big challenge to process multi-modal data efficiently and extract useful information. On the other hand, the recently emerging multi-modal transformer (MMT) is a promising technique that can process multi-modal data by capturing long-range dependencies. While MMT is highly effective in handling multi-modal data and providing robust beam management, integrating reinforcement learning (RL) further enhances their adaptability in dynamic environments. In this work, we propose a two-step beam management method by combining MMT with RL for dynamic beam index prediction. In the first step, we divide available beam indices into several groups and leverage MMT to process diverse data modalities to predict the optimal beam group. In the second step, we employ RL for fast beam decision-making within each group, which in return maximizes throughput. Our proposed framework is tested on a 6G dataset. In this testing scenario, it achieves higher beam prediction accuracy and system throughput compared to both the MMT-only based method and the RL-only based method.",
        "subjects": [
            "eess.SP",
            "cs.AI"
        ],
        "comment": "5 pages, 5 figures, IEEE Networking Letters"
    },
    {
        "paper id": "2410.16704",
        "abstract url": "https://arxiv.org/abs/2410.16704",
        "title": "Resolvability of classical-quantum channels",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Channel resolvability concerns the minimum resolution for approximating the channel output. We study the resolvability of classical-quantum channels in two settings, for the channel output generated from the worst input, and form the fixed independent and identically distributed (i.i.d.) input. The direct part of the worst-input setting is derived from sequential hypothesis testing as it involves of non-i.i.d.~inputs. The strong converse of the worst-input setting is obtained via the connection to identification codes. For the fixed-input setting, while the direct part follows from the known quantum soft covering result, we exploit the recent alternative quantum Sanov theorem to solve the strong converse.",
        "subjects": [
            "quant-ph",
            "cs.ET",
            "cs.IT"
        ],
        "comment": "20 pages, 3 figures. Comments are welcome!"
    },
    {
        "paper id": "2410.16732",
        "abstract url": "https://arxiv.org/abs/2410.16732",
        "title": "Polyp-E: Benchmarking the Robustness of Deep Segmentation Models via Polyp Editing",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic polyp segmentation is helpful to assist clinical diagnosis and treatment. In daily clinical practice, clinicians exhibit robustness in identifying polyps with both location and size variations. It is uncertain if deep segmentation models can achieve comparable robustness in automated colonoscopic analysis. To benchmark the model robustness, we focus on evaluating the robustness of segmentation models on the polyps with various attributes (e.g. location and size) and healthy samples. Based on the Latent Diffusion Model, we perform attribute editing on real polyps and build a new dataset named Polyp-E. Our synthetic dataset boasts exceptional realism, to the extent that clinical experts find it challenging to discern them from real data. We evaluate several existing polyp segmentation models on the proposed benchmark. The results reveal most of the models are highly sensitive to attribute variations. As a novel data augmentation technique, the proposed editing pipeline can improve both in-distribution and out-of-distribution generalization ability. The code and datasets will be released.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16734",
        "abstract url": "https://arxiv.org/abs/2410.16734",
        "title": "High-Order Associative Learning Based on Memristive Circuits for Efficient Learning",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Memristive associative learning has gained significant attention for its ability to mimic fundamental biological learning mechanisms while maintaining system simplicity. In this work, we introduce a high-order memristive associative learning framework with a biologically realistic structure. By utilizing memristors as synaptic modules and their state information to bridge different orders of associative learning, our design effectively establishes associations between multiple stimuli and replicates the transient nature of high-order associative learning. In Pavlov's classical conditioning experiments, our design achieves a 230% improvement in learning efficiency compared to previous works, with memristor power consumption in the synaptic modules remaining below 11 \u03bcW. In large-scale image recognition tasks, we utilize a 20*20 memristor array to represent images, enabling the system to recognize and label test images with semantic information at 100% accuracy. This scalability across different tasks highlights the framework's potential for a wide range of applications, offering enhanced learning efficiency for current memristor-based neuromorphic systems.",
        "subjects": [
            "cs.NE",
            "eess.SP",
            "physics.app-ph"
        ],
        "comment": "5 pages, 7 figures"
    },
    {
        "paper id": "2410.16749",
        "abstract url": "https://arxiv.org/abs/2410.16749",
        "title": "Fast State-of-Health Estimation Method for Lithium-ion Battery using Sparse Identification of Nonlinear Dynamics",
        "rating": "-2",
        "keywords": [
            [
                "Health"
            ]
        ],
        "abstract": "Lithium-ion batteries (LIBs) are utilized as a major energy source in various fields because of their high energy density and long lifespan. During repeated charging and discharging, the degradation of LIBs, which reduces their maximum power output and operating time, is a pivotal issue. This degradation can affect not only battery performance but also safety of the system. Therefore, it is essential to accurately estimate the state-of-health (SOH) of the battery in real time. To address this problem, we propose a fast SOH estimation method that utilizes the sparse model identification algorithm (SINDy) for nonlinear dynamics. SINDy can discover the governing equations of target systems with low data assuming that few functions have the dominant characteristic of the system. To decide the state of degradation model, correlation analysis is suggested. Using SINDy and correlation analysis, we can obtain the data-driven SOH model to improve the interpretability of the system. To validate the feasibility of the proposed method, the estimation performance of the SOH and the computation time are evaluated by comparing it with various machine learning algorithms.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16755",
        "abstract url": "https://arxiv.org/abs/2410.16755",
        "title": "Coarse-to-fine Dynamic Uplift Modeling for Real-time Video Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "industrial",
                "Recommendation"
            ]
        ],
        "abstract": "With the rise of short video platforms, video recommendation technology faces more complex challenges. Currently, there are multiple non-personalized modules in the video recommendation pipeline that urgently need personalized modeling techniques for improvement. Inspired by the success of uplift modeling in online marketing, we attempt to implement uplift modeling in the video recommendation scenario. However, we face two main challenges: 1) Design and utilization of treatments, and 2) Capture of user real-time interest. To address them, we design adjusting the distribution of videos with varying durations as the treatment and propose Coarse-to-fine Dynamic Uplift Modeling (CDUM) for real-time video recommendation. CDUM consists of two modules, CPM and FIC. The former module fully utilizes the offline features of users to model their long-term preferences, while the latter module leverages online real-time contextual features and request-level candidates to model users' real-time interests. These two modules work together to dynamically identify and targeting specific user groups and applying treatments effectively. Further, we conduct comprehensive experiments on the offline public and industrial datasets and online A/B test, demonstrating the superiority and effectiveness of our proposed CDUM. Our proposed CDUM is eventually fully deployed on the Kuaishou platform, serving hundreds of millions of users every day. The source code will be provided after the paper is accepted.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "9 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2410.16802",
        "abstract url": "https://arxiv.org/abs/2410.16802",
        "title": "Evaluating the Effectiveness of Attack-Agnostic Features for Morphing Attack Detection",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "SVM"
            ],
            [
                "Attack"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Morphing attacks have diversified significantly over the past years, with new methods based on generative adversarial networks (GANs) and diffusion models posing substantial threats to face recognition systems. Recent research has demonstrated the effectiveness of features extracted from large vision models pretrained on bonafide data only (attack-agnostic features) for detecting deep generative images. Building on this, we investigate the potential of these image representations for morphing attack detection (MAD). We develop supervised detectors by training a simple binary linear SVM on the extracted features and one-class detectors by modeling the distribution of bonafide features with a Gaussian Mixture Model (GMM). Our method is evaluated across a comprehensive set of attacks and various scenarios, including generalization to unseen attacks, different source datasets, and print-scan data. Our results indicate that attack-agnostic features can effectively detect morphing attacks, outperforming traditional supervised and one-class detectors from the literature in most scenarios. Additionally, we provide insights into the strengths and limitations of each considered representation and discuss potential future research directions to further enhance the robustness and generalizability of our approach.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "Published in the 2024 IEEE International Joint Conference on Biometrics (IJCB)"
    },
    {
        "paper id": "2410.16823",
        "abstract url": "https://arxiv.org/abs/2410.16823",
        "title": "Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other?",
        "rating": "-2",
        "keywords": [
            [
                "industrial",
                "Recommendation"
            ]
        ],
        "abstract": "Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the breakthroughs of Large Language Models (LLMs), these generative systems can play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items learned by generative recommenders are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item's representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item's popularity, and [H2] the joint training regularizes the item's latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted for publication in the 18th ACM Conference on Recommender Systems (RecSys'24)"
    },
    {
        "paper id": "2410.16887",
        "abstract url": "https://arxiv.org/abs/2410.16887",
        "title": "Distribution of Responsibility During the Usage of AI-Based Exoskeletons for Upper Limb Rehabilitation",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "The ethical issues concerning the AI-based exoskeletons used in healthcare have already been studied literally rather than technically. How the ethical guidelines can be integrated into the development process has not been widely studied. However, this is one of the most important topics which should be studied more in real-life applications. Therefore, in this paper we highlight one ethical concern in the context of an exoskeleton used to train a user to perform a gesture: during the interaction between the exoskeleton, patient and therapist, how is the responsibility for decision making distributed? Based on the outcome of this, we will discuss how to integrate ethical guidelines into the development process of an AI-based exoskeleton. The discussion is based on a case study: AiBle. The different technical factors affecting the rehabilitation results and the human-machine interaction for AI-based exoskeletons are identified and discussed in this paper in order to better apply the ethical guidelines during the development of AI-based exoskeletons.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Robot Trust for Symbiotic Societies (RTSS) at IROS 2022"
    },
    {
        "paper id": "2410.16898",
        "abstract url": "https://arxiv.org/abs/2410.16898",
        "title": "MBD: Multi b-value Denoising of Diffusion Magnetic Resonance Images",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We propose a novel approach to denoising diffusion magnetic resonance images (dMRI) using convolutional neural networks, that exploits the benefits of data acquired at multiple b-values to offset the need for many redundant observations. Denoising is especially relevant in dMRI since noise can have a deleterious impact on both quantification accuracy and image preprocessing. The most successful methods proposed to date, like Marchenko-Pastur Principal Component Analysis (MPPCA) denoising, are tailored to diffusion-weighting repeated for many encoding directions. They exploit high redundancy of the dataset that oversamples the diffusion-encoding direction space, since many directions have collinear components. However, there are many dMRI techniques that do not entail a large number of encoding directions or repetitions, and are therefore less suited to this approach. For example, clinical dMRI exams may include as few as three encoding directions, with low or negligible data redundancy across directions. Moreover, promising new dMRI approaches, like spherical b-tensor encoding (STE), benefit from high b-values while sensitizing the signal to diffusion along all directions in just a single shot. We introduce a convolutional neural network approach that we call multi-b-value-based denoising (MBD). MBD exploits the similarity in diffusion-weighted images (DWI) across different b-values but along the same diffusion encoding direction. It allows denoising of diffusion images with high noise variance while avoiding blurring, and using just a small number input images.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "this is a biomedical engineering work using machine learning to enhance medical images"
    },
    {
        "paper id": "2410.16959",
        "abstract url": "https://arxiv.org/abs/2410.16959",
        "title": "Evaluation of a Data Annotation Platform for Large, Time-Series Datasets in Intensive Care: Mixed Methods Study",
        "rating": "-2",
        "keywords": [
            [
                "clinical"
            ]
        ],
        "abstract": "Intensive Care Units are complex, data-rich environments where critically ill patients are treated using variety of clinical equipment. The data collected using this equipment can be used clinical staff to gain insight into the condition of the patients and provide adequate treatment, but it also provides ample opportunity for applications in machine learning and data science. While this data can frequently be used directly, complex problems may require additional annotations to provide context and meaning before it could be used to train the machine learning models. Annotating time-series datasets in clinical setting is a complex problem due to a large volume and complexity of the data, time-consuming nature of the process and the fact that clinicians' time is in both high demand and short supply. In this study, we present an evaluation of a bespoke tool designed to annotate large, clinical time-series datasets with staff from intensive care units. The software incorporates two modes for annotation: by annotating individual admissions and by generating rulesets which are applied to the entire dataset. Our study was split into two stages focusing on individual and semi-automated annotation and included 28 annotators across both stages who utilised 50 clinical parameters to guide their annotations. We experienced significant challenges in recruitment and engagement of the participants in the annotation activities and developed interventions which improved the participation over the course of the study. During the semi-automated annotation, we observed preferences for different parameter types (measured vs. observed), as well as relative agreement of participants across shared admissions to the decision-tree model trained using their rulesets.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16978",
        "abstract url": "https://arxiv.org/abs/2410.16978",
        "title": "Multi-Layer Gaussian Splatting for Immersive Anatomy Visualization",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "medical",
                "CT"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In medical image visualization, path tracing of volumetric medical data like CT scans produces lifelike three-dimensional visualizations. Immersive VR displays can further enhance the understanding of complex anatomies. Going beyond the diagnostic quality of traditional 2D slices, they enable interactive 3D evaluation of anatomies, supporting medical education and planning. Rendering high-quality visualizations in real-time, however, is computationally intensive and impractical for compute-constrained devices like mobile headsets. We propose a novel approach utilizing GS to create an efficient but static intermediate representation of CT scans. We introduce a layered GS representation, incrementally including different anatomical structures while minimizing overlap and extending the GS training to remove inactive Gaussians. We further compress the created model with clustering across layers. Our approach achieves interactive frame rates while preserving anatomical structures, with quality adjustable to the target hardware. Compared to standard GS, our representation retains some of the explorative qualities initially enabled by immersive path tracing. Selective activation and clipping of layers are possible at rendering time, adding a degree of interactivity to otherwise static GS models. This could enable scenarios where high computational demands would otherwise prohibit using path-traced medical volumes.",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16980",
        "abstract url": "https://arxiv.org/abs/2410.16980",
        "title": "Electrode SOC and SOH estimation with electrode-level ECMs",
        "rating": "-2",
        "keywords": [
            [
                "health",
                "diagnosis"
            ]
        ],
        "abstract": "Being able to predict battery internal states that are related to battery degradation is a key aspect to improve battery lifetime and performance, enhancing cleaner electric transportation and energy generation. However, most present battery management systems (BMSs) use equivalent-circuit models (ECMs) for state of charge (SOC) and state of health (SOH) estimation. These models are not able to predict these aging-related variables, and therefore, they cannot be used to limit battery degradation. In this paper, we propose a method for electrode-level SOC (eSOC) and electrode-level SOH (eSOH) estimation using an electrode-level ECM (eECM). The method can produce estimates of the states of lithiation (SOL) of both electrodes and update the eSOH parameters to maintain estimation accuracy through the lifetime of the battery. Furthermore, the eSOH parameter estimates are used to obtain degradation mode information, which could be used to improve state estimation, health diagnosis and prognosis. The method was validated in simulation and experimentally.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17015",
        "abstract url": "https://arxiv.org/abs/2410.17015",
        "title": "Magneto-oscillatory localization for small-scale robots",
        "rating": "-2",
        "keywords": [
            [
                "biological",
                "medical",
                "surgical"
            ]
        ],
        "abstract": "Magnetism is widely used for the wireless localization and actuation of robots and devices for medical procedures. However, current static magnetic localization methods suffer from large required magnets and are limited to only five degrees of freedom due to a fundamental constraint of the rotational symmetry around the magnetic axis. We present the small-scale magneto-oscillatory localization (SMOL) method, which is capable of wirelessly localizing a millimeter-scale tracker with full six degrees of freedom in deep biological tissues. The SMOL device uses the temporal oscillation of a mechanically resonant cantilever with a magnetic dipole to break the rotational symmetry, and exploits the frequency-response to achieve a high signal-to-noise ratio with sub-millimeter accuracy over a large distance of up to 12 centimeters and quasi-continuous refresh rates up to 200 Hz. Integration into real-time closed-loop controlled robots and minimally-invasive surgical tools are demonstrated to reveal the vast potential of the SMOL method.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Pages 1-35 main text (incl. 4 figures), pages 36-57 supplementary materials"
    },
    {
        "paper id": "2410.17035",
        "abstract url": "https://arxiv.org/abs/2410.17035",
        "title": "DIRI: Adversarial Patient Reidentification with Large Language Models for Evaluating Clinical Text Anonymization",
        "rating": "-2",
        "keywords": [
            [
                "Re-Identification"
            ],
            [
                "biomedical",
                "medical",
                "health",
                "Clinical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Sharing protected health information (PHI) is critical for furthering biomedical research. Before data can be distributed, practitioners often perform deidentification to remove any PHI contained in the text. Contemporary deidentification methods are evaluated on highly saturated datasets (tools achieve near-perfect accuracy) which may not reflect the full variability or complexity of real-world clinical text and annotating them is resource intensive, which is a barrier to real-world applications. To address this gap, we developed an adversarial approach using a large language model (LLM) to re-identify the patient corresponding to a redacted clinical note and evaluated the performance with a novel De-Identification/Re-Identification (DIRI) method. Our method uses a large language model to reidentify the patient corresponding to a redacted clinical note. We demonstrate our method on medical data from Weill Cornell Medicine anonymized with three deidentification tools: rule-based Philter and two deep-learning-based models, BiLSTM-CRF and ClinicalBERT. Although ClinicalBERT was the most effective, masking all identified PII, our tool still reidentified 9% of clinical notes Our study highlights significant weaknesses in current deidentification technologies while providing a tool for iterative development and improvement.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17048",
        "abstract url": "https://arxiv.org/abs/2410.17048",
        "title": "Security Enhancement of Quantum Communication in Space-Air-Ground Integrated Networks",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "This paper investigates a transmission scheme for enhancing quantum communication security, aimed at improving the security of space-air-ground integrated networks (SAGIN). Quantum teleportation achieves the transmission of quantum states through quantum channels. In simple terms, an unknown quantum state at one location can be reconstructed on a particle at another location. By combining classical Turbo coding with quantum Shor error-correcting codes, we propose a practical solution that ensures secure information transmission even in the presence of errors in both classical and quantum channels. To provide absolute security under SAGIN, we add a quantum secure direct communication (QSDC) protocol to the current system. Specifically, by accounting for the practical scenario of eavesdropping in quantum channels, the QSDC protocol utilizes virtual entangled pairs to detect the presence of eavesdroppers. Consequently, the overall scheme guarantees both the reliability and absolute security of communication.",
        "subjects": [
            "quant-ph",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17051",
        "abstract url": "https://arxiv.org/abs/2410.17051",
        "title": "Data-driven Coreference-based Ontology Building",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "biomedical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "While coreference resolution is traditionally used as a component in individual document understanding, in this work we take a more global view and explore what can we learn about a domain from the set of all document-level coreference relations that are present in a large corpus. We derive coreference chains from a corpus of 30 million biomedical abstracts and construct a graph based on the string phrases within these chains, establishing connections between phrases if they co-occur within the same coreference chain. We then use the graph structure and the betweeness centrality measure to distinguish between edges denoting hierarchy, identity and noise, assign directionality to edges denoting hierarchy, and split nodes (strings) that correspond to multiple distinct concepts. The result is a rich, data-driven ontology over concepts in the biomedical domain, parts of which overlaps significantly with human-authored ontologies. We release the coreference chains and resulting ontology under a creative-commons license, along with the code.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17062",
        "abstract url": "https://arxiv.org/abs/2410.17062",
        "title": "Miniature magneto-oscillatory wireless sensor for magnetic field and gradient measurements",
        "rating": "-2",
        "keywords": [
            [
                "surgical"
            ]
        ],
        "abstract": "Magneto-oscillatory devices have been recently developed as very potent wireless miniature position trackers and sensors with an exceptional accuracy and sensing distance for surgical and robotic applications. However, it is still unclear to which extend a mechanically resonating sub-millimeter magnet interacts with external magnetic fields or gradients, which induce frequency shifts of sub-mHz to several Hz and therefore affect the sensing accuracy. Here, we investigate this effect experimentally on a cantilever-based magneto-oscillatory wireless sensor (MOWS) and build an analytical model concerning magnetic and mechanical interactions. The millimeter-scale MOWS is capable to detect magnetic fields with sub-uT resolution to at least +/- 5 mT, and simultaneously detects magnetic field gradients with a resolution of 65 uT/m to at least +/- 50 mT/m. The magnetic field sensitivity allows direct calculation of mechanical device properties, and by rotation, individual contributions of the magnetic field and gradient can be analyzed. The derived model is general and can be applied to other magneto-oscillatory systems interacting with magnetic environments.",
        "subjects": [
            "cs.RO",
            "physics.app-ph"
        ],
        "comment": "Main text: 7 pages with figures; Supplementary materials 6 pages with figures"
    },
    {
        "paper id": "2410.17103",
        "abstract url": "https://arxiv.org/abs/2410.17103",
        "title": "A Hybrid Simulation of DNN-based Gray Box Models",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Simulation is vital for engineering disciplines, as it enables the prediction and design of physical systems. However, the computational challenges inherent to large-scale simulations often arise from complex device models featuring high degrees of nonlinearities or hidden physical behaviors not captured by first principles. Gray-box models combine deep neural networks (DNNs) with physics-based models to address the computational challenges in modeling physical systems. A well-crafted gray box model capitalizes on the interpretability and accuracy of a physical model while incorporating DNNs to capture hidden physical behaviors and mitigate computational load associated with highly nonlinear components. Previously, gray box models have been constructed by defining an explicit combination of physics-based and DNN models to represent the behavior of sub-systems; however this cannot represent the coupled interactions within physical systems. We explore an implicit gray box model, where both DNNs and physical equations share a common set of state-variables. While this approach captures coupled interactions at the boundary of DNN and physics-based models, simulating the implicit gray box model remains an open-ended problem. In this work, we introduce a new hybrid simulation that integrates DNNs into the numerical solvers of simulation engines to fully simulate implicit gray box models of large physical systems. This is accomplished by backpropagating through the DNN to calculate Jacobian values during each iteration of the numerical method. The hybrid simulation improves the accuracy and runtime compared to physics-based simulation and enables reusable DNN models with lower data requirements. We explore the advantages of this approach as compared to physics-based, black box, and other gray box methods for simulating the steady-state and transient behavior of power systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17134",
        "abstract url": "https://arxiv.org/abs/2410.17134",
        "title": "TELII: Temporal Event Level Inverted Indexing for Cohort Discovery on a Large Covid-19 EHR Dataset",
        "rating": "-2",
        "keywords": [
            [
                "Health",
                "clinical"
            ]
        ],
        "abstract": "Cohort discovery is a crucial step in clinical research on Electronic Health Record (EHR) data. Temporal queries, which are common in cohort discovery, can be time-consuming and prone to errors when processed on large EHR datasets. In this work, we introduce TELII, a temporal event level inverted indexing method designed for cohort discovery on large EHR datasets. TELII is engineered to pre-compute and store the relations along with the time difference between events, thereby providing fast and accurate temporal query capabilities. We implemented TELII for the OPTUM de-identified COVID-19 EHR dataset, which contains data from 8.87 million patients. We demonstrate four common temporal query tasks and their implementation using TELII with a MongoDB backend. Our results show that the temporal query speed for TELII is up to 2000 times faster than that of existing non-temporal inverted indexes. TELII achieves millisecond-level response times, enabling users to quickly explore event relations and find preliminary evidence for their research questions. Not only is TELII practical and straightforward to implement, but it also offers easy adaptability to other EHR datasets. These advantages underscore TELII's potential to serve as the query engine for EHR-based applications, ensuring fast, accurate, and user-friendly query responses.",
        "subjects": [
            "cs.DB",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17184",
        "abstract url": "https://arxiv.org/abs/2410.17184",
        "title": "Technical Report: Toward Applying Quantum Computing to Network Verification",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Network verification (NWV), broadly defined as the verification of properties of distributed protocols used in network systems, cannot be efficiently solved on classical hardware via brute force. Prior work has developed a variety of methods that scale by observing a structure in the search space and then evaluating classes within the search space instead of individual instances. However, even these classification mechanisms have their limitations. In this paper, we consider a radically different approach: applying quantum computing to more efficiently solve NWV problems. We provide an overview of how to map variants of NWV problems into unstructured search problems that can be solved via quantum computing with quadratic speedup, making the approach feasible in theory to problems that are double in size (of the input). Emerging quantum systems cannot yet tackle problems of practical interest, but rapid advances in hardware and algorithm development make now a great time to start thinking about their application. With this in mind, we explore the limits of scale of the problem for which quantum computing can solve NWV problems as unstructured search.",
        "subjects": [
            "quant-ph",
            "cs.CR",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17198",
        "abstract url": "https://arxiv.org/abs/2410.17198",
        "title": "One-shot Multiple Access Channel Simulation",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We consider the problem of shared randomness-assisted multiple access channel (MAC) simulation for product inputs and characterize the one-shot communication cost region via almost-matching inner and outer bounds in terms of the smooth max-information of the channel, featuring auxiliary random variables of bounded size. The achievability relies on a rejection-sampling algorithm to simulate an auxiliary channel between each sender and the decoder, and producing the final output based on the output of these intermediate channels. The converse follows via information-spectrum based arguments. To bound the cardinality of the auxiliary random variables, we employ the perturbation method from [Anantharam et al., IEEE Trans. Inf. Theory (2019)] in the one-shot setting. For the asymptotic setting and vanishing errors, our result expands to a tight single-letter rate characterization and consequently extends a special case of the simulation results of [Kurri et al., IEEE Trans. Inf. Theory (2022)] for fixed, independent and identically distributed (iid) product inputs to universal simulation for any product inputs. We broaden our discussion into the quantum realm by studying feedback simulation of quantum-to-classical (QC) MACs with product measurements [Atif et al., IEEE Trans. Inf. Theory (2022)]. For fixed product inputs and with shared randomness assistance, we give a quasi tight one-shot communication cost region with corresponding single-letter asymptotic iid expansion.",
        "subjects": [
            "cs.IT",
            "quant-ph"
        ],
        "comment": "Total 42 pages, main text 23 pages, References and Appendices 19 pages, 2 Figures"
    },
    {
        "paper id": "2410.17348",
        "abstract url": "https://arxiv.org/abs/2410.17348",
        "title": "User Experience Evaluation of AR Assisted Industrial Maintenance and Support Applications",
        "rating": "-2",
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "The paper introduces an innovative approach to industrial maintenance leveraging augmented reality (AR) technology, focusing on enhancing the user experience and efficiency. The shift from traditional to proactive maintenance strategies underscores the significance of maintenance in industrial systems. The proposed solution integrates AR interfaces, particularly through Head-Mounted Display (HMD) devices, to provide expert personnel-aided decision support for maintenance technicians, with the association of Artificial Intelligence (AI) solutions. The study explores the user experience aspect of AR interfaces in a simulated industrial environment, aiming to improve the maintenance processes' intuitiveness and effectiveness. Evaluation metrics such as the NASA Task Load Index (NASA-TLX) and the System Usability Scale (SUS) are employed to assess the usability, performance, and workload implications of the AR maintenance system. Additionally, the paper discusses the technical implementation, methodology, and results of experiments conducted to evaluate the effectiveness of the proposed solution.",
        "subjects": [
            "cs.HC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17374",
        "abstract url": "https://arxiv.org/abs/2410.17374",
        "title": "Reconstructing MRI Parameters Using a Noncentral Chi Noise Model",
        "rating": "-2",
        "keywords": [
            [
                "MRI",
                "clinical"
            ]
        ],
        "abstract": "Quantitative magnetic resonance imaging (qMRI) allows images to be compared across sites and time points, which is particularly important for assessing long-term conditions or for longitudinal studies. The multiparametric mapping (MPM) protocol is used to acquire images with conventional clinical contrasts, namely PD-, T1-, and MT-weighted volumes. Through multi-echo acquisition for each contrast and variations in flip angles between PD- and T1-weighted contrasts, parameter maps, such as proton density (PD), longitudinal relaxation rate (R1), apparent transverse relaxation rate (R2$^*$), and magnetization transfer saturation (MT$_{sat}$), can be estimated. Various algorithms have been employed to estimate these parameters from the acquired volumes. This paper extends an existing maximum a posteriori approach, which uses joint total variation regularization, by transitioning from a Gaussian noise approximation to a more physically plausible model that assumes noncentral chi-distributed noise.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17409",
        "abstract url": "https://arxiv.org/abs/2410.17409",
        "title": "Geometric Graph Neural Network Modeling of Human Interactions in Crowded Environments",
        "rating": "-2",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "psychological"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Modeling human trajectories in crowded environments is challenging due to the complex nature of pedestrian behavior and interactions. This paper proposes a geometric graph neural network (GNN) architecture that integrates domain knowledge from psychological studies to model pedestrian interactions and predict future trajectories. Unlike prior studies using complete graphs, we define interaction neighborhoods using pedestrians' field of view, motion direction, and distance-based kernel functions to construct graph representations of crowds. Evaluations across multiple datasets demonstrate improved prediction accuracy through reduced average and final displacement error metrics. Our findings underscore the importance of integrating domain knowledge with data-driven approaches for effective modeling of human interactions in crowds.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.RO",
            "eess.SY"
        ],
        "comment": "\\c{opyright} 2024 the authors. This work has been accepted to IFAC for publication under a Creative Commons Licence CC-BY-NC-ND"
    },
    {
        "paper id": "2410.17441",
        "abstract url": "https://arxiv.org/abs/2410.17441",
        "title": "On the Sampling Sparsity of Neuromorphic Analog-to-Spike Conversion based on Leaky Integrate-and-Fire",
        "rating": "-2",
        "keywords": [
            [
                "bio-inspired"
            ]
        ],
        "abstract": "In contrast to the traditional principle of periodic sensing neuromorphic engineering pursues a paradigm shift towards bio-inspired event-based sensing, where events are primarily triggered by a change in the perceived stimulus. We show in a rigorous mathematical way that information encoding by means of Threshold-Based Representation based on either Leaky Integrate-and-Fire (LIF) or Send-on-Delta (SOD) is linked to an analog-to-spike conversion that guarantees maximum sparsity while satisfying an approximation condition based on the Alexiewicz norm.",
        "subjects": [
            "eess.SP",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17484",
        "abstract url": "https://arxiv.org/abs/2410.17484",
        "title": "Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering",
        "rating": "-2",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Medical",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Conventional medical artificial intelligence (AI) models face barriers in clinical application and ethical issues owing to their inability to handle the privacy-sensitive characteristics of medical data. We present a novel personalized federated learning (pFL) method for medical visual question answering (VQA) models, addressing privacy reliability challenges in the medical domain. Our method introduces learnable prompts into a Transformer architecture to efficiently train it on diverse medical datasets without massive computational costs. Then we introduce a reliable client VQA model that incorporates Dempster-Shafer evidence theory to quantify uncertainty in predictions, enhancing the model's reliability. Furthermore, we propose a novel inter-client communication mechanism that uses maximum likelihood estimation to balance accuracy and uncertainty, fostering efficient integration of insights across clients.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17488",
        "abstract url": "https://arxiv.org/abs/2410.17488",
        "title": "GenDP: 3D Semantic Fields for Category-Level Generalizable Diffusion Policy",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "RGBD"
            ],
            [
                "Diffusion"
            ],
            [
                "robotic manipulation"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion-based policies have shown remarkable capability in executing complex robotic manipulation tasks but lack explicit characterization of geometry and semantics, which often limits their ability to generalize to unseen objects and layouts. To enhance the generalization capabilities of Diffusion Policy, we introduce a novel framework that incorporates explicit spatial and semantic information via 3D semantic fields. We generate 3D descriptor fields from multi-view RGBD observations with large foundational vision models, then compare these descriptor fields against reference descriptors to obtain semantic fields. The proposed method explicitly considers geometry and semantics, enabling strong generalization capabilities in tasks requiring category-level generalization, resolving geometric ambiguities, and attention to subtle geometric details. We evaluate our method across eight tasks involving articulated objects and instances with varying shapes and textures from multiple object categories. Our method demonstrates its effectiveness by increasing Diffusion Policy's average success rate on unseen instances from 20% to 93%. Additionally, we provide a detailed analysis and visualization to interpret the sources of performance gain and explain how our method can generalize to novel instances.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted to Conference on Robot Learning (CoRL 2024). Project Page: https://robopil.github.io/GenDP/"
    },
    {
        "paper id": "2410.17494",
        "abstract url": "https://arxiv.org/abs/2410.17494",
        "title": "Enhancing Multimodal Medical Image Classification using Cross-Graph Modal Contrastive Learning",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Medical",
                "diagnosis",
                "disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The classification of medical images is a pivotal aspect of disease diagnosis, often enhanced by deep learning techniques. However, traditional approaches typically focus on unimodal medical image data, neglecting the integration of diverse non-image patient data. This paper proposes a novel Cross-Graph Modal Contrastive Learning (CGMCL) framework for multimodal medical image classification. The model effectively integrates both image and non-image data by constructing cross-modality graphs and leveraging contrastive learning to align multimodal features in a shared latent space. An inter-modality feature scaling module further optimizes the representation learning process by reducing the gap between heterogeneous modalities. The proposed approach is evaluated on two datasets: a Parkinson's disease (PD) dataset and a public melanoma dataset. Results demonstrate that CGMCL outperforms conventional unimodal methods in accuracy, interpretability, and early disease prediction. Additionally, the method shows superior performance in multi-class melanoma classification. The CGMCL framework provides valuable insights into medical image classification while offering improved disease interpretability and predictive capabilities.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17539",
        "abstract url": "https://arxiv.org/abs/2410.17539",
        "title": "Urban Outdoor Propagation Measurements and Channel Models at 6.75 GHz FR1(C) and 16.95 GHz FR3 Upper Mid-Band Spectrum for 5G and 6G",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Global allocations in the upper mid-band spectrum (4--24 GHz) necessitate a comprehensive exploration of the propagation behavior to meet the promise of coverage and capacity. This paper presents an extensive Urban Microcell (UMi) outdoor propagation measurement campaign at 6.75 GHz and 16.95 GHz conducted in Downtown Brooklyn, USA, using a 1 GHz bandwidth sliding correlation channel sounder over 40--880 m propagation distance, encompassing 7 Line of Sight (LOS) and 13 Non-Line of Sight (NLOS) locations. Analysis of the path loss (PL) reveals lower directional and omnidirectional PL exponents compared to mmWave and sub-THz frequencies in the UMi environment, using the close-in PL model with a 1 m reference distance. Additionally, a decreasing trend in root mean square (RMS) delay spread (DS) and angular spread (AS) with increasing frequency was observed. The NLOS RMS DS and RMS AS mean values are obtained consistently lower compared to 3GPP model predictions. Point data for all measured statistics at each TX-RX location are provided to supplement the models and results. The spatio-temporal statistics evaluated here offer valuable insights for the design of next-generation wireless systems and networks.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 4 figures, 6 tables"
    },
    {
        "paper id": "2410.17547",
        "abstract url": "https://arxiv.org/abs/2410.17547",
        "title": "Generalizable Motion Planning via Operator Learning",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "super-resolution"
            ]
        ],
        "abstract": "In this work, we introduce a planning neural operator (PNO) for predicting the value function of a motion planning problem. We recast value function approximation as learning a single operator from the cost function space to the value function space, which is defined by an Eikonal partial differential equation (PDE). Specifically, we recast computing value functions as learning a single operator across continuous function spaces which prove is equivalent to solving an Eikonal PDE. Through this reformulation, our learned PNO is able to generalize to new motion planning problems without retraining. Therefore, our PNO model, despite being trained with a finite number of samples at coarse resolution, inherits the zero-shot super-resolution property of neural operators. We demonstrate accurate value function approximation at 16 times the training resolution on the MovingAI lab's 2D city dataset and compare with state-of-the-art neural value function predictors on 3D scenes from the iGibson building dataset. Lastly, we investigate employing the value function output of PNO as a heuristic function to accelerate motion planning. We show theoretically that the PNO heuristic is $\u03b5$-consistent by introducing an inductive bias layer that guarantees our value functions satisfy the triangle inequality. With our heuristic, we achieve a 30% decrease in nodes visited while obtaining near optimal path lengths on the MovingAI lab 2D city dataset, compared to classical planning methods (A*, RRT*).",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17552",
        "abstract url": "https://arxiv.org/abs/2410.17552",
        "title": "ESpeW: Robust Copyright Protection for LLM-based EaaS via Embedding-Specific Watermark",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Watermark"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Embeddings as a Service (EaaS) is emerging as a crucial role in AI applications. Unfortunately, EaaS is vulnerable to model extraction attacks, highlighting the urgent need for copyright protection. Although some preliminary works propose applying embedding watermarks to protect EaaS, recent research reveals that these watermarks can be easily removed. Hence, it is crucial to inject robust watermarks resistant to watermark removal attacks. Existing watermarking methods typically inject a target embedding into embeddings through linear interpolation when the text contains triggers. However, this mechanism results in each watermarked embedding having the same component, which makes the watermark easy to identify and eliminate. Motivated by this, in this paper, we propose a novel embedding-specific watermarking (ESpeW) mechanism to offer robust copyright protection for EaaS. Our approach involves injecting unique, yet readily identifiable watermarks into each embedding. Watermarks inserted by ESpeW are designed to maintain a significant distance from one another and to avoid sharing common components, thus making it significantly more challenging to remove the watermarks. Extensive experiments on four popular datasets demonstrate that ESpeW can even watermark successfully against a highly aggressive removal strategy without sacrificing the quality of embeddings. Code is available at https://github.com/liudan193/ESpeW.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19857",
        "abstract url": "https://arxiv.org/abs/2410.19857",
        "title": "Coevolutionary Control of a Neuromorphic Network through a Mixed-Feedback Architecture",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Neuromorphic computing is an interdisciplinary field that combines principles of computer engineering, electronics, and neuroscience, aiming to design hardware and software that can process information in a similar manner to biological brains, offering advantages in efficiency, adaptability, and cognitive capabilities. In this work, we propose a coevolutionary (or adaptive) mixed-feedback framework in which, mimicking a feedback control loop, a neuromorphic plant follows a predetermined desired rhythmic profile. This simple, yet efficient coevolutionary law adaptively minimizes the error between the responses of the reference and the plant through a node-to-node mapping. Such direct node correspondence ensures that each node in the plant is associated with a corresponding element in the reference, even in the presence of a discrepancy in the number of oscillators between the two networks. As a result, the controlled output of the plant effectively replicates the response of the reference in an orderly manner. Moreover, we demonstrate the effectiveness of our mixed-feedback control approach through several examples, including the amplitude and phase control when considering a plant and a reference with the same and different topologies on their associated networks, as well as the generation of complete synchrony by considering a single node reference. Additionally, we further test our control methodology by demonstrating its efficiency even in the presence of reference networks with a time-varying topology. Finally, we discuss future work for the development of similar coevolutionary laws that enable the control of networks which describe different dynamical systems, as well as higher-order topological dependencies.",
        "subjects": [
            "eess.SY",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04131",
        "abstract url": "https://arxiv.org/abs/2411.04131",
        "title": "Data Processing Chain and Products of EOS-06 OCM-3 Payload From Signal Processing to Geometric Precision",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "The Ocean Color Monitor-3, launched aboard Oceansat-3, represents a significant advancement in ocean observation technology, building upon the capabilities of its predecessors. With thirteen spectral bands, OCM-3 enhances feature identification and atmospheric correction, enabling precise data collection from a sun-synchronous orbit. With thirteen spectral bands, OCM-3 enhances feature identification and atmospheric correction, enabling precise data collection from a sunsynchronous orbit. Operating at an altitude of 732.5 km, the satellite achieves high signal-to-noise ratios (SNR) through sophisticated onboard and ground processing techniques, including advanced geometric modeling for pixel registration.The OCM-3 processing pipeline, consisting of multiple levels, ensures rigorous calibration and correction of radiometric and geometric data. This paper presents key methodologies such as dark data modeling, photo response non-uniformity correction, and smear correction, are employed to enhance data quality. The effective implementation of ground time delay integration (TDI) allows for the refinement of SNR, with evaluations demonstrating that performance specifications were exceeded. Geometric calibration procedures, including band-to-band registration and geolocation accuracy assessments, which further optimize data reliability are presented in the paper. Advanced image registration techniques leveraging Ground Control Points (GCPs) and residual error analysis significantly reduce geolocation errors, achieving precision within specified thresholds. Overall, OCM-3 comprehensive calibration and processing strategies ensure high-quality, reliable data crucial for ocean monitoring and change detection applications, facilitating improved understanding of ocean dynamics and environmental changes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2410.16858",
        "abstract url": "https://arxiv.org/abs/2410.16858",
        "title": "Dynamic graph neural networks for enhanced volatility prediction in financial markets",
        "rating": "-2.5",
        "keywords": [
            [
                "GNNs",
                "graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Volatility forecasting is essential for risk management and decision-making in financial markets. Traditional models like Generalized Autoregressive Conditional Heteroskedasticity (GARCH) effectively capture volatility clustering but often fail to model complex, non-linear interdependencies between multiple indices. This paper proposes a novel approach using Graph Neural Networks (GNNs) to represent global financial markets as dynamic graphs. The Temporal Graph Attention Network (Temporal GAT) combines Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs) to capture the temporal and structural dynamics of volatility spillovers. By utilizing correlation-based and volatility spillover indices, the Temporal GAT constructs directed graphs that enhance the accuracy of volatility predictions. Empirical results from a 15-year study of eight major global indices show that the Temporal GAT outperforms traditional GARCH models and other machine learning methods, particularly in short- to mid-term forecasts. The sensitivity and scenario-based analysis over a range of parameters and hyperparameters further demonstrate the significance of the proposed technique. Hence, this work highlights the potential of GNNs in modeling complex market behaviors, providing valuable insights for financial analysts and investors.",
        "subjects": [
            "q-fin.MF",
            "cs.LG",
            "q-fin.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17175",
        "abstract url": "https://arxiv.org/abs/2410.17175",
        "title": "Remote Timing Attacks on Efficient Language Model Inference",
        "rating": "-2.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "medical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Scaling up language models has significantly increased their capabilities. But larger models are slower models, and so there is now an extensive body of work (e.g., speculative sampling or parallel decoding) that improves the (average case) efficiency of language model generation. But these techniques introduce data-dependent timing characteristics. We show it is possible to exploit these timing differences to mount a timing attack. By monitoring the (encrypted) network traffic between a victim user and a remote language model, we can learn information about the content of messages by noting when responses are faster or slower. With complete black-box access, on open source systems we show how it is possible to learn the topic of a user's conversation (e.g., medical advice vs. coding assistance) with 90%+ precision, and on production systems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish between specific messages or infer the user's language. We further show that an active adversary can leverage a boosting attack to recover PII placed in messages (e.g., phone numbers or credit card numbers) for open source systems. We conclude with potential defenses and directions for future work.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17212",
        "abstract url": "https://arxiv.org/abs/2410.17212",
        "title": "Neuroevolution Neural Architecture Search for Evolving RNNs in Stock Return Prediction and Portfolio Trading",
        "rating": "-2.5",
        "keywords": [
            [
                "Architecture Search"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Stock return forecasting is a major component of numerous finance applications. Predicted stock returns can be incorporated into portfolio trading algorithms to make informed buy or sell decisions which can optimize returns. In such portfolio trading applications, the predictive performance of a time series forecasting model is crucial. In this work, we propose the use of the Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to progressively evolve recurrent neural networks (RNNs) for stock return predictions. RNNs are evolved independently for each stocks and portfolio trading decisions are made based on the predicted stock returns. The portfolio used for testing consists of the 30 companies in the Dow-Jones Index (DJI) with each stock have the same weight. Results show that using these evolved RNNs and a simple daily long-short strategy can generate higher returns than both the DJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull market).",
        "subjects": [
            "q-fin.PM",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17410",
        "abstract url": "https://arxiv.org/abs/2410.17410",
        "title": "Learning Graph Filters for Structure-Function Coupling based Hub Node Identification",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "fMRI"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Over the past two decades, tools from network science have been leveraged to characterize the organization of both structural and functional networks of the brain. One such measure of network organization is hub node identification. Hubs are specialized nodes within a network that link distinct brain units corresponding to specialized functional processes. Conventional methods for identifying hub nodes utilize different types of centrality measures and participation coefficient to profile various aspects of nodal importance. These methods solely rely on the functional connectivity networks constructed from functional magnetic resonance imaging (fMRI), ignoring the structure-function coupling in the brain. In this paper, we introduce a graph signal processing (GSP) based hub detection framework that utilizes both the structural connectivity and the functional activation to identify hub nodes. The proposed framework models functional activity as graph signals on the structural connectivity. Hub nodes are then detected based on the premise that hub nodes are sparse, have higher level of activity compared to their neighbors, and the non-hub nodes' activity can be modeled as the output of a graph-based filter. Based on these assumptions, an optimization framework, GraFHub, is formulated to learn the coefficients of the optimal polynomial graph filter and detect the hub nodes. The proposed framework is evaluated on both simulated data and resting state fMRI (rs-fMRI) data from Human Connectome Project (HCP).",
        "subjects": [
            "cs.SI",
            "cs.LG",
            "q-bio.NC",
            "stat.ML"
        ],
        "comment": "13 pages, 4 figures"
    },
    {
        "paper id": "2410.17430",
        "abstract url": "https://arxiv.org/abs/2410.17430",
        "title": "Real-time experiment-theory closed-loop interaction for autonomous materials science",
        "rating": "-2.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "Thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Iterative cycles of theoretical prediction and experimental validation are the cornerstone of the modern scientific method. However, the proverbial \"closing of the loop\" in experiment-theory cycles in practice are usually ad hoc, often inherently difficult, or impractical to repeat on a systematic basis, beset by the scale or the time constraint of computation or the phenomena under study. Here, we demonstrate Autonomous MAterials Search Engine (AMASE), where we enlist robot science to perform self-driving continuous cyclical interaction of experiments and computational predictions for materials exploration. In particular, we have applied the AMASE formalism to the rapid mapping of a temperature-composition phase diagram, a fundamental task for the search and discovery of new materials. Thermal processing and experimental determination of compositional phase boundaries in thin films are autonomously interspersed with real-time updating of the phase diagram prediction through the minimization of Gibbs free energies. AMASE was able to accurately determine the eutectic phase diagram of the Sn-Bi binary thin-film system on the fly from a self-guided campaign covering just a small fraction of the entire composition - temperature phase space, translating to a 6-fold reduction in the number of necessary experiments. This study demonstrates for the first time the possibility of real-time, autonomous, and iterative interactions of experiments and theory carried out without any human intervention.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17459",
        "abstract url": "https://arxiv.org/abs/2410.17459",
        "title": "Data Obfuscation through Latent Space Projection (LSP) for Privacy-Preserving AI Governance: Case Studies in Medical Diagnosis and Finance Fraud Detection",
        "rating": "-2.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "Medical",
                "healthcare",
                "Diagnosis",
                "cancer"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "As AI systems increasingly integrate into critical societal sectors, the demand for robust privacy-preserving methods has escalated. This paper introduces Data Obfuscation through Latent Space Projection (LSP), a novel technique aimed at enhancing AI governance and ensuring Responsible AI compliance. LSP uses machine learning to project sensitive data into a latent space, effectively obfuscating it while preserving essential features for model training and inference. Unlike traditional privacy methods like differential privacy or homomorphic encryption, LSP transforms data into an abstract, lower-dimensional form, achieving a delicate balance between data utility and privacy. Leveraging autoencoders and adversarial training, LSP separates sensitive from non-sensitive information, allowing for precise control over privacy-utility trade-offs. We validate LSP's effectiveness through experiments on benchmark datasets and two real-world case studies: healthcare cancer diagnosis and financial fraud analysis. Our results show LSP achieves high performance (98.7% accuracy in image classification) while providing strong privacy (97.3% protection against sensitive attribute inference), outperforming traditional anonymization and privacy-preserving methods. The paper also examines LSP's alignment with global AI governance frameworks, such as GDPR, CCPA, and HIPAA, highlighting its contribution to fairness, transparency, and accountability. By embedding privacy within the machine learning pipeline, LSP offers a promising approach to developing AI systems that respect privacy while delivering valuable insights. We conclude by discussing future research directions, including theoretical privacy guarantees, integration with federated learning, and enhancing latent space interpretability, positioning LSP as a critical tool for ethical AI advancement.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.CY"
        ],
        "comment": "19 pages, 6 figures, submitted to Conference ICADCML2025"
    },
    {
        "paper id": "2410.17510",
        "abstract url": "https://arxiv.org/abs/2410.17510",
        "title": "Congestion Forecast for Trains with Railroad-Graph-based Semi-Supervised Learning using Sparse Passenger Reports",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Forecast"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Forecasting rail congestion is crucial for efficient mobility in transport systems. We present rail congestion forecasting using reports from passengers collected through a transit application. Although reports from passengers have received attention from researchers, ensuring a sufficient volume of reports is challenging due to passenger's reluctance. The limited number of reports results in the sparsity of the congestion label, which can be an issue in building a stable prediction model. To address this issue, we propose a semi-supervised method for congestion forecasting for trains, or SURCONFORT. Our key idea is twofold: firstly, we adopt semi-supervised learning to leverage sparsely labeled data and many unlabeled data. Secondly, in order to complement the unlabeled data from nearby stations, we design a railway network-oriented graph and apply the graph to semi-supervised graph regularization. Empirical experiments with actual reporting data show that SURCONFORT improved the forecasting performance by 14.9% over state-of-the-art methods under the label sparsity.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted in ACM SIGSPATIAL 2024"
    },
    {
        "paper id": "2410.17518",
        "abstract url": "https://arxiv.org/abs/2410.17518",
        "title": "Univariate Conditional Variational Autoencoder for Morphogenic Patterns Design in Frontal Polymerization-Based Manufacturing",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Under some initial and boundary conditions, the rapid reaction-thermal diffusion process taking place during frontal polymerization (FP) destabilizes the planar mode of front propagation, leading to spatially varying, complex hierarchical patterns in thermoset polymeric materials. Although modern reaction-diffusion models can predict the patterns resulting from unstable FP, the inverse design of patterns, which aims to retrieve process conditions that produce a desired pattern, remains an open challenge due to the non-unique and non-intuitive mapping between process conditions and manufactured patterns. In this work, we propose a probabilistic generative model named univariate conditional variational autoencoder (UcVAE) for the inverse design of hierarchical patterns in FP-based manufacturing. Unlike the cVAE, which encodes both the design space and the design target, the UcVAE encodes only the design space. In the encoder of the UcVAE, the number of training parameters is significantly reduced compared to the cVAE, resulting in a shorter training time while maintaining comparable performance. Given desired pattern images, the trained UcVAE can generate multiple process condition solutions that produce high-fidelity hierarchical patterns.",
        "subjects": [
            "physics.comp-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17555",
        "abstract url": "https://arxiv.org/abs/2410.17555",
        "title": "FairDgcl: Fairness-aware Recommendation with Dynamic Graph Contrastive Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "As trustworthy AI continues to advance, the fairness issue in recommendations has received increasing attention. A recommender system is considered unfair when it produces unequal outcomes for different user groups based on user-sensitive attributes (e.g., age, gender). Some researchers have proposed data augmentation-based methods aiming at alleviating user-level unfairness by altering the skewed distribution of training data among various user groups. Despite yielding promising results, they often rely on fairness-related assumptions that may not align with reality, potentially reducing the data quality and negatively affecting model effectiveness. To tackle this issue, in this paper, we study how to implement high-quality data augmentation to improve recommendation fairness. Specifically, we propose FairDgcl, a dynamic graph adversarial contrastive learning framework aiming at improving fairness in recommender system. First, FairDgcl develops an adversarial contrastive network with a view generator and a view discriminator to learn generating fair augmentation strategies in an adversarial style. Then, we propose two dynamic, learnable models to generate contrastive views within contrastive learning framework, which automatically fine-tune the augmentation strategies. Meanwhile, we theoretically show that FairDgcl can simultaneously generate enhanced representations that possess both fairness and accuracy. Lastly, comprehensive experiments conducted on four real-world datasets demonstrate the effectiveness of the proposed FairDgcl.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "12 pages, submitted to TKDE"
    },
    {
        "paper id": "2411.02423",
        "abstract url": "https://arxiv.org/abs/2411.02423",
        "title": "Development of CODO: A Comprehensive Tool for COVID-19 Data Representation, Analysis, and Visualization",
        "rating": "-2.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "diagnosis"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial intelligence (AI) has become indispensable for managing and processing the vast amounts of data generated during the COVID-19 pandemic. Ontology, which formalizes knowledge within a domain using standardized vocabularies and relationships, plays a crucial role in AI by enabling automated reasoning, data integration, semantic interoperability, and extracting meaningful insights from extensive datasets. The diversity of COVID-19 datasets poses challenges in comprehending this information for both human and machines. Existing COVID-19 ontologies are designed to address specific aspects of the pandemic but lack comprehensive coverage across all essential dimensions. To address this gap, CODO, an integrated ontological model has been developed encompassing critical facets of COVID-19 information such as aetiology, epidemiology, transmission, pathogenesis, diagnosis, prevention, genomics, therapeutic safety, and more. This paper reviews CODO since its inception in 2020, detailing its developments and highlighting CODO as a tool for the aggregation, representation, analysis, and visualization of diverse COVID-19 data. The major contribution of this paper is to provide a summary of the development of CODO, and outline the overall development and evaluation approach. By adhering to best practices and leveraging W3C standards, CODO ensures data integration and semantic interoperability, supporting effective navigation of COVID-19 complexities across various domains.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "15 pages, 4 figures, journal"
    },
    {
        "paper id": "2411.03328",
        "abstract url": "https://arxiv.org/abs/2411.03328",
        "title": "Foundation Models for Rapid Autonomy Validation",
        "rating": "-2.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "pathological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We are motivated by the problem of autonomous vehicle performance validation. A key challenge is that an autonomous vehicle requires testing in every kind of driving scenario it could encounter, including rare events, to provide a strong case for safety and show there is no edge-case pathological behavior. Autonomous vehicle companies rely on potentially millions of miles driven in realistic simulation to expose the driving stack to enough miles to estimate rates and severity of collisions. To address scalability and coverage, we propose the use of a behavior foundation model, specifically a masked autoencoder (MAE), trained to reconstruct driving scenarios. We leverage the foundation model in two complementary ways: we (i) use the learned embedding space to group qualitatively similar scenarios together and (ii) fine-tune the model to label scenario difficulty based on the likelihood of a collision upon re-simulation. We use the difficulty scoring as importance weighting for the groups of scenarios. The result is an approach which can more rapidly estimate the rates and severity of collisions by prioritizing hard scenarios while ensuring exposure to every kind of driving scenario.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16731",
        "abstract url": "https://arxiv.org/abs/2410.16731",
        "title": "RIS-Assisted THz MIMO Wireless System in the Presence of Direct Link for CV-QKD with Limited Quantum Memory",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "A reconfigurable intelligent surface (RIS)-aided multiple-input multiple-output (MIMO) wireless communication system is considered in this paper wherein the transmitter, Alice modulates secret keys, by using a continuous variable quantum key distribution technique to be transmitted to the receiver, Bob, which employs homodyne detection for data decoding. The data is transmitted over two paths, namely a direct path between Alice and Bob and the wireless path between them via the RIS. Transmit and receive beamsplitters are employed in the system to transform the MIMO terahertz channels into parallel single-input single-output channels. Considering an eavesdropper, Eve, to attack all the three wireless channels in the system (i.e., the direct channel, the channel between Alice and RIS, and between the RIS and Bob) but having restricted quantum memory limiting it to store the ancilla modes from either of these three wireless channels, novel expressions for the secret key rate (SKR) of the system are derived. Numerical results are presented to demonstrate the dependency of the system's performance on various system parameters. It is observed that the RIS plays a key role in increasing the SKR of the system and the transmission distance, ensuring secure communications between Alice and Bob. The significance of employing RIS is observed specifically for the case when Eve measures the ancilla modes of the channel between the RIS and Bob. Furthermore, for all such measurement scenarios, optimal angles are obtained for the phase shifts of the RIS elements to maximize the SKR for various MIMO configurations and transmission distance between Alice and Bob.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "13 pages, 6 figures"
    },
    {
        "paper id": "2410.16875",
        "abstract url": "https://arxiv.org/abs/2410.16875",
        "title": "Edge-Spreading Raptor-Like LDPC Codes for 6G Wireless Systems",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "Next-generation channel coding has stringent demands on throughput, energy consumption, and error rate performance while maintaining key features of 5G New Radio (NR) standard codes such as rate compatibility, which is a significant challenge. Due to excellent capacity-achieving performance, spatially-coupled low-density parity-check (SC-LDPC) codes are considered a promising candidate for next-generation channel coding. In this paper, we propose an SC-LDPC code family called edge-spreading Raptor-like (ESRL) codes for 6G. Unlike other SC-LDPC codes that adopt the structure of existing rate-compatible LDPC block codes before coupling, ESRL codes maximize the possible locations of edge placement and focus on constructing an optimal coupled matrix. Moreover, a new graph representation called the unified graph is introduced. This graph offers a global perspective on ESRL codes and identifies the optimal edge reallocation to optimize the spreading strategy. We conduct comprehensive comparisons of ESRL codes and 5G-NR LDPC codes. Simulation results demonstrate that when all decoding parameters and complexity are the same, ESRL codes have obvious advantages in error rate performance and throughput compared to 5G-NR LDPC codes, making them a promising solution towards next-generation channel coding.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "13 pages, 14 figures"
    },
    {
        "paper id": "2410.16943",
        "abstract url": "https://arxiv.org/abs/2410.16943",
        "title": "FlightAR: AR Flight Assistance Interface with Multiple Video Streams and Object Detection Aimed at Immersive Drone Control",
        "rating": "-3",
        "keywords": [
            [
                "vehicle",
                "Flight"
            ],
            [
                "UAV",
                "Drone"
            ]
        ],
        "abstract": "The swift advancement of unmanned aerial vehicle (UAV) technologies necessitates new standards for developing human-drone interaction (HDI) interfaces. Most interfaces for HDI, especially first-person view (FPV) goggles, limit the operator's ability to obtain information from the environment. This paper presents a novel interface, FlightAR, that integrates augmented reality (AR) overlays of UAV first-person view (FPV) and bottom camera feeds with head-mounted display (HMD) to enhance the pilot's situational awareness. Using FlightAR, the system provides pilots not only with a video stream from several UAV cameras simultaneously, but also the ability to observe their surroundings in real time. User evaluation with NASA-TLX and UEQ surveys showed low physical demand ($\u03bc=1.8$, $SD = 0.8$) and good performance ($\u03bc=3.4$, $SD = 0.8$), proving better user assessments in comparison with baseline FPV goggles. Participants also rated the system highly for stimulation ($\u03bc=2.35$, $SD = 0.9$), novelty ($\u03bc=2.1$, $SD = 0.9$) and attractiveness ($\u03bc=1.97$, $SD = 1$), indicating positive user experiences. These results demonstrate the potential of the system to improve UAV piloting experience through enhanced situational awareness and intuitive control. The code is available here: https://github.com/Sautenich/FlightAR",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Manuscript accepted in IEEE International Conference on Robotics and Biomimetics (IEEE ROBIO 2024)"
    },
    {
        "paper id": "2410.16965",
        "abstract url": "https://arxiv.org/abs/2410.16965",
        "title": "Downtime Required for Bitcoin Quantum-Safety",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum devices capable of breaking the public-key cryptosystems that Bitcoin relies on to secure its transactions are expected with reasonable probability within a decade. Quantum attacks would put at risk the entire Bitcoin network, which has an estimated value of around 500 billion USD. To prevent this threat, a proactive approach is critical. The only known way to prevent any such attack is to upgrade the currently used public-key cryptosystems, namely ECDSA, with so-called post-quantum cryptosystems which have no known vulnerabilities to quantum attacks. In this paper, we analyse the technical cost of such an upgrade. We calculate a non-tight lower bound on the cumulative downtime required for the above transition to be 1827.96 hours, or 76.16 days. We also demonstrate that the transition needs to be fully completed before the availability of ECDSA-256 breaking quantum devices, in order to ensure Bitcoin's ongoing security. The conclusion is that the Bitcoin upgrade to quantum-safe protocols needs to be started as soon as possible in order to guarantee its ongoing operations.",
        "subjects": [
            "quant-ph",
            "cs.CR",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17005",
        "abstract url": "https://arxiv.org/abs/2410.17005",
        "title": "Hybrid Generative AI for De Novo Design of Co-Crystals with Enhanced Tabletability",
        "rating": "-3",
        "keywords": [
            [
                "biomedical"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Co-crystallization is an accessible way to control physicochemical characteristics of organic crystals, which finds many biomedical applications. In this work, we present Generative Method for Co-crystal Design (GEMCODE), a novel pipeline for automated co-crystal screening based on the hybridization of deep generative models and evolutionary optimization for broader exploration of the target chemical space. GEMCODE enables fast de novo co-crystal design with target tabletability profiles, which is crucial for the development of pharmaceuticals. With a series of experimental studies highlighting validation and discovery cases, we show that GEMCODE is effective even under realistic computational constraints. Furthermore, we explore the potential of language models in generating co-crystals. Finally, we present numerous previously unknown co-crystals predicted by GEMCODE and discuss its potential in accelerating drug development.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted at 38th Conference on Neural Information Processing Systems (NeurIPS)"
    },
    {
        "paper id": "2410.17017",
        "abstract url": "https://arxiv.org/abs/2410.17017",
        "title": "SPVSoAP3D: A Second-order Average Pooling Approach to enhance 3D Place Recognition in Horticultural Environments",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "LiDAR"
            ],
            [
                "agricultural"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D LiDAR-based place recognition has been extensively researched in urban environments, yet it remains underexplored in agricultural settings. Unlike urban contexts, horticultural environments, characterized by their permeability to laser beams, result in sparse and overlapping LiDAR scans with suboptimal geometries. This phenomenon leads to intra- and inter-row descriptor ambiguity. In this work, we address this challenge by introducing SPVSoAP3D, a novel modeling approach that combines a voxel-based feature extraction network with an aggregation technique based on a second-order average pooling operator, complemented by a descriptor enhancement stage. Furthermore, we augment the existing HORTO-3DLM dataset by introducing two new sequences derived from horticultural environments. We evaluate the performance of SPVSoAP3D against state-of-the-art (SOTA) models, including OverlapTransformer, PointNetVLAD, and LOGG3D-Net, utilizing a cross-validation protocol on both the newly introduced sequences and the existing HORTO-3DLM dataset. The findings indicate that the average operator is more suitable for horticultural environments compared to the max operator and other first-order pooling techniques. Additionally, the results highlight the improvements brought by the descriptor enhancement stage.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "This work has been accepted to IROS 2024"
    },
    {
        "paper id": "2410.17171",
        "abstract url": "https://arxiv.org/abs/2410.17171",
        "title": "Impact of 3D LiDAR Resolution in Graph-based SLAM Approaches: A Comparative Study",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "Simultaneous Localization and Mapping (SLAM) is a key component of autonomous systems operating in environments that require a consistent map for reliable localization. SLAM has been a widely studied topic for decades with most of the solutions being camera or LiDAR based. Early LiDAR-based approaches primarily relied on 2D data, whereas more recent frameworks use 3D data. In this work, we survey recent 3D LiDAR-based Graph-SLAM methods in urban environments, aiming to compare their strengths, weaknesses, and limitations. Additionally, we evaluate their robustness regarding the LiDAR resolution namely 64 $vs$ 128 channels. Regarding SLAM methods, we evaluate SC-LeGO-LOAM, SC-LIO-SAM, Cartographer, and HDL-Graph on real-world urban environments using the KITTI odometry dataset (a LiDAR with 64-channels only) and a new dataset (AUTONOMOS-LABS). The latter dataset, collected using instrumented vehicles driving in Berlin suburban area, comprises both 64 and 128 LiDARs. The experimental results are reported in terms of quantitative `metrics' and complemented by qualitative maps.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "This work has been accepted for publication in ROBOT24"
    },
    {
        "paper id": "2410.17525",
        "abstract url": "https://arxiv.org/abs/2410.17525",
        "title": "Physics-driven AI for Channel Estimation in Cellular Network",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Physics"
            ]
        ],
        "abstract": "In cellular mobile networks, wireless channel quality (CQ) is a crucial factor in determining communication performance and user's network experience. Accurately predicting CQ based on real environmental characteristics, specific base station configurations and user trajectories can help network operators optimize base station deployment, improving coverage and capacity. The Received Signal Reference Power (RSRP) and Signal-to-Interference-plus-Noise Ratio (SINR) of user equipment (UE) are key indicators of CQ in wireless communication. However, existing researches have limitations in terms of generation accuracy. Regression methods such as statistical inference and random forests fail to effectively capture the unique characteristics of wireless environments; theoretical derivations relying on specific communication protocols lack generalization capability; data-driven machine learning (ML) methods like Long Short-Term Memory (LSTM) Network often suffer from a lack of interpretability. To overcome these limitations, we propose physics-informed diffusion models, which accurately generate RSRP and SINR at UE based on the wireless environment, base station configurations, and user trajectories. The model adopts a modular and end-to-end design, employing a teacher-student framework to achieve knowledge distillation. This method integrates expert knowledge into the training of diffusion models, enhancing both the interpretability and accuracy, while also facilitating faster convergence of the model parameters. Furthermore, it allows for self-adaptation in various scenarios through few-shot learning. This approach provides valuable guidance for optimizing base station deployment, predicting user network experience, and building real-world simulators.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2410.16737",
        "abstract url": "https://arxiv.org/abs/2410.16737",
        "title": "Co-training partial domain adaptation networks for industrial Fault Diagnosis",
        "rating": "-3.5",
        "keywords": [
            [
                "Diagnosis"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The partial domain adaptation (PDA) challenge is a prevalent issue in industrial fault diagnosis. Drawing inspiration from traditional classification settings where such partial challenge is not a concern, we propose a novel PDA framework called Interactive Residual Domain Adaptation Networks (IRDAN), which introduces domain-wise models for each domain to provide a new perspective for the PDA challenge. Each domain-wise model is equipped with a residual domain adaptation (RDA) block to mitigate the ADP problem. Additionally, we introduce a confident information flow via an interactive learning strategy, training the modules of IRDAN sequentially to avoid cross-interference. We also establish a reliable stopping criterion for selecting the best-performing model, ensuring practical usability in real-world applications. Experiments have demonstrated the superior performance of the proposed IRDAN.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16924",
        "abstract url": "https://arxiv.org/abs/2410.16924",
        "title": "SleepCoT: A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation",
        "rating": "-3.5",
        "keywords": [
            [
                "Health",
                "healthcare"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present a novel approach to personalized sleep health management using few-shot Chain-of-Thought (CoT) distillation, enabling small-scale language models (> 2B parameters) to rival the performance of large language models (LLMs) in specialized health domains. Our method simultaneously distills problem-solving strategies, long-tail expert knowledge, and personalized recommendation capabilities from larger models into more efficient, compact models. Unlike existing systems, our approach offers three key functionalities: generating personalized sleep health recommendations, supporting user-specific follow-up inquiries, and providing responses to domain-specific knowledge questions. We focus on sleep health due to its measurability via wearable devices and its impact on overall well-being. Our experimental setup, involving GPT-4o for data synthesis, Qwen-max for instruction set creation, and Qwen2.5 1.5B for model distillation, demonstrates significant improvements over baseline small-scale models in penalization, reasoning, and knowledge application. Experiments using 100 simulated sleep reports and 1,000 domain-specific questions shows our model achieves comparable performance to larger models while maintaining efficiency for real-world deployment. This research not only advances AI-driven health management but also provides a novel approach to leveraging LLM capabilities in resource-constrained environments, potentially enhancing the accessibility of personalized healthcare solutions.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16975",
        "abstract url": "https://arxiv.org/abs/2410.16975",
        "title": "Publishing Neural Networks in Drug Discovery Might Compromise Training Data Privacy",
        "rating": "-3.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "attacks"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study investigates the risks of exposing confidential chemical structures when machine learning models trained on these structures are made publicly available. We use membership inference attacks, a common method to assess privacy that is largely unexplored in the context of drug discovery, to examine neural networks for molecular property prediction in a black-box setting. Our results reveal significant privacy risks across all evaluated datasets and neural network architectures. Combining multiple attacks increases these risks. Molecules from minority classes, often the most valuable in drug discovery, are particularly vulnerable. We also found that representing molecules as graphs and using message-passing neural networks may mitigate these risks. We provide a framework to assess privacy risks of classification models and molecular representations. Our findings highlight the need for careful consideration when sharing neural networks trained on proprietary chemical structures, informing organisations and researchers about the trade-offs between data confidentiality and model openness.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17467",
        "abstract url": "https://arxiv.org/abs/2410.17467",
        "title": "Multi-modal Machine Learning Analysis of X-ray Absorption Near-Edge Spectra and Pair Distribution Functions: Performance and Interpretability towards Experimental Design",
        "rating": "-3.5",
        "keywords": [
            [
                "X-ray"
            ],
            [
                "chemistry"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We used off-the-shelf interpretable ML techniques to combine information from multiple heterogeneous spectra: X-ray absorption near-edge spectra (XANES) and atomic pair distribution functions (PDFs), to extract information about local structure and chemistry of transition metal oxides. This approach enabled us to analyze the relative contributions of the different spectra to different prediction tasks. Specifically, we trained random forest models on XANES, PDF, and both of them combined, to extract charge (oxidation) state, coordination number, and mean nearest-neighbor bond length of transition metal cations in oxides. We find that XANES-only models tend to outperform the PDF-only models for all the tasks, and information from XANES often dominated when the two inputs were combined. This was even true for structural tasks where we might expect PDF to dominate. However, the performance gap closes when we used species-specific differential PDFs (dPDFs) as the inputs instead of total PDFs. Our results highlight that XANES contains rich structural information and may be further developed as a structural probe. Our interpretable, multimodal approach is quick and easy to implement when suitable structural and spectroscopic databases are available. This approach provides valuable insights into the relative strengths of different modalities for a practical scientific goal, guiding researchers in their experiment design tasks such as deciding when it is useful to combine complementary techniques in a scientific investigation.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17533",
        "abstract url": "https://arxiv.org/abs/2410.17533",
        "title": "FedGMark: Certifiably Robust Watermarking for Federated Graph Learning",
        "rating": "-3.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Federated graph learning (FedGL) is an emerging learning paradigm to collaboratively train graph data from various clients. However, during the development and deployment of FedGL models, they are susceptible to illegal copying and model theft. Backdoor-based watermarking is a well-known method for mitigating these attacks, as it offers ownership verification to the model owner. We take the first step to protect the ownership of FedGL models via backdoor-based watermarking. Existing techniques have challenges in achieving the goal: 1) they either cannot be directly applied or yield unsatisfactory performance; 2) they are vulnerable to watermark removal attacks; and 3) they lack of formal guarantees. To address all the challenges, we propose FedGMark, the first certified robust backdoor-based watermarking for FedGL. FedGMark leverages the unique graph structure and client information in FedGL to learn customized and diverse watermarks. It also designs a novel GL architecture that facilitates defending against both the empirical and theoretically worst-case watermark removal attacks. Extensive experiments validate the promising empirical and provable watermarking performance of FedGMark. Source code is available at: https://github.com/Yuxin104/FedGMark.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This paper is accepted to NeurIPS 2024"
    },
    {
        "paper id": "2410.16727",
        "abstract url": "https://arxiv.org/abs/2410.16727",
        "title": "DiffusionSeeder: Seeding Motion Optimization with Diffusion for Rapid Motion Planning",
        "rating": "-4",
        "keywords": [
            [
                "depth"
            ],
            [
                "Diffusion"
            ],
            [
                "robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Running optimization across many parallel seeds leveraging GPU compute have relaxed the need for a good initialization, but this can fail if the problem is highly non-convex as all seeds could get stuck in local minima. One such setting is collision-free motion optimization for robot manipulation, where optimization converges quickly on easy problems but struggle in obstacle dense environments (e.g., a cluttered cabinet or table). In these situations, graph-based planning algorithms are used to obtain seeds, resulting in significant slowdowns. We propose DiffusionSeeder, a diffusion based approach that generates trajectories to seed motion optimization for rapid robot motion planning. DiffusionSeeder takes the initial depth image observation of the scene and generates high quality, multi-modal trajectories that are then fine-tuned with a few iterations of motion optimization. We integrate DiffusionSeeder to generate the seed trajectories for cuRobo, a GPU-accelerated motion optimization method, which results in 12x speed up on average, and 36x speed up for more complicated problems, while achieving 10% higher success rate in partially observed simulation environments. Our results show the effectiveness of using diverse solutions from a learned diffusion model. Physical experiments on a Franka robot demonstrate the sim2real transfer of DiffusionSeeder to the real robot, with an average success rate of 86% and planning time of 26ms, improving on cuRobo by 51% higher success rate while also being 2.5x faster.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16746",
        "abstract url": "https://arxiv.org/abs/2410.16746",
        "title": "SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition",
        "rating": "-4",
        "keywords": [
            [
                "Event cameras"
            ],
            [
                "autonomous driving"
            ],
            [
                "robotics"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Human action recognition (HAR) plays a key role in various applications such as video analysis, surveillance, autonomous driving, robotics, and healthcare. Most HAR algorithms are developed from RGB images, which capture detailed visual information. However, these algorithms raise concerns in privacy-sensitive environments due to the recording of identifiable features. Event cameras offer a promising solution by capturing scene brightness changes sparsely at the pixel level, without capturing full images. Moreover, event cameras have high dynamic ranges that can effectively handle scenarios with complex lighting conditions, such as low light or high contrast environments. However, using event cameras introduces challenges in modeling the spatially sparse and high temporal resolution event data for HAR. To address these issues, we propose the SpikMamba framework, which combines the energy efficiency of spiking neural networks and the long sequence modeling capability of Mamba to efficiently capture global features from spatially sparse and high a temporal resolution event data. Additionally, to improve the locality of modeling, a spiking window-based linear attention mechanism is used. Extensive experiments show that SpikMamba achieves remarkable recognition performance, surpassing the previous state-of-the-art by 1.45%, 7.22%, 0.15%, and 3.92% on the PAF, HARDVS, DVS128, and E-FAction datasets, respectively. The code is available at https://github.com/Typistchen/SpikMamba.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2410.17343",
        "abstract url": "https://arxiv.org/abs/2410.17343",
        "title": "EEG-DIF: Early Warning of Epileptic Seizures through Generative Diffusion Model-based Multi-channel EEG Signals Forecasting",
        "rating": "-4.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "EEG",
                "clinical"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Multi-channel EEG signals are commonly used for the diagnosis and assessment of diseases such as epilepsy. Currently, various EEG diagnostic algorithms based on deep learning have been developed. However, most research efforts focus solely on diagnosing and classifying current signal data but do not consider the prediction of future trends for early warning. Additionally, since multi-channel EEG can be essentially regarded as the spatio-temporal signal data received by detectors at different locations in the brain, how to construct spatio-temporal information representations of EEG signals to facilitate future trend prediction for multi-channel EEG becomes an important problem. This study proposes a multi-signal prediction algorithm based on generative diffusion models (EEG-DIF), which transforms the multi-signal forecasting task into an image completion task, allowing for comprehensive representation and learning of the spatio-temporal correlations and future developmental patterns of multi-channel EEG signals. Here, we employ a publicly available epilepsy EEG dataset to construct and validate the EEG-DIF. The results demonstrate that our method can accurately predict future trends for multi-channel EEG signals simultaneously. Furthermore, the early warning accuracy for epilepsy seizures based on the generated EEG data reaches 0.89. In general, EEG-DIF provides a novel approach for characterizing multi-channel EEG signals and an innovative early warning algorithm for epilepsy seizures, aiding in optimizing and enhancing the clinical diagnosis process. The code is available at https://github.com/JZK00/EEG-DIF.",
        "subjects": [
            "eess.SP",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "9 pages, 4 figures, 3 tables, accepted by ACM BCB 2024"
    },
    {
        "paper id": "2410.16838",
        "abstract url": "https://arxiv.org/abs/2410.16838",
        "title": "Neural Collaborative Filtering Classification Model to Obtain Prediction Reliabilities",
        "rating": "-5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "recommendation"
            ],
            [
                "song"
            ]
        ],
        "abstract": "Neural collaborative filtering is the state of art field in the recommender systems area; it provides some models that obtain accurate predictions and recommendations. These models are regression-based, and they just return rating predictions. This paper proposes the use of a classification-based approach, returning both rating predictions and their reliabilities. The extra information (prediction reliabilities) can be used in a variety of relevant collaborative filtering areas such as detection of shilling attacks, recommendations explanation or navigational tools to show users and items dependences. Additionally, recommendation reliabilities can be gracefully provided to users: \"probably you will like this film\", \"almost certainly you will like this song\", etc. This paper provides the proposed neural architecture; it also tests that the quality of its recommendation results is as good as the state of art baselines. Remarkably, individual rating predictions are improved by using the proposed architecture compared to baselines. Experiments have been performed making use of four popular public datasets, showing generalizable quality results. Overall, the proposed architecture improves individual rating predictions quality, maintains recommendation results and opens the doors to a set of relevant collaborative filtering fields.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "9 pages, 7 figures"
    },
    {
        "paper id": "2410.17541",
        "abstract url": "https://arxiv.org/abs/2410.17541",
        "title": "Improving Connectivity of RIS-Assisted UAV Networks using RIS Partitioning and Deployment",
        "rating": "-6",
        "keywords": [
            [
                "3D"
            ],
            [
                "vehicle"
            ],
            [
                "5G"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Reconfigurable intelligent surface (RIS) is pivotal for beyond 5G networks in regards to the surge demand for reliable communication in unmanned aerial vehicle (UAV) networks. This paper presents an innovative approach to maximize connectivity of UAV networks using RIS deployment and virtual partitioning, wherein an RIS is deployed to assist in the communications between an user-equipment (UE) and blocked UAVs. Closed-form (CF) expressions for signal-to-noise ratio (SNR) of the two-UAV setup are derived and validated. Then, an optimization problem is formulated to maximize network connectivity by optimizing the 3D deployment of the RIS and its partitioning subject to predefined quality-of-service (QoS) constraints. To tackle this problem, we propose a method of virtually partitioning the RIS given a fixed 3D location, such that the partition phase shifts are configured to create cascaded channels between the UE and the blocked two UAVs. Then, simulated-annealing (SA) method is used to find the 3D location of the RIS. Simulation results demonstrate that the proposed joint RIS deployment and partitioning framework can significantly improve network connectivity compared to benchmarks, including RIS-free and RIS with a single narrow-beam link.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "6 pages, 5 figures, conference"
    },
    {
        "paper id": "2411.04130",
        "abstract url": "https://arxiv.org/abs/2411.04130",
        "title": "ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design",
        "rating": "-6.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "graphs"
            ],
            [
                "bioisosteric"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Engineering molecules to exhibit precise 3D intermolecular interactions with their environment forms the basis of chemical design. In ligand-based drug design, bioisosteric analogues of known bioactive hits are often identified by virtually screening chemical libraries with shape, electrostatic, and pharmacophore similarity scoring functions. We instead hypothesize that a generative model which learns the joint distribution over 3D molecular structures and their interaction profiles may facilitate 3D interaction-aware chemical design. We specifically design ShEPhERD, an SE(3)-equivariant diffusion model which jointly diffuses/denoises 3D molecular graphs and representations of their shapes, electrostatic potential surfaces, and (directional) pharmacophores to/from Gaussian noise. Inspired by traditional ligand discovery, we compose 3D similarity scoring functions to assess ShEPhERD's ability to conditionally generate novel molecules with desired interaction profiles. We demonstrate ShEPhERD's potential for impact via exemplary drug design tasks including natural product ligand hopping, protein-blind bioactive hit diversification, and bioisosteric fragment merging.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16720",
        "abstract url": "https://arxiv.org/abs/2410.16720",
        "title": "NodeOP: Optimizing Node Management for Decentralized Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present NodeOP, a novel framework designed to optimize the management of General Node Operators in decentralized networks. By integrating Agent-Based Modeling (ABM) with a Tendermint Byzantine Fault Tolerance (BFT)-based consensus mechanism, NodeOP addresses key challenges in task allocation, consensus formation, and system stability. Through rigorous mathematical modeling and formal optimization, NodeOP ensures stable equilibrium in node task distribution. We validate the framework via convergence analysis and performance metrics such as transaction throughput, system latency, and fault tolerance. We further demonstrate NodeOP's practical utility through two use cases: decentralized sequencer management in Layer 2 networks and off-chain payment validation. These examples underscore how NodeOP enhances validation efficiency and unlocks new revenue opportunities in large-scale decentralized environments. Our results position NodeOP as a scalable and flexible solution, significantly improving operational efficiency and economic sustainability in decentralized systems.",
        "subjects": [
            "cs.DB",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16745",
        "abstract url": "https://arxiv.org/abs/2410.16745",
        "title": "Characterizing the top trading cycles rule for housing markets with lexicographic preferences",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a housing market model with limited externalities where agents care both about their own consumption via demand preferences and about the agent who receives their endowment via supply preferences (we extend the associated lexicographic preference domains introduced in Klaus and Meo, 2023). If preferences are demand lexicographic, then our model extends the classical Shapley-Scarf housing market (Shapley and Scarf, 1974) with strict preferences model. Our main result is a characterization of the corresponding top trading cycles (TTC) rule by individual rationality, pair efficiency, and strategy-proofness (Theorem 1), which extends that of Ekici (2024) from classical Shapley-Scarf housing markets with strict preferences to our model. Two further characterizations are immediately obtained by strengthening pair efficiency to either Pareto efficiency or pairwise stability (Corollaries 1 and 2). Finally, we show that as soon as we extend the preference domain to include demand lexicographic as well as supply lexicographic preferences (e.g., when preferences are separable), no rule satisfying individual rationality, pair efficiency, and strategy-proofness exists (Theorem 2).",
        "subjects": [
            "econ.TH",
            "cs.GT"
        ],
        "comment": "JEL codes: C71, C78, D62, D63. Keywords: Core; characterization; externalities; housing markets; pair efficiency; pairwise stability; top trading cycles rule"
    },
    {
        "paper id": "2410.16784",
        "abstract url": "https://arxiv.org/abs/2410.16784",
        "title": "3SUM in Preprocessed Universes: Faster and Simpler",
        "rating": "-10",
        "keywords": [],
        "abstract": "We revisit the 3SUM problem in the \\emph{preprocessed universes} setting. We present an algorithm that, given three sets $A$, $B$, $C$ of $n$ integers, preprocesses them in quadratic time, so that given any subsets $A' \\subseteq A$, $B' \\subseteq B$, $C' \\subseteq C$, it can decide if there exist $a \\in A'$, $b \\in B'$, $c \\in C'$ with $a+b=c$ in time $O(n^{1.5} \\log n)$. In contrast to both the first subquadratic $\\tilde{O}(n^{13/7})$-time algorithm by Chan and Lewenstein (STOC 2015) and the current fastest $\\tilde{O}(n^{11/6})$-time algorithm by Chan, Vassilevska Williams, and Xu (STOC 2023), which are based on the Balog--Szemer\u00e9di--Gowers theorem from additive combinatorics, our algorithm uses only standard 3SUM-related techniques, namely FFT and linear hashing modulo a prime. It is therefore not only faster but also simpler. Just as the two previous algorithms, ours not only decides if there is a single 3SUM solution but it actually determines for each $c \\in C'$ if there is a solution containing it. We also modify the algorithm to still work in the scenario where the set $C$ is unknown at the time of preprocessing. Finally, even though the simplest version of our algorithm is randomized, we show how to make it deterministic losing only polylogarithmic factors in the running time.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "SOSA 2025"
    },
    {
        "paper id": "2410.16828",
        "abstract url": "https://arxiv.org/abs/2410.16828",
        "title": "The Continuous-Time RC-Chain ADC",
        "rating": "-10",
        "keywords": [],
        "abstract": "An amplifier-less continuous-time analog-to-digital converter consisting of only passives, comparators, and inverters is presented. Beyond simplicity, the architecture displays significant robustness properties with respect to component variations and comparator input offsets. We give an analytical design procedure demonstrating how to parameterize the architecture to a range of signal-to-noise and bandwidth requirements and validate the procedure's accuracy with behavioral transient simulations.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 7 figures"
    },
    {
        "paper id": "2410.16829",
        "abstract url": "https://arxiv.org/abs/2410.16829",
        "title": "Nature-inspired dynamic control for pursuit-evasion of robots",
        "rating": "-10",
        "keywords": [],
        "abstract": "The pursuit-evasion problem is widespread in nature, engineering and societal applications. It is commonly observed in nature that a predator runs faster than its prey but it has less agile maneuverability. Over millions of years of evolution, animals have developed effective and efficient pursuit and evasion strategies. In this paper, we provide a dynamic framework for pursuit-evasion of unicycle systems from a nature-inspired perspective. Firstly, for the problem with one pursuer and one evader, we propose an Alert-Turn control strategy which consists of two efficient ingredients: the suddenly turning maneuver and the alert condition for starting and maintaining the maneuver. We present and analyze the escape and capture results at a lower level of a single run and at a higher level with respect to parameters' changes. A theorem with sufficient condition for capture is also given. Then, the Alert-Turn strategy is combined with aggregation control laws and a target-changing mechanism to model more complex phenomenons with multiple pursuers and evaders. By adjusting a selfish parameter, the aggregation control commands can achieve different escape patterns of evaders: cooperative mode, selfish mode, as well as their combinations, and the influence of the selfish parameter is quantified. We present the effects of the number of pursuers and the target-changing mechanism from a statistical perspective. Our findings are largely in line with observations in nature. Furthermore, our control strategies are verified by numerical simulations that replicate some chasing behaviors of animals in nature.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2410.16865",
        "abstract url": "https://arxiv.org/abs/2410.16865",
        "title": "Polycubes via Dual Loops",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a complete characterization of polycubes of any genus based on their dual structure: a collection of oriented loops which run in each of the axis directions and capture polycubes via their intersection patterns. A polycube loop structure uniquely corresponds to a polycube. We also describe all combinatorially different ways to add a loop to a loop structure while maintaining its validity; similarly, we show how to identify loops that can be removed from a polycube loop structure without invalidating it. Our characterization gives rise to an iterative algorithm to construct provably valid polycube-maps for a given input surface; polycube-maps are frequently used to solve texture mapping, spline fitting, and hexahedral meshing. We showcase some results of a proof-of-concept implementation of this iterative algorithm.",
        "subjects": [
            "cs.CG",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16923",
        "abstract url": "https://arxiv.org/abs/2410.16923",
        "title": "A Toolbox for Design of Experiments for Energy Systems in Co-Simulation and Hardware Tests",
        "rating": "-10",
        "keywords": [],
        "abstract": "In context of highly complex energy system experiments, sensitivity analysis is gaining more and more importance to investigate the effects changing parameterization has on the outcome. Thus, it is crucial how to design an experiment to efficiently use the available resources. This paper describes the functionality of a toolbox designed to support the users in design of experiment for (co-)simulation and hardware tests. It provides a structure for object-oriented description of the parameterization and variations and performs sample generation based on this to provide a complete parameterization for the recommended experiment runs. After execution of the runs, it can also be used for analysis of the results to calculate and visualize the effects. The paper also presents two application cases using the toolbox which show how it can be implemented in sensitivity analysis studies with the co-simulation framework mosaik and a hybrid energy storage experiment.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "7 pages, 6 figures, 2 tables, conference proceedings of OSMSES 2024"
    },
    {
        "paper id": "2410.16929",
        "abstract url": "https://arxiv.org/abs/2410.16929",
        "title": "CUBIT: Concurrent Updatable Bitmap Indexing (Extended Version)",
        "rating": "-10",
        "keywords": [],
        "abstract": "Bitmap indexes are widely used for read-intensive analytical workloads because they are clustered and offer efficient reads with a small memory footprint. However, they are notoriously inefficient to update. As analytical applications are increasingly fused with transactional applications, leading to the emergence of hybrid transactional/analytical processing (HTAP), it is desirable that bitmap indexes support efficient concurrent real-time updates. In this paper, we propose Concurrent Updatable Bitmap indexing (CUBIT) that offers efficient real-time updates that scale with the number of CPU cores used and do not interfere with queries. Our design relies on three principles. First, we employ a horizontal bitwise representation of updated bits, which enables efficient atomic updates without locking entire bitvectors. Second, we propose a lightweight snapshotting mechanism that allows queries (including range queries) to run on separate snapshots and provides a wait-free progress guarantee. Third, we consolidate updates in a latch-free manner, providing a strong progress guarantee. Our evaluation shows that CUBIT offers 3x - 16x higher throughput and 3x - 220x lower latency than state-of-the-art updatable bitmap indexes. CUBIT's update-friendly nature widens the applicability of bitmap indexing. Experimenting with OLAP workloads with standard, batched updates shows that CUBIT overcomes the maintenance downtime and outperforms DuckDB by 1.2x - 2.7x on TPC-H. For HTAP workloads with real-time updates, CUBIT achieves 2x - 11x performance improvement over the state-of-the-art approaches.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2410.16937",
        "abstract url": "https://arxiv.org/abs/2410.16937",
        "title": "MOSAIK 3.0: Combining Time-Stepped and Discrete Event Simulation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Co-simulation is commonly used for the analysis of complex cyber-physical energy systems (CPES). Different domain-specific simulation tools and modeling approaches are used to simulate all or parts of the system. The co-simulation framework mosaik is a powerful tool to couple these simulation tools and models. This paper identifies the limitations of mosaik 2 for simulating systems that combine continuous and discrete behavior, and introduces the new version mosaik 3.0 with improved event capabilities to efficiently combine time-stepped and discrete event simulation. Here it is explained how these extensions and new features of mosaik can be applied and implemented for extended co-simulation scenarios.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "5 pages, 6 figures, 1 table, conference proceedings of OSMSES 2022"
    },
    {
        "paper id": "2410.16956",
        "abstract url": "https://arxiv.org/abs/2410.16956",
        "title": "Towards an Assisted Simulation Planning for Co-Simulation of Cyber-Physical Energy Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Increasing complexity in the power system and the transformation towards a smart grid lead to the necessity of new tools and methods for the development and testing of new technologies. One testing method is co-simulation, which allows coupling simulation components from different domains to test their interaction. Because the manual configuration of complex large-scale co-simulation scenarios can be error-prone, we propose an approach for assisting the user in the development of co-simulation scenarios. Our approach uses an information model, a component catalog implemented in a Semantic Media Wiki, and Semantic Web technologies to assist the high-level modeling of co-simulation scenarios, recommend suitable simulation components, and validate co-simulation scenarios. This assistance aims to improve the usability of co-simulation in the development of interdisciplinary, large-scale scenarios.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "6 pages, 3 figures, conference proceedings Workshop on Modeling and Simulation of Cyber-Physical Energy Systems (MSCPES) 2019"
    },
    {
        "paper id": "2410.16960",
        "abstract url": "https://arxiv.org/abs/2410.16960",
        "title": "Iterative Cut-Based PWA Approximation of Multi-Dimensional Nonlinear Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "PieceWise Affine (PWA) approximations for nonlinear functions have been extensively used for tractable, computationally efficient control of nonlinear systems. However, reaching a desired approximation accuracy without prior information about the behavior of the nonlinear systems remains a challenge in the function approximation and control literature. As the name suggests, PWA approximation aims at approximating a nonlinear function or system by dividing the domain into multiple subregions where the nonlinear function or dynamics is approximated locally by an affine function also called local mode. Without prior knowledge of the form of the nonlinearity, the required number of modes, the locations of the subregions, and the local approximations need to be optimized simultaneously, which becomes highly complex for large-scale systems with multi-dimensional nonlinear functions. This paper introduces a novel approach for PWA approximation of multi-dimensional nonlinear systems, utilizing a hinging hyperplane formalism for cut-based partitioning of the domain. The complexity of the PWA approximation is iteratively increased until reaching the desired accuracy level. Further, the tractable cut definitions allow for different forms of subregions, as well as the ability to impose continuity constraints on the PWA approximation. The methodology is explained via multiple examples and its performance is compared to two existing approaches through case studies, showcasing its efficacy.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "9 pages, 4 figures, submitted to journal"
    },
    {
        "paper id": "2410.17008",
        "abstract url": "https://arxiv.org/abs/2410.17008",
        "title": "Double-Side Delay Alignment Modulation for Multi-User Millimeter Wave and TeraHertz Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Delay alignment modulation (DAM) is an innovative broadband modulation technique well suited for millimeter wave (mmWave) and terahertz (THz) massive multiple-input multiple-output (MIMO) communication systems. Leveraging the high spatial resolution and sparsity of multi-path channels, DAM mitigates inter-symbol interference (ISI) effectively, by aligning all multi-path components through a combination of delay pre/post-compensation and path-based beamforming. As such, ISI is eliminated while preserving multi-path power gains. In this paper, we explore multi-user double-side DAM with both delay pre-compensation at the transmitter and post-compensation at the receiver, contrasting with prior one-side DAM that primarily focuses on delay pre-compensation only. Firstly, we reveal the constraint for the introduced delays and the delay pre/post-compensation vectors tailored for multi-user double-side DAM, given a specific number of delay pre/post-compensations. Furthermore, we show that as long as the number of base station (BS)/user equipment (UE) antennas is sufficiently large, single-side DAM, where delay compensation is only performed at the BS/UE, is preferred than double-side DAM since the former results in less ISI to be spatially eliminated. Next, we propose two low-complexity path-based beamforming strategies based on the eigen-beamforming transmission and ISI-zero forcing (ZF) principles, respectively, based on which the achievable sum rates are studied. Simulation results verify that with sufficiently large BS/UE antennas, single-side DAM is sufficient. Furthermore, compared to the benchmark scheme of orthogonal frequency division multiplexing (OFDM), multi-user BS-side DAM achieves higher spectral efficiency and/or lower peak-to-average power ratio (PAPR).",
        "subjects": [
            "eess.SP"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2410.17012",
        "abstract url": "https://arxiv.org/abs/2410.17012",
        "title": "Nanosecond Precision Time Synchronization for Optical Data Center Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Optical data center networks (DCNs) are renovating the infrastructure design for the cloud in the post Moore's law era. The fact that optical DCNs rely on optical circuits of microsecond-scale durations makes nanosecond-precision time synchronization essential for the correct functioning of routing on the network fabric. However, current studies on optical DCNs neglect the fundamental need for accurate time synchronization. In this paper, we bridge the gap by developing Nanosecond Optical Synchronization (NOS), the first nanosecond-precision synchronization solution for optical DCNs general to various optical hardware. NOS builds clock propagation trees on top of the dynamically reconfigured circuits in optical DCNs, allowing switches to seek better sync parents throughout time. It predicts drifts in the tree-building process, which enables minimization of sync errors. We also tailor today's sync protocols to the needs of optical DCNs, including reducing the number of sync messages to fit into short circuit durations and correcting timestamp errors for higher sync accuracy. Our implementation on programmable switches shows 28ns sync accuracy in a 192-ToR setting.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17019",
        "abstract url": "https://arxiv.org/abs/2410.17019",
        "title": "Recent consumer OLED monitors can be suitable for vision science",
        "rating": "-10",
        "keywords": [],
        "abstract": "Vision science imposes rigorous requirements for the design and execution of psychophysical studies and experiments. These requirements ensure precise control over variables, accurate measurement of perceptual responses, and reproducibility of results, which are essential for investigating visual perception and its underlying mechanisms. Since different experiments have different requirements, not all aspects of a display system are critical for a given setting. Therefore, some display systems may be suitable for certain types of experiments but unsuitable for others. An additional challenge is that the performance of consumer systems is often highly dependent on specific monitor settings and firmware behavior. Here, we evaluate the performance of four display systems: a consumer LCD gaming monitor, a consumer OLED gaming monitor, a consumer OLED TV, and a VPixx PROPixx projector system. To allow the reader to assess the suitability of these systems for different experiments, we present a range of different metrics: luminance behavior, luminance uniformity across display surface, estimated gamma values and linearity, channel additivity, channel dependency, color gamut, pixel response time, and pixel waveform. In addition, we exhaustively report the monitor firmware settings used. Our analyses show that current consumer-level OLED display systems are promising, and adequate to fulfill the requirements of some critical vision science experiments, allowing laboratories to run their experiments even without investing in high-quality professional display systems. For example, the tested Asus OLED gaming monitor shows excellent response time, a sharp square waveform even at 240 Hz, a color gamut that covers 94% of DCI-P3 color space, and the best luminance uniformity among all four tested systems, making it a favorable option on price-to-performance ratio.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "29 pages, 13 figures, 4 tables"
    },
    {
        "paper id": "2410.17045",
        "abstract url": "https://arxiv.org/abs/2410.17045",
        "title": "Abstract Operational Methods for Call-by-Push-Value",
        "rating": "-10",
        "keywords": [],
        "abstract": "Levy's call-by-push-value is a comprehensive programming paradigm that combines elements from functional and imperative programming, supports computational effects and subsumes both call-by-value and call-by-name evaluation strategies. In the present work, we develop modular methods to reason about program equivalence in call-by-push-value, and in fine-grain call-by-value, which is a popular lightweight call-by-value sublanguage of the former. Our approach is based on the fundamental observation that presheaf categories of sorted sets are suitable universes to model call-by-(push)-value languages, and that natural, coalgebraic notions of program equivalence such as applicative similarity and logical relations can be developed within. Starting from this observation, we formalize fine-grain call-by-value and call-by-push-value in the higher-order abstract GSOS framework, reduce their key congruence properties to simple syntactic conditions by leveraging existing theory and argue that introducing changes to either language incurs minimal proof overhead.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17068",
        "abstract url": "https://arxiv.org/abs/2410.17068",
        "title": "Delay-Constrained Grant-Free Random Access in MIMO Systems: Distributed Pilot Allocation and Power Control",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study a delay-constrained grant-free random access system with a multi-antenna base station. The users randomly generate data packets with expiration deadlines, which are then transmitted from data queues on a first-in first-out basis. To deliver a packet, a user needs to succeed in both random access phase (sending a pilot without collision) and data transmission phase (achieving a required data rate with imperfect channel information) before the packet expires. We develop a distributed, cross-layer policy that allows the users to dynamically and independently choose their pilots and transmit powers to achieve a high effective sum throughput with fairness consideration. Our policy design involves three key components: 1) a proxy of the instantaneous data rate that depends only on macroscopic environment variables and transmission decisions, considering pilot collisions and imperfect channel estimation; 2) a quantitative, instantaneous measure of fairness within each communication round; and 3) a deep learning-based, multi-agent control framework with centralized training and distributed execution. The proposed framework benefits from an accurate, differentiable objective function for training, thereby achieving a higher sample efficiency compared with a conventional application of model-free, multi-agent reinforcement learning algorithms. The performance of the proposed approach is verified by simulations under highly dynamic and heterogeneous scenarios.",
        "subjects": [
            "cs.IT",
            "cs.MA"
        ],
        "comment": "15 pages, 7 figures. Accepted for publication in IEEE Transactions on Cognitive Communications and Networking"
    },
    {
        "paper id": "2410.17073",
        "abstract url": "https://arxiv.org/abs/2410.17073",
        "title": "Personalized Playback Technology: How Short Video Services Create Excellent User Experience",
        "rating": "-10",
        "keywords": [],
        "abstract": "Short-form video content has become increasingly popular and influential in recent years. Its concise yet engaging format aligns well with todays' fast-paced and on-the-go lifestyles, making it a dominating trend in the digital world. As one of the front runners in the short video platform space, ByteDance has been highly successful in delivering a one-of-a-kind short video experience and attracting billions of users worldwide. One key contributing factor is its advanced end-to-end personalized short video playback technology, where we pioneered and developed the new technical field over the past five years to optimize user experience. This paper introduces the major concepts and methodologies of this personalized video playback technology that distinguish it from traditional multimedia technologies. More details, including goal setting, iterative process, modeling, experimental methods and required supporting systems, are also provided to encourage deeper research in this area.",
        "subjects": [
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17078",
        "abstract url": "https://arxiv.org/abs/2410.17078",
        "title": "FlowTracer: A Tool for Uncovering Network Path Usage Imbalance in AI Training Clusters",
        "rating": "-10",
        "keywords": [],
        "abstract": "The increasing complexity of AI workloads, especially distributed Large Language Model (LLM) training, places significant strain on the networking infrastructure of parallel data centers and supercomputing systems. While Equal-Cost Multi- Path (ECMP) routing distributes traffic over parallel paths, hash collisions often lead to imbalanced network resource utilization and performance bottlenecks. This paper presents FlowTracer, a tool designed to analyze network path utilization and evaluate different routing strategies. FlowTracer aids in debugging network inefficiencies by providing detailed visibility into traffic distribution and helping to identify the root causes of performance degradation, such as issues caused by hash collisions. By offering flow-level insights, FlowTracer enables system operators to optimize routing, reduce congestion, and improve the performance of distributed AI workloads. We use a RoCEv2-enabled cluster with a leaf-spine network and 16 400-Gbps nodes to demonstrate how FlowTracer can be used to compare the flow imbalances of ECMP routing against a statically configured network. The example showcases a 30% reduction in imbalance, as measured by a new metric we introduce.",
        "subjects": [
            "cs.NI",
            "cs.DC"
        ],
        "comment": "Submitted for peer reviewing in IEEE ICC 2025"
    },
    {
        "paper id": "2410.17095",
        "abstract url": "https://arxiv.org/abs/2410.17095",
        "title": "Inferentially-Private Private Information",
        "rating": "-10",
        "keywords": [],
        "abstract": "Information disclosure can compromise privacy when revealed information is correlated with private information. We consider the notion of inferential privacy, which measures privacy leakage by bounding the inferential power a Bayesian adversary can gain by observing a released signal. Our goal is to devise an inferentially-private private information structure that maximizes the informativeness of the released signal, following the Blackwell ordering principle, while adhering to inferential privacy constraints. To achieve this, we devise an efficient release mechanism that achieves the inferentially-private Blackwell optimal private information structure for the setting where the private information is binary. Additionally, we propose a programming approach to compute the optimal structure for general cases given the utility function. The design of our mechanisms builds on our geometric characterization of the Blackwell-optimal disclosure mechanisms under privacy constraints, which may be of independent interest.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17106",
        "abstract url": "https://arxiv.org/abs/2410.17106",
        "title": "Feature Homomorphism -- A Cryptographic Scheme For Data Verification Under Ciphertext-Only Conditions",
        "rating": "-10",
        "keywords": [],
        "abstract": "Privacy computing involves the extensive exchange and processing of encrypted data. For the parties involved in these interactions, how to determine the consistency of exchanged data without accessing the original data, ensuring tamper resistance, non-repudiation, quality traceability, indexing, and retrieval during the use of encrypted data, which is a key topic of achieving \"Data Availability versus Visibility\". This paper proposes a new type of homomorphism: Feature Homomorphism, and based on this feature, introduces a cryptographic scheme for data verification under ciphertext-only conditions. The proposed scheme involves designing a group of algorithms that meet the requirements outlined in this paper, including encryption/decryption algorithms and Feature Homomorphic Algorithm. This group of algorithms not only allows for the encryption and decryption of data but also ensures that the plaintext and its corresponding ciphertext, encrypted using the specified encryption algorithm, satisfy the following property: the eigenvalue of the plaintext obtained using the Feature Homomorphic Algorithm is equal to the eigenvalue of the ciphertext obtained using the same algorithm. With this group of algorithms, it is possible to verify data consistency directly by comparing the eigenvalues of the plaintext and ciphertext without accessing the original data (i.e., under ciphertext-only conditions). This can be used for tamper resistance, non-repudiation, and quality traceability. Additionally, the eigenvalue can serve as a ciphertext index, enabling searchable encryption. This scheme completes a piece of the puzzle in homomorphic encryption. Keywords: Privacy Computing, Data Consistency, Searchable Encryption, Zero-Knowledge Proof, Feature Homomorphism",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17113",
        "abstract url": "https://arxiv.org/abs/2410.17113",
        "title": "A Unified Activity Detection Framework for Massive Access: Beyond the Block-Fading Paradigm",
        "rating": "-10",
        "keywords": [],
        "abstract": "The wireless channel changes continuously with time and frequency and the block-fading assumption, which is popular in many theoretical analyses, never holds true in practical scenarios. This discrepancy is critical for user activity detection in grant-free random access, where joint processing across multiple coherence blocks is undesirable, especially when the environment becomes more dynamic. In this paper, we develop a framework for low-dimensional approximation of the channel to capture its variations over time and frequency, and use this framework to implement robust activity detection algorithms. Furthermore, we investigate how to efficiently estimate the principal subspace that defines the low-dimensional approximation. We also examine pilot hopping as a way of exploiting time and frequency diversity in scenarios with limited channel coherence, and extend our algorithms to this case. Through numerical examples, we demonstrate a substantial performance improvement achieved by our proposed framework.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "15 pages, 14 figures. Accepted for publication in IEEE Journal of Selected Topics in Signal Processing"
    },
    {
        "paper id": "2410.17114",
        "abstract url": "https://arxiv.org/abs/2410.17114",
        "title": "Lunar Subterra: a Self-Integrative Unit with an Automated Drilling System",
        "rating": "-10",
        "keywords": [],
        "abstract": "As humans venture deeper into space, the need for a lunar settlement, housing the first group of settlers, grows steadily. By means of new technologies such as in situ resource utilisation (ISRU) as well as computational design, this goal can be implemented in present years. Providing the first arrivals with an immediate underground habitat safe from radiation and other environmental constraints is of crucial importance to initialise a prolonged mission on the Moon. The project's proposal revolves around the idea of establishing a base which provides an immediately habitable space with the possibility for future expansion. Advanced construction methods and sustainable practices lay the groundwork for a permanent human presence, predominantly based on ISRU. This paper outlines a two-phase initiative aimed at the foundation of the Lunar Subterra, followed by an extension of the habitat above ground. Following our collaboration with the PoliSpace Sparc Student Association group, a Virtual Reality (VR) reproduction of the proposed habitat enabled quick iterative testing of the habitable space with the use of a Meta Quest 2 headset. This not only allowed an evaluation of the environment and its impact on human residents but also eradicated the need for tangible models to conceptualise the idea, enabling rapid user-centred design and implementation in the future of space exploration.",
        "subjects": [
            "cs.HC",
            "cs.ET"
        ],
        "comment": "75th International Astronautical Congress (IAC), Milan, Italy, 14-18 October 2024"
    },
    {
        "paper id": "2410.17143",
        "abstract url": "https://arxiv.org/abs/2410.17143",
        "title": "Empowering the Grid: Decentralized Autonomous Control for Effective Utilization and Resilience",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the emergence of low-inertia microgrids powered by inverter-based generation, there remains a concern about the operational resilience of these systems. Grid-forming inverters (GFMs), enabled by various device-level (primary) and system-level (secondary) control methods, are poised to play a significant role in achieving certain operational objectives, such as the effective utilization of clean energy resources while maintaining stability. However, despite the recent advances in GFMs, there is a lack of suitable controls that can ascertain resilience-constrained operations, like maintaining critical operational safety limits during transients under various cyber-physical disruptions. In this work, we develop decentralized autonomous controllers (DACs) that enforce resilience-constrained operation via local, minimally invasive adjustments (e.g., changes in set-points) while co-existing within the hierarchy of existing (primary and secondary) controls. The DACs work autonomously by sensing only local GFM measurements and act only when operational resilience constraints are violated. The proposed DAC scheme is computationally efficient (only algebraic computations), which enables fast, real-time execution and demonstrates the efficacy of the proposed control framework on GridLAB-D-HELICS-based control-grid co-simulations on the IEEE 123-node networked microgrid. Finally, we show how the developed DACs empower the grid by utilizing the available resources entirely to ensure resilience (maintain frequency safe limits).",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "This paper is currently under review in a journal"
    },
    {
        "paper id": "2410.17166",
        "abstract url": "https://arxiv.org/abs/2410.17166",
        "title": "Towards Map-Agnostic Policies for Adaptive Informative Path Planning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Robots are frequently tasked to gather relevant sensor data in unknown terrains. A key challenge for classical path planning algorithms used for autonomous information gathering is adaptively replanning paths online as the terrain is explored given limited onboard compute resources. Recently, learning-based approaches emerged that train planning policies offline and enable computationally efficient online replanning performing policy inference. These approaches are designed and trained for terrain monitoring missions assuming a single specific map representation, which limits their applicability to different terrains. To address these issues, we propose a novel formulation of the adaptive informative path planning problem unified across different map representations, enabling training and deploying planning policies in a larger variety of monitoring missions. Experimental results validate that our novel formulation easily integrates with classical non-learning-based planning approaches while maintaining their performance. Our trained planning policy performs similarly to state-of-the-art map-specifically trained policies. We validate our learned policy on unseen real-world terrain datasets.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2410.17185",
        "abstract url": "https://arxiv.org/abs/2410.17185",
        "title": "The Decision Problem for Regular First-Order Theories",
        "rating": "-10",
        "keywords": [],
        "abstract": "The classical `decision problem' asks whether a given formula of first-order logic is satisfiable. In this work we consider an extension of this problem to regular first-order theories, i.e. (infinite) regular sets of formulae. Building on the beautiful classification of syntactic classes as decidable or undecidable for the classical decision problem, we show that some classes (the EPR and Gurevich classes) which are decidable in the classical setting are undecidable for regular theories; on the other hand for each we show a subclass which remains decidable in our setting, leaving a complete classification as a challenge for future work. Finally, we observe that our problem generalises prior work on verification of uninterpreted programs, and give a semantic class of existential formulae for which the problem is decidable.",
        "subjects": [
            "cs.LO",
            "cs.FL",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17204",
        "abstract url": "https://arxiv.org/abs/2410.17204",
        "title": "Vulnerability anti-patterns in Solidity: Increasing smart contracts security by reducing false alarms",
        "rating": "-10",
        "keywords": [],
        "abstract": "Turing completeness has made Ethereum smart contracts attractive to blockchain developers and attackers alike. To increase code security, many tools can now spot most known vulnerabilities$-$at the cost of production efficiency. Recent studies show false-positive ratios over 99% in state-of-the-art technologies: this makes them impractical for use in industry and have raised questions on the direction of academic research. In this work we show how integrating and extending current analyses is not only feasible, but also a next logical step in smart-contract security. We propose light-weight static checks on the morphology and dynamics of Solidity code, stemming from a developer-centric notion of vulnerability, that we use to verify the output of other tools, flag potential false alarms, and suggest verifications. Besides technical details we implemented an open-source prototype. For three top-10 vulnerabilities it flags 324 warnings of other tools as false-positives, in 60 verified de-duplicated smart contracts selected from the blockchain by the presence of true (and false) vulnerabilities. This amounts to a 92%- to 100%-reduction in the number of false-positives for these vulnerabilities.",
        "subjects": [
            "cs.CR",
            "cs.CE",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17208",
        "abstract url": "https://arxiv.org/abs/2410.17208",
        "title": "On Recurrence Relations of Multi-dimensional Sequences",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present a new algorithm for computing the linear recurrence relations of multi-dimensional sequences. Existing algorithms for computing these relations arise in computational algebra and include constructing structured matrices and computing their kernels. The challenging problem is to reduce the size of the corresponding matrices. In this paper, we show how to convert the problem of computing recurrence relations of multi-dimensional sequences into computing the orthogonal of certain ideals as subvector spaces of the dual module of polynomials. We propose an algorithm using efficient dual module computation algorithms. We present a complexity bound for this algorithm, carry on experiments using Maple implementation, and discuss the cases when using this algorithm is much faster than the existing approaches.",
        "subjects": [
            "cs.SC",
            "math.AC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17220",
        "abstract url": "https://arxiv.org/abs/2410.17220",
        "title": "Heuristic Search for Linear Positive Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work considers infinite-horizon optimal control of positive linear systems applied to the case of network routing problems. We demonstrate the equivalence between Stochastic Shortest Path (SSP) problems and optimal control of a certain class of linear systems. This is used to construct a heuristic search framework for this class of linear systems inspired by existing methods for SSP. We propose a heuristics-based algorithm for finding local solutions to the analyzed class of optimal control problems with positive state and linear dynamics. More fundamentally, the results allow for analysis of the conditions for explicit solutions to the Bellman equation utilized by heuristic search methods.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "Preprint submitted to Automatica for review"
    },
    {
        "paper id": "2410.17353",
        "abstract url": "https://arxiv.org/abs/2410.17353",
        "title": "Preserving Privacy in Cloud-based Data-Driven Stabilization",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the recent years, we have observed three significant trends in control systems: a renewed interest in data-driven control design, the abundance of cloud computational services and the importance of preserving privacy for the system under control. Motivated by these factors, this work investigates privacy-preserving outsourcing for the design of a stabilizing controller for unknown linear time-invariant systems.The main objective of this research is to preserve the privacy for the system dynamics by designing an outsourcing mechanism. To achieve this goal, we propose a scheme that combines transformation-based techniques and robust data-driven control design methods. The scheme preserves the privacy of both the open-loop and closed-loop system matrices while stabilizing the system under control.The scheme is applicable to both data with and without disturbance and is lightweight in terms of computational overhead. Numerical investigations for a case study demonstrate the impacts of our mechanism and its role in hindering malicious adversaries from achieving their goals.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17356",
        "abstract url": "https://arxiv.org/abs/2410.17356",
        "title": "Wireless Picosecond Time Synchronization for Distributed Antenna Arrays with Dynamic Connectivity",
        "rating": "-10",
        "keywords": [],
        "abstract": "Phase, time, and frequency coordination are crucial for the coherent operation of distributed antenna arrays. This paper demonstrates a high accuracy decentralized time synchronization method for arrays with dynamic connectivity. To overcome challenges such as alteration in network topology, system scaling, and single- or multiple-node failures, we present a decentralized time synchronization method implementing the average consensus algorithm and two-way time transfer. Our approach supports decentralized time synchronization with picosecond accuracy ($< 13$ ps), unbiased convergence, resilience to node failures, and robustness to other network connection adversities. A time synchronization precision of under 3 ps was achieved for a fully connected frequency syntonized network. The algorithm ensured convergence in time even for a network with only one link connecting two randomly chosen nodes at each iteration; however, the speed of convergence decreased along with the number of connected links. The method is exhibited for a six-node distributed array, by both simulation and experimental implementation using software defined radios.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, and six figures, This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2410.17367",
        "abstract url": "https://arxiv.org/abs/2410.17367",
        "title": "Generalizing Geometric Partition Entropy for the Estimation of Mutual Information in the Presence of Informative Outliers",
        "rating": "-10",
        "keywords": [],
        "abstract": "The recent introduction of geometric partition entropy brought a new viewpoint to non-parametric entropy quantification that incorporated the impacts of informative outliers, but its original formulation was limited to the context of a one-dimensional state space. A generalized definition of geometric partition entropy is now provided for samples within a bounded (finite measure) region of a d-dimensional vector space. The basic definition invokes the concept of a Voronoi diagram, but the computational complexity and reliability of Voronoi diagrams in high dimension make estimation by direct theoretical computation unreasonable. This leads to the development of approximation schemes that enable estimation that is faster than current methods by orders of magnitude. The partition intersection ($\u03c0$) approximation, in particular, enables direct estimates of marginal entropy in any context resulting in an efficient and versatile mutual information estimator. This new measure-based paradigm for data driven information theory allows flexibility in the incorporation of geometry to vary the representation of outlier impact, which leads to a significant broadening in the applicability of established entropy-based concepts. The incorporation of informative outliers is illustrated through analysis of transient dynamics in the synchronization of coupled chaotic dynamical systems.",
        "subjects": [
            "physics.soc-ph",
            "cs.IT",
            "nlin.CD"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17370",
        "abstract url": "https://arxiv.org/abs/2410.17370",
        "title": "On the use of Large Language Models in Model-Driven Engineering",
        "rating": "-10",
        "keywords": [],
        "abstract": "Model-Driven Engineering (MDE) has seen significant advancements with the integration of Machine Learning (ML) and Deep Learning (DL) techniques. Building upon the groundwork of previous investigations, our study provides a concise overview of current Language Large Models (LLMs) applications in MDE, emphasizing their role in automating tasks like model repository classification and developing advanced recommender systems. The paper also outlines the technical considerations for seamlessly integrating LLMs in MDE, offering a practical guide for researchers and practitioners. Looking forward, the paper proposes a focused research agenda for the future interplay of LLMs and MDE, identifying key challenges and opportunities. This concise roadmap envisions the deployment of LLM techniques to enhance the management, exploration, and evolution of modeling ecosystems. By offering a compact exploration of LLMs in MDE, this paper contributes to the ongoing evolution of MDE practices, providing a forward-looking perspective on the transformative role of Language Large Models in software engineering and model-driven practices.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "A paper submitted to the Software Systems and Modeling Journal (Springer), and it has undergone the second revision"
    },
    {
        "paper id": "2410.17372",
        "abstract url": "https://arxiv.org/abs/2410.17372",
        "title": "A Systematic Mapping Study on Architectural Approaches to Software Performance Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software architecture is the foundation of a system's ability to achieve various quality attributes, including software performance. However, there lacks comprehensive and in-depth understanding of why and how software architecture and performance analysis are integrated to guide related future research. To fill this gap, this paper presents a systematic mapping study of 109 papers that integrate software architecture and performance analysis. We focused on five research questions that provide guidance for researchers and practitioners to gain an in-depth understanding of this research area. These questions addressed: a systematic mapping of related studies based on the high-level research purposes and specific focuses (RQ1), the software development activities these studies intended to facilitate (RQ2), the typical study templates of different research purposes (RQ3), the available tools and instruments for automating the analysis (RQ4), and the evaluation methodology employed in the studies (RQ5). Through these research questions, we also identified critical research gaps and future directions, including: 1) the lack of available tools and benchmark datasets to support replication, cross-validation and comparison of studies; 2) the need for architecture and performance analysis techniques that handle the challenges in emerging software domains; 3) the lack of consideration of practical factors that impact the adoption of the architecture and performance analysis approaches; and finally 4) the need for the adoption of modern ML/AI techniques to efficiently integrate architecture and performance analysis.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "27 pages, 4 figures"
    },
    {
        "paper id": "2410.17406",
        "abstract url": "https://arxiv.org/abs/2410.17406",
        "title": "ProveRAG: Provenance-Driven Vulnerability Analysis with Automated Retrieval-Augmented LLMs",
        "rating": "-10",
        "keywords": [],
        "abstract": "In cybersecurity, security analysts face the challenge of mitigating newly discovered vulnerabilities in real-time, with over 300,000 Common Vulnerabilities and Exposures (CVEs) identified since 1999. The sheer volume of known vulnerabilities complicates the detection of patterns for unknown threats. While LLMs can assist, they often hallucinate and lack alignment with recent threats. Over 25,000 vulnerabilities have been identified so far in 2024, which are introduced after popular LLMs' (e.g., GPT-4) training data cutoff. This raises a major challenge of leveraging LLMs in cybersecurity, where accuracy and up-to-date information are paramount. In this work, we aim to improve the adaptation of LLMs in vulnerability analysis by mimicking how analysts perform such tasks. We propose ProveRAG, an LLM-powered system designed to assist in rapidly analyzing CVEs with automated retrieval augmentation of web data while self-evaluating its responses with verifiable evidence. ProveRAG incorporates a self-critique mechanism to help alleviate omission and hallucination common in the output of LLMs applied in cybersecurity applications. The system cross-references data from verifiable sources (NVD and CWE), giving analysts confidence in the actionable insights provided. Our results indicate that ProveRAG excels in delivering verifiable evidence to the user with over 99% and 97% accuracy in exploitation and mitigation strategies, respectively. This system outperforms direct prompting and chunking retrieval in vulnerability analysis by overcoming temporal and context-window limitations. ProveRAG guides analysts to secure their systems more effectively while documenting the process for future audits.",
        "subjects": [
            "cs.CR",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17411",
        "abstract url": "https://arxiv.org/abs/2410.17411",
        "title": "Harnessing Visualization for Climate Action and Sustainable Future",
        "rating": "-10",
        "keywords": [],
        "abstract": "The urgency of climate change is now recognized globally. As humanity confronts the critical need to mitigate climate change and foster sustainability, data visualization emerges as a powerful tool with a unique capacity to communicate insights crucial for understanding environmental complexities. This paper explores the critical need for designing and investigating responsible data visualization that can act as a catalyst for engaging communities within global climate action and sustainability efforts. Grounded in prior work and reflecting on a decade of community engagement research, I propose five critical considerations: (1) inclusive and accessible visualizations for enhancing climate education and communication, (2) interactive visualizations for fostering agency and deepening engagement, (3) in-situ visualizations for reducing spatial indirection, (4) shared immersive experiences for catalyzing collective action, and (5) accurate, transparent, and credible visualizations for ensuring trust and integrity. These considerations offer strategies and new directions for visualization research, aiming to enhance community engagement, deepen involvement, and foster collective action on critical socio-technical including and beyond climate change.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17426",
        "abstract url": "https://arxiv.org/abs/2410.17426",
        "title": "Sketching, Moment Estimation, and the L\u00e9vy-Khintchine Representation Theorem",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the $d$-dimensional turnstile streaming model, a frequency vector $\\mathbf{x}=(\\mathbf{x}(1),\\ldots,\\mathbf{x}(n))\\in (\\mathbb{R}^d)^n$ is updated entry-wisely over a stream. We consider the problem of \\emph{$f$-moment estimation} for which one wants to estimate $$f(\\mathbf{x})=\\sum_{v\\in[n]}f(\\mathbf{x}(v))$$ with a small-space sketch. In this work we present a simple and generic scheme to construct sketches with the novel idea of hashing indices to \\emph{L\u00e9vy processes}, from which one can estimate the $f$-moment $f(\\mathbf{x})$ where $f$ is the \\emph{characteristic exponent} of the L\u00e9vy process. The fundamental \\emph{L\u00e9vy-Khintchine{} representation theorem} completely characterizes the space of all possible characteristic exponents, which in turn characterizes the set of $f$-moments that can be estimated by this generic scheme. The new scheme has strong explanatory power. It unifies the construction of many existing sketches ($F_0$, $L_0$, $L_2$, $L_\u03b1$, $L_{p,q}$, etc.) and it implies the tractability of many nearly periodic functions that were previously unclassified. Furthermore, the scheme can be conveniently generalized to multidimensional cases ($d\\geq 2$) by considering multidimensional L\u00e9vy processes and can be further generalized to estimate \\emph{heterogeneous moments} by projecting different indices with different L\u00e9vy processes. We conjecture that the set of tractable functions can be characterized using the L\u00e9vy-Khintchine representation theorem via what we called the \\emph{Fourier-Hahn-L\u00e9vy} method.",
        "subjects": [
            "cs.DS",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17435",
        "abstract url": "https://arxiv.org/abs/2410.17435",
        "title": "AI-focused HPC Data Centers Can Provide More Power Grid Flexibility and at Lower Cost",
        "rating": "-10",
        "keywords": [],
        "abstract": "The recent growth of Artificial Intelligence (AI), particularly large language models, requires energy-demanding high-performance computing (HPC) data centers, which poses a significant burden on power system capacity. Scheduling data center computing jobs to manage power demand can alleviate network stress with minimal infrastructure investment and contribute to fast time-scale power system balancing. This study, for the first time, comprehensively analyzes the capability and cost of grid flexibility provision by GPU-heavy AI-focused HPC data centers, along with a comparison with CPU-heavy general-purpose HPC data centers traditionally used for scientific computing. Using real-world data from 7 AI-focused HPC data centers, 7 general-purpose HPC data centers, and 3 cloud platforms, we find that AI-focused HPC data centers can offer greater flexibility at 50% lower cost for a range of power system services. By comparing the cost to flexibility market prices, we illustrate the financial profitability of flexibility provision for AI-focused HPC data centers.",
        "subjects": [
            "eess.SY",
            "cs.DC"
        ],
        "comment": "22 pages (including supplementary materials and references), under review for Joule"
    },
    {
        "paper id": "2410.17444",
        "abstract url": "https://arxiv.org/abs/2410.17444",
        "title": "Gains-from-Trade in Bilateral Trade with a Broker",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study bilateral trade with a broker, where a buyer and seller interact exclusively through the broker. The broker strategically maximizes her payoff through arbitrage by trading with the buyer and seller at different prices. We study whether the presence of the broker interferes with the mechanism's gains-from-trade (GFT) achieving a constant-factor approximation to the first-best gains-from-trade (FB). We first show that the GFT achieves a $1 / 36$-approximation to the FB even if the broker runs an optimal posted-pricing mechanism under symmetric agents with monotone-hazard-rate distributions. Beyond posted-pricing mechanisms, even if the broker uses an arbitrary incentive-compatible (IC) and individually-rational (IR) mechanism that maximizes her expected profit, we prove that it induces a $1 / 2$-approximation to the first-best GFT when the buyer and seller's distributions are uniform distributions with arbitrary support. This bound is shown to be tight. We complement such results by proving that if the broker uses an arbitrary profit-maximizing IC and IR mechanism, there exists a family of problem instances under which the approximation factor to the first-best GFT becomes arbitrarily bad. We show that this phenomenon persists even if we restrict one of the buyer's or seller's distributions to have a singleton support, or even in the symmetric setting where the buyer and seller have identical distributions.",
        "subjects": [
            "cs.GT",
            "econ.TH"
        ],
        "comment": "To appear at SODA'25"
    },
    {
        "paper id": "2410.17463",
        "abstract url": "https://arxiv.org/abs/2410.17463",
        "title": "Simply-typed constant-domain modal lambda calculus I: distanced beta reduction and combinatory logic",
        "rating": "-10",
        "keywords": [],
        "abstract": "A system $\\boldsymbol\u03bb_{\\upsilon}$ is developed that combines modal logic and simply-typed lambda calculus, and that generalizes the system studied by Montague and Gallin. Whereas Montague and Gallin worked with Church's simple theory of types, the system $\\boldsymbol\u03bb_{\\upsilon}$ is developed in the typed base theory most commonly used today, namely the simply-typed lambda calculus. Further, the system $\\boldsymbol\u03bb_{\\upsilon}$ is controlled by a parameter $\\upsilon$ which allows more options for state types and state variables than is present in Montague and Gallin. A main goal of the paper is to establish the basic metatheory of $\\boldsymbol\u03bb_{\\upsilon}$: (i) a completeness theorem is proven for $\u03b2\u03b7$-reduction, and (ii) an Andrews-like characterization of Henkin models in terms of combinatory logic is given; and this involves a distanced version of $\u03b2$-reduction and a $\\mathsf{BCKW}$-like basis rather than $\\mathsf{SKI}$-like basis. Further, conservation of the maximal system $\\boldsymbol\u03bb_\u03c9$ over $\\boldsymbol\u03bb_{\\upsilon}$ is proven, and expressibility of $\\boldsymbol\u03bb_\u03c9$ in $\\boldsymbol\u03bb_{\\upsilon}$ is proven; thus these modal logics are highly expressive. Similar results are proven for the relation between $\\boldsymbol\u03bb_\u03c9$ and $\\boldsymbol\u03bb$, the corresponding ordinary simply-typed lambda calculus. This answers a question of Zimmerman in the simply-typed setting. In a companion paper this is extended to Church's simple theory of types.",
        "subjects": [
            "cs.LO",
            "math.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17468",
        "abstract url": "https://arxiv.org/abs/2410.17468",
        "title": "Formal Privacy Guarantees with Invariant Statistics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Motivated by the 2020 US Census products, this paper extends differential privacy (DP) to address the joint release of DP outputs and nonprivate statistics, referred to as invariant. Our framework, Semi-DP, redefines adjacency by focusing on datasets that conform to the given invariant, ensuring indistinguishability between adjacent datasets within invariant-conforming datasets. We further develop customized mechanisms that satisfy Semi-DP, including the Gaussian mechanism and the optimal $K$-norm mechanism for rank-deficient sensitivity spaces. Our framework is applied to contingency table analysis which is relevant to the 2020 US Census, illustrating how Semi-DP enables the release of private outputs given the one-way margins as the invariant. Additionally, we provide a privacy analysis of the 2020 US Decennial Census using the Semi-DP framework, revealing that the effective privacy guarantees are weaker than advertised.",
        "subjects": [
            "cs.CR",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17527",
        "abstract url": "https://arxiv.org/abs/2410.17527",
        "title": "Adaptive coupling of peridynamic and classical continuum mechanical models driven by broken bond/strength criteria for structural dynamic failure",
        "rating": "-10",
        "keywords": [],
        "abstract": "Peridynamics (PD) is widely used to simulate structural failure. However, PD models are time-consuming. To improve the computational efficiency, we developed an adaptive coupling model between PD and classical continuum mechanics (PD-CCM) based on the Morphing method [1], driven by the broken bond or strength criteria. We derived the dynamic equation of the coupled models from the Lagrangian equation and then the discretized finite element formulation. An adaptive coupling strategy was introduced by determining the key position using the broken bond or strength criteria. The PD subdomain was expanded by altering the value of the Morphing function around the key position. Additionally, the PD subdomain was meshed by discrete elements (DEs) (i.e., nodes were not shared between elements), allowing the crack to propagate freely along the boundary of the DE. The remaining subdomains were meshed by continuous elements (CEs). Following the PD subdomain expansion, the CEs were converted into DEs, and new nodes were inserted. The displacement vector and mass matrix were reconfigured to ensure calculation consistency throughout the solving process. Furthermore, the relationship between the expansion radius of the PD subdomain and the speed of crack propagation was also discussed. Finally, the effectiveness, efficiency, and accuracy of the proposed model were verified via three two-dimensional numerical examples.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "43pages,Double space, 19 Figures"
    },
    {
        "paper id": "2410.17540",
        "abstract url": "https://arxiv.org/abs/2410.17540",
        "title": "The Dispersion of Broadcast Channels With Degraded Message Sets Using Gaussian Codebooks",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the two-user broadcast channel with degraded message sets and derive second-order achievability rate regions. Specifically, the channel noises are not necessarily Gaussian and we use spherical codebooks for both users. The weak user with worse channel quality applies nearest neighbor decoding by treating the signal of the other user as interference. For the strong user with better channel quality, we consider two decoding schemes: successive interference cancellation (SIC) decoding and joint nearest neighbor (JNN) decoding. We adopt two performance criteria: separate error probabilities (SEP) and joint error probability (JEP). Counterintuitively, the second-order achievable rate regions under both SIC and JNN decoding are identical although JNN decoding usually yields better performance in other multiterminal problems with Gaussian noise. Furthermore, we generalize our results to the case with quasi-static fading and show that the asymptotic notion of outage capacity region is an accurate performance measure even at finite blocklengths.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2410.17556",
        "abstract url": "https://arxiv.org/abs/2410.17556",
        "title": "Performance of orthogonal delay-doppler division multiplexing modulation with imperfect channel estimation",
        "rating": "-10",
        "keywords": [],
        "abstract": "The orthogonal delay-Doppler division multiplexing (ODDM) modulation is a recently proposed multi-carrier modulation that features a realizable pulse orthogonal with respect to the delay-Doppler (DD) plane's fine resolutions. In this paper, we investigate the performance of ODDM systems with imperfect channel estimation considering three detectors, namely the message passing algorithm (MPA) detector, iterative maximum-ratio combining (MRC) detector, and successive interference cancellation with minimum mean square error (SIC-MMSE) detector. We derive the post-equalization signal-to-interference-plus-noise ratio (SINR) for MRC and SIC-MMSE and analyze their bit error rate (BER) performance. Based on this analysis, we propose the MRC with subtractive dither (MRC-SD) and soft SIC-MMSE initialized MRC (SSMI-MRC) detector to improve the BER of iterative MRC. Our results demonstrate that soft SIC-MMSE consistently outperforms the other detectors in BER performance under perfect and imperfect CSI. While MRC exhibits a BER floor above $10^{-5}$, MRC-SD effectively lowers the BER with a negligible increase in detection complexity. SSMI-MRC achieves better BER than hard SIC-MMSE with the same detection complexity order. Additionally, we show that MPA has an error floor and is sensitive to imperfect CSI.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.18707",
        "abstract url": "https://arxiv.org/abs/2410.18707",
        "title": "Disjoint Projected Enumeration for SAT and SMT without Blocking Clauses",
        "rating": "-10",
        "keywords": [],
        "abstract": "All-Solution Satisfiability (AllSAT) and its extension, All-Satisfiability Modulo Theories (AllSMT), have become more relevant in recent years, mainly in formal verification and artificial intelligence applications. The goal of these problems is the enumeration of all satisfying assignments to a formula (for SAT and SMT problems, respectively), making them useful for test generation, model checking, and probabilistic inference. Nevertheless, traditional AllSAT algorithms face significant computational challenges due to the exponential growth of the search space and inefficiencies caused by blocking clauses, which cause memory blowups and degrade unit propagation performances in the long term. This paper presents two novel solvers: \\solverPlus{}, a projected AllSAT solver, and \\solverSMT{}, a projected AllSMT solver. Both solvers combine Conflict-Driven Clause Learning (CDCL) with chronological backtracking to improve efficiency while ensuring disjoint enumeration. To retrieve compact partial assignments we propose a novel aggressive implicant shrinking algorithm to minimize the number of partial assignments, reducing overall search complexity, and compatible with chronological backtracking. Furthermore, we extend the solver framework to handle projected enumeration and SMT formulae effectively and efficiently, adapting the baseline framework to integrate theory reasoning and the distinction between important and non-important variables. An extensive experimental evaluation demonstrates the superiority of our approach compared to state-of-the-art solvers, particularly in scenarios requiring projection and SMT-based reasoning.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2306.00461"
    },
    {
        "paper id": "2410.19011",
        "abstract url": "https://arxiv.org/abs/2410.19011",
        "title": "Local hedging approximately solves Pandora's box problems with nonobligatory inspection",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider search problems with nonobligatory inspection and single-item or combinatorial selection. A decision maker is presented with a number of items, each of which contains an unknown price, and can pay an inspection cost to observe the item's price before selecting it. Under single-item selection, the decision maker must select one item; under combinatorial selection, the decision maker must select a set of items that satisfies certain constraints. In our nonobligatory inspection setting, the decision maker can select items without first inspecting them. It is well-known that search with nonobligatory inspection is harder than the well-studied obligatory inspection case, for which the optimal policy for single-item selection (Weitzman, 1979) and approximation algorithms for combinatorial selection (Singla, 2018) are known. We introduce a technique, local hedging, for constructing policies with good approximation ratios in the nonobligatory inspection setting. Local hedging transforms policies for the obligatory inspection setting into policies for the nonobligatory inspection setting, at the cost of an extra factor in the approximation ratio. The factor is instance-dependent but is at most 4/3. We thus obtain the first approximation algorithms for a variety of combinatorial selection problems, including matroid basis, matching, and facility location.",
        "subjects": [
            "cs.GT",
            "econ.TH",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.02422",
        "abstract url": "https://arxiv.org/abs/2411.02422",
        "title": "About the Kannan-Bachem algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Smith reduction is a basic tool when analyzing integer matrices up to equivalence, and the Kannan-Bachem (KB) algorithm is the first polynomial algorithm computing such a reduction. Using this algorithm in complicated situations where the rank of the studied matrix is not maximal revealed an unexpected obstacle in the algorithm. This difficulty is described, analyzed, a simple solution is given to overcome it, finally leading to a general organization of the KB algorithm, simpler than the original one, efficient and having a general scope.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "An equivalent algorithm is used by the Magma program, without any detailed explanation, without any reference. The present text could so be useful"
    },
    {
        "paper id": "2411.02424",
        "abstract url": "https://arxiv.org/abs/2411.02424",
        "title": "Set-based queries for multiscale shape-material modeling",
        "rating": "-10",
        "keywords": [],
        "abstract": "Multiscale structures are becoming increasingly prevalent in the field of mechanical design. The variety of fine-scale structures and their respective representations results in an interoperability challenge. To address this, a query-based API was recently proposed which allows different representations to be combined across the scales for multiscale structures modeling. The query-based approach is fully parallelizable and has a low memory footprint; however, this architecture requires repeated evaluation of the fine-scale structures locally for each individual query. While this overhead is manageable for simpler fine-scale structures such as parametric lattice structures, it is problematic for structures requiring non-trivial computations, such as Voronoi foam structures. In this paper, we develop a set-based query that retains the compatibility and usability of the point-based query while leveraging locality between multiple point-based queries to provide a significant speedup and further decrease the memory consumption for common applications, including visualization and slicing for manufacturing planning. We first define the general set-based query that consolidates multiple point-based queries at arbitrary locations. We then implement specialized preprocessing methods for different types of fine-scale structures which are otherwise inefficient with the point-based query. Finally, we apply the set-based query to downstream applications such as ray-casting and slicing, increasing their performance by an order of magnitude. The overall improvements result in the generation and rendering of complex fine-scale structures such as Voronoi foams at interactive frame rates on the CPU.",
        "subjects": [
            "cs.CE",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.03325",
        "abstract url": "https://arxiv.org/abs/2411.03325",
        "title": "Geographical and Disciplinary Coverage of Open Access Journals: OpenAlex, Scopus and WoS",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study aims to compare the geographical and disciplinary coverage of OA journals in three databases: OpenAlex, Scopus and the WoS. We used the ROAD database, managed by the ISSN International Centre, as a reference database which indexes 62,701 OA active resources (as of May 2024). Among the 62,701 active resources indexed in the ROAD database, the Web of Science indexes 6,157 journals, while Scopus indexes 7,351, and OpenAlex indexes 34,217. A striking observation is the presence of 25,658 OA journals exclusively in OpenAlex, whereas only 182 journals are exclusively present in WoS and 373 in Scopus. The geographical analysis focusses on two levels: continents and countries. As for disciplinary comparison, we use the ten disciplinary levels of the ROAD database. Moreover, our findings reveal a striking similarity in OA journal coverage between WoS and Scopus. However, while OpenAlex offers better inclusivity and indexing, it is not without biases. WoS and Scopus predictably favor journals from Europe, North America and Oceania. Although OpenAlex presents a much more balanced indexing, certain regions and countries remain relatively underrepresented. Typically, Africa is proportionally as under-represented in OpenAlex as it is in WoS, and some emerging countries are proportionally less represented in OpenAlex than in WoS and Scopus. These results underscore a marked similarity in OA journal indexing between WoS and Scopus, while OpenAlex aligns more closely with the distribution observed in the ROAD database, although it also exhibits some representational biases.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    }
]