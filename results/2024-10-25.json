[
    {
        "paper id": "2410.19313",
        "abstract url": "https://arxiv.org/abs/2410.19313",
        "title": "COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training",
        "rating": "2.5",
        "keywords": [
            [
                "Memory-Efficient"
            ],
            [
                "Vision Language"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "FP8 training has emerged as a promising method for improving training efficiency. Existing frameworks accelerate training by applying FP8 computation to linear layers while leaving optimizer states and activations in higher precision, which fails to fully optimize memory usage. This paper introduces COAT (Compressing Optimizer States and Activations for FP8 Training), a novel FP8 training framework designed to significantly reduce memory footprint when training large models. COAT addresses current limitations through two key innovations: (1) Dynamic Range Expansion, which aligns optimizer state distributions more closely with the FP8 representation range, thereby reducing quantization error, and (2) Mixed-Granularity Activation Quantization, which optimizes activation memory using a combination of per-tensor and per-group quantization strategies. Experiments demonstrate that COAT effectively reduces end-to-end training memory footprint by 1.54x compared to BF16 while achieving nearly lossless performance across various tasks, such as Large Language Model pretraining and fine-tuning and Vision Language Model training. COAT also achieves a 1.43x end-to-end training speedup compared to BF16, performing on par with or surpassing TransformerEngine's speedup. COAT enables efficient full-parameter training of large models on fewer GPUs, and facilitates doubling the batch size in distributed training settings, providing a practical solution for scaling large-scale model training. The code is available at https://github.com/NVlabs/COAT.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "16 pages. 9 Figures. 8 Tables"
    },
    {
        "paper id": "2410.19925",
        "abstract url": "https://arxiv.org/abs/2410.19925",
        "title": "Improving Multimodal Large Language Models Using Continual Learning",
        "rating": "2.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Generative large language models (LLMs) exhibit impressive capabilities, which can be further augmented by integrating a pre-trained vision model into the original LLM to create a multimodal LLM (MLLM). However, this integration often significantly decreases performance on natural language understanding and generation tasks, compared to the original LLM. This study investigates this issue using the LLaVA MLLM, treating the integration as a continual learning problem. We evaluate five continual learning methods to mitigate forgetting and identify a technique that enhances visual understanding while minimizing linguistic performance loss. Our approach reduces linguistic performance degradation by up to 15\\% over the LLaVA recipe, while maintaining high multimodal accuracy. We also demonstrate the robustness of our method through continual learning on a sequence of vision-language tasks, effectively preserving linguistic skills while acquiring new multimodal capabilities.",
        "subjects": [
            "cs.CL",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "NeurIPS 2024 Workshop on Scalable Continual Learning for Lifelong Foundation Models"
    },
    {
        "paper id": "2410.20008",
        "abstract url": "https://arxiv.org/abs/2410.20008",
        "title": "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models",
        "rating": "2.5",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Fine-tuning pre-trained large language models (LLMs) on a diverse array of tasks has become a common approach for building models that can solve various natural language processing (NLP) tasks. However, where and to what extent these models retain task-specific knowledge remains largely unexplored. This study investigates the task-specific information encoded in pre-trained LLMs and the effects of instruction tuning on their representations across a diverse set of over 60 NLP tasks. We use a set of matrix analysis tools to examine the differences between the way pre-trained and instruction-tuned LLMs store task-specific information. Our findings reveal that while some tasks are already encoded within the pre-trained LLMs, others greatly benefit from instruction tuning. Additionally, we pinpointed the layers in which the model transitions from high-level general representations to more task-oriented representations. This finding extends our understanding of the governing mechanisms of LLMs and facilitates future research in the fields of parameter-efficient transfer learning and multi-task learning.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted to EMNLP 2024"
    },
    {
        "paper id": "2410.19314",
        "abstract url": "https://arxiv.org/abs/2410.19314",
        "title": "Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs)",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Pre-trained large language models (LLMs) have been reliably integrated with visual input for multimodal tasks. The widespread adoption of instruction-tuned image-to-text vision-language assistants (VLAs) like LLaVA and InternVL necessitates evaluating gender biases. We study gender bias in 22 popular open-source VLAs with respect to personality traits, skills, and occupations. Our results show that VLAs replicate human biases likely present in the data, such as real-world occupational imbalances. Similarly, they tend to attribute more skills and positive personality traits to women than to men, and we see a consistent tendency to associate negative personality traits with men. To eliminate the gender bias in these models, we find that finetuning-based debiasing methods achieve the best tradeoff between debiasing and retaining performance on downstream tasks. We argue for pre-deploying gender bias assessment in VLAs and motivate further development of debiasing strategies to ensure equitable societal outcomes.",
        "subjects": [
            "cs.CY",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19694",
        "abstract url": "https://arxiv.org/abs/2410.19694",
        "title": "Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "Efficient Finetuning"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Fine-tuning Large Language Models (LLMs) has become a crucial technique for adapting pre-trained models to downstream tasks. However, the enormous size of LLMs poses significant challenges in terms of computational complexity and resource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising solution. However, there exists a gap between the practical performance of low-rank adaptations and its theoretical optimum. In this work, we propose eXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this gap by leveraging the power of ensemble learning. Inspired by gradient boosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations to refine model predictions. It achieves better performance than the standard LoRA, while enjoying the computational efficiency of rank-1 adaptations. We provide theoretical analysis to show the convergence and optimality of our approach, and conduct extensive experiments on a range of natural language processing tasks. The results demonstrate that XGBLoRA consistently outperforms standard LoRA and achieves performance comparable to full fine-tuning with significantly fewer trainable parameters. This work advances parameter-efficient fine-tuning for LLMs, and offers a promising solution for adapting LLMs to downstream tasks while optimizing performance and efficiency.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "19 pages"
    },
    {
        "paper id": "2410.19732",
        "abstract url": "https://arxiv.org/abs/2410.19732",
        "title": "Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Large Vision-Language Models (LVLMs) excel in cross-model tasks but experience performance declines in long-context reasoning due to overreliance on textual information and reduced visual dependency. In this study, we empirically analyze LVLMs in long-context reasoning, revealing that increased context length leads to a higher dependence on language at the expense of visual dependency. To address this issue, we propose a novel training-free context pruning method that selectively removes less critical textual information. Our approach enhances visual dependency and reduces textual noise, thereby improving LVLM performance in long-context reasoning. We validate our method by constructing a long-context dataset, demonstrating its effectiveness across various LVLMs. Moreover, further analysis confirms the robustness of different token pruning strategies and preliminary explores scaling laws between pruning rates and context length.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.21311",
        "abstract url": "https://arxiv.org/abs/2410.21311",
        "title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable performance in many vision-language tasks, yet their capabilities in fine-grained visual understanding remain insufficiently evaluated. Existing benchmarks either contain limited fine-grained evaluation samples that are mixed with other data, or are confined to object-level assessments in natural images. To holistically assess LVLMs' fine-grained visual understanding capabilities, we propose using document images with multi-granularity and multi-modal information to supplement natural images. In this light, we construct MMDocBench, a benchmark with various OCR-free document understanding tasks for the evaluation of fine-grained visual perception and reasoning abilities. MMDocBench defines 15 main tasks with 4,338 QA pairs and 11,353 supporting regions, covering various document images such as research papers, receipts, financial reports, Wikipedia tables, charts, and infographics. Based on MMDocBench, we conduct extensive experiments using 13 open-source and 3 proprietary advanced LVLMs, assessing their strengths and weaknesses across different tasks and document image types. The benchmark, task instructions, and evaluation code will be made publicly available.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2410.19319",
        "abstract url": "https://arxiv.org/abs/2410.19319",
        "title": "Fully First-Order Methods for Decentralized Bilevel Optimization",
        "rating": "1.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper focuses on decentralized stochastic bilevel optimization (DSBO) where agents only communicate with their neighbors. We propose Decentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a novel algorithm that only requires first-order oracles that are much cheaper than second-order oracles widely adopted in existing works. We further provide a finite-time convergence analysis showing that for $n$ agents collaboratively solving the DSBO problem, the sample complexity of finding an $\u03b5$-stationary point in our algorithm is $\\mathcal{O}(n^{-1}\u03b5^{-7})$, which matches the currently best-known results of the single-agent counterpart with linear speedup. The numerical experiments demonstrate both the communication and training efficiency of our algorithm.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": "46 pages"
    },
    {
        "paper id": "2410.19461",
        "abstract url": "https://arxiv.org/abs/2410.19461",
        "title": "EDGE: Enhanced Grounded GUI Understanding with Enriched Multi-Granularity Synthetic Data",
        "rating": "1.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Autonomous agents operating on the graphical user interfaces (GUIs) of various applications hold immense practical value. Unlike the large language model (LLM)-based methods which rely on structured texts and customized backends, the approaches using large vision-language models (LVLMs) are more intuitive and adaptable as they can visually perceive and directly interact with screens, making them indispensable in general scenarios without text metadata and tailored backends. Given the lack of high-quality training data for GUI-related tasks in existing work, this paper aims to enhance the GUI understanding and interacting capabilities of LVLMs through a data-driven approach. We propose EDGE, a general data synthesis framework that automatically generates large-scale, multi-granularity training data from webpages across the Web. Evaluation results on various GUI and agent benchmarks demonstrate that the model trained with the dataset generated through EDGE exhibits superior webpage understanding capabilities, which can then be easily transferred to previously unseen desktop and mobile environments. Our approach significantly reduces the dependence on manual annotations, empowering researchers to harness the vast public resources available on the Web to advance their work. Our source code, the dataset and the model are available at https://anonymous.4open.science/r/EDGE-1CDB.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19479",
        "abstract url": "https://arxiv.org/abs/2410.19479",
        "title": "Peter Parker or Spiderman? Disambiguating Multiple Class Labels",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In the supervised classification setting, during inference, deep networks typically make multiple predictions. For a pair of such predictions (that are in the top-k predictions), two distinct possibilities might occur. On the one hand, each of the two predictions might be primarily driven by two distinct sets of entities in the input. On the other hand, it is possible that there is a single entity or set of entities that is driving the prediction for both the classes in question. This latter case, in effect, corresponds to the network making two separate guesses about the identity of a single entity type. Clearly, both the guesses cannot be true, i.e. both the labels cannot be present in the input. Current techniques in interpretability research do not readily disambiguate these two cases, since they typically consider input attributions for one class label at a time. Here, we present a framework and method to do so, leveraging modern segmentation and input attribution techniques. Notably, our framework also provides a simple counterfactual \"proof\" of each case, which can be verified for the input on the model (i.e. without running the method again). We demonstrate that the method performs well for a number of samples from the ImageNet validation set and on multiple models.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted to Neural Information Processing Systems (NeurIPS 2024). ATTRIB Workshop"
    },
    {
        "paper id": "2410.19553",
        "abstract url": "https://arxiv.org/abs/2410.19553",
        "title": "On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "This paper explores the impact of occlusions in video action detection. We facilitate this study by introducing five new benchmark datasets namely O-UCF and O-JHMDB consisting of synthetically controlled static/dynamic occlusions, OVIS-UCF and OVIS-JHMDB consisting of occlusions with realistic motions and Real-OUCF for occlusions in realistic-world scenarios. We formally confirm an intuitive expectation: existing models suffer a lot as occlusion severity is increased and exhibit different behaviours when occluders are static vs when they are moving. We discover several intriguing phenomenon emerging in neural nets: 1) transformers can naturally outperform CNN models which might have even used occlusion as a form of data augmentation during training 2) incorporating symbolic-components like capsules to such backbones allows them to bind to occluders never even seen during training and 3) Islands of agreement can emerge in realistic images/videos without instance-level supervision, distillation or contrastive-based objectives2(eg. video-textual training). Such emergent properties allow us to derive simple yet effective training recipes which lead to robust occlusion models inductively satisfying the first two stages of the binding mechanism (grouping/segregation). Models leveraging these recipes outperform existing video action-detectors under occlusion by 32.3% on O-UCF, 32.7% on O-JHMDB & 2.6% on Real-OUCF in terms of the vMAP metric. The code for this work has been released at https://github.com/rajatmodi62/OccludedActionBenchmark.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "This paper was accepted to NeurIPS 2023 Dataset And Benchmark Track. It also showcases: Hinton's Islands of Agreement on realistic datasets which were previously hypothesized in his GLOM paper"
    },
    {
        "paper id": "2410.19635",
        "abstract url": "https://arxiv.org/abs/2410.19635",
        "title": "Frozen-DETR: Enhancing DETR with Image Understanding from Frozen Foundation Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Recent vision foundation models can extract universal representations and show impressive abilities in various tasks. However, their application on object detection is largely overlooked, especially without fine-tuning them. In this work, we show that frozen foundation models can be a versatile feature enhancer, even though they are not pre-trained for object detection. Specifically, we explore directly transferring the high-level image understanding of foundation models to detectors in the following two ways. First, the class token in foundation models provides an in-depth understanding of the complex scene, which facilitates decoding object queries in the detector's decoder by providing a compact context. Additionally, the patch tokens in foundation models can enrich the features in the detector's encoder by providing semantic details. Utilizing frozen foundation models as plug-and-play modules rather than the commonly used backbone can significantly enhance the detector's performance while preventing the problems caused by the architecture discrepancy between the detector's backbone and the foundation model. With such a novel paradigm, we boost the SOTA query-based detector DINO from 49.0% AP to 51.9% AP (+2.9% AP) and further to 53.8% AP (+4.8% AP) by integrating one or two foundation models respectively, on the COCO validation set after training for 12 epochs with R50 as the detector's backbone.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to NeurIPS 2024"
    },
    {
        "paper id": "2410.19637",
        "abstract url": "https://arxiv.org/abs/2410.19637",
        "title": "A distributional simplicity bias in the learning dynamics of transformers",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The remarkable capability of over-parameterised neural networks to generalise effectively has been explained by invoking a ``simplicity bias'': neural networks prevent overfitting by initially learning simple classifiers before progressing to more complex, non-linear functions. While simplicity biases have been described theoretically and experimentally in feed-forward networks for supervised learning, the extent to which they also explain the remarkable success of transformers trained with self-supervised techniques remains unclear. In our study, we demonstrate that transformers, trained on natural language data, also display a simplicity bias. Specifically, they sequentially learn many-body interactions among input tokens, reaching a saturation point in the prediction error for low-degree interactions while continuing to learn high-degree interactions. To conduct this analysis, we develop a procedure to generate \\textit{clones} of a given natural language data set, which rigorously capture the interactions between tokens up to a specified order. This approach opens up the possibilities of studying how interactions of different orders in the data affect learning, in natural language processing and beyond.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, 5 figures, Accepted at NeurIPS 2024"
    },
    {
        "paper id": "2410.19889",
        "abstract url": "https://arxiv.org/abs/2410.19889",
        "title": "Ensembling Finetuned Language Models for Text Classification",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Finetuning is a common practice widespread across different communities to adapt pretrained models to particular tasks. Text classification is one of these tasks for which many pretrained models are available. On the other hand, ensembles of neural networks are typically used to boost performance and provide reliable uncertainty estimates. However, ensembling pretrained models for text classification is not a well-studied avenue. In this paper, we present a metadataset with predictions from five large finetuned models on six datasets, and report results of different ensembling strategies from these predictions. Our results shed light on how ensembling can improve the performance of finetuned text classifiers and incentivize future adoption of ensembles in such tasks.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Workshop on Fine-Tuning in Modern Machine Learning @ NeurIPS 2024. arXiv admin note: text overlap with arXiv:2410.04520"
    },
    {
        "paper id": "2410.19935",
        "abstract url": "https://arxiv.org/abs/2410.19935",
        "title": "Do Discrete Self-Supervised Representations of Speech Capture Tone Distinctions?",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Discrete representations of speech, obtained from Self-Supervised Learning (SSL) foundation models, are widely used, especially where there are limited data for the downstream task, such as for a low-resource language. Typically, discretization of speech into a sequence of symbols is achieved by unsupervised clustering of the latents from an SSL model. Our study evaluates whether discrete symbols - found using k-means - adequately capture tone in two example languages, Mandarin and Yoruba. We compare latent vectors with discrete symbols, obtained from HuBERT base, MandarinHuBERT, or XLS-R, for vowel and tone classification. We find that using discrete symbols leads to a substantial loss of tone information, even for language-specialised SSL models. We suggest that discretization needs to be task-aware, particularly for tone-dependent downstream tasks.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Submitted to ICASSP 2025"
    },
    {
        "paper id": "2410.22360",
        "abstract url": "https://arxiv.org/abs/2410.22360",
        "title": "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "When conducting literature reviews, scientists often create literature review tables - tables whose rows are publications and whose columns constitute a schema, a set of aspects used to compare and contrast the papers. Can we automatically generate these tables using language models (LMs)? In this work, we introduce a framework that leverages LMs to perform this task by decomposing it into separate schema and value generation steps. To enable experimentation, we address two main challenges: First, we overcome a lack of high-quality datasets to benchmark table generation by curating and releasing arxivDIGESTables, a new dataset of 2,228 literature review tables extracted from ArXiv papers that synthesize a total of 7,542 research papers. Second, to support scalable evaluation of model generations against human-authored reference tables, we develop DecontextEval, an automatic evaluation method that aligns elements of tables with the same underlying aspects despite differing surface forms. Given these tools, we evaluate LMs' abilities to reconstruct reference tables, finding this task benefits from additional context to ground the generation (e.g. table captions, in-text references). Finally, through a human evaluation study we find that even when LMs fail to fully reconstruct a reference table, their generated novel aspects can still be useful.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EMNLP 2024, 21 pages, 8 figures, 10 tables"
    },
    {
        "paper id": "2410.19307",
        "abstract url": "https://arxiv.org/abs/2410.19307",
        "title": "Semi-supervised Chinese Poem-to-Painting Generation via Cycle-consistent Adversarial Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Classical Chinese poetry and painting represent the epitome of artistic expression, but the abstract and symbolic nature of their relationship poses a significant challenge for computational translation. Most existing methods rely on large-scale paired datasets, which are scarce in this domain. In this work, we propose a semi-supervised approach using cycle-consistent adversarial networks to leverage the limited paired data and large unpaired corpus of poems and paintings. The key insight is to learn bidirectional mappings that enforce semantic alignment between the visual and textual modalities. We introduce novel evaluation metrics to assess the quality, diversity, and consistency of the generated poems and paintings. Extensive experiments are conducted on a new Chinese Painting Description Dataset (CPDD). The proposed model outperforms previous methods, showing promise in capturing the symbolic essence of artistic expression. Codes are available online \\url{https://github.com/Mnster00/poemtopainting}.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19317",
        "abstract url": "https://arxiv.org/abs/2410.19317",
        "title": "FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The growing use of large language model (LLM)-based chatbots has raised concerns about fairness. Fairness issues in LLMs can lead to severe consequences, such as bias amplification, discrimination, and harm to marginalized communities. While existing fairness benchmarks mainly focus on single-turn dialogues, multi-turn scenarios, which in fact better reflect real-world conversations, present greater challenges due to conversational complexity and potential bias accumulation. In this paper, we propose a comprehensive fairness benchmark for LLMs in multi-turn dialogue scenarios, \\textbf{FairMT-Bench}. Specifically, we formulate a task taxonomy targeting LLM fairness capabilities across three stages: context understanding, user interaction, and instruction trade-offs, with each stage comprising two tasks. To ensure coverage of diverse bias types and attributes, we draw from existing fairness datasets and employ our template to construct a multi-turn dialogue dataset, \\texttt{FairMT-10K}. For evaluation, GPT-4 is applied, alongside bias classifiers including Llama-Guard-3 and human validation to ensure robustness. Experiments and analyses on \\texttt{FairMT-10K} reveal that in multi-turn dialogue scenarios, current LLMs are more likely to generate biased responses, and there is significant variation in performance across different tasks and models. Based on this, we curate a challenging dataset, \\texttt{FairMT-1K}, and test 15 current state-of-the-art (SOTA) LLMs on this dataset. The results show the current state of fairness in LLMs and showcase the utility of this novel approach for assessing fairness in more realistic multi-turn dialogue contexts, calling for future work to focus on LLM fairness improvement and the adoption of \\texttt{FairMT-1K} in such efforts.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19318",
        "abstract url": "https://arxiv.org/abs/2410.19318",
        "title": "Two are better than one: Context window extension with multi-grained self-injection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The limited context window of contemporary large language models (LLMs) remains a huge barrier to their broader application across various domains. While continual pre-training on long-context data is a straightforward and effective solution, it incurs substantial costs in terms of data acquisition and computational resources. To alleviate this issue, we propose SharedLLM, a novel approach grounded in the design philosophy of multi-grained context compression and query-aware information retrieval. SharedLLM is composed of two short-context LLMs such as LLaMA-2, termed upper model and lower model. The lower model functions as a compressor while the upper model acts as a decoder. The upper model receives compressed, multi-grained context information from the lower model and performs context-aware modeling on the running text. Information transfer between the compressor and decoder occurs only at the lowest layers to refrain from long forward paths in the lower model and redundant cross-attention modules in the upper model. Based on this architecture, we introduce a specialized tree-style data structure to efficiently encode, store and retrieve multi-grained contextual information for text chunks. This structure, combined with a search algorithm, enables rapid encoding and retrieval of relevant information from various levels of the tree based on the input query. This entire process, wherein the sender and receiver are derived from the same LLM layer, is referred to as self-injection.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "The code is available at https://github.com/Clement25/SharedLLM"
    },
    {
        "paper id": "2410.19324",
        "abstract url": "https://arxiv.org/abs/2410.19324",
        "title": "Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion",
        "rating": "1",
        "keywords": [
            [
                "memory-efficient"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Latent diffusion models have become the popular choice for scaling up diffusion models for high resolution image synthesis. Compared to pixel-space models that are trained end-to-end, latent models are perceived to be more efficient and to produce higher image quality at high resolution. Here we challenge these notions, and show that pixel-space models can in fact be very competitive to latent approaches both in quality and efficiency, achieving 1.5 FID on ImageNet512 and new SOTA results on ImageNet128 and ImageNet256. We present a simple recipe for scaling end-to-end pixel-space diffusion models to high resolutions. 1: Use the sigmoid loss (Kingma & Gao, 2023) with our prescribed hyper-parameters. 2: Use our simplified memory-efficient architecture with fewer skip-connections. 3: Scale the model to favor processing the image at high resolution with fewer parameters, rather than using more parameters but at a lower resolution. When combining these three steps with recently proposed tricks like guidance intervals, we obtain a family of pixel-space diffusion models we call Simple Diffusion v2 (SiD2).",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19346",
        "abstract url": "https://arxiv.org/abs/2410.19346",
        "title": "AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are increasingly leveraged to empower autonomous agents to simulate human beings in various fields of behavioral research. However, evaluating their capacity to navigate complex social interactions remains a challenge. Previous studies face limitations due to insufficient scenario diversity, complexity, and a single-perspective focus. To this end, we introduce AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense employs a bottom-up approach to create 1,225 diverse social scenarios constructed from extensive scripts. We evaluate LLM-driven agents through multi-turn interactions, emphasizing both goal completion and implicit reasoning. We analyze goals using ERG theory and conduct comprehensive experiments. Our findings highlight that LLMs struggle with goals in complex social scenarios, especially high-level growth needs, and even GPT-4o requires improvement in private information reasoning.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19347",
        "abstract url": "https://arxiv.org/abs/2410.19347",
        "title": "Practical High-Contrast Holography",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Holographic displays are a promising technology for immersive visual experiences, and their potential for compact form factor makes them a strong candidate for head-mounted displays. However, at the short propagation distances needed for a compact, head-mounted architecture, image contrast is low when using a traditional phase-only spatial light modulator (SLM). Although a complex SLM could restore contrast, these modulators require bulky lenses to optically co-locate the amplitude and phase components, making them poorly suited for a compact head-mounted design. In this work, we introduce a novel architecture to improve contrast: by adding a low resolution amplitude SLM a short distance away from the phase modulator, we demonstrate peak signal-to-noise ratio improvement up to 31 dB in simulation compared to phase-only, even when the amplitude modulator is 60$\\times$ lower resolution than its phase counterpart. We analyze the relationship between diffraction angle and amplitude modulator pixel size, and validate the concept with a benchtop experimental prototype. By showing that low resolution modulation is sufficient to improve contrast, we pave the way towards practical high-contrast holography in a compact form factor.",
        "subjects": [
            "physics.optics",
            "cs.GR",
            "eess.IV"
        ],
        "comment": "19 pages, 17 figures"
    },
    {
        "paper id": "2410.19353",
        "abstract url": "https://arxiv.org/abs/2410.19353",
        "title": "Interleaving Text and Number Embeddings to Solve Mathemathics Problems",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Integrating text and numbers effectively is a crucial step towards enhancing Large Language Models (LLMs) capabilities in assisting in scientific tasks. While most current approaches rely on discrete tokenization of numbers, for instance, conversion to scientific notation or base 10-decomposition, a recent approach proposed a continuous numerical encoding as an inductive bias. In this paper, we build upon this approach by introducing more expressive numerical embeddings. Our method addresses key shortcomings, including the elimination of numerical artefacts and the ability to handle a wide range of magnitudes without clipping. Our work presents two key contributions. First, we employ an MLP to assign distinct directions in the embedding space to different numbers. Our second contribution is the introduction of a routing layer that differentiates between numerical and text embeddings. We hypothesise that this combined approach enables the model to distinguish between text and number distributions while maintaining its capacity for arithmetic operations. Using only a 45 M parameter encoder-decoder architecture our method achieves a $R^2$=0.9988 over a wide range of magnitude ($10^{-3},10^{8}$). In addition, we empirically observe a reduction of the numerical artefacts and biases observed compared to the baselines.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19378",
        "abstract url": "https://arxiv.org/abs/2410.19378",
        "title": "Unified Cross-Modal Image Synthesis with Hierarchical Mixture of Product-of-Experts",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We propose a deep mixture of multimodal hierarchical variational auto-encoders called MMHVAE that synthesizes missing images from observed images in different modalities. MMHVAE's design focuses on tackling four challenges: (i) creating a complex latent representation of multimodal data to generate high-resolution images; (ii) encouraging the variational distributions to estimate the missing information needed for cross-modal image synthesis; (iii) learning to fuse multimodal information in the context of missing data; (iv) leveraging dataset-level information to handle incomplete data sets at training time. Extensive experiments are performed on the challenging problem of pre-operative brain multi-parametric magnetic resonance and intra-operative ultrasound imaging.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "Manuscript under review"
    },
    {
        "paper id": "2410.19385",
        "abstract url": "https://arxiv.org/abs/2410.19385",
        "title": "Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are powerful computational models trained on extensive corpora of human-readable text, enabling them to perform general-purpose language understanding and generation. LLMs have garnered significant attention in both industry and academia due to their exceptional performance across various natural language processing (NLP) tasks. Despite these successes, LLMs often produce inaccuracies, commonly referred to as hallucinations. Prompt engineering, the process of designing and formulating instructions for LLMs to perform specific tasks, has emerged as a key approach to mitigating hallucinations. This paper provides a comprehensive empirical evaluation of different prompting strategies and frameworks aimed at reducing hallucinations in LLMs. Various prompting techniques are applied to a broad set of benchmark datasets to assess the accuracy and hallucination rate of each method. Additionally, the paper investigates the influence of tool-calling agents (LLMs augmented with external tools to enhance their capabilities beyond language generation) on hallucination rates in the same benchmarks. The findings demonstrate that the optimal prompting technique depends on the type of problem, and that simpler techniques often outperform more complex methods in reducing hallucinations. Furthermore, it is shown that LLM agents can exhibit significantly higher hallucination rates due to the added complexity of external tool usage.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19400",
        "abstract url": "https://arxiv.org/abs/2410.19400",
        "title": "Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In offline reinforcement learning (RL), addressing the out-of-distribution (OOD) action issue has been a focus, but we argue that there exists an OOD state issue that also impairs performance yet has been underexplored. Such an issue describes the scenario when the agent encounters states out of the offline dataset during the test phase, leading to uncontrolled behavior and performance degradation. To this end, we propose SCAS, a simple yet effective approach that unifies OOD state correction and OOD action suppression in offline RL. Technically, SCAS achieves value-aware OOD state correction, capable of correcting the agent from OOD states to high-value in-distribution states. Theoretical and empirical results show that SCAS also exhibits the effect of suppressing OOD actions. On standard offline RL benchmarks, SCAS achieves excellent performance without additional hyperparameter tuning. Moreover, benefiting from its OOD state correction feature, SCAS demonstrates enhanced robustness against environmental perturbations.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to NeurIPS 2024"
    },
    {
        "paper id": "2410.19437",
        "abstract url": "https://arxiv.org/abs/2410.19437",
        "title": "Transductive Learning for Near-Duplicate Image Detection in Scanned Photo Collections",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a comparative study of near-duplicate image detection techniques in a real-world use case scenario, where a document management company is commissioned to manually annotate a collection of scanned photographs. Detecting duplicate and near-duplicate photographs can reduce the time spent on manual annotation by archivists. This real use case differs from laboratory settings as the deployment dataset is available in advance, allowing the use of transductive learning. We propose a transductive learning approach that leverages state-of-the-art deep learning architectures such as convolutional neural networks (CNNs) and Vision Transformers (ViTs). Our approach involves pre-training a deep neural network on a large dataset and then fine-tuning the network on the unlabeled target collection with self-supervised learning. The results show that the proposed approach outperforms the baseline methods in the task of near-duplicate image detection in the UKBench and an in-house private dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published in ICDAR 2023"
    },
    {
        "paper id": "2410.19453",
        "abstract url": "https://arxiv.org/abs/2410.19453",
        "title": "ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Although fine-tuning Large Language Models (LLMs) with multilingual data can rapidly enhance the multilingual capabilities of LLMs, they still exhibit a performance gap between the dominant language (e.g., English) and non-dominant ones due to the imbalance of training data across languages. To further enhance the performance of non-dominant languages, we propose ShifCon, a Shift-based Contrastive framework that aligns the internal forward process of other languages toward that of the dominant one. Specifically, it shifts the representations of non-dominant languages into the dominant language subspace, allowing them to access relatively rich information encoded in the model parameters. The enriched representations are then shifted back into their original language subspace before generation. Moreover, we introduce a subspace distance metric to pinpoint the optimal layer area for shifting representations and employ multilingual contrastive learning to further enhance the alignment of representations within this area. Experiments demonstrate that our ShifCon framework significantly enhances the performance of non-dominant languages, particularly for low-resource ones. Further analysis offers extra insights to verify the effectiveness of ShifCon and propel future research",
        "subjects": [
            "cs.CL"
        ],
        "comment": "23 pages, 11 figures"
    },
    {
        "paper id": "2410.19460",
        "abstract url": "https://arxiv.org/abs/2410.19460",
        "title": "Accelerating AI Performance using Anderson Extrapolation on GPUs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We present a novel approach for accelerating AI performance by leveraging Anderson extrapolation, a vector-to-vector mapping technique based on a window of historical iterations. By identifying the crossover point where a mixing penalty is incurred, the method focuses on reducing iterations to convergence, with fewer more compute-intensive but generally cacheable iterations, balancing speed and memory usage with accuracy and algorithmic stability, respectively. We demonstrate significant improvements, in both training and inference, motivated by scalability and efficiency extensions to the realm of high-performance computing (HPC).",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.PF",
            "math.NA"
        ],
        "comment": "6 pages, 6 figures, 1 table, Accepted by NeurIPS 2024 Workshop MLNCP https://openreview.net/forum?id=wkP2ZFRn9e"
    },
    {
        "paper id": "2410.19485",
        "abstract url": "https://arxiv.org/abs/2410.19485",
        "title": "A Debate-Driven Experiment on LLM Hallucinations and Accuracy",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have achieved a degree of success in generating coherent and contextually relevant text, yet they remain prone to a significant challenge known as hallucination: producing information that is not substantiated by the input or external knowledge. Previous efforts to mitigate hallucinations have focused on techniques such as fine-tuning models on high-quality datasets, incorporating fact-checking mechanisms, and developing adversarial training methods. While these approaches have shown some promise, they often address the issue at the level of individual model outputs, leaving unexplored the effects of inter-model interactions on hallucination. This study investigates the phenomenon of hallucination in LLMs through a novel experimental framework where multiple instances of GPT-4o-Mini models engage in a debate-like interaction prompted with questions from the TruthfulQA dataset. One model is deliberately instructed to generate plausible but false answers while the other models are asked to respond truthfully. The experiment is designed to assess whether the introduction of misinformation by one model can challenge the truthful majority to better justify their reasoning, improving performance on the TruthfulQA benchmark. The findings suggest that inter-model interactions can offer valuable insights into improving the accuracy and robustness of LLM outputs, complementing existing mitigation strategies.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19493",
        "abstract url": "https://arxiv.org/abs/2410.19493",
        "title": "Conditional Hallucinations for Image Compression",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In lossy image compression, models face the challenge of either hallucinating details or generating out-of-distribution samples due to the information bottleneck. This implies that at times, introducing hallucinations is necessary to generate in-distribution samples. The optimal level of hallucination varies depending on image content, as humans are sensitive to small changes that alter the semantic meaning. We propose a novel compression method that dynamically balances the degree of hallucination based on content. We collect data and train a model to predict user preferences on hallucinations. By using this prediction to adjust the perceptual weight in the reconstruction loss, we develop a Conditionally Hallucinating compression model (ConHa) that outperforms state-of-the-art image compression methods. Code and images are available at https://polybox.ethz.ch/index.php/s/owS1k5JYs4KD4TA.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19499",
        "abstract url": "https://arxiv.org/abs/2410.19499",
        "title": "Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Momentum-Aided Prompt Optimization (MAPO) enhances the efficiency and efficacy of prompt optimization for Large Language Models (LLMs). Building on ProTeGi, MAPO uses positive natural language \"gradients\" and a momentum-based extension to refine prompts effectively. By tracking gradient history, MAPO avoids local minima and oscillations. It also utilizes beam search and an Upper Confidence Bound (UCB) algorithm for balanced candidate expansion and selection. Benchmark testing shows that MAPO achieves faster convergence time with fewer API calls and higher F1 scores than ProTeGi, proving it as a robust and scalable solution for automated prompt engineering in LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19503",
        "abstract url": "https://arxiv.org/abs/2410.19503",
        "title": "SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite the success of Large Language Models (LLMs), they still face challenges related to high inference costs and memory requirements. To address these issues, Knowledge Distillation (KD) has emerged as a popular method for model compression, with student-generated outputs (SGOs) being particularly notable for reducing the mismatch between training and inference. However, SGOs often produce noisy and biased sequences, which can lead to misguidance from the teacher model, especially in long sequences. To mitigate these challenges, we propose SWITCH (Studying WIth TeaCHer for Knowledge Distillation), a novel approach that strategically incorporates the teacher model during the student's sequence generation. SWITCH identifies discrepancies between the token probabilities of the teacher and student models, allowing the teacher to intervene selectively, particularly in long sequences that are more prone to teacher misguidance. Extensive experimental results across three model families and five instruction-following datasets show that SWITCH surpasses traditional KD methods, particularly excelling in the generation of long sequential data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19517",
        "abstract url": "https://arxiv.org/abs/2410.19517",
        "title": "Detection of Human and Machine-Authored Fake News in Urdu",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The rise of social media has amplified the spread of fake news, now further complicated by large language models (LLMs) like ChatGPT, which ease the generation of highly convincing, error-free misinformation, making it increasingly challenging for the public to discern truth from falsehood. Traditional fake news detection methods relying on linguistic cues also becomes less effective. Moreover, current detectors primarily focus on binary classification and English texts, often overlooking the distinction between machine-generated true vs. fake news and the detection in low-resource languages. To this end, we updated detection schema to include machine-generated news with focus on the Urdu language. We further propose a hierarchical detection strategy to improve the accuracy and robustness. Experiments show its effectiveness across four datasets in various settings.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19549",
        "abstract url": "https://arxiv.org/abs/2410.19549",
        "title": "Mirror Matrix on the Wall: coding and vector notation as tools for introspection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The vector notation adopted by GNU Octave plays a significant role as a tool for introspection, aligning itself with the vision of Kenneth E. Iverson. He believed that, just like mathematics, a programming language should be an effective thinking tool for representing and reasoning about problems we wish to address. This work aims to explore the use of vector notation in GNU Octave through the analysis of operators and functions, providing a closer alignment with mathematical notation and enhancing code efficiency. We will delve into fundamental concepts such as indexing, broadcasting, and function handles, and present case studies for a deeper understanding of these concepts. By adopting vector notation, GNU Octave becomes a powerful tool for mathematicians, scientists and engineers, enabling them to express and solve complex problems more effectively and intuitively.",
        "subjects": [
            "cs.SE",
            "cs.CL"
        ],
        "comment": "22 pages, 1 figure (3 subfigures)"
    },
    {
        "paper id": "2410.19560",
        "abstract url": "https://arxiv.org/abs/2410.19560",
        "title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In recent advancements in unsupervised visual representation learning, the Joint-Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabeled imagery through an innovative masking strategy. Despite its success, two primary limitations have been identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPA in preventing entire collapse and the inadequacy of I-JEPA prediction in accurately learning the mean of patch representations. Addressing these challenges, this study introduces a novel framework, namely C-JEPA (Contrastive-JEPA), which integrates the Image-based Joint-Embedding Predictive Architecture with the Variance-Invariance-Covariance Regularization (VICReg) strategy. This integration is designed to effectively learn the variance/covariance for preventing entire collapse and ensuring invariance in the mean of augmented views, thereby overcoming the identified limitations. Through empirical and theoretical evaluations, our work demonstrates that C-JEPA significantly enhances the stability and quality of visual representation learning. When pre-trained on the ImageNet-1K dataset, C-JEPA exhibits rapid and improved convergence in both linear probing and fine-tuning performance metrics.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "eess.IV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19572",
        "abstract url": "https://arxiv.org/abs/2410.19572",
        "title": "ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-Augmented Generation (RAG) systems using large language models (LLMs) often generate inaccurate responses due to the retrieval of irrelevant or loosely related information. Existing methods, which operate at the document level, fail to effectively filter out such content. We propose LLM-driven chunk filtering, ChunkRAG, a framework that enhances RAG systems by evaluating and filtering retrieved information at the chunk level. Our approach employs semantic chunking to divide documents into coherent sections and utilizes LLM-based relevance scoring to assess each chunk's alignment with the user's query. By filtering out less pertinent chunks before the generation phase, we significantly reduce hallucinations and improve factual accuracy. Experiments show that our method outperforms existing RAG models, achieving higher accuracy on tasks requiring precise information retrieval. This advancement enhances the reliability of RAG systems, making them particularly beneficial for applications like fact-checking and multi-hop reasoning.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19595",
        "abstract url": "https://arxiv.org/abs/2410.19595",
        "title": "Mask-Weighted Spatial Likelihood Coding for Speaker-Independent Joint Localization and Mask Estimation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Due to their robustness and flexibility, neural-driven beamformers are a popular choice for speech separation in challenging environments with a varying amount of simultaneous speakers alongside noise and reverberation. Time-frequency masks and relative directions of the speakers regarding a fixed spatial grid can be used to estimate the beamformer's parameters. To some degree, speaker-independence is achieved by ensuring a greater amount of spatial partitions than speech sources. In this work, we analyze how to encode both mask and positioning into such a grid to enable joint estimation of both quantities. We propose mask-weighted spatial likelihood coding and show that it achieves considerable performance in both tasks compared to baseline encodings optimized for either localization or mask estimation. In the same setup, we demonstrate superiority for joint estimation of both quantities. Conclusively, we propose a universal approach which can replace an upstream sound source localization system solely by adapting the training framework, making it highly relevant in performance-critical scenarios.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "comment": "\u00a92024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works"
    },
    {
        "paper id": "2410.19642",
        "abstract url": "https://arxiv.org/abs/2410.19642",
        "title": "VARS: Vision-based Assessment of Risk in Security Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The accurate prediction of danger levels in video content is critical for enhancing safety and security systems, particularly in environments where quick and reliable assessments are essential. In this study, we perform a comparative analysis of various machine learning and deep learning models to predict danger ratings in a custom dataset of 100 videos, each containing 50 frames, annotated with human-rated danger scores ranging from 0 to 10. The danger ratings are further classified into three categories: no alert (less than 7)and high alert (greater than equal to 7). Our evaluation covers classical machine learning models, such as Support Vector Machines, as well as Neural Networks, and transformer-based models. Model performance is assessed using standard metrics such as accuracy, F1-score, and mean absolute error (MAE), and the results are compared to identify the most robust approach. This research contributes to developing a more accurate and generalizable danger assessment framework for video-based risk detection.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19692",
        "abstract url": "https://arxiv.org/abs/2410.19692",
        "title": "AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Generating diverse and effective clarifying questions is crucial for improving query understanding and retrieval performance in open-domain conversational search (CS) systems. We propose AGENT-CQ (Automatic GENeration, and evaluaTion of Clarifying Questions), an end-to-end LLM-based framework addressing the challenges of scalability and adaptability faced by existing methods that rely on manual curation or template-based approaches. AGENT-CQ consists of two stages: a generation stage employing LLM prompting strategies to generate clarifying questions, and an evaluation stage (CrowdLLM) that simulates human crowdsourcing judgments using multiple LLM instances to assess generated questions and answers based on comprehensive quality metrics. Extensive experiments on the ClariQ dataset demonstrate CrowdLLM's effectiveness in evaluating question and answer quality. Human evaluation and CrowdLLM show that the AGENT-CQ - generation stage, consistently outperforms baselines in various aspects of question and answer quality. In retrieval-based evaluation, LLM-generated questions significantly enhance retrieval effectiveness for both BM25 and cross-encoder models compared to human-generated questions.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "23 pages"
    },
    {
        "paper id": "2410.19702",
        "abstract url": "https://arxiv.org/abs/2410.19702",
        "title": "TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive performance in short video understanding. However, understanding long-form videos still remains challenging for MLLMs. This paper proposes TimeSuite, a collection of new designs to adapt the existing short-form video MLLMs for long video understanding, including a simple yet efficient framework to process long video sequence, a high-quality video dataset for grounded tuning of MLLMs, and a carefully-designed instruction tuning task to explicitly incorporate the grounding supervision in the traditional QA format. Specifically, based on VideoChat, we propose our long-video MLLM, coined as VideoChat-T, by implementing a token shuffling to compress long video tokens and introducing Temporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness of visual representation. Meanwhile, we introduce the TimePro, a comprehensive grounding-centric instruction tuning dataset composed of 9 tasks and 349k high-quality grounded annotations. Notably, we design a new instruction tuning task type, called Temporal Grounded Caption, to peform detailed video descriptions with the corresponding time stamps prediction. This explicit temporal location prediction will guide MLLM to correctly attend on the visual content when generating description, and thus reduce the hallucination risk caused by the LLMs. Experimental results demonstrate that our TimeSuite provides a successful solution to enhance the long video understanding capability of short-form MLLM, achieving improvement of 5.6% and 6.8% on the benchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-T exhibits robust zero-shot temporal grounding capabilities, significantly outperforming the existing state-of-the-art MLLMs. After fine-tuning, it performs on par with the traditional supervised expert models.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19720",
        "abstract url": "https://arxiv.org/abs/2410.19720",
        "title": "2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in Direct Preference Optimization (DPO) have significantly enhanced the alignment of Large Language Models (LLMs) with human preferences, owing to its simplicity and effectiveness. However, existing methods typically optimize a scalar score or ranking reward, thereby overlooking the multi-dimensional nature of human preferences. In this work, we propose to extend the preference of DPO to two dimensions: segments and aspects. We first introduce a 2D supervision dataset called HelpSteer-2D. For the segment dimension, we divide the response into sentences and assign scores to each segment. For the aspect dimension, we meticulously design several criteria covering the response quality rubrics. With the 2-dimensional signals as feedback, we develop a 2D-DPO framework, decomposing the overall objective into multi-segment and multi-aspect objectives. Extensive experiments on popular benchmarks demonstrate that 2D-DPO performs better than methods that optimize for scalar or 1-dimensional preferences.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "The first four authors contributed equally, 25 pages"
    },
    {
        "paper id": "2410.19735",
        "abstract url": "https://arxiv.org/abs/2410.19735",
        "title": "Model merging with SVD to tie the Knots",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent model merging methods demonstrate that the parameters of fully-finetuned models specializing in distinct tasks can be combined into one model capable of solving all tasks without retraining. Yet, this success does not transfer well when merging LoRA finetuned models. We study this phenomenon and observe that the weights of LoRA finetuned models showcase a lower degree of alignment compared to their fully-finetuned counterparts. We hypothesize that improving this alignment is key to obtaining better LoRA model merges, and propose KnOTS to address this problem. KnOTS uses the SVD to jointly transform the weights of different LoRA models into an aligned space, where existing merging methods can be applied. In addition, we introduce a new benchmark that explicitly evaluates whether merged models are general models. Notably, KnOTS consistently improves LoRA merging by up to 4.3% across several vision and language benchmarks, including our new setting. We release our code at: https://github.com/gstoica27/KnOTS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19899",
        "abstract url": "https://arxiv.org/abs/2410.19899",
        "title": "Exploring Self-Supervised Learning with U-Net Masked Autoencoders and EfficientNet B7 for Improved Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present a self-supervised U-Net-based masked autoencoder and noise removal model designed to reconstruct original images. Once adequately trained, this model extracts high-level features, which are then combined with features from the EfficientNet B7 model. These integrated features are subsequently fed into dense layers for classification. Among the approaches of masked input and Gaussian noise removal, we selected the best U-Net reconstruction model. Additionally, we explored various configurations, including EfficientNet with attention, attention fusion of the autoencoder, and classification utilizing U-Net encoder features. The best performance was achieved with EfficientNet B7 combined with U-Net encoder features. We employed the Adam optimizer with a learning rate of 0.0001, achieving a top accuracy of 0.94 on the validation set.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Capsule Vision 2024 Challenge"
    },
    {
        "paper id": "2410.19974",
        "abstract url": "https://arxiv.org/abs/2410.19974",
        "title": "Evaluating Cost-Accuracy Trade-offs in Multimodal Search Relevance Judgements",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated potential as effective search relevance evaluators. However, there is a lack of comprehensive guidance on which models consistently perform optimally across various contexts or within specific use cases. In this paper, we assess several LLMs and Multimodal Language Models (MLLMs) in terms of their alignment with human judgments across multiple multimodal search scenarios. Our analysis investigates the trade-offs between cost and accuracy, highlighting that model performance varies significantly depending on the context. Interestingly, in smaller models, the inclusion of a visual component may hinder performance rather than enhance it. These findings highlight the complexities involved in selecting the most appropriate model for practical applications.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20007",
        "abstract url": "https://arxiv.org/abs/2410.20007",
        "title": "Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Enhancing the reasoning capabilities of large language models (LLMs) is crucial for enabling them to tackle complex, multi-step problems. Multi-agent frameworks have shown great potential in enhancing LLMs' reasoning capabilities. However, the lack of effective cooperation between LLM agents hinders their performance, especially for multi-step reasoning tasks. This paper proposes a novel cooperative multi-agent reasoning framework (CoPlanner) by separating reasoning steps and assigning distinct duties to different agents. CoPlanner consists of two LLM agents: a planning agent and a reasoning agent. The planning agent provides high-level strategic hints, while the reasoning agent follows these hints and infers answers. By training the planning agent's policy through the interactive reasoning process via Proximal Policy Optimization (PPO), the LLaMA-3-8B-based CoPlanner outperforms the previous best method by 9.94\\% on LogiQA and 3.09\\% on BBH. Our results demonstrate that the guidance from the planning agent and the effective cooperation between the agents contribute to the superior performance of CoPlanner in tackling multi-step reasoning problems.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Working in progress"
    },
    {
        "paper id": "2410.20011",
        "abstract url": "https://arxiv.org/abs/2410.20011",
        "title": "A Survey of Small Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Small Language Models (SLMs) have become increasingly important due to their efficiency and performance to perform various language tasks with minimal computational resources, making them ideal for various settings including on-device, mobile, edge devices, among many others. In this article, we present a comprehensive survey on SLMs, focusing on their architectures, training techniques, and model compression techniques. We propose a novel taxonomy for categorizing the methods used to optimize SLMs, including model compression, pruning, and quantization techniques. We summarize the benchmark datasets that are useful for benchmarking SLMs along with the evaluation metrics commonly used. Additionally, we highlight key open challenges that remain to be addressed. Our survey aims to serve as a valuable resource for researchers and practitioners interested in developing and deploying small yet efficient language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20016",
        "abstract url": "https://arxiv.org/abs/2410.20016",
        "title": "Vulnerability of LLMs to Vertically Aligned Text Manipulations",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Text classification involves categorizing a given text, such as determining its sentiment or identifying harmful content. With the advancement of large language models (LLMs), these models have become highly effective at performing text classification tasks. However, they still show vulnerabilities to variations in text formatting. Recent research demonstrates that modifying input formats, such as vertically aligning words for encoder-based models, can substantially lower accuracy in text classification tasks. While easily understood by humans, these inputs can significantly mislead models, posing a potential risk of bypassing detection in real-world scenarios involving harmful or sensitive information. With the expanding application of LLMs, a crucial question arises: Do decoder-based LLMs exhibit similar vulnerabilities to vertically formatted text input? In this paper, we investigate the impact of vertical text input on the performance of various LLMs across multiple text classification datasets and analyze the underlying causes. Our findings are as follows: (i) Vertical text input significantly degrades the accuracy of LLMs in text classification tasks. (ii) Chain of Thought (CoT) reasoning does not help LLMs recognize vertical input or mitigate its vulnerability, but few-shot learning with careful analysis does. (iii) We explore the underlying cause of the vulnerability by analyzing the inherent issues in tokenization and attention matrices.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20021",
        "abstract url": "https://arxiv.org/abs/2410.20021",
        "title": "Think Carefully and Check Again! Meta-Generation Unlocking LLMs for Low-Resource Cross-Lingual Summarization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Cross-lingual summarization (CLS) aims to generate a summary for the source text in a different target language. Currently, instruction-tuned large language models (LLMs) excel at various English tasks. However, unlike languages such as English, Chinese or Spanish, for those relatively low-resource languages with limited usage or data, recent studies have shown that LLMs' performance on CLS tasks remains unsatisfactory even with few-shot settings. This raises the question: Are LLMs capable of handling cross-lingual summarization tasks for low-resource languages? To resolve this question, we fully explore the potential of large language models on cross-lingual summarization task for low-resource languages through our four-step zero-shot method: Summarization, Improvement, Translation and Refinement (SITR) with correspondingly designed prompts. We test our proposed method with multiple LLMs on two well-known cross-lingual summarization datasets with various low-resource target languages. The results show that: i) GPT-3.5 and GPT-4 significantly and consistently outperform other baselines when using our zero-shot SITR methods. ii) By employing our proposed method, we unlock the potential of LLMs, enabling them to effectively handle cross-lingual summarization tasks for relatively low-resource languages.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20022",
        "abstract url": "https://arxiv.org/abs/2410.20022",
        "title": "Dynamic layer selection in decoder-only transformers",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The vast size of Large Language Models (LLMs) has prompted a search to optimize inference. One effective approach is dynamic inference, which adapts the architecture to the sample-at-hand to reduce the overall computational cost. We empirically examine two common dynamic inference methods for natural language generation (NLG): layer skipping and early exiting. We find that a pre-trained decoder-only model is significantly more robust to layer removal via layer skipping, as opposed to early exit. We demonstrate the difficulty of using hidden state information to adapt computation on a per-token basis for layer skipping. Finally, we show that dynamic computation allocation on a per-sequence basis holds promise for significant efficiency gains by constructing an oracle controller. Remarkably, we find that there exists an allocation which achieves equal performance to the full model using only 23.3% of its layers on average.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20024",
        "abstract url": "https://arxiv.org/abs/2410.20024",
        "title": "Beyond Fine-Tuning: Effective Strategies for Mitigating Hallucinations in Large Language Models for Data Analytics",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have become increasingly important in natural language processing, enabling advanced data analytics through natural language queries. However, these models often generate \"hallucinations\"-inaccurate or fabricated information-that can undermine their reliability in critical data-driven decision-making. Addressing the challenge of hallucinations is essential to improve the accuracy and trustworthiness of LLMs in processing natural language queries. This research focuses on mitigating hallucinations in LLMs, specifically within the context of data analytics. We introduce and evaluate four targeted strategies: Structured Output Generation, Strict Rules Enforcement, System Prompt Enhancements, and Semantic Layer Integration. Our findings show that these methods are more effective than traditional fine-tuning approaches in reducing hallucinations, offering a more reliable framework for deploying LLMs in natural language queries for data analytics. This research demonstrates the potential of these strategies to enhance the accuracy of LLM-driven data queries, ensuring more dependable results in data-driven environments.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20035",
        "abstract url": "https://arxiv.org/abs/2410.20035",
        "title": "Training the Untrainable: Introducing Inductive Bias via Representational Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We demonstrate that architectures which traditionally are considered to be ill-suited for a task can be trained using inductive biases from another architecture. Networks are considered untrainable when they overfit, underfit, or converge to poor results even when tuning their hyperparameters. For example, plain fully connected networks overfit on object recognition while deep convolutional networks without residual connections underfit. The traditional answer is to change the architecture to impose some inductive bias, although what that bias is remains unknown. We introduce guidance, where a guide network guides a target network using a neural distance function. The target is optimized to perform well and to match its internal representations, layer-by-layer, to those of the guide; the guide is unchanged. If the guide is trained, this transfers over part of the architectural prior and knowledge of the guide to the target. If the guide is untrained, this transfers over only part of the architectural prior of the guide. In this manner, we can investigate what kinds of priors different architectures place on untrainable networks such as fully connected networks. We demonstrate that this method overcomes the immediate overfitting of fully connected networks on vision tasks, makes plain CNNs competitive to ResNets, closes much of the gap between plain vanilla RNNs and Transformers, and can even help Transformers learn tasks which RNNs can perform more easily. We also discover evidence that better initializations of fully connected networks likely exist to avoid overfitting. Our method provides a mathematical tool to investigate priors and architectures, and in the long term, may demystify the dark art of architecture creation, even perhaps turning architectures into a continuous optimizable parameter of the network.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Under Review; 24 pages, 9 figures; Project page and code is at https://untrainable-networks.github.io/"
    },
    {
        "paper id": "2410.20036",
        "abstract url": "https://arxiv.org/abs/2410.20036",
        "title": "Architectural Flaw Detection in Civil Engineering Using GPT-4",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The application of artificial intelligence (AI) in civil engineering presents a transformative approach to enhancing design quality and safety. This paper investigates the potential of the advanced LLM GPT4 Turbo vision model in detecting architectural flaws during the design phase, with a specific focus on identifying missing doors and windows. The study evaluates the model's performance through metrics such as precision, recall, and F1 score, demonstrating AI's effectiveness in accurately detecting flaws compared to human-verified data. Additionally, the research explores AI's broader capabilities, including identifying load-bearing issues, material weaknesses, and ensuring compliance with building codes. The findings highlight how AI can significantly improve design accuracy, reduce costly revisions, and support sustainable practices, ultimately revolutionizing the civil engineering field by ensuring safer, more efficient, and aesthetically optimized structures.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20056",
        "abstract url": "https://arxiv.org/abs/2410.20056",
        "title": "Multi-Field Adaptive Retrieval",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Document retrieval for tasks such as search and retrieval-augmented generation typically involves datasets that are unstructured: free-form text without explicit internal structure in each document. However, documents can have a structured form, consisting of fields such as an article title, message body, or HTML header. To address this gap, we introduce Multi-Field Adaptive Retrieval (MFAR), a flexible framework that accommodates any number of and any type of document indices on structured data. Our framework consists of two main steps: (1) the decomposition of an existing document into fields, each indexed independently through dense and lexical methods, and (2) learning a model which adaptively predicts the importance of a field by conditioning on the document query, allowing on-the-fly weighting of the most likely field(s). We find that our approach allows for the optimized use of dense versus lexical representations across field types, significantly improves in document ranking over a number of existing retrievers, and achieves state-of-the-art performance for multi-field structured data.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.21276",
        "abstract url": "https://arxiv.org/abs/2410.21276",
        "title": "GPT-4o System Card",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY",
                "cs.CV",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "GPT-4o is an autoregressive omni model that accepts as input any combination of text, audio, image, and video, and generates any combination of text, audio, and image outputs. It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network. GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation. It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50\\% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models. In line with our commitment to building AI safely and consistent with our voluntary commitments to the White House, we are sharing the GPT-4o System Card, which includes our Preparedness Framework evaluations. In this System Card, we provide a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures we've implemented to ensure the model is safe and aligned. We also include third-party assessments on dangerous capabilities, as well as discussion of potential societal impacts of GPT-4o's text and vision capabilities.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.CY",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.21308",
        "abstract url": "https://arxiv.org/abs/2410.21308",
        "title": "A Robust Anchor-based Method for Multi-Camera Pedestrian Localization",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This paper addresses the problem of vision-based pedestrian localization, which estimates a pedestrian's location using images and camera parameters. In practice, however, calibrated camera parameters often deviate from the ground truth, leading to inaccuracies in localization. To address this issue, we propose an anchor-based method that leverages fixed-position anchors to reduce the impact of camera parameter errors. We provide a theoretical analysis that demonstrates the robustness of our approach. Experiments conducted on simulated, real-world, and public datasets show that our method significantly improves localization accuracy and remains resilient to noise in camera parameters, compared to methods without anchors.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.21317",
        "abstract url": "https://arxiv.org/abs/2410.21317",
        "title": "MatExpert: Decomposing Materials Discovery by Mimicking Human Experts",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Material discovery is a critical research area with profound implications for various industries. In this work, we introduce MatExpert, a novel framework that leverages Large Language Models (LLMs) and contrastive learning to accelerate the discovery and design of new solid-state materials. Inspired by the workflow of human materials design experts, our approach integrates three key stages: retrieval, transition, and generation. First, in the retrieval stage, MatExpert identifies an existing material that closely matches the desired criteria. Second, in the transition stage, MatExpert outlines the necessary modifications to transform this material formulation to meet specific requirements outlined by the initial user query. Third, in the generation state, MatExpert performs detailed computations and structural generation to create new materials based on the provided information. Our experimental results demonstrate that MatExpert outperforms state-of-the-art methods in material generation tasks, achieving superior performance across various metrics including validity, distribution, and stability. As such, MatExpert represents a meaningful advancement in computational material discovery using langauge-based generative models.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.21318",
        "abstract url": "https://arxiv.org/abs/2410.21318",
        "title": "Multi-path Exploration and Feedback Adjustment for Text-to-Image Person Retrieval",
        "rating": "1",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Text-to-Image"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Text-based person retrieval aims to identify the specific persons using textual descriptions as queries. Existing ad vanced methods typically depend on vision-language pre trained (VLP) models to facilitate effective cross-modal alignment. However, the inherent constraints of VLP mod-els, which include the global alignment biases and insuffi-cient self-feedback regulation, impede optimal retrieval per formance. In this paper, we propose MeFa, a Multi-Pathway Exploration, Feedback, and Adjustment framework, which deeply explores intrinsic feedback of intra and inter-modal to make targeted adjustment, thereby achieving more precise person-text associations. Specifically, we first design an intra modal reasoning pathway that generates hard negative sam ples for cross-modal data, leveraging feedback from these samples to refine intra-modal reasoning, thereby enhancing sensitivity to subtle discrepancies. Subsequently, we intro duce a cross-modal refinement pathway that utilizes both global information and intermodal feedback to refine local in formation, thus enhancing its global semantic representation. Finally, the discriminative clue correction pathway incorpo rates fine-grained features of secondary similarity as discrim inative clues to further mitigate retrieval failures caused by disparities in these features. Experimental results on three public benchmarks demonstrate that MeFa achieves superior person retrieval performance without necessitating additional data or complex structures.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19352",
        "abstract url": "https://arxiv.org/abs/2410.19352",
        "title": "Interpreting Neural Networks through Mahalanobis Distance",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces a theoretical framework that connects neural network linear layers with the Mahalanobis distance, offering a new perspective on neural network interpretability. While previous studies have explored activation functions primarily for performance optimization, our work interprets these functions through statistical distance measures, a less explored area in neural network research. By establishing this connection, we provide a foundation for developing more interpretable neural network models, which is crucial for applications requiring transparency. Although this work is theoretical and does not include empirical data, the proposed distance-based interpretation has the potential to enhance model robustness, improve generalization, and provide more intuitive explanations of neural network decisions.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "11 pages, October 2024"
    },
    {
        "paper id": "2410.19356",
        "abstract url": "https://arxiv.org/abs/2410.19356",
        "title": "FeBiM: Efficient and Compact Bayesian Inference Engine Empowered with Ferroelectric In-Memory Computing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In scenarios with limited training data or where explainability is crucial, conventional neural network-based machine learning models often face challenges. In contrast, Bayesian inference-based algorithms excel in providing interpretable predictions and reliable uncertainty estimation in these scenarios. While many state-of-the-art in-memory computing (IMC) architectures leverage emerging non-volatile memory (NVM) technologies to offer unparalleled computing capacity and energy efficiency for neural network workloads, their application in Bayesian inference is limited. This is because the core operations in Bayesian inference differ significantly from the multiplication-accumulation (MAC) operations common in neural networks, rendering them generally unsuitable for direct implementation in most existing IMC designs. In this paper, we propose FeBiM, an efficient and compact Bayesian inference engine powered by multi-bit ferroelectric field-effect transistor (FeFET)-based IMC. FeBiM effectively encodes the trained probabilities of a Bayesian inference model within a compact FeFET-based crossbar. It maps quantized logarithmic probabilities to discrete FeFET states. As a result, the accumulated outputs of the crossbar naturally represent the posterior probabilities, i.e., the Bayesian inference model's output given a set of observations. This approach enables efficient in-memory Bayesian inference without the need for additional calculation circuitry. As the first FeFET-based in-memory Bayesian inference engine, FeBiM achieves an impressive storage density of 26.32 Mb/mm$^{2}$ and a computing efficiency of 581.40 TOPS/W in a representative Bayesian classification task. These results demonstrate 10.7$\\times$/43.4$\\times$ improvement in compactness/efficiency compared to the state-of-the-art hardware implementation of Bayesian inference.",
        "subjects": [
            "cs.LG",
            "cs.ET"
        ],
        "comment": "6 pages, 8 figures, to be published in the 61st DAC (Design Automation Conference) proceedings"
    },
    {
        "paper id": "2410.19360",
        "abstract url": "https://arxiv.org/abs/2410.19360",
        "title": "LArctan-SKAN: Simple and Efficient Single-Parameterized Kolmogorov-Arnold Networks using Learnable Trigonometric Function",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper proposes a novel approach for designing Single-Parameterized Kolmogorov-Arnold Networks (SKAN) by utilizing a Single-Parameterized Function (SFunc) constructed from trigonometric functions. Three new SKAN variants are developed: LSin-SKAN, LCos-SKAN, and LArctan-SKAN. Experimental validation on the MNIST dataset demonstrates that LArctan-SKAN excels in both accuracy and computational efficiency. Specifically, LArctan-SKAN significantly improves test set accuracy over existing models, outperforming all pure KAN variants compared, including FourierKAN, LSS-SKAN, and Spl-KAN. It also surpasses mixed MLP-based models such as MLP+rKAN and MLP+fKAN in accuracy. Furthermore, LArctan-SKAN exhibits remarkable computational efficiency, with a training speed increase of 535.01% and 49.55% compared to MLP+rKAN and MLP+fKAN, respectively. These results confirm the effectiveness and potential of SKANs constructed with trigonometric functions. The experiment code is available at https://github.com/chikkkit/LArctan-SKAN .",
        "subjects": [
            "cs.AI"
        ],
        "comment": "7 pages, 3 figures, experiment code is available at https://github.com/chikkkit/LArctan-SKAN"
    },
    {
        "paper id": "2410.19361",
        "abstract url": "https://arxiv.org/abs/2410.19361",
        "title": "Engineering Trustworthy AI: A Developer Guide for Empirical Risk Minimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "AI systems increasingly shape critical decisions across personal and societal domains. While empirical risk minimization (ERM) drives much of the AI success, it typically prioritizes accuracy over trustworthiness, often resulting in biases, opacity, and other adverse effects. This paper discusses how key requirements for trustworthy AI can be translated into design choices for the components of ERM. We hope to provide actionable guidance for building AI systems that meet emerging standards for trustworthiness of AI.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19367",
        "abstract url": "https://arxiv.org/abs/2410.19367",
        "title": "BitPipe: Bidirectional Interleaved Pipeline Parallelism for Accelerating Large Models Training",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "With the increasing scale of models, the need for efficient distributed training has become increasingly urgent. Recently, many synchronous pipeline parallelism approaches have been proposed to improve training throughput. However, these approaches still suffer from two major issues, i.e., pipeline bubbles caused by periodic flushing and extra communication due to the increasing number of pipeline stages. To this end, we propose BitPipe, a bidirectional interleaved pipeline parallelism for accelerating large models training. Specifically, a hybrid scheme of fusing interleaved pipelines with bidirectional pipelines is proposed to reduce the computational time of each single micro-batch and multiply the number of devices executing simultaneously. A V-shaped schedule with eager gradient synchronization is introduced to reduce and overlap the communication between devices. Experiments conducted on up to 32 GPUs show that BitPipe improves the training throughput of GPT-style and BERT-style models by 1.05x-1.28x compared to the state-of-the-art synchronous approaches. The code of our implementation is available at https://github.com/wuhouming/BitPipe.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "10 pages, 13 figures"
    },
    {
        "paper id": "2410.19370",
        "abstract url": "https://arxiv.org/abs/2410.19370",
        "title": "Notes on the Mathematical Structure of GPT LLM Architectures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "An exposition of the mathematics underpinning the neural network architecture of a GPT-3-style LLM.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2410.19371",
        "abstract url": "https://arxiv.org/abs/2410.19371",
        "title": "Noise-Aware Differentially Private Variational Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Differential privacy (DP) provides robust privacy guarantees for statistical inference, but this can lead to unreliable results and biases in downstream applications. While several noise-aware approaches have been proposed which integrate DP perturbation into the inference, they are limited to specific types of simple probabilistic models. In this work, we propose a novel method for noise-aware approximate Bayesian inference based on stochastic gradient variational inference which can also be applied to high-dimensional and non-conjugate models. We also propose a more accurate evaluation method for noise-aware posteriors. Empirically, our inference method has similar performance to existing methods in the domain where they are applicable. Outside this domain, we obtain accurate coverages on high-dimensional Bayesian linear regression and well-calibrated predictive probabilities on Bayesian logistic regression with the UCI Adult dataset.",
        "subjects": [
            "stat.ML",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19372",
        "abstract url": "https://arxiv.org/abs/2410.19372",
        "title": "Toward Finding Strong Pareto Optimal Policies in Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we study the problem of finding Pareto optimal policies in multi-agent reinforcement learning problems with cooperative reward structures. We show that any algorithm where each agent only optimizes their reward is subject to suboptimal convergence. Therefore, to achieve Pareto optimality, agents have to act altruistically by considering the rewards of others. This observation bridges the multi-objective optimization framework and multi-agent reinforcement learning together. We first propose a framework for applying the Multiple Gradient Descent algorithm (MGDA) for learning in multi-agent settings. We further show that standard MGDA is subjected to weak Pareto convergence, a problem that is often overlooked in other learning settings but is prevalent in multi-agent reinforcement learning. To mitigate this issue, we propose MGDA++, an improvement of the existing algorithm to handle the weakly optimal convergence of MGDA properly. Theoretically, we prove that MGDA++ converges to strong Pareto optimal solutions in convex, smooth bi-objective problems. We further demonstrate the superiority of our MGDA++ in cooperative settings in the Gridworld benchmark. The results highlight that our proposed method can converge efficiently and outperform the other methods in terms of the optimality of the convergent policies. The source code is available at \\url{https://github.com/giangbang/Strong-Pareto-MARL}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submitted to ACML 2024 Special Issue Journal track"
    },
    {
        "paper id": "2410.19382",
        "abstract url": "https://arxiv.org/abs/2410.19382",
        "title": "Multi-Agent Reinforcement Learning with Selective State-Space Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The Transformer model has demonstrated success across a wide range of domains, including in Multi-Agent Reinforcement Learning (MARL) where the Multi-Agent Transformer (MAT) has emerged as a leading algorithm in the field. However, a significant drawback of Transformer models is their quadratic computational complexity relative to input size, making them computationally expensive when scaling to larger inputs. This limitation restricts MAT's scalability in environments with many agents. Recently, State-Space Models (SSMs) have gained attention due to their computational efficiency, but their application in MARL remains unexplored. In this work, we investigate the use of Mamba, a recent SSM, in MARL and assess whether it can match the performance of MAT while providing significant improvements in efficiency. We introduce a modified version of MAT that incorporates standard and bi-directional Mamba blocks, as well as a novel \"cross-attention\" Mamba block. Extensive testing shows that our Multi-Agent Mamba (MAM) matches the performance of MAT across multiple standard multi-agent environments, while offering superior scalability to larger agent scenarios. This is significant for the MARL community, because it indicates that SSMs could replace Transformers without compromising performance, whilst also supporting more effective scaling to higher numbers of agents. Our project page is available at https://sites.google.com/view/multi-agent-mamba .",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "17 pages, 7 figures"
    },
    {
        "paper id": "2410.19384",
        "abstract url": "https://arxiv.org/abs/2410.19384",
        "title": "Learning Neural Strategy-Proof Matching Mechanism from Examples",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Designing effective two-sided matching mechanisms is a major problem in mechanism design, and the goodness of matching cannot always be formulated. The existing work addresses this issue by searching over a parameterized family of mechanisms with certain properties by learning to fit a human-crafted dataset containing examples of preference profiles and matching results. However, this approach does not consider a strategy-proof mechanism, implicitly assumes the number of agents to be a constant, and does not consider the public contextual information of the agents. In this paper, we propose a new parametric family of strategy-proof matching mechanisms by extending the serial dictatorship (SD). We develop a novel attention-based neural network called NeuralSD, which can learn a strategy-proof mechanism from a human-crafted dataset containing public contextual information. NeuralSD is constructed by tensor operations that make SD differentiable and learns a parameterized mechanism by estimating an order of SD from the contextual information. We conducted experiments to learn a strategy-proof matching from matching examples with different numbers of agents. We demonstrated that our method shows the superiority of learning with context-awareness over a baseline in terms of regression performance and other metrics.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19390",
        "abstract url": "https://arxiv.org/abs/2410.19390",
        "title": "CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Obtaining well-calibrated photometric redshift probability densities for galaxies without a spectroscopic measurement remains a challenge. Deep learning discriminative models, typically fed with multi-band galaxy images, can produce outputs that mimic probability densities and achieve state-of-the-art accuracy. However, such models may be affected by miscalibration that would result in discrepancies between the model outputs and the actual distributions of true redshifts. Our work develops a novel method called the Contrastive Learning and Adaptive KNN for Photometric Redshift (CLAP) that resolves this issue. It leverages supervised contrastive learning (SCL) and k-nearest neighbours (KNN) to construct and calibrate raw probability density estimates, and implements a refitting procedure to resume end-to-end discriminative models ready to produce final estimates for large-scale imaging data. The harmonic mean is adopted to combine an ensemble of estimates from multiple realisations for improving accuracy. Our experiments demonstrate that CLAP takes advantage of both deep learning and KNN, outperforming benchmark methods on the calibration of probability density estimates and retaining high accuracy and computational efficiency. With reference to CLAP, we point out that miscalibration is particularly sensitive to the method-induced excessive correlations among data instances in addition to the unaccounted-for epistemic uncertainties. Reducing the uncertainties may not guarantee the removal of miscalibration due to the presence of such excessive correlations, yet this is a problem for conventional deep learning methods rather than CLAP. These discussions underscore the robustness of CLAP for obtaining photometric redshift probability densities required by astrophysical and cosmological applications. This is the first paper in our series on CLAP.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.CO",
            "cs.AI"
        ],
        "comment": "22 + 6 pages, 9 + 5 figures"
    },
    {
        "paper id": "2410.19394",
        "abstract url": "https://arxiv.org/abs/2410.19394",
        "title": "Analysis of Financial Risk Behavior Prediction Using Deep Learning and Big Data Algorithms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "As the complexity and dynamism of financial markets continue to grow, traditional financial risk prediction methods increasingly struggle to handle large datasets and intricate behavior patterns. This paper explores the feasibility and effectiveness of using deep learning and big data algorithms for financial risk behavior prediction. First, the application and advantages of deep learning and big data algorithms in the financial field are analyzed. Then, a deep learning-based big data risk prediction framework is designed and experimentally validated on actual financial datasets. The experimental results show that this method significantly improves the accuracy of financial risk behavior prediction and provides valuable support for risk management in financial institutions. Challenges in the application of deep learning are also discussed, along with potential directions for future research.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19406",
        "abstract url": "https://arxiv.org/abs/2410.19406",
        "title": "An Auditing Test To Detect Behavioral Shift in Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As language models (LMs) approach human-level performance, a comprehensive understanding of their behavior becomes crucial. This includes evaluating capabilities, biases, task performance, and alignment with societal values. Extensive initial evaluations, including red teaming and diverse benchmarking, can establish a model's behavioral profile. However, subsequent fine-tuning or deployment modifications may alter these behaviors in unintended ways. We present a method for continual Behavioral Shift Auditing (BSA) in LMs. Building on recent work in hypothesis testing, our auditing test detects behavioral shifts solely through model generations. Our test compares model generations from a baseline model to those of the model under scrutiny and provides theoretical guarantees for change detection while controlling false positives. The test features a configurable tolerance parameter that adjusts sensitivity to behavioral changes for different use cases. We evaluate our approach using two case studies: monitoring changes in (a) toxicity and (b) translation performance. We find that the test is able to detect meaningful changes in behavior distributions using just hundreds of examples.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "25 pages, 12 figures"
    },
    {
        "paper id": "2410.19426",
        "abstract url": "https://arxiv.org/abs/2410.19426",
        "title": "Analyzing Generative Models by Manifold Entropic Metrics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Good generative models should not only synthesize high quality data, but also utilize interpretable representations that aid human understanding of their behavior. However, it is difficult to measure objectively if and to what degree desirable properties of disentangled representations have been achieved. Inspired by the principle of independent mechanisms, we address this difficulty by introducing a novel set of tractable information-theoretic evaluation metrics. We demonstrate the usefulness of our metrics on illustrative toy examples and conduct an in-depth comparison of various normalizing flow architectures and $\u03b2$-VAEs on the EMNIST dataset. Our method allows to sort latent features by importance and assess the amount of residual correlations of the resulting concepts. The most interesting finding of our experiments is a ranking of model architectures and training procedures in terms of their inductive bias to converge to aligned and disentangled representations during training.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19448",
        "abstract url": "https://arxiv.org/abs/2410.19448",
        "title": "Gradient Descent Efficiency Index",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Gradient descent is a widely used iterative algorithm for finding local minima in multivariate functions. However, the final iterations often either overshoot the minima or make minimal progress, making it challenging to determine an optimal stopping point. This study introduces a new efficiency metric, Ek, designed to quantify the effectiveness of each iteration. The proposed metric accounts for both the relative change in error and the stability of the loss function across iterations. This measure is particularly valuable in resource-constrained environments, where costs are closely tied to training time. Experimental validation across multiple datasets and models demonstrates that Ek provides valuable insights into the convergence behavior of gradient descent, complementing traditional performance metrics. The index has the potential to guide more informed decisions in the selection and tuning of optimization algorithms in machine learning applications and be used to compare the \"effectiveness\" of models relative to each other.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": "12 Pages, 3 Figures"
    },
    {
        "paper id": "2410.19450",
        "abstract url": "https://arxiv.org/abs/2410.19450",
        "title": "Offline-to-Online Multi-Agent Reinforcement Learning with Offline Value Function Memory and Sequential Exploration",
        "rating": "0.5",
        "keywords": [
            [
                "efficient fine-tuning"
            ],
            [
                "unlearning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Offline-to-Online Reinforcement Learning has emerged as a powerful paradigm, leveraging offline data for initialization and online fine-tuning to enhance both sample efficiency and performance. However, most existing research has focused on single-agent settings, with limited exploration of the multi-agent extension, i.e., Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL). In O2O MARL, two critical challenges become more prominent as the number of agents increases: (i) the risk of unlearning pre-trained Q-values due to distributional shifts during the transition from offline-to-online phases, and (ii) the difficulty of efficient exploration in the large joint state-action space. To tackle these challenges, we propose a novel O2O MARL framework called Offline Value Function Memory with Sequential Exploration (OVMSE). First, we introduce the Offline Value Function Memory (OVM) mechanism to compute target Q-values, preserving knowledge gained during offline training, ensuring smoother transitions, and enabling efficient fine-tuning. Second, we propose a decentralized Sequential Exploration (SE) strategy tailored for O2O MARL, which effectively utilizes the pre-trained offline policy for exploration, thereby significantly reducing the joint state-action space to be explored. Extensive experiments on the StarCraft Multi-Agent Challenge (SMAC) demonstrate that OVMSE significantly outperforms existing baselines, achieving superior sample efficiency and overall performance.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19456",
        "abstract url": "https://arxiv.org/abs/2410.19456",
        "title": "Computational Bottlenecks of Training Small-scale Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "While large language models (LLMs) dominate the AI landscape, Small-scale large Language Models (SLMs) are gaining attention due to cost and efficiency demands from consumers. However, there is limited research on the training behavior and computational requirements of SLMs. In this study, we explore the computational bottlenecks of training SLMs (up to 2B parameters) by examining the effects of various hyperparameters and configurations, including GPU type, batch size, model size, communication protocol, attention type, and the number of GPUs. We assess these factors on popular cloud services using metrics such as loss per dollar and tokens per second. Our findings aim to support the broader adoption and optimization of language model training for low-resource AI research institutes.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2410.19469",
        "abstract url": "https://arxiv.org/abs/2410.19469",
        "title": "Unified Causality Analysis Based on the Degrees of Freedom",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Temporally evolving systems are typically modeled by dynamic equations. A key challenge in accurate modeling is understanding the causal relationships between subsystems, as well as identifying the presence and influence of unobserved hidden drivers on the observed dynamics. This paper presents a unified method capable of identifying fundamental causal relationships between pairs of systems, whether deterministic or stochastic. Notably, the method also uncovers hidden common causes beyond the observed variables. By analyzing the degrees of freedom in the system, our approach provides a more comprehensive understanding of both causal influence and hidden confounders. This unified framework is validated through theoretical models and simulations, demonstrating its robustness and potential for broader application.",
        "subjects": [
            "stat.ME",
            "cs.AI",
            "cs.LG",
            "econ.EM",
            "math-ph"
        ],
        "comment": "32 pages, 7 figures"
    },
    {
        "paper id": "2410.19471",
        "abstract url": "https://arxiv.org/abs/2410.19471",
        "title": "Improving Inverse Folding for Peptide Design with Diversity-regularized Direct Preference Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Inverse folding models play an important role in structure-based design by predicting amino acid sequences that fold into desired reference structures. Models like ProteinMPNN, a message-passing encoder-decoder model, are trained to reliably produce new sequences from a reference structure. However, when applied to peptides, these models are prone to generating repetitive sequences that do not fold into the reference structure. To address this, we fine-tune ProteinMPNN to produce diverse and structurally consistent peptide sequences via Direct Preference Optimization (DPO). We derive two enhancements to DPO: online diversity regularization and domain-specific priors. Additionally, we develop a new understanding on improving diversity in decoder models. When conditioned on OpenFold generated structures, our fine-tuned models achieve state-of-the-art structural similarity scores, improving base ProteinMPNN by at least 8%. Compared to standard DPO, our regularized method achieves up to 20% higher sequence diversity with no loss in structural similarity score.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Preprint. 10 pages plus appendices"
    },
    {
        "paper id": "2410.19482",
        "abstract url": "https://arxiv.org/abs/2410.19482",
        "title": "Measuring memorization through probabilistic discoverable extraction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs) are susceptible to memorizing training data, raising concerns due to the potential extraction of sensitive information. Current methods to measure memorization rates of LLMs, primarily discoverable extraction (Carlini et al., 2022), rely on single-sequence greedy sampling, potentially underestimating the true extent of memorization. This paper introduces a probabilistic relaxation of discoverable extraction that quantifies the probability of extracting a target sequence within a set of generated samples, considering various sampling schemes and multiple attempts. This approach addresses the limitations of reporting memorization rates through discoverable extraction by accounting for the probabilistic nature of LLMs and user interaction patterns. Our experiments demonstrate that this probabilistic measure can reveal cases of higher memorization rates compared to rates found through discoverable extraction. We further investigate the impact of different sampling schemes on extractability, providing a more comprehensive and realistic assessment of LLM memorization and its associated risks. Our contributions include a new probabilistic memorization definition, empirical evidence of its effectiveness, and a thorough evaluation across different models, sizes, sampling schemes, and training data repetitions.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19483",
        "abstract url": "https://arxiv.org/abs/2410.19483",
        "title": "Content-Aware Radiance Fields: Aligning Model Complexity with Scene Intricacy Through Learned Bitwidth Quantization",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "The recent popular radiance field models, exemplified by Neural Radiance Fields (NeRF), Instant-NGP and 3D Gaussian Splatting, are designed to represent 3D content by that training models for each individual scene. This unique characteristic of scene representation and per-scene training distinguishes radiance field models from other neural models, because complex scenes necessitate models with higher representational capacity and vice versa. In this paper, we propose content-aware radiance fields, aligning the model complexity with the scene intricacies through Adversarial Content-Aware Quantization (A-CAQ). Specifically, we make the bitwidth of parameters differentiable and trainable, tailored to the unique characteristics of specific scenes and requirements. The proposed framework has been assessed on Instant-NGP, a well-known NeRF variant and evaluated using various datasets. Experimental results demonstrate a notable reduction in computational complexity, while preserving the requisite reconstruction and rendering quality, making it beneficial for practical deployment of radiance fields models. Codes are available at https://github.com/WeihangLiu2024/Content_Aware_NeRF.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "accepted by ECCV2024"
    },
    {
        "paper id": "2410.19495",
        "abstract url": "https://arxiv.org/abs/2410.19495",
        "title": "Beyond One Solution: The Case for a Comprehensive Exploration of Solution Space in Community Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "This article explores the importance of examining the solution space in community detection, highlighting its role in achieving reliable results when dealing with real-world problems. A Bayesian framework is used to estimate the stability of the solution space and classify it into categories Single, Dominant, Multiple, Sparse or Empty. By applying this approach to real-world networks, the study highlights the importance of considering multiple solutions rather than relying on a single partition. This ensures more reliable results and efficient use of computational resources in community detection analysis.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19496",
        "abstract url": "https://arxiv.org/abs/2410.19496",
        "title": "A neural network approach for solving the Monge-Amp\u00e8re equation with transport boundary condition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces a novel neural network-based approach to solving the Monge-Amp\u00e8re equation with the transport boundary condition, specifically targeted towards optical design applications. We leverage multilayer perceptron networks to learn approximate solutions by minimizing a loss function that encompasses the equation's residual, boundary conditions, and convexity constraints. Our main results demonstrate the efficacy of this method, optimized using L-BFGS, through a series of test cases encompassing symmetric and asymmetric circle-to-circle, square-to-circle, and circle-to-flower reflector mapping problems. Comparative analysis with a conventional least-squares finite-difference solver reveals the competitive, and often superior, performance of our neural network approach on the test cases examined here. A comprehensive hyperparameter study further illuminates the impact of factors such as sampling density, network architecture, and optimization algorithm. While promising, further investigation is needed to verify the method's robustness for more complicated problems and to ensure consistent convergence. Nonetheless, the simplicity and adaptability of this neural network-based approach position it as a compelling alternative to specialized partial differential equation solvers.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19528",
        "abstract url": "https://arxiv.org/abs/2410.19528",
        "title": "AgentForge: A Flexible Low-Code Platform for Reinforcement Learning Agent Design",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Developing a reinforcement learning (RL) agent often involves identifying effective values for a large number of parameters, covering the policy, reward function, environment, and the agent's internal architecture, such as parameters controlling how the peripheral vision and memory modules work. Critically, since these parameters are interrelated in complex ways, optimizing them can be viewed as a black box optimization problem, which is especially challenging for non-experts. Although existing optimization-as-a-service platforms (e.g., Vizier, Optuna) can handle such problems, they are impractical for RL systems, as users must manually map each parameter to different components, making the process cumbersome and error-prone. They also require deep understanding of the optimization process, limiting their application outside ML experts and restricting access for fields like cognitive science, which models human decision-making. To tackle these challenges, we present AgentForge, a flexible low-code framework to optimize any parameter set across an RL system. AgentForge allows the user to perform individual or joint optimization of parameter sets. An optimization problem can be defined in a few lines of code and handed to any of the interfaced optimizers. We evaluated its performance in a challenging vision-based RL problem. AgentForge enables practitioners to develop RL agents without requiring extensive coding or deep expertise in optimization.",
        "subjects": [
            "cs.LG",
            "cs.SE"
        ],
        "comment": "This preprint was submitted to the 17th International Conference on Agents and Artificial Intelligence (ICAART'2025) and is currently under review"
    },
    {
        "paper id": "2410.19538",
        "abstract url": "https://arxiv.org/abs/2410.19538",
        "title": "Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Series",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Lately, there has been a surge in interest surrounding generative modeling of time series data. Most existing approaches are designed either to process short sequences or to handle long-range sequences. This dichotomy can be attributed to gradient issues with recurrent networks, computational costs associated with transformers, and limited expressiveness of state space models. Towards a unified generative model for varying-length time series, we propose in this work to transform sequences into images. By employing invertible transforms such as the delay embedding and the short-time Fourier transform, we unlock three main advantages: i) We can exploit advanced diffusion vision models; ii) We can remarkably process short- and long-range inputs within the same framework; and iii) We can harness recent and established tools proposed in the time series to image literature. We validate the effectiveness of our method through a comprehensive evaluation across multiple tasks, including unconditional generation, interpolation, and extrapolation. We show that our approach achieves consistently state-of-the-art results against strong baselines. In the unconditional generation tasks, we show remarkable mean improvements of 58.17% over previous diffusion models in the short discriminative score and 132.61% in the (ultra-)long classification scores. Code is at https://github.com/azencot-group/ImagenTime.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted to NeurIPS 2024; The first two authors contributed equally"
    },
    {
        "paper id": "2410.19546",
        "abstract url": "https://arxiv.org/abs/2410.19546",
        "title": "Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?",
        "rating": "0.5",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's GPT-4o, have emerged, seemingly demonstrating advanced reasoning capabilities across text and image modalities. Yet, the depth of these advances in language-guided perception and abstract reasoning remains underexplored, and it is unclear whether these models can truly live up to their ambitious promises. To assess the progress and identify shortcomings, we enter the wonderland of Bongard problems, a set of classical visual reasoning puzzles that require human-like abilities of pattern recognition and abstract reasoning. While VLMs occasionally succeed in identifying discriminative concepts and solving some of the problems, they frequently falter, failing to understand and reason about visual concepts. Surprisingly, even elementary concepts that may seem trivial to humans, such as simple spirals, pose significant challenges. Moreover, even when asked to explicitly focus on and analyze these concepts, they continue to falter, suggesting not only a lack of understanding of these elementary visual concepts but also an inability to generalize to unseen concepts. These observations underscore the current limitations of VLMs, emphasize that a significant gap remains between human-like visual reasoning and machine cognition, and highlight the ongoing need for innovation in this area.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19573",
        "abstract url": "https://arxiv.org/abs/2410.19573",
        "title": "FastPCI: Motion-Structure Guided Fast Point Cloud Frame Interpolation",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Point cloud frame interpolation is a challenging task that involves accurate scene flow estimation across frames and maintaining the geometry structure. Prevailing techniques often rely on pre-trained motion estimators or intensive testing-time optimization, resulting in compromised interpolation accuracy or prolonged inference. This work presents FastPCI that introduces Pyramid Convolution-Transformer architecture for point cloud frame interpolation. Our hybrid Convolution-Transformer improves the local and long-range feature learning, while the pyramid network offers multilevel features and reduces the computation. In addition, FastPCI proposes a unique Dual-Direction Motion-Structure block for more accurate scene flow estimation. Our design is motivated by two facts: (1) accurate scene flow preserves 3D structure, and (2) point cloud at the previous timestep should be reconstructable using reverse motion from future timestep. Extensive experiments show that FastPCI significantly outperforms the state-of-the-art PointINet and NeuralPCI with notable gains (e.g. 26.6% and 18.3% reduction in Chamfer Distance in KITTI), while being more than 10x and 600x faster, respectively. Code is available at https://github.com/genuszty/FastPCI",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To appear in ECCV 2024"
    },
    {
        "paper id": "2410.19605",
        "abstract url": "https://arxiv.org/abs/2410.19605",
        "title": "CoqPilot, a plugin for LLM-based generation of proofs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present CoqPilot, a VS Code extension designed to help automate writing of Coq proofs. The plugin collects the parts of proofs marked with the admit tactic in a Coq file, i.e., proof holes, and combines LLMs along with non-machine-learning methods to generate proof candidates for the holes. Then, CoqPilot checks if each proof candidate solves the given subgoal and, if successful, replaces the hole with it. The focus of CoqPilot is twofold. Firstly, we want to allow users to seamlessly combine multiple Coq generation approaches and provide a zero-setup experience for our tool. Secondly, we want to deliver a platform for LLM-based experiments on Coq proof generation. We developed a benchmarking system for Coq generation methods, available in the plugin, and conducted an experiment using it, showcasing the framework's possibilities. Demo of CoqPilot is available at: https://youtu.be/oB1Lx-So9Lo. Code at: https://github.com/JetBrains-Research/coqpilot",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.LO"
        ],
        "comment": "Published in the proceedings of the ASE'24 Tool Demonstrations Track"
    },
    {
        "paper id": "2410.19644",
        "abstract url": "https://arxiv.org/abs/2410.19644",
        "title": "Improving Stochastic Cubic Newton with Momentum",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study stochastic second-order methods for solving general non-convex optimization problems. We propose using a special version of momentum to stabilize the stochastic gradient and Hessian estimates in Newton's method. We show that momentum provably improves the variance of stochastic estimates and allows the method to converge for any noise level. Using the cubic regularization technique, we prove a global convergence rate for our method on general non-convex problems to a second-order stationary point, even when using only a single stochastic data sample per iteration. This starkly contrasts with all existing stochastic second-order methods for non-convex problems, which typically require large batches. Therefore, we are the first to demonstrate global convergence for batches of arbitrary size in the non-convex case for the Stochastic Cubic Newton. Additionally, we show improved speed on convex stochastic problems for our regularized Newton methods with momentum.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19651",
        "abstract url": "https://arxiv.org/abs/2410.19651",
        "title": "Community detection on directed networks with missing edges",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Identifying significant community structures in networks with incomplete data is a challenging task, as the reliability of solutions diminishes with increasing levels of missing information. However, in many empirical contexts, some information about the uncertainty in the network measurements can be estimated. In this work, we extend the recently developed Flow Stability framework, originally designed for detecting communities in time-varying networks, to address the problem of community detection in weighted, directed networks with missing links. Our approach leverages known uncertainty levels in nodes' out-degrees to enhance the robustness of community detection. Through comparisons on synthetic networks and a real-world network of messaging channels on the Telegram platform, we demonstrate that our method delivers more reliable community structures, even when a significant portion of data is missing.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19653",
        "abstract url": "https://arxiv.org/abs/2410.19653",
        "title": "Conformal Prediction for Multimodal Regression",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces multimodal conformal regression. Traditionally confined to scenarios with solely numerical input features, conformal prediction is now extended to multimodal contexts through our methodology, which harnesses internal features from complex neural network architectures processing images and unstructured text. Our findings highlight the potential for internal neural network features, extracted from convergence points where multimodal information is combined, to be used by conformal prediction to construct prediction intervals (PIs). This capability paves new paths for deploying conformal prediction in domains abundant with multimodal data, enabling a broader range of problems to benefit from guaranteed distribution-free uncertainty quantification.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "20 pages, 34 figures"
    },
    {
        "paper id": "2410.19675",
        "abstract url": "https://arxiv.org/abs/2410.19675",
        "title": "Learning the Regularization Strength for Deep Fine-Tuning via a Data-Emphasized Variational Objective",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A number of popular transfer learning methods rely on grid search to select regularization hyperparameters that control over-fitting. This grid search requirement has several key disadvantages: the search is computationally expensive, requires carving out a validation set that reduces the size of available data for model training, and requires practitioners to specify candidate values. In this paper, we propose an alternative to grid search: directly learning regularization hyperparameters on the full training set via model selection techniques based on the evidence lower bound (\"ELBo\") objective from variational methods. For deep neural networks with millions of parameters, we specifically recommend a modified ELBo that upweights the influence of the data likelihood relative to the prior while remaining a valid bound on the evidence for Bayesian model selection. Our proposed technique overcomes all three disadvantages of grid search. We demonstrate effectiveness on image classification tasks on several datasets, yielding heldout accuracy comparable to existing approaches with far less compute time.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19706",
        "abstract url": "https://arxiv.org/abs/2410.19706",
        "title": "Super Gradient Descent: Global Optimization requires Global Gradient",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Global minimization is a fundamental challenge in optimization, especially in machine learning, where finding the global minimum of a function directly impacts model performance and convergence. This article introduces a novel optimization method that we called Super Gradient Descent, designed specifically for one-dimensional functions, guaranteeing convergence to the global minimum for any k-Lipschitz function defined on a closed interval [a, b]. Our approach addresses the limitations of traditional optimization algorithms, which often get trapped in local minima. In particular, we introduce the concept of global gradient which offers a robust solution for precise and well-guided global optimization. By focusing on the global minimization problem, this work bridges a critical gap in optimization theory, offering new insights and practical advancements in different optimization problems in particular Machine Learning problems like line search.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19725",
        "abstract url": "https://arxiv.org/abs/2410.19725",
        "title": "On the Benefits of Active Data Collection in Operator Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We investigate active data collection strategies for operator learning when the target operator is linear and the input functions are drawn from a mean-zero stochastic process with continuous covariance kernels. With an active data collection strategy, we establish an error convergence rate in terms of the decay rate of the eigenvalues of the covariance kernel. Thus, with sufficiently rapid eigenvalue decay of the covariance kernels, arbitrarily fast error convergence rates can be achieved. This contrasts with the passive (i.i.d.) data collection strategies, where the convergence rate is never faster than $\\sim n^{-1}$. In fact, for our setting, we establish a \\emph{non-vanishing} lower bound for any passive data collection strategy, regardless of the eigenvalues decay rate of the covariance kernel. Overall, our results show the benefit of active over passive data collection strategies in operator learning.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19728",
        "abstract url": "https://arxiv.org/abs/2410.19728",
        "title": "cymyc -- Calabi-Yau Metrics, Yukawas, and Curvature",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce \\texttt{cymyc}, a high-performance Python library for numerical investigation of the geometry of a large class of string compactification manifolds and their associated moduli spaces. We develop a well-defined geometric ansatz to numerically model tensor fields of arbitrary degree on a large class of Calabi-Yau manifolds. \\texttt{cymyc} includes a machine learning component which incorporates this ansatz to model tensor fields of interest on these spaces by finding an approximate solution to the system of partial differential equations they should satisfy.",
        "subjects": [
            "hep-th",
            "cs.LG",
            "hep-ph"
        ],
        "comment": "35 pages, 12 figures"
    },
    {
        "paper id": "2410.19888",
        "abstract url": "https://arxiv.org/abs/2410.19888",
        "title": "EnergyPlus Room Simulator",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Research towards energy optimization in buildings heavily relies on building-related data such as measured indoor climate factors. While data collection is a labor- and cost-intensive task, simulations are a cheap alternative to generate datasets of arbitrary sizes, particularly useful for data-intensive deep learning methods. In this paper, we present the tool EnergyPlus Room Simulator, which enables the simulation of indoor climate in a specific room of a building using the simulation software EnergyPlus. It allows to alter room models and simulate various factors such as temperature, humidity, and CO2 concentration. In contrast to manually working with EnergyPlus, this tool enhances the simulation process by offering a convenient interface, including a user-friendly graphical user interface (GUI) as well as a REST API. The tool is intended to support scientific, building-related tasks such as occupancy detection on a room level by facilitating fast access to simulation data that may, for instance, be used for pre-training machine learning models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Presented at BuildSim Nordic 2024. The conference was held from June 9 to 11, 2024, in Espoo, Finland"
    },
    {
        "paper id": "2410.19915",
        "abstract url": "https://arxiv.org/abs/2410.19915",
        "title": "Urban Mobility: AI, ODE-Based Modeling, and Scenario Planning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Urbanization and technological advancements are reshaping the future of urban mobility, presenting both challenges and opportunities. This paper combines foresight and scenario planning with mathematical modeling using Ordinary Differential Equations (ODEs) to explore how Artificial Intelligence (AI)-driven technologies can transform transportation systems. By simulating ODE-based models in Python, we quantify the impact of AI innovations, such as autonomous vehicles and intelligent traffic management, on reducing traffic congestion under different regulatory conditions. Our ODE models capture the dynamic relationship between AI adoption rates and traffic congestion, providing quantitative insights into how future scenarios might unfold. By incorporating industry collaborations and case studies, we offer strategic guidance for businesses and policymakers navigating this evolving landscape. This study contributes to understanding how foresight, scenario planning, and ODE modeling can inform strategies for creating more efficient, sustainable, and livable cities through AI adoption.",
        "subjects": [
            "econ.GN",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19917",
        "abstract url": "https://arxiv.org/abs/2410.19917",
        "title": "Collaborative Inference over Wireless Channels with Feature Differential Privacy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Collaborative inference among multiple wireless edge devices has the potential to significantly enhance Artificial Intelligence (AI) applications, particularly for sensing and computer vision. This approach typically involves a three-stage process: a) data acquisition through sensing, b) feature extraction, and c) feature encoding for transmission. However, transmitting the extracted features poses a significant privacy risk, as sensitive personal data can be exposed during the process. To address this challenge, we propose a novel privacy-preserving collaborative inference mechanism, wherein each edge device in the network secures the privacy of extracted features before transmitting them to a central server for inference. Our approach is designed to achieve two primary objectives: 1) reducing communication overhead and 2) ensuring strict privacy guarantees during feature transmission, while maintaining effective inference performance. Additionally, we introduce an over-the-air pooling scheme specifically designed for classification tasks, which provides formal guarantees on the privacy of transmitted features and establishes a lower bound on classification accuracy.",
        "subjects": [
            "cs.CR",
            "cs.IT",
            "cs.LG"
        ],
        "comment": "This work is under review for possible IEEE publication. arXiv admin note: substantial text overlap with arXiv:2406.00256"
    },
    {
        "paper id": "2410.19919",
        "abstract url": "https://arxiv.org/abs/2410.19919",
        "title": "Provably Adaptive Average Reward Reinforcement Learning for Metric Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We study infinite-horizon average-reward reinforcement learning (RL) for Lipschitz MDPs and develop an algorithm ZoRL that discretizes the state-action space adaptively and zooms into promising regions of the state-action space. We show that its regret can be bounded as $\\mathcal{\\tilde{O}}\\big(T^{1 - d_{\\text{eff.}}^{-1}}\\big)$, where $d_{\\text{eff.}} = 2d_\\mathcal{S} + d_z + 3$, $d_\\mathcal{S}$ is the dimension of the state space, and $d_z$ is the zooming dimension. $d_z$ is a problem-dependent quantity, which allows us to conclude that if MDP is benign, then its regret will be small. We note that the existing notion of zooming dimension for average reward RL is defined in terms of policy coverings, and hence it can be huge when the policy class is rich even though the underlying MDP is simple, so that the regret upper bound is nearly $O(T)$. The zooming dimension proposed in the current work is bounded above by $d$, the dimension of the state-action space, and hence is truly adaptive, i.e., shows how to capture adaptivity gains for infinite-horizon average-reward RL. ZoRL outperforms other state-of-the-art algorithms in experiments; thereby demonstrating the gains arising due to adaptivity.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19920",
        "abstract url": "https://arxiv.org/abs/2410.19920",
        "title": "Reinforcement Learning for Aligning Large Language Models Agents with Interactive Environments: Quantifying and Mitigating Prompt Overfitting",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning (RL) is a promising approach for aligning large language models (LLMs) knowledge with sequential decision-making tasks. However, few studies have thoroughly investigated the impact on LLM agents capabilities of fine-tuning them with RL in a specific environment. In this paper, we propose a novel framework to analyze the sensitivity of LLMs to prompt formulations following RL training in a textual environment. Our findings reveal that the performance of LLMs degrades when faced with prompt formulations different from those used during the RL training phase. Besides, we analyze the source of this sensitivity by examining the model's internal representations and salient tokens. Finally, we propose to use a contrastive loss to mitigate this sensitivity and improve the robustness and generalization capabilities of LLMs.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19923",
        "abstract url": "https://arxiv.org/abs/2410.19923",
        "title": "Language Agents Meet Causality -- Bridging LLMs and Causal World Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have recently shown great promise in planning and reasoning applications. These tasks demand robust systems, which arguably require a causal understanding of the environment. While LLMs can acquire and reflect common sense causal knowledge from their pretraining data, this information is often incomplete, incorrect, or inapplicable to a specific environment. In contrast, causal representation learning (CRL) focuses on identifying the underlying causal structure within a given environment. We propose a framework that integrates CRLs with LLMs to enable causally-aware reasoning and planning. This framework learns a causal world model, with causal variables linked to natural language expressions. This mapping provides LLMs with a flexible interface to process and generate descriptions of actions and states in text form. Effectively, the causal world model acts as a simulator that the LLM can query and interact with. We evaluate the framework on causal inference and planning tasks across temporal scales and environmental complexities. Our experiments demonstrate the effectiveness of the approach, with the causally-aware method outperforming LLM-based reasoners, especially for longer planning horizons.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "stat.ME"
        ],
        "comment": "Project page: https://j0hngou.github.io/LLMCWM/"
    },
    {
        "paper id": "2410.19933",
        "abstract url": "https://arxiv.org/abs/2410.19933",
        "title": "Enhancing Safety in Reinforcement Learning with Human Feedback via Rectified Policy Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Balancing helpfulness and safety (harmlessness) is a critical challenge in aligning large language models (LLMs). Current approaches often decouple these two objectives, training separate preference models for helpfulness and safety, while framing safety as a constraint within a constrained Markov Decision Process (CMDP) framework. However, these methods can lead to ``safety interference'', where average-based safety constraints compromise the safety of some prompts in favor of others. To address this issue, we propose \\textbf{Rectified Policy Optimization (RePO)}, which replaces the average safety constraint with stricter (per prompt) safety constraints. At the core of RePO is a policy update mechanism driven by rectified policy gradients, which penalizes the strict safety violation of every prompt, thereby enhancing safety across nearly all prompts. Our experiments on Alpaca-7B demonstrate that RePO improves the safety alignment and reduces the safety interference compared to baseline methods. Code is available at https://github.com/pxyWaterMoon/RePO.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19940",
        "abstract url": "https://arxiv.org/abs/2410.19940",
        "title": "Cobblestone: Iterative Automation for Formal Verification",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Formal verification using proof assistants, such as Coq, is an effective way of improving software quality, but it is expensive. Writing proofs manually requires both significant effort and expertise. Recent research has used machine learning to automatically synthesize proofs, reducing verification effort, but these tools are able to prove only a fraction of the desired software properties. We introduce Cobblestone, a new proof-synthesis approach that improves on the state of the art by taking advantage of partial progress in proof synthesis attempts. Unlike prior tools, Cobblestone can produce multiple unsuccessful proofs using a large language model (LLM), identify the working portions of those proofs, and combine them into a single, successful proof, taking advantage of internal partial progress. We evaluate Cobblestone on two benchmarks of open-source Coq projects, controlling for training data leakage in LLM datasets. Fully automatically, Cobblestone can prove 48% of the theorems, while Proverbot9001, the previous state-of-the-art, learning-based, proof-synthesis tool, can prove 17%. Cobblestone establishes a new state of the art for fully automated proof synthesis tools for Coq. We also evaluate Cobblestone in a setting where it is given external partial proof progress from oracles, serving as proxies for a human proof engineer or another tool. When the theorem is broken down into a set of subgoals and Cobblestone is given a set of relevant lemmas already proven in the project, it can prove up to 58% of the theorems. We qualitatively study the theorems Cobblestone is and is not able to prove to outline potential future research directions to further improve proof synthesis, including developing interactive, semi-automated tools. Our research shows that tools can make better use of partial progress made during proof synthesis to more effectively automate formal verification.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.PL"
        ],
        "comment": "13 pages, 10 figures"
    },
    {
        "paper id": "2410.19941",
        "abstract url": "https://arxiv.org/abs/2410.19941",
        "title": "Privacy without Noisy Gradients: Slicing Mechanism for Generative Model Training",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Training generative models with differential privacy (DP) typically involves injecting noise into gradient updates or adapting the discriminator's training procedure. As a result, such approaches often struggle with hyper-parameter tuning and convergence. We consider the slicing privacy mechanism that injects noise into random low-dimensional projections of the private data, and provide strong privacy guarantees for it. These noisy projections are used for training generative models. To enable optimizing generative models using this DP approach, we introduce the smoothed-sliced $f$-divergence and show it enjoys statistical consistency. Moreover, we present a kernel-based estimator for this divergence, circumventing the need for adversarial training. Extensive numerical experiments demonstrate that our approach can generate synthetic data of higher quality compared with baselines. Beyond performance improvement, our method, by sidestepping the need for noisy gradients, offers data scientists the flexibility to adjust generator architecture and hyper-parameters, run the optimization over any number of epochs, and even restart the optimization process -- all without incurring additional privacy costs.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "accepted to Neurips 2024"
    },
    {
        "paper id": "2410.19948",
        "abstract url": "https://arxiv.org/abs/2410.19948",
        "title": "Assessing the societal influence of academic research with ChatGPT: Impact case study evaluations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Academics and departments are sometimes judged by how their research has benefitted society. For example, the UK Research Excellence Framework (REF) assesses Impact Case Studies (ICS), which are five-page evidence-based claims of societal impacts. This study investigates whether ChatGPT can evaluate societal impact claims and therefore potentially support expert human assessors. For this, various parts of 6,220 public ICS from REF2021 were fed to ChatGPT 4o-mini along with the REF2021 evaluation guidelines, comparing the results with published departmental average ICS scores. The results suggest that the optimal strategy for high correlations with expert scores is to input the title and summary of an ICS but not the remaining text, and to modify the original REF guidelines to encourage a stricter evaluation. The scores generated by this approach correlated positively with departmental average scores in all 34 Units of Assessment (UoAs), with values between 0.18 (Economics and Econometrics) and 0.56 (Psychology, Psychiatry and Neuroscience). At the departmental level, the corresponding correlations were higher, reaching 0.71 for Sport and Exercise Sciences, Leisure and Tourism. Thus, ChatGPT-based ICS evaluations are simple and viable to support or cross-check expert judgments, although their value varies substantially between fields.",
        "subjects": [
            "cs.DL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19964",
        "abstract url": "https://arxiv.org/abs/2410.19964",
        "title": "Understanding Adam Requires Better Rotation Dependent Assumptions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Despite its widespread adoption, Adam's advantage over Stochastic Gradient Descent (SGD) lacks a comprehensive theoretical explanation. This paper investigates Adam's sensitivity to rotations of the parameter space. We demonstrate that Adam's performance in training transformers degrades under random rotations of the parameter space, indicating a crucial sensitivity to the choice of basis. This reveals that conventional rotation-invariant assumptions are insufficient to capture Adam's advantages theoretically. To better understand the rotation-dependent properties that benefit Adam, we also identify structured rotations that preserve or even enhance its empirical performance. We then examine the rotation-dependent assumptions in the literature, evaluating their adequacy in explaining Adam's behavior across various rotation types. This work highlights the need for new, rotation-dependent theoretical frameworks to fully understand Adam's empirical success in modern machine learning tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19982",
        "abstract url": "https://arxiv.org/abs/2410.19982",
        "title": "SAD: State-Action Distillation for In-Context Reinforcement Learning under Random Policies",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Pretrained foundation models have exhibited extraordinary in-context learning performance, allowing zero-shot generalization to new tasks not encountered during the pretraining. In the case of RL, in-context RL (ICRL) emerges when pretraining FMs on decision-making problems in an autoregressive-supervised manner. Nevertheless, current state-of-the-art ICRL algorithms, such as AD, DPT and DIT, impose stringent requirements on generating the pretraining dataset concerning the behavior (source) policies, context information, and action labels, etc. Notably, these algorithms either demand optimal policies or require varying degrees of well-trained behavior policies for all environments during the generation of the pretraining dataset. This significantly hinders the application of ICRL to real-world scenarios, where acquiring optimal or well-trained policies for a substantial volume of real-world training environments can be both prohibitively intractable and expensive. To overcome this challenge, we introduce a novel approach, termed State-Action Distillation (SAD), that allows to generate a remarkable pretraining dataset guided solely by random policies. In particular, SAD selects query states and corresponding action labels by distilling the outstanding state-action pairs from the entire state and action spaces by using random policies within a trust horizon, and then inherits the classical autoregressive-supervised mechanism during the pretraining. To the best of our knowledge, this is the first work that enables promising ICRL under (e.g., uniform) random policies and random contexts. We establish theoretical analyses regarding the performance guarantees of SAD. Moreover, our empirical results across multiple ICRL benchmark environments demonstrate that, on average, SAD outperforms the best baseline by 180.86% in the offline evaluation and by 172.8% in the online evaluation.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19987",
        "abstract url": "https://arxiv.org/abs/2410.19987",
        "title": "Residual Random Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The single-layer feedforward neural network with random weights is a recurring motif in the neural networks literature. The advantage of these networks is their simplified training, which reduces to solving a ridge-regression problem. A general assumption is that these networks require a large number of hidden neurons relative to the dimensionality of the data samples, in order to achieve good classification accuracy. Contrary to this assumption, here we show that one can obtain good classification results even if the number of hidden neurons has the same order of magnitude as the dimensionality of the data samples, if this dimensionality is reasonably high. Inspired by this result, we also develop an efficient iterative residual training method for such random neural networks, and we extend the algorithm to the least-squares kernel version of the neural network model. Moreover, we also describe an encryption (obfuscation) method which can be used to protect both the data and the resulted network model.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "revised version, 17 pages, 8 figures, added kernel method"
    },
    {
        "paper id": "2410.19990",
        "abstract url": "https://arxiv.org/abs/2410.19990",
        "title": "Dimension reduction via score ratio matching",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Gradient-based dimension reduction decreases the cost of Bayesian inference and probabilistic modeling by identifying maximally informative (and informed) low-dimensional projections of the data and parameters, allowing high-dimensional problems to be reformulated as cheaper low-dimensional problems. A broad family of such techniques identify these projections and provide error bounds on the resulting posterior approximations, via eigendecompositions of certain diagnostic matrices. Yet these matrices require gradients or even Hessians of the log-likelihood, excluding the purely data-driven setting and many problems of simulation-based inference. We propose a framework, derived from score-matching, to extend gradient-based dimension reduction to problems where gradients are unavailable. Specifically, we formulate an objective function to directly learn the score ratio function needed to compute the diagnostic matrices, propose a tailored parameterization for the score ratio network, and introduce regularization methods that capitalize on the hypothesized low-dimensional structure. We also introduce a novel algorithm to iteratively identify the low-dimensional reduced basis vectors more accurately with limited data based on eigenvalue deflation methods. We show that our approach outperforms standard score-matching for problems with low-dimensional structure, and demonstrate its effectiveness for PDE-constrained Bayesian inverse problems and conditional generative modeling.",
        "subjects": [
            "stat.CO",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "23 pages, 9 figures, 1 table"
    },
    {
        "paper id": "2410.20019",
        "abstract url": "https://arxiv.org/abs/2410.20019",
        "title": "Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions",
        "rating": "0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Large Language Models have introduced novel opportunities for text comprehension and generation. Yet, they are vulnerable to adversarial perturbations and data poisoning attacks, particularly in tasks like text classification and translation. However, the adversarial robustness of abstractive text summarization models remains less explored. In this work, we unveil a novel approach by exploiting the inherent lead bias in summarization models, to perform adversarial perturbations. Furthermore, we introduce an innovative application of influence functions, to execute data poisoning, which compromises the model's integrity. This approach not only shows a skew in the models behavior to produce desired outcomes but also shows a new behavioral change, where models under attack tend to generate extractive summaries rather than abstractive summaries.",
        "subjects": [
            "cs.CL",
            "cs.CR"
        ],
        "comment": "10 pages, 3 figures, Accepted at EMNLP Findings 2024"
    },
    {
        "paper id": "2410.20041",
        "abstract url": "https://arxiv.org/abs/2410.20041",
        "title": "Annotation Efficiency: Identifying Hard Samples via Blocked Sparse Linear Bandits",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper considers the problem of annotating datapoints using an expert with only a few annotation rounds in a label-scarce setting. We propose soliciting reliable feedback on difficulty in annotating a datapoint from the expert in addition to ground truth label. Existing literature in active learning or coreset selection turns out to be less relevant to our setting since they presume the existence of a reliable trained model, which is absent in the label-scarce regime. However, the literature on coreset selection emphasizes the presence of difficult data points in the training set to perform supervised learning in downstream tasks (Mindermann et al., 2022). Therefore, for a given fixed annotation budget of $\\mathsf{T}$ rounds, we model the sequential decision-making problem of which (difficult) datapoints to choose for annotation in a sparse linear bandits framework with the constraint that no arm can be pulled more than once (blocking constraint). With mild assumptions on the datapoints, our (computationally efficient) Explore-Then-Commit algorithm BSLB achieves a regret guarantee of $\\widetilde{\\mathsf{O}}(k^{\\frac{1}{3}} \\mathsf{T}^{\\frac{2}{3}} +k^{-\\frac{1}{2}} \u03b2_k + k^{-\\frac{1}{12}} \u03b2_k^{\\frac{1}{2}}\\mathsf{T}^{\\frac{5}{6}})$ where the unknown parameter vector has tail magnitude $\u03b2_k$ at sparsity level $k$. To this end, we show offline statistical guarantees of Lasso estimator with mild Restricted Eigenvalue (RE) condition that is also robust to sparsity. Finally, we propose a meta-algorithm C-BSLB that does not need knowledge of the optimal sparsity parameters at a no-regret cost. We demonstrate the efficacy of our BSLB algorithm for annotation in the label-scarce setting for an image classification task on the PASCAL-VOC dataset, where we use real-world annotation difficulty scores.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "31 Pages"
    },
    {
        "paper id": "2410.20047",
        "abstract url": "https://arxiv.org/abs/2410.20047",
        "title": "ResAD: A Simple Framework for Class Generalizable Anomaly Detection",
        "rating": "0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "This paper explores the problem of class-generalizable anomaly detection, where the objective is to train one unified AD model that can generalize to detect anomalies in diverse classes from different domains without any retraining or fine-tuning on the target data. Because normal feature representations vary significantly across classes, this will cause the widely studied one-for-one AD models to be poorly classgeneralizable (i.e., performance drops dramatically when used for new classes). In this work, we propose a simple but effective framework (called ResAD) that can be directly applied to detect anomalies in new classes. Our main insight is to learn the residual feature distribution rather than the initial feature distribution. In this way, we can significantly reduce feature variations. Even in new classes, the distribution of normal residual features would not remarkably shift from the learned distribution. Therefore, the learned model can be directly adapted to new classes. ResAD consists of three components: (1) a Feature Converter that converts initial features into residual features; (2) a simple and shallow Feature Constraintor that constrains normal residual features into a spatial hypersphere for further reducing feature variations and maintaining consistency in feature scales among different classes; (3) a Feature Distribution Estimator that estimates the normal residual feature distribution, anomalies can be recognized as out-of-distribution. Despite the simplicity, ResAD can achieve remarkable anomaly detection results when directly used in new classes. The code is available at https://github.com/xcyao00/ResAD.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "This paper was accepted as a spotlight papaer by NeurIPS 2024"
    },
    {
        "paper id": "2410.20057",
        "abstract url": "https://arxiv.org/abs/2410.20057",
        "title": "Mechanism learning: Reverse causal inference in the presence of multiple unknown confounding through front-door causal bootstrapping",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A major limitation of machine learning (ML) prediction models is that they recover associational, rather than causal, predictive relationships between variables. In high-stakes automation applications of ML this is problematic, as the model often learns spurious, non-causal associations. This paper proposes mechanism learning, a simple method which uses front-door causal bootstrapping to deconfound observational data such that any appropriate ML model is forced to learn predictive relationships between effects and their causes (reverse causal inference), despite the potential presence of multiple unknown and unmeasured confounding. Effect variables can be very high dimensional, and the predictive relationship nonlinear, as is common in ML applications. This novel method is widely applicable, the only requirement is the existence of a mechanism variable mediating the cause (prediction target) and effect (feature data), which is independent of the (unmeasured) confounding variables. We test our method on fully synthetic, semi-synthetic and real-world datasets, demonstrating that it can discover reliable, unbiased, causal ML predictors where by contrast, the same ML predictor trained naively using classical supervised learning on the original observational data, is heavily biased by spurious associations. We provide code to implement the results in the paper, online.",
        "subjects": [
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2410.20061",
        "abstract url": "https://arxiv.org/abs/2410.20061",
        "title": "Deep Concept Identification for Generative Design",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A generative design based on topology optimization provides diverse alternatives as entities in a computational model with a high design degree. However, as the diversity of the generated alternatives increases, the cognitive burden on designers to select the most appropriate alternatives also increases. Whereas the concept identification approach, which finds various categories of entities, is an effective means to structure alternatives, evaluation of their similarities is challenging due to shape diversity. To address this challenge, this study proposes a concept identification framework for generative design using deep learning (DL) techniques. One of the key abilities of DL is the automatic learning of different representations of a specific task. Deep concept identification finds various categories that provide insights into the mapping relationships between geometric properties and structural performance through representation learning using DL. The proposed framework generates diverse alternatives using a generative design technique, clusters the alternatives into several categories using a DL technique, and arranges these categories for design practice using a classification model. This study demonstrates its fundamental capabilities by implementing variational deep embedding, a generative and clustering model based on the DL paradigm, and logistic regression as a classification model. A simplified design problem of a two-dimensional bridge structure is applied as a case study to validate the proposed framework. Although designers are required to determine the viewing aspect level by setting the number of concepts, this implementation presents the identified concepts and their relationships in the form of a decision tree based on a specified level.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20072",
        "abstract url": "https://arxiv.org/abs/2410.20072",
        "title": "CGKN: A Deep Learning Framework for Modeling Complex Dynamical Systems and Efficient Data Assimilation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning is widely used to predict complex dynamical systems in many scientific and engineering areas. However, the black-box nature of these deep learning models presents significant challenges for carrying out simultaneous data assimilation (DA), which is a crucial technique for state estimation, model identification, and reconstructing missing data. Integrating ensemble-based DA methods with nonlinear deep learning models is computationally expensive and may suffer from large sampling errors. To address these challenges, we introduce a deep learning framework designed to simultaneously provide accurate forecasts and efficient DA. It is named Conditional Gaussian Koopman Network (CGKN), which transforms general nonlinear systems into nonlinear neural differential equations with conditional Gaussian structures. CGKN aims to retain essential nonlinear components while applying systematic and minimal simplifications to facilitate the development of analytic formulae for nonlinear DA. This allows for seamless integration of DA performance into the deep learning training process, eliminating the need for empirical tuning as required in ensemble methods. CGKN compensates for structural simplifications by lifting the dimension of the system, which is motivated by Koopman theory. Nevertheless, CGKN exploits special nonlinear dynamics within the lifted space. This enables the model to capture extreme events and strong non-Gaussian features in joint and marginal distributions with appropriate uncertainty quantification. We demonstrate the effectiveness of CGKN for both prediction and DA on three strongly nonlinear and non-Gaussian turbulent systems: the projected stochastic Burgers--Sivashinsky equation, the Lorenz 96 system, and the El Ni\u00f1o-Southern Oscillation. The results justify the robustness and computational efficiency of CGKN.",
        "subjects": [
            "cs.LG",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.21316",
        "abstract url": "https://arxiv.org/abs/2410.21316",
        "title": "Deep Optimizer States: Towards Scalable Training of Transformer Models Using Interleaved Offloading",
        "rating": "0.5",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Transformers and large language models~(LLMs) have seen rapid adoption in all domains. Their sizes have exploded to hundreds of billions of parameters and keep increasing. Under these circumstances, the training of transformers is very expensive and often hits a ``memory wall'', i.e., even when using 3D parallelism (pipeline, tensor, data) and aggregating the memory of many GPUs, it is still not enough to hold the necessary data structures (model parameters, optimizer state, gradients, activations) in GPU memory. To compensate, state-of-the-art approaches offload the optimizer state, at least partially, to the host memory and perform hybrid CPU-GPU computations. However, the management of the combined host-GPU memory is often suboptimal and results in poor overlapping between data movements and computations. This leads to missed opportunities to simultaneously leverage the interconnect bandwidth and computational capabilities of CPUs and GPUs. In this paper, we leverage a key observation that the interleaving of the forward, backward and update phases generate fluctuations in the GPU memory utilization, which can be exploited to dynamically move a part of the optimizer state between the host and the GPU memory at each iteration. To this end, we design and implement \\proj, a novel technique to split the LLM into subgroups, whose update phase is scheduled on either the CPU or the GPU based on our proposed performance model that addresses the trade-off between data movement cost, acceleration on the GPUs vs the CPUs, and competition for shared resources. We integrate our approach with DeepSpeed and demonstrate 2.5$\\times$ faster iterations over state-of-the-art approaches using extensive experiments.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC",
            "cs.ET",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19310",
        "abstract url": "https://arxiv.org/abs/2410.19310",
        "title": "Flow Generator Matching",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In the realm of Artificial Intelligence Generated Content (AIGC), flow-matching models have emerged as a powerhouse, achieving success due to their robust theoretical underpinnings and solid ability for large-scale generative modeling. These models have demonstrated state-of-the-art performance, but their brilliance comes at a cost. The process of sampling from these models is notoriously demanding on computational resources, as it necessitates the use of multi-step numerical ordinary differential equations (ODEs). Against this backdrop, this paper presents a novel solution with theoretical guarantees in the form of Flow Generator Matching (FGM), an innovative approach designed to accelerate the sampling of flow-matching models into a one-step generation, while maintaining the original performance. On the CIFAR10 unconditional generation benchmark, our one-step FGM model achieves a new record Fr\u00e9chet Inception Distance (FID) score of 3.08 among few-step flow-matching-based models, outperforming original 50-step flow-matching models. Furthermore, we use the FGM to distill the Stable Diffusion 3, a leading text-to-image flow-matching model based on the MM-DiT architecture. The resulting MM-DiT-FGM one-step text-to-image model demonstrates outstanding industry-level performance. When evaluated on the GenEval benchmark, MM-DiT-FGM has delivered remarkable generating qualities, rivaling other multi-step models in light of the efficiency of a single generation step.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19336",
        "abstract url": "https://arxiv.org/abs/2410.19336",
        "title": "DECADE: Towards Designing Efficient-yet-Accurate Distance Estimation Modules for Collision Avoidance in Mobile Advanced Driver Assistance Systems",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The proliferation of smartphones and other mobile devices provides a unique opportunity to make Advanced Driver Assistance Systems (ADAS) accessible to everyone in the form of an application empowered by low-cost Machine/Deep Learning (ML/DL) models to enhance road safety. For the critical feature of Collision Avoidance in Mobile ADAS, lightweight Deep Neural Networks (DNN) for object detection exist, but conventional pixel-wise depth/distance estimation DNNs are vastly more computationally expensive making them unsuitable for a real-time application on resource-constrained devices. In this paper, we present a distance estimation model, DECADE, that processes each detector output instead of constructing pixel-wise depth/disparity maps. In it, we propose a pose estimation DNN to estimate allocentric orientation of detections to supplement the distance estimation DNN in its prediction of distance using bounding box features. We demonstrate that these modules can be attached to any detector to extend object detection with fast distance estimation. Evaluation of the proposed modules with attachment to and fine-tuning on the outputs of the YOLO object detector on the KITTI 3D Object Detection dataset achieves state-of-the-art performance with 1.38 meters in Mean Absolute Error and 7.3% in Mean Relative Error in the distance range of 0-150 meters. Our extensive evaluation scheme not only evaluates class-wise performance, but also evaluates range-wise accuracy especially in the critical range of 0-70m.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 17 figures, 4 tables"
    },
    {
        "paper id": "2410.19341",
        "abstract url": "https://arxiv.org/abs/2410.19341",
        "title": "Context-Based Visual-Language Place Recognition",
        "rating": "0",
        "keywords": [
            [
                "Visual-Language"
            ],
            [
                "SLAM"
            ],
            [
                "robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In vision-based robot localization and SLAM, Visual Place Recognition (VPR) is essential. This paper addresses the problem of VPR, which involves accurately recognizing the location corresponding to a given query image. A popular approach to vision-based place recognition relies on low-level visual features. Despite significant progress in recent years, place recognition based on low-level visual features is challenging when there are changes in scene appearance. To address this, end-to-end training approaches have been proposed to overcome the limitations of hand-crafted features. However, these approaches still fail under drastic changes and require large amounts of labeled data to train models, presenting a significant limitation. Methods that leverage high-level semantic information, such as objects or categories, have been proposed to handle variations in appearance. In this paper, we introduce a novel VPR approach that remains robust to scene changes and does not require additional training. Our method constructs semantic image descriptors by extracting pixel-level embeddings using a zero-shot, language-driven semantic segmentation model. We validate our approach in challenging place recognition scenarios using real-world public dataset. The experiments demonstrate that our method outperforms non-learned image representation techniques and off-the-shelf convolutional neural network (CNN) descriptors. Our code is available at https: //github.com/woo-soojin/context-based-vlpr.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19355",
        "abstract url": "https://arxiv.org/abs/2410.19355",
        "title": "FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we present \\textbf{\\textit{FasterCache}}, a novel training-free strategy designed to accelerate the inference of video diffusion models with high-quality generation. By analyzing existing cache-based methods, we observe that \\textit{directly reusing adjacent-step features degrades video quality due to the loss of subtle variations}. We further perform a pioneering investigation of the acceleration potential of classifier-free guidance (CFG) and reveal significant redundancy between conditional and unconditional features within the same timestep. Capitalizing on these observations, we introduce FasterCache to substantially accelerate diffusion-based video generation. Our key contributions include a dynamic feature reuse strategy that preserves both feature distinction and temporal continuity, and CFG-Cache which optimizes the reuse of conditional and unconditional outputs to further enhance inference speed without compromising video quality. We empirically evaluate FasterCache on recent video diffusion models. Experimental results show that FasterCache can significantly accelerate video generation (\\eg 1.67$\\times$ speedup on Vchitect-2.0) while keeping video quality comparable to the baseline, and consistently outperform existing methods in both inference speed and video quality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19415",
        "abstract url": "https://arxiv.org/abs/2410.19415",
        "title": "Integration of Communication and Computational Imaging",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Communication enables the expansion of human visual perception beyond the limitations of time and distance, while computational imaging overcomes the constraints of depth and breadth. Although impressive achievements have been witnessed with the two types of technologies, the occlusive information flow between the two domains is a bottleneck hindering their ulterior progression. Herein, we propose a novel framework that integrates communication and computational imaging (ICCI) to break through the inherent isolation between communication and computational imaging for remote perception. By jointly considering the sensing and transmitting of remote visual information, the ICCI framework performs a full-link information transfer optimization, aiming to minimize information loss from the generation of the information source to the execution of the final vision tasks. We conduct numerical analysis and experiments to demonstrate the ICCI framework by integrating communication systems and snapshot compressive imaging systems. Compared with straightforward combination schemes, which sequentially execute sensing and transmitting, the ICCI scheme shows greater robustness against channel noise and impairments while achieving higher data compression. Moreover, an 80 km 27-band hyperspectral video perception with a rate of 30 fps is experimentally achieved. This new ICCI remote perception paradigm offers a highefficiency solution for various real-time computer vision tasks.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19419",
        "abstract url": "https://arxiv.org/abs/2410.19419",
        "title": "KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-To-Image"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) and Text-To-Image (T2I) models have demonstrated the ability to generate compelling text and visual stories. However, their outputs are predominantly aligned with the sensibilities of the Global North, often resulting in an outsider's gaze on other cultures. As a result, non-Western communities have to put extra effort into generating culturally specific stories. To address this challenge, we developed a visual storytelling pipeline called KAHANI that generates culturally grounded visual stories for non-Western cultures. Our pipeline leverages off-the-shelf models GPT-4 Turbo and Stable Diffusion XL (SDXL). By using Chain of Thought (CoT) and T2I prompting techniques, we capture the cultural context from user's prompt and generate vivid descriptions of the characters and scene compositions. To evaluate the effectiveness of KAHANI, we conducted a comparative user study with ChatGPT-4 (with DALL-E3) in which participants from different regions of India compared the cultural relevance of stories generated by the two tools. Results from the qualitative and quantitative analysis performed on the user study showed that KAHANI was able to capture and incorporate more Culturally Specific Items (CSIs) compared to ChatGPT-4. In terms of both its cultural competence and visual story generation quality, our pipeline outperformed ChatGPT-4 in 27 out of the 36 comparisons.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2410.19424",
        "abstract url": "https://arxiv.org/abs/2410.19424",
        "title": "Paint Bucket Colorization Using Anime Character Color Design Sheets",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Line art colorization plays a crucial role in hand-drawn animation production, where digital artists manually colorize segments using a paint bucket tool, guided by RGB values from character color design sheets. This process, often called paint bucket colorization, involves two main tasks: keyframe colorization, where colors are applied according to the character's color design sheet, and consecutive frame colorization, where these colors are replicated across adjacent frames. Current automated colorization methods primarily focus on reference-based and segment-matching approaches. However, reference-based methods often fail to accurately assign specific colors to each region, while matching-based methods are limited to consecutive frame colorization and struggle with issues like significant deformation and occlusion. In this work, we introduce inclusion matching, which allows the network to understand the inclusion relationships between segments, rather than relying solely on direct visual correspondences. By integrating this approach with segment parsing and color warping modules, our inclusion matching pipeline significantly improves performance in both keyframe colorization and consecutive frame colorization. To support our network's training, we have developed a unique dataset named PaintBucket-Character, which includes rendered line arts alongside their colorized versions and shading annotations for various 3D characters. To replicate industry animation data formats, we also created color design sheets for each character, with semantic information for each color and standard pose reference images. Experiments highlight the superiority of our method, demonstrating accurate and consistent colorization across both our proposed benchmarks and hand-drawn animations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Extension of arXiv:2403.18342; Project page at https://github.com/ykdai/BasicPBC"
    },
    {
        "paper id": "2410.19446",
        "abstract url": "https://arxiv.org/abs/2410.19446",
        "title": "Fusion-then-Distillation: Toward Cross-modal Positive Distillation for Domain Adaptive 3D Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In cross-modal unsupervised domain adaptation, a model trained on source-domain data (e.g., synthetic) is adapted to target-domain data (e.g., real-world) without access to target annotation. Previous methods seek to mutually mimic cross-modal outputs in each domain, which enforces a class probability distribution that is agreeable in different domains. However, they overlook the complementarity brought by the heterogeneous fusion in cross-modal learning. In light of this, we propose a novel fusion-then-distillation (FtD++) method to explore cross-modal positive distillation of the source and target domains for 3D semantic segmentation. FtD++ realizes distribution consistency between outputs not only for 2D images and 3D point clouds but also for source-domain and augment-domain. Specially, our method contains three key ingredients. First, we present a model-agnostic feature fusion module to generate the cross-modal fusion representation for establishing a latent space. In this space, two modalities are enforced maximum correlation and complementarity. Second, the proposed cross-modal positive distillation preserves the complete information of multi-modal input and combines the semantic content of the source domain with the style of the target domain, thereby achieving domain-modality alignment. Finally, cross-modal debiased pseudo-labeling is devised to model the uncertainty of pseudo-labels via a self-training manner. Extensive experiments report state-of-the-art results on several domain adaptive scenarios under unsupervised and semi-supervised settings. Code is available at https://github.com/Barcaaaa/FtD-PlusPlus.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19459",
        "abstract url": "https://arxiv.org/abs/2410.19459",
        "title": "Evaluation of strategies for efficient rate-distortion NeRF streaming",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRF) have revolutionized the field of 3D visual representation by enabling highly realistic and detailed scene reconstructions from a sparse set of images. NeRF uses a volumetric functional representation that maps 3D points to their corresponding colors and opacities, allowing for photorealistic view synthesis from arbitrary viewpoints. Despite its advancements, the efficient streaming of NeRF content remains a significant challenge due to the large amount of data involved. This paper investigates the rate-distortion performance of two NeRF streaming strategies: pixel-based and neural network (NN) parameter-based streaming. While in the former, images are coded and then transmitted throughout the network, in the latter, the respective NeRF model parameters are coded and transmitted instead. This work also highlights the trade-offs in complexity and performance, demonstrating that the NN parameter-based strategy generally offers superior efficiency, making it suitable for one-to-many streaming scenarios.",
        "subjects": [
            "cs.MM",
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19494",
        "abstract url": "https://arxiv.org/abs/2410.19494",
        "title": "Graph Linearization Methods for Reasoning on Graphs with Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models have evolved to process multiple modalities beyond text, such as images and audio, which motivates us to explore how to effectively leverage them for graph machine learning tasks. The key question, therefore, is how to transform graphs into linear sequences of tokens, a process we term graph linearization, so that LLMs can handle graphs naturally. We consider that graphs should be linearized meaningfully to reflect certain properties of natural language text, such as local dependency and global alignment, in order to ease contemporary LLMs, trained on trillions of textual tokens, better understand graphs. To achieve this, we developed several graph linearization methods based on graph centrality, degeneracy, and node relabeling schemes. We then investigated their effect on LLM performance in graph reasoning tasks. Experimental results on synthetic graphs demonstrate the effectiveness of our methods compared to random linearization baselines. Our work introduces novel graph representations suitable for LLMs, contributing to the potential integration of graph machine learning with the trend of multi-modal processing using a unified transformer model.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19552",
        "abstract url": "https://arxiv.org/abs/2410.19552",
        "title": "GeoLLaVA: Efficient Fine-Tuned Vision-Language Models for Temporal Change Detection in Remote Sensing",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Detecting temporal changes in geographical landscapes is critical for applications like environmental monitoring and urban planning. While remote sensing data is abundant, existing vision-language models (VLMs) often fail to capture temporal dynamics effectively. This paper addresses these limitations by introducing an annotated dataset of video frame pairs to track evolving geographical patterns over time. Using fine-tuning techniques like Low-Rank Adaptation (LoRA), quantized LoRA (QLoRA), and model pruning on models such as Video-LLaVA and LLaVA-NeXT-Video, we significantly enhance VLM performance in processing remote sensing temporal changes. Results show significant improvements, with the best performance achieving a BERT score of 0.864 and ROUGE-1 score of 0.576, demonstrating superior accuracy in describing land-use transformations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 5 figures, 3 tables"
    },
    {
        "paper id": "2410.19568",
        "abstract url": "https://arxiv.org/abs/2410.19568",
        "title": "Prediction of microstructural representativity from a single image",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this study, we present a method for predicting the representativity of the phase fraction observed in a single image (2D or 3D) of a material. Traditional approaches often require large datasets and extensive statistical analysis to estimate the Integral Range, a key factor in determining the variance of microstructural properties. Our method leverages the Two-Point Correlation function to directly estimate the variance from a single image (2D or 3D), thereby enabling phase fraction prediction with associated confidence levels. We validate our approach using open-source datasets, demonstrating its efficacy across diverse microstructures. This technique significantly reduces the data requirements for representativity analysis, providing a practical tool for material scientists and engineers working with limited microstructural data. To make the method easily accessible, we have created a web-application, \\url{www.imagerep.io}, for quick, simple and informative use of the method.",
        "subjects": [
            "stat.CO",
            "cs.CV",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19590",
        "abstract url": "https://arxiv.org/abs/2410.19590",
        "title": "MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Perspective projection has been extensively utilized in monocular 3D object detection methods. It introduces geometric priors from 2D bounding boxes and 3D object dimensions to reduce the uncertainty of depth estimation. However, due to depth errors originating from the object's visual surface, the height of the bounding box often fails to represent the actual projected central height, which undermines the effectiveness of geometric depth. Direct prediction for the projected height unavoidably results in a loss of 2D priors, while multi-depth prediction with complex branches does not fully leverage geometric depth. This paper presents a Transformer-based monocular 3D object detection method called MonoDGP, which adopts perspective-invariant geometry errors to modify the projection formula. We also try to systematically discuss and explain the mechanisms and efficacy behind geometry errors, which serve as a simple but effective alternative to multi-depth prediction. Additionally, MonoDGP decouples the depth-guided decoder and constructs a 2D decoder only dependent on visual features, providing 2D priors and initializing object queries without the disturbance of 3D detection. To further optimize and fine-tune input tokens of the transformer decoder, we also introduce a Region Segment Head (RSH) that generates enhanced features and segment embeddings. Our monocular method demonstrates state-of-the-art performance on the KITTI benchmark without extra data. Code is available at https://github.com/PuFanqi23/MonoDGP.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19604",
        "abstract url": "https://arxiv.org/abs/2410.19604",
        "title": "Microplastic Identification Using AI-Driven Image Segmentation and GAN-Generated Ecological Context",
        "rating": "0",
        "keywords": [
            [
                "GAN"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Current methods for microplastic identification in water samples are costly and require expert analysis. Here, we propose a deep learning segmentation model to automatically identify microplastics in microscopic images. We labeled images of microplastic from the Moore Institute for Plastic Pollution Research and employ a Generative Adversarial Network (GAN) to supplement and generate diverse training data. To verify the validity of the generated data, we conducted a reader study where an expert was able to discern the generated microplastic from real microplastic at a rate of 68 percent. Our segmentation model trained on the combined data achieved an F1-Score of 0.91 on a diverse dataset, compared to the model without generated data's 0.82. With our findings we aim to enhance the ability of both experts and citizens to detect microplastic across diverse ecological contexts, thereby improving the cost and accessibility of microplastic analysis.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "6 pages one figure"
    },
    {
        "paper id": "2410.19606",
        "abstract url": "https://arxiv.org/abs/2410.19606",
        "title": "Multi-modal Motion Prediction using Temporal Ensembling with Learning-based Aggregation",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent years have seen a shift towards learning-based methods for trajectory prediction, with challenges remaining in addressing uncertainty and capturing multi-modal distributions. This paper introduces Temporal Ensembling with Learning-based Aggregation, a meta-algorithm designed to mitigate the issue of missing behaviors in trajectory prediction, which leads to inconsistent predictions across consecutive frames. Unlike conventional model ensembling, temporal ensembling leverages predictions from nearby frames to enhance spatial coverage and prediction diversity. By confirming predictions from multiple frames, temporal ensembling compensates for occasional errors in individual frame predictions. Furthermore, trajectory-level aggregation, often utilized in model ensembling, is insufficient for temporal ensembling due to a lack of consideration of traffic context and its tendency to assign candidate trajectories with incorrect driving behaviors to final predictions. We further emphasize the necessity of learning-based aggregation by utilizing mode queries within a DETR-like architecture for our temporal ensembling, leveraging the characteristics of predictions from nearby frames. Our method, validated on the Argoverse 2 dataset, shows notable improvements: a 4% reduction in minADE, a 5% decrease in minFDE, and a 1.16% reduction in the miss rate compared to the strongest baseline, QCNet, highlighting its efficacy and potential in autonomous driving.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024), accepted by IROS2024"
    },
    {
        "paper id": "2410.19609",
        "abstract url": "https://arxiv.org/abs/2410.19609",
        "title": "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization",
        "rating": "0",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with the ability to explore environments and continuously improve over time, they are building text-only agents in synthetic environments where the reward signals are clearly defined. Such agents struggle to generalize to realistic settings that require multimodal perception abilities and lack ground-truth signals. In this paper, we introduce an open-source framework designed to facilitate the development of multimodal web agent that can autonomously conduct real-world exploration and improve itself. We first train the base model with imitation learning to gain the basic abilities. We then let the agent explore the open web and collect feedback on its trajectories. After that, it further improves its policy by learning from well-performing trajectories judged by another general-purpose model. This exploration-feedback-optimization cycle can continue for several iterations. Experimental results show that our web agent successfully improves itself after each iteration, demonstrating strong performance across multiple test sets.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19673",
        "abstract url": "https://arxiv.org/abs/2410.19673",
        "title": "Spatial Shortcuts in Graph Neural Controlled Differential Equations",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We incorporate prior graph topology information into a Neural Controlled Differential Equation (NCDE) to predict the future states of a dynamical system defined on a graph. The informed NCDE infers the future dynamics at the vertices of simulated advection data on graph edges with a known causal graph, observed only at vertices during training. We investigate different positions in the model architecture to inform the NCDE with graph information and identify an outer position between hidden state and control as theoretically and empirically favorable. Our such informed NCDE requires fewer parameters to reach a lower Mean Absolute Error (MAE) compared to previous methods that do not incorporate additional graph topology information.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Accepted as a workshop paper at the NeurIPS 2024 workshop on Data-driven and Differentiable Simulations, Surrogates, and Solvers (D3S3)"
    },
    {
        "paper id": "2410.19680",
        "abstract url": "https://arxiv.org/abs/2410.19680",
        "title": "Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors",
        "rating": "0",
        "keywords": [
            [
                "point cloud",
                "SDF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "It is important to estimate an accurate signed distance function (SDF) from a point cloud in many computer vision applications. The latest methods learn neural SDFs using either a data-driven based or an overfitting-based strategy. However, these two kinds of methods are with either poor generalization or slow convergence, which limits their capability under challenging scenarios like highly noisy point clouds. To resolve this issue, we propose a method to promote pros of both data-driven based and overfitting-based methods for better generalization, faster inference, and higher accuracy in learning neural SDFs. We introduce a novel statistical reasoning algorithm in local regions which is able to finetune data-driven based priors without signed distance supervision, clean point cloud, or point normals. This helps our method start with a good initialization, and converge to a minimum in a much faster way. Our numerical and visual comparisons with the state-of-the-art methods show our superiority over these methods in surface reconstruction and point cloud denoising on widely used shape and scene benchmarks. The code is available at https://github.com/chenchao15/LocalN2NM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by NeurlPS 2024. Project page: https://chenchao15.github.io/LocalN2NM/"
    },
    {
        "paper id": "2410.19687",
        "abstract url": "https://arxiv.org/abs/2410.19687",
        "title": "ProvocationProbe: Instigating Hate Speech Dataset from Twitter",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the recent years online social media platforms has been flooded with hateful remarks such as racism, sexism, homophobia etc. As a result, there have been many measures taken by various social media platforms to mitigate the spread of hate-speech over the internet. One particular concept within the domain of hate speech is instigating hate, which involves provoking hatred against a particular community, race, colour, gender, religion or ethnicity. In this work, we introduce \\textit{ProvocationProbe} - a dataset designed to explore what distinguishes instigating hate speech from general hate speech. For this study, we collected around twenty thousand tweets from Twitter, encompassing a total of nine global controversies. These controversies span various themes including racism, politics, and religion. In this paper, i) we present an annotated dataset after comprehensive examination of all the controversies, ii) we also highlight the difference between hate speech and instigating hate speech by identifying distinguishing features, such as targeted identity attacks and reasons for hate.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19727",
        "abstract url": "https://arxiv.org/abs/2410.19727",
        "title": "FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Financial intelligence generation from vast data sources has typically relied on traditional methods of knowledge-graph construction or database engineering. Recently, fine-tuned financial domain-specific Large Language Models (LLMs), have emerged. While these advancements are promising, limitations such as high inference costs, hallucinations, and the complexity of concurrently analyzing high-dimensional financial data, emerge. This motivates our invention FISHNET (Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert swarming, and Task planning), an agentic architecture that accomplishes highly complex analytical tasks for more than 98,000 regulatory filings that vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows remarkable performance for financial insight generation (61.8% success rate over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to empirically prove the success of FISHNET, each agent's importance, and the optimized performance of assembling all agents. Our modular architecture can be leveraged for a myriad of use-cases, enabling scalability, flexibility, and data integrity that are critical for financial tasks.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "Accepted at the 5th ACM International Conference on AI in Finance (ICAIF '24)"
    },
    {
        "paper id": "2410.19730",
        "abstract url": "https://arxiv.org/abs/2410.19730",
        "title": "Counting Ability of Large Language Models and Impact of Tokenization",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Transformers, the backbone of modern large language models (LLMs), face inherent architectural limitations that impede their reasoning capabilities. Unlike recurrent networks, Transformers lack recurrent connections, confining them to constant-depth computation. This restriction places them in the complexity class TC$^0$, making them theoretically incapable of solving tasks that demand increasingly deep reasoning as input length grows. Counting, a fundamental component of many reasoning tasks, also requires reasoning depth to grow linearly to be performed inductively. While previous studies have established the upper limits of counting ability in Transformer-based expert models (i.e., models specifically trained for counting tasks), these findings do not directly extend to general-purpose LLMs due to differences in reasoning mechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoning can help alleviate some of the architectural limitations of Transformers in counting tasks. However, little attention has been paid to the role of tokenization in these models. Unlike expert models that often use character-level tokenization, LLMs typically rely on byte-level (BPE) tokenizers, which fundamentally alters the way reasoning is processed. Our work investigates the impact of tokenization on the counting abilities of LLMs, uncovering substantial performance variations based on input tokenization differences. We provide both theoretical and experimental analyses, offering insights into how tokenization choices can undermine models' theoretical computability, thereby inspiring the design of new tokenization methods to enhance reasoning in LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19932",
        "abstract url": "https://arxiv.org/abs/2410.19932",
        "title": "Tracking and triangulating firefly flashes in field recordings",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Identifying firefly flashes from other bright features in nature images is complicated. I provide a training dataset and trained neural networks for reliable flash classification. The training set consists of thousands of cropped images (patches) extracted by manual labeling from video recordings of fireflies in their natural habitat. The trained network appears as considerably more reliable to differentiate flashes from other sources of light compared to traditional methods relying solely on intensity thresholding. This robust tracking enables a new calibration-free method for the 3D reconstruction of flash occurrences from stereoscopic 360-degree videos, which I also present here.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19937",
        "abstract url": "https://arxiv.org/abs/2410.19937",
        "title": "RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Jailbreak attacks circumvent LLMs' built-in safeguards by concealing harmful queries within jailbreak prompts. While existing defenses primarily focus on mitigating the effects of jailbreak prompts, they often prove inadequate as jailbreak prompts can take arbitrary, adaptive forms. This paper presents RobustKV, a novel defense that adopts a fundamentally different approach by selectively removing critical tokens of harmful queries from key-value (KV) caches. Intuitively, for a jailbreak prompt to be effective, its tokens must achieve sufficient `importance' (as measured by attention scores), which inevitably lowers the importance of tokens in the concealed harmful query. Thus, by strategically evicting the KVs of the lowest-ranked tokens, RobustKV diminishes the presence of the harmful query in the KV cache, thus preventing the LLM from generating malicious responses. Extensive evaluation using benchmark datasets and models demonstrates that RobustKV effectively counters state-of-the-art jailbreak attacks while maintaining the LLM's general performance on benign queries. Moreover, RobustKV creates an intriguing evasiveness dilemma for adversaries, forcing them to balance between evading RobustKV and bypassing the LLM's built-in safeguards. This trade-off contributes to RobustKV's robustness against adaptive attacks. (warning: this paper contains potentially harmful content generated by LLMs.)",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19954",
        "abstract url": "https://arxiv.org/abs/2410.19954",
        "title": "Turn-by-Turn Indoor Navigation for the Visually Impaired",
        "rating": "0",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Navigating indoor environments presents significant challenges for visually impaired individuals due to complex layouts and the absence of GPS signals. This paper introduces a novel system that provides turn-by-turn navigation inside buildings using only a smartphone equipped with a camera, leveraging multimodal models, deep learning algorithms, and large language models (LLMs). The smartphone's camera captures real-time images of the surroundings, which are then sent to a nearby Raspberry Pi capable of running on-device LLM models, multimodal models, and deep learning algorithms to detect and recognize architectural features, signage, and obstacles. The interpreted visual data is then translated into natural language instructions by an LLM running on the Raspberry Pi, which is sent back to the user, offering intuitive and context-aware guidance via audio prompts. This solution requires minimal workload on the user's device, preventing it from being overloaded and offering compatibility with all types of devices, including those incapable of running AI models. This approach enables the client to not only run advanced models but also ensure that the training data and other information do not leave the building. Preliminary evaluations demonstrate the system's effectiveness in accurately guiding users through complex indoor spaces, highlighting its potential for widespread application",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20018",
        "abstract url": "https://arxiv.org/abs/2410.20018",
        "title": "GHIL-Glue: Hierarchical Control with Filtered Subgoal Images",
        "rating": "0",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Image and video generative models that are pre-trained on Internet-scale data can greatly increase the generalization capacity of robot learning systems. These models can function as high-level planners, generating intermediate subgoals for low-level goal-conditioned policies to reach. However, the performance of these systems can be greatly bottlenecked by the interface between generative models and low-level controllers. For example, generative models may predict photorealistic yet physically infeasible frames that confuse low-level policies. Low-level policies may also be sensitive to subtle visual artifacts in generated goal images. This paper addresses these two facets of generalization, providing an interface to effectively \"glue together\" language-conditioned image or video prediction models with low-level goal-conditioned policies. Our method, Generative Hierarchical Imitation Learning-Glue (GHIL-Glue), filters out subgoals that do not lead to task progress and improves the robustness of goal-conditioned policies to generated subgoals with harmful visual artifacts. We find in extensive experiments in both simulated and real environments that GHIL-Glue achieves a 25% improvement across several hierarchical models that leverage generative subgoals, achieving a new state-of-the-art on the CALVIN simulation benchmark for policies using observations from a single RGB camera. GHIL-Glue also outperforms other generalist robot policies across 3/4 language-conditioned manipulation tasks testing zero-shot generalization in physical experiments.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Code, model checkpoints and videos can be found at https://ghil-glue.github.io"
    },
    {
        "paper id": "2410.21313",
        "abstract url": "https://arxiv.org/abs/2410.21313",
        "title": "Towards Robust Out-of-Distribution Generalization: Data Augmentation and Neural Architecture Search Approaches",
        "rating": "0",
        "keywords": [
            [
                "Architecture Search"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning has been demonstrated with tremendous success in recent years. Despite so, its performance in practice often degenerates drastically when encountering out-of-distribution (OoD) data, i.e. training and test data are sampled from different distributions. In this thesis, we study ways toward robust OoD generalization for deep learning, i.e., its performance is not susceptible to distribution shift in the test data. We first propose a novel and effective approach to disentangle the spurious correlation between features that are not essential for recognition. It employs decomposed feature representation by orthogonalizing the two gradients of losses for category and context branches. Furthermore, we perform gradient-based augmentation on context-related features (e.g., styles, backgrounds, or scenes of target objects) to improve the robustness of learned representations. Results show that our approach generalizes well for different distribution shifts. We then study the problem of strengthening neural architecture search in OoD scenarios. We propose to optimize the architecture parameters that minimize the validation loss on synthetic OoD data, under the condition that corresponding network parameters minimize the training loss. Moreover, to obtain a proper validation set, we learn a conditional generator by maximizing their losses computed by different neural architectures. Results show that our approach effectively discovers robust architectures that perform well for OoD generalization.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Hong Kong University of Science and Technology Thesis"
    },
    {
        "paper id": "2410.21314",
        "abstract url": "https://arxiv.org/abs/2410.21314",
        "title": "Decoding Diffusion: A Scalable Framework for Unsupervised Analysis of Latent Space Biases and Representations Using Natural Language Prompts",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in image generation have made diffusion models powerful tools for creating high-quality images. However, their iterative denoising process makes understanding and interpreting their semantic latent spaces more challenging than other generative models, such as GANs. Recent methods have attempted to address this issue by identifying semantically meaningful directions within the latent space. However, they often need manual interpretation or are limited in the number of vectors that can be trained, restricting their scope and utility. This paper proposes a novel framework for unsupervised exploration of diffusion latent spaces. We directly leverage natural language prompts and image captions to map latent directions. This method allows for the automatic understanding of hidden features and supports a broader range of analysis without the need to train specific vectors. Our method provides a more scalable and interpretable understanding of the semantic knowledge encoded within diffusion models, facilitating comprehensive analysis of latent biases and the nuanced representations these models learn. Experimental results show that our framework can uncover hidden patterns and associations in various domains, offering new insights into the interpretability of diffusion model latent spaces.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.21315",
        "abstract url": "https://arxiv.org/abs/2410.21315",
        "title": "GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Heterogeneous graph neural networks have recently gained attention for long document summarization, modeling the extraction as a node classification task. Although effective, these models often require external tools or additional machine learning models to define graph components, producing highly complex and less intuitive structures. We present GraphLSS, a heterogeneous graph construction for long document extractive summarization, incorporating Lexical, Structural, and Semantic features. It defines two levels of information (words and sentences) and four types of edges (sentence semantic similarity, sentence occurrence order, word in sentence, and word semantic similarity) without any need for auxiliary learning models. Experiments on two benchmark datasets show that GraphLSS is competitive with top-performing graph-based methods, outperforming recent non-graph models. We release our code on GitHub.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Short paper submitted to ACL ARR November cycle"
    },
    {
        "paper id": "2410.19321",
        "abstract url": "https://arxiv.org/abs/2410.19321",
        "title": "Free-Rider and Conflict Aware Collaboration Formation for Cross-Silo Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated learning (FL) is a machine learning paradigm that allows multiple FL participants (FL-PTs) to collaborate on training models without sharing private data. Due to data heterogeneity, negative transfer may occur in the FL training process. This necessitates FL-PT selection based on their data complementarity. In cross-silo FL, organizations that engage in business activities are key sources of FL-PTs. The resulting FL ecosystem has two features: (i) self-interest, and (ii) competition among FL-PTs. This requires the desirable FL-PT selection strategy to simultaneously mitigate the problems of free riders and conflicts of interest among competitors. To this end, we propose an optimal FL collaboration formation strategy -- FedEgoists -- which ensures that: (1) a FL-PT can benefit from FL if and only if it benefits the FL ecosystem, and (2) a FL-PT will not contribute to its competitors or their supporters. It provides an efficient clustering solution to group FL-PTs into coalitions, ensuring that within each coalition, FL-PTs share the same interest. We theoretically prove that the FL-PT coalitions formed are optimal since no coalitions can collaborate together to improve the utility of any of their members. Extensive experiments on widely adopted benchmark datasets demonstrate the effectiveness of FedEgoists compared to nine state-of-the-art baseline methods, and its ability to establish efficient collaborative networks in cross-silos FL with FL-PTs that engage in business activities.",
        "subjects": [
            "cs.GT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19323",
        "abstract url": "https://arxiv.org/abs/2410.19323",
        "title": "Double Difference Earthquake Location with Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Double difference earthquake relocation is an essential component of many earthquake catalog development workflows. This technique produces high-resolution relative relocations between events by minimizing differential measurements of the arrival times of waves from nearby sources, which highlights the resolution of faults and improves interpretation of seismic activity. The inverse problem is typically solved iteratively using conjugate-gradient minimization, however the cost scales significantly with the total number of sources and stations considered. Here we propose a Graph Neural Network (GNN) based earthquake double-difference relocation framework, Graph Double Difference (GraphDD), that is trained to minimize the double-difference residuals of a catalog to locate earthquakes. Through batching and sampling the method can scale to arbitrarily large catalogs. Our architecture uses one graph to represent the stations, a second graph to represent the sources, and creates the Cartesian product graph between the two graphs to capture the relationships between the stations and sources (e.g., the residuals and travel time partial derivatives). This key feature allows a natural architecture that can be used to minimize the double-difference residuals. We implement our model on several distinct test cases including seismicity from northern California, Turkiye, and northern Chile, which have highly variable data quality, and station and source distributions. We obtain high resolution relocations in these tests, and our model shows adaptability to variable types of loss functions and location objectives, including learning station corrections and mapping into the reference frame of a different catalog. Our results suggest that a GNN approach to double-difference relocation is a promising direction for scaling to very large catalogs and gaining new insights into the relocation problem.",
        "subjects": [
            "physics.geo-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19449",
        "abstract url": "https://arxiv.org/abs/2410.19449",
        "title": "Learned Reference-based Diffusion Sampling for multi-modal distributions",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Over the past few years, several approaches utilizing score-based diffusion have been proposed to sample from probability distributions, that is without having access to exact samples and relying solely on evaluations of unnormalized densities. The resulting samplers approximate the time-reversal of a noising diffusion process, bridging the target distribution to an easy-to-sample base distribution. In practice, the performance of these methods heavily depends on key hyperparameters that require ground truth samples to be accurately tuned. Our work aims to highlight and address this fundamental issue, focusing in particular on multi-modal distributions, which pose significant challenges for existing sampling methods. Building on existing approaches, we introduce Learned Reference-based Diffusion Sampler (LRDS), a methodology specifically designed to leverage prior knowledge on the location of the target modes in order to bypass the obstacle of hyperparameter tuning. LRDS proceeds in two steps by (i) learning a reference diffusion model on samples located in high-density space regions and tailored for multimodality, and (ii) using this reference model to foster the training of a diffusion-based sampler. We experimentally demonstrate that LRDS best exploits prior knowledge on the target distribution compared to competing algorithms on a variety of challenging distributions.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2410.19464",
        "abstract url": "https://arxiv.org/abs/2410.19464",
        "title": "LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Discovering the underlying Directed Acyclic Graph (DAG) from time series observational data is highly challenging due to the dynamic nature and complex nonlinear interactions between variables. Existing methods often struggle with inefficiency and the handling of high-dimensional data. To address these research gap, we propose LOCAL, a highly efficient, easy-to-implement, and constraint-free method for recovering dynamic causal structures. LOCAL is the first attempt to formulate a quasi-maximum likelihood-based score function for learning the dynamic DAG equivalent to the ground truth. On this basis, we propose two adaptive modules for enhancing the algebraic characterization of acyclicity with new capabilities: Asymptotic Causal Mask Learning (ACML) and Dynamic Graph Parameter Learning (DGPL). ACML generates causal masks using learnable priority vectors and the Gumbel-Sigmoid function, ensuring the creation of DAGs while optimizing computational efficiency. DGPL transforms causal learning into decomposed matrix products, capturing the dynamic causal structure of high-dimensional data and enhancing interpretability. Extensive experiments on synthetic and real-world datasets demonstrate that LOCAL significantly outperforms existing methods, and highlight LOCAL's potential as a robust and efficient method for dynamic causal discovery. Our code will be available soon.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "10 pages, 7 figures"
    },
    {
        "paper id": "2410.19514",
        "abstract url": "https://arxiv.org/abs/2410.19514",
        "title": "Parametric Nonlinear Volterra Series via Machine Learning: Transonic Aerodynamics",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study introduces an approach for modeling unsteady transonic aerodynamics within a parametric space, using Volterra series to capture aerodynamic responses and machine learning to enable interpolation. The first- and second-order Volterra kernels are derived from indicial aerodynamic responses obtained through computational fluid dynamics, with the second-order kernel calculated as a correction to the dominant linear response. Machine learning algorithms, specifically artificial neural network and Gaussian process regression, are used to interpolate kernel coefficients within a parameter space defined by Mach number and angle of attack. The methodology is applied to two and three dimensional test cases in the transonic regime. Results underscore the benefit of including the second-order kernel to address strong nonlinearity and demonstrate the effectiveness of neural networks. The approach achieves a level of accuracy that appears sufficient for use in conceptual design.",
        "subjects": [
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19550",
        "abstract url": "https://arxiv.org/abs/2410.19550",
        "title": "DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Software defect prediction (SDP) aims to identify high-risk defect modules in software development, optimizing resource allocation. While previous studies show that dependency network metrics improve defect prediction, most methods focus on code-based dependency graphs, overlooking developer factors. Current metrics, based on handcrafted features like ego and global network metrics, fail to fully capture defect-related information. To address this, we propose DeMuVGN, a defect prediction model that learns multi-view software dependency via graph neural networks. We introduce a Multi-view Software Dependency Graph (MSDG) that integrates data, call, and developer dependencies. DeMuVGN also leverages the Synthetic Minority Oversampling Technique (SMOTE) to address class imbalance and enhance defect module identification. In a case study of eight open-source projects across 20 versions, DeMuVGN demonstrates significant improvements: i) models based on multi-view graphs improve F1 scores by 11.1% to 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to 45.8% in within-project contexts and by 17.9% to 41.0% in cross-project contexts. Additionally, DeMuVGN excels in software evolution, showing more improvement in later-stage software versions. Its strong performance across different projects highlights its generalizability. We recommend future research focus on multi-view dependency graphs for defect prediction in both mature and newly developed projects.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19607",
        "abstract url": "https://arxiv.org/abs/2410.19607",
        "title": "Analyzing Neural Network Robustness Using Graph Curvature",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a new look at the neural network (NN) robustness problem, from the point of view of graph theory analysis, specifically graph curvature. Graph curvature (e.g., Ricci curvature) has been used to analyze system dynamics and identify bottlenecks in many domains, including road traffic analysis and internet routing. We define the notion of neural Ricci curvature and use it to identify bottleneck NN edges that are heavily used to ``transport data\" to the NN outputs. We provide an evaluation on MNIST that illustrates that such edges indeed occur more frequently for inputs where NNs are less robust. These results will serve as the basis for an alternative method of robust training, by minimizing the number of bottleneck edges.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19612",
        "abstract url": "https://arxiv.org/abs/2410.19612",
        "title": "Shared Control with Black Box Agents using Oracle Queries",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Shared control problems involve a robot learning to collaborate with a human. When learning a shared control policy, short communication between the agents can often significantly reduce running times and improve the system's accuracy. We extend the shared control problem to include the ability to directly query a cooperating agent. We consider two types of potential responses to a query, namely oracles: one that can provide the learner with the best action they should take, even when that action might be myopically wrong, and one with a bounded knowledge limited to its part of the system. Given this additional information channel, this work further presents three heuristics for choosing when to query: reinforcement learning-based, utility-based, and entropy-based. These heuristics aim to reduce a system's overall learning cost. Empirical results on two environments show the benefits of querying to learn a better control policy and the tradeoffs between the proposed heuristics.",
        "subjects": [
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19657",
        "abstract url": "https://arxiv.org/abs/2410.19657",
        "title": "DiffGS: Functional Gaussian Splatting Diffusion",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "3D Gaussian Splatting (3DGS) has shown convincing performance in rendering speed and fidelity, yet the generation of Gaussian Splatting remains a challenge due to its discreteness and unstructured nature. In this work, we propose DiffGS, a general Gaussian generator based on latent diffusion models. DiffGS is a powerful and efficient 3D generative model which is capable of generating Gaussian primitives at arbitrary numbers for high-fidelity rendering with rasterization. The key insight is to represent Gaussian Splatting in a disentangled manner via three novel functions to model Gaussian probabilities, colors and transforms. Through the novel disentanglement of 3DGS, we represent the discrete and unstructured 3DGS with continuous Gaussian Splatting functions, where we then train a latent diffusion model with the target of generating these Gaussian Splatting functions both unconditionally and conditionally. Meanwhile, we introduce a discretization algorithm to extract Gaussians at arbitrary numbers from the generated functions via octree-guided sampling and optimization. We explore DiffGS for various tasks, including unconditional generation, conditional generation from text, image, and partial 3DGS, as well as Point-to-Gaussian generation. We believe that DiffGS provides a new direction for flexibly modeling and generating Gaussian Splatting.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by NeurIPS 2024. Project page: https://junshengzhou.github.io/DiffGS"
    },
    {
        "paper id": "2410.19685",
        "abstract url": "https://arxiv.org/abs/2410.19685",
        "title": "The Sound of Silence in Social Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "We generalize the classic multi-agent DeGroot model for opinion dynamics to incorporate the Spiral of Silence theory from political science. This theory states that individuals may withhold their opinions when they perceive them to be in the minority. As in the DeGroot model, a community of agents is represented as a weighted directed graph whose edges indicate how much agents influence one another. However, agents whose current opinions are in the minority become silent (i.e., they do not express their opinion). Two models for opinion update are then introduced. In the memoryless opinion model ($\\mbox{SOM}^-$), agents update their opinion by taking the weighted average of their non-silent neighbors' opinions. In the memory based opinion model ($\\mbox{SOM}^+$), agents update their opinions by taking the weighted average of the opinions of all their neighbors, but for silent neighbors, their most recent opinion is considered. We show that for $\\mbox{SOM}^-$ convergence to consensus is guaranteed for clique graphs but, unlike for the classic DeGroot, not guaranteed for strongly-connected aperiodic graphs. In contrast, we show that for $\\mbox{SOM}^+$ convergence to consensus is not guaranteed even for clique graphs. We showcase our models through simulations offering experimental insights that align with key aspects of the Spiral of Silence theory. These findings reveal the impact of silence dynamics on opinion formation and highlight the limitations of consensus in more nuanced social models.",
        "subjects": [
            "cs.MA",
            "cs.SI"
        ],
        "comment": "20 pages and 5 figures"
    },
    {
        "paper id": "2410.19693",
        "abstract url": "https://arxiv.org/abs/2410.19693",
        "title": "MILES: Making Imitation Learning Easy with Self-Supervision",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Data collection in imitation learning often requires significant, laborious human supervision, such as numerous demonstrations, and/or frequent environment resets for methods that incorporate reinforcement learning. In this work, we propose an alternative approach, MILES: a fully autonomous, self-supervised data collection paradigm, and we show that this enables efficient policy learning from just a single demonstration and a single environment reset. MILES autonomously learns a policy for returning to and then following the single demonstration, whilst being self-guided during data collection, eliminating the need for additional human interventions. We evaluated MILES across several real-world tasks, including tasks that require precise contact-rich manipulation such as locking a lock with a key. We found that, under the constraints of a single demonstration and no repeated environment resetting, MILES significantly outperforms state-of-the-art alternatives like imitation learning methods that leverage reinforcement learning. Videos of our experiments and code can be found on our webpage: www.robot-learning.uk/miles.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Published at the Conference on Robot Learning (CoRL) 2024"
    },
    {
        "paper id": "2410.19705",
        "abstract url": "https://arxiv.org/abs/2410.19705",
        "title": "Robust Thompson Sampling Algorithms Against Reward Poisoning Attacks",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Thompson sampling is one of the most popular learning algorithms for online sequential decision-making problems and has rich real-world applications. However, current Thompson sampling algorithms are limited by the assumption that the rewards received are uncorrupted, which may not be true in real-world applications where adversarial reward poisoning exists. To make Thompson sampling more reliable, we want to make it robust against adversarial reward poisoning. The main challenge is that one can no longer compute the actual posteriors for the true reward, as the agent can only observe the rewards after corruption. In this work, we solve this problem by computing pseudo-posteriors that are less likely to be manipulated by the attack. We propose robust algorithms based on Thompson sampling for the popular stochastic and contextual linear bandit settings in both cases where the agent is aware or unaware of the budget of the attacker. We theoretically show that our algorithms guarantee near-optimal regret under any attack strategy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19715",
        "abstract url": "https://arxiv.org/abs/2410.19715",
        "title": "Adversarial Environment Design via Regret-Guided Diffusion Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Training agents that are robust to environmental changes remains a significant challenge in deep reinforcement learning (RL). Unsupervised environment design (UED) has recently emerged to address this issue by generating a set of training environments tailored to the agent's capabilities. While prior works demonstrate that UED has the potential to learn a robust policy, their performance is constrained by the capabilities of the environment generation. To this end, we propose a novel UED algorithm, adversarial environment design via regret-guided diffusion models (ADD). The proposed method guides the diffusion-based environment generator with the regret of the agent to produce environments that the agent finds challenging but conducive to further improvement. By exploiting the representation power of diffusion models, ADD can directly generate adversarial environments while maintaining the diversity of training environments, enabling the agent to effectively learn a robust policy. Our experimental results demonstrate that the proposed method successfully generates an instructive curriculum of environments, outperforming UED baselines in zero-shot generalization across novel, out-of-distribution environments. Project page: https://github.com/rllab-snu.github.io/projects/ADD",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "38th Conference on Neural Information Processing Systems"
    },
    {
        "paper id": "2410.19718",
        "abstract url": "https://arxiv.org/abs/2410.19718",
        "title": "Evolving Neural Networks Reveal Emergent Collective Behavior from Minimal Agent Interactions",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Understanding the mechanisms behind emergent behaviors in multi-agent systems is critical for advancing fields such as swarm robotics and artificial intelligence. In this study, we investigate how neural networks evolve to control agents' behavior in a dynamic environment, focusing on the relationship between the network's complexity and collective behavior patterns. By performing quantitative and qualitative analyses, we demonstrate that the degree of network non-linearity correlates with the complexity of emergent behaviors. Simpler behaviors, such as lane formation and laminar flow, are characterized by more linear network operations, while complex behaviors like swarming and flocking show highly non-linear neural processing. Moreover, specific environmental parameters, such as moderate noise, broader field of view, and lower agent density, promote the evolution of non-linear networks that drive richer, more intricate collective behaviors. These results highlight the importance of tuning evolutionary conditions to induce desired behaviors in multi-agent systems, offering new pathways for optimizing coordination in autonomous swarms. Our findings contribute to a deeper understanding of how neural mechanisms influence collective dynamics, with implications for the design of intelligent, self-organizing systems.",
        "subjects": [
            "nlin.AO",
            "cs.AI",
            "cs.MA"
        ],
        "comment": "25 pages, 9 figures"
    },
    {
        "paper id": "2410.19931",
        "abstract url": "https://arxiv.org/abs/2410.19931",
        "title": "Provable optimal transport with transformers: The essence of depth and prompt engineering",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Can we establish provable performance guarantees for transformers? Establishing such theoretical guarantees is a milestone in developing trustworthy generative AI. In this paper, we take a step toward addressing this question by focusing on optimal transport, a fundamental problem at the intersection of combinatorial and continuous optimization. Leveraging the computational power of attention layers, we prove that a transformer with fixed parameters can effectively solve the optimal transport problem in Wasserstein-2 with entropic regularization for an arbitrary number of points. Consequently, the transformer can sort lists of arbitrary sizes up to an approximation factor. Our results rely on an engineered prompt that enables the transformer to implement gradient descent with adaptive stepsizes on the dual optimal transport. Combining the convergence analysis of gradient descent with Sinkhorn dynamics, we establish an explicit approximation bound for optimal transport with transformers, which improves as depth increases. Our findings provide novel insights into the essence of prompt engineering and depth for solving optimal transport. In particular, prompt engineering boosts the algorithmic expressivity of transformers, allowing them implement an optimization method. With increasing depth, transformers can simulate several iterations of gradient descent.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19966",
        "abstract url": "https://arxiv.org/abs/2410.19966",
        "title": "Maximizing User Engagement in Social Networks: A Game-Theoretic Approach to Network Participation and Resource Sharing",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "We propose a game-theoretic framework to model and optimize user engagement in cooperative activities over social networks. While traditional diffusion models suggest that individuals are only influenced by their neighbors, empirical evidence shows that diffusion alone does not fully explain network evolution, and non-diffusion factors play a significant role in network growth. We model network participation and resource-sharing as strategic games involving boundedly rational players to address this gap between the analytical models and empirical evidence. Specifically, we employ Log-Linear Learning (LLL), a version of noisy best response, to capture players' decision-making strategies. By incorporating stochastic decision models like LLL, our framework integrates both diffusion and non-diffusion dynamics into network evolution dynamics. Through equilibrium analysis and simulations, we demonstrate that our model aligns with theoretical predictions from existing analytical frameworks and empirical observations across various initial network configurations. Our second contribution is a novel method for selecting anchor nodes to enhance user participation. This approach allows system designers to identify anchor nodes and compute their incentives in real time under a more realistic information requirement constraints as compared to the existing approaches. The proposed approach adapts to changing network conditions by reallocating resources from less impactful to more influential nodes. Furthermore, the method is resilient to anchor node failures, ensuring sustained and continuous network participation.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "16 pages, 8 figures"
    },
    {
        "paper id": "2410.19978",
        "abstract url": "https://arxiv.org/abs/2410.19978",
        "title": "Global Graph Counterfactual Explanation: A Subgraph Mapping Approach",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have been widely deployed in various real-world applications. However, most GNNs are black-box models that lack explanations. One strategy to explain GNNs is through counterfactual explanation, which aims to find minimum perturbations on input graphs that change the GNN predictions. Existing works on GNN counterfactual explanations primarily concentrate on the local-level perspective (i.e., generating counterfactuals for each individual graph), which suffers from information overload and lacks insights into the broader cross-graph relationships. To address such issues, we propose GlobalGCE, a novel global-level graph counterfactual explanation method. GlobalGCE aims to identify a collection of subgraph mapping rules as counterfactual explanations for the target GNN. According to these rules, substituting certain significant subgraphs with their counterfactual subgraphs will change the GNN prediction to the desired class for most graphs (i.e., maximum coverage). Methodologically, we design a significant subgraph generator and a counterfactual subgraph autoencoder in our GlobalGCE, where the subgraphs and the rules can be effectively generated. Extensive experiments demonstrate the superiority of our GlobalGCE compared to existing baselines. Our code can be found at https://anonymous.4open.science/r/GlobalGCE-92E8.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19986",
        "abstract url": "https://arxiv.org/abs/2410.19986",
        "title": "Resolving Domain Shift For Representations Of Speech In Non-Invasive Brain Recordings",
        "rating": "-0.5",
        "keywords": [
            [
                "surgical"
            ],
            [
                "cs.LG",
                "eess.IV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Machine learning techniques have enabled researchers to leverage neuroimaging data to decode speech from brain activity, with some amazing recent successes achieved by applications built using invasive devices. However, research requiring surgical implants has a number of practical limitations. Non-invasive neuroimaging techniques provide an alternative but come with their own set of challenges, the limited scale of individual studies being among them. Without the ability to pool the recordings from different non-invasive studies, data on the order of magnitude needed to leverage deep learning techniques to their full potential remains out of reach. In this work, we focus on non-invasive data collected using magnetoencephalography (MEG). We leverage two different, leading speech decoding models to investigate how an adversarial domain adaptation framework augments their ability to generalize across datasets. We successfully improve the performance of both models when training across multiple datasets. To the best of our knowledge, this study is the first ever application of feature-level, deep learning based harmonization for MEG neuroimaging data. Our analysis additionally offers further evidence of the impact of demographic features on neuroimaging data, demonstrating that participant age strongly affects how machine learning models solve speech decoding tasks using MEG data. Lastly, in the course of this study we produce a new open-source implementation of one of these models to the benefit of the broader scientific community.",
        "subjects": [
            "cs.LG",
            "eess.IV",
            "q-bio.NC"
        ],
        "comment": "Submitted to ICLR 2025"
    },
    {
        "paper id": "2410.20034",
        "abstract url": "https://arxiv.org/abs/2410.20034",
        "title": "Sensor2Text: Enabling Natural Language Interactions for Daily Activity Tracking Using Wearable Sensors",
        "rating": "-0.5",
        "keywords": [
            [
                "visual-language"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Visual Question-Answering, a technology that generates textual responses from an image and natural language question, has progressed significantly. Notably, it can aid in tracking and inquiring about daily activities, crucial in healthcare monitoring, especially for elderly patients or those with memory disabilities. However, video poses privacy concerns and has a limited field of view. This paper presents Sensor2Text, a model proficient in tracking daily activities and engaging in conversations using wearable sensors. The approach outlined here tackles several challenges, including low information density in wearable sensor data, insufficiency of single wearable sensors in human activities recognition, and model's limited capacity for Question-Answering and interactive conversations. To resolve these obstacles, transfer learning and student-teacher networks are utilized to leverage knowledge from visual-language models. Additionally, an encoder-decoder neural network model is devised to jointly process language and sensor data for conversational purposes. Furthermore, Large Language Models are also utilized to enable interactive capabilities. The model showcases the ability to identify human activities and engage in Q\\&A dialogues using various wearable sensor modalities. It performs comparably to or better than existing visual-language models in both captioning and conversational tasks. To our knowledge, this represents the first model capable of conversing about wearable sensor data, offering an innovative approach to daily activity tracking that addresses privacy and field-of-view limitations associated with current vision-based solutions.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20038",
        "abstract url": "https://arxiv.org/abs/2410.20038",
        "title": "Revisiting PlayeRank",
        "rating": "-0.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this article we revise the football's performance score called PlayeRank, designed and evaluated by Pappalardo et al.\\ in 2019. First, we analyze the weights extracted from the Linear Support Vector Machine (SVM) that solves the classification problem of \"which set of events has a higher impact on the chances of winning a match\". Here, we notice that the previously published results include the Goal-Scored event during the training phase, which produces inconsistencies. We fix these inconsistencies, and show new weights capable of solving the same problem. Following the intuition that the best team should always win a match, we define the team's quality as the average number of players involved in the game. We show that, using the original PlayeRank, in 94.13\\% of the matches either the superior team beats the inferior team or the teams end tied if the scores are similar. Finally, we present a way to use PlayeRank in an online fashion using modified free analysis tools. Calculating this modified version of PlayeRank, we performed an online analysis of a real football match every five minutes of game. Here, we evaluate the usefulness of that information with experts and managers, and conclude that the obtained data indeed provides useful information that was not previously available to the manager during the match.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20053",
        "abstract url": "https://arxiv.org/abs/2410.20053",
        "title": "LinBridge: A Learnable Framework for Interpreting Nonlinear Neural Encoding Models",
        "rating": "-0.5",
        "keywords": [
            [
                "fMRI"
            ],
            [
                "cs.CL"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Neural encoding of artificial neural networks (ANNs) links their computational representations to brain responses, offering insights into how the brain processes information. Current studies mostly use linear encoding models for clarity, even though brain responses are often nonlinear. This has sparked interest in developing nonlinear encoding models that are still interpretable. To address this problem, we propose LinBridge, a learnable and flexible framework based on Jacobian analysis for interpreting nonlinear encoding models. LinBridge posits that the nonlinear mapping between ANN representations and neural responses can be factorized into a linear inherent component that approximates the complex nonlinear relationship, and a mapping bias that captures sample-selective nonlinearity. The Jacobian matrix, which reflects output change rates relative to input, enables the analysis of sample-selective mapping in nonlinear models. LinBridge employs a self-supervised learning strategy to extract both the linear inherent component and nonlinear mapping biases from the Jacobian matrices of the test set, allowing it to adapt effectively to various nonlinear encoding models. We validate the LinBridge framework in the scenario of neural visual encoding, using computational visual representations from CLIP-ViT to predict brain activity recorded via functional magnetic resonance imaging (fMRI). Our experimental results demonstrate that: 1) the linear inherent component extracted by LinBridge accurately reflects the complex mappings of nonlinear neural encoding models; 2) the sample-selective mapping bias elucidates the variability of nonlinearity across different levels of the visual processing hierarchy. This study presents a novel tool for interpreting nonlinear neural encoding models and offers fresh evidence about hierarchical nonlinearity distribution in the visual cortex.",
        "subjects": [
            "q-bio.NC",
            "cs.CL"
        ],
        "comment": "9 pages of main text, 23 pages total, submitted to ICLR 2025 and currently under review"
    },
    {
        "paper id": "2410.20054",
        "abstract url": "https://arxiv.org/abs/2410.20054",
        "title": "Evaluating Neural Networks for Early Maritime Threat Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We consider the task of classifying trajectories of boat activities as a proxy for assessing maritime threats. Previous approaches have considered entropy-based metrics for clustering boat activity into three broad categories: random walk, following, and chasing. Here, we comprehensively assess the accuracy of neural network-based approaches as alternatives to entropy-based clustering. We train four neural network models and compare them to shallow learning using synthetic data. We also investigate the accuracy of models as time steps increase and with and without rotated data. To improve test-time robustness, we normalize trajectories and perform rotation-based data augmentation. Our results show that deep networks can achieve a test-set accuracy of up to 100% on a full trajectory, with graceful degradation as the number of time steps decreases, outperforming entropy-based clustering.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20068",
        "abstract url": "https://arxiv.org/abs/2410.20068",
        "title": "Understanding the Effect of GCN Convolutions in Regression Tasks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Convolutional Networks (GCNs) have become a pivotal method in machine learning for modeling functions over graphs. Despite their widespread success across various applications, their statistical properties (e.g. consistency, convergence rates) remain ill-characterized. To begin addressing this knowledge gap, in this paper, we provide a formal analysis of the impact of convolution operators on regression tasks over homophilic networks. Focusing on estimators based solely on neighborhood aggregation, we examine how two common convolutions - the original GCN and GraphSage convolutions - affect the learning error as a function of the neighborhood topology and the number of convolutional layers. We explicitly characterize the bias-variance trade-off incurred by GCNs as a function of the neighborhood size and identify specific graph topologies where convolution operators are less effective. Our theoretical findings are corroborated by synthetic experiments, and provide a start to a deeper quantitative understanding of convolutional effects in GCNs for offering rigorous guidelines for practitioners.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2410.21310",
        "abstract url": "https://arxiv.org/abs/2410.21310",
        "title": "ArCSEM: Artistic Colorization of SEM Images via Gaussian Splatting",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "image editing"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Scanning Electron Microscopes (SEMs) are widely renowned for their ability to analyze the surface structures of microscopic objects, offering the capability to capture highly detailed, yet only grayscale, images. To create more expressive and realistic illustrations, these images are typically manually colorized by an artist with the support of image editing software. This task becomes highly laborious when multiple images of a scanned object require colorization. We propose facilitating this process by using the underlying 3D structure of the microscopic scene to propagate the color information to all the captured images, from as little as one colorized view. We explore several scene representation techniques and achieve high-quality colorized novel view synthesis of a SEM scene. In contrast to prior work, there is no manual intervention or labelling involved in obtaining the 3D representation. This enables an artist to color a single or few views of a sequence and automatically retrieve a fully colored scene or video. Project page: https://ronly2460.github.io/ArCSEM",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "presented and published at AI for Visual Arts Workshop and Challenges (AI4VA) in conjunction with European Conference on Computer Vision (ECCV) 2024, Milano, Italy"
    },
    {
        "paper id": "2410.19332",
        "abstract url": "https://arxiv.org/abs/2410.19332",
        "title": "Beyond Point Annotation: A Weakly Supervised Network Guided by Multi-Level Labels Generated from Four-Point Annotation for Thyroid Nodule Segmentation in Ultrasound Image",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Weakly-supervised methods typically guided the pixel-wise training by comparing the predictions to single-level labels containing diverse segmentation-related information at once, but struggled to represent delicate feature differences between nodule and background regions and confused incorrect information, resulting in underfitting or overfitting in the segmentation predictions. In this work, we propose a weakly-supervised network that generates multi-level labels from four-point annotation to refine diverse constraints for delicate nodule segmentation. The Distance-Similarity Fusion Prior referring to the points annotations filters out information irrelevant to nodules. The bounding box and pure foreground/background labels, generated from the point annotation, guarantee the rationality of the prediction in the arrangement of target localization and the spatial distribution of target/background regions, respectively. Our proposed network outperforms existing weakly-supervised methods on two public datasets with respect to the accuracy and robustness, improving the applicability of deep-learning based segmentation in the clinical practice of thyroid nodule diagnosis.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19363",
        "abstract url": "https://arxiv.org/abs/2410.19363",
        "title": "Capsule Endoscopy Multi-classification via Gated Attention and Wavelet Transformations",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "diagnosis"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Abnormalities in the gastrointestinal tract significantly influence the patient's health and require a timely diagnosis for effective treatment. With such consideration, an effective automatic classification of these abnormalities from a video capsule endoscopy (VCE) frame is crucial for improvement in diagnostic workflows. The work presents the process of developing and evaluating a novel model designed to classify gastrointestinal anomalies from a VCE video frame. Integration of Omni Dimensional Gated Attention (OGA) mechanism and Wavelet transformation techniques into the model's architecture allowed the model to focus on the most critical areas in the endoscopy images, reducing noise and irrelevant features. This is particularly advantageous in capsule endoscopy, where images often contain a high degree of variability in texture and color. Wavelet transformations contributed by efficiently capturing spatial and frequency-domain information, improving feature extraction, especially for detecting subtle features from the VCE frames. Furthermore, the features extracted from the Stationary Wavelet Transform and Discrete Wavelet Transform are concatenated channel-wise to capture multiscale features, which are essential for detecting polyps, ulcerations, and bleeding. This approach improves classification accuracy on imbalanced capsule endoscopy datasets. The proposed model achieved 92.76% and 91.19% as training and validation accuracies respectively. At the same time, Training and Validation losses are 0.2057 and 0.2700. The proposed model achieved a Balanced Accuracy of 94.81%, AUC of 87.49%, F1-score of 91.11%, precision of 91.17%, recall of 91.19% and specificity of 98.44%. Additionally, the model's performance is benchmarked against two base models, VGG16 and ResNet50, demonstrating its enhanced ability to identify and classify a range of gastrointestinal abnormalities accurately.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Capsule Vision 2024 Challenge"
    },
    {
        "paper id": "2410.19379",
        "abstract url": "https://arxiv.org/abs/2410.19379",
        "title": "Visual Imitation Learning of Non-Prehensile Manipulation Tasks with Dynamics-Supervised Models",
        "rating": "-1",
        "keywords": [
            [
                "robotic manipulation"
            ]
        ],
        "abstract": "Unlike quasi-static robotic manipulation tasks like pick-and-place, dynamic tasks such as non-prehensile manipulation pose greater challenges, especially for vision-based control. Successful control requires the extraction of features relevant to the target task. In visual imitation learning settings, these features can be learnt by backpropagating the policy loss through the vision backbone. Yet, this approach tends to learn task-specific features with limited generalizability. Alternatively, learning world models can realize more generalizable vision backbones. Utilizing the learnt features, task-specific policies are subsequently trained. Commonly, these models are trained solely to predict the next RGB state from the current state and action taken. But only-RGB prediction might not fully-capture the task-relevant dynamics. In this work, we hypothesize that direct supervision of target dynamic states (Dynamics Mapping) can learn better dynamics-informed world models. Beside the next RGB reconstruction, the world model is also trained to directly predict position, velocity, and acceleration of environment rigid bodies. To verify our hypothesis, we designed a non-prehensile 2D environment tailored to two tasks: \"Balance-Reaching\" and \"Bin-Dropping\". When trained on the first task, dynamics mapping enhanced the task performance under different training configurations (Decoupled, Joint, End-to-End) and policy architectures (Feedforward, Recurrent). Notably, its most significant impact was for world model pretraining boosting the success rate from 21% to 85%. Although frozen dynamics-informed world models could generalize well to a task with in-domain dynamics, but poorly to a one with out-of-domain dynamics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IEEE CASE 2024"
    },
    {
        "paper id": "2410.19410",
        "abstract url": "https://arxiv.org/abs/2410.19410",
        "title": "Embedded Graph Reconstruction under Hausdorff Noise",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Filamentary structures (topologically embedded graphs with a metric structure) are ubiquitous in science and engineering. A challenging problem in topological data analysis (TDA) is to reconstruct the topology and geometry of such an underlying (usually unknown) metric graph from possibly noisy data sampled around it. Reeb graphs have recently been successfully employed in abstract metric graph reconstruction under Gromov$\\unicode{x2013}$Hausdorff noise: the sample is assumed to be metrically close to the ground truth. However, such a strong global density assumption is hardly achieved in applications, making the existing Reeb graph-based methods untractible. We relax the density assumption to give provable geometric reconstruction schemes, even when the sample is metrically close only locally. A very different yet more relevant paradigm focuses on the reconstruction of metric graphs$\\unicode{x2014}$embedded in the Euclidean space$\\unicode{x2014}$from Euclidean samples that are only Hausdorff-close. We further extend our methodologies to provide novel, provable guarantees for the successful geometric reconstruction of Euclidean graphs under the Hausdorff noise model. Our technique produces promising results in reconstructing earthquake plate tectonic boundaries from the global earthquake catalog.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19432",
        "abstract url": "https://arxiv.org/abs/2410.19432",
        "title": "Image-Based Visual Servoing for Enhanced Cooperation of Dual-Arm Manipulation",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "The cooperation of a pair of robot manipulators is required to manipulate a target object without any fixtures. The conventional control methods coordinate the end-effector pose of each manipulator with that of the other using their kinematics and joint coordinate measurements. Yet, the manipulators' inaccurate kinematics and joint coordinate measurements can cause significant pose synchronization errors in practice. This paper thus proposes an image-based visual servoing approach for enhancing the cooperation of a dual-arm manipulation system. On top of the classical control, the visual servoing controller lets each manipulator use its carried camera to measure the image features of the other's marker and adapt its end-effector pose with the counterpart on the move. Because visual measurements are robust to kinematic errors, the proposed control can reduce the end-effector pose synchronization errors and the fluctuations of the interaction forces of the pair of manipulators on the move. Theoretical analyses have rigorously proven the stability of the closed-loop system. Comparative experiments on real robots have substantiated the effectiveness of the proposed control.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "8 pages, 7 figures. Corresponding author: Yuan Yang (yuan_evan_yang@seu.edu.cn). For associated video file, see https://zizhe.io/assets/d16d4124b851e10a9db1775ed4a4ece9.mp4 This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2410.19444",
        "abstract url": "https://arxiv.org/abs/2410.19444",
        "title": "Balancing the Scales: Enhancing Fairness in Facial Expression Recognition with Latent Alignment",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Automatically recognizing emotional intent using facial expression has been a thoroughly investigated topic in the realm of computer vision. Facial Expression Recognition (FER), being a supervised learning task, relies heavily on substantially large data exemplifying various socio-cultural demographic attributes. Over the past decade, several real-world in-the-wild FER datasets that have been proposed were collected through crowd-sourcing or web-scraping. However, most of these practically used datasets employ a manual annotation methodology for labeling emotional intent, which inherently propagates individual demographic biases. Moreover, these datasets also lack an equitable representation of various socio-cultural demographic groups, thereby inducing a class imbalance. Bias analysis and its mitigation have been investigated across multiple domains and problem settings, however, in the FER domain, this is a relatively lesser explored area. This work leverages representation learning based on latent spaces to mitigate bias in facial expression recognition systems, thereby enhancing a deep learning model's fairness and overall accuracy.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19454",
        "abstract url": "https://arxiv.org/abs/2410.19454",
        "title": "On combinatorial descriptions of faces of the cone of supermodular functions",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Five different ways of combinatorial description of non-empty faces of the cone of supermodular functions on the power set of a finite basic set $N$ are introduced. Their identification with faces of the cone of supermodular games allows one to associate to them certain polytopes in $\\mathbb{R}^{N}$, known as cores (of these games) in context of cooperative game theory, or generalized permutohedra in context of polyhedral geometry. Non-empty faces of the supermodular cone then correspond to normal fans of those polytopes. This (basically) geometric way of description of faces of the cone then leads to the combinatorial ways of their description. The first combinatorial way is to identify the faces with certain partitions of the set of enumerations of $N$, known as rank tests in context of algebraic statistics. The second combinatorial way is to identify faces with certain collections of posets on $N$, known as (complete) fans of posets in context of polyhedral geometry. The third combinatorial way is to identify the faces with certain coverings of the power set of $N$, introduced relatively recently in context of cooperative game theory under name core structures. The fourth combinatorial way is to identify the faces with certain formal conditional independence structures, introduced formerly in context of multivariate statistics under name structural semi-graphoids. The fifth way is to identify the faces with certain subgraphs of the permutohedral graph, whose nodes are enumerations of $N$. We prove the equivalence of those six ways of description of non-empty faces of the supermodular cone. This result also allows one to describe the faces of the polyhedral cone of (rank functions of) polymatroids over $N$ and the faces of the submodular cone over $N$.",
        "subjects": [
            "math.CO",
            "cs.IT",
            "math.AG",
            "math.MG"
        ],
        "comment": "47 pages"
    },
    {
        "paper id": "2410.19468",
        "abstract url": "https://arxiv.org/abs/2410.19468",
        "title": "Efficient D-2-D with a Strong Group: Arbitrary Initial Configuration and No Global Knowledge",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Distance-2-Dispersion (D-2-D) problem aims to disperse $k$ mobile agents starting from an arbitrary initial configuration on an anonymous port-labeled graph $G$ with $n$ nodes such that no two agents occupy adjacent nodes in the final configuration, though multiple agents may occupy a single node if there is no other empty node whose all adjacent nodes are also empty. In the existing literature, this problem is solved starting from a rooted configuration for $k(\\geq 1)$ agents using $O(m\u0394)$ synchronous rounds with a total of $O(\\log n)$ memory per agent, where $m$ is the number of edges and $\u0394$ is the maximum degree of the graph. The existing work that solves the problem of D-2-D from scattered initial configuration considers $n+1$ agents to begin with. In this work, we start with $n$ mobile agents that start from an arbitrary initial configuration. They achieve D-2-D configuration that is also a maximal independent set of the graph and terminate in $O(max\\{n\\log^2 n, m\\})$ rounds using $O(\\log n)$ memory per agent. The agents do not have any prior knowledge of any graph parameters. This is a significant improvement over the existing works that solve D-2-D on arbitrary graphs.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19486",
        "abstract url": "https://arxiv.org/abs/2410.19486",
        "title": "x-RAGE: eXtended Reality -- Action & Gesture Events Dataset",
        "rating": "-1",
        "keywords": [
            [
                "bio-inspired"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the emergence of the Metaverse and focus on wearable devices in the recent years gesture based human-computer interaction has gained significance. To enable gesture recognition for VR/AR headsets and glasses several datasets focusing on egocentric i.e. first-person view have emerged in recent years. However, standard frame-based vision suffers from limitations in data bandwidth requirements as well as ability to capture fast motions. To overcome these limitation bio-inspired approaches such as event-based cameras present an attractive alternative. In this work, we present the first event-camera based egocentric gesture dataset for enabling neuromorphic, low-power solutions for XR-centric gesture recognition. The dataset has been made available publicly at the following URL: https://gitlab.com/NVM_IITD_Research/xrage.",
        "subjects": [
            "cs.CV",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19488",
        "abstract url": "https://arxiv.org/abs/2410.19488",
        "title": "MM-WLAuslan: Multi-View Multi-Modal Word-Level Australian Sign Language Recognition Dataset",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Isolated Sign Language Recognition (ISLR) focuses on identifying individual sign language glosses. Considering the diversity of sign languages across geographical regions, developing region-specific ISLR datasets is crucial for supporting communication and research. Auslan, as a sign language specific to Australia, still lacks a dedicated large-scale word-level dataset for the ISLR task. To fill this gap, we curate \\underline{\\textbf{the first}} large-scale Multi-view Multi-modal Word-Level Australian Sign Language recognition dataset, dubbed MM-WLAuslan. Compared to other publicly available datasets, MM-WLAuslan exhibits three significant advantages: (1) the largest amount of data, (2) the most extensive vocabulary, and (3) the most diverse of multi-modal camera views. Specifically, we record 282K+ sign videos covering 3,215 commonly used Auslan glosses presented by 73 signers in a studio environment. Moreover, our filming system includes two different types of cameras, i.e., three Kinect-V2 cameras and a RealSense camera. We position cameras hemispherically around the front half of the model and simultaneously record videos using all four cameras. Furthermore, we benchmark results with state-of-the-art methods for various multi-modal ISLR settings on MM-WLAuslan, including multi-view, cross-camera, and cross-view. Experiment results indicate that MM-WLAuslan is a challenging ISLR dataset, and we hope this dataset will contribute to the development of Auslan and the advancement of sign languages worldwide. All datasets and benchmarks are available at MM-WLAuslan.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19516",
        "abstract url": "https://arxiv.org/abs/2410.19516",
        "title": "Near-Optimal Deterministic Network Decomposition and Ruling Set, and Improved MIS",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "This paper improves and in two cases nearly settles, up to logarithmically lower-order factors, the deterministic complexity of some of the most central problems in distributed graph algorithms, which have been studied for over three decades: Near-Optimal Network Decomposition: We present a deterministic distributed algorithm that computes a network decomposition in approximately O(log^2 n) rounds, with O(log n) diameter and O(log n) colors. This round complexity is near-optimal in the following sense: even given an ideal network decomposition, using it (in the standard way) requires round complexity equal to the product of diameter and number of colors, which is known to be approximately Omega(log^2 n). This near-optimality is remarkable, considering the rarity of optimal deterministic distributed algorithms and that for network decomposition, the first polylogarithmic-round algorithm was achieved only recently, by Rozhon and Ghaffari [STOC 2020], after three decades. Near-Optimal Ruling Set: We present a deterministic distributed algorithm that computes an O(log log n) ruling set in approximately O(log n) rounds. This is an exponential improvement over the O(log n) ruling set of Awerbuch, Goldberg, Luby, and Plotkin [FOCS 1989], while almost matching their O(log n) round complexity. Our result's round complexity nearly matches the approximately Omega(log n) lower bound established by Balliu, Brandt, Kuhn, and Olivetti [STOC 2022], which applies to any poly(log log n) ruling set. Improved Maximal Independent Set (MIS): We present a deterministic distributed algorithm for computing an MIS in approximately O(log^(5/3) n) rounds. This improves upon the approximately O(log^2 n) complexity achieved by Ghaffari and Grunau [STOC 2023] and breaks the log-squared barrier necessary for any method based on network decomposition.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "comment": "FOCS 2024"
    },
    {
        "paper id": "2410.19536",
        "abstract url": "https://arxiv.org/abs/2410.19536",
        "title": "Dynamic O(arboricity) coloring in polylogarithmic worst-case time",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "A recent work by Christiansen, Nowicki, and Rotenberg provides dynamic algorithms for coloring sparse graphs, concretely as a function of the arboricity alpha of the input graph. They give two randomized algorithms: O({alpha} log {alpha}) implicit coloring in poly(log n) worst-case update and query times, and O(min{{alpha} log {alpha}, {alpha} log log log n}) implicit coloring in poly(log n) amortized update and query times (against an oblivious adversary). We improve these results in terms of the number of colors and the time guarantee: First, we present an extremely simple algorithm that computes an O({alpha})-implicit coloring with poly(log n) amortized update and query times. Second, and as the main technical contribution of our work, we show that the time complexity guarantee can be strengthened from amortized to worst-case. That is, we give a dynamic algorithm for implicit O({alpha})-coloring with poly(log n) worst-case update and query times (against an oblivious adversary).",
        "subjects": [
            "cs.DS"
        ],
        "comment": "STOC 2024"
    },
    {
        "paper id": "2410.19540",
        "abstract url": "https://arxiv.org/abs/2410.19540",
        "title": "CloserMusicDB: A Modern Multipurpose Dataset of High Quality Music",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, we introduce CloserMusicDB, a collection of full length studio quality tracks annotated by a team of human experts. We describe the selected qualities of our dataset, along with three example tasks possible to perform using this dataset: hook detection, contextual tagging and artist identification. We conduct baseline experiments and provide initial benchmarks for these tasks.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19580",
        "abstract url": "https://arxiv.org/abs/2410.19580",
        "title": "Hybrid Memetic Search for Electric Vehicle Routing with Time Windows, Simultaneous Pickup-Delivery, and Partial Recharges",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "With growing environmental concerns, electric vehicles for logistics have gained significant attention within the computational intelligence community in recent years. This work addresses an emerging and significant extension of the electric vehicle routing problem (EVRP), namely EVRP with time windows, simultaneous pickup-delivery, and partial recharges (EVRP-TW-SPD), which has wide real-world applications. We propose a hybrid memetic algorithm (HMA) for solving EVRP-TW-SPD. HMA incorporates two novel components: a parallel-sequential station insertion procedure for handling partial recharges that can better avoid local optima compared to purely sequential insertion, and a cross-domain neighborhood search that explores solution spaces of both electric and non-electric problem domains simultaneously. These components can also be easily applied to various EVRP variants. To bridge the gap between existing benchmarks and real-world scenarios, we introduce a new, large-scale EVRP-TW-SPD benchmark set derived from real-world applications, containing instances with many more customers and charging stations than existing benchmark instances. Extensive experiments demonstrate the significant performance advantages of HMA over existing algorithms across a wide range of problem instances. Both the benchmark set and HMA will be open-sourced to facilitate further research in this area.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19586",
        "abstract url": "https://arxiv.org/abs/2410.19586",
        "title": "Diverse Sign Language Translation",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Like spoken languages, a single sign language expression could correspond to multiple valid textual interpretations. Hence, learning a rigid one-to-one mapping for sign language translation (SLT) models might be inadequate, particularly in the case of limited data. In this work, we introduce a Diverse Sign Language Translation (DivSLT) task, aiming to generate diverse yet accurate translations for sign language videos. Firstly, we employ large language models (LLM) to generate multiple references for the widely-used CSL-Daily and PHOENIX14T SLT datasets. Here, native speakers are only invited to touch up inaccurate references, thus significantly improving the annotation efficiency. Secondly, we provide a benchmark model to spur research in this task. Specifically, we investigate multi-reference training strategies to enable our DivSLT model to achieve diverse translations. Then, to enhance translation accuracy, we employ the max-reward-driven reinforcement learning objective that maximizes the reward of the translated result. Additionally, we utilize multiple metrics to assess the accuracy, diversity, and semantic precision of the DivSLT task. Experimental results on the enriched datasets demonstrate that our DivSLT method achieves not only better translation performance but also diverse translation results.",
        "subjects": [
            "cs.MM",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19591",
        "abstract url": "https://arxiv.org/abs/2410.19591",
        "title": "Beyond the Cascade: Juggling Vanilla Siteswap Patterns",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Being widespread in human motor behavior, dynamic movements demonstrate higher efficiency and greater capacity to address a broader range of skill domains compared to their quasi-static counterparts. Among the frequently studied dynamic manipulation problems, robotic juggling tasks stand out due to their inherent ability to scale their difficulty levels to arbitrary extents, making them an excellent subject for investigation. In this study, we explore juggling patterns with mixed throw heights, following the vanilla siteswap juggling notation, which jugglers widely adopted to describe toss juggling patterns. This requires extending our previous analysis of the simpler cascade juggling task by a throw-height sequence planner and further constraints on the end effector trajectory. These are not necessary for cascade patterns but are vital to achieving patterns with mixed throw heights. Using a simulated environment, we demonstrate successful juggling of most common 3-9 ball siteswap patterns up to 9 ball height, transitions between these patterns, and random sequences covering all possible vanilla siteswap patterns with throws between 2 and 9 ball height. https://kai-ploeger.com/beyond-cascades",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Published at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2024"
    },
    {
        "paper id": "2410.19632",
        "abstract url": "https://arxiv.org/abs/2410.19632",
        "title": "SDR-Based Metal Classification using Spectrogram Images from Micro-Doppler Signatures",
        "rating": "-1",
        "keywords": [
            [
                "industrial"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Metallic materials such as brass, copper, and aluminum are used in numerous applications, including industrial manufacturing. The vibration characteristics of these objects are unique and can be used to identify these objects from a distance. This research presents a methodology for detecting and classifying these metallic objects using the vibration dynamics induced by their micro-Doppler signatures. The proposed approach utilizes image processing techniques to extract pivotal features from spectrograms. These spectrograms originate from micro-Doppler signatures of data collected during controlled laboratory experiments where signals were transmitted towards vibrating metal sheets, and the ensuing reflections were recorded using a software-defined radio (SDR). The spectrogram data was augmented using geometric transformation to train a convolutional neural network (CNN) based machine learning model for object classification. The results indicate that the proposed CNN model achieved an accuracy of more than 95% in classifying metals into brass, copper, and aluminum. This research could be used to understand the foundations of classifying spectrogram images using micro-Doppler signatures for its applications towards enhancing the sensing capabilities in industrial and defense applications.",
        "subjects": [
            "eess.SP",
            "eess.IV"
        ],
        "comment": "11 pages, to be published in the May 2025 issue of the IEEE Instrumentation & Measurement Magazine"
    },
    {
        "paper id": "2410.19638",
        "abstract url": "https://arxiv.org/abs/2410.19638",
        "title": "Improved Hardness-of-Approximation for Token Swapping",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We study the token swapping problem, in which we are given a graph with an initial assignment of one distinct token to each vertex, and a final desired assignment (again with one token per vertex). The goal is to find the minimum length sequence of swaps of adjacent tokens required to get from the initial to final assignment. The token swapping problem is known to be NP-complete. It is also known to have a polynomial-time 4-approximation algorithm. From the hardness-of-approximation side, it is known to be NP-hard to approximate with ratio better than 1001/1000. Our main result is an improvement of the approximation ratio of the lower bound: We show that it is NP-hard to approximate with ratio better than 14/13. We then turn our attention to the 0/1-weighted version, in which every token has a weight of either 0 or 1, and the cost of a swap is the sum of the weights of the two participating tokens. Unlike standard token swapping, no constant-factor approximation is known for this version, and we provide an explanation. We prove that 0/1-weighted token swapping is NP-hard to approximate with ratio better than $(1-\\varepsilon) \\ln(n)$ for any constant $\u03b5>0$. Lastly, we prove two barrier results for the standard (unweighted) token swapping problem. We show that one cannot beat the current best known approximation ratio of 4 using a large class of algorithms which includes all known algorithms, nor can one beat it using a common analysis framework.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "comment": "23 pages, 3 figures"
    },
    {
        "paper id": "2410.19656",
        "abstract url": "https://arxiv.org/abs/2410.19656",
        "title": "APRICOT: Active Preference Learning and Constraint-Aware Task Planning with LLMs",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Home robots performing personalized tasks must adeptly balance user preferences with environmental affordances. We focus on organization tasks within constrained spaces, such as arranging items into a refrigerator, where preferences for placement collide with physical limitations. The robot must infer user preferences based on a small set of demonstrations, which is easier for users to provide than extensively defining all their requirements. While recent works use Large Language Models (LLMs) to learn preferences from user demonstrations, they encounter two fundamental challenges. First, there is inherent ambiguity in interpreting user actions, as multiple preferences can often explain a single observed behavior. Second, not all user preferences are practically feasible due to geometric constraints in the environment. To address these challenges, we introduce APRICOT, a novel approach that merges LLM-based Bayesian active preference learning with constraint-aware task planning. APRICOT refines its generated preferences by actively querying the user and dynamically adapts its plan to respect environmental constraints. We evaluate APRICOT on a dataset of diverse organization tasks and demonstrate its effectiveness in real-world scenarios, showing significant improvements in both preference satisfaction and plan feasibility. The project website is at https://portal-cornell.github.io/apricot/",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Conference on Robot Learning (CoRL) 2024"
    },
    {
        "paper id": "2410.19690",
        "abstract url": "https://arxiv.org/abs/2410.19690",
        "title": "Deep Learning for Classification of Inflammatory Bowel Disease Activity in Whole Slide Images of Colonic Histopathology",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "Whole Slide",
                "Disease"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Grading inflammatory bowel disease (IBD) activity using standardized histopathological scoring systems remains challenging due to resource constraints and inter-observer variability. In this study, we developed a deep learning model to classify activity grades in hematoxylin and eosin-stained whole slide images (WSIs) from patients with IBD, offering a robust approach for general pathologists. We utilized 2,077 WSIs from 636 patients treated at Dartmouth-Hitchcock Medical Center in 2018 and 2019, scanned at 40x magnification (0.25 micron/pixel). Board-certified gastrointestinal pathologists categorized the WSIs into four activity classes: inactive, mildly active, moderately active, and severely active. A transformer-based model was developed and validated using five-fold cross-validation to classify IBD activity. Using HoVerNet, we examined neutrophil distribution across activity grades. Attention maps from our model highlighted areas contributing to its prediction. The model classified IBD activity with weighted averages of 0.871 [95% Confidence Interval (CI): 0.860-0.883] for the area under the curve, 0.695 [95% CI: 0.674-0.715] for precision, 0.697 [95% CI: 0.678-0.716] for recall, and 0.695 [95% CI: 0.674-0.714] for F1-score. Neutrophil distribution was significantly different across activity classes. Qualitative evaluation of attention maps by a gastrointestinal pathologist suggested their potential for improved interpretability. Our model demonstrates robust diagnostic performance and could enhance consistency and efficiency in IBD activity assessment.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19697",
        "abstract url": "https://arxiv.org/abs/2410.19697",
        "title": "IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Navigation"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Navigating efficiently to an object in an unexplored environment is a critical skill for general-purpose intelligent robots. Recent approaches to this object goal navigation problem have embraced a modular strategy, integrating classical exploration algorithms-notably frontier exploration-with a learned semantic mapping/exploration module. This paper introduces a novel informative path planning and 3D object probability mapping approach. The mapping module computes the probability of the object of interest through semantic segmentation and a Bayes filter. Additionally, it stores probabilities for common objects, which semantically guides the exploration based on common sense priors from a large language model. The planner terminates when the current viewpoint captures enough voxels identified with high confidence as the object of interest. Although our planner follows a zero-shot approach, it achieves state-of-the-art performance as measured by the Success weighted by Path Length (SPL) and Soft SPL in the Habitat ObjectNav Challenge 2023, outperforming other works by more than 20%. Furthermore, we validate its effectiveness on real robots. Project webpage: https://ippon-paper.github.io/",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19894",
        "abstract url": "https://arxiv.org/abs/2410.19894",
        "title": "Topology-aware Mamba for Crack Segmentation in Structures",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "retinal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "CrackMamba, a Mamba-based model, is designed for efficient and accurate crack segmentation for monitoring the structural health of infrastructure. Traditional Convolutional Neural Network (CNN) models struggle with limited receptive fields, and while Vision Transformers (ViT) improve segmentation accuracy, they are computationally intensive. CrackMamba addresses these challenges by utilizing the VMambaV2 with pre-trained ImageNet-1k weights as the encoder and a newly designed decoder for better performance. To handle the random and complex nature of crack development, a Snake Scan module is proposed to reshape crack feature sequences, enhancing feature extraction. Additionally, the three-branch Snake Conv VSS (SCVSS) block is proposed to target cracks more effectively. Experiments show that CrackMamba achieves state-of-the-art (SOTA) performance on the CrackSeg9k and SewerCrack datasets, and demonstrates competitive performance on the retinal vessel segmentation dataset CHASE\\underline{~}DB1, highlighting its generalization capability. The code is publicly available at: {https://github.com/shengyu27/CrackMamba.}",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Published at Journal of Automation in Construction"
    },
    {
        "paper id": "2410.19896",
        "abstract url": "https://arxiv.org/abs/2410.19896",
        "title": "FLAASH: Flow-Attention Adaptive Semantic Hierarchical Fusion for Multi-Modal Tobacco Content Analysis",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The proliferation of tobacco-related content on social media platforms poses significant challenges for public health monitoring and intervention. This paper introduces a novel multi-modal deep learning framework named Flow-Attention Adaptive Semantic Hierarchical Fusion (FLAASH) designed to analyze tobacco-related video content comprehensively. FLAASH addresses the complexities of integrating visual and textual information in short-form videos by leveraging a hierarchical fusion mechanism inspired by flow network theory. Our approach incorporates three key innovations, including a flow-attention mechanism that captures nuanced interactions between visual and textual modalities, an adaptive weighting scheme that balances the contribution of different hierarchical levels, and a gating mechanism that selectively emphasizes relevant features. This multi-faceted approach enables FLAASH to effectively process and analyze diverse tobacco-related content, from product showcases to usage scenarios. We evaluate FLAASH on the Multimodal Tobacco Content Analysis Dataset (MTCAD), a large-scale collection of tobacco-related videos from popular social media platforms. Our results demonstrate significant improvements over existing methods, outperforming state-of-the-art approaches in classification accuracy, F1 score, and temporal consistency. The proposed method also shows strong generalization capabilities when tested on standard video question-answering datasets, surpassing current models. This work contributes to the intersection of public health and artificial intelligence, offering an effective tool for analyzing tobacco promotion in digital media.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under review at International Journal of Computer Vision; 20 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2410.19942",
        "abstract url": "https://arxiv.org/abs/2410.19942",
        "title": "Ramsey Goodness of paths and unbalanced graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Given graphs $G$ and $H$, we say that $G$ is $H$-$good$ if the Ramsey number $R(G,H)$ equals the trivial lower bound $(|G| - 1)(\u03c7(H) - 1) + \u03c3(H)$, where $\u03c7(H)$ denotes the usual chromatic number of $H$, and $\u03c3(H)$ denotes the minimum size of a color class in a $\u03c7(H)$-coloring of $H$. Pokrovskiy and Sudakov [Ramsey goodness of paths. Journal of Combinatorial Theory, Series B, 122:384-390, 2017.] proved that $P_n$ is $H$-good whenever $n\\geq 4|H|$. In this paper, given $\\varepsilon>0$, we show that if $H$ satisfy a special unbalance condition, then $P_n$ is $H$-good whenever $n \\geq (2 + \\varepsilon)|H|$. More specifically, we show that if $m_1,\\ldots, m_k$ are such that $\\varepsilon\\cdot m_i \\geq 2m_{i-1}^2$ for $2\\leq i\\leq k$, and $n \\geq (2 + \\varepsilon)(m_1 + \\cdots + m_k)$, then $P_n$ is $K_{m_1,\\ldots,m_k}$-good.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "10 pages, 1 figure"
    },
    {
        "paper id": "2410.19944",
        "abstract url": "https://arxiv.org/abs/2410.19944",
        "title": "A Multimodal Approach For Endoscopic VCE Image Classification Using BiomedCLIP-PubMedBERT",
        "rating": "-1",
        "keywords": [
            [
                "BiomedCLIP-PubMedBERT",
                "healthcare",
                "clinical",
                "Endoscopic"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This Paper presents an advanced approach for fine-tuning BiomedCLIP PubMedBERT, a multimodal model, to classify abnormalities in Video Capsule Endoscopy (VCE) frames, aiming to enhance diagnostic efficiency in gastrointestinal healthcare. By integrating the PubMedBERT language model with a Vision Transformer (ViT) to process endoscopic images, our method categorizes images into ten specific classes: angioectasia, bleeding, erosion, erythema, foreign body, lymphangiectasia, polyp, ulcer, worms, and normal. Our workflow incorporates image preprocessing and fine-tunes the BiomedCLIP model to generate high-quality embeddings for both visual and textual inputs, aligning them through similarity scoring for classification. Performance metrics, including classification, accuracy, recall, and F1 score, indicate the models strong ability to accurately identify abnormalities in endoscopic frames, showing promise for practical use in clinical diagnostics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 Pages, 2 Figures, Capsule Vision 2024 Challenge"
    },
    {
        "paper id": "2410.19965",
        "abstract url": "https://arxiv.org/abs/2410.19965",
        "title": "OReole-FM: successes and challenges toward billion-parameter foundation models for high-resolution satellite imagery",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing",
                "satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "While the pretraining of Foundation Models (FMs) for remote sensing (RS) imagery is on the rise, models remain restricted to a few hundred million parameters. Scaling models to billions of parameters has been shown to yield unprecedented benefits including emergent abilities, but requires data scaling and computing resources typically not available outside industry R&D labs. In this work, we pair high-performance computing resources including Frontier supercomputer, America's first exascale system, and high-resolution optical RS data to pretrain billion-scale FMs. Our study assesses performance of different pretrained variants of vision Transformers across image classification, semantic segmentation and object detection benchmarks, which highlight the importance of data scaling for effective model scaling. Moreover, we discuss construction of a novel TIU pretraining dataset, model initialization, with data and pretrained models intended for public release. By discussing technical challenges and details often lacking in the related literature, this work is intended to offer best practices to the geospatial community toward efficient training and benchmarking of larger FMs.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19972",
        "abstract url": "https://arxiv.org/abs/2410.19972",
        "title": "Implementaci\u00f3n de Navegaci\u00f3n en Plataforma Rob\u00f3tica M\u00f3vil Basada en ROS y Gazebo",
        "rating": "-1",
        "keywords": [
            [
                "robotics",
                "robot",
                "navigation"
            ]
        ],
        "abstract": "This research focused on utilizing ROS2 and Gazebo for simulating the TurtleBot3 robot, with the aim of exploring autonomous navigation capabilities. While the study did not achieve full autonomous navigation, it successfully established the connection between ROS2 and Gazebo and enabled manual simulation of the robot's movements. The primary objective was to understand how these tools can be integrated to support autonomous functions, providing valuable insights into the development process. The results of this work lay the groundwork for future research into autonomous robotics. The topic is particularly engaging for both teenagers and adults interested in discovering how robots function independently and the underlying technology involved. This research highlights the potential for further advancements in autonomous systems and serves as a stepping stone for more in-depth studies in the field.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "in Spanish language"
    },
    {
        "paper id": "2410.19973",
        "abstract url": "https://arxiv.org/abs/2410.19973",
        "title": "Multi-Class Abnormality Classification Task in Video Capsule Endoscopy",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this work we addressed the challenge of multi-class anomaly classification in Video Capsule Endoscopy (VCE)[1] with a variety of deep learning models, ranging from custom CNNs to advanced transformer architectures. The purpose is to correctly classify diverse gastrointestinal disorders, which is critical for increasing diagnostic efficiency in clinical settings. We started with a proprietary CNN and improved performance with ResNet[7] for better feature extraction, followed by Vision Transformer (ViT)[2] to capture global dependencies. Multiscale Vision Transformer (MViT)[6] improved hierarchical feature extraction, while Dual Attention Vision Transformer (DaViT)[4] delivered cutting-edge results by combining spatial and channel attention methods. This methodology enabled us to improve model accuracy across a wide range of criteria, greatly surpassing older methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Submission for Video Capsule Endoscopy Challenge"
    },
    {
        "paper id": "2410.19975",
        "abstract url": "https://arxiv.org/abs/2410.19975",
        "title": "Duality of Stochastic Observability and Constructability and Their Relation to the Fisher Information",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "Given a set of measurements, observability characterizes the distinguishability of a system's initial state, whereas constructability focuses on the final state in a trajectory. In the presence of process and/or measurement noise, the Fisher information matrices with respect to the initial and final states$\\unicode{x2013}$equivalent to the stochastic observability and constructability Gramians$\\unicode{x2013}$bound the performance of corresponding estimators through the Cram\u00e9r-Rao inequality. This letter establishes a connection between stochastic observability and constructability of discrete-time linear systems and provides a more numerically stable way for calculating the stochastic observability Gramian. We define a dual system and show that the dual system's stochastic constructability is equivalent to the original system's stochastic observability, and vice versa. This duality enables the interchange of theorems and tools for observability and constructability. For example, we use this result to translate an existing recursive formula for the stochastic constructability Gramian into a formula for recursively calculating the stochastic observability Gramian for both time-varying and time-invariant systems, and we show the convergence of this sequence for the latter. Finally, we illustrate the robustness of our formula compared to existing (non-recursive) formulas through a numerical example.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "10 pages, 2 figures"
    },
    {
        "paper id": "2410.20006",
        "abstract url": "https://arxiv.org/abs/2410.20006",
        "title": "Unsupervised Machine Learning for Detecting and Locating Human-Made Objects in 3D Point Cloud",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "A 3D point cloud is an unstructured, sparse, and irregular dataset, typically collected by airborne LiDAR systems over a geological region. Laser pulses emitted from these systems reflect off objects both on and above the ground, resulting in a dataset containing the longitude, latitude, and elevation of each point, as well as information about the corresponding laser pulse strengths. A widely studied research problem, addressed in many previous works, is ground filtering, which involves partitioning the points into ground and non-ground subsets. This research introduces a novel task: detecting and identifying human-made objects amidst natural tree structures. This task is performed on the subset of non-ground points derived from the ground filtering stage. Marked Point Fields (MPFs) are used as models well-suited to these tasks. The proposed methodology consists of three stages: ground filtering, local information extraction (LIE), and clustering. In the ground filtering stage, a statistical method called One-Sided Regression (OSR) is introduced, addressing the limitations of prior ground filtering methods on uneven terrains. In the LIE stage, unsupervised learning methods are lacking. To mitigate this, a kernel-based method for the Hessian matrix of the MPF is developed. In the clustering stage, the Gaussian Mixture Model (GMM) is applied to the results of the LIE stage to partition the non-ground points into trees and human-made objects. The underlying assumption is that LiDAR points from trees exhibit a three-dimensional distribution, while those from human-made objects follow a two-dimensional distribution. The Hessian matrix of the MPF effectively captures this distinction. Experimental results demonstrate that the proposed ground filtering method outperforms previous techniques, and the LIE method successfully distinguishes between points representing trees and human-made objects.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20058",
        "abstract url": "https://arxiv.org/abs/2410.20058",
        "title": "Optimal demand-responsive connector design: Comparing fully-flexible routing and semi-flexible routing strategies",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Demand-responsive connector (DRC) services are increasingly recognized for their convenience, comfort, and efficiency, offering seamless integrations between travelers' origins/destinations and major transportation hubs such as rail stations. Past analytical models for DRC optimization often failed to distinguish between two commonly used DRC operating strategies: (i) the \"fully-flexible routing\" strategy, where a vehicle serves only the requests received before its dispatch through an optimal tour, and (ii) the \"semi-flexible routing\" strategy, where a vehicle follows a predefined path through a swath to serve requests received en route. Additionally, these models often adopted oversimplified approaches for estimating local tour lengths and capturing the stochastic nature of demand. This paper distinctly identifies and analyzes the two DRC operating strategies, developing analytical models for each that accurately incorporate the second-order effects of stochastic demand and utilize refined local tour length formulas. Numerical experiments demonstrate that our models reduce cost estimation errors to within 2% for fully-flexible routing and to 0.25% for semi-flexible routing, a significant improvement over the previous errors of 8-12% and 6.3%, respectively. These enhanced models allow for more precise determination of critical demand densities for selecting between the two DRC strategies and the fixed-route feeder service. Our extensive numerical analysis offers many insights, particularly highlighting the transition from fully-flexible to semi-flexible routing as demand and region size increase, before ultimately shifting to fixed-route service. Additionally, zoning is identified as pivotal in DRC service design, with fully-flexible routing favoring square-shaped zones and semi-flexible routing preferring elongated rectangular zones.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "31 pages, 10 figures"
    },
    {
        "paper id": "2410.20062",
        "abstract url": "https://arxiv.org/abs/2410.20062",
        "title": "Transforming Precision: A Comparative Analysis of Vision Transformers, CNNs, and Traditional ML for Knee Osteoarthritis Severity Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "X-ray",
                "disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Knee osteoarthritis(KO) is a degenerative joint disease that can cause severe pain and impairment. With increased prevalence, precise diagnosis by medical imaging analytics is crucial for appropriate illness management. This research investigates a comparative analysis between traditional machine learning techniques and new deep learning models for diagnosing KO severity from X-ray pictures. This study does not introduce new architectural innovations but rather illuminates the robust applicability and comparative effectiveness of pre-existing ViT models in a medical imaging context, specifically for KO severity diagnosis. The insights garnered from this comparative analysis advocate for the integration of advanced ViT models in clinical diagnostic workflows, potentially revolutionizing the precision and reliability of KO assessments. This study does not introduce new architectural innovations but rather illuminates the robust applicability and comparative effectiveness of pre-existing ViT models in a medical imaging context, specifically for KO severity diagnosis. The insights garnered from this comparative analysis advocate for the integration of advanced ViT models in clinical diagnostic workflows, potentially revolutionizing the precision & reliability of KO assessments. The study utilizes an osteoarthritis dataset from the Osteoarthritis Initiative (OAI) comprising images with 5 severity categories and uneven class distribution. While classic machine learning models like GaussianNB and KNN struggle in feature extraction, Convolutional Neural Networks such as Inception-V3, VGG-19 achieve better accuracy between 55-65% by learning hierarchical visual patterns. However, Vision Transformer architectures like Da-VIT, GCViT and MaxViT emerge as indisputable champions, displaying 66.14% accuracy, 0.703 precision, 0.614 recall, AUC exceeding 0.835 thanks to self-attention processes.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.00813",
        "abstract url": "https://arxiv.org/abs/2411.00813",
        "title": "Personality Analysis from Online Short Video Platforms with Multi-domain Adaptation",
        "rating": "-1",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "cs.CY",
                "cs.CV",
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "Personality analysis from online short videos has gained prominence due to its applications in personalized recommendation systems, sentiment analysis, and human-computer interaction. Traditional assessment methods, such as questionnaires based on the Big Five Personality Framework, are limited by self-report biases and are impractical for large-scale or real-time analysis. Leveraging the rich, multi-modal data present in short videos offers a promising alternative for more accurate personality inference. However, integrating these diverse and asynchronous modalities poses significant challenges, particularly in aligning time-varying data and ensuring models generalize well to new domains with limited labeled data. In this paper, we propose a novel multi-modal personality analysis framework that addresses these challenges by synchronizing and integrating features from multiple modalities and enhancing model generalization through domain adaptation. We introduce a timestamp-based modality alignment mechanism that synchronizes data based on spoken word timestamps, ensuring accurate correspondence across modalities and facilitating effective feature integration. To capture temporal dependencies and inter-modal interactions, we employ Bidirectional Long Short-Term Memory networks and self-attention mechanisms, allowing the model to focus on the most informative features for personality prediction. Furthermore, we develop a gradient-based domain adaptation method that transfers knowledge from multiple source domains to improve performance in target domains with scarce labeled data. Extensive experiments on real-world datasets demonstrate that our framework significantly outperforms existing methods in personality prediction tasks, highlighting its effectiveness in capturing complex behavioral cues and robustness in adapting to new domains.",
        "subjects": [
            "cs.MM",
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.CY",
            "cs.LG",
            "cs.SI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19349",
        "abstract url": "https://arxiv.org/abs/2410.19349",
        "title": "pEBR: A Probabilistic Approach to Embedding Based Retrieval",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Embedding retrieval aims to learn a shared semantic representation space for both queries and items, thus enabling efficient and effective item retrieval using approximate nearest neighbor (ANN) algorithms. In current industrial practice, retrieval systems typically retrieve a fixed number of items for different queries, which actually leads to insufficient retrieval (low recall) for head queries and irrelevant retrieval (low precision) for tail queries. Mostly due to the trend of frequentist approach to loss function designs, till now there is no satisfactory solution to holistically address this challenge in the industry. In this paper, we move away from the frequentist approach, and take a novel \\textbf{p}robabilistic approach to \\textbf{e}mbedding \\textbf{b}ased \\textbf{r}etrieval (namely \\textbf{pEBR}) by learning the item distribution for different queries, which enables a dynamic cosine similarity threshold calculated by the probabilistic cumulative distribution function (CDF) value. The experimental results show that our approach improves both the retrieval precision and recall significantly. Ablation studies also illustrate how the probabilistic approach is able to capture the differences between head and tail queries.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19375",
        "abstract url": "https://arxiv.org/abs/2410.19375",
        "title": "COMSPLIT: A Communication-Aware Split Learning Design for Heterogeneous IoT Platforms",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The significance of distributed learning and inference algorithms in Internet of Things (IoT) network is growing since they flexibly distribute computation load between IoT devices and the infrastructure, enhance data privacy, and minimize latency. However, a notable challenge stems from the influence of communication channel conditions on their performance. In this work, we introduce COMSPLIT: a novel communication-aware design for split learning (SL) and inference paradigm tailored to processing time series data in IoT networks. COMSPLIT provides a versatile framework for deploying adaptable SL in IoT networks affected by diverse channel conditions. In conjunction with the integration of an early-exit strategy, and addressing IoT scenarios containing devices with heterogeneous computational capabilities, COMSPLIT represents a comprehensive design solution for communication-aware SL in IoT networks. Numerical results show superior performance of COMSPLIT compared to vanilla SL approaches (that assume ideal communication channel), demonstrating its ability to offer both design simplicity and adaptability to different channel conditions.",
        "subjects": [
            "cs.NI",
            "cs.DC",
            "cs.LG"
        ],
        "comment": "Accepted for publication in IEEE Internet of Things Journal"
    },
    {
        "paper id": "2410.19412",
        "abstract url": "https://arxiv.org/abs/2410.19412",
        "title": "Robust Time Series Causal Discovery for Agent-Based Model Validation",
        "rating": "-1.5",
        "keywords": [
            [
                "fMRI"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Agent-Based Model (ABM) validation is crucial as it helps ensuring the reliability of simulations, and causal discovery has become a powerful tool in this context. However, current causal discovery methods often face accuracy and robustness challenges when applied to complex and noisy time series data, which is typical in ABM scenarios. This study addresses these issues by proposing a Robust Cross-Validation (RCV) approach to enhance causal structure learning for ABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two prominent causal discovery algorithms. These aim to reduce the impact of noise better and give more reliable causal relation results, even with high-dimensional, time-dependent data. The proposed approach is then integrated into an enhanced ABM validation framework, which is designed to handle diverse data and model structures. The approach is evaluated using synthetic datasets and a complex simulated fMRI dataset. The results demonstrate greater reliability in causal structure identification. The study examines how various characteristics of datasets affect the performance of established causal discovery methods. These characteristics include linearity, noise distribution, stationarity, and causal structure density. This analysis is then extended to the RCV method to see how it compares in these different situations. This examination helps confirm whether the results are consistent with existing literature and also reveals the strengths and weaknesses of the novel approaches. By tackling key methodological challenges, the study aims to enhance ABM validation with a more resilient valuation framework presented. These improvements increase the reliability of model-driven decision making processes in complex systems analysis.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "econ.EM",
            "stat.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19427",
        "abstract url": "https://arxiv.org/abs/2410.19427",
        "title": "Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models",
        "rating": "-1.5",
        "keywords": [
            [
                "model editing",
                "Unlearning"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Backdoor attacks covertly implant triggers into deep neural networks (DNNs) by poisoning a small portion of the training data with pre-designed backdoor triggers. This vulnerability is exacerbated in the era of large models, where extensive (pre-)training on web-crawled datasets is susceptible to compromise. In this paper, we introduce a novel two-step defense framework named Expose Before You Defend (EBYD). EBYD unifies existing backdoor defense methods into a comprehensive defense system with enhanced performance. Specifically, EBYD first exposes the backdoor functionality in the backdoored model through a model preprocessing step called backdoor exposure, and then applies detection and removal methods to the exposed model to identify and eliminate the backdoor features. In the first step of backdoor exposure, we propose a novel technique called Clean Unlearning (CUL), which proactively unlearns clean features from the backdoored model to reveal the hidden backdoor features. We also explore various model editing/modification techniques for backdoor exposure, including fine-tuning, model sparsification, and weight perturbation. Using EBYD, we conduct extensive experiments on 10 image attacks and 6 text attacks across 2 vision datasets (CIFAR-10 and an ImageNet subset) and 4 language datasets (SST-2, IMDB, Twitter, and AG's News). The results demonstrate the importance of backdoor exposure for backdoor defense, showing that the exposed models can significantly benefit a range of downstream defense tasks, including backdoor label detection, backdoor trigger recovery, backdoor model detection, and backdoor removal. We hope our work could inspire more research in developing advanced defense frameworks with exposed models. Our code is available at: https://github.com/bboylyg/Expose-Before-You-Defend.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "19 pages"
    },
    {
        "paper id": "2410.19436",
        "abstract url": "https://arxiv.org/abs/2410.19436",
        "title": "On the Application of Deep Learning for Precise Indoor Positioning in 6G",
        "rating": "-1.5",
        "keywords": [
            [
                "6G"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurate localization in indoor environments is a challenge due to the Non Line of Sight (NLoS) nature of the signaling. In this paper, we explore the use of AI/ML techniques for positioning accuracy enhancement in Indoor Factory (InF) scenarios. The proposed neural network, which we term LocNet, is trained on measurements such as Channel Impulse Response (CIR) and Reference Signal Received Power (RSRP) from multiple Transmit Receive Points (TRPs). Simulation results show that when using measurements from 18 TRPs, LocNet achieves a 9 cm positioning accuracy at the 90th percentile. Additionally, we demonstrate that the same model generalizes effectively even when measurements from some TRPs randomly become unavailable. Lastly, we provide insights on the robustness of the trained model to the errors in ground truth labels used for training.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "6 Pages, 6 Figures"
    },
    {
        "paper id": "2410.19452",
        "abstract url": "https://arxiv.org/abs/2410.19452",
        "title": "NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "fMRI"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Reconstruction of static visual stimuli from non-invasion brain activity fMRI achieves great success, owning to advanced deep learning models such as CLIP and Stable Diffusion. However, the research on fMRI-to-video reconstruction remains limited since decoding the spatiotemporal perception of continuous visual experiences is formidably challenging. We contend that the key to addressing these challenges lies in accurately decoding both high-level semantics and low-level perception flows, as perceived by the brain in response to video stimuli. To the end, we propose NeuroClips, an innovative framework to decode high-fidelity and smooth video from fMRI. NeuroClips utilizes a semantics reconstructor to reconstruct video keyframes, guiding semantic accuracy and consistency, and employs a perception reconstructor to capture low-level perceptual details, ensuring video smoothness. During inference, it adopts a pre-trained T2V diffusion model injected with both keyframes and low-level perception flows for video reconstruction. Evaluated on a publicly available fMRI-video dataset, NeuroClips achieves smooth high-fidelity video reconstruction of up to 6s at 8FPS, gaining significant improvements over state-of-the-art models in various metrics, e.g., a 128% improvement in SSIM and an 81% improvement in spatiotemporal metrics. Our project is available at https://github.com/gongzix/NeuroClips.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "NeurIPS 2024 Oral"
    },
    {
        "paper id": "2410.19492",
        "abstract url": "https://arxiv.org/abs/2410.19492",
        "title": "TRADE: Transfer of Distributions between External Conditions with Normalizing Flows",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Modeling distributions that depend on external control parameters is a common scenario in diverse applications like molecular simulations, where system properties like temperature affect molecular configurations. Despite the relevance of these applications, existing solutions are unsatisfactory as they require severely restricted model architectures or rely on backward training, which is prone to unstable training. We introduce TRADE, which overcomes these limitations by formulating the learning process as a boundary value problem. By initially training the model for a specific condition using either i.i.d. samples or backward KL training, we establish a boundary distribution. We then propagate this information across other conditions using the gradient of the unnormalized density with respect to the external parameter. This formulation, akin to the principles of physics-informed neural networks, allows us to efficiently learn parameter-dependent distributions without restrictive assumptions. Experimentally, we demonstrate that TRADE achieves excellent results in a wide range of applications, ranging from Bayesian inference and molecular simulations to physical lattice models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Preprint, under review"
    },
    {
        "paper id": "2410.19504",
        "abstract url": "https://arxiv.org/abs/2410.19504",
        "title": "DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Dimensionality reduction (DR) plays a crucial role in various fields, including data engineering and visualization, by simplifying complex datasets while retaining essential information. However, the challenge of balancing DR accuracy and interpretability remains crucial, particularly for users dealing with high-dimensional data. Traditional DR methods often face a trade-off between precision and transparency, where optimizing for performance can lead to reduced interpretability, and vice versa. This limitation is especially prominent in real-world applications such as image, tabular, and text data analysis, where both accuracy and interpretability are critical. To address these challenges, this work introduces the MOE-based Hyperbolic Interpretable Deep Manifold Transformation (DMT-HI). The proposed approach combines hyperbolic embeddings, which effectively capture complex hierarchical structures, with Mixture of Experts (MOE) models, which dynamically allocate tasks based on input features. DMT-HI enhances DR accuracy by leveraging hyperbolic embeddings to represent the hierarchical nature of data, while also improving interpretability by explicitly linking input data, embedding outcomes, and key features through the MOE structure. Extensive experiments demonstrate that DMT-HI consistently achieves superior performance in both DR accuracy and model interpretability, making it a robust solution for complex data analysis. The code is available at \\url{https://github.com/zangzelin/code_dmthi}.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "14 pages, 8 figures"
    },
    {
        "paper id": "2410.19512",
        "abstract url": "https://arxiv.org/abs/2410.19512",
        "title": "Marked Temporal Bayesian Flow Point Processes",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Marked event data captures events by recording their continuous-valued occurrence timestamps along with their corresponding discrete-valued types. They have appeared in various real-world scenarios such as social media, financial transactions, and healthcare records, and have been effectively modeled through Marked Temporal Point Process (MTPP) models. Recently, developing generative models for these MTPP models have seen rapid development due to their powerful generative capability and less restrictive functional forms. However, existing generative MTPP models are usually challenged in jointly modeling events' timestamps and types since: (1) mainstream methods design the generative mechanisms for timestamps only and do not include event types; (2) the complex interdependence between the timestamps and event types are overlooked. In this paper, we propose a novel generative MTPP model called BMTPP. Unlike existing generative MTPP models, BMTPP flexibly models marked temporal joint distributions using a parameter-based approach. Additionally, by adding joint noise to the marked temporal data space, BMTPP effectively captures and explicitly reveals the interdependence between timestamps and event types. Extensive experiments validate the superiority of our approach over other state-of-the-art models and its ability to effectively capture marked-temporal interdependence.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19548",
        "abstract url": "https://arxiv.org/abs/2410.19548",
        "title": "Privacy-Preserving Federated Learning via Dataset Distillation",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) allows users to share knowledge instead of raw data to train a model with high accuracy. Unfortunately, during the training, users lose control over the knowledge shared, which causes serious data privacy issues. We hold that users are only willing and need to share the essential knowledge to the training task to obtain the FL model with high accuracy. However, existing efforts cannot help users minimize the shared knowledge according to the user intention in the FL training procedure. This work proposes FLiP, which aims to bring the principle of least privilege (PoLP) to FL training. The key design of FLiP is applying elaborate information reduction on the training data through a local-global dataset distillation design. We measure the privacy performance through attribute inference and membership inference attacks. Extensive experiments show that FLiP strikes a good balance between model accuracy and privacy protection.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19556",
        "abstract url": "https://arxiv.org/abs/2410.19556",
        "title": "Mapping leadership and communities in EU-funded research through network analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Horizon 2020 and Horizon Europe the EU programs supporting research and innovation through collaboration between companies, academic institutions, and research organisations. This paper introduces a novel methodology using open data on Horizon programs to analyse collaborations, leadership roles, and their evolution, with a focus on the North Adriatic Hydrogen Valley project in the hydrogen energy sector. The methodology employs network analysis, transforming tabular data into weighted networks that represent collaborations between organisations. Centrality measures and community detection algorithms identify influential organisations and stable partnerships over time. To ensure robust and reliable results, the methodology addresses challenges such as input-ordering bias and result variability, while the exploration of the solution space enhances the accuracy of identified collaboration patterns. The case study reveals key leaders and stable communities within the hydrogen energy sector, providing valuable insights for policymakers and organisations fostering innovation through sustained collaborations. The proposed methodology effectively identifies influential organisations and tracks the stability of research collaborations. The insights gained are valuable for policymakers and organisations seeking to foster innovation through sustained partnerships. This approach can be extended to other sectors, offering a framework for understanding the impact of EU research funding on collaboration and leadership dynamics.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19565",
        "abstract url": "https://arxiv.org/abs/2410.19565",
        "title": "How Critical is Site-Specific RAN Optimization? 5G Open-RAN Uplink Air Interface Performance Test and Optimization from Macro-Cell CIR Data",
        "rating": "-1.5",
        "keywords": [
            [
                "5G"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we consider the importance of channel measurement data from specific sites and its impact on air interface optimization and test. Currently, a range of statistical channel models including 3GPP 38.901 tapped delay line (TDL), clustered delay line (CDL), urban microcells (UMi) and urban macrocells (UMa) type channels are widely used for air interface performance testing and simulation. However, there remains a gap in the realism of these models for air interface testing and optimization when compared with real world measurement based channels. To address this gap, we compare the performance impacts of training neural receivers with 1) statistical 3GPP TDL models, and 2) measured macro-cell channel impulse response (CIR) data. We leverage our OmniPHY-5G neural receiver for NR PUSCH uplink simulation, with a training procedure that uses statistical TDL channel models for pre-training, and fine-tuning based on measured site specific MIMO CIR data. The proposed fine-tuning method achieves a 10% block error rate (BLER) at a 1.85 dB lower signal-to-noise ratio (SNR) compared to pre-training only on simulated TDL channels, illustrating a rough magnitude of the gap that can be closed by site-specific training, and gives the first answer to the question \"how much can fine-tuning the RAN for site-specific channels help?\"",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "Appears in the proceedings of the First Workshop on Research and Innovation in Testing and Integration for Open Radio Access Networks (RitiRAN)"
    },
    {
        "paper id": "2410.19574",
        "abstract url": "https://arxiv.org/abs/2410.19574",
        "title": "Institutional Review Boards as Soft Governance Mechanisms of R&D: Governing the R&D of AI-based Medical Products",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Risk-based approaches to governance bear an ambiguous stance regarding the Research and Development stages of AI, for they the possibility of explicit risks before they are posed by a given finalised product. In this context, Institutional Review Boards (IRBs) stand as unique governance mechanisms, capable of addressing the step from general research to concrete product development. However, IRBs face several challenges in governing AI-based medical products, including: (a) achieving consistency, (b) being exhaustive, (c) ensuring process transparency, and (d) reducing the existing capacity and knowledge asymmetry between different stakeholders. This article explores four governance levers that can be used to effect change, four governance entry-points throughout a product's lifecycle, and five different behaviours that IRBs should try to advance to ensure the effective governance of the R&D stages of AI-based medical projects. In doing so, IRBs can seize the unique opportunity they present to bring principles into practice, increase research quality, reduce governance costs, and bridge the knowledge gap between stakeholders.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "10 pages, 1 figure, paper published by AIRe after peer review"
    },
    {
        "paper id": "2410.19575",
        "abstract url": "https://arxiv.org/abs/2410.19575",
        "title": "Considerations for Distribution Shift Robustness of Diagnostic Models in Healthcare",
        "rating": "-1.5",
        "keywords": [
            [
                "biomarker",
                "health",
                "Healthcare",
                "disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider robustness to distribution shifts in the context of diagnostic models in healthcare, where the prediction target $Y$, e.g., the presence of a disease, is causally upstream of the observations $X$, e.g., a biomarker. Distribution shifts may occur, for instance, when the training data is collected in a domain with patients having particular demographic characteristics while the model is deployed on patients from a different demographic group. In the domain of applied ML for health, it is common to predict $Y$ from $X$ without considering further information about the patient. However, beyond the direct influence of the disease $Y$ on biomarker $X$, a predictive model may learn to exploit confounding dependencies (or shortcuts) between $X$ and $Y$ that are unstable under certain distribution shifts. In this work, we highlight a data generating mechanism common to healthcare settings and discuss how recent theoretical results from the causality literature can be applied to build robust predictive models. We theoretically show why ignoring covariates as well as common invariant learning approaches will in general not yield robust predictors in the studied setting, while including certain covariates into the prediction model will. In an extensive simulation study, we showcase the robustness (or lack thereof) of different predictors under various data generating processes. Lastly, we analyze the performance of the different approaches using the PTB-XL dataset, a public dataset of annotated ECG recordings.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19631",
        "abstract url": "https://arxiv.org/abs/2410.19631",
        "title": "Efficient Biological Data Acquisition through Inference Set Design",
        "rating": "-1.5",
        "keywords": [
            [
                "Biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In drug discovery, highly automated high-throughput laboratories are used to screen a large number of compounds in search of effective drugs. These experiments are expensive, so we might hope to reduce their cost by experimenting on a subset of the compounds, and predicting the outcomes of the remaining experiments. In this work, we model this scenario as a sequential subset selection problem: we aim to select the smallest set of candidates in order to achieve some desired level of accuracy for the system as a whole. Our key observation is that, if there is heterogeneity in the difficulty of the prediction problem across the input space, selectively obtaining the labels for the hardest examples in the acquisition pool will leave only the relatively easy examples to remain in the inference set, leading to better overall system performance. We call this mechanism inference set design, and propose the use of an uncertainty-based active learning solution to prune out these challenging examples. Our algorithm includes an explicit stopping criterion that stops running the experiments when it is sufficiently confident that the system has reached the target performance. Our empirical studies on image and molecular datasets, as well as a real-world large-scale biological assay, show that deploying active learning for inference set design leads to significant reduction in experimental cost while obtaining high system performance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19643",
        "abstract url": "https://arxiv.org/abs/2410.19643",
        "title": "Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites",
        "rating": "-1.5",
        "keywords": [
            [
                "biomedical",
                "MRI",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) models benefit from large datasets. Collecting data in biomedical domains is costly and challenging, hence, combining datasets has become a common practice. However, datasets obtained under different conditions could present undesired site-specific variability. Data harmonization methods aim to remove site-specific variance while retaining biologically relevant information. This study evaluates the effectiveness of popularly used ComBat-based methods for harmonizing data in scenarios where the class balance is not equal across sites. We find that these methods struggle with data leakage issues. To overcome this problem, we propose a novel approach PrettYharmonize, designed to harmonize data by pretending the target labels. We validate our approach using controlled datasets designed to benchmark the utility of harmonization. Finally, using real-world MRI and clinical data, we compare leakage-prone methods with PrettYharmonize and show that it achieves comparable performance while avoiding data leakage, particularly in site-target-dependence scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19646",
        "abstract url": "https://arxiv.org/abs/2410.19646",
        "title": "Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "survival",
                "diagnosis",
                "cancer",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Early screening for cancer has proven to improve the survival rate and spare patients from intensive and costly treatments due to late diagnosis. Cancer screening in the healthy population involves an initial risk stratification step to determine the screening method and frequency, primarily to optimize resource allocation by targeting screening towards individuals who draw most benefit. For most screening programs, age and clinical risk factors such as family history are part of the initial risk stratification algorithm. In this paper, we focus on developing a blood marker-based risk stratification approach, which could be used to identify patients with elevated cancer risk to be encouraged for taking a diagnostic test or participate in a screening program. We demonstrate that the combination of simple, widely available blood tests, such as complete blood count and complete metabolic panel, could potentially be used to identify patients at risk for colorectal, liver, and lung cancers with areas under the ROC curve of 0.76, 0.85, 0.78, respectively. Furthermore, we hypothesize that such an approach could not only be used as pre-screening risk assessment for individuals but also as population health management tool, for example to better interrogate the cancer risk in certain sub-populations.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19667",
        "abstract url": "https://arxiv.org/abs/2410.19667",
        "title": "Electromechanical Dynamics of the Heart: A Study of Cardiac Hysteresis During Physical Stress Test",
        "rating": "-1.5",
        "keywords": [
            [
                "biomarker",
                "Cardiac"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cardiovascular diseases are best diagnosed using multiple modalities that assess both the heart's electrical and mechanical functions. While effective, imaging techniques like echocardiography and nuclear imaging are costly and not widely accessible. More affordable technologies, such as simultaneous electrocardiography (ECG) and phonocardiography (PCG), may provide valuable insights into electromechanical coupling and could be useful for prescreening in low-resource settings. Using physical stress test data from the EPHNOGRAM ECG-PCG dataset, collected from 23 healthy male subjects (age: 25.4+/-1.9 yrs), we investigated electromechanical intervals (RR, QT, systolic, and diastolic) and their interactions during exercise, along with hysteresis between cardiac electrical activity and mechanical responses. Time delay analysis revealed distinct temporal relationships between QT, systolic, and diastolic intervals, with RR as the primary driver. The diastolic interval showed near-synchrony with RR, while QT responded to RR interval changes with an average delay of 10.5s, and the systolic interval responded more slowly, with an average delay of 28.3s. We examined QT-RR, systolic-RR, and diastolic-RR hysteresis, finding narrower loops for diastolic RR and wider loops for systolic RR. Significant correlations (average:0.75) were found between heart rate changes and hysteresis loop areas, suggesting the equivalent circular area diameter as a promising biomarker for cardiac function under exercise stress. Deep learning models, including Long Short-Term Memory and Convolutional Neural Networks, estimated the QT, systolic, and diastolic intervals from RR data, confirming the nonlinear relationship between RR and other intervals. Findings highlight a significant cardiac memory effect, linking ECG and PCG morphology and timing to heart rate history.",
        "subjects": [
            "physics.med-ph",
            "cs.LG",
            "eess.SP",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19709",
        "abstract url": "https://arxiv.org/abs/2410.19709",
        "title": "Water and Electricity Consumption Forecasting at an Educational Institution using Machine Learning models with Metaheuristic Optimization",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Educational institutions are essential for economic and social development. Budget cuts in Brazil in recent years have made it difficult to carry out their activities and projects. In the case of expenses with water and electricity, unexpected situations can occur, such as leaks and equipment failures, which make their management challenging. This study proposes a comparison between two machine learning models, Random Forest (RF) and Support Vector Regression (SVR), for water and electricity consumption forecasting at the Federal Institute of Paran\u00e1-Campus Palmas, with a 12-month forecasting horizon, as well as evaluating the influence of the application of climatic variables as exogenous features. The data were collected over the past five years, combining details pertaining to invoices with exogenous and endogenous variables. The two models had their hyperpa-rameters optimized using the Genetic Algorithm (GA) to select the individuals with the best fitness to perform the forecasting with and without climatic variables. The absolute percentage errors and root mean squared error were used as performance measures to evaluate the forecasting accuracy. The results suggest that in forecasting water and electricity consumption over a 12-step horizon, the Random Forest model exhibited the most superior performance. The integration of climatic variables often led to diminished forecasting accuracy, resulting in higher errors. Both models still had certain difficulties in predicting water consumption, indicating that new studies with different models or variables are welcome.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Conference: International Joint Conference on Industrial Engineering and Operations Management (IJCIEOM ). At: Salvador-BA, Brazil"
    },
    {
        "paper id": "2410.19722",
        "abstract url": "https://arxiv.org/abs/2410.19722",
        "title": "Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection",
        "rating": "-1.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "industrial"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "The early detection of potential failures in industrial machinery components is paramount for ensuring the reliability and safety of operations, thereby preserving Machine Condition Monitoring (MCM). This research addresses this imperative by introducing an innovative approach to Real-Time Acoustic Anomaly Detection. Our method combines semi-supervised temporal convolution with representation learning and a hybrid model strategy with Temporal Convolutional Networks (TCN) to handle various intricate anomaly patterns found in acoustic data effectively. The proposed model demonstrates superior performance compared to established research in the field, underscoring the effectiveness of this approach. Not only do we present quantitative evidence of its superiority, but we also employ visual representations, such as t-SNE plots, to further substantiate the model's efficacy.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "10 pages, 10 figures, ICMLC2024"
    },
    {
        "paper id": "2410.19733",
        "abstract url": "https://arxiv.org/abs/2410.19733",
        "title": "The Potential and Value of AI Chatbot in Personalized Cognitive Training",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "disease"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In recent years, the rapid aging of the global population has led to an increase in cognitive disorders, such as Alzheimer's disease, presenting significant public health challenges. Although no effective treatments currently exist to reverse Alzheimer's, prevention and early intervention, including cognitive training, are critical. This report explores the potential of AI chatbots in enhancing personalized cognitive training. We introduce ReMe, a web-based framework designed to create AI chatbots that facilitate cognitive training research, specifically targeting episodic memory tasks derived from personal life logs. By leveraging large language models, ReMe provides enhanced user-friendly, interactive, and personalized training experiences. Case studies demonstrate ReMe's effectiveness in engaging users through life recall and open-ended language puzzles, highlighting its potential to improve cognitive training design. Despite promising results, further research is needed to validate training effectiveness through large-scale studies that include cognitive ability evaluations. Overall, ReMe offers a promising approach to personalized cognitive training, utilizing AI capabilities to meet the growing demand for non-pharmacological interventions in cognitive health, with future research aiming to expand its applications and efficacy.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19887",
        "abstract url": "https://arxiv.org/abs/2410.19887",
        "title": "TBBC: Predict True Bacteraemia in Blood Cultures via Deep Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "diagnosis"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Bacteraemia, a bloodstream infection with high morbidity and mortality rates, poses significant diagnostic challenges. Accurate diagnosis through blood cultures is resource-intensive. Developing a machine learning model to predict blood culture outcomes in emergency departments offers potential for improved diagnosis, reduced healthcare costs, and mitigated antibiotic use.This thesis aims to identify optimal machine learning techniques for predicting bacteraemia and develop a predictive model using data from St. Antonius Hospital's emergency department. Based on current literature, CatBoost and Random Forest were selected as the most promising techniques. Model optimization using Optuna prioritized sensitivity.The final Random Forest model achieved an ROC AUC of 0.78 and demonstrated 0.92 sensitivity on the test set. Notably, it accurately identified 36.02% of patients at low risk of bacteraemia, with only 0.85% false negatives.Implementation of this model in St. Antonius Hospital's emergency department could reduce blood cultures, healthcare costs, and antibiotic treatments. Future studies should focus on external validation, exploring advanced techniques, and addressing potential confounders to ensure model generalizability.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2410.19898",
        "abstract url": "https://arxiv.org/abs/2410.19898",
        "title": "A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "diagnosis",
                "clinical",
                "facial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This review paper explores recent advances in deep learning approaches for non-invasive cognitive impairment detection. We examine various non-invasive indicators of cognitive decline, including speech and language, facial, and motoric mobility. The paper provides an overview of relevant datasets, feature-extracting techniques, and deep-learning architectures applied to this domain. We have analyzed the performance of different methods across modalities and observed that speech and language-based methods generally achieved the highest detection performance. Studies combining acoustic and linguistic features tended to outperform those using a single modality. Facial analysis methods showed promise for visual modalities but were less extensively studied. Most papers focused on binary classification (impaired vs. non-impaired), with fewer addressing multi-class or regression tasks. Transfer learning and pre-trained language models emerged as popular and effective techniques, especially for linguistic analysis. Despite significant progress, several challenges remain, including data standardization and accessibility, model explainability, longitudinal analysis limitations, and clinical adaptation. Lastly, we propose future research directions, such as investigating language-agnostic speech analysis methods, developing multi-modal diagnostic systems, and addressing ethical considerations in AI-assisted healthcare. By synthesizing current trends and identifying key obstacles, this review aims to guide further development of deep learning-based cognitive impairment detection systems to improve early diagnosis and ultimately patient outcomes.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19912",
        "abstract url": "https://arxiv.org/abs/2410.19912",
        "title": "Simmering: Sufficient is better than optimal for training neural networks",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The broad range of neural network training techniques that invoke optimization but rely on ad hoc modification for validity suggests that optimization-based training is misguided. Shortcomings of optimization-based training are brought to particularly strong relief by the problem of overfitting, where naive optimization produces spurious outcomes. The broad success of neural networks for modelling physical processes has prompted advances that are based on inverting the direction of investigation and treating neural networks as if they were physical systems in their own right These successes raise the question of whether broader, physical perspectives could motivate the construction of improved training algorithms. Here, we introduce simmering, a physics-based method that trains neural networks to generate weights and biases that are merely ``good enough'', but which, paradoxically, outperforms leading optimization-based approaches. Using classification and regression examples we show that simmering corrects neural networks that are overfit by Adam, and show that simmering avoids overfitting if deployed from the outset. Our results question optimization as a paradigm for neural network training, and leverage information-geometric arguments to point to the existence of classes of sufficient training algorithms that do not take optimization as their starting point.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19924",
        "abstract url": "https://arxiv.org/abs/2410.19924",
        "title": "Prediction of Final Phosphorus Content of Steel in a Scrap-Based Electric Arc Furnace Using Artificial Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The scrap-based electric arc furnace process is expected to capture a significant share of the steel market in the future due to its potential for reducing environmental impacts through steel recycling. However, managing impurities, particularly phosphorus, remains a challenge. This study aims to develop a machine learning model to estimate the steel phosphorus content at the end of the process based on input parameters. Data were collected over two years from a steel plant, focusing on the chemical composition and weight of the scrap, the volume of oxygen injected, and process duration. After preprocessing the data, several machine learning models were evaluated, with the artificial neural network (ANN) emerging as the most effective. The best ANN model included four hidden layers. The model was trained for 500 epochs with a batch size of 50. The best model achieves a mean square error (MSE) of 0.000016, a root-mean-square error (RMSE) of 0.0049998, a coefficient of determination (R2) of 99.96%, and a correlation coefficient (r) of 99.98%. Notably, the model achieved a 100% hit rate for predicting phosphorus content within +-0.001 wt% (+-10 ppm). These results demonstrate that the optimized ANN model offers accurate predictions for the steel final phosphorus content.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci"
        ],
        "comment": "53 pages, 8 figures"
    },
    {
        "paper id": "2410.19950",
        "abstract url": "https://arxiv.org/abs/2410.19950",
        "title": "Statistical Inference in Classification of High-dimensional Gaussian Mixture",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider the classification problem of a high-dimensional mixture of two Gaussians with general covariance matrices. Using the replica method from statistical physics, we investigate the asymptotic behavior of a general class of regularized convex classifiers in the high-dimensional limit, where both the sample size $n$ and the dimension $p$ approach infinity while their ratio $\u03b1=n/p$ remains fixed. Our focus is on the generalization error and variable selection properties of the estimators. Specifically, based on the distributional limit of the classifier, we construct a de-biased estimator to perform variable selection through an appropriate hypothesis testing procedure. Using $L_1$-regularized logistic regression as an example, we conducted extensive computational experiments to confirm that our analytical findings are consistent with numerical simulations in finite-sized systems. We also explore the influence of the covariance structure on the performance of the de-biased estimator.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "22 pages, 4 figures"
    },
    {
        "paper id": "2410.19989",
        "abstract url": "https://arxiv.org/abs/2410.19989",
        "title": "On-Robot Reinforcement Learning with Goal-Contrastive Rewards",
        "rating": "-1.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "Robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement Learning (RL) has the potential to enable robots to learn from their own actions in the real world. Unfortunately, RL can be prohibitively expensive, in terms of on-robot runtime, due to inefficient exploration when learning from a sparse reward signal. Designing dense reward functions is labour-intensive and requires domain expertise. In our work, we propose GCR (Goal-Contrastive Rewards), a dense reward function learning method that can be trained on passive video demonstrations. By using videos without actions, our method is easier to scale, as we can use arbitrary videos. GCR combines two loss functions, an implicit value loss function that models how the reward increases when traversing a successful trajectory, and a goal-contrastive loss that discriminates between successful and failed trajectories. We perform experiments in simulated manipulation environments across RoboMimic and MimicGen tasks, as well as in the real world using a Franka arm and a Spot quadruped. We find that GCR leads to a more-sample efficient RL, enabling model-free RL to solve about twice as many tasks as our baseline reward learning methods. We also demonstrate positive cross-embodiment transfer from videos of people and of other robots performing a task. Appendix: \\url{https://tinyurl.com/gcr-appendix-2}.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19998",
        "abstract url": "https://arxiv.org/abs/2410.19998",
        "title": "Artificial Intelligence of Things: A Survey",
        "rating": "-1.5",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The integration of the Internet of Things (IoT) and modern Artificial Intelligence (AI) has given rise to a new paradigm known as the Artificial Intelligence of Things (AIoT). In this survey, we provide a systematic and comprehensive review of AIoT research. We examine AIoT literature related to sensing, computing, and networking & communication, which form the three key components of AIoT. In addition to advancements in these areas, we review domain-specific AIoT systems that are designed for various important application domains. We have also created an accompanying GitHub repository, where we compile the papers included in this survey: https://github.com/AIoT-MLSys-Lab/AIoT-Survey. This repository will be actively maintained and updated with new research as it becomes available. As both IoT and AI become increasingly critical to our society, we believe AIoT is emerging as an essential research field at the intersection of IoT and modern AI. We hope this survey will serve as a valuable resource for those engaged in AIoT research and act as a catalyst for future explorations to bridge gaps and drive advancements in this exciting field.",
        "subjects": [
            "cs.NI",
            "cs.AI"
        ],
        "comment": "Accepted in ACM Transactions on Sensor Networks (TOSN)"
    },
    {
        "paper id": "2410.20005",
        "abstract url": "https://arxiv.org/abs/2410.20005",
        "title": "Enhancing Battery Storage Energy Arbitrage with Deep Reinforcement Learning and Time-Series Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Energy arbitrage is one of the most profitable sources of income for battery operators, generating revenues by buying and selling electricity at different prices. Forecasting these revenues is challenging due to the inherent uncertainty of electricity prices. Deep reinforcement learning (DRL) emerged in recent years as a promising tool, able to cope with uncertainty by training on large quantities of historical data. However, without access to future electricity prices, DRL agents can only react to the currently observed price and not learn to plan battery dispatch. Therefore, in this study, we combine DRL with time-series forecasting methods from deep learning to enhance the performance on energy arbitrage. We conduct a case study using price data from Alberta, Canada that is characterized by irregular price spikes and highly non-stationary. This data is challenging to forecast even when state-of-the-art deep learning models consisting of convolutional layers, recurrent layers, and attention modules are deployed. Our results show that energy arbitrage with DRL-enabled battery control still significantly benefits from these imperfect predictions, but only if predictors for several horizons are combined. Grouping multiple predictions for the next 24-hour window, accumulated rewards increased by 60% for deep Q-networks (DQN) compared to the experiments without forecasts. We hypothesize that multiple predictors, despite their imperfections, convey useful information regarding the future development of electricity prices through a \"majority vote\" principle, enabling the DRL agent to learn more profitable control policies.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.OS",
            "eess.SY"
        ],
        "comment": "Accepted for publication at the 18th ASME International Conference on Energy Sustainability"
    },
    {
        "paper id": "2410.20017",
        "abstract url": "https://arxiv.org/abs/2410.20017",
        "title": "Off-Policy Selection for Initiating Human-Centric Experimental Design",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In human-centric tasks such as healthcare and education, the heterogeneity among patients and students necessitates personalized treatments and instructional interventions. While reinforcement learning (RL) has been utilized in those tasks, off-policy selection (OPS) is pivotal to close the loop by offline evaluating and selecting policies without online interactions, yet current OPS methods often overlook the heterogeneity among participants. Our work is centered on resolving a pivotal challenge in human-centric systems (HCSs): how to select a policy to deploy when a new participant joining the cohort, without having access to any prior offline data collected over the participant? We introduce First-Glance Off-Policy Selection (FPS), a novel approach that systematically addresses participant heterogeneity through sub-group segmentation and tailored OPS criteria to each sub-group. By grouping individuals with similar traits, FPS facilitates personalized policy selection aligned with unique characteristics of each participant or group of participants. FPS is evaluated via two important but challenging applications, intelligent tutoring systems and a healthcare application for sepsis treatment and intervention. FPS presents significant advancement in enhancing learning outcomes of students and in-hospital care outcomes.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20027",
        "abstract url": "https://arxiv.org/abs/2410.20027",
        "title": "FLOW: A Feedback LOop FrameWork for Simultaneously Enhancing Recommendation and User Agents",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Agents powered by large language models have shown remarkable reasoning and execution capabilities, attracting researchers to explore their potential in the recommendation domain. Previous studies have primarily focused on enhancing the capabilities of either recommendation agents or user agents independently, but have not considered the interaction and collaboration between recommendation agents and user agents. To address this gap, we propose a novel framework named FLOW, which achieves collaboration between the recommendation agent and the user agent by introducing a feedback loop. Specifically, the recommendation agent refines its understanding of the user's preferences by analyzing the user agent's feedback on previously suggested items, while the user agent leverages suggested items to uncover deeper insights into the user's latent interests. This iterative refinement process enhances the reasoning capabilities of both the recommendation agent and the user agent, enabling more precise recommendations and a more accurate simulation of user behavior. To demonstrate the effectiveness of the feedback loop, we evaluate both recommendation performance and user simulation performance on three widely used recommendation domain datasets. The experimental results indicate that the feedback loop can simultaneously improve the performance of both the recommendation and user agents.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20030",
        "abstract url": "https://arxiv.org/abs/2410.20030",
        "title": "SCube: Instant Large-Scale Scene Reconstruction using VoxSplats",
        "rating": "-1.5",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "diffusion"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We present SCube, a novel method for reconstructing large-scale 3D scenes (geometry, appearance, and semantics) from a sparse set of posed images. Our method encodes reconstructed scenes using a novel representation VoxSplat, which is a set of 3D Gaussians supported on a high-resolution sparse-voxel scaffold. To reconstruct a VoxSplat from images, we employ a hierarchical voxel latent diffusion model conditioned on the input images followed by a feedforward appearance prediction model. The diffusion model generates high-resolution grids progressively in a coarse-to-fine manner, and the appearance network predicts a set of Gaussians within each voxel. From as few as 3 non-overlapping input images, SCube can generate millions of Gaussians with a 1024^3 voxel grid spanning hundreds of meters in 20 seconds. Past works tackling scene reconstruction from images either rely on per-scene optimization and fail to reconstruct the scene away from input views (thus requiring dense view coverage as input) or leverage geometric priors based on low-resolution models, which produce blurry results. In contrast, SCube leverages high-resolution sparse networks and produces sharp outputs from few views. We show the superiority of SCube compared to prior art using the Waymo self-driving dataset on 3D reconstruction and demonstrate its applications, such as LiDAR simulation and text-to-scene generation.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "comment": "NeurIPS 2024. Project page: https://research.nvidia.com/labs/toronto-ai/scube/"
    },
    {
        "paper id": "2410.20037",
        "abstract url": "https://arxiv.org/abs/2410.20037",
        "title": "Roles of LLMs in the Overall Mental Architecture",
        "rating": "-1.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "To better understand existing LLMs, we may examine the human mental (cognitive/psychological) architecture, and its components and structures. Based on psychological, philosophical, and cognitive science literatures, it is argued that, within the human mental architecture, existing LLMs correspond well with implicit mental processes (intuition, instinct, and so on). However, beyond such implicit processes, explicit processes (with better symbolic capabilities) are also present within the human mental architecture, judging from psychological, philosophical, and cognitive science literatures. Various theoretical and empirical issues and questions in this regard are explored. Furthermore, it is argued that existing dual-process computational cognitive architectures (models of the human cognitive/psychological architecture) provide usable frameworks for fundamentally enhancing LLMs by introducing dual processes (both implicit and explicit) and, in the meantime, can also be enhanced by LLMs. The results are synergistic combinations (in several different senses simultaneously).",
        "subjects": [
            "q-bio.NC",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20046",
        "abstract url": "https://arxiv.org/abs/2410.20046",
        "title": "DQRM: Deep Quantized Recommendation Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large-scale recommendation models are currently the dominant workload for many large Internet companies. These recommenders are characterized by massive embedding tables that are sparsely accessed by the index for user and item features. The size of these 1TB+ tables imposes a severe memory bottleneck for the training and inference of recommendation models. In this work, we propose a novel recommendation framework that is small, powerful, and efficient to run and train, based on the state-of-the-art Deep Learning Recommendation Model (DLRM). The proposed framework makes inference more efficient on the cloud servers, explores the possibility of deploying powerful recommenders on smaller edge devices, and optimizes the workload of the communication overhead in distributed training under the data parallelism settings. Specifically, we show that quantization-aware training (QAT) can impose a strong regularization effect to mitigate the severe overfitting issues suffered by DLRMs. Consequently, we achieved INT4 quantization of DLRM models without any accuracy drop. We further propose two techniques that improve and accelerate the conventional QAT workload specifically for the embedding tables in the recommendation models. Furthermore, to achieve efficient training, we quantize the gradients of the embedding tables into INT8 on top of the well-supported specified sparsification. We show that combining gradient sparsification and quantization together significantly reduces the amount of communication. Briefly, DQRM models with INT4 can achieve 79.07% accuracy on Kaggle with 0.27 GB model size, and 81.21% accuracy on the Terabyte dataset with 1.57 GB, which even outperform FP32 DLRMs that have much larger model sizes (2.16 GB on Kaggle and 12.58 on Terabyte).",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20050",
        "abstract url": "https://arxiv.org/abs/2410.20050",
        "title": "AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "health"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Medical information retrieval (MIR) is essential for retrieving relevant medical knowledge from diverse sources, including electronic health records, scientific literature, and medical databases. However, achieving effective zero-shot dense retrieval in the medical domain poses substantial challenges due to the lack of relevance-labeled data. In this paper, we introduce a novel approach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to tackle this issue. SL-HyDE leverages large language models (LLMs) as generators to generate hypothetical documents based on a given query. These generated documents encapsulate key medical context, guiding a dense retriever in identifying the most relevant documents. The self-learning framework progressively refines both pseudo-document generation and retrieval, utilizing unlabeled medical corpora without requiring any relevance-labeled data. Additionally, we present the Chinese Medical Information Retrieval Benchmark (CMIRB), a comprehensive evaluation framework grounded in real-world medical scenarios, encompassing five tasks and ten datasets. By benchmarking ten models on CMIRB, we establish a rigorous standard for evaluating medical information retrieval systems. Experimental results demonstrate that SL-HyDE significantly surpasses existing methods in retrieval accuracy while showcasing strong generalization and scalability across various LLM and retriever configurations. CMIRB data and evaluation code are publicly available at: https://github.com/CMIRB-benchmark/CMIRB.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "15 pages, 3 figures"
    },
    {
        "paper id": "2410.20066",
        "abstract url": "https://arxiv.org/abs/2410.20066",
        "title": "A Multi-Modal Non-Invasive Deep Learning Framework for Progressive Prediction of Seizures",
        "rating": "-1.5",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces an innovative framework designed for progressive (granular in time to onset) prediction of seizures through the utilization of a Deep Learning (DL) methodology based on non-invasive multi-modal sensor networks. Epilepsy, a debilitating neurological condition, affects an estimated 65 million individuals globally, with a substantial proportion facing drug-resistant epilepsy despite pharmacological interventions. To address this challenge, we advocate for predictive systems that provide timely alerts to individuals at risk, enabling them to take precautionary actions. Our framework employs advanced DL techniques and uses personalized data from a network of non-invasive electroencephalogram (EEG) and electrocardiogram (ECG) sensors, thereby enhancing prediction accuracy. The algorithms are optimized for real-time processing on edge devices, mitigating privacy concerns and minimizing data transmission overhead inherent in cloud-based solutions, ultimately preserving battery energy. Additionally, our system predicts the countdown time to seizures (with 15-minute intervals up to an hour prior to the onset), offering critical lead time for preventive actions. Our multi-modal model achieves 95% sensitivity, 98% specificity, and 97% accuracy, averaged among 29 patients.",
        "subjects": [
            "eess.SP",
            "cs.AI"
        ],
        "comment": "4 pages, 5 figures, Proceedings of the IEEE 20th International Conference on Body Sensor Networks (BSN), October 2024"
    },
    {
        "paper id": "2410.21319",
        "abstract url": "https://arxiv.org/abs/2410.21319",
        "title": "Towards Continuous Skin Sympathetic Nerve Activity Monitoring: Removing Muscle Noise",
        "rating": "-1.5",
        "keywords": [
            [
                "pathological",
                "physiological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Continuous monitoring of non-invasive skin sympathetic nerve activity (SKNA) holds promise for understanding the sympathetic nervous system (SNS) dynamics in various physiological and pathological conditions. However, muscle noise artifacts present a challenge in accurate SKNA analysis, particularly in real-life scenarios. This study proposes a deep convolutional neural network (CNN) approach to detect and remove muscle noise from SKNA recordings obtained via ECG electrodes. Twelve healthy participants underwent controlled experimental protocols involving cognitive stress induction and voluntary muscle movements, while collecting SKNA data. Power spectral analysis revealed significant muscle noise interference within the SKNA frequency band (500-1000 Hz). A 2D CNN model was trained on the spectrograms of the data segments to classify them into baseline, stress-induced SKNA, and muscle noise-contaminated periods, achieving an average accuracy of 89.85% across all subjects. Our findings underscore the importance of addressing muscle noise for accurate SKNA monitoring, advancing towards wearable SKNA sensors for real-world applications.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.NC"
        ],
        "comment": "4 pages, 5 figures, 1 table, IEEE-EMBS International Conference on Body Sensor Networks: NextGen Health: Sensor Innovation, AI, and Social Responsibility (IEEE BSN 2024)"
    },
    {
        "paper id": "2410.19320",
        "abstract url": "https://arxiv.org/abs/2410.19320",
        "title": "Pseudorandomness in the (Inverseless) Haar Random Oracle Model",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We study the (in)feasibility of quantum pseudorandom notions in a quantum analog of the random oracle model, where all the parties, including the adversary, have oracle access to the same Haar random unitary. In this model, we show the following: - (Unbounded-query secure) pseudorandom unitaries (PRU) exist. Moreover, the PRU construction makes two calls to the Haar oracle. - We consider constructions of PRUs making a single call to the Haar oracle. In this setting, we show that unbounded-query security is impossible to achieve. We complement this result by showing that bounded-query secure PRUs do exist with a single query to the Haar oracle. - We show that multi-copy pseudorandom state generators and function-like state generators (with classical query access), making a single call to the Haar oracle, exist. Our results have two consequences: (a) when the Haar random unitary is instantiated suitably, our results present viable approaches for building quantum pseudorandom objects without relying upon one-way functions and, (b) for the first time, we show that the key length in pseudorandom unitaries can be generically shrunk (relative to the output length). Our results are also some of the first usecases of the new \"path recording\" formalism for Haar random unitaries, introduced in the recent breakthrough work of Ma and Huang.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.CR"
        ],
        "comment": "51 pages; 4 figures"
    },
    {
        "paper id": "2410.19328",
        "abstract url": "https://arxiv.org/abs/2410.19328",
        "title": "A New Security and Identification Concept for SWIPT Systems in IoT Applications",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "This article addresses an innovative concept to enhance the security for IoT applications in the case of Simultaneous Wireless Information and Power Transfer. This is achieved by integrating a complementary security and identification mechanism through Wireless Power Transfer link within the network of autonomous wireless nodes. This mechanism is implemented at the level of the RF rectifier used to receive energy from a dedicated RF source. A prototype of such RF rectifier has been developed, it generates in real time a backscattered waveform (uplink from the wireless node to the RF source) as function of the parameters of the incoming energy waveform (downlink from RF source) and a digital private key code, generated/available at the level of the wireless node. This uplink waveform can be monitored at the level of the RF source for security/identification purposes implementing an autonomous hardware/physical security layer that operates independently from the communication protocols.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19344",
        "abstract url": "https://arxiv.org/abs/2410.19344",
        "title": "Task queue implementation for edge computing platform",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "With the rising number of distributed computer systems, from microservice web applications to IoT platforms, the question of reliable communication between different parts of the aforementioned systems is becoming increasingly important. As part of this paper, a task queue, which facilitates reliable asynchronous communication between different services, will be implemented. In order to control the flow of tasks through the queue and limit the load on downstream components, we are going to explore ways of efficiently restricting throughput, and defining priority queues within the task queue service. The research will also take a look at how different aspects of the task queue, such as the underlying persistence layer, affect their performance, reliability, and resource usage. This task queue will be implemented as a component in the already existing platform for managing clusters, constellations",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19373",
        "abstract url": "https://arxiv.org/abs/2410.19373",
        "title": "An Enhanced Hierarchical Planning Framework for Multi-Robot Autonomous Exploration",
        "rating": "-2",
        "keywords": [
            [
                "Robot"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "The autonomous exploration of environments by multi-robot systems is a critical task with broad applications in rescue missions, exploration endeavors, and beyond. Current approaches often rely on either greedy frontier selection or end-to-end deep reinforcement learning (DRL) methods, yet these methods are frequently hampered by limitations such as short-sightedness, overlooking long-term implications, and convergence difficulties stemming from the intricate high-dimensional learning space. To address these challenges, this paper introduces an innovative integration strategy that combines the low-dimensional action space efficiency of frontier-based methods with the far-sightedness and optimality of DRL-based approaches. We propose a three-tiered planning framework that first identifies frontiers in free space, creating a sparse map representation that lightens data transmission burdens and reduces the DRL action space's dimensionality. Subsequently, we develop a multi-graph neural network (mGNN) that incorporates states of potential targets and robots, leveraging policy-based reinforcement learning to compute affinities, thereby superseding traditional heuristic utility values. Lastly, we implement local routing planning through subsequence search, which avoids exhaustive sequence traversal. Extensive validation across diverse scenarios and comprehensive simulation results demonstrate the effectiveness of our proposed method. Compared to baseline approaches, our framework achieves environmental exploration with fewer time steps and a notable reduction of over 30% in data transmission, showcasing its superiority in terms of efficiency and performance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 6figures"
    },
    {
        "paper id": "2410.19403",
        "abstract url": "https://arxiv.org/abs/2410.19403",
        "title": "Genetic Motifs as a Blueprint for Mismatch-Tolerant Neuromorphic Computing",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Mixed-signal implementations of SNNs offer a promising solution to edge computing applications that require low-power and compact embedded processing systems. However, device mismatch in the analog circuits of these neuromorphic processors poses a significant challenge to the deployment of robust processing in these systems. Here we introduce a novel architectural solution inspired by biological development to address this issue. Specifically we propose to implement architectures that incorporate network motifs found in developed brains through a differentiable re-parameterization of weight matrices based on gene expression patterns and genetic rules. Thanks to the gradient descent optimization compatibility of the method proposed, we can apply the robustness of biological neural development to neuromorphic computing. To validate this approach we benchmark it using the Yin-Yang classification dataset, and compare its performance with that of standard multilayer perceptrons trained with state-of-the-art hardware-aware training method. Our results demonstrate that the proposed method mitigates mismatch-induced noise without requiring precise device mismatch measurements, effectively outperforming alternative hardware-aware techniques proposed in the literature, and providing a more general solution for improving the robustness of SNNs in neuromorphic hardware.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19455",
        "abstract url": "https://arxiv.org/abs/2410.19455",
        "title": "Project Lx Conventos: Travelling through space and time in Lisbon's religious buildings",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Project Lx Conventos aims to study, in a systematic and integrated manner, the impact of the dissolution of religious orders in the dynamics of urban transformation in nineteenth century Lisbon. After the liberal revolution and the civil war, in the 19th century, the dissolution of religious orders led to the alienation, in Lisbon, of nearly 130 religious buildings which were then given profane occupations (mainly public services) or demolished and divided in plots, originating new urban realities. Project Lx Conventos thus aims to show that the extinction of the convents was decisive in the urban development of Lisbon, in the eighteen hundreds. The project stands on a large set of multimedia data which includes historic and contemporary cartography and geo-referenced photos, videos and 3D models, provided by the projects partners, Lisbon Municipality and the Portuguese National Archive, Torre do Tombo. Supported by these materials, the project's team is creating an online system that will implement a spatial and temporal navigation of these resources integrated in an interactive Map of Lisbon. Besides spatially locating and analyzing the data available for each of the religious buildings considered in the project, the tool integrates cutting edge interaction technology for: 1) Enabling a temporal voyage over the available traces of religious buildings; 2) Analyzing the evolution of religious buildings and their surroundings, through available data; 3) Using 3D representations of the buildings for accessing related data, through time. In this paper, the tools under development in the context of Lx Conventos are described, as well as the technologies supporting them. The current status of the system is presented and future developments are proposed.",
        "subjects": [
            "cs.HC",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19472",
        "abstract url": "https://arxiv.org/abs/2410.19472",
        "title": "Geometric Uncertainty of Patient-Specific Blood Vessels and its Impact on Aortic Hemodynamics",
        "rating": "-2",
        "keywords": [
            [
                "physiological"
            ]
        ],
        "abstract": "In the context of numerical simulations of the vascular system, local geometric uncertainties have not yet been examined in sufficient detail due to model complexity and the associated large numerical effort. Such uncertainties are related to geometric modeling errors resulting from computed tomography imaging, segmentation and meshing. This work presents a methodology to systematically induce local modifications and perform a sufficient number of blood flow simulations to draw statistically relevant conclusions on the most commonly employed quantities of interest, such as flow rates or wall shear stress. The surface of a structured hexahedral mesh of a patient-specific aorta is perturbed by displacement maps defined via Gaussian random fields to stochastically model the local uncertainty of the boundary. Three different cases are studied, with the mean perturbation magnitude of $0.25$, $0.5$ and $1.0~$mm. Valid, locally perturbed meshes are constructed via an elasticity operator that extends surface perturbations into the interior. Otherwise, identical incompressible flow problems are solved on these meshes, taking physiological boundary conditions and Carreau fluid parameters into account. Roughly $300\\,000$ three-dimensional non-stationary blood flow simulations are performed for the three different perturbation cases to estimate the probability distributions of the quantities of interest. Convergence studies justify the spatial resolution of the employed meshes. Overall, the results suggest that moderate geometric perturbations result in reasonable engineering accuracy (relative errors in single-digit percentage range) of the quantities of interest, with higher sensitivity for gradient-related measures, noting that the observed errors are not negligible.",
        "subjects": [
            "physics.med-ph",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19529",
        "abstract url": "https://arxiv.org/abs/2410.19529",
        "title": "A Multiscale-Multiphysics Framework for Modeling Organ-scale Liver Regrowth",
        "rating": "-2",
        "keywords": [
            [
                "surgical",
                "clinical",
                "Organ"
            ]
        ],
        "abstract": "We present a framework for modeling liver regrowth on the organ scale that is based on three components: (1) a multiscale perfusion model that combines synthetic vascular tree generation with a multi-compartment homogenized flow model, including a homogenization procedure to obtain effective parameters; (2) a poroelastic finite growth model that acts on all compartments and the synthetic vascular tree structure; (3) an evolution equation for the local volumetric growth factor, driven by the homogenized flow rate into the microcirculation as a measure of local hyperperfusion and well-suited for calibration with available data. We apply our modeling framework to a prototypical benchmark and a full-scale patient-specific liver, for which we assume a common surgical cut. Our simulation results demonstrate that our model represents hyperperfusion as a consequence of partial resection and accounts for its reduction towards a homeostatic perfusion state, exhibiting overall regrowth dynamics that correspond well with clinical observations. In addition, our results show that our model also captures local hypoperfusion in the vicinity of orphan vessels, a key requirement for the prediction of ischemia or the preoperative identification of suitable cut patterns.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19535",
        "abstract url": "https://arxiv.org/abs/2410.19535",
        "title": "Detection of Emerging Infectious Diseases in Lung CT based on Spatial Anomaly Patterns",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "CT",
                "disease"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Fast detection of emerging diseases is important for containing their spread and treating patients effectively. Local anomalies are relevant, but often novel diseases involve familiar disease patterns in new spatial distributions. Therefore, established local anomaly detection approaches may fail to identify them as new. Here, we present a novel approach to detect the emergence of new disease phenotypes exhibiting distinct patterns of the spatial distribution of lesions. We first identify anomalies in lung CT data, and then compare their distribution in a continually acquired new patient cohorts with historic patient population observed over a long prior period. We evaluate how accumulated evidence collected in the stream of patients is able to detect the onset of an emerging disease. In a gram-matrix based representation derived from the intermediate layers of a three-dimensional convolutional neural network, newly emerging clusters indicate emerging diseases.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19564",
        "abstract url": "https://arxiv.org/abs/2410.19564",
        "title": "Robotic Learning in your Backyard: A Neural Simulator from Open Source Components",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "The emergence of 3D Gaussian Splatting for fast and high-quality novel view synthesize has opened up the possibility to construct photo-realistic simulations from video for robotic reinforcement learning. While the approach has been demonstrated in several research papers, the software tools used to build such a simulator remain unavailable or proprietary. We present SplatGym, an open source neural simulator for training data-driven robotic control policies. The simulator creates a photorealistic virtual environment from a single video. It supports ego camera view generation, collision detection, and virtual object in-painting. We demonstrate training several visual navigation policies via reinforcement learning. SplatGym represents a notable first step towards an open-source general-purpose neural environment for robotic learning. It broadens the range of applications that can effectively utilise reinforcement learning by providing convenient and unrestricted tooling, and by eliminating the need for the manual development of conventional 3D environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for Oral Presentation at IEEE International Conference on Robotic Computing (IRC)"
    },
    {
        "paper id": "2410.19589",
        "abstract url": "https://arxiv.org/abs/2410.19589",
        "title": "Energy-Efficiency Architectural Enhancements for Sensing-Enabled Mobile Networks",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Sensing will be a key technology in 6G networks, enabling a plethora of new sensing-enabled use cases. Some of the use cases relate to deployments over a wide physical area that needs to be sensed by multiple sensing sources at different locations. The efficient management of the sensing resources is pivotal for sustainable sensing-enabled mobile network designs. In this paper, we provide an example of such use case, and show the energy consumption due to sensing has potential to scale to prohibitive levels. We then propose architectural enhancements to solve this problem, and discuss energy saving and energy efficient strategies in sensing, that can only be properly quantified and applied with the proposed architectural enhancements.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "6 pages, 2 figures"
    },
    {
        "paper id": "2410.19623",
        "abstract url": "https://arxiv.org/abs/2410.19623",
        "title": "Toward Generalizable Multiple Sclerosis Lesion Segmentation Models",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "diagnosis",
                "MRI",
                "disease",
                "clinical",
                "Lesion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Automating Multiple Sclerosis (MS) lesion segmentation would be of great benefit in initial diagnosis as well as monitoring disease progression. Deep learning based segmentation models perform well in many domains, but the state-of-the-art in MS lesion segmentation is still suboptimal. Complementary to previous MS lesion segmentation challenges which focused on optimizing the performance on a single evaluation dataset, this study aims to develop models that generalize across diverse evaluation datasets, mirroring real-world clinical scenarios that involve varied scanners, settings, and patient cohorts. To this end, we used all high-quality publicly-available MS lesion segmentation datasets on which we systematically trained a state-of-the-art UNet++ architecture. The resulting models demonstrate consistent performance across the remaining test datasets (are generalizable), with larger and more heterogeneous datasets leading to better models. To the best of our knowledge, this represents the most comprehensive cross-dataset evaluation of MS lesion segmentation models to date using publicly available datasets. Additionally, explicitly enhancing dataset size by merging datasets improved model performance. Specifically, a model trained on the combined MSSEG2016-train, ISBI2015, and 3D-MR-MS datasets surpasses the winner of the MICCAI-2016 competition. Moreover, we demonstrate that the generalizability of our models also relies on our original use of quantile normalization on MRI intensities.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19660",
        "abstract url": "https://arxiv.org/abs/2410.19660",
        "title": "Perception, Control and Hardware for In-Hand Slip-Aware Object Manipulation with Parallel Grippers",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Dexterous in-hand manipulation offers significant potential to enhance robotic manipulator capabilities. This paper presents a comprehensive study on custom sensors and parallel gripper hardware specifically designed for in-hand slippage control. The gripper features rapid closed-loop, low-level force control, and is equipped with sensors capable of independently measuring contact forces and sliding velocities. Our system can quickly estimate essential object properties during pick-up using only in-hand sensing, without relying on prior object information. We introduce four distinct slippage controllers: gravity-assisted trajectory following for both rotational and linear slippage, a hinge controller that maintains the object's orientation while the gripper rotates, and a slip-avoidance controller. The system is mounted on a robot arm and validated through extensive experiments involving a diverse range of objects, demonstrating its novel capabilities.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19712",
        "abstract url": "https://arxiv.org/abs/2410.19712",
        "title": "DA-VIL: Adaptive Dual-Arm Manipulation with Reinforcement Learning and Variable Impedance Control",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robotics"
            ]
        ],
        "abstract": "Dual-arm manipulation is an area of growing interest in the robotics community. Enabling robots to perform tasks that require the coordinated use of two arms, is essential for complex manipulation tasks such as handling large objects, assembling components, and performing human-like interactions. However, achieving effective dual-arm manipulation is challenging due to the need for precise coordination, dynamic adaptability, and the ability to manage interaction forces between the arms and the objects being manipulated. We propose a novel pipeline that combines the advantages of policy learning based on environment feedback and gradient-based optimization to learn controller gains required for the control outputs. This allows the robotic system to dynamically modulate its impedance in response to task demands, ensuring stability and dexterity in dual-arm operations. We evaluate our pipeline on a trajectory-tracking task involving a variety of large, complex objects with different masses and geometries. The performance is then compared to three other established methods for controlling dual-arm robots, demonstrating superior results.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19994",
        "abstract url": "https://arxiv.org/abs/2410.19994",
        "title": "A Photonic Crystal Receiver for Rydberg Atom-Based Sensing",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Rydberg atom-based sensors use atoms dressed by lasers to detect and measure radio frequency electromagnetic fields. The absorptive properties of the atomic gas, configured as a Rydberg atom-based sensor, change in the presence of a radio frequency electromagnetic field. While these sensors are reasonably sensitive, the best conventional radio frequency sensors still outperform Rydberg atom-based sensors with respect to sensitivity. One approach to increase the sensitivity of Rydberg atom-based sensors is to engineer the vapor cell that contains the atomic gas. In this work, we introduce a passive, all-dielectric amplifier integrated into a Rydberg atom-based sensor vapor cell. The vapor cell is a combination of a slot waveguide and a photonic crystal. The structural features of the vapor cell yield a power amplification of ~24 dB. The radio frequency electromagnetic field is coupled adiabatically into the slot waveguide and slowed to increase the interaction between the radio frequency field and the atoms to effectively amplify the incoming signal, i.e., increase the Rabi frequency on the radio frequency transition. The work shows the utility of vapor cell engineering for atom-based quantum technologies and paves the way for other such devices.",
        "subjects": [
            "physics.atom-ph",
            "eess.SP",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20026",
        "abstract url": "https://arxiv.org/abs/2410.20026",
        "title": "Towards Robust Algorithms for Surgical Phase Recognition via Digital Twin-based Scene Representation",
        "rating": "-2",
        "keywords": [
            [
                "robotics"
            ],
            [
                "Surgical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Purpose: Surgical phase recognition (SPR) is an integral component of surgical data science, enabling high-level surgical analysis. End-to-end trained neural networks that predict surgical phase directly from videos have shown excellent performance on benchmarks. However, these models struggle with robustness due to non-causal associations in the training set, resulting in poor generalizability. Our goal is to improve model robustness to variations in the surgical videos by leveraging the digital twin (DT) paradigm -- an intermediary layer to separate high-level analysis (SPR) from low-level processing (geometric understanding). This approach takes advantage of the recent vision foundation models that ensure reliable low-level scene understanding to craft DT-based scene representations that support various high-level tasks. Methods: We present a DT-based framework for SPR from videos. The framework employs vision foundation models to extract representations. We embed the representation in place of raw video inputs in the state-of-the-art Surgformer model. The framework is trained on the Cholec80 dataset and evaluated on out-of-distribution (OOD) and corrupted test samples. Results: Contrary to the vulnerability of the baseline model, our framework demonstrates strong robustness on both OOD and corrupted samples, with a video-level accuracy of 51.1 on the challenging CRCD dataset, 96.0 on an internal robotics training dataset, and 64.4 on a highly corrupted Cholec80 test set. Conclusion: Our findings lend support to the thesis that DT-based scene representations are effective in enhancing model robustness. Future work will seek to improve the feature informativeness, automate feature extraction, and incorporate interpretability for a more comprehensive framework.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20055",
        "abstract url": "https://arxiv.org/abs/2410.20055",
        "title": "3D Distance-color-coded Assessment of PCI Stent Apposition via Deep-learning-based Three-dimensional Multi-object Segmentation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "health",
                "disease",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Coronary artery disease poses a significant global health challenge, often necessitating percutaneous coronary intervention (PCI) with stent implantation. Assessing stent apposition holds pivotal importance in averting and identifying PCI complications that lead to in-stent restenosis. Here we proposed a novel three-dimensional (3D) distance-color-coded assessment (DccA)for PCI stent apposition via deep-learning-based 3D multi-object segmentation in intravascular optical coherence tomography (IV-OCT). Our proposed 3D DccA accurately segments 3D vessel lumens and stents in IV-OCT images, using a spatial matching network and dual-layer training with style transfer. It quantifies and maps stent-lumen distances into a 3D color space, facilitating 3D visual assessment of PCI stent apposition. Achieving over 95% segmentation precision, our proposed DccA enhances clinical evaluation of PCI stent deployment and supports personalized treatment planning.",
        "subjects": [
            "cs.CV",
            "physics.optics"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19308",
        "abstract url": "https://arxiv.org/abs/2410.19308",
        "title": "Semantics in Robotics: Environmental Data Can't Yield Conventions of Human Behaviour",
        "rating": "-2.5",
        "keywords": [
            [
                "Robotics"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The word semantics, in robotics and AI, has no canonical definition. It usually serves to denote additional data provided to autonomous agents to aid HRI. Most researchers seem, implicitly, to understand that such data cannot simply be extracted from environmental data. I try to make explicit why this is so and argue that so-called semantics are best understood as data comprised of conventions of human behaviour. This includes labels, most obviously, but also places, ontologies, and affordances. Object affordances are especially problematic because they require not only semantics that are not in the environmental data (conventions of object use) but also an understanding of physics and object combinations that would, if achieved, constitute artificial superintelligence.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19315",
        "abstract url": "https://arxiv.org/abs/2410.19315",
        "title": "A prescriptive theory for brain-like inference",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "biological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The Evidence Lower Bound (ELBO) is a widely used objective for training deep generative models, such as Variational Autoencoders (VAEs). In the neuroscience literature, an identical objective is known as the variational free energy, hinting at a potential unified framework for brain function and machine learning. Despite its utility in interpreting generative models, including diffusion models, ELBO maximization is often seen as too broad to offer prescriptive guidance for specific architectures in neuroscience or machine learning. In this work, we show that maximizing ELBO under Poisson assumptions for general sequence data leads to a spiking neural network that performs Bayesian posterior inference through its membrane potential dynamics. The resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to biological neurons than previous brain-inspired predictive coding models based on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns sparser representations and exhibits superior generalization to out-of-distribution samples. These findings suggest that optimizing ELBO, combined with Poisson assumptions, provides a solid foundation for developing prescriptive theories in NeuroAI.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19343",
        "abstract url": "https://arxiv.org/abs/2410.19343",
        "title": "High Resolution Seismic Waveform Generation using Denoising Diffusion",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Accurate prediction and synthesis of seismic waveforms are crucial for seismic hazard assessment and earthquake-resistant infrastructure design. Existing prediction methods, such as Ground Motion Models and physics-based simulations, often fail to capture the full complexity of seismic wavefields, particularly at higher frequencies. This study introduces a novel, efficient, and scalable generative model for high-frequency seismic waveform generation. Our approach leverages a spectrogram representation of seismic waveform data, which is reduced to a lower-dimensional submanifold via an autoencoder. A state-of-the-art diffusion model is trained to generate this latent representation, conditioned on key input parameters: earthquake magnitude, recording distance, site conditions, and faulting type. The model generates waveforms with frequency content up to 50 Hz. Any scalar ground motion statistic, such as peak ground motion amplitudes and spectral accelerations, can be readily derived from the synthesized waveforms. We validate our model using commonly used seismological metrics, and performance metrics from image generation studies. Our results demonstrate that our openly available model can generate distributions of realistic high-frequency seismic waveforms across a wide range of input parameters, even in data-sparse regions. For the scalar ground motion statistics commonly used in seismic hazard and earthquake engineering studies, we show that the model accurately reproduces both the median trends of the real data and its variability. To evaluate and compare the growing number of this and similar 'Generative Waveform Models' (GWM), we argue that they should generally be openly available and that they should be included in community efforts for ground motion model evaluations.",
        "subjects": [
            "physics.geo-ph",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19429",
        "abstract url": "https://arxiv.org/abs/2410.19429",
        "title": "Generative Diffusion Models for Sequential Recommendations",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generative models such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) have shown promise in sequential recommendation tasks. However, they face challenges, including posterior collapse and limited representation capacity. The work by Li et al. (2023) introduces a novel approach that leverages diffusion models to address these challenges by representing item embeddings as distributions rather than fixed vectors. This approach allows for a more adaptive reflection of users' diverse interests and various item aspects. During the diffusion phase, the model converts the target item embedding into a Gaussian distribution by adding noise, facilitating the representation of sequential item distributions and the injection of uncertainty. An Approximator then processes this noisy item representation to reconstruct the target item. In the reverse phase, the model utilizes users' past interactions to reverse the noise and finalize the item prediction through a rounding operation. This research introduces enhancements to the DiffuRec architecture, particularly by adding offset noise in the diffusion process to improve robustness and incorporating a cross-attention mechanism in the Approximator to better capture relevant user-item interactions. These contributions led to the development of a new model, DiffuRecSys, which improves performance. Extensive experiments conducted on three public benchmark datasets demonstrate that these modifications enhance item representation, effectively capture diverse user preferences, and outperform existing baselines in sequential recommendation research.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "ROEGEN@RecSys'24: The 1st Workshop on Risks, Opportunities, and Evaluation of Generative Models in Recommender Systems, Co-located with ACM RecSys in Bari, Italy, October 2024"
    },
    {
        "paper id": "2410.19542",
        "abstract url": "https://arxiv.org/abs/2410.19542",
        "title": "Brain-like Functional Organization within Large Language Models",
        "rating": "-2.5",
        "keywords": [
            [
                "voxel"
            ],
            [
                "fMRI"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The human brain has long inspired the pursuit of artificial intelligence (AI). Recently, neuroimaging studies provide compelling evidence of alignment between the computational representation of artificial neural networks (ANNs) and the neural responses of the human brain to stimuli, suggesting that ANNs may employ brain-like information processing strategies. While such alignment has been observed across sensory modalities--visual, auditory, and linguistic--much of the focus has been on the behaviors of artificial neurons (ANs) at the population level, leaving the functional organization of individual ANs that facilitates such brain-like processes largely unexplored. In this study, we bridge this gap by directly coupling sub-groups of artificial neurons with functional brain networks (FBNs), the foundational organizational structure of the human brain. Specifically, we extract representative patterns from temporal responses of ANs in large language models (LLMs), and use them as fixed regressors to construct voxel-wise encoding models to predict brain activity recorded by functional magnetic resonance imaging (fMRI). This framework links the AN sub-groups to FBNs, enabling the delineation of brain-like functional organization within LLMs. Our findings reveal that LLMs (BERT and Llama 1-3) exhibit brain-like functional architecture, with sub-groups of artificial neurons mirroring the organizational patterns of well-established FBNs. Notably, the brain-like functional organization of LLMs evolves with the increased sophistication and capability, achieving an improved balance between the diversity of computational behaviors and the consistency of functional specializations. This research represents the first exploration of brain-like functional organization within LLMs, offering novel insights to inform the development of artificial general intelligence (AGI) with human brain principles.",
        "subjects": [
            "q-bio.NC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19599",
        "abstract url": "https://arxiv.org/abs/2410.19599",
        "title": "Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina",
        "rating": "-2.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "survival"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Recent studies suggest large language models (LLMs) can exhibit human-like reasoning, aligning with human behavior in economic experiments, surveys, and political discourse. This has led many to propose that LLMs can be used as surrogates for humans in social science research. However, LLMs differ fundamentally from humans, relying on probabilistic patterns, absent the embodied experiences or survival objectives that shape human cognition. We assess the reasoning depth of LLMs using the 11-20 money request game. Almost all advanced approaches fail to replicate human behavior distributions across many models, except in one case involving fine-tuning using a substantial amount of human behavior data. Causes of failure are diverse, relating to input language, roles, and safeguarding. These results caution against using LLMs to study human behaviors or as human surrogates.",
        "subjects": [
            "econ.GN",
            "cs.AI",
            "cs.CY",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19627",
        "abstract url": "https://arxiv.org/abs/2410.19627",
        "title": "Knowledge Graph Enhanced Language Agents for Recommendation",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Language agents have recently been used to simulate human behavior and user-item interactions for recommendation systems. However, current language agent simulations do not understand the relationships between users and items, leading to inaccurate user profiles and ineffective recommendations. In this work, we explore the utility of Knowledge Graphs (KGs), which contain extensive and reliable relationships between users and items, for recommendation. Our key insight is that the paths in a KG can capture complex relationships between users and items, eliciting the underlying reasons for user preferences and enriching user profiles. Leveraging this insight, we propose Knowledge Graph Enhanced Language Agents(KGLA), a framework that unifies language agents and KG for recommendation systems. In the simulated recommendation scenario, we position the user and item within the KG and integrate KG paths as natural language descriptions into the simulation. This allows language agents to interact with each other and discover sufficient rationale behind their interactions, making the simulation more accurate and aligned with real-world cases, thus improving recommendation performance. Our experimental results show that KGLA significantly improves recommendation performance (with a 33%-95% boost in NDCG@1 among three widely used benchmarks) compared to the previous best baseline method.",
        "subjects": [
            "cs.AI",
            "cs.IR",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19701",
        "abstract url": "https://arxiv.org/abs/2410.19701",
        "title": "Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery",
        "rating": "-2.5",
        "keywords": [
            [
                "flight"
            ],
            [
                "Health"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper investigates the inclusion of microservices architecture in the development of scalable and reliable airline reservation systems. Most of the traditional reservation systems are very rigid and centralized which makes them prone to bottlenecks and a single point of failure. As such, systems do not meet the requirements of modern airlines which are dynamic. Microservices offer better resiliency and scalability because the services do not depend on one another and can be deployed independently. The approach is grounded on the Circuit Breaker Pattern to maintain fault tolerance while consuming foreign resources such as flight APIs and payment systems. This avoided the failure propagation to the systems by 60% enabling the systems to function under external failures. Traffic rerouting also bolstered this with a guarantee of above 99.95% uptime in systems where high availability was demanded. To address this, load balancing was used, particularly the Round-Robin method which managed to enhance performance by 35% through the equal distribution of user requests among the service instances. Health checks, as well as monitoring in real-time, helped as well with failure management as they helped to contain failures before the users of the system were affected. The results suggest that the use of microservices led to a 40% increase in system scalability, a 50% decrease in downtime and a support for 30% more concurrent users than the use of monolithic architectures. These findings affirm the capability of microservices in the development of robust and flexible airline ticket booking systems that are responsive to change and recover from external system unavailability.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "comment": "18 pages, 3 figures"
    },
    {
        "paper id": "2410.19704",
        "abstract url": "https://arxiv.org/abs/2410.19704",
        "title": "Multi-view biomedical foundation models for molecule-target and property prediction",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "biomedical",
                "disease"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Foundation models applied to bio-molecular space hold promise to accelerate drug discovery. Molecular representation is key to building such models. Previous works have typically focused on a single representation or view of the molecules. Here, we develop a multi-view foundation model approach, that integrates molecular views of graph, image and text. Single-view foundation models are each pre-trained on a dataset of up to 200M molecules and then aggregated into combined representations. Our multi-view model is validated on a diverse set of 18 tasks, encompassing ligand-protein binding, molecular solubility, metabolism and toxicity. We show that the multi-view models perform robustly and are able to balance the strengths and weaknesses of specific views. We then apply this model to screen compounds against a large (>100 targets) set of G Protein-Coupled receptors (GPCRs). From this library of targets, we identify 33 that are related to Alzheimer's disease. On this subset, we employ our model to identify strong binders, which are validated through structure-based modeling and identification of key binding motifs.",
        "subjects": [
            "q-bio.BM",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "34 pages including supplement. 9 figures, 4 tables"
    },
    {
        "paper id": "2410.19723",
        "abstract url": "https://arxiv.org/abs/2410.19723",
        "title": "Sparse Decomposition of Graph Neural Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNN) exhibit superior performance in graph representation learning, but their inference cost can be high, due to an aggregation operation that can require a memory fetch for a very large number of nodes. This inference cost is the major obstacle to deploying GNN models with \\emph{online prediction} to reflect the potentially dynamic node features. To address this, we propose an approach to reduce the number of nodes that are included during aggregation. We achieve this through a sparse decomposition, learning to approximate node representations using a weighted sum of linearly transformed features of a carefully selected subset of nodes within the extended neighbourhood. The approach achieves linear complexity with respect to the average node degree and the number of layers in the graph neural network. We introduce an algorithm to compute the optimal parameters for the sparse decomposition, ensuring an accurate approximation of the original GNN model, and present effective strategies to reduce the training time and improve the learning process. We demonstrate via extensive experiments that our method outperforms other baselines designed for inference speedup, achieving significant accuracy gains with comparable inference times for both node classification and spatio-temporal forecasting tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19955",
        "abstract url": "https://arxiv.org/abs/2410.19955",
        "title": "DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Medical",
                "Health",
                "healthcare",
                "diagnosis",
                "disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Electronic Health Records (EHR) has revolutionized healthcare data management and prediction in the field of AI and machine learning. Accurate predictions of diagnosis and medications significantly mitigate health risks and provide guidance for preventive care. However, EHR driven models often have limited scope on understanding medical-domain knowledge and mostly rely on simple-and-sole ontologies. In addition, due to the missing features and incomplete disease coverage of EHR, most studies only focus on basic analysis on conditions and medication. We propose DualMAR, a framework that enhances EHR prediction tasks through both individual observation data and public knowledge bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG) using verified public clinical ontologies and augment this KG via Large Language Models (LLMs); Second, we design a new proxy-task learning on lab results in EHR for pretraining, which further enhance KG representation and patient embeddings. By retrieving radial and angular coordinates upon polar space, DualMAR enables accurate predictions based on rich hierarchical and semantic embeddings from KG. Experiments also demonstrate that DualMAR outperforms state-of-the-art models, validating its effectiveness in EHR prediction and KG integration in medical domains.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20070",
        "abstract url": "https://arxiv.org/abs/2410.20070",
        "title": "hateUS -- Analysis, impact of Social media use and Hate speech over University Student platforms: Case study, Problems, and Solutions",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "health"
            ],
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "The use of social media applications, hate speech engagement, and public debates among teenagers, primarily by university and college students, is growing day by day. The feelings of tremendous stress, anxiety, and depression via social media among our youths have a direct impact on their daily lives and personal workspace apart from delayed sleep, social media addictions, and memory loss. The use of NO phone times and NO phone zones is now popular in workplaces and family cultures. The use of hate speech, negotiations, and toxic words can lead to verbal abuse and cybercrime. Growing concern of mobile device security, cyberbullying, ransomware attacks, and mental health issues are another serious impact of social media among university students. The future challenges including health issues of social media use and hate speech has a serious impact on livelihood, freedom, and diverse communities of university students. Our case study is related to social media use and hate speech related to public debates over university students. We have presented the analysis and impact of social media and hate speech with several conclusions, cybercrimes, and components. The use of questionnaires for collecting primary data over university students help in the analysis of case study. The conclusion of case study and future scope of the research is extremely important to counter negative impacts.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2410.19358",
        "abstract url": "https://arxiv.org/abs/2410.19358",
        "title": "Joint Beamforming Design and Satellite Selection for Integrated Communication and Navigation in LEO Satellite Networks",
        "rating": "-3",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "Relying on the powerful communication capabilities and rapidly changing geometric configuration, the Low Earth Orbit (LEO) satellites have the potential to offer integrated communication and navigation (ICAN) services. However, the isolated resource utilization in the traditional satellite communication and navigation systems has led to a compromised system performance. Against this backdrop, this paper formulates a joint beamforming design and satellite selection optimization problem for the LEO-ICAN network to maximize the sum rate, while simultaneously reconciling the positioning performance. A two-layer algorithm is proposed, where the beamforming design in the inner layer is solved by the difference-of-convex programming method to maximize the sum rate, and the satellite selection in the outer layer is modeled as a coalition formation game to simultaneously reconcile the positioning performance. Simulation results verify the superiority of our proposed algorithms by increasing the sum rate by 16.6% and 29.3% compared with the conventional beamforming and satellite selection schemes, respectively.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This work has been accepted by GLOBECOM 2024"
    },
    {
        "paper id": "2410.19374",
        "abstract url": "https://arxiv.org/abs/2410.19374",
        "title": "Gaze estimation learning architecture as support to affective, social and cognitive studies in natural human-robot interaction",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "clinical"
            ]
        ],
        "abstract": "Gaze is a crucial social cue in any interacting scenario and drives many mechanisms of social cognition (joint and shared attention, predicting human intention, coordination tasks). Gaze direction is an indication of social and emotional functions affecting the way the emotions are perceived. Evidence shows that embodied humanoid robots endowing social abilities can be seen as sophisticated stimuli to unravel many mechanisms of human social cognition while increasing engagement and ecological validity. In this context, building a robotic perception system to automatically estimate the human gaze only relying on robot's sensors is still demanding. Main goal of the paper is to propose a learning robotic architecture estimating the human gaze direction in table-top scenarios without any external hardware. Table-top tasks are largely used in many studies in experimental psychology because they are suitable to implement numerous scenarios allowing agents to collaborate while maintaining a face-to-face interaction. Such an architecture can provide a valuable support in studies where external hardware might represent an obstacle to spontaneous human behaviour, especially in environments less controlled than the laboratory (e.g., in clinical settings). A novel dataset was also collected with the humanoid robot iCub, including images annotated from 24 participants in different gaze conditions.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19414",
        "abstract url": "https://arxiv.org/abs/2410.19414",
        "title": "Motion Planning for Robotics: A Review for Sampling-based Planners",
        "rating": "-3",
        "keywords": [
            [
                "Robotics"
            ],
            [
                "surgery"
            ]
        ],
        "abstract": "Recent advancements in robotics have transformed industries such as manufacturing, logistics, surgery, and planetary exploration. A key challenge is developing efficient motion planning algorithms that allow robots to navigate complex environments while avoiding collisions and optimizing metrics like path length, sweep area, execution time, and energy consumption. Among the available algorithms, sampling-based methods have gained the most traction in both research and industry due to their ability to handle complex environments, explore free space, and offer probabilistic completeness along with other formal guarantees. Despite their widespread application, significant challenges still remain. To advance future planning algorithms, it is essential to review the current state-of-the-art solutions and their limitations. In this context, this work aims to shed light on these challenges and assess the development and applicability of sampling-based methods. Furthermore, we aim to provide an in-depth analysis of the design and evaluation of ten of the most popular planners across various scenarios. Our findings highlight the strides made in sampling-based methods while underscoring persistent challenges. This work offers an overview of the important ongoing research in robotic motion planning.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "20 pages, 11 figures"
    },
    {
        "paper id": "2410.19451",
        "abstract url": "https://arxiv.org/abs/2410.19451",
        "title": "Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework",
        "rating": "-3",
        "keywords": [
            [
                "disease"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper explores the application of prompt engineering to enhance the performance of large language models (LLMs) in the domain of Traditional Chinese Medicine (TCM). We propose TCM-Prompt, a framework that integrates various pre-trained language models (PLMs), templates, tokenization, and verbalization methods, allowing researchers to easily construct and fine-tune models for specific TCM-related tasks. We conducted experiments on disease classification, syndrome identification, herbal medicine recommendation, and general NLP tasks, demonstrating the effectiveness and superiority of our approach compared to baseline methods. Our findings suggest that prompt engineering is a promising technique for improving the performance of LLMs in specialized domains like TCM, with potential applications in digitalization, modernization, and personalized medicine.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19510",
        "abstract url": "https://arxiv.org/abs/2410.19510",
        "title": "COR-MP: Conservation of Resources Model for Maneuver Planning",
        "rating": "-3",
        "keywords": [
            [
                "automated driving",
                "vehicle"
            ],
            [
                "psychological"
            ]
        ],
        "abstract": "Decision-making for automated driving remains a challenging task. For their integration into real platforms, these algorithms must guarantee passenger safety and comfort while ensuring interpretability and an appropriate computational time. To model and solve this decision-making problem, we have developed a novel approach called COR-MP (Conservation of Resources model for Maneuver Planning). This model is based on the Conservation of Resources theory, a psychological concept applied to human behavior. COR-MP is based on various driving parameters, such as comfort, safety, or energy, and provides in real-time a profit value that enables us to quantify the impact of a decision on the decision-maker. Our method has been tested and validated through closed-loop simulations using RTMaps middleware, and preliminary results have been obtained by testing COR-MP on a real vehicle.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2410.19558",
        "abstract url": "https://arxiv.org/abs/2410.19558",
        "title": "SODA: a Soft Origami Dynamic utensil for Assisted feeding",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "healthcare"
            ]
        ],
        "abstract": "SODA aims to revolutionize assistive feeding systems by designing a multi-purpose utensil using origami-inspired artificial muscles. Traditional utensils, such as forks and spoons,are hard and stiff, causing discomfort and fear among users, especially when operated by autonomous robotic arms. Additionally, these systems require frequent utensil changes to handle different food types. Our innovative utensil design addresses these issues by offering a versatile, adaptive solution that can seamlessly transition between gripping and scooping various foods without the need for manual intervention. Utilizing the flexibility and strength of origami-inspired artificial muscles, the utensil ensures safe and comfortable interactions, enhancing user experience and efficiency. This approach not only simplifies the feeding process but also promotes greater independence for individuals with limited mobility, contributing to the advancement of soft robotics in healthcare applications.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "2 Pages, 4 Figures, RO-MAN 2024 Robot Design Competition"
    },
    {
        "paper id": "2410.19719",
        "abstract url": "https://arxiv.org/abs/2410.19719",
        "title": "Arabic Music Classification and Generation using Deep Learning",
        "rating": "-3",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "Music"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper proposes a machine learning approach for classifying classical and new Egyptian music by composer and generating new similar music. The proposed system utilizes a convolutional neural network (CNN) for classification and a CNN autoencoder for generation. The dataset used in this project consists of new and classical Egyptian music pieces composed by different composers. To classify the music by composer, each sample is normalized and transformed into a mel spectrogram. The CNN model is trained on the dataset using the mel spectrograms as input features and the composer labels as output classes. The model achieves 81.4\\% accuracy in classifying the music by composer, demonstrating the effectiveness of the proposed approach. To generate new music similar to the original pieces, a CNN autoencoder is trained on a similar dataset. The model is trained to encode the mel spectrograms of the original pieces into a lower-dimensional latent space and then decode them back into the original mel spectrogram. The generated music is produced by sampling from the latent space and decoding the samples back into mel spectrograms, which are then transformed into audio. In conclusion, the proposed system provides a promising approach to classifying and generating classical Egyptian music, which can be applied in various musical applications, such as music recommendation systems, music production, and music education.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19996",
        "abstract url": "https://arxiv.org/abs/2410.19996",
        "title": "A-MFST: Adaptive Multi-Flow Sparse Tracker for Real-Time Tissue Tracking Under Occlusion",
        "rating": "-3",
        "keywords": [
            [
                "Depth"
            ],
            [
                "robot"
            ],
            [
                "surgical",
                "surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Purpose: Tissue tracking is critical for downstream tasks in robot-assisted surgery. The Sparse Efficient Neural Depth and Deformation (SENDD) model has previously demonstrated accurate and real-time sparse point tracking, but struggled with occlusion handling. This work extends SENDD to enhance occlusion detection and tracking consistency while maintaining real-time performance. Methods: We use the Segment Anything Model2 (SAM2) to detect and mask occlusions by surgical tools, and we develop and integrate into SENDD an Adaptive Multi-Flow Sparse Tracker (A-MFST) with forward-backward consistency metrics, to enhance occlusion and uncertainty estimation. A-MFST is an unsupervised variant of the Multi-Flow Dense Tracker (MFT). Results: We evaluate our approach on the STIR dataset and demonstrate a significant improvement in tracking accuracy under occlusion, reducing average tracking errors by 12 percent in Mean Endpoint Error (MEE) and showing a 6 percent improvement in the averaged accuracy over thresholds of 4, 8, 16, 32, and 64 pixels. The incorporation of forward-backward consistency further improves the selection of optimal tracking paths, reducing drift and enhancing robustness. Notably, these improvements were achieved without compromising the model's real-time capabilities. Conclusions: Using A-MFST and SAM2, we enhance SENDD's ability to track tissue in real time under instrument and tissue occlusions.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "12 pages, 6 figures. Submitted to IPCAI2025"
    },
    {
        "paper id": "2410.21312",
        "abstract url": "https://arxiv.org/abs/2410.21312",
        "title": "$\\texttt{PatentAgent}$: Intelligent Agent for Automated Pharmaceutical Patent Analysis",
        "rating": "-3",
        "keywords": [
            [
                "biochemical"
            ],
            [
                "Patent",
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Pharmaceutical patents play a vital role in biochemical industries, especially in drug discovery, providing researchers with unique early access to data, experimental results, and research insights. With the advancement of machine learning, patent analysis has evolved from manual labor to tasks assisted by automatic tools. However, there still lacks an unified agent that assists every aspect of patent analysis, from patent reading to core chemical identification. Leveraging the capabilities of Large Language Models (LLMs) to understand requests and follow instructions, we introduce the $\\textbf{first}$ intelligent agent in this domain, $\\texttt{PatentAgent}$, poised to advance and potentially revolutionize the landscape of pharmaceutical research. $\\texttt{PatentAgent}$ comprises three key end-to-end modules -- $\\textit{PA-QA}$, $\\textit{PA-Img2Mol}$, and $\\textit{PA-CoreId}$ -- that respectively perform (1) patent question-answering, (2) image-to-molecular-structure conversion, and (3) core chemical structure identification, addressing the essential needs of scientists and practitioners in pharmaceutical patent analysis. Each module of $\\texttt{PatentAgent}$ demonstrates significant effectiveness with the updated algorithm and the synergistic design of $\\texttt{PatentAgent}$ framework. $\\textit{PA-Img2Mol}$ outperforms existing methods across CLEF, JPO, UOB, and USPTO patent benchmarks with an accuracy gain between 2.46% and 8.37% while $\\textit{PA-CoreId}$ realizes accuracy improvement ranging from 7.15% to 7.62% on PatentNetML benchmark. Our code and dataset will be publicly available.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2410.19544",
        "abstract url": "https://arxiv.org/abs/2410.19544",
        "title": "PMM-Net: Single-stage Multi-agent Trajectory Prediction with Patching-based Embedding and Explicit Modal Modulation",
        "rating": "-3.5",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Analyzing and forecasting trajectories of agents like pedestrians plays a pivotal role for embodied intelligent applications. The inherent indeterminacy of human behavior and complex social interaction among a rich variety of agents make this task more challenging than common time-series forecasting. In this letter, we aim to explore a distinct formulation for multi-agent trajectory prediction framework. Specifically, we proposed a patching-based temporal feature extraction module and a graph-based social feature extraction module, enabling effective feature extraction and cross-scenario generalization. Moreover, we reassess the role of social interaction and present a novel method based on explicit modality modulation to integrate temporal and social features, thereby constructing an efficient single-stage inference pipeline. Results on public benchmark datasets demonstrate the superior performance of our model compared with the state-of-the-art methods. The code is available at: github.com/TIB-K330/pmm-net.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19639",
        "abstract url": "https://arxiv.org/abs/2410.19639",
        "title": "Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving",
        "rating": "-3.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Autonomous driving technology has seen significant advancements, but existing models often fail to fully capture the complexity of multi-agent environments, where interactions between dynamic agents are critical. To address this, we propose the Planning-Integrated Forecasting Model (PIFM), a novel framework inspired by neural mechanisms governing decision-making and multi-agent coordination in the brain. PIFM leverages rich contextual information, integrating road structures, traffic rules, and the behavior of surrounding vehicles to improve both the accuracy and interpretability of predictions. By adopting a diffusion-based architecture, akin to neural diffusion processes involved in predicting and planning, PIFM is able to forecast future trajectories of all agents within a scenario. This architecture enhances model transparency, as it parallels the brain's method of dynamically adjusting predictions based on external stimuli and other agents'behaviors. Extensive experiments validate PIFM's capacity to provide interpretable, neuroscience-driven solutions for safer and more efficient autonomous driving systems, with an extremely low number of parameters.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "The experimental verification section has some issues"
    },
    {
        "paper id": "2410.19665",
        "abstract url": "https://arxiv.org/abs/2410.19665",
        "title": "MetaTrading: An Immersion-Aware Model Trading Framework for Vehicular Metaverse Services",
        "rating": "-3.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "federated learning"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Updates of extensive Internet of Things (IoT) data are critical to the immersion of vehicular metaverse services. However, providing high-quality and sustainable data in unstable and resource-constrained vehicular networks remains a significant challenge. To address this problem, we put forth a novel immersion-aware model trading framework that incentivizes metaverse users (MUs) to contribute learning models trained by their latest local data for augmented reality (AR) services in the vehicular metaverse, while preserving their privacy through federated learning. To comprehensively evaluate the contribution of locally trained learning models provided by MUs to AR services, we design a new immersion metric that captures service immersion by considering the freshness and accuracy of learning models, as well as the amount and potential value of raw data used for training. We model the trading interactions between metaverse service providers (MSPs) and MUs as an equilibrium problem with equilibrium constraints (EPEC) to analyze and balance their costs and gains. Moreover, considering dynamic network conditions and privacy concerns, we formulate the reward decisions of MSPs as a multi-agent Markov decision process. Then, a fully distributed dynamic reward method based on deep reinforcement learning is presented, which operates without any private information about MUs and other MSPs. Experimental results demonstrate that the proposed framework can effectively provide higher-value models for object detection and classification in AR services on real AR-related vehicle datasets compared to benchmark schemes.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19892",
        "abstract url": "https://arxiv.org/abs/2410.19892",
        "title": "Air Quality Prediction with Physics-Informed Dual Neural ODEs in Open Systems",
        "rating": "-3.5",
        "keywords": [
            [
                "health"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Air pollution significantly threatens human health and ecosystems, necessitating effective air quality prediction to inform public policy. Traditional approaches are generally categorized into physics-based and data-driven models. Physics-based models usually struggle with high computational demands and closed-system assumptions, while data-driven models may overlook essential physical dynamics, confusing the capturing of spatiotemporal correlations. Although some physics-informed approaches combine the strengths of both models, they often face a mismatch between explicit physical equations and implicit learned representations. To address these challenges, we propose Air-DualODE, a novel physics-informed approach that integrates dual branches of Neural ODEs for air quality prediction. The first branch applies open-system physical equations to capture spatiotemporal dependencies for learning physics dynamics, while the second branch identifies the dependencies not addressed by the first in a fully data-driven way. These dual representations are temporally aligned and fused to enhance prediction accuracy. Our experimental results demonstrate that Air-DualODE achieves state-of-the-art performance in predicting pollutant concentrations across various spatial scales, thereby offering a promising solution for real-world air quality challenges.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19921",
        "abstract url": "https://arxiv.org/abs/2410.19921",
        "title": "Method for noise-induced regularization in quantum neural networks",
        "rating": "-3.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the current quantum computing paradigm, significant focus is placed on the reduction or mitigation of quantum decoherence. When designing new quantum processing units, the general objective is to reduce the amount of noise qubits are subject to, and in algorithm design, a large effort is underway to provide scalable error correction or mitigation techniques. Yet some previous work has indicated that certain classes of quantum algorithms, such as quantum machine learning, may, in fact, be intrinsically robust to or even benefit from the presence of a small amount of noise. Here, we demonstrate that noise levels in quantum hardware can be effectively tuned to enhance the ability of quantum neural networks to generalize data, acting akin to regularisation in classical neural networks. As an example, we consider a medical regression task, where, by tuning the noise level in the circuit, we improved the mean squared error loss by 8%.",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "11 pages, 6 figures, 2 tables"
    },
    {
        "paper id": "2410.19922",
        "abstract url": "https://arxiv.org/abs/2410.19922",
        "title": "Disentangling Genotype and Environment Specific Latent Features for Improved Trait Prediction using a Compositional Autoencoder",
        "rating": "-3.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "agricultural"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This study introduces a compositional autoencoder (CAE) framework designed to disentangle the complex interplay between genotypic and environmental factors in high-dimensional phenotype data to improve trait prediction in plant breeding and genetics programs. Traditional predictive methods, which use compact representations of high-dimensional data through handcrafted features or latent features like PCA or more recently autoencoders, do not separate genotype-specific and environment-specific factors. We hypothesize that disentangling these features into genotype-specific and environment-specific components can enhance predictive models. To test this, we developed a compositional autoencoder (CAE) that decomposes high-dimensional data into distinct genotype-specific and environment-specific latent features. Our CAE framework employs a hierarchical architecture within an autoencoder to effectively separate these entangled latent features. Applied to a maize diversity panel dataset, the CAE demonstrates superior modeling of environmental influences and 5-10 times improved predictive performance for key traits like Days to Pollen and Yield, compared to the traditional methods, including standard autoencoders, PCA with regression, and Partial Least Squares Regression (PLSR). By disentangling latent features, the CAE provides powerful tool for precision breeding and genetic research. This work significantly enhances trait prediction models, advancing agricultural and biological sciences.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19467",
        "abstract url": "https://arxiv.org/abs/2410.19467",
        "title": "Quantum optimization for Nonlinear Model Predictive Control",
        "rating": "-4",
        "keywords": [
            [
                "industrial"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Nonlinear Model Predictive Control (NMPC) is a general and flexible control approach, used in many industrial contexts, and is based on the online solution of a nonlinear optimization problem. This operation requires in general a high computational cost, which may compromise the NMPC implementation in ``fast'' applications, especially if a large number variables is involved. To overcome this issue, we propose a quantum computing approach for the solution of the NMPC optimization problem. Assuming the availability of an efficient quantum computer, the approach has the potential to considerably decrease the computational time and/or enhance the solution quality compared to classical algorithms.",
        "subjects": [
            "eess.SY",
            "quant-ph"
        ],
        "comment": "9 pages, no figures, no tables"
    },
    {
        "paper id": "2410.19661",
        "abstract url": "https://arxiv.org/abs/2410.19661",
        "title": "Experimental implementation of an economic model predictive control for froth flotation",
        "rating": "-4",
        "keywords": [
            [
                "mineral"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "We present the implementation of a novel economic model predictive control (E-MPC) strategy for froth flotation, the largest tonnage mineral separation process. A previously calibrated and validated dynamic model incorporating froth physics was used, which overcomes the limitations of previous simplified models reported in the literature. The E-MPC's optimal control problem was solved using full discretization with orthogonal collocation over finite elements, employing automatic differentiation via CasADi. This approach was applied in a 30-litre laboratory-scale flotation cell, significantly improving mineral recovery from 9% to 29% under feed flowrate disturbances while maintaining a minimum concentrate grade of 20%.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19717",
        "abstract url": "https://arxiv.org/abs/2410.19717",
        "title": "Enhanced Anomaly Detection in Industrial Control Systems aided by Machine Learning",
        "rating": "-4",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "attack"
            ],
            [
                "Industrial"
            ]
        ],
        "abstract": "Traditional intrusion detection systems (IDSs) often rely on either network traffic or process data, but this single-source approach may miss complex attack patterns that span multiple layers within industrial control systems (ICSs) or persistent threats that target different layers of operational technology systems. This study investigates whether combining both network and process data can improve attack detection in ICSs environments. Leveraging the SWaT dataset, we evaluate various machine learning models on individual and combined data sources. Our findings suggest that integrating network traffic with operational process data can enhance detection capabilities, evidenced by improved recall rates for cyber attack classification. Serving as a proof-of-concept within a limited testing environment, this research explores the feasibility of advancing intrusion detection through a multi-source data approach in ICSs. Although the results are promising, they are preliminary and highlight the need for further studies across diverse datasets and refined methodologies.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages, Norwegian Information Security Conference, 2024"
    },
    {
        "paper id": "2410.20073",
        "abstract url": "https://arxiv.org/abs/2410.20073",
        "title": "Super-resolved virtual staining of label-free tissue using diffusion models",
        "rating": "-4",
        "keywords": [
            [
                "diffusion",
                "super-resolution"
            ],
            [
                "clinical"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Virtual staining of tissue offers a powerful tool for transforming label-free microscopy images of unstained tissue into equivalents of histochemically stained samples. This study presents a diffusion model-based super-resolution virtual staining approach utilizing a Brownian bridge process to enhance both the spatial resolution and fidelity of label-free virtual tissue staining, addressing the limitations of traditional deep learning-based methods. Our approach integrates novel sampling techniques into a diffusion model-based image inference process to significantly reduce the variance in the generated virtually stained images, resulting in more stable and accurate outputs. Blindly applied to lower-resolution auto-fluorescence images of label-free human lung tissue samples, the diffusion-based super-resolution virtual staining model consistently outperformed conventional approaches in resolution, structural similarity and perceptual accuracy, successfully achieving a super-resolution factor of 4-5x, increasing the output space-bandwidth product by 16-25-fold compared to the input label-free microscopy images. Diffusion-based super-resolved virtual tissue staining not only improves resolution and image quality but also enhances the reliability of virtual staining without traditional chemical staining, offering significant potential for clinical diagnostics.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "physics.med-ph",
            "physics.optics"
        ],
        "comment": "26 Pages, 5 Figures"
    },
    {
        "paper id": "2410.19562",
        "abstract url": "https://arxiv.org/abs/2410.19562",
        "title": "Neuromorphic IoT Architecture for Efficient Water Management: A Smart Village Case Study",
        "rating": "-4.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "biological"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The exponential growth of IoT networks necessitates a paradigm shift towards architectures that offer high flexibility and learning capabilities while maintaining low energy consumption, minimal communication overhead, and low latency. Traditional IoT systems, particularly when integrated with machine learning approaches, often suffer from high communication overhead and significant energy consumption. This work addresses these challenges by proposing a neuromorphic architecture inspired by biological systems. To illustrate the practical application of our proposed architecture, we present a case study focusing on water management in the Carinthian community of Neuhaus. Preliminary results regarding water consumption prediction and anomaly detection in this community are presented. We also introduce a novel neuromorphic IoT architecture that integrates biological principles into the design of IoT systems. This architecture is specifically tailored for edge computing scenarios, where low power and high efficiency are crucial. Our approach leverages the inherent advantages of neuromorphic computing, such as asynchronous processing and event-driven communication, to create an IoT framework that is both energy-efficient and responsive. This case study demonstrates how the neuromorphic IoT architecture can be deployed in a real-world scenario, highlighting its benefits in terms of energy savings, reduced communication overhead, and improved system responsiveness.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submitted to Edge AI conference, Cagliari, Italy"
    },
    {
        "paper id": "2410.20003",
        "abstract url": "https://arxiv.org/abs/2410.20003",
        "title": "Federated Anomaly Detection for Early-Stage Diagnosis of Autism Spectrum Disorders using Serious Game Data",
        "rating": "-4.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "attacks"
            ],
            [
                "Diagnosis"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Early identification of Autism Spectrum Disorder (ASD) is considered critical for effective intervention to mitigate emotional, financial and societal burdens. Although ASD belongs to a group of neurodevelopmental disabilities that are not curable, researchers agree that targeted interventions during childhood can drastically improve the overall well-being of individuals. However, conventional ASD detection methods such as screening tests, are often costly and time-consuming. This study presents a novel semi-supervised approach for ASD detection using AutoEncoder-based Machine Learning (ML) methods due to the challenge of obtaining ground truth labels for the associated task. Our approach utilizes data collected manually through a serious game specifically designed for this purpose. Since the sensitive data collected by the gamified application are susceptible to privacy leakage, we developed a Federated Learning (FL) framework that can enhance user privacy without compromising the overall performance of the ML models. The framework is further enhanced with Fully Homomorphic Encryption (FHE) during model aggregation to minimize the possibility of inference attacks and client selection mechanisms as well as state-of-the-art aggregators to improve the model's predictive accuracy. Our results demonstrate that semi-supervised FL can effectively predict an ASD risk indicator for each case while simultaneously addressing privacy concerns.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04135",
        "abstract url": "https://arxiv.org/abs/2411.04135",
        "title": "A New Variant of Benes Network: Its Topological Characterisation and Comparative Analysis",
        "rating": "-5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "biology"
            ],
            [
                "chemistry"
            ]
        ],
        "abstract": "The modern era always looks into advancements in technology. Design and topology of interconnection networks play a mutual role in development of technology. Analysing the topological properties and characteristics of an interconnection network is not an easy task. Graph theory helps in solving this task analytically and efficiently through the use of numerical parameters known as distance based topological descriptors. These descriptors have considerable applications in various fields of computer science, chemistry, biology, etc. This paper deals with the evaluation of topological descriptors for an n-dimensional multistage interconnection network, the benes network,BB(n). Also, a new variant of interconnection network is derived from the benes network, named as augmented benes network and denoted as BB^* (n). The topological descriptors for the benes derived network are also determined in this work. Further, the benes network and augmented benes network undergoes a comparative analysis based on few network parameters, which helps to understand the efficiency of newly derived benes network. A broadcasting algorithm for the augmented benes network is also provided.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19338",
        "abstract url": "https://arxiv.org/abs/2410.19338",
        "title": "Privacy-preserving server-supported decryption",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we consider encryption systems with two-out-of-two threshold decryption, where one of the parties (the client) initiates the decryption and the other one (the server) assists. Existing threshold decryption schemes disclose to the server the ciphertext that is being decrypted. We give a construction, where the identity of the ciphertext is not leaked to the server, and the client's privacy is thus preserved. While showing the security of this construction, we run into the issue of defining the security of a scheme with blindly assisted decryption. We discuss previously proposed security definitions for similar cryptographic functionalities and argue why they do not capture the expected meaning of security. We propose an ideal functionality for the encryption with server-supported blind threshold decryption in the universal composability model, carefully balancing between the meaning of privacy, and the ability to implement it. We construct a protocol and show that it is a secure implementation of the proposed functionality in the random oracle model.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "To appear at Computer Security Foundations Symposium, CSF 2025"
    },
    {
        "paper id": "2410.19348",
        "abstract url": "https://arxiv.org/abs/2410.19348",
        "title": "How high dimensional neural dynamics are confined in phase space",
        "rating": "-10",
        "keywords": [],
        "abstract": "High dimensional dynamics play a vital role in brain function, ecological systems, and neuro-inspired machine learning. Where and how these dynamics are confined in the phase space remains challenging to solve. Here, we provide an analytic argument that the confinement region is an M-shape when the neural dynamics show a diversity, with two sharp boundaries and a flat low-density region in between. Despite increasing synaptic strengths in a neural circuit, the shape remains qualitatively the same, while the left boundary is continuously pushed away. However, in deep chaotic regions, an arch-shaped confinement gradually emerges. Our theory is supported by numerical simulations on finite-sized networks. This analytic theory opens up a geometric route towards addressing fundamental questions about high dimensional non-equilibrium dynamics.",
        "subjects": [
            "q-bio.NC",
            "cond-mat.stat-mech",
            "cs.NE",
            "nlin.CD"
        ],
        "comment": "24 pages, 5 figures"
    },
    {
        "paper id": "2410.19359",
        "abstract url": "https://arxiv.org/abs/2410.19359",
        "title": "Joint User Scheduling and Precoding for RIS-Aided MU-MISO Systems: A MADRL Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the increasing demand for spectrum efficiency and energy efficiency, reconfigurable intelligent surfaces (RISs) have attracted massive attention due to its low-cost and capability of controlling wireless environment. However, there is still a lack of treatments to deal with the growth of the number of users and RIS elements, which may incur performance degradation or computational complexity explosion. In this paper, we investigate the joint optimization of user scheduling and precoding for distributed RIS-aided communication systems. Firstly, we propose an optimization-based numerical method to obtain suboptimal solutions with the aid of the approximation of ergodic sum rate. Secondly, to reduce the computational complexity caused by the high dimensionality, we propose a data-driven scalable and generalizable multi-agent deep reinforcement learning (MADRL) framework with the aim to maximize the ergodic sum rate approximation through the cooperation of all agents. Further, we propose a novel dynamic working process exploiting the trained MADRL algorithm, which enables distributed RISs to configure their own passive precoding independently. Simulation results show that our algorithm substantially reduces the computational complexity by a time reduction of three orders of magnitude at the cost of 3% performance degradation, compared with the optimization-based method, and achieves 6% performance improvement over the state-of-the-art MADRL algorithms.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19364",
        "abstract url": "https://arxiv.org/abs/2410.19364",
        "title": "The Impact of Train-Test Leakage on Machine Learning-based Android Malware Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "When machine learning is used for Android malware detection, an app needs to be represented in a numerical format for training and testing. We identify a widespread occurrence of distinct Android apps that have identical or nearly identical app representations. In particular, among app samples in the testing dataset, there can be a significant percentage of apps that have an identical or nearly identical representation to an app in the training dataset. This will lead to a data leakage problem that inflates a machine learning model's performance as measured on the testing dataset. The data leakage not only could lead to overly optimistic perceptions on the machine learning models' ability to generalize beyond the data on which they are trained, in some cases it could also lead to qualitatively different conclusions being drawn from the research. We present two case studies to illustrate this impact. In the first case study, the data leakage inflated the performance results but did not impact the overall conclusions made by the researchers in a qualitative way. In the second case study, the data leakage problem would have led to qualitatively different conclusions being drawn from the research. We further propose a leak-aware scheme to construct a machine learning-based Android malware detector, and show that it can improve upon the overall detection performance.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19383",
        "abstract url": "https://arxiv.org/abs/2410.19383",
        "title": "A Modulo Sampling Hardware Prototype and Reconstruction Algorithm Evaluation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Analog-to-digital converters (ADCs) play a vital important role in any devices via manipulating analog signals in a digital manner. Given that the amplitude of the signal exceeds the dynamic range of the ADCs, clipping occurs and the quality of the digitized signal degrades significantly. In this paper, we design a joint modulo sampling hardware and processing prototype which improves the ADCs' dynamic range by folding the signal before sampling. Both the detailed design of the hardware and the recovery results of various state-of-the-art processing algorithms including our proposed unlimited sampling line spectral estimation (USLSE) algorithm are presented. Additionally, key issues that arise during implementation are also addressed. It is demonstrated that the USLSE algorithm successfully recovers the original signal with a frequency of 2.5 kHz and an amplitude 10 times the ADC's dynamic range, and the linear prediction (LP) algorithm successfully recovers the original signal with a frequency of 3.5 kHz and an amplitude 10 times the ADC's dynamic range.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19386",
        "abstract url": "https://arxiv.org/abs/2410.19386",
        "title": "A Uniform Framework for Problems on Context-Free Grammars",
        "rating": "-10",
        "keywords": [],
        "abstract": "In a paper published in Information Processing Letters in 2000, Bouajjani et al. presented an automata-based approach to a number of elementary problems on context-free grammars. This approach is of pedagogical interest since it provides a uniform solution to decision procedures usually solved by independent algorithms in textbooks. This paper improves upon the work by Bouajjani et al. in a number of ways. We present a new algorithm which not only has a better space complexity but is also (in our opinion) easier to read and understand. Moreover, a closer inspection reveals that the new algorithm is competitive to well-known solutions for most (but not all) standard problems.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19405",
        "abstract url": "https://arxiv.org/abs/2410.19405",
        "title": "Completeness of FSM Test Suites Reconsidered",
        "rating": "-10",
        "keywords": [],
        "abstract": "A fault domain that has been widely studied in black-box conformance testing is the class of finite state machines (FSMs) with at most $k$ extra states. Numerous methods for generating test suites have been proposed that guarantee fault coverage for this class. These test suites grow exponentially in $k$, so one can only run them for small $k$. But the assumption that $k$ is small is not realistic in practice. As a result, completeness for this fault domain has limited practical significance. As an alternative, we propose (much larger) fault domains that capture the assumption that when bugs in an implementation introduce extra states, these states can be reached via a few (at most $k$) transitions from states reachable via a set $A$ of common scenarios. Preliminary evidence suggests these fault domains, which contain FSMs with an exponential number of extra states (in $k$), are of practical use for testing network protocols. We present a sufficient condition for \\emph{$k$-$A$-completeness} of test suites with respect to these fault domains, phrased entirely in terms of properties of their testing tree. Our condition implies $k$-$A$-completeness of two prominent test suite generation algorithms, the Wp and HSI methods. Counterexamples show that three other approaches, the H, SPY and SPYH methods, do not always generate $k$-$A$-complete test suites.",
        "subjects": [
            "cs.FL",
            "cs.SE"
        ],
        "comment": "40 pages"
    },
    {
        "paper id": "2410.19411",
        "abstract url": "https://arxiv.org/abs/2410.19411",
        "title": "A potpourri of results on molecular communication with active transport",
        "rating": "-10",
        "keywords": [],
        "abstract": "Molecular communication (MC) is a model of information transmission where the signal is transmitted by information-carrying molecules through their physical transport from a transmitter to a receiver through a communication channel. Prior efforts have identified suitable \"information molecules\" whose efficacy for signal transmission has been studied extensively in diffusive channels (DC). Although easy to implement, DCs are inefficient for distances longer than tens of nanometers. In contrast, molecular motor-driven nonequilibrium or active transport can drastically increase the range of communication and may permit efficient communication up to tens of micrometers. In this paper, we investigate how active transport influences the efficacy of molecular communication, quantified by the mutual information between transmitted and received signals. We consider two specific scenarios: (a) active transport through relays and (b) active transport through a mixture of active and diffusing particles. In each case, we discuss the efficacy of the communication channel and discuss their potential pitfalls.",
        "subjects": [
            "cond-mat.stat-mech",
            "cond-mat.soft",
            "cs.ET",
            "eess.SP",
            "physics.bio-ph"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2410.19430",
        "abstract url": "https://arxiv.org/abs/2410.19430",
        "title": "Progressive Glimmer: Expanding Dimensionality in Multidimensional Scaling",
        "rating": "-10",
        "keywords": [],
        "abstract": "Progressive dimensionality reduction algorithms allow for visually investigating intermediate results, especially for large data sets. While different algorithms exist that progressively increase the number of data points, we propose an algorithm that allows for increasing the number of dimensions. Especially in spatio-temporal data, where each spatial location can be seen as one data point and each time step as one dimension, the data is often stored in a format that supports quick access to the individual dimensions of all points. Therefore, we propose Progressive Glimmer, a progressive multidimensional scaling (MDS) algorithm. We adapt the Glimmer algorithm to support progressive updates for changes in the data's dimensionality. We evaluate Progressive Glimmer's embedding quality and runtime. We observe that the algorithm provides more stable results, leading to visually consistent results for progressive rendering and making the approach applicable to streaming data. We show the applicability of our approach to spatio-temporal simulation ensemble data where we add the individual ensemble members progressively.",
        "subjects": [
            "cs.GR",
            "cs.HC"
        ],
        "comment": "6 pages, 5 figures, presented at 2024 IEEE VIS Workshop on Progressive Data Analysis and Visualization (PDAV)"
    },
    {
        "paper id": "2410.19434",
        "abstract url": "https://arxiv.org/abs/2410.19434",
        "title": "Evolving choice hysteresis in reinforcement learning: comparing the adaptive value of positivity bias and gradual perseveration",
        "rating": "-10",
        "keywords": [],
        "abstract": "The tendency of repeating past choices more often than expected from the history of outcomes has been repeatedly empirically observed in reinforcement learning experiments. It can be explained by at least two computational processes: asymmetric update and (gradual) choice perseveration. A recent meta-analysis showed that both mechanisms are detectable in human reinforcement learning. However, while their descriptive value seems to be well established, they have not been compared regarding their possible adaptive value. In this study, we address this gap by simulating reinforcement learning agents in a variety of environments with a new variant of an evolutionary algorithm. Our results show that positivity bias (in the form of asymmetric update) is evolutionary stable in many situations, while the emergence of gradual perseveration is less systematic and robust. Overall, our results illustrate that biases can be adaptive and selected by evolution, in an environment-specific manner.",
        "subjects": [
            "cs.NE",
            "q-bio.NC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19439",
        "abstract url": "https://arxiv.org/abs/2410.19439",
        "title": "Non-Dominated Sorting Bidirectional Differential Coevolution",
        "rating": "-10",
        "keywords": [],
        "abstract": "Constrained multiobjective optimization problems (CMOPs) are commonly found in real-world applications. CMOP is a complex problem that needs to satisfy a set of equality or inequality constraints. This paper proposes a variant of the bidirectional coevolution algorithm (BiCo) with differential evolution (DE). The novelties in the model include the DE differential mutation and crossover operators as the main search engine and a non-dominated sorting selection scheme. Experimental results on two benchmark test suites and eight real-world CMOPs suggested that the proposed model reached better overall performance than the original model.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2410.19473",
        "abstract url": "https://arxiv.org/abs/2410.19473",
        "title": "A Robust and Efficient Visual-Inertial Initialization with Probabilistic Normal Epipolar Constraint",
        "rating": "-10",
        "keywords": [],
        "abstract": "Accurate and robust initialization is essential for Visual-Inertial Odometry (VIO), as poor initialization can severely degrade pose accuracy. During initialization, it is crucial to estimate parameters such as accelerometer bias, gyroscope bias, initial velocity, and gravity, etc. The IMU sensor requires precise estimation of gyroscope bias because gyroscope bias affects rotation, velocity and position. Most existing VIO initialization methods adopt Structure from Motion (SfM) to solve for gyroscope bias. However, SfM is not stable and efficient enough in fast motion or degenerate scenes. To overcome these limitations, we extended the rotation-translation-decoupling framework by adding new uncertainty parameters and optimization modules. First, we adopt a gyroscope bias optimizer that incorporates probabilistic normal epipolar constraints. Second, we fuse IMU and visual measurements to solve for velocity, gravity, and scale efficiently. Finally, we design an additional refinement module that effectively diminishes gravity and scale errors. Extensive initialization tests on the EuRoC dataset show that our method reduces the gyroscope bias and rotation estimation error by an average of 16% and 4% respectively. It also significantly reduces the gravity error, with an average reduction of 29%.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19497",
        "abstract url": "https://arxiv.org/abs/2410.19497",
        "title": "Available Degrees of Spatial Multiplexing of a Uniform Linear Array with Multiple Polarizations: a Holographic Perspective",
        "rating": "-10",
        "keywords": [],
        "abstract": "The capabilities of multi-antenna technology have recently been significantly enhanced by the proliferation of extra large array architectures. The high dimensionality of these systems implies that communications take place in the nearfield regime, which poses some questions as to their effective perfomrance even under simple line of sight configurations. In order to study these limitations, a uniform linear array (ULA) is considered here, the elements of which are three infinitesimal dipoles transmitting different signals in the three spatial dimensions. The receiver consists of a single element with three orthogonal infinitesimal dipoles and full channel state information is assumed to be available at both ends. A capacity analysis is presented when the number of elements of the ULA increases without bound while the interelement distance converges to zero, so that the total aperture length is kept asymptotically fixed. In particular, the total number of available spatial eigenmodes is shown to depend crucially on the receiver position in space, and closed form expressions are provided for the different achievability regions. From the analysis it can be concluded that the use of three orthogonal polarizations at the transmitter guarantees the almost universal availability of two spatial streams, whereas the use of only two polarizations results in a more extensive region where maximum multiplexing gain is available.",
        "subjects": [
            "cs.IT",
            "cs.ET",
            "eess.SP"
        ],
        "comment": "Submitted to IEEE Open Journal on Signal Processing"
    },
    {
        "paper id": "2410.19520",
        "abstract url": "https://arxiv.org/abs/2410.19520",
        "title": "Synthetic 1-Categories in Directed Type Theory",
        "rating": "-10",
        "keywords": [],
        "abstract": "The field of directed type theory seeks to design type theories capable of reasoning synthetically about (higher) categories, by generalizing the symmetric identity types of Martin-L\u00f6f Type Theory to asymmetric hom-types. We articulate the directed type theory of the category model, with appropriate modalities for keeping track of variances and a powerful directed-J rule capable of proving results about arbitrary terms of hom-types; we put this rule to use in making several constructions in synthetic 1-category theory. Because this theory is expressed entirely in terms of generalized algebraic theories, we know automatically that this directed type theory admits a syntax model and is the first step towards directed higher observational type theory.",
        "subjects": [
            "math.CT",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19522",
        "abstract url": "https://arxiv.org/abs/2410.19522",
        "title": "A Practical Approach to Combinatorial Test Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Typical software has a huge input space. The number of inputs may be astronomical or even infinite. Thus, the task of validating that the software is correct seems hopeless. To deal with this difficult task, Combinatorial Test Design (CTD) can be used to provide reduction of the testing space and high quality and efficient testing. The application of CTD is largely determined by the quality of the CTD model. This book covers the CTD test design methodology and CTD modeling in details. It elaborates on the process of constraints definition. It also explains how to best define your coverage requirements to direct and focus your tests. It is hard to create good CTD models without a good grasp of the implementation of CTD tooling. To that hand, the book also takes a deeper dive into covering principles and algorithms needed to build CTD tooling. Hands on exercises are used throughout the text and help create a clear understanding of the concepts covered within this book.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19559",
        "abstract url": "https://arxiv.org/abs/2410.19559",
        "title": "Flexibility Options: A Proposed Product for Managing Imbalance Risk",
        "rating": "-10",
        "keywords": [],
        "abstract": "The presence of variable renewable energy resources with uncertain outputs in day-ahead electricity markets results in additional balancing needs in real-time. Addressing those needs cost-effectively and reliably within a competitive market with unbundled products is challenging as both the demand for and the availability of flexibility depends on day-ahead energy schedules. Existing approaches for reserve procurement usually rely either on oversimplified demand curves that do not consider how system conditions that particular day affect the value of flexibility, or on bilateral trading of hedging instruments that are not co-optimized with day-ahead schedules. This article proposes a new product, `Flexibility Options', to address these two limitations. The demand for this product is endogenously determined in the day-ahead market and it is met cost-effectively by considering real-time supply curves for product providers, which are co-optimized with the energy supply. As we illustrate with numerical examples and mathematical analysis, the product addresses the hedging needs of participants with imbalances, provides a less intermittent revenue stream for participants with flexible outputs, promotes convergence between day-ahead and real-time energy prices, and ensures that the system operator is revenue-neutral. This article provides a comprehensive design that can be further tested and applied in large-scale systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19571",
        "abstract url": "https://arxiv.org/abs/2410.19571",
        "title": "A Field Calibration Approach for Triaxial MEMS Gyroscopes Based on Gravity and Rotation Consistency",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper developed an efficient method for calibrating triaxial MEMS gyroscopes, which can be effectively utilized in the field environment. The core strategy is to utilize the criterion that the dot product of the measured gravity and the rotation speed in a fixed frame remains constant. To eliminate the impact of external acceleration, the calibration process involves separate procedures for measuring local gravity and rotation speed. Moreover, unlike existing approaches for auto calibration of triaxial sensors that often result in nonlinear optimization problems, the proposed method simplifies the estimation of the gyroscope scale factor by employing a linear least squares algorithm. Extensive numerical simulations have been conducted to analyze the proposed method's performance in calibrating the six-parameter triaxial gyroscope model, taking into consideration measurements corrupted by simulated noise. Experimental validation was also carried out using two commercially available MEMS inertial measurement units (LSM9DS1) and a servo motor. The experimental results effectively demonstrate the efficacy of the proposed calibration approach.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19593",
        "abstract url": "https://arxiv.org/abs/2410.19593",
        "title": "Energy Efficient Dual Designs of FeFET-Based Analog In-Memory Computing with Inherent Shift-Add Capability",
        "rating": "-10",
        "keywords": [],
        "abstract": "In-memory computing (IMC) architecture emerges as a promising paradigm, improving the energy efficiency of multiply-and-accumulate (MAC) operations within DNNs by integrating the parallel computations within the memory arrays. Various high-precision analog IMC array designs have been developed based on both SRAM and emerging non-volatile memories. These designs perform MAC operations of partial input and weight, with the corresponding partial products then fed into shift-add circuitry to produce the final MAC results. However, existing works often present intricate shift-add process for weight. The traditional digital shift-add process is limited in throughput due to time-multiplexing of ADCs, and advancing the shift-add process to the analog domain necessitates customized circuit implementations, resulting in compromises in energy and area efficiency. Furthermore, the joint optimization of the partial MAC operations and the weight shift-add process is rarely explored. In this paper, we propose novel, energy efficient dual designs of FeFET based high precision analog IMC featuring inherent shift-add capability. We introduce a FeFET based IMC paradigm that performs partial MAC in each column, and inherently integrates the shift-add process for 4-bit weights by leveraging FeFET's analog storage characteristics. This paradigm supports both 2's complement mode and non-2's complement mode MAC, thereby offering flexible support for 4-/8-bit weight data in 2's complement format. Building upon this paradigm, we propose novel FeFET based dual designs, CurFe for the current mode and ChgFe for the charge mode, to accommodate the high precision analog domain IMC architecture.Evaluation results at circuit and system levels indicate that the circuit/system-level energy efficiency of the proposed FeFET-based analog IMC is 1.56$\\times$/1.37$\\times$ higher when compared to SOTA analog IMC designs.",
        "subjects": [
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19615",
        "abstract url": "https://arxiv.org/abs/2410.19615",
        "title": "Equilibrium Adaptation-Based Control for Track Stand of Single-Track Two-Wheeled Robots",
        "rating": "-10",
        "keywords": [],
        "abstract": "Stationary balance control is challenging for single-track two-wheeled (STTW) robots due to the lack of elegant balancing mechanisms and the conflict between the limited attraction domain and external disturbances. To address the absence of balancing mechanisms, we draw inspiration from cyclists and leverage the track stand maneuver, which relies solely on steering and rear-wheel actuation. To achieve accurate tracking in the presence of matched and mismatched disturbances, we propose an equilibrium adaptation-based control (EABC) scheme that can be seamlessly integrated with standard disturbance observers and controllers. This scheme enables adaptation to slow-varying disturbances by utilizing a disturbed equilibrium estimator, effectively handling both matched and mismatched disturbances in a unified manner while ensuring accurate tracking with zero steady-state error. We integrate the EABC scheme with nonlinear model predictive control (MPC) for the track stand of STTW robots and validate its effectiveness through two experimental scenarios. Our method demonstrates significant improvements in tracking accuracy, reducing errors by several orders of magnitude.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2410.19626",
        "abstract url": "https://arxiv.org/abs/2410.19626",
        "title": "On warped product on information geometry: statistical manifolds and statistical models",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study a differential geometric construction, the warped product, on the background geometry for information theory. Divergences, dual structures and symmetric 3-tensor are studied under this construction, and we show that warped product of manifolds endow with such structure also is endowed with the same geometric notion. However, warped product does not preserve canonical divergences, which in particular shows that warped product lacks of meaning in the information theory setting.",
        "subjects": [
            "math.DG",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19629",
        "abstract url": "https://arxiv.org/abs/2410.19629",
        "title": "Sampling in Parametric and Nonparametric System Identification: Aliasing, Input Conditions, and Consistency",
        "rating": "-10",
        "keywords": [],
        "abstract": "The sampling rate of input and output signals is known to play a critical role in the identification and control of dynamical systems. For slow-sampled continuous-time systems that do not satisfy the Nyquist-Shannon sampling condition for perfect signal reconstructability, careful consideration is required when identifying parametric and nonparametric models. In this letter, a comprehensive statistical analysis of estimators under slow sampling is performed. Necessary and sufficient conditions are obtained for unbiased estimates of the frequency response function beyond the Nyquist frequency, and it is shown that consistency of parametric estimators can be achieved even if input frequencies overlap after aliasing. Monte Carlo simulations confirm the theoretical properties.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "6 pages, 2 figures"
    },
    {
        "paper id": "2410.19654",
        "abstract url": "https://arxiv.org/abs/2410.19654",
        "title": "An explicit condition for boundedly supermultiplicative subshifts",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study some properties of the growth rate of $\\mathcal{L}(\\mathcal{A},\\mathcal{F})$, that is, the language of words over the alphabet $\\mathcal{A}$ avoiding the set of forbidden factors $\\mathcal{F}$. We first provide a sufficient condition on $\\mathcal{F}$ and $\\mathcal{A}$ for the growth of $\\mathcal{L}(\\mathcal{A},\\mathcal{F})$ to be boundedly supermultiplicative. That is, there exist constants $C>0$ and $\u03b1\\ge0$, such that for all $n$, the number of words of length $n$ in $\\mathcal{L}(\\mathcal{A},\\mathcal{F})$ is between $\u03b1^n$ and $C\u03b1^n$. In some settings, our condition provides a way to compute $C$, which implies that $\u03b1$, the growth rate of the language, is also computable whenever our condition holds. We also apply our technique to the specific setting of power-free words where the argument can be slightly refined to provide better bounds. Finally, we apply a similar idea to $\\mathcal{F}$-free circular words and in particular we make progress toward a conjecture of Shur about the number of square-free circular words.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19681",
        "abstract url": "https://arxiv.org/abs/2410.19681",
        "title": "Optimizing Hearthstone Agents using an Evolutionary Algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "Digital collectible card games are not only a growing part of the video game industry, but also an interesting research area for the field of computational intelligence. This game genre allows researchers to deal with hidden information, uncertainty and planning, among other aspects. This paper proposes the use of evolutionary algorithms (EAs) to develop agents who play a card game, Hearthstone, by optimizing a data-driven decision-making mechanism that takes into account all the elements currently in play. Agents feature self-learning by means of a competitive coevolutionary training approach, whereby no external sparring element defined by the user is required for the optimization process. One of the agents developed through the proposed approach was runner-up (best 6%) in an international Hearthstone Artificial Intelligence (AI) competition. Our proposal performed remarkably well, even when it faced state-of-the-art techniques that attempted to take into account future game states, such as Monte-Carlo Tree search. This outcome shows how evolutionary computation could represent a considerable advantage in developing AIs for collectible card games such as Hearthstone.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "43 pages, 11 figures"
    },
    {
        "paper id": "2410.19684",
        "abstract url": "https://arxiv.org/abs/2410.19684",
        "title": "Soft Finger Grasp Force and Contact State Estimation from Tactile Sensors",
        "rating": "-10",
        "keywords": [],
        "abstract": "Soft robotic fingers can improve adaptability in grasping and manipulation, compensating for geometric variation in object or environmental contact, but today lack force capacity and fine dexterity. Integrated tactile sensors can provide grasp and task information which can improve dexterity,but should ideally not require object-specific training. The total force vector exerted by a finger provides general information to the internal grasp forces (e.g. for grasp stability) and, when summed over fingers, an estimate of the external force acting on the grasped object (e.g. for task-level control). In this study, we investigate the efficacy of estimating finger force from integrated soft sensors and use it to estimate contact states. We use a neural network for force regression, collecting labelled data with a force/torque sensor and a range of test objects. Subsequently, we apply this model in a plug-in task scenario and demonstrate its validity in estimating contact states.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19696",
        "abstract url": "https://arxiv.org/abs/2410.19696",
        "title": "Age of Coded Updates In Gossip Networks Under Memory and Memoryless Schemes",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider an information update system on a gossip network, where a source node encodes information into $n$ total keys such that any subset of at least $k+1$ keys can fully reconstruct the original information. This encoding process follows the principles of a $k$-out-of-$n$ threshold system. The encoded updates are then disseminated across the network through peer-to-peer communication. We have two different types of nodes in a network: subscriber nodes, which receive a unique key from the source node for every status update instantaneously, and nonsubscriber nodes, which receive a unique key for an update only if the node is selected by the source, and this selection is renewed for each update. For the message structure between nodes, we consider two different schemes: a memory scheme (in which the nodes keep the source's current and previous encrypted messages) and a memoryless scheme (in which the nodes are allowed to only keep the source's current message). We measure the timeliness of information updates by using a recent performance metric, the version age of information. We present explicit formulas for the time average AoI in a scalable homogeneous network as functions of the network parameters under a memoryless scheme. Additionally, we provide strict lower and upper bounds for the time average AoI under a memory scheme.",
        "subjects": [
            "cs.IT",
            "eess.SY"
        ],
        "comment": "A part of this work is presented at the ACSSC24. This work has been submitted to IEEE for possible publication. arXiv admin note: text overlap with arXiv:2402.11462"
    },
    {
        "paper id": "2410.19708",
        "abstract url": "https://arxiv.org/abs/2410.19708",
        "title": "Integrating LoRaWAN with Mobile Ad-hoc Networks for Enhanced Campus Communication",
        "rating": "-10",
        "keywords": [],
        "abstract": "The integration of Long Range Wide Area Network (LoRaWAN) with Mobile Ad-hoc Networks (MANETs) presents a promising solution for enhancing communication networks within campus environments. This paper explores the unique advantages of combining these two technologies, including scalability, energy efficiency, flexibility, and support for diverse applications. LoRaWAN low power consumption and extended range capabilities address the challenges of traditional communication methods, enabling reliable data transmission across various campus scenarios, such as emergency alerts, event coordination, and real-time monitoring. We also identify key challenges faced in this integrated architecture, including signal interference, data packet collisions, and energy management. By providing a comprehensive survey of existing techniques and solutions categorized by the network protocol stack layers, this study aims to inform future research and development efforts in creating robust, energy efficient communication systems tailored for modern educational institutions. Ultimately, the findings highlight the potential of LoRaWAN MANET architectures to transform campus communication into a more reliable, adaptable, and cost effective framework.",
        "subjects": [
            "cs.NI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19721",
        "abstract url": "https://arxiv.org/abs/2410.19721",
        "title": "Validity in Network-Agnostic Byzantine Agreement",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Byzantine Agreement (BA), there is a set of $n$ parties, from which up to $t$ can act byzantine. All honest parties must eventually decide on a common value (agreement), which must belong to a set determined by the inputs (validity). Depending on the use case, this set can grow or shrink, leading to various possible desiderata collectively known as validity conditions. Varying the validity property requirement can affect the regime under which BA is solvable. We study how the selected validity property impacts BA solvability in the network-agnostic model, where the network can either be synchronous with up to $t_s$ byzantine parties or asynchronous with up to $t_a \\leq t_s$ byzantine parties. We show that for any non-trivial validity property the condition $2t_s + t_a < n$ is necessary for BA to be solvable, even with cryptographic setup. Noteworthy, specializing this claim to $t_a = 0$ gives that $t < n / 2$ is required when one expects a purely synchronous protocol to also work in asynchrony when there are no corruptions. This is especially surprising given that for some validity properties $t < n$ are known to be achievable without the last stipulation. Thereafter, we give necessary and sufficient conditions for a validity property to render BA solvable, both for the case with cryptographic setup and for the one without. This traces the precise boundary of solvability in the network-agnostic model for every validity property. Our proof of sufficiency provides a universal protocol, that achieves BA for a given validity property whenever the provided conditions are satisfied.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Working paper"
    },
    {
        "paper id": "2410.19927",
        "abstract url": "https://arxiv.org/abs/2410.19927",
        "title": "Scheduling Languages: A Past, Present, and Future Taxonomy",
        "rating": "-10",
        "keywords": [],
        "abstract": "Scheduling languages express to a compiler a sequence of optimizations to apply. Compilers that support a scheduling language interface allow exploration of compiler optimizations, i.e., exploratory compilers. While scheduling languages have become a common feature of tools for expert users, the proliferation of these languages without unifying common features may be confusing to users. Moreover, we recognize a need to organize the compiler developer community around common exploratory compiler infrastructure, and future advances to address, for example, data layout and data movement. To support a broader set of users may require raising the level of abstraction. This paper provides a taxonomy of scheduling languages, first discussing their origins in iterative compilation and autotuning, noting the common features and how they are used in existing frameworks, and then calling for changes to increase their utility and portability.",
        "subjects": [
            "cs.PL",
            "cs.DC",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19958",
        "abstract url": "https://arxiv.org/abs/2410.19958",
        "title": "Hybrid Iterative Linear Quadratic Estimation: Optimal Estimation for Hybrid Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we present Hybrid iterative Linear Quadratic Estimation (HiLQE), an optimization based offline state estimation algorithm for hybrid dynamical systems. We utilize the saltation matrix, a first order approximation of the variational update through an event driven hybrid transition, to calculate gradient information through hybrid events in the backward pass of an iterative linear quadratic optimization over state estimates. This enables accurate computation of the value function approximation at each timestep. Additionally, the forward pass in the iterative algorithm is augmented with hybrid dynamics in the rollout. A reference extension method is used to account for varying impact times when comparing states for the feedback gain in noise calculation. The proposed method is demonstrated on an ASLIP hopper system with position measurements. In comparison to the Salted Kalman Filter (SKF), the algorithm presented here achieves a maximum of 63.55% reduction in estimation error magnitude over all state dimensions near impact events.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19962",
        "abstract url": "https://arxiv.org/abs/2410.19962",
        "title": "The Signaler-Responder Game: Learning to Communicate using Thompson Sampling",
        "rating": "-10",
        "keywords": [],
        "abstract": "We are interested in studying how heterogeneous agents can learn to communicate and cooperate with each other without being explicitly pre-programmed to do so. Motivated by this goal, we present and analyze a distributed solution to a two-player signaler-responder game which is defined as follows. The signaler agent has a random, exogenous need and can choose from four different strategies: never signal, always signal, signal when need, and signal when no need. The responder agent can choose to either ignore or respond to the signal. We define a reward to both agents when they cooperate to satisfy the signaler's need, and costs associated with communication, response and unmet needs. We identify pure Nash equilibria of the game and the conditions under which they occur. As a solution for this game, we propose two new distributed Bayesian learning algorithms, one for each agent, based on the classic Thompson Sampling policy for multi-armed bandits. These algorithms allow both agents to update beliefs about both the exogenous need and the behavior of the other agent and optimize their own expected reward. We show that by using these policies, the agents are able to intelligently adapt their strategies over multiple iterations to attain efficient, reward-maximizing equilibria under different settings, communicating and cooperating when it is rewarding to do so, and not communicating or cooperating when it is too expensive.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2410.19993",
        "abstract url": "https://arxiv.org/abs/2410.19993",
        "title": "XbarSim: A Decomposition-Based Memristive Crossbar Simulator",
        "rating": "-10",
        "keywords": [],
        "abstract": "Given the growing focus on memristive crossbar-based in-memory computing (IMC) architectures as a potential alternative to current energy-hungry machine learning hardware, the availability of a fast and accurate circuit-level simulation framework could greatly enhance research and development efforts in this field. This paper introduces XbarSim, a domain-specific circuit-level simulator designed to analyze the nodal equations of memristive crossbars. The first version of XbarSim, proposed herein, leverages the lower-upper (LU) decomposition approach to solve the nodal equations for the matrices associated with crossbars. The XbarSim is capable of simulating interconnect parasitics within crossbars and supports batch processing of the inputs. Through comprehensive experiments, we demonstrate that the XbarSim can achieve orders of magnitude speedup compared to HSPICE across various sizes of memristive crossbars. The XbarSim's full suite of features is accessible to researchers as an open-source tool.",
        "subjects": [
            "cs.ET",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20004",
        "abstract url": "https://arxiv.org/abs/2410.20004",
        "title": "Lightweight, Secure and Stateful Serverless Computing with PSL",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present PSL, a lightweight, secure and stateful Function-as-a-Serivce (FaaS) framework for Trusted Execution Environments (TEEs). The framework provides rich programming language support on heterogeneous TEE hardware for statically compiled binaries and/or WebAssembly (WASM) bytecodes, with a familiar Key-Value Store (KVS) interface to secure, performant, network-embedded storage. It achieves near-native execution speeds by utilizing the dynamic memory mapping capabilities of Intel SGX2 to create an in-enclave WASM runtime with Just-In-Time (JIT) compilation. PSL is designed to efficiently operate within an asynchronous environment with a distributed tamper-proof confidential storage system, assuming minority failures. The system exchanges eventually-consistent state updates across nodes while utilizing release-consistent locking mechanisms to enhance transactional capabilities. The execution of PSL is up to 3.7x faster than the state-of-the-art SGX WASM runtime. PSL reaches 95k ops/s with YCSB 100% read workload and 89k ops/s with 50% read/write workload. We demonstrate the scalability and adaptivity of PSL through a case study of secure and distributed training of deep neural networks.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20020",
        "abstract url": "https://arxiv.org/abs/2410.20020",
        "title": "List-Decoding Capacity Implies Capacity on the q-ary Symmetric Channel",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is known that the Shannon capacity of the q-ary symmetric channel (qSC) is the same as the list-decoding capacity of an adversarial channel, raising the question of whether there is a formal (and black-box) connection between the two. We show that there is: Any linear code $C\\subseteq \\mathbb{F}_q^n$ that has minimum distance $d_{\\min}=\u03c9(q^3)$ and achieves list-decoding capacity also achieves capacity on the qSC.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2410.20042",
        "abstract url": "https://arxiv.org/abs/2410.20042",
        "title": "Multi-IRS Enhanced Wireless Coverage: Deployment Optimization Based on Large-Scale Channel Knowledge",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we study the intelligent reflecting surface (IRS) deployment problem where a number of IRSs are optimally placed in a target area to improve its signal coverage with the serving base station (BS). To achieve this, we assume that there is a given set of candidate sites in the target area for deploying IRSs and divide the area into multiple grids of identical size. Then, we derive the average channel power gains from the BS to IRS in each candidate site and from this IRS to any grid in the target area in terms of IRS deployment parameters, including its size, position, height, and orientation. Thus, we are able to approximate the average cascaded channel power gain from the BS to each grid via any IRS, assuming an effective IRS reflection gain based on the large-scale channel knowledge only. Next, we formulate a multi-IRS deployment optimization problem to minimize the total deployment cost by selecting a subset of candidate sites for deploying IRSs and jointly optimizing their heights, orientations, and numbers of reflecting elements while satisfying a given coverage rate performance requirement over all grids in the target area. To solve this challenging combinatorial optimization problem, we first reformulate it as an integer linear programming problem and solve it optimally using the branch-and-bound (BB) algorithm. In addition, we propose an efficient successive refinement algorithm to further reduce computational complexity. Simulation results demonstrate that the proposed lower-complexity successive refinement algorithm achieves near-optimal performance but with significantly reduced running time compared to the proposed optimal BB algorithm, as well as superior performance-cost trade-off than other baseline IRS deployment strategies.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2410.20067",
        "abstract url": "https://arxiv.org/abs/2410.20067",
        "title": "Evaluating the Influences of Explanation Style on Human-AI Reliance",
        "rating": "-10",
        "keywords": [],
        "abstract": "Explainable AI (XAI) aims to support appropriate human-AI reliance by increasing the interpretability of complex model decisions. Despite the proliferation of proposed methods, there is mixed evidence surrounding the effects of different styles of XAI explanations on human-AI reliance. Interpreting these conflicting findings requires an understanding of the individual and combined qualities of different explanation styles that influence appropriate and inappropriate human-AI reliance, and the role of interpretability in this interaction. In this study, we investigate the influences of feature-based, example-based, and combined feature- and example-based XAI methods on human-AI reliance through a two-part experimental study with 274 participants comparing these explanation style conditions. Our findings suggest differences between feature-based and example-based explanation styles beyond interpretability that affect human-AI reliance patterns across differences in individual performance and task complexity. Our work highlights the importance of adapting explanations to their specific users and context over maximising broad interpretability.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "20 pages"
    },
    {
        "paper id": "2410.20075",
        "abstract url": "https://arxiv.org/abs/2410.20075",
        "title": "Almost Sure Convergence of Networked Policy Gradient over Time-Varying Networks in Markov Potential Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose networked policy gradient play for solving Markov potential games including continuous action and state spaces. In the decentralized algorithm, agents sample their actions from parametrized and differentiable policies that depend on the current state and other agents' policy parameters. During training, agents estimate their gradient information through two consecutive episodes, generating unbiased estimators of reward and policy score functions. Using this information, agents compute the stochastic gradients of their policy functions and update their parameters accordingly. Additionally, they update their estimates of other agents' policy parameters based on the local estimates received through a time-varying communication network. In Markov potential games, there exists a potential value function among agents with gradients corresponding to the gradients of local value functions. Using this structure, we prove the almost sure convergence of joint policy parameters to stationary points of the potential value function. We also show that the convergence rate of the networked policy gradient algorithm is $\\mathcal{O}(1/\u03b5^2)$. Numerical experiments on a dynamic multi-agent newsvendor problem verify the convergence of local beliefs and gradients. It further shows that networked policy gradient play converges as fast as independent policy gradient updates, while collecting higher rewards.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "22 pages, journal version"
    },
    {
        "paper id": "2410.21320",
        "abstract url": "https://arxiv.org/abs/2410.21320",
        "title": "The D-Subspace Algorithm for Online Learning over Distributed Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "This material introduces the D-Subspace algorithm derived on the basis of the centralized algorithm [1], which originally addresses parameter estimation problems under a subspace constraint.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2410.22092",
        "abstract url": "https://arxiv.org/abs/2410.22092",
        "title": "Towards Data-Informed Interventions: Opportunities and Challenges of Street-level Multimodal Sensing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Over the past decades, improvements in data collection hardware coupled with novel artificial intelligence algorithms have made it possible for researchers to understand urban environments at an unprecedented scale. From local interactions between actors to city-wide infrastructural problems, this new data-driven approach enables a more informed and trustworthy decision-making process aiming at transforming cities into safer and more equitable places for living. This new moment unfolded new opportunities to understand various phenomena that directly impact how accessible cities are to heterogeneous populations. Specifically, sensing localized physical interactions among actors under different scenarios can drive substantial interventions in urban environments to make them safer for all. In this manuscript, we list opportunities and associated challenges to leverage street-level multimodal sensing data to empower domain experts in making more informed decisions and, ultimately, supporting a data-informed policymaking framework. The challenges presented here can motivate research in different areas, such as computer vision and human-computer interaction, to support cities in growing more sustainably.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "ASSETS 2024 UrbanAccess Workshop"
    }
]