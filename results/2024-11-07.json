[
    {
        "paper id": "2411.04535",
        "abstract url": "https://arxiv.org/abs/2411.04535",
        "title": "Meta-Reasoning Improves Tool Use in Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "External tools help large language models (LLMs) succeed at tasks where they would otherwise typically fail. In existing frameworks, LLMs learn tool use either by in-context demonstrations or via full model fine-tuning on annotated data. As these approaches do not easily scale, a recent trend is to abandon them in favor of lightweight, parameter-efficient tuning paradigms. These methods allow quickly alternating between the frozen LLM and its specialised fine-tuned version, by switching on or off a handful of additional custom parameters. Hence, we postulate that the generalization ability of the frozen model can be leveraged to improve tool selection. We present Tool selECTion via meta-reasONing (TECTON), a two-phase system that first reasons over a task using a custom fine-tuned LM head and outputs candidate tools. Then, with the custom head disabled, it meta-reasons (i.e., it reasons over the previous reasoning process) to make a final choice. We show that TECTON results in substantial gains - both in-distribution and out-of-distribution - on a range of math reasoning datasets.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04642",
        "abstract url": "https://arxiv.org/abs/2411.04642",
        "title": "TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Vision-Language (VL) models have garnered considerable research interest; however, they still face challenges in effectively handling text within images. To address this limitation, researchers have developed two approaches. The first method involves utilizing external Optical Character Recognition (OCR) tools to extract textual information from images, which is then prepended to other textual inputs. The second strategy focuses on employing extremely high-resolution images to improve text recognition capabilities. In this paper, we focus on enhancing the first strategy by introducing a novel method, named TAP-VL, which treats OCR information as a distinct modality and seamlessly integrates it into any VL model. TAP-VL employs a lightweight transformer-based OCR module to receive OCR with layout information, compressing it into a short fixed-length sequence for input into the LLM. Initially, we conduct model-agnostic pretraining of the OCR module on unlabeled documents, followed by its integration into any VL architecture through brief fine-tuning. Extensive experiments demonstrate consistent performance improvements when applying TAP-VL to top-performing VL models, across scene-text and document-based VL benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04680",
        "abstract url": "https://arxiv.org/abs/2411.04680",
        "title": "Differentially Private Continual Learning using Pre-Trained Models",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "This work explores the intersection of continual learning (CL) and differential privacy (DP). Crucially, continual learning models must retain knowledge across tasks, but this conflicts with the differential privacy requirement of restricting individual samples to be memorised in the model. We propose using pre-trained models to address the trade-offs between privacy and performance in a continual learning setting. More specifically, we present necessary assumptions to enable privacy-preservation and propose combining pre-trained models with parameter-free classifiers and parameter-efficient adapters that are learned under differential privacy. Our experiments demonstrate their effectiveness and provide insights into balancing the competing demands of continual learning and privacy.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "15 pages, 3 figures, Accepted at Scalable Continual Learning for Lifelong Foundation Models Workshop at 38th Conference on Neural Information Processing Systems (NeurIPS 2024)"
    },
    {
        "paper id": "2411.04923",
        "abstract url": "https://arxiv.org/abs/2411.04923",
        "title": "VideoGLaMM: A Large Multimodal Model for Pixel-Level Visual Grounding in Videos",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fine-grained alignment between videos and text is challenging due to complex spatial and temporal dynamics in videos. Existing video-based Large Multimodal Models (LMMs) handle basic conversations but struggle with precise pixel-level grounding in videos. To address this, we introduce VideoGLaMM, a LMM designed for fine-grained pixel-level grounding in videos based on user-provided textual inputs. Our design seamlessly connects three key components: a Large Language Model, a dual vision encoder that emphasizes both spatial and temporal details, and a spatio-temporal decoder for accurate mask generation. This connection is facilitated via tunable V-L and L-V adapters that enable close Vision-Language (VL) alignment. The architecture is trained to synchronize both spatial and temporal elements of video content with textual instructions. To enable fine-grained grounding, we curate a multimodal dataset featuring detailed visually-grounded conversations using a semiautomatic annotation pipeline, resulting in a diverse set of 38k video-QA triplets along with 83k objects and 671k masks. We evaluate VideoGLaMM on three challenging tasks: Grounded Conversation Generation, Visual Grounding, and Referring Video Segmentation. Experimental results show that our model consistently outperforms existing approaches across all three tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Technical Report of VideoGLaMM"
    },
    {
        "paper id": "2411.05195",
        "abstract url": "https://arxiv.org/abs/2411.05195",
        "title": "On Erroneous Agreements of CLIP Image Embeddings",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Recent research suggests that the failures of Vision-Language Models (VLMs) at visual reasoning often stem from erroneous agreements -- when semantically distinct images are ambiguously encoded by the CLIP image encoder into embeddings with high cosine similarity. In this paper, we show that erroneous agreements are not always the main culprit, as Multimodal Large Language Models (MLLMs) can still extract distinct information from them. For instance, when distinguishing objects on the left vs right in the What'sUp benchmark, the CLIP image embeddings of the left/right pairs have an average cosine similarity $>0.99$, and CLIP performs at random chance; but LLaVA-1.5-7B, which uses the same CLIP image encoder, achieves nearly $100\\%$ accuracy. We find that the extractable information in CLIP image embeddings is likely obscured by CLIP's inadequate vision-language alignment: Its matching score learned by the contrastive objective might not capture all diverse image-text correspondences. We also study the MMVP benchmark, on which prior work has shown that LLaVA-1.5 cannot distinguish image pairs with high cosine similarity. We observe a performance gain brought by attending more to visual input through an alternative decoding algorithm. Further, the accuracy significantly increases if the model can take both images as input to emphasize their nuanced differences. Both findings indicate that LLaVA-1.5 did not utilize extracted visual information sufficiently. In conclusion, our findings suggest that while improving image encoders could benefit VLMs, there is still room to enhance models with a fixed image encoder by applying better strategies for extracting and utilizing visual information.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "18 pages, 4 figures"
    },
    {
        "paper id": "2411.05261",
        "abstract url": "https://arxiv.org/abs/2411.05261",
        "title": "Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Despite significant advancements in report generation methods, a critical limitation remains: the lack of interpretability in the generated text. This paper introduces an innovative approach to enhance the explainability of text generated by report generation models. Our method employs cyclic text manipulation and visual comparison to identify and elucidate the features in the original content that influence the generated text. By manipulating the generated reports and producing corresponding images, we create a comparative framework that highlights key attributes and their impact on the text generation process. This approach not only identifies the image features aligned to the generated text but also improves transparency but also provides deeper insights into the decision-making mechanisms of the report generation models. Our findings demonstrate the potential of this method to significantly enhance the interpretability and transparency of AI-generated reports.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05281",
        "abstract url": "https://arxiv.org/abs/2411.05281",
        "title": "Fox-1 Technical Report",
        "rating": "2",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We present Fox-1, a series of small language models (SLMs) consisting of Fox-1-1.6B and Fox-1-1.6B-Instruct-v0.1. These models are pre-trained on 3 trillion tokens of web-scraped document data and fine-tuned with 5 billion tokens of instruction-following and multi-turn conversation data. Aiming to improve the pre-training efficiency, Fox-1-1.6B model introduces a novel 3-stage data curriculum across all the training data with 2K-8K sequence length. In architecture design, Fox-1 features a deeper layer structure, an expanded vocabulary, and utilizes Grouped Query Attention (GQA), offering a performant and efficient architecture compared to other SLMs. Fox-1 achieves better or on-par performance in various benchmarks compared to StableLM-2-1.6B, Gemma-2B, Qwen1.5-1.8B, and OpenELM1.1B, with competitive inference speed and throughput. The model weights have been released under the Apache 2.0 license, where we aim to promote the democratization of LLMs and make them fully accessible to the whole open-source community.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Base model is available at https://huggingface.co/tensoropera/Fox-1-1.6B and the instruction-tuned version is available at https://huggingface.co/tensoropera/Fox-1-1.6B-Instruct-v0.1"
    },
    {
        "paper id": "2411.04448",
        "abstract url": "https://arxiv.org/abs/2411.04448",
        "title": "Gradient Localization Improves Lifelong Pretraining of Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Large Language Models (LLMs) trained on web-scale text corpora have been shown to capture world knowledge in their parameters. However, the mechanism by which language models store different types of knowledge is poorly understood. In this work, we examine two types of knowledge relating to temporally sensitive entities and demonstrate that each type is localized to different sets of parameters within the LLMs. We hypothesize that the lack of consideration of the locality of knowledge in existing continual learning methods contributes to both: the failed uptake of new information, and catastrophic forgetting of previously learned information. We observe that sequences containing references to updated and newly mentioned entities exhibit larger gradient norms in a subset of layers. We demonstrate that targeting parameter updates to these relevant layers can improve the performance of continually pretraining on language containing temporal drift.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EMNLP Findings 2024"
    },
    {
        "paper id": "2411.04732",
        "abstract url": "https://arxiv.org/abs/2411.04732",
        "title": "Convolutional Differentiable Logic Gate Networks",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "With the increasing inference cost of machine learning models, there is a growing interest in models with fast and efficient inference. Recently, an approach for learning logic gate networks directly via a differentiable relaxation was proposed. Logic gate networks are faster than conventional neural network approaches because their inference only requires logic gate operators such as NAND, OR, and XOR, which are the underlying building blocks of current hardware and can be efficiently executed. We build on this idea, extending it by deep logic gate tree convolutions, logical OR pooling, and residual initializations. This allows scaling logic gate networks up by over one order of magnitude and utilizing the paradigm of convolution. On CIFAR-10, we achieve an accuracy of 86.29% using only 61 million logic gates, which improves over the SOTA while being 29x smaller.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Published at NeurIPS 2024 (Oral)"
    },
    {
        "paper id": "2411.05079",
        "abstract url": "https://arxiv.org/abs/2411.05079",
        "title": "Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model",
        "rating": "1.5",
        "keywords": [
            [
                "Vision Language"
            ],
            [
                "Text-to-Image"
            ],
            [
                "cs.CV",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Despite advancements in text-to-image models, generating images that precisely align with textual descriptions remains challenging due to misalignment in training data. In this paper, we analyze the critical role of caption precision and recall in text-to-image model training. Our analysis of human-annotated captions shows that both precision and recall are important for text-image alignment, but precision has a more significant impact. Leveraging these insights, we utilize Large Vision Language Models to generate synthetic captions for training. Models trained with these synthetic captions show similar behavior to those trained on human-annotated captions, underscores the potential for synthetic data in text-to-image training.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "EMNLP 2024 Findings. Code: https://github.com/shengcheng/Captions4T2I"
    },
    {
        "paper id": "2411.05184",
        "abstract url": "https://arxiv.org/abs/2411.05184",
        "title": "Discern-XR: An Online Classifier for Metaverse Network Traffic",
        "rating": "1.5",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we design an exclusive Metaverse network traffic classifier, named Discern-XR, to help Internet service providers (ISP) and router manufacturers enhance the quality of Metaverse services. Leveraging segmented learning, the Frame Vector Representation (FVR) algorithm and Frame Identification Algorithm (FIA) are proposed to extract critical frame-related statistics from raw network data having only four application-level features. A novel Augmentation, Aggregation, and Retention Online Training (A2R-OT) algorithm is proposed to find an accurate classification model through online training methodology. In addition, we contribute to the real-world Metaverse dataset comprising virtual reality (VR) games, VR video, VR chat, augmented reality (AR), and mixed reality (MR) traffic, providing a comprehensive benchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while improving training efficiency and reducing false-negative rates. Our work advances Metaverse network traffic classification by standing as the state-of-the-art solution.",
        "subjects": [
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05222",
        "abstract url": "https://arxiv.org/abs/2411.05222",
        "title": "Don't Look Twice: Faster Video Transformers with Run-Length Tokenization",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Transformers are slow to train on videos due to extremely large numbers of input tokens, even though many video tokens are repeated over time. Existing methods to remove such uninformative tokens either have significant overhead, negating any speedup, or require tuning for different datasets and examples. We present Run-Length Tokenization (RLT), a simple approach to speed up video transformers inspired by run-length encoding for data compression. RLT efficiently finds and removes runs of patches that are repeated over time prior to model inference, then replaces them with a single patch and a positional encoding to represent the resulting token's new length. Our method is content-aware, requiring no tuning for different datasets, and fast, incurring negligible overhead. RLT yields a large speedup in training, reducing the wall-clock time to fine-tune a video transformer by 30% while matching baseline model performance. RLT also works without any training, increasing model throughput by 35% with only 0.1% drop in accuracy. RLT speeds up training at 30 FPS by more than 100%, and on longer video datasets, can reduce the token count by up to 80%. Our project page is at https://rccchoudhury.github.io/projects/rlt/.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "16 pages, 6 figures. Accepted to NeurIPS 2024 (spotlight)"
    },
    {
        "paper id": "2411.05224",
        "abstract url": "https://arxiv.org/abs/2411.05224",
        "title": "Beyond the Numbers: Transparency in Relation Extraction Benchmark Creation and Leaderboards",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "This paper investigates the transparency in the creation of benchmarks and the use of leaderboards for measuring progress in NLP, with a focus on the relation extraction (RE) task. Existing RE benchmarks often suffer from insufficient documentation, lacking crucial details such as data sources, inter-annotator agreement, the algorithms used for the selection of instances for datasets, and information on potential biases like dataset imbalance. Progress in RE is frequently measured by leaderboards that rank systems based on evaluation methods, typically limited to aggregate metrics like F1-score. However, the absence of detailed performance analysis beyond these metrics can obscure the true generalisation capabilities of models. Our analysis reveals that widely used RE benchmarks, such as TACRED and NYT, tend to be highly imbalanced and contain noisy labels. Moreover, the lack of class-based performance metrics fails to accurately reflect model performance across datasets with a large number of relation types. These limitations should be carefully considered when reporting progress in RE. While our discussion centers on the transparency of RE benchmarks and leaderboards, the observations we discuss are broadly applicable to other NLP tasks as well. Rather than undermining the significance and value of existing RE benchmarks and the development of new models, this paper advocates for improved documentation and more rigorous evaluation to advance the field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This paper was accepted at the GenBench workshop at EMNLP2024"
    },
    {
        "paper id": "2411.05254",
        "abstract url": "https://arxiv.org/abs/2411.05254",
        "title": "Hierarchical Visual Feature Aggregation for OCR-Free Document Understanding",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We present a novel OCR-free document understanding framework based on pretrained Multimodal Large Language Models (MLLMs). Our approach employs multi-scale visual features to effectively handle various font sizes within document images. To address the increasing costs of considering the multi-scale visual inputs for MLLMs, we propose the Hierarchical Visual Feature Aggregation (HVFA) module, designed to reduce the number of input tokens to LLMs. Leveraging a feature pyramid with cross-attentive pooling, our approach effectively manages the trade-off between information loss and efficiency without being affected by varying document image sizes. Furthermore, we introduce a novel instruction tuning task, which facilitates the model's text-reading capability by learning to predict the relative positions of input text, eventually minimizing the risk of truncated text caused by the limited capacity of LLMs. Comprehensive experiments validate the effectiveness of our approach, demonstrating superior performance in various document understanding tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.05289",
        "abstract url": "https://arxiv.org/abs/2411.05289",
        "title": "SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have become essential in advancing natural language processing (NLP) tasks, but their sequential token generation limits inference speed. Multi-Draft Speculative Decoding (MDSD) offers a promising solution by using a smaller draft model to generate multiple token sequences, which the target LLM verifies in parallel. However, current heuristic approaches, such as Recursive Rejection Sampling (RRS), suffer from low acceptance rates in subsequent drafts, limiting the advantages of using multiple drafts. Meanwhile, Optimal Transport with Membership Cost (OTM) can theoretically improve acceptance rates, but its computational cost is too high for real-time use. We present SpecHub, a novel, efficient sampling-verification method for MDSD that improves acceptance rates with only linear computational overhead. By simplifying the OTM problem into a compact Linear Programming model, SpecHub significantly reduces computational complexity. It further accelerates sampling by leveraging a sparse joint distribution, focusing computation on high-probability token sequences. In extensive experiments, Spechub consistently generates 0.05-0.27 and 0.02-0.16 more tokens per step than RRS and RRS without replacement. We attach our code at \\url{https://github.com/MasterGodzilla/Speculative_decoding_OT}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "EMNLP 2024 (Main)"
    },
    {
        "paper id": "2411.05296",
        "abstract url": "https://arxiv.org/abs/2411.05296",
        "title": "On Training of Kolmogorov-Arnold Networks",
        "rating": "1.5",
        "keywords": [
            [
                "parameter efficiency"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Kolmogorov-Arnold Networks have recently been introduced as a flexible alternative to multi-layer Perceptron architectures. In this paper, we examine the training dynamics of different KAN architectures and compare them with corresponding MLP formulations. We train with a variety of different initialization schemes, optimizers, and learning rates, as well as utilize back propagation free approaches like the HSIC Bottleneck. We find that (when judged by test accuracy) KANs are an effective alternative to MLP architectures on high-dimensional datasets and have somewhat better parameter efficiency, but suffer from more unstable training dynamics. Finally, we provide recommendations for improving training stability of larger KAN models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2411.04443",
        "abstract url": "https://arxiv.org/abs/2411.04443",
        "title": "ACCIO: Table Understanding Enhanced via Contrastive Learning with Aggregations",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The attention to table understanding using recent natural language models has been growing. However, most related works tend to focus on learning the structure of the table directly. Just as humans improve their understanding of sentences by comparing them, they can also enhance their understanding by comparing tables. With this idea, in this paper, we introduce ACCIO, tAble understanding enhanCed via Contrastive learnIng with aggregatiOns, a novel approach to enhancing table understanding by contrasting original tables with their pivot summaries through contrastive learning. ACCIO trains an encoder to bring these table pairs closer together. Through validation via column type annotation, ACCIO achieves competitive performance with a macro F1 score of 91.1 compared to state-of-the-art methods. This work represents the first attempt to utilize pairs of tables for table embedding, promising significant advancements in table comprehension. Our code is available at https://github.com/whnhch/ACCIO/.",
        "subjects": [
            "cs.CL",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04466",
        "abstract url": "https://arxiv.org/abs/2411.04466",
        "title": "Enabling Adaptive Agent Training in Open-Ended Simulators by Targeting Diversity",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The wider application of end-to-end learning methods to embodied decision-making domains remains bottlenecked by their reliance on a superabundance of training data representative of the target domain. Meta-reinforcement learning (meta-RL) approaches abandon the aim of zero-shot generalization--the goal of standard reinforcement learning (RL)--in favor of few-shot adaptation, and thus hold promise for bridging larger generalization gaps. While learning this meta-level adaptive behavior still requires substantial data, efficient environment simulators approaching real-world complexity are growing in prevalence. Even so, hand-designing sufficiently diverse and numerous simulated training tasks for these complex domains is prohibitively labor-intensive. Domain randomization (DR) and procedural generation (PG), offered as solutions to this problem, require simulators to possess carefully-defined parameters which directly translate to meaningful task diversity--a similarly prohibitive assumption. In this work, we present DIVA, an evolutionary approach for generating diverse training tasks in such complex, open-ended simulators. Like unsupervised environment design (UED) methods, DIVA can be applied to arbitrary parameterizations, but can additionally incorporate realistically-available domain knowledge--thus inheriting the flexibility and generality of UED, and the supervised structure embedded in well-designed simulators exploited by DR and PG. Our empirical results showcase DIVA's unique ability to overcome complex parameterizations and successfully train adaptive agent behavior, far outperforming competitive baselines from prior literature. These findings highlight the potential of such semi-supervised environment design (SSED) approaches, of which DIVA is the first humble constituent, to enable training in realistic simulated domains, and produce more robust and capable adaptive agents.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO",
            "stat.ML"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.04473",
        "abstract url": "https://arxiv.org/abs/2411.04473",
        "title": "ML-Promise: A Multilingual Dataset for Corporate Promise Verification",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Promises made by politicians, corporate leaders, and public figures have a significant impact on public perception, trust, and institutional reputation. However, the complexity and volume of such commitments, coupled with difficulties in verifying their fulfillment, necessitate innovative methods for assessing their credibility. This paper introduces the concept of Promise Verification, a systematic approach involving steps such as promise identification, evidence assessment, and the evaluation of timing for verification. We propose the first multilingual dataset, ML-Promise, which includes English, French, Chinese, Japanese, and Korean, aimed at facilitating in-depth verification of promises, particularly in the context of Environmental, Social, and Governance (ESG) reports. Given the growing emphasis on corporate environmental contributions, this dataset addresses the challenge of evaluating corporate promises, especially in light of practices like greenwashing. Our findings also explore textual and image-based baselines, with promising results from retrieval-augmented generation (RAG) approaches. This work aims to foster further discourse on the accountability of public commitments across multiple languages and domains.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "6 pages"
    },
    {
        "paper id": "2411.04496",
        "abstract url": "https://arxiv.org/abs/2411.04496",
        "title": "Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "To increase social bonding with interlocutors, humans naturally acquire the ability to respond appropriately in a given situation by considering which conversational skill is most suitable for the response - a process we call skill-of-mind. For large language model (LLM)-based conversational agents, planning appropriate conversational skills, as humans do, is challenging due to the complexity of social dialogue, especially in interactive scenarios. To address this, we propose a skill-of-mind-annotated conversation dataset, named Multifaceted Skill-of-Mind, which includes multi-turn and multifaceted conversational skills across various interactive scenarios (e.g., long-term, counseling, task-oriented), grounded in diverse social contexts (e.g., demographics, persona, rules of thumb). This dataset consists of roughly 100K conversations. Using this dataset, we introduce a new family of skill-of-mind-infused LLMs, named Thanos, with model sizes of 1B, 3B, and 8B parameters. With extensive experiments, these models successfully demonstrate the skill-of-mind process and exhibit strong generalizability in inferring multifaceted skills across a variety of domains. Moreover, we show that Thanos significantly enhances the quality of responses generated by LLM-based conversational agents and promotes prosocial behavior in human evaluations.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Code: https://github.com/passing2961/Thanos"
    },
    {
        "paper id": "2411.04530",
        "abstract url": "https://arxiv.org/abs/2411.04530",
        "title": "Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Human understanding of language is robust to different word choices as far as they represent similar semantic concepts. To what extent does our human intuition transfer to language models, which represent all subwords as distinct embeddings? In this work, we take an initial step on measuring the role of shared semantics among subwords in the encoder-only multilingual language models (mLMs). To this end, we form \"semantic tokens\" by merging the semantically similar subwords and their embeddings, and evaluate the updated mLMs on 5 heterogeneous multilingual downstream tasks. Results show that the general shared semantics could get the models a long way in making the predictions on mLMs with different tokenizers and model sizes. Inspections on the grouped subwords show that they exhibit a wide range of semantic similarities, including synonyms and translations across many languages and scripts. Lastly, we found the zero-shot results with semantic tokens are on par or even better than the original models on certain classification tasks, suggesting that the shared subword-level semantics may serve as the anchors for cross-lingual transferring.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "8 pages, 9 figures"
    },
    {
        "paper id": "2411.04539",
        "abstract url": "https://arxiv.org/abs/2411.04539",
        "title": "Best Practices for Distilling Large Language Models into BERT for Web Search Ranking",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent studies have highlighted the significant potential of Large Language Models (LLMs) as zero-shot relevance rankers. These methods predominantly utilize prompt learning to assess the relevance between queries and documents by generating a ranked list of potential documents. Despite their promise, the substantial costs associated with LLMs pose a significant challenge for their direct implementation in commercial search systems. To overcome this barrier and fully exploit the capabilities of LLMs for text ranking, we explore techniques to transfer the ranking expertise of LLMs to a more compact model similar to BERT, using a ranking loss to enable the deployment of less resource-intensive models. Specifically, we enhance the training of LLMs through Continued Pre-Training, taking the query as input and the clicked title and summary as output. We then proceed with supervised fine-tuning of the LLM using a rank loss, assigning the final token as a representative of the entire sentence. Given the inherent characteristics of autoregressive language models, only the final token </s> can encapsulate all preceding tokens. Additionally, we introduce a hybrid point-wise and margin MSE loss to transfer the ranking knowledge from LLMs to smaller models like BERT. This method creates a viable solution for environments with strict resource constraints. Both offline and online evaluations have confirmed the efficacy of our approach, and our model has been successfully integrated into a commercial web search engine as of February 2024.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": "Arxiv Version"
    },
    {
        "paper id": "2411.04557",
        "abstract url": "https://arxiv.org/abs/2411.04557",
        "title": "Pruning Literals for Highly Efficient Explainability at Word Level",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Designing an explainable model becomes crucial now for Natural Language Processing(NLP) since most of the state-of-the-art machine learning models provide a limited explanation for the prediction. In the spectrum of an explainable model, Tsetlin Machine(TM) is promising because of its capability of providing word-level explanation using proposition logic. However, concern rises over the elaborated combination of literals (propositional logic) in the clause that makes the model difficult for humans to comprehend, despite having a transparent learning process. In this paper, we design a post-hoc pruning of clauses that eliminate the randomly placed literals in the clause thereby making the model more efficiently interpretable than the vanilla TM. Experiments on the publicly available YELP-HAT Dataset demonstrate that the proposed pruned TM's attention map aligns more with the human attention map than the vanilla TM's attention map. In addition, the pairwise similarity measure also surpasses the attention map-based neural network models. In terms of accuracy, the proposed pruning method does not degrade the accuracy significantly but rather enhances the performance up to 4% to 9% in some test data.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "8 pages, 3 figures"
    },
    {
        "paper id": "2411.04562",
        "abstract url": "https://arxiv.org/abs/2411.04562",
        "title": "Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In offline reinforcement learning, a policy is learned using a static dataset in the absence of costly feedback from the environment. In contrast to the online setting, only using static datasets poses additional challenges, such as policies generating out-of-distribution samples. Model-based offline reinforcement learning methods try to overcome these by learning a model of the underlying dynamics of the environment and using it to guide policy search. It is beneficial but, with limited datasets, errors in the model and the issue of value overestimation among out-of-distribution states can worsen performance. Current model-based methods apply some notion of conservatism to the Bellman update, often implemented using uncertainty estimation derived from model ensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP) which learns a generative model of the joint distribution of observations and actions. We cast policy learning as a constrained objective to always stay within the support of the latent action distribution, and use the generative capabilities of the model to impose an implicit constraint on the generated actions. Thereby eliminating the need to use additional uncertainty penalties on the Bellman update and significantly decreasing the number of gradient steps required to learn a policy. We empirically evaluate C-LAP on the D4RL and V-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art methods, especially outperforming on datasets with visual observations.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "38th Conference on Neural Information Processing Systems (NeurIPS 2024)"
    },
    {
        "paper id": "2411.04569",
        "abstract url": "https://arxiv.org/abs/2411.04569",
        "title": "Impact of Label Noise on Learning Complex Features",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Neural networks trained with stochastic gradient descent exhibit an inductive bias towards simpler decision boundaries, typically converging to a narrow family of functions, and often fail to capture more complex features. This phenomenon raises concerns about the capacity of deep models to adequately learn and represent real-world datasets. Traditional approaches such as explicit regularization, data augmentation, architectural modifications, etc., have largely proven ineffective in encouraging the models to learn diverse features. In this work, we investigate the impact of pre-training models with noisy labels on the dynamics of SGD across various architectures and datasets. We show that pretraining promotes learning complex functions and diverse features in the presence of noise. Our experiments demonstrate that pre-training with noisy labels encourages gradient descent to find alternate minima that do not solely depend upon simple features, rather learns more complex and broader set of features, without hurting performance.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted at Workshop on Scientific Methods for Understanding Deep Learning, NeurIPS 2024"
    },
    {
        "paper id": "2411.04573",
        "abstract url": "https://arxiv.org/abs/2411.04573",
        "title": "Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper presents a novel multistage fine-tuning strategy designed to enhance automatic speech recognition (ASR) performance in low-resource languages using OpenAI's Whisper model. In this approach we aim to build ASR model for languages with limited digital resources by sequentially adapting the model across linguistically similar languages. We experimented this on the Malasar language, a Dravidian language spoken by approximately ten thousand people in the Western Ghats of South India. Malasar language faces critical challenges for technological intervention due to its lack of a native script and absence of digital or spoken data resources. Working in collaboration with Wycliffe India and Malasar community members, we created a spoken Malasar corpus paired with transcription in Tamil script, a closely related major language. In our approach to build ASR model for Malasar, we first build an intermediate Tamil ASR, leveraging higher data availability for Tamil annotated speech. This intermediate model is subsequently fine-tuned on Malasar data, allowing for more effective ASR adaptation despite limited resources. The multistage fine-tuning strategy demonstrated significant improvements over direct fine-tuning on Malasar data alone, achieving a word error rate (WER) of 51.9%, which is 4.5% absolute reduction when compared to the direct fine-tuning method. Further a WER reduction to 47.3% was achieved through punctuation removal in post-processing, which addresses formatting inconsistencies that impact evaluation. Our results underscore the effectiveness of sequential multistage fine-tuning combined with targeted post-processing as a scalable strategy for ASR system development in low-resource languages, especially where linguistic similarities can be leveraged to bridge gaps in training data.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04585",
        "abstract url": "https://arxiv.org/abs/2411.04585",
        "title": "The State and Fate of Summarization Datasets",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Automatic summarization has consistently attracted attention, due to its versatility and wide application in various downstream tasks. Despite its popularity, we find that annotation efforts have largely been disjointed, and have lacked common terminology. Consequently, it is challenging to discover existing resources or identify coherent research directions. To address this, we survey a large body of work spanning 133 datasets in over 100 languages, creating a novel ontology covering sample properties, collection methods and distribution. With this ontology we make key observations, including the lack in accessible high-quality datasets for low-resource languages, and the field's over-reliance on the news domain and on automatically collected distant supervision. Finally, we make available a web interface that allows users to interact and explore our ontology and dataset collection, as well as a template for a summarization data card, which can be used to streamline future research into a more coherent body of work.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04586",
        "abstract url": "https://arxiv.org/abs/2411.04586",
        "title": "On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Robustness is a fundamental aspect for developing safe and trustworthy models, particularly when they are deployed in the open world. In this work we analyze the inherent capability of one-stage object detectors to robustly operate in the presence of out-of-distribution (OoD) data. Specifically, we propose a novel detection algorithm for detecting unknown objects in image data, which leverages the features extracted by the model from each sample. Differently from other recent approaches in the literature, our proposal does not require retraining the object detector, thereby allowing for the use of pretrained models. Our proposed OoD detector exploits the application of supervised dimensionality reduction techniques to mitigate the effects of the curse of dimensionality on the features extracted by the model. Furthermore, it utilizes high-resolution feature maps to identify potential unknown objects in an unsupervised fashion. Our experiments analyze the Pareto trade-off between the performance detecting known and unknown objects resulting from different algorithmic configurations and inference confidence thresholds. We also compare the performance of our proposed algorithm to that of logits-based post-hoc OoD methods, as well as possible fusion strategies. Finally, we discuss on the competitiveness of all tested methods against state-of-the-art OoD approaches for object detection models over the recently published Unknown Object Detection benchmark. The obtained results verify that the performance of avant-garde post-hoc OoD detectors can be further improved when combined with our proposed algorithm.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "12 figures, 4 tables, under review"
    },
    {
        "paper id": "2411.04594",
        "abstract url": "https://arxiv.org/abs/2411.04594",
        "title": "Verification of Neural Networks against Convolutional Perturbations via Parameterised Kernels",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We develop a method for the efficient verification of neural networks against convolutional perturbations such as blurring or sharpening. To define input perturbations we use well-known camera shake, box blur and sharpen kernels. We demonstrate that these kernels can be linearly parameterised in a way that allows for a variation of the perturbation strength while preserving desired kernel properties. To facilitate their use in neural network verification, we develop an efficient way of convolving a given input with these parameterised kernels. The result of this convolution can be used to encode the perturbation in a verification setting by prepending a linear layer to a given network. This leads to tight bounds and a high effectiveness in the resulting verification step. We add further precision by employing input splitting as a branch and bound strategy. We demonstrate that we are able to verify robustness on a number of standard benchmarks where the baseline is unable to provide any safety certificates. To the best of our knowledge, this is the first solution for verifying robustness against specific convolutional perturbations such as camera shake.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04596",
        "abstract url": "https://arxiv.org/abs/2411.04596",
        "title": "The Impact of Semi-Supervised Learning on Line Segment Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper we present a method for line segment detection in images, based on a semi-supervised framework. Leveraging the use of a consistency loss based on differently augmented and perturbed unlabeled images with a small amount of labeled data, we show comparable results to fully supervised methods. This opens up application scenarios where annotation is difficult or expensive, and for domain specific adaptation of models. We are specifically interested in real-time and online applications, and investigate small and efficient learning backbones. Our method is to our knowledge the first to target line detection using modern state-of-the-art methodologies for semi-supervised learning. We test the method on both standard benchmarks and domain specific scenarios for forestry applications, showing the tractability of the proposed method.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "9 pages, 6 figures, 7 tables"
    },
    {
        "paper id": "2411.04602",
        "abstract url": "https://arxiv.org/abs/2411.04602",
        "title": "Self-Calibrated Listwise Reranking with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs), with advanced linguistic capabilities, have been employed in reranking tasks through a sequence-to-sequence approach. In this paradigm, multiple passages are reranked in a listwise manner and a textual reranked permutation is generated. However, due to the limited context window of LLMs, this reranking paradigm requires a sliding window strategy to iteratively handle larger candidate sets. This not only increases computational costs but also restricts the LLM from fully capturing all the comparison information for all candidates. To address these challenges, we propose a novel self-calibrated listwise reranking method, which aims to leverage LLMs to produce global relevance scores for ranking. To achieve it, we first propose the relevance-aware listwise reranking framework, which incorporates explicit list-view relevance scores to improve reranking efficiency and enable global comparison across the entire candidate set. Second, to ensure the comparability of the computed scores, we propose self-calibrated training that uses point-view relevance assessments generated internally by the LLM itself to calibrate the list-view relevance assessments. Extensive experiments and comprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks demonstrate the effectiveness and efficiency of our proposed method.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04604",
        "abstract url": "https://arxiv.org/abs/2411.04604",
        "title": "FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In the context of low-resource languages, the Algerian dialect (AD) faces challenges due to the absence of annotated corpora, hindering its effective processing, notably in Machine Learning (ML) applications reliant on corpora for training and assessment. This study outlines the development process of a specialized corpus for Fake News (FN) detection and sentiment analysis (SA) in AD called FASSILA. This corpus comprises 10,087 sentences, encompassing over 19,497 unique words in AD, and addresses the significant lack of linguistic resources in the language and covers seven distinct domains. We propose an annotation scheme for FN detection and SA, detailing the data collection, cleaning, and labelling process. Remarkable Inter-Annotator Agreement indicates that the annotation scheme produces consistent annotations of high quality. Subsequent classification experiments using BERT-based models and ML models are presented, demonstrate promising results and highlight avenues for further research. The dataset is made freely available on GitHub (https://github.com/amincoding/FASSILA) to facilitate future advancements in the field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "16 pages, 6 Figuers"
    },
    {
        "paper id": "2411.04637",
        "abstract url": "https://arxiv.org/abs/2411.04637",
        "title": "Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Training and deploying machine learning models relies on a large amount of human-annotated data. As human labeling becomes increasingly expensive and time-consuming, recent research has developed multiple strategies to speed up annotation and reduce costs and human workload: generating synthetic training data, active learning, and hybrid labeling. This tutorial is oriented toward practical applications: we will present the basics of each strategy, highlight their benefits and limitations, and discuss in detail real-life case studies. Additionally, we will walk through best practices for managing human annotators and controlling the quality of the final dataset. The tutorial includes a hands-on workshop, where attendees will be guided in implementing a hybrid annotation setup. This tutorial is designed for NLP practitioners from both research and industry backgrounds who are involved in or interested in optimizing data labeling projects.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "To be presented at COLING 2025"
    },
    {
        "paper id": "2411.04649",
        "abstract url": "https://arxiv.org/abs/2411.04649",
        "title": "DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "With the rapid advancement of neural language models, the deployment of over-parameterized models has surged, increasing the need for interpretable explanations comprehensible to human inspectors. Existing post-hoc interpretability methods, which often focus on unigram features of single input textual instances, fail to capture the models' decision-making process fully. Additionally, many methods do not differentiate between decisions based on spurious correlations and those based on a holistic understanding of the input. Our paper introduces DISCO, a novel method for discovering global, rule-based explanations by identifying causal n-gram associations with model predictions. This method employs a scalable sequence mining technique to extract relevant text spans from training data, associate them with model predictions, and conduct causality checks to distill robust rules that elucidate model behavior. These rules expose potential overfitting and provide insights into misleading feature combinations. We validate DISCO through extensive testing, demonstrating its superiority over existing methods in offering comprehensive insights into complex model behaviors. Our approach successfully identifies all shortcuts manually introduced into the training data (100% detection rate on the MultiRC dataset), resulting in an 18.8% regression in model performance -- a capability unmatched by any other method. Furthermore, DISCO supports interactive explanations, enabling human inspectors to distinguish spurious causes in the rule-based output. This alleviates the burden of abundant instance-wise explanations and helps assess the model's risk when encountering out-of-distribution (OOD) data.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04679",
        "abstract url": "https://arxiv.org/abs/2411.04679",
        "title": "CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this work, we address the cooperation problem among large language model (LLM) based embodied agents, where agents must cooperate to achieve a common goal. Previous methods often execute actions extemporaneously and incoherently, without long-term strategic and cooperative planning, leading to redundant steps, failures, and even serious repercussions in complex tasks like search-and-rescue missions where discussion and cooperative plan are crucial. To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance the cooperation efficiency of LLM-based embodied agents. Inspired by human cooperation schemes, CaPo improves cooperation efficiency with two phases: 1) meta-plan generation, and 2) progress-adaptive meta-plan and execution. In the first phase, all agents analyze the task, discuss, and cooperatively create a meta-plan that decomposes the task into subtasks with detailed steps, ensuring a long-term strategic and coherent plan for efficient coordination. In the second phase, agents execute tasks according to the meta-plan and dynamically adjust it based on their latest progress (e.g., discovering a target object) through multi-turn discussions. This progress-based adaptation eliminates redundant actions, improving the overall cooperation efficiency of agents. Experimental results on the ThreeDworld Multi-Agent Transport and Communicative Watch-And-Help tasks demonstrate that CaPo achieves much higher task completion rate and efficiency compared with state-of-the-arts.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.MA"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2411.04699",
        "abstract url": "https://arxiv.org/abs/2411.04699",
        "title": "BhasaAnuvaad: A Speech Translation Dataset for 13 Indian Languages",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Automatic Speech Translation (AST) datasets for Indian languages remain critically scarce, with public resources covering fewer than 10 of the 22 official languages. This scarcity has resulted in AST systems for Indian languages lagging far behind those available for high-resource languages like English. In this paper, we first evaluate the performance of widely-used AST systems on Indian languages, identifying notable performance gaps and challenges. Our findings show that while these systems perform adequately on read speech, they struggle significantly with spontaneous speech, including disfluencies like pauses and hesitations. Additionally, there is a striking absence of systems capable of accurately translating colloquial and informal language, a key aspect of everyday communication. To this end, we introduce BhasaAnuvaad, the largest publicly available dataset for AST involving 13 out of 22 scheduled Indian languages and English spanning over 44,400 hours and 17M text segments. BhasaAnuvaad contains data for English speech to Indic text, as well as Indic speech to English text. This dataset comprises three key categories: (1) Curated datasets from existing resources, (2) Large-scale web mining, and (3) Synthetic data generation. By offering this diverse and expansive dataset, we aim to bridge the resource gap and promote advancements in AST for Indian languages.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Work in Progress"
    },
    {
        "paper id": "2411.04717",
        "abstract url": "https://arxiv.org/abs/2411.04717",
        "title": "Subspace-Constrained Quadratic Matrix Factorization: Algorithm and Applications",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Matrix Factorization has emerged as a widely adopted framework for modeling data exhibiting low-rank structures. To address challenges in manifold learning, this paper presents a subspace-constrained quadratic matrix factorization model. The model is designed to jointly learn key low-dimensional structures, including the tangent space, the normal subspace, and the quadratic form that links the tangent space to a low-dimensional representation. We solve the proposed factorization model using an alternating minimization method, involving an in-depth investigation of nonlinear regression and projection subproblems. Theoretical properties of the quadratic projection problem and convergence characteristics of the alternating strategy are also investigated. To validate our approach, we conduct numerical experiments on synthetic and real-world datasets. Results demonstrate that our model outperforms existing methods, highlighting its robustness and efficacy in capturing core low-dimensional structures.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04788",
        "abstract url": "https://arxiv.org/abs/2411.04788",
        "title": "Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In recent years, the application of generative artificial intelligence (GenAI) in financial analysis and investment decision-making has gained significant attention. However, most existing approaches rely on single-agent systems, which fail to fully utilize the collaborative potential of multiple AI agents. In this paper, we propose a novel multi-agent collaboration system designed to enhance decision-making in financial investment research. The system incorporates agent groups with both configurable group sizes and collaboration structures to leverage the strengths of each agent group type. By utilizing a sub-optimal combination strategy, the system dynamically adapts to varying market conditions and investment scenarios, optimizing performance across different tasks. We focus on three sub-tasks: fundamentals, market sentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30 companies listed on the Dow Jones Index. Our findings reveal significant performance variations based on the configurations of AI agents for different tasks. The results demonstrate that our multi-agent collaboration system outperforms traditional single-agent models, offering improved accuracy, efficiency, and adaptability in complex financial environments. This study highlights the potential of multi-agent systems in transforming financial analysis and investment decision-making by integrating diverse analytical perspectives.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "q-fin.ST",
            "q-fin.TR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04794",
        "abstract url": "https://arxiv.org/abs/2411.04794",
        "title": "AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Empirical evidence suggests that LLMs exhibit spontaneous cross-lingual alignment. Our findings suggest that although LLMs also demonstrate promising cross-lingual alignment in Information Extraction, there remains significant imbalance across languages, revealing an underlying deficiency in the IE alignment. To address this issue, we propose AlignXIE, a powerful code-based LLM that significantly enhances cross-lingual IE alignment through two strategies. Firstly, AlignXIE formulates IE across different languages, especially non-English ones, as code generation tasks, standardizing the representation of various schemas using Python classes to ensure consistency of the same ontology in different languages and align the schema. Secondly, it incorporates an IE cross-lingual alignment phase through a translated instance prediction task proposed in this paper to align the extraction process, utilizing ParallelNER, an IE bilingual parallel dataset with 257,190 samples, generated by our proposed LLM-based automatic pipeline for IE parallel data construction, with manual annotation to ensure quality. Ultimately, we obtain AlignXIE through multilingual IE instruction tuning. Although without training in 9 unseen languages, AlignXIE surpasses ChatGPT by $30.17\\%$ and SoTA by $20.03\\%$, thereby demonstrating superior cross-lingual IE capabilities. Comprehensive evaluations on 63 IE benchmarks in Chinese and English under various settings, demonstrate that AlignXIE significantly enhances cross-lingual and multilingual IE through boosting the IE alignment.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2411.04799",
        "abstract url": "https://arxiv.org/abs/2411.04799",
        "title": "Kwai-STaR: Transform LLMs into State-Transition Reasoners",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Mathematical reasoning presents a significant challenge to the cognitive capabilities of LLMs. Various methods have been proposed to enhance the mathematical ability of LLMs. However, few recognize the value of state transition for LLM reasoning. In this work, we define mathematical problem-solving as a process of transiting from an initial unsolved state to the final resolved state, and propose Kwai-STaR framework, which transforms LLMs into State-Transition Reasoners to improve their intuitive reasoning capabilities. Our approach comprises three main steps: (1) Define the state space tailored to the mathematical reasoning. (2) Generate state-transition data based on the state space. (3) Convert original LLMs into State-Transition Reasoners via a curricular training strategy. Our experiments validate the effectiveness of Kwai-STaR in enhancing mathematical reasoning: After training on the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and LLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard dataset. Additionally, the state transition-based design endows Kwai-STaR with remarkable training and inference efficiency. Further experiments are underway to establish the generality of Kwai-STaR.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "6 pages, 2 figures"
    },
    {
        "paper id": "2411.04825",
        "abstract url": "https://arxiv.org/abs/2411.04825",
        "title": "VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Existing text simplification or paraphrase datasets mainly focus on sentence-level text generation in a general domain. These datasets are typically developed without using domain knowledge. In this paper, we release a novel dataset, VTechAGP, which is the first academic-to-general-audience text paraphrase dataset consisting of 4,938 document-level these and dissertation academic and general-audience abstract pairs from 8 colleges authored over 25 years. We also propose a novel dynamic soft prompt generative language model, DSPT5. For training, we leverage a contrastive-generative loss function to learn the keyword vectors in the dynamic prompt. For inference, we adopt a crowd-sampling decoding strategy at both semantic and structural levels to further select the best output candidate. We evaluate DSPT5 and various state-of-the-art large language models (LLMs) from multiple perspectives. Results demonstrate that the SOTA LLMs does not provide satisfactory outcomes, while the lightweight DSPT5 can achieve competitive results. To the best of our knowledge, we are the first to build a benchmark dataset and solutions for academic-to-general-audience text paraphrase dataset.",
        "subjects": [
            "cs.CL",
            "cs.DL",
            "cs.LG"
        ],
        "comment": "21 pages, 3 figures"
    },
    {
        "paper id": "2411.04847",
        "abstract url": "https://arxiv.org/abs/2411.04847",
        "title": "Prompt-Guided Internal States for Hallucination Detection of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a variety of tasks in different domains. However, they sometimes generate responses that are logically coherent but factually incorrect or misleading, which is known as LLM hallucinations. Data-driven supervised methods train hallucination detectors by leveraging the internal states of LLMs, but detectors trained on specific domains often struggle to generalize well to other domains. In this paper, we aim to enhance the cross-domain performance of supervised detectors with only in-domain data. We propose a novel framework, prompt-guided internal states for hallucination detection of LLMs, namely PRISM. By utilizing appropriate prompts to guide changes in the structure related to text truthfulness within the LLM's internal states, we make this structure more salient and consistent across texts from different domains. We integrated our framework with existing hallucination detection methods and conducted experiments on datasets from different domains. The experimental results indicate that our framework significantly enhances the cross-domain generalization of existing hallucination detection methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04859",
        "abstract url": "https://arxiv.org/abs/2411.04859",
        "title": "A multi-purpose automatic editing system based on lecture semantics for remote education",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Remote teaching has become popular recently due to its convenience and safety, especially under extreme circumstances like a pandemic. However, online students usually have a poor experience since the information acquired from the views provided by the broadcast platforms is limited. One potential solution is to show more camera views simultaneously, but it is technically challenging and distracting for the viewers. Therefore, an automatic multi-camera directing/editing system, which aims at selecting the most concerned view at each time instance to guide the attention of online students, is in urgent demand. However, existing systems mostly make simple assumptions and focus on tracking the position of the speaker instead of the real lecture semantics, and therefore have limited capacities to deliver optimal information flow. To this end, this paper proposes an automatic multi-purpose editing system based on the lecture semantics, which can both direct the multiple video streams for real-time broadcasting and edit the optimal video offline for review purposes. Our system directs the views by semantically analyzing the class events while following the professional directing rules, mimicking a human director to capture the regions of interest from the viewpoint of the onsite students. We conduct both qualitative and quantitative analyses to verify the effectiveness of the proposed system and its components.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04905",
        "abstract url": "https://arxiv.org/abs/2411.04905",
        "title": "OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) for code have become indispensable in various domains, including code generation, reasoning tasks and agent systems. While open-access code LLMs are increasingly approaching the performance levels of proprietary models, high-quality code LLMs suitable for rigorous scientific investigation, particularly those with reproducible data processing pipelines and transparent training protocols, remain limited. The scarcity is due to various challenges, including resource constraints, ethical considerations, and the competitive advantages of keeping models advanced. To address the gap, we introduce OpenCoder, a top-tier code LLM that not only achieves performance comparable to leading models but also serves as an \"open cookbook\" for the research community. Unlike most prior efforts, we release not only model weights and inference code, but also the reproducible training data, complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols for open scientific research. Through this comprehensive release, we identify the key ingredients for building a top-tier code LLM: (1) code optimized heuristic rules for data cleaning and methods for data deduplication, (2) recall of text corpus related to code and (3) high-quality synthetic data in both annealing and supervised fine-tuning stages. By offering this level of openness, we aim to broaden access to all aspects of a top-tier code LLM, with OpenCoder serving as both a powerful model and an open foundation to accelerate research, and enable reproducible advancements in code AI.",
        "subjects": [
            "cs.CL",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04912",
        "abstract url": "https://arxiv.org/abs/2411.04912",
        "title": "Robust Iris Centre Localisation for Assistive Eye-Gaze Tracking",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this research work, we address the problem of robust iris centre localisation in unconstrained conditions as a core component of our eye-gaze tracking platform. We investigate the application of U-Net variants for segmentation-based and regression-based approaches to improve our iris centre localisation, which was previously based on Bayes' classification. The achieved results are comparable to or better than the state-of-the-art, offering a drastic improvement over those achieved by the Bayes' classifier, and without sacrificing the real-time performance of our eye-gaze tracking platform.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04914",
        "abstract url": "https://arxiv.org/abs/2411.04914",
        "title": "GASE: Generatively Augmented Sentence Encoding",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We propose an approach to enhance sentence embeddings by applying generative text models for data augmentation at inference time. Unlike conventional data augmentation that utilises synthetic training data, our approach does not require access to model parameters or the computational resources typically required for fine-tuning state-of-the-art models. Generatively Augmented Sentence Encoding uses diverse linguistic synthetic variants of input texts generated by paraphrasing, summarising, or extracting keywords, followed by pooling the original and synthetic embeddings. Experimental results on the Massive Text Embedding Benchmark for Semantic Textual Similarity (STS) demonstrate performance improvements across a range of embedding models using different generative models for augmentation. We find that generative augmentation leads to larger performance improvements for embedding models with lower baseline performance. These findings suggest that integrating generative augmentation at inference time adds semantic diversity and can enhance the robustness and generalizability of sentence embeddings for embedding models. Our results show that the degree to which generative augmentation can improve STS performance depends not only on the embedding model but also on the dataset. From a broader perspective, the approach allows trading training for inference compute.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "12 pages, 3 figures"
    },
    {
        "paper id": "2411.04920",
        "abstract url": "https://arxiv.org/abs/2411.04920",
        "title": "GPTKB: Building Very Large Knowledge Bases from Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "General-domain knowledge bases (KB), in particular the \"big three\" -- Wikidata, Yago and DBpedia -- are the backbone of many intelligent applications. While these three have seen steady development, comprehensive KB construction at large has seen few fresh attempts. In this work, we propose to build a large general-domain KB entirely from a large language model (LLM). We demonstrate the feasibility of large-scale KB construction from LLMs, while highlighting specific challenges arising around entity recognition, entity and property canonicalization, and taxonomy construction. As a prototype, we use GPT-4o-mini to construct GPTKB, which contains 105 million triples for more than 2.9 million entities, at a cost 100x less than previous KBC projects. Our work is a landmark for two fields: For NLP, for the first time, it provides \\textit{constructive} insights into the knowledge (or beliefs) of LLMs. For the Semantic Web, it shows novel ways forward for the long-standing challenge of general-domain KB construction. GPTKB is accessible at http://gptkb.org.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DB"
        ],
        "comment": "11 pages, 4 tables"
    },
    {
        "paper id": "2411.04925",
        "abstract url": "https://arxiv.org/abs/2411.04925",
        "title": "StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The advent of AI-Generated Content (AIGC) has spurred research into automated video generation to streamline conventional processes. However, automating storytelling video production, particularly for customized narratives, remains challenging due to the complexity of maintaining subject consistency across shots. While existing approaches like Mora and AesopAgent integrate multiple agents for Story-to-Video (S2V) generation, they fall short in preserving protagonist consistency and supporting Customized Storytelling Video Generation (CSVG). To address these limitations, we propose StoryAgent, a multi-agent framework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks assigned to specialized agents, mirroring the professional production process. Notably, our framework includes agents for story design, storyboard generation, video creation, agent coordination, and result evaluation. Leveraging the strengths of different models, StoryAgent enhances control over the generation process, significantly improving character consistency. Specifically, we introduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance intra-shot temporal consistency, while a novel storyboard generation pipeline is proposed to maintain subject consistency across shots. Extensive experiments demonstrate the effectiveness of our approach in synthesizing highly consistent storytelling videos, outperforming state-of-the-art methods. Our contributions include the introduction of StoryAgent, a versatile framework for video generation tasks, and novel techniques for preserving protagonist consistency.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04942",
        "abstract url": "https://arxiv.org/abs/2411.04942",
        "title": "A Reinforcement Learning-Based Automatic Video Editing Method Using Pre-trained Vision-Language Model",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language",
                "VLM"
            ],
            [
                "Video Editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this era of videos, automatic video editing techniques attract more and more attention from industry and academia since they can reduce workloads and lower the requirements for human editors. Existing automatic editing systems are mainly scene- or event-specific, e.g., soccer game broadcasting, yet the automatic systems for general editing, e.g., movie or vlog editing which covers various scenes and events, were rarely studied before, and converting the event-driven editing method to a general scene is nontrivial. In this paper, we propose a two-stage scheme for general editing. Firstly, unlike previous works that extract scene-specific features, we leverage the pre-trained Vision-Language Model (VLM) to extract the editing-relevant representations as editing context. Moreover, to close the gap between the professional-looking videos and the automatic productions generated with simple guidelines, we propose a Reinforcement Learning (RL)-based editing framework to formulate the editing problem and train the virtual editor to make better sequential editing decisions. Finally, we evaluate the proposed method on a more general editing task with a real movie dataset. Experimental results demonstrate the effectiveness and benefits of the proposed context representation and the learning ability of our RL-based editing framework.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04950",
        "abstract url": "https://arxiv.org/abs/2411.04950",
        "title": "Estimating the Influence of Sequentially Correlated Literary Properties in Textual Classification: A Data-Centric Hypothesis-Testing Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Stylometry aims to distinguish authors by analyzing literary traits assumed to reflect semi-conscious choices distinct from elements like genre or theme. However, these components often overlap, complicating text classification based solely on feature distributions. While some literary properties, such as thematic content, are likely to manifest as correlations between adjacent text units, others, like authorial style, may be independent thereof. We introduce a hypothesis-testing approach to evaluate the influence of sequentially correlated literary properties on text classification, aiming to determine when these correlations drive classification. Using a multivariate binary distribution, our method models sequential correlations between text units as a stochastic process, assessing the likelihood of clustering across varying adjacency scales. This enables us to examine whether classification is dominated by sequentially correlated properties or remains independent. In experiments on a diverse English prose corpus, our analysis integrates traditional and neural embeddings within supervised and unsupervised frameworks. Results demonstrate that our approach effectively identifies when textual classification is not primarily influenced by sequentially correlated literary properties, particularly in cases where texts differ in authorial style or genre rather than by a single author within a similar genre.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04952",
        "abstract url": "https://arxiv.org/abs/2411.04952",
        "title": "M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Document visual question answering (DocVQA) pipelines that answer questions from documents have broad applications. Existing methods focus on handling single-page documents with multi-modal language models (MLMs), or rely on text-based retrieval-augmented generation (RAG) that uses text extraction tools such as optical character recognition (OCR). However, there are difficulties in applying these methods in real-world scenarios: (a) questions often require information across different pages or documents, where MLMs cannot handle many long documents; (b) documents often have important information in visual elements such as figures, but text extraction tools ignore them. We introduce M3DocRAG, a novel multi-modal RAG framework that flexibly accommodates various document contexts (closed-domain and open-domain), question hops (single-hop and multi-hop), and evidence modalities (text, chart, figure, etc.). M3DocRAG finds relevant documents and answers questions using a multi-modal retriever and an MLM, so that it can efficiently handle single or many documents while preserving visual information. Since previous DocVQA datasets ask questions in the context of a specific document, we also present M3DocVQA, a new benchmark for evaluating open-domain DocVQA over 3,000+ PDF documents with 40,000+ pages. In three benchmarks (M3DocVQA/MMLongBench-Doc/MP-DocVQA), empirical results show that M3DocRAG with ColPali and Qwen2-VL 7B achieves superior performance than many strong baselines, including state-of-the-art performance in MP-DocVQA. We provide comprehensive analyses of different indexing, MLMs, and retrieval models. Lastly, we qualitatively show that M3DocRAG can successfully handle various scenarios, such as when relevant information exists across multiple pages and when answer evidence only exists in images.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Project webpage: https://m3docrag.github.io"
    },
    {
        "paper id": "2411.04954",
        "abstract url": "https://arxiv.org/abs/2411.04954",
        "title": "CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper aims to design a unified Computer-Aided Design (CAD) generation system that can easily generate CAD models based on the user's inputs in the form of textual description, images, point clouds, or even a combination of them. Towards this goal, we introduce the CAD-MLLM, the first system capable of generating parametric CAD models conditioned on the multimodal input. Specifically, within the CAD-MLLM framework, we leverage the command sequences of CAD models and then employ advanced large language models (LLMs) to align the feature space across these diverse multi-modalities data and CAD models' vectorized representations. To facilitate the model training, we design a comprehensive data construction and annotation pipeline that equips each CAD model with corresponding multimodal data. Our resulting dataset, named Omni-CAD, is the first multimodal CAD dataset that contains textual description, multi-view images, points, and command sequence for each CAD model. It contains approximately 450K instances and their CAD construction sequences. To thoroughly evaluate the quality of our generated CAD models, we go beyond current evaluation metrics that focus on reconstruction quality by introducing additional metrics that assess topology quality and surface enclosure extent. Extensive experimental results demonstrate that CAD-MLLM significantly outperforms existing conditional generative methods and remains highly robust to noises and missing points. The project page and more visualizations can be found at: https://cad-mllm.github.io/",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://cad-mllm.github.io/"
    },
    {
        "paper id": "2411.04965",
        "abstract url": "https://arxiv.org/abs/2411.04965",
        "title": "BitNet a4.8: 4-bit Activations for 1-bit LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Recent research on the 1-bit Large Language Models (LLMs), such as BitNet b1.58, presents a promising direction for reducing the inference cost of LLMs while maintaining their performance. In this work, we introduce BitNet a4.8, enabling 4-bit activations for 1-bit LLMs. BitNet a4.8 employs a hybrid quantization and sparsification strategy to mitigate the quantization errors introduced by the outlier channels. Specifically, we utilize 4-bit activations for inputs to the attention and feed-forward network layers, while sparsifying intermediate states followed with 8-bit quantization. Extensive experiments demonstrate that BitNet a4.8 achieves performance comparable to BitNet b1.58 with equivalent training costs, while being faster in inference with enabling 4-bit (INT4/FP4) kernels. Additionally, BitNet a4.8 activates only 55% of parameters and supports 3-bit KV cache, further enhancing the efficiency of large-scale LLM deployment and inference.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2411.04986",
        "abstract url": "https://arxiv.org/abs/2411.04986",
        "title": "The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Modern language models can process inputs across diverse languages and modalities. We hypothesize that models acquire this capability through learning a shared representation space across heterogeneous data types (e.g., different languages and modalities), which places semantically similar inputs near one another, even if they are from different modalities/languages. We term this the semantic hub hypothesis, following the hub-and-spoke model from neuroscience (Patterson et al., 2007) which posits that semantic knowledge in the human brain is organized through a transmodal semantic \"hub\" which integrates information from various modality-specific \"spokes\" regions. We first show that model representations for semantically equivalent inputs in different languages are similar in the intermediate layers, and that this space can be interpreted using the model's dominant pretraining language via the logit lens. This tendency extends to other data types, including arithmetic expressions, code, and visual/audio inputs. Interventions in the shared representation space in one data type also predictably affect model outputs in other data types, suggesting that this shared representations space is not simply a vestigial byproduct of large-scale training on broad data, but something that is actively utilized by the model during input processing.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04990",
        "abstract url": "https://arxiv.org/abs/2411.04990",
        "title": "Clustering in Causal Attention Masking",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "This work presents a modification of the self-attention dynamics proposed by Geshkovski et al. (arXiv:2312.10794) to better reflect the practically relevant, causally masked attention used in transformer architectures for generative AI. This modification translates into an interacting particle system that cannot be interpreted as a mean-field gradient flow. Despite this loss of structure, we significantly strengthen the results of Geshkovski et al. (arXiv:2312.10794) in this context: While previous rigorous results focused on cases where all three matrices (Key, Query, and Value) were scaled identities, we prove asymptotic convergence to a single cluster for arbitrary key-query matrices and a value matrix equal to the identity. Additionally, we establish a connection to the classical R\u00e9nyi parking problem from combinatorial geometry to make initial theoretical steps towards demonstrating the existence of meta-stable states.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.AP",
            "math.DS"
        ],
        "comment": "38th Conference on Neural Information Processing Systems (NeurIPS 2024), 22 pages, 6 figures"
    },
    {
        "paper id": "2411.04992",
        "abstract url": "https://arxiv.org/abs/2411.04992",
        "title": "Which bits went where? Past and future transfer entropy decomposition with the information bottleneck",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Whether the system under study is a shoal of fish, a collection of neurons, or a set of interacting atmospheric and oceanic processes, transfer entropy measures the flow of information between time series and can detect possible causal relationships. Much like mutual information, transfer entropy is generally reported as a single value summarizing an amount of shared variation, yet a more fine-grained accounting might illuminate much about the processes under study. Here we propose to decompose transfer entropy and localize the bits of variation on both sides of information flow: that of the originating process's past and that of the receiving process's future. We employ the information bottleneck (IB) to compress the time series and identify the transferred entropy. We apply our method to decompose the transfer entropy in several synthetic recurrent processes and an experimental mouse dataset of concurrent behavioral and neural activity. Our approach highlights the nuanced dynamics within information flow, laying a foundation for future explorations into the intricate interplay of temporal processes in complex systems.",
        "subjects": [
            "cs.LG",
            "cs.IT"
        ],
        "comment": "NeurIPS 2024 workshop \"Machine learning and the physical sciences\" Camera ready"
    },
    {
        "paper id": "2411.04996",
        "abstract url": "https://arxiv.org/abs/2411.04996",
        "title": "Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The development of large language models (LLMs) has expanded to multi-modal systems capable of processing text, images, and speech within a unified framework. Training these models demands significantly larger datasets and computational resources compared to text-only LLMs. To address the scaling challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal transformer architecture that significantly reduces pretraining computational costs. MoT decouples non-embedding parameters of the model by modality -- including feed-forward networks, attention matrices, and layer normalization -- enabling modality-specific processing with global self-attention over the full input sequence. We evaluate MoT across multiple settings and model scales. In the Chameleon 7B setting (autoregressive text-and-image generation), MoT matches the dense baseline's performance using only 55.8\\% of the FLOPs. When extended to include speech, MoT reaches speech performance comparable to the dense baseline with only 37.2\\% of the FLOPs. In the Transfusion setting, where text and image are trained with different objectives, a 7B MoT model matches the image modality performance of the dense baseline with one third of the FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image generation metrics. System profiling further highlights MoT's practical benefits, achieving dense baseline image quality in 47.2\\% of the wall-clock time and text quality in 75.6\\% of the wall-clock time (measured on AWS p4de.24xlarge instances with NVIDIA A100 GPUs).",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04997",
        "abstract url": "https://arxiv.org/abs/2411.04997",
        "title": "LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "CLIP is one of the most important multimodal foundational models today. What powers CLIP's capabilities? The rich supervision signals provided by natural language, the carrier of human knowledge, shape a powerful cross-modal representation space. However, with the rapid advancements in large language models LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and generation are continually being pushed. This raises an intriguing question: can the capabilities of LLMs be harnessed to further improve multimodal representation learning? The potential benefits of incorporating LLMs into CLIP are clear. LLMs' strong textual understanding can fundamentally improve CLIP's ability to handle image captions, drastically enhancing its ability to process long and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs are trained on a vast corpus of text, possessing open-world knowledge. This allows them to expand on caption information during training, increasing the efficiency of the learning process. In this paper, we propose LLM2CLIP, a novel approach that embraces the power of LLMs to unlock CLIP's potential. By fine-tuning the LLM in the caption space with contrastive learning, we extract its textual capabilities into the output embeddings, significantly improving the output layer's textual discriminability. We then design an efficient training process where the fine-tuned LLM acts as a powerful teacher for CLIP's visual encoder. Thanks to the LLM's presence, we can now incorporate longer and more complex captions without being restricted by vanilla CLIP's text encoder's context window and ability limitations. Our experiments demonstrate that this approach brings substantial improvements in cross-modal tasks.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05000",
        "abstract url": "https://arxiv.org/abs/2411.05000",
        "title": "Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "As the context limits of Large Language Models (LLMs) increase, the range of possible applications and downstream functions broadens. In many real-world tasks, decisions depend on details scattered across collections of often disparate documents containing mostly irrelevant information. Long-context LLMs appear well-suited to this form of complex information retrieval and reasoning, which has traditionally proven costly and time-consuming. However, although the development of longer context models has seen rapid gains in recent years, our understanding of how effectively LLMs use their context has not kept pace. To address this, we conduct a set of retrieval experiments designed to evaluate the capabilities of 17 leading LLMs, such as their ability to follow threads of information through the context window. Strikingly, we find that many models are remarkably threadsafe: capable of simultaneously following multiple threads without significant loss in performance. Still, for many models, we find the effective context limit is significantly shorter than the supported context length, with accuracy decreasing as the context window grows. Our study also highlights the important point that token counts from different tokenizers should not be directly compared -- they often correspond to substantially different numbers of written characters. We release our code and long-context experimental data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05049",
        "abstract url": "https://arxiv.org/abs/2411.05049",
        "title": "ProverbEval: Exploring LLM Evaluation Challenges for Low-resource Language Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "With the rapid development of evaluation datasets to assess LLMs understanding across a wide range of subjects and domains, identifying a suitable language understanding benchmark has become increasingly challenging. In this work, we explore LLM evaluation challenges for low-resource language understanding and introduce ProverbEval, LLM evaluation benchmark for low-resource languages based on proverbs to focus on low-resource language understanding in culture-specific scenarios. We benchmark various LLMs and explore factors that create variability in the benchmarking process. We observed performance variances of up to 50%, depending on the order in which answer choices were presented in multiple-choice tasks. Native language proverb descriptions significantly improve tasks such as proverb generation, contributing to improved outcomes. Additionally, monolingual evaluations consistently outperformed their cross-lingual counterparts. We argue special attention must be given to the order of choices, choice of prompt language, task variability, and generation tasks when creating LLM evaluation benchmarks.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05050",
        "abstract url": "https://arxiv.org/abs/2411.05050",
        "title": "Selecting Between BERT and GPT for Text Classification in Political Science Research",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Political scientists often grapple with data scarcity in text classification. Recently, fine-tuned BERT models and their variants have gained traction as effective solutions to address this issue. In this study, we investigate the potential of GPT-based models combined with prompt engineering as a viable alternative. We conduct a series of experiments across various classification tasks, differing in the number of classes and complexity, to evaluate the effectiveness of BERT-based versus GPT-based models in low-data scenarios. Our findings indicate that while zero-shot and few-shot learning with GPT models provide reasonable performance and are well-suited for early-stage research exploration, they generally fall short - or, at best, match - the performance of BERT fine-tuning, particularly as the training set reaches a substantial size (e.g., 1,000 samples). We conclude by comparing these approaches in terms of performance, ease of use, and cost, providing practical guidance for researchers facing data limitations. Our results are particularly relevant for those engaged in quantitative text analysis in low-resource settings or with limited labeled data.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "28 pages, 5 figures, 7 tables"
    },
    {
        "paper id": "2411.05054",
        "abstract url": "https://arxiv.org/abs/2411.05054",
        "title": "FMEA Builder: Expert Guided Text Generation for Equipment Maintenance",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Foundation models show great promise for generative tasks in many domains. Here we discuss the use of foundation models to generate structured documents related to critical assets. A Failure Mode and Effects Analysis (FMEA) captures the composition of an asset or piece of equipment, the ways it may fail and the consequences thereof. Our system uses large language models to enable fast and expert supervised generation of new FMEA documents. Empirical analysis shows that foundation models can correctly generate over half of an FMEA's key content. Results from polling audiences of reliability professionals show a positive outlook on using generative AI to create these documents for critical assets.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "4 pages, 2 figures. AI for Critical Infrastructure Workshop @ IJCAI 2024"
    },
    {
        "paper id": "2411.05060",
        "abstract url": "https://arxiv.org/abs/2411.05060",
        "title": "A Guide to Misinformation Detection Datasets",
        "rating": "1",
        "keywords": [
            [
                "cs.SI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Misinformation is a complex societal issue, and mitigating solutions are difficult to create due to data deficiencies. To address this problem, we have curated the largest collection of (mis)information datasets in the literature, totaling 75. From these, we evaluated the quality of all of the 36 datasets that consist of statements or claims. We assess these datasets to identify those with solid foundations for empirical work and those with flaws that could result in misleading and non-generalizable results, such as insufficient label quality, spurious correlations, or political bias. We further provide state-of-the-art baselines on all these datasets, but show that regardless of label quality, categorical labels may no longer give an accurate evaluation of detection model performance. We discuss alternatives to mitigate this problem. Overall, this guide aims to provide a roadmap for obtaining higher quality data and conducting more effective evaluations, ultimately improving research in misinformation detection. All datasets and other artifacts are available at https://misinfo-datasets.complexdatalab.com/.",
        "subjects": [
            "cs.SI",
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05088",
        "abstract url": "https://arxiv.org/abs/2411.05088",
        "title": "Findings of the IWSLT 2024 Evaluation Campaign",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper reports on the shared tasks organized by the 21st IWSLT Conference. The shared tasks address 7 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, dialect and low-resource speech translation, and Indic languages. The shared tasks attracted 18 teams whose submissions are documented in 26 system papers. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "IWSLT 2024; 59 pages"
    },
    {
        "paper id": "2411.05154",
        "abstract url": "https://arxiv.org/abs/2411.05154",
        "title": "TelEdge: Haptic Tele-Communication of a Smartphone by Electro-Tactile Stimulation Through the Edges",
        "rating": "1",
        "keywords": [
            [
                "audio-visual"
            ]
        ],
        "abstract": "We present TelEdge, a novel method of remote haptic communication using electrical stimulation through the edges of the smartphone. The aim of this study is to explore communications that can be created by adding touch sensing and haptic feedback using the electrical edge display to conventional audio-visual functionality. We conducted monitoring observations and interviews during a video call between two people, presenting interactive haptic feedback.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05192",
        "abstract url": "https://arxiv.org/abs/2411.05192",
        "title": "Explaining Mixtures of Sources in News Articles",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Human writers plan, then write. For large language models (LLMs) to play a role in longer-form article generation, we must understand the planning steps humans make before writing. We explore one kind of planning, source-selection in news, as a case-study for evaluating plans in long-form generation. We ask: why do specific stories call for specific kinds of sources? We imagine a generative process for story writing where a source-selection schema is first selected by a journalist, and then sources are chosen based on categories in that schema. Learning the article's plan means predicting the schema initially chosen by the journalist. Working with professional journalists, we adapt five existing schemata and introduce three new ones to describe journalistic plans for the inclusion of sources in documents. Then, inspired by Bayesian latent-variable modeling, we develop metrics to select the most likely plan, or schema, underlying a story, which we use to compare schemata. We find that two schemata: stance and social affiliation best explain source plans in most documents. However, other schemata like textual entailment explain source plans in factually rich topics like \"Science\". Finally, we find we can predict the most suitable schema given just the article's headline with reasonable accuracy. We see this as an important case-study for human planning, and provides a framework and approach for evaluating other kinds of plans. We release a corpora, NewsSources, with annotations for 4M articles.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2411.05193",
        "abstract url": "https://arxiv.org/abs/2411.05193",
        "title": "Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning",
        "rating": "1",
        "keywords": [
            [
                "VLMs"
            ],
            [
                "robotic manipulation",
                "navigation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Value-based reinforcement learning (RL) can in principle learn effective policies for a wide range of multi-turn problems, from games to dialogue to robotic control, including via offline RL from static previously collected datasets. However, despite the widespread use of policy gradient methods to train large language models for single turn tasks (e.g., question answering), value-based methods for multi-turn RL in an off-policy or offline setting have proven particularly challenging to scale to the setting of large language models. This setting requires effectively leveraging pretraining, scaling to large architectures with billions of parameters, and training on large datasets, all of which represent major challenges for current value-based RL methods. In this work, we propose a novel offline RL algorithm that addresses these drawbacks, casting Q-learning as a modified supervised fine-tuning (SFT) problem where the probabilities of tokens directly translate to Q-values. In this way we obtain an algorithm that smoothly transitions from maximizing the likelihood of the data during pretraining to learning a near-optimal Q-function during finetuning. Our algorithm has strong theoretical foundations, enjoying performance bounds similar to state-of-the-art Q-learning methods, while in practice utilizing an objective that closely resembles SFT. Because of this, our approach can enjoy the full benefits of the pretraining of language models, without the need to reinitialize any weights before RL finetuning, and without the need to initialize new heads for predicting values or advantages. Empirically, we evaluate our method on both pretrained LLMs and VLMs, on a variety of tasks including both natural language dialogue and robotic manipulation and navigation from images.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "16 pages, 4 figures"
    },
    {
        "paper id": "2411.05199",
        "abstract url": "https://arxiv.org/abs/2411.05199",
        "title": "CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have significantly advanced code generation but often require substantial resources and tend to over-generalize, limiting their efficiency for specific tasks. Fine-tuning smaller, open-source LLMs presents a viable alternative; however, it typically lags behind cutting-edge models due to supervised fine-tuning's reliance solely on correct code examples, which restricts the model's ability to learn from its own mistakes and adapt to diverse programming challenges. To bridge this gap, we introduce CodeLutra, a novel framework that enhances low-performing LLMs by leveraging both successful and failed code generation attempts. Unlike conventional fine-tuning, CodeLutra employs an iterative preference learning mechanism to compare correct and incorrect solutions as well as maximize the likelihood of correct codes. Through continuous iterative refinement, CodeLutra enables smaller LLMs to match or surpass GPT-4's performance in various code generation tasks without relying on vast external datasets or larger auxiliary models. On a challenging data analysis task, using just 500 samples improved Llama-3-8B's accuracy from 28.2% to 48.6%, approaching GPT-4's performance. These results highlight CodeLutra's potential to close the gap between open-source and closed-source models, making it a promising approach in the field of code generation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "18 pages, 4 figures"
    },
    {
        "paper id": "2411.05200",
        "abstract url": "https://arxiv.org/abs/2411.05200",
        "title": "Toward Cultural Interpretability: A Linguistic Anthropological Framework for Describing and Evaluating Large Language Models (LLMs)",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "This article proposes a new integration of linguistic anthropology and machine learning (ML) around convergent interests in both the underpinnings of language and making language technologies more socially responsible. While linguistic anthropology focuses on interpreting the cultural basis for human language use, the ML field of interpretability is concerned with uncovering the patterns that Large Language Models (LLMs) learn from human verbal behavior. Through the analysis of a conversation between a human user and an LLM-powered chatbot, we demonstrate the theoretical feasibility of a new, conjoint field of inquiry, cultural interpretability (CI). By focusing attention on the communicative competence involved in the way human users and AI chatbots co-produce meaning in the articulatory interface of human-computer interaction, CI emphasizes how the dynamic relationship between language and culture makes contextually sensitive, open-ended conversation possible. We suggest that, by examining how LLMs internally \"represent\" relationships between language and culture, CI can: (1) provide insight into long-standing linguistic anthropological questions about the patterning of those relationships; and (2) aid model developers and interface designers in improving value alignment between language models and stylistically diverse speakers and culturally diverse speech communities. Our discussion proposes three critical research axes: relativity, variation, and indexicality.",
        "subjects": [
            "cs.CY",
            "cs.CL",
            "cs.HC",
            "cs.LG"
        ],
        "comment": "Accepted for publication in Big Data & Society, November 2, 2024"
    },
    {
        "paper id": "2411.05209",
        "abstract url": "https://arxiv.org/abs/2411.05209",
        "title": "Alopex: A Computational Framework for Enabling On-Device Function Calls with LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid advancement of Large Language Models (LLMs) has led to their increased integration into mobile devices for personalized assistance, which enables LLMs to call external API functions to enhance their performance. However, challenges such as data scarcity, ineffective question formatting, and catastrophic forgetting hinder the development of on-device LLM agents. To tackle these issues, we propose Alopex, a framework that enables precise on-device function calls using the Fox LLM. Alopex introduces a logic-based method for generating high-quality training data and a novel ``description-question-output'' format for fine-tuning, reducing risks of function information leakage. Additionally, a data mixing strategy is used to mitigate catastrophic forgetting, combining function call data with textbook datasets to enhance performance in various tasks. Experimental results show that Alopex improves function call accuracy and significantly reduces catastrophic forgetting, providing a robust solution for integrating function call capabilities into LLMs without manual intervention.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05214",
        "abstract url": "https://arxiv.org/abs/2411.05214",
        "title": "STAND-Guard: A Small Task-Adaptive Content Moderation Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Content moderation, the process of reviewing and monitoring the safety of generated content, is important for development of welcoming online platforms and responsible large language models. Content moderation contains various tasks, each with its unique requirements tailored to specific scenarios. Therefore, it is crucial to develop a model that can be easily adapted to novel or customized content moderation tasks accurately without extensive model tuning. This paper presents STAND-GUARD, a Small Task-Adaptive coNtent moDeration model. The basic motivation is: by performing instruct tuning on various content moderation tasks, we can unleash the power of small language models (SLMs) on unseen (out-of-distribution) content moderation tasks. We also carefully study the effects of training tasks and model size on the efficacy of cross-task fine-tuning mechanism. Experiments demonstrate STAND-Guard is comparable to GPT-3.5-Turbo across over 40 public datasets, as well as proprietary datasets derived from real-world business scenarios. Remarkably, STAND-Guard achieved nearly equivalent results to GPT-4-Turbo on unseen English binary classification tasks",
        "subjects": [
            "cs.CL"
        ],
        "comment": "20 pages, 1 figure"
    },
    {
        "paper id": "2411.05227",
        "abstract url": "https://arxiv.org/abs/2411.05227",
        "title": "CHATTER: A Character Attribution Dataset for Narrative Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Computational narrative understanding studies the identification, description, and interaction of the elements of a narrative: characters, attributes, events, and relations. Narrative research has given considerable attention to defining and classifying character types. However, these character-type taxonomies do not generalize well because they are small, too simple, or specific to a domain. We require robust and reliable benchmarks to test whether narrative models truly understand the nuances of the character's development in the story. Our work addresses this by curating the Chatter dataset that labels whether a character portrays some attribute for 88148 character-attribute pairs, encompassing 2998 characters, 13324 attributes and 660 movies. We validate a subset of Chatter, called ChatterEval, using human annotations to serve as an evaluation benchmark for the character attribution task in movie scripts. ChatterEval assesses narrative understanding and the long-context modeling capacity of language models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "submitted to NAACL 2025"
    },
    {
        "paper id": "2411.05231",
        "abstract url": "https://arxiv.org/abs/2411.05231",
        "title": "Evaluating GPT-4 at Grading Handwritten Solutions in Math Exams",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in generative artificial intelligence (AI) have shown promise in accurately grading open-ended student responses. However, few prior works have explored grading handwritten responses due to a lack of data and the challenge of combining visual and textual information. In this work, we leverage state-of-the-art multi-modal AI models, in particular GPT-4o, to automatically grade handwritten responses to college-level math exams. Using real student responses to questions in a probability theory exam, we evaluate GPT-4o's alignment with ground-truth scores from human graders using various prompting techniques. We find that while providing rubrics improves alignment, the model's overall accuracy is still too low for real-world settings, showing there is significant room for growth in this task.",
        "subjects": [
            "cs.CY",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05232",
        "abstract url": "https://arxiv.org/abs/2411.05232",
        "title": "Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have shown remarkable performance across various tasks, yet their ability to handle long-context reading remains challenging. This study explores the effectiveness of leveraging high-quality academic peer review data for fine-tuning LLMs to enhance their long-context capabilities. We compare the Direct Preference Optimization (DPO) method with the Supervised Fine-Tuning (SFT) method, demonstrating DPO's superiority and data efficiency. Our experiments show that the fine-tuned model achieves a 4.04-point improvement over phi-3 and a 2.6\\% increase on the Qasper benchmark using only 2000 samples. Despite facing limitations in data scale and processing costs, this study underscores the potential of DPO and high-quality data in advancing LLM performance. Additionally, the zero-shot benchmark results indicate that aggregated high-quality human reviews are overwhelmingly preferred over LLM-generated responses, even for the most capable models like GPT-4o. This suggests that high-quality human reviews are extremely rich in information, reasoning, and long-context retrieval, capabilities that even the most advanced models have not fully captured. These findings highlight the high utility of leveraging human reviews to further advance the field.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "We share our latest dataset on https://github.com/findalexli/Abstract2Appendix"
    },
    {
        "paper id": "2411.05238",
        "abstract url": "https://arxiv.org/abs/2411.05238",
        "title": "Generating Highly Designable Proteins with Geometric Algebra Flow Matching",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We introduce a generative model for protein backbone design utilizing geometric products and higher order message passing. In particular, we propose Clifford Frame Attention (CFA), an extension of the invariant point attention (IPA) architecture from AlphaFold2, in which the backbone residue frames and geometric features are represented in the projective geometric algebra. This enables to construct geometrically expressive messages between residues, including higher order terms, using the bilinear operations of the algebra. We evaluate our architecture by incorporating it into the framework of FrameFlow, a state-of-the-art flow matching model for protein backbone generation. The proposed model achieves high designability, diversity and novelty, while also sampling protein backbones that follow the statistical distribution of secondary structure elements found in naturally occurring proteins, a property so far only insufficiently achieved by many state-of-the-art generative models.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "To be published in proceedings of NeurIPS 2024"
    },
    {
        "paper id": "2411.05253",
        "abstract url": "https://arxiv.org/abs/2411.05253",
        "title": "What talking you?: Translating Code-Mixed Messaging Texts to English",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Translation of code-mixed texts to formal English allow a wider audience to understand these code-mixed languages, and facilitate downstream analysis applications such as sentiment analysis. In this work, we look at translating Singlish, which is colloquial Singaporean English, to formal standard English. Singlish is formed through the code-mixing of multiple Asian languages and dialects. We analysed the presence of other Asian languages and variants which can facilitate translation. Our dataset is short message texts, written as informal communication between Singlish speakers. We use a multi-step prompting scheme on five Large Language Models (LLMs) for language detection and translation. Our analysis show that LLMs do not perform well in this task, and we describe the challenges involved in translation of code-mixed languages. We also release our dataset in this link https://github.com/luoqichan/singlish.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05265",
        "abstract url": "https://arxiv.org/abs/2411.05265",
        "title": "Image Decomposition: Theory, Numerical Schemes, and Performance Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This paper describes the many image decomposition models that allow to separate structures and textures or structures, textures, and noise. These models combined a total variation approach with different adapted functional spaces such as Besov or Contourlet spaces or a special oscillating function space based on the work of Yves Meyer. We propose a method to evaluate the performance of such algorithms to enhance understanding of the behavior of these models.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "math.FA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05270",
        "abstract url": "https://arxiv.org/abs/2411.05270",
        "title": "Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination Detection Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a comparative analysis of hallucination detection systems for AI, focusing on automatic summarization and question answering tasks for Large Language Models (LLMs). We evaluate different hallucination detection systems using the diagnostic odds ratio (DOR) and cost-effectiveness metrics. Our results indicate that although advanced models can perform better they come at a much higher cost. We also demonstrate how an ideal hallucination detection system needs to maintain performance across different model sizes. Our findings highlight the importance of choosing a detection system aligned with specific application needs and resource constraints. Future research will explore hybrid systems and automated identification of underperforming components to enhance AI reliability and efficiency in detecting and mitigating hallucinations.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "18 pags, 13 figures, 2 tables"
    },
    {
        "paper id": "2411.05307",
        "abstract url": "https://arxiv.org/abs/2411.05307",
        "title": "Revisiting Network Perturbation for Semi-Supervised Semantic Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In semi-supervised semantic segmentation (SSS), weak-to-strong consistency regularization techniques are widely utilized in recent works, typically combined with input-level and feature-level perturbations. However, the integration between weak-to-strong consistency regularization and network perturbation has been relatively rare. We note several problems with existing network perturbations in SSS that may contribute to this phenomenon. By revisiting network perturbations, we introduce a new approach for network perturbation to expand the existing weak-to-strong consistency regularization for unlabeled data. Additionally, we present a volatile learning process for labeled data, which is uncommon in existing research. Building upon previous work that includes input-level and feature-level perturbations, we present MLPMatch (Multi-Level-Perturbation Match), an easy-to-implement and efficient framework for semi-supervised semantic segmentation. MLPMatch has been validated on the Pascal VOC and Cityscapes datasets, achieving state-of-the-art performance. Code is available from https://github.com/LlistenL/MLPMatch.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted by PRCV2024"
    },
    {
        "paper id": "2411.05858",
        "abstract url": "https://arxiv.org/abs/2411.05858",
        "title": "Saliency Assisted Quantization for Neural Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning methods have established a significant place in image classification. While prior research has focused on enhancing final outcomes, the opaque nature of the decision-making process in these models remains a concern for experts. Additionally, the deployment of these methods can be problematic in resource-limited environments. This paper tackles the inherent black-box nature of these models by providing real-time explanations during the training phase, compelling the model to concentrate on the most distinctive and crucial aspects of the input. Furthermore, we employ established quantization techniques to address resource constraints. To assess the effectiveness of our approach, we explore how quantization influences the interpretability and accuracy of Convolutional Neural Networks through a comparative analysis of saliency maps from standard and quantized models. Quantization is implemented during the training phase using the Parameterized Clipping Activation method, with a focus on the MNIST and FashionMNIST benchmark datasets. We evaluated three bit-width configurations (2-bit, 4-bit, and mixed 4/2-bit) to explore the trade-off between efficiency and interpretability, with each configuration designed to highlight varying impacts on saliency map clarity and model accuracy. The results indicate that while quantization is crucial for implementing models on resource-limited devices, it necessitates a trade-off between accuracy and interpretability. Lower bit-widths result in more pronounced reductions in both metrics, highlighting the necessity of meticulous quantization parameter selection in applications where model transparency is paramount. The study underscores the importance of achieving a balance between efficiency and interpretability in the deployment of neural networks.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05872",
        "abstract url": "https://arxiv.org/abs/2411.05872",
        "title": "Dialectal Coverage And Generalization in Arabic Speech Recognition",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Developing robust automatic speech recognition (ASR) systems for Arabic, a language characterized by its rich dialectal diversity and often considered a low-resource language in speech technology, demands effective strategies to manage its complexity. This study explores three critical factors influencing ASR performance: the role of dialectal coverage in pre-training, the effectiveness of dialect-specific fine-tuning compared to a multi-dialectal approach, and the ability to generalize to unseen dialects. Through extensive experiments across different dialect combinations, our findings offer key insights towards advancing the development of ASR systems for pluricentric languages like Arabic.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05875",
        "abstract url": "https://arxiv.org/abs/2411.05875",
        "title": "Towards Improved Preference Optimization Pipeline: from Data Generation to Budget-Controlled Regularization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Direct Preference Optimization (DPO) and its variants have become the de facto standards for aligning large language models (LLMs) with human preferences or specific goals. However, DPO requires high-quality preference data and suffers from unstable preference optimization. In this work, we aim to improve the preference optimization pipeline by taking a closer look at preference data generation and training regularization techniques. For preference data generation, we demonstrate that existing scoring-based reward models produce unsatisfactory preference data and perform poorly on out-of-distribution tasks. This significantly impacts the LLM alignment performance when using these data for preference tuning. To ensure high-quality preference data generation, we propose an iterative pairwise ranking mechanism that derives preference ranking of completions using pairwise comparison signals. For training regularization, we observe that preference optimization tends to achieve better convergence when the LLM predicted likelihood of preferred samples gets slightly reduced. However, the widely used supervised next-word prediction regularization strictly prevents any likelihood reduction of preferred samples. This observation motivates our design of a budget-controlled regularization formulation. Empirically we show that combining the two designs leads to aligned models that surpass existing SOTA across two popular benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2411.05876",
        "abstract url": "https://arxiv.org/abs/2411.05876",
        "title": "Trends, Challenges, and Future Directions in Deep Learning for Glaucoma: A Systematic Review",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Here, we examine the latest advances in glaucoma detection through Deep Learning (DL) algorithms using Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). This study focuses on three aspects of DL-based glaucoma detection frameworks: input data modalities, processing strategies, and model architectures and applications. Moreover, we analyze trends in employing each aspect since the onset of DL in this field. Finally, we address current challenges and suggest future research directions.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05877",
        "abstract url": "https://arxiv.org/abs/2411.05877",
        "title": "Generative Adapter: Contextualizing Language Models in Parameters with A Single Forward Pass",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LMs) are typically adapted to improve performance on new contexts (\\eg text prompts that define new tasks or domains) through fine-tuning or prompting. However, there is an accuracy compute tradeoff -- fine-tuning incurs significant training cost and prompting increases inference overhead. We introduce $GenerativeAdapter$, an effective and efficient adaptation method that directly maps new contexts to low-rank LM adapters, thereby significantly reducing inference overhead with no need for finetuning. The adapter generator is trained via self-supervised learning, and can be used to adapt a single frozen LM for any new task simply by mapping the associated task or domain context to a new adapter. We apply $GenerativeAdapter$ to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models in three adaption scenarios: knowledge acquisition from documents, learning from demonstrations, and personalization for users. In StreamingQA, our approach is effective in injecting knowledge into the LM's parameters, achieving a 63.5% improvement in F1 score over the model with supervised fine-tuning (from $19.5$ to $31.5$) for contexts as long as 32K tokens. In the MetaICL in-context learning evaluation, our method achieves an average accuracy of $44.9$ across 26 tasks, outperforming the base model. On MSC, our method proves to be highly competitive in memorizing user information from conversations with a 4x reduction in computation and memory costs compared to prompting with full conversation history. Together, these results suggest that $GenerativeAdapter$ should allow for general adaption to a wide range of different contexts.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04453",
        "abstract url": "https://arxiv.org/abs/2411.04453",
        "title": "Comparing Fairness of Generative Mobility Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work examines the fairness of generative mobility models, addressing the often overlooked dimension of equity in model performance across geographic regions. Predictive models built on crowd flow data are instrumental in understanding urban structures and movement patterns; however, they risk embedding biases, particularly in spatiotemporal contexts where model performance may reflect and reinforce existing inequities tied to geographic distribution. We propose a novel framework for assessing fairness by measuring the utility and equity of generated traces. Utility is assessed via the Common Part of Commuters (CPC), a similarity metric comparing generated and real mobility flows, while fairness is evaluated using demographic parity. By reformulating demographic parity to reflect the difference in CPC distribution between two groups, our analysis reveals disparities in how various models encode biases present in the underlying data. We utilized four models (Gravity, Radiation, Deep Gravity, and Non-linear Gravity) and our results indicate that traditional gravity and radiation models produce fairer outcomes, although Deep Gravity achieves higher CPC. This disparity underscores a trade-off between model accuracy and equity, with the feature-rich Deep Gravity model amplifying pre-existing biases in community representations. Our findings emphasize the importance of integrating fairness metrics in mobility modeling to avoid perpetuating inequities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "2 pages, Accepted at the Network Mobility (NetMob) 2024 conference"
    },
    {
        "paper id": "2411.04459",
        "abstract url": "https://arxiv.org/abs/2411.04459",
        "title": "GPT-Guided Monte Carlo Tree Search for Symbolic Regression in Financial Fraud Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the increasing number of financial services available online, the rate of financial fraud has also been increasing. The traffic and transaction rates on the internet have increased considerably, leading to a need for fast decision-making. Financial institutions also have stringent regulations that often require transparency and explainability of the decision-making process. However, most state-of-the-art algorithms currently used in the industry are highly parameterized black-box models that rely on complex computations to generate a score. These algorithms are inherently slow and lack the explainability and speed of traditional rule-based learners. This work introduces SR-MCTS (Symbolic Regression MCTS), which utilizes a foundational GPT model to guide the MCTS, significantly enhancing its convergence speed and the quality of the generated expressions which are further extracted to rules. Our experiments show that SR-MCTS can detect fraud more efficiently than widely used methods in the industry while providing substantial insights into the decision-making process.",
        "subjects": [
            "cs.CE",
            "cs.LG"
        ],
        "comment": "ACM International Conference on Information and Knowledge Management 2024 RAG - Enterprise"
    },
    {
        "paper id": "2411.04462",
        "abstract url": "https://arxiv.org/abs/2411.04462",
        "title": "Can CDT rationalise the ex ante optimal policy via modified anthropics?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In Newcomb's problem, causal decision theory (CDT) recommends two-boxing and thus comes apart from evidential decision theory (EDT) and ex ante policy optimisation (which prescribe one-boxing). However, in Newcomb's problem, you should perhaps believe that with some probability you are in a simulation run by the predictor to determine whether to put a million dollars into the opaque box. If so, then causal decision theory might recommend one-boxing in order to cause the predictor to fill the opaque box. In this paper, we study generalisations of this approach. That is, we consider general Newcomblike problems and try to form reasonable self-locating beliefs under which CDT's recommendations align with an EDT-like notion of ex ante policy optimisation. We consider approaches in which we model the world as running simulations of the agent, and an approach not based on such models (which we call 'Generalised Generalised Thirding', or GGT). For each approach, we characterise the resulting CDT policies, and prove that under certain conditions, these include the ex ante optimal policies.",
        "subjects": [
            "cs.AI",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04468",
        "abstract url": "https://arxiv.org/abs/2411.04468",
        "title": "Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Modern AI agents, driven by advances in large foundation models, promise to enhance our productivity and transform our lives by augmenting our knowledge and capabilities. To achieve this vision, AI agents must effectively plan, perform multi-step reasoning and actions, respond to novel observations, and recover from errors, to successfully complete complex tasks across a wide range of scenarios. In this work, we introduce Magentic-One, a high-performing open-source agentic system for solving such tasks. Magentic-One uses a multi-agent architecture where a lead agent, the Orchestrator, plans, tracks progress, and re-plans to recover from errors. Throughout task execution, the Orchestrator directs other specialized agents to perform tasks as needed, such as operating a web browser, navigating local files, or writing and executing Python code. We show that Magentic-One achieves statistically competitive performance to the state-of-the-art on three diverse and challenging agentic benchmarks: GAIA, AssistantBench, and WebArena. Magentic-One achieves these results without modification to core agent capabilities or to how they collaborate, demonstrating progress towards generalist agentic systems. Moreover, Magentic-One's modular design allows agents to be added or removed from the team without additional prompt tuning or training, easing development and making it extensible to future scenarios. We provide an open-source implementation of Magentic-One, and we include AutoGenBench, a standalone tool for agentic evaluation. AutoGenBench provides built-in controls for repetition and isolation to run agentic benchmarks in a rigorous and contained manner -- which is important when agents' actions have side-effects. Magentic-One, AutoGenBench and detailed empirical performance evaluations of Magentic-One, including ablations and error analysis are available at https://aka.ms/magentic-one",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04476",
        "abstract url": "https://arxiv.org/abs/2411.04476",
        "title": "LLM-R: A Framework for Domain-Adaptive Maintenance Scheme Generation Combining Hierarchical Agents and RAG",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The increasing use of smart devices has emphasized the critical role of maintenance in production activities. Interactive Electronic Technical Manuals (IETMs) are vital tools that support the maintenance of smart equipment. However, traditional IETMs face challenges such as transitioning from Graphical User Interfaces (GUIs) to natural Language User Interfaces (LUIs) and managing complex logical relationships. Additionally, they must meet the current demands for higher intelligence. This paper proposes a Maintenance Scheme Generation Method based on Large Language Models (LLM-R). The proposed method includes several key innovations: We propose the Low Rank Adaptation-Knowledge Retention (LORA-KR) loss technology to proportionally adjust mixed maintenance data for fine-tuning the LLM. This method prevents knowledge conflicts caused by mixed data, improving the model's adaptability and reasoning ability in specific maintenance domains, Besides, Hierarchical Task-Based Agent and Instruction-level Retrieval-Augmented Generation (RAG) technologies are adopted to optimize the generation steps and mitigate the phenomenon of hallucination caused by the model's Inability to access contextual information. This enhancement improves the model's flexibility and accuracy in handling known or unknown maintenance objects and maintenance scheme scenarios. To validate the proposed method's effectiveness in maintenance tasks, a maintenance scheme dataset was constructed using objects from different fields. The experimental results show that the accuracy of the maintenance schemes generated by the proposed method reached 91.59%, indicating which improvement enhances the intelligence of maintenance schemes and introduces novel technical approaches for equipment maintenance.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "30 pages, 7 figures"
    },
    {
        "paper id": "2411.04490",
        "abstract url": "https://arxiv.org/abs/2411.04490",
        "title": "Smoke Screens and Scapegoats: The Reality of General Data Protection Regulation Compliance -- Privacy and Ethics in the Case of Replika AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Currently artificial intelligence (AI)-enabled chatbots are capturing the hearts and imaginations of the public at large. Chatbots that users can build and personalize, as well as pre-designed avatars ready for users' selection, all of these are on offer in applications to provide social companionship, friends and even love. These systems, however, have demonstrated challenges on the privacy and ethics front. This paper takes a critical approach towards examining the intricacies of these issues within AI companion services. We chose Replika as a case and employed close reading to examine the service's privacy policy. We additionally analyze articles from public media about the company and its practices to gain insight into the trustworthiness and integrity of the information provided in the policy. The aim is to ascertain whether seeming General Data Protection Regulation (GDPR) compliance equals reliability of required information, or whether the area of GDPR compliance in itself is one riddled with ethical challenges. The paper contributes to a growing body of scholarship on ethics and privacy related matters in the sphere of social chatbots. The results reveal that despite privacy notices, data collection practices might harvest personal data without users' full awareness. Cross-textual comparison reveals that privacy notice information does not fully correspond with other information sources.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04511",
        "abstract url": "https://arxiv.org/abs/2411.04511",
        "title": "Improve the Fitting Accuracy of Deep Learning for the Nonlinear Schr\u00f6dinger Equation Using Linear Feature Decoupling Method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We utilize the Feature Decoupling Distributed (FDD) method to enhance the capability of deep learning to fit the Nonlinear Schrodinger Equation (NLSE), significantly reducing the NLSE loss compared to non decoupling model.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04512",
        "abstract url": "https://arxiv.org/abs/2411.04512",
        "title": "Normalized Space Alignment: A Versatile Metric for Representation Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a manifold analysis technique for neural network representations. Normalized Space Alignment (NSA) compares pairwise distances between two point clouds derived from the same source and having the same size, while potentially possessing differing dimensionalities. NSA can act as both an analytical tool and a differentiable loss function, providing a robust means of comparing and aligning representations across different layers and models. It satisfies the criteria necessary for both a similarity metric and a neural network loss function. We showcase NSA's versatility by illustrating its utility as a representation space analysis metric, a structure-preserving loss function, and a robustness analysis tool. NSA is not only computationally efficient but it can also approximate the global structural discrepancy during mini-batching, facilitating its use in a wide variety of neural network training paradigms.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2411.04525",
        "abstract url": "https://arxiv.org/abs/2411.04525",
        "title": "GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns from Subplan Hints",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Query optimization has become a research area where classical algorithms are being challenged by machine learning algorithms. At the same time, recent trends in learned query optimizers have shown that it is prudent to take advantage of decades of database research and augment classical query optimizers by shrinking the plan search space through different types of hints (e.g. by specifying the join type, scan type or the order of joins) rather than completely replacing the classical query optimizer with machine learning models. It is especially relevant for cases when classical optimizers cannot fully enumerate all logical and physical plans and, as an alternative, need to rely on less robust approaches like genetic algorithms. However, even symbiotically learned query optimizers are hampered by the need for vast amounts of training data, slow plan generation during inference and unstable results across various workload conditions. In this paper, we present GenJoin - a novel learned query optimizer that considers the query optimization problem as a generative task and is capable of learning from a random set of subplan hints to produce query plans that outperform the classical optimizer. GenJoin is the first learned query optimizer that significantly and consistently outperforms PostgreSQL as well as state-of-the-art methods on two well-known real-world benchmarks across a variety of workloads using rigorous machine learning evaluations.",
        "subjects": [
            "cs.DB",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04532",
        "abstract url": "https://arxiv.org/abs/2411.04532",
        "title": "Real-time stress detection on social network posts using big data technology",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the context of modern life, particularly in Industry 4.0 within the online space, emotions and moods are frequently conveyed through social media posts. The trend of sharing stories, thoughts, and feelings on these platforms generates a vast and promising data source for Big Data. This creates both a challenge and an opportunity for research in applying technology to develop more automated and accurate methods for detecting stress in social media users. In this study, we developed a real-time system for stress detection in online posts, using the \"Dreaddit: A Reddit Dataset for Stress Analysis in Social Media,\" which comprises 187,444 posts across five different Reddit domains. Each domain contains texts with both stressful and non-stressful content, showcasing various expressions of stress. A labeled dataset of 3,553 lines was created for training. Apache Kafka, PySpark, and AirFlow were utilized to build and deploy the model. Logistic Regression yielded the best results for new streaming data, achieving 69,39% for measuring accuracy and 68,97 for measuring F1-scores.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "6 pages, 4 figures"
    },
    {
        "paper id": "2411.04547",
        "abstract url": "https://arxiv.org/abs/2411.04547",
        "title": "Dynamic Detection of Relevant Objectives and Adaptation to Preference Drifts in Interactive Evolutionary Multi-Objective Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Evolutionary Multi-Objective Optimization Algorithms (EMOAs) are widely employed to tackle problems with multiple conflicting objectives. Recent research indicates that not all objectives are equally important to the decision-maker (DM). In the context of interactive EMOAs, preference information elicited from the DM during the optimization process can be leveraged to identify and discard irrelevant objectives, a crucial step when objective evaluations are computationally expensive. However, much of the existing literature fails to account for the dynamic nature of DM preferences, which can evolve throughout the decision-making process and affect the relevance of objectives. This study addresses this limitation by simulating dynamic shifts in DM preferences within a ranking-based interactive algorithm. Additionally, we propose methods to discard outdated or conflicting preferences when such shifts occur. Building on prior research, we also introduce a mechanism to safeguard relevant objectives that may become trapped in local or global optima due to the diminished correlation with the DM-provided rankings. Our experimental results demonstrate that the proposed methods effectively manage evolving preferences and significantly enhance the quality and desirability of the solutions produced by the algorithm.",
        "subjects": [
            "cs.AI",
            "cs.NE",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04549",
        "abstract url": "https://arxiv.org/abs/2411.04549",
        "title": "Vision Language Models are In-Context Value Learners",
        "rating": "0.5",
        "keywords": [
            [
                "Vision Language",
                "VLMs"
            ],
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Predicting temporal progress from visual trajectories is important for intelligent robots that can learn, adapt, and improve. However, learning such progress estimator, or temporal value function, across different tasks and domains requires both a large amount of diverse data and methods which can scale and generalize. To address these challenges, we present Generative Value Learning (\\GVL), a universal value function estimator that leverages the world knowledge embedded in vision-language models (VLMs) to predict task progress. Naively asking a VLM to predict values for a video sequence performs poorly due to the strong temporal correlation between successive frames. Instead, GVL poses value estimation as a temporal ordering problem over shuffled video frames; this seemingly more challenging task encourages VLMs to more fully exploit their underlying semantic and temporal grounding capabilities to differentiate frames based on their perceived task progress, consequently producing significantly better value predictions. Without any robot or task specific training, GVL can in-context zero-shot and few-shot predict effective values for more than 300 distinct real-world tasks across diverse robot platforms, including challenging bimanual manipulation tasks. Furthermore, we demonstrate that GVL permits flexible multi-modal in-context learning via examples from heterogeneous tasks and embodiments, such as human videos. The generality of GVL enables various downstream applications pertinent to visuomotor policy learning, including dataset filtering, success detection, and advantage-weighted regression -- all without any model training or finetuning.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Project website and demo: https://generative-value-learning.github.io/"
    },
    {
        "paper id": "2411.04551",
        "abstract url": "https://arxiv.org/abs/2411.04551",
        "title": "Measure-to-measure interpolation using Transformers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformers are deep neural network architectures that underpin the recent successes of large language models. Unlike more classical architectures that can be viewed as point-to-point maps, a Transformer acts as a measure-to-measure map implemented as specific interacting particle system on the unit sphere: the input is the empirical measure of tokens in a prompt and its evolution is governed by the continuity equation. In fact, Transformers are not limited to empirical measures and can in principle process any input measure. As the nature of data processed by Transformers is expanding rapidly, it is important to investigate their expressive power as maps from an arbitrary measure to another arbitrary measure. To that end, we provide an explicit choice of parameters that allows a single Transformer to match $N$ arbitrary input measures to $N$ arbitrary target measures, under the minimal assumption that every pair of input-target measures can be matched by some transport map.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04555",
        "abstract url": "https://arxiv.org/abs/2411.04555",
        "title": "An Axiomatic Study of the Evaluation of Enthymeme Decoding in Weighted Structured Argumentation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "An argument can be seen as a pair consisting of a set of premises and a claim supported by them. Arguments used by humans are often enthymemes, i.e., some premises are implicit. To better understand, evaluate, and compare enthymemes, it is essential to decode them, i.e., to find the missing premisses. Many enthymeme decodings are possible. We need to distinguish between reasonable decodings and unreasonable ones. However, there is currently no research in the literature on \"How to evaluate decodings?\". To pave the way and achieve this goal, we introduce seven criteria related to decoding, based on different research areas. Then, we introduce the notion of criterion measure, the objective of which is to evaluate a decoding with regard to a certain criterion. Since such measures need to be validated, we introduce several desirable properties for them, called axioms. Another main contribution of the paper is the construction of certain criterion measures that are validated by our axioms. Such measures can be used to identify the best enthymemes decodings.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2411.04571",
        "abstract url": "https://arxiv.org/abs/2411.04571",
        "title": "DomainGallery: Few-shot Domain-driven Image Generation by Attribute-centric Finetuning",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The recent progress in text-to-image models pretrained on large-scale datasets has enabled us to generate various images as long as we provide a text prompt describing what we want. Nevertheless, the availability of these models is still limited when we expect to generate images that fall into a specific domain either hard to describe or just unseen to the models. In this work, we propose DomainGallery, a few-shot domain-driven image generation method which aims at finetuning pretrained Stable Diffusion on few-shot target datasets in an attribute-centric manner. Specifically, DomainGallery features prior attribute erasure, attribute disentanglement, regularization and enhancement. These techniques are tailored to few-shot domain-driven generation in order to solve key issues that previous works have failed to settle. Extensive experiments are given to validate the superior performance of DomainGallery on a variety of domain-driven generation scenarios. Codes are available at https://github.com/Ldhlwh/DomainGallery.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.04578",
        "abstract url": "https://arxiv.org/abs/2411.04578",
        "title": "Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multi-agent systems - systems with multiple independent AI agents working together to achieve a common goal - are becoming increasingly prevalent in daily life. Drawing inspiration from the phenomenon of human group social influence, we investigate whether a group of AI agents can create social pressure on users to agree with them, potentially changing their stance on a topic. We conducted a study in which participants discussed social issues with either a single or multiple AI agents, and where the agents either agreed or disagreed with the user's stance on the topic. We found that conversing with multiple agents (holding conversation content constant) increased the social pressure felt by participants, and caused a greater shift in opinion towards the agents' stances on each topic. Our study shows the potential advantages of multi-agent systems over single-agent platforms in causing opinion change. We discuss design implications for possible multi-agent systems that promote social good, as well as the potential for malicious actors to use these systems to manipulate public opinion.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04579",
        "abstract url": "https://arxiv.org/abs/2411.04579",
        "title": "Towards Robust Federated Analytics via Differentially Private Measurements of Statistical Heterogeneity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Statistical heterogeneity is a measure of how skewed the samples of a dataset are. It is a common problem in the study of differential privacy that the usage of a statistically heterogeneous dataset results in a significant loss of accuracy. In federated scenarios, statistical heterogeneity is more likely to happen, and so the above problem is even more pressing. We explore the three most promising ways to measure statistical heterogeneity and give formulae for their accuracy, while simultaneously incorporating differential privacy. We find the optimum privacy parameters via an analytic mechanism, which incorporates root finding methods. We validate the main theorems and related hypotheses experimentally, and test the robustness of the analytic mechanism to different heterogeneity levels. The analytic mechanism in a distributed setting delivers superior accuracy to all combinations involving the classic mechanism and/or the centralized setting. All measures of statistical heterogeneity do not lose significant accuracy when a heterogeneous sample is used.",
        "subjects": [
            "cs.LG",
            "cs.DB"
        ],
        "comment": "26 pages, 6 tables, 1 figure"
    },
    {
        "paper id": "2411.04580",
        "abstract url": "https://arxiv.org/abs/2411.04580",
        "title": "Interpreting the Learned Model in MuZero Planning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "MuZero has achieved superhuman performance in various games by using a dynamics network to predict environment dynamics for planning, without relying on simulators. However, the latent states learned by the dynamics network make its planning process opaque. This paper aims to demystify MuZero's model by interpreting the learned latent states. We incorporate observation reconstruction and state consistency into MuZero training and conduct an in-depth analysis to evaluate latent states across two board games: 9x9 Go and Outer-Open Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our findings reveal that while the dynamics network becomes less accurate over longer simulations, MuZero still performs effectively by using planning to correct errors. Our experiments also show that the dynamics network learns better latent states in board games than in Atari games. These insights contribute to a better understanding of MuZero and offer directions for future research to improve the playing performance, robustness, and interpretability of the MuZero algorithm.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted by the 29th International Conference on Technologies and Applications of Artificial Intelligence (TAAI 2024)"
    },
    {
        "paper id": "2411.04625",
        "abstract url": "https://arxiv.org/abs/2411.04625",
        "title": "Sharp Analysis for KL-Regularized Contextual Bandits and RLHF",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reverse-Kullback-Leibler (KL) regularization has emerged to be a predominant technique used to enhance policy optimization in reinforcement learning (RL) and reinforcement learning from human feedback (RLHF), which forces the learned policy to stay close to a reference policy. While the effectiveness and necessity of KL-regularization have been empirically demonstrated in various practical scenarios, current theoretical analysis of KL-regularized RLHF still obtains the same $\\mathcal{O}(1 / \u03b5^2)$ sample complexity as problems without KL-regularization. To understand the fundamental distinction between policy learning objectives with KL-regularization and ones without KL-regularization, we are the first to theoretically demonstrate the power of KL-regularization by providing a sharp analysis for KL-regularized contextual bandits and RLHF, revealing an $\\mathcal{O}(1 / \u03b5)$ sample complexity when $\u03b5$ is sufficiently small. We further explore the role of data coverage in contextual bandits and RLHF. While the coverage assumption is commonly employed in offline RLHF to link the samples from the reference policy to the optimal policy, often at the cost of a multiplicative dependence on the coverage coefficient, its impact on the sample complexity of online RLHF remains unclear. Previous theoretical analyses of online RLHF typically require explicit exploration and additional structural assumptions on the reward function class. In contrast, we show that with sufficient coverage from the reference policy, a simple two-stage mixed sampling strategy can achieve a sample complexity with only an additive dependence on the coverage coefficient. Our results provide a comprehensive understanding of the roles of KL-regularization and data coverage in RLHF, shedding light on the design of more efficient RLHF algorithms.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04681",
        "abstract url": "https://arxiv.org/abs/2411.04681",
        "title": "A dynamical model of platform choice and online segregation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "In order to truly understand how social media might shape online discourses or contribute to societal polarization, we need refined models of platform choice, that is: models that help us understand why users prefer one social media platform over another. This study develops a dynamic model of platform selection, extending Social Feedback Theory by incorporating multi-agent reinforcement learning to capture how user decisions are shaped by past rewards across different platforms. A key parameter ($\u03bc$) in the model governs users' tendencies to either seek approval from like-minded peers or engage with opposing views. Our findings reveal that online environments can evolve into suboptimal states characterized by polarized, strongly opinionated echo chambers, even when users prefer diverse perspectives. Interestingly, this polarizing state coexists with another equilibrium, where users gravitate toward a single dominant platform, marginalizing other platforms into extremity. Using agent-based simulations and dynamical systems analysis, our model underscores the complex interplay of user preferences and platform dynamics, offering insights into how digital spaces might be better managed to foster diverse discourse.",
        "subjects": [
            "nlin.AO",
            "cs.SI",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04685",
        "abstract url": "https://arxiv.org/abs/2411.04685",
        "title": "Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper focuses on the generalized grouping problem in the context of cellular manufacturing systems (CMS), where parts may have more than one process route. A process route lists the machines corresponding to each part of the operation. Inspired by the extensive and widespread use of network flow algorithms, this research formulates the process route family formation for generalized grouping as a unit capacity minimum cost network flow model. The objective is to minimize dissimilarity (based on the machines required) among the process routes within a family. The proposed model optimally solves the process route family formation problem without pre-specifying the number of part families to be formed. The process route of family formation is the first stage in a hierarchical procedure. For the second stage (machine cell formation), two procedures, a quadratic assignment programming (QAP) formulation and a heuristic procedure, are proposed. The QAP simultaneously assigns process route families and machines to a pre-specified number of cells in such a way that total machine utilization is maximized. The heuristic procedure for machine cell formation is hierarchical in nature. Computational results for some test problems show that the QAP and the heuristic procedure yield the same results.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Submitted to a journal"
    },
    {
        "paper id": "2411.04695",
        "abstract url": "https://arxiv.org/abs/2411.04695",
        "title": "Is network fragmentation a useful complexity measure?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "It has been observed that the input space of deep neural network classifiers can exhibit `fragmentation', where the model function rapidly changes class as the input space is traversed. The severity of this fragmentation tends to follow the double descent curve, achieving a maximum at the interpolation regime. We study this phenomenon in the context of image classification and ask whether fragmentation could be predictive of generalization performance. Using a fragmentation-based complexity measure, we show this to be possible by achieving good performance on the PGDL (Predicting Generalization in Deep Learning) benchmark. In addition, we report on new observations related to fragmentation, namely (i) fragmentation is not limited to the input space but occurs in the hidden representations as well, (ii) fragmentation follows the trends in the validation error throughout training, and (iii) fragmentation is not a direct result of increased weight norms. Together, this indicates that fragmentation is a phenomenon worth investigating further when studying the generalization ability of deep neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04710",
        "abstract url": "https://arxiv.org/abs/2411.04710",
        "title": "Differential Privacy Overview and Fundamental Techniques",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This chapter is meant to be part of the book \"Differential Privacy in Artificial Intelligence: From Theory to Practice\" and provides an introduction to Differential Privacy. It starts by illustrating various attempts to protect data privacy, emphasizing where and why they failed, and providing the key desiderata of a robust privacy definition. It then defines the key actors, tasks, and scopes that make up the domain of privacy-preserving data analysis. Following that, it formalizes the definition of Differential Privacy and its inherent properties, including composition, post-processing immunity, and group privacy. The chapter also reviews the basic techniques and mechanisms commonly used to implement Differential Privacy in its pure and approximate forms.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": "Chapter 1 of book: \"Differential Privacy in Artificial Intelligence: From Theory to Practice\""
    },
    {
        "paper id": "2411.04744",
        "abstract url": "https://arxiv.org/abs/2411.04744",
        "title": "Respecting the limit:Bayesian optimization with a bound on the optimal value",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In many real-world optimization problems, we have prior information about what objective function values are achievable. In this paper, we study the scenario that we have either exact knowledge of the minimum value or a, possibly inexact, lower bound on its value. We propose bound-aware Bayesian optimization (BABO), a Bayesian optimization method that uses a new surrogate model and acquisition function to utilize such prior information. We present SlogGP, a new surrogate model that incorporates bound information and adapts the Expected Improvement (EI) acquisition function accordingly. Empirical results on a variety of benchmarks demonstrate the benefit of taking prior information about the optimal value into account, and that the proposed approach significantly outperforms existing techniques. Furthermore, we notice that even in the absence of prior information on the bound, the proposed SlogGP surrogate model still performs better than the standard GP model in most cases, which we explain by its larger expressiveness.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04761",
        "abstract url": "https://arxiv.org/abs/2411.04761",
        "title": "Mining the Minoria: Unknown, Under-represented, and Under-performing Minority Groups",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Due to a variety of reasons, such as privacy, data in the wild often misses the grouping information required for identifying minorities. On the other hand, it is known that machine learning models are only as good as the data they are trained on and, hence, may underperform for the under-represented minority groups. The missing grouping information presents a dilemma for responsible data scientists who find themselves in an unknown-unknown situation, where not only do they not have access to the grouping attributes but do not also know what groups to consider. This paper is an attempt to address this dilemma. Specifically, we propose a minority mining problem, where we find vectors in the attribute space that reveal potential groups that are under-represented and under-performing. Technically speaking, we propose a geometric transformation of data into a dual space and use notions such as the arrangement of hyperplanes to design an efficient algorithm for the problem in lower dimensions. Generalizing our solution to the higher dimensions is cursed by dimensionality. Therefore, we propose a solution based on smart exploration of the search space for such cases. We conduct comprehensive experiments using real-world and synthetic datasets alongside the theoretical analysis. Our experiment results demonstrate the effectiveness of our proposed solutions in mining the unknown, under-represented, and under-performing minorities.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "This paper is currently under review at VLDB 2025"
    },
    {
        "paper id": "2411.04775",
        "abstract url": "https://arxiv.org/abs/2411.04775",
        "title": "Learning dynamical systems from data: Gradient-based dictionary optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Koopman operator plays a crucial role in analyzing the global behavior of dynamical systems. Existing data-driven methods for approximating the Koopman operator or discovering the governing equations of the underlying system typically require a fixed set of basis functions, also called dictionary. The optimal choice of basis functions is highly problem-dependent and often requires domain knowledge. We present a novel gradient descent-based optimization framework for learning suitable and interpretable basis functions from data and show how it can be used in combination with EDMD, SINDy, and PDE-FIND. We illustrate the efficacy of the proposed approach with the aid of various benchmark problems such as the Ornstein-Uhlenbeck process, Chua's circuit, a nonlinear heat equation, as well as protein-folding data.",
        "subjects": [
            "math.DS",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04784",
        "abstract url": "https://arxiv.org/abs/2411.04784",
        "title": "Navigating Trade-offs: Policy Summarization for Multi-Objective Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Multi-objective reinforcement learning (MORL) is used to solve problems involving multiple objectives. An MORL agent must make decisions based on the diverse signals provided by distinct reward functions. Training an MORL agent yields a set of solutions (policies), each presenting distinct trade-offs among the objectives (expected returns). MORL enhances explainability by enabling fine-grained comparisons of policies in the solution set based on their trade-offs as opposed to having a single policy. However, the solution set is typically large and multi-dimensional, where each policy (e.g., a neural network) is represented by its objective values. We propose an approach for clustering the solution set generated by MORL. By considering both policy behavior and objective values, our clustering method can reveal the relationship between policy behaviors and regions in the objective space. This approach can enable decision makers (DMs) to identify overarching trends and insights in the solution set rather than examining each policy individually. We tested our method in four multi-objective environments and found it outperformed traditional k-medoids clustering. Additionally, we include a case study that demonstrates its real-world application.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04796",
        "abstract url": "https://arxiv.org/abs/2411.04796",
        "title": "MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation",
        "rating": "0.5",
        "keywords": [
            [
                "robot",
                "Navigation"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Visual odometry (VO) is essential for enabling accurate point-goal navigation of embodied agents in indoor environments where GPS and compass sensors are unreliable and inaccurate. However, traditional VO methods face challenges in wide-baseline scenarios, where fast robot motions and low frames per second (FPS) during inference hinder their performance, leading to drift and catastrophic failures in point-goal navigation. Recent deep-learned VO methods show robust performance but suffer from sample inefficiency during training; hence, they require huge datasets and compute resources. So, we propose a robust and sample-efficient VO pipeline based on motion priors available while an agent is navigating an environment. It consists of a training-free action-prior based geometric VO module that estimates a coarse relative pose which is further consumed as a motion prior by a deep-learned VO model, which finally produces a fine relative pose to be used by the navigation policy. This strategy helps our pipeline achieve up to 2x sample efficiency during training and demonstrates superior accuracy and robustness in point-goal navigation tasks compared to state-of-the-art VO method(s). Realistic indoor environments of the Gibson dataset is used in the AI-Habitat simulator to evaluate the proposed approach using navigation metrics (like success/SPL) and pose metrics (like RPE/ATE). We hope this method further opens a direction of work where motion priors from various sources can be utilized to improve VO estimates and achieve better results in embodied navigation tasks.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted in 50SFM Workshop of the 18th European Conference on Computer Vision (ECCV) 2024"
    },
    {
        "paper id": "2411.04812",
        "abstract url": "https://arxiv.org/abs/2411.04812",
        "title": "Soft Hoeffding Tree: A Transparent and Differentiable Model on Data Streams",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose soft Hoeffding trees (SoHoT) as a new differentiable and transparent model for possibly infinite and changing data streams. Stream mining algorithms such as Hoeffding trees grow based on the incoming data stream, but they currently lack the adaptability of end-to-end deep learning systems. End-to-end learning can be desirable if a feature representation is learned by a neural network and used in a tree, or if the outputs of trees are further processed in a deep learning model or workflow. Different from Hoeffding trees, soft trees can be integrated into such systems due to their differentiability, but are neither transparent nor explainable. Our novel model combines the extensibility and transparency of Hoeffding trees with the differentiability of soft trees. We introduce a new gating function to regulate the balance between univariate and multivariate splits in the tree. Experiments are performed on 20 data streams, comparing SoHoT to standard Hoeffding trees, Hoeffding trees with limited complexity, and soft trees applying a sparse activation function for sample routing. The results show that soft Hoeffding trees outperform Hoeffding trees in estimating class probabilities and, at the same time, maintain transparency compared to soft trees, with relatively small losses in terms of AUROC and cross-entropy. We also demonstrate how to trade off transparency against performance using a hyperparameter, obtaining univariate splits at one end of the spectrum and multivariate splits at the other.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04814",
        "abstract url": "https://arxiv.org/abs/2411.04814",
        "title": "A Simple Packing Algorithm for Optimized Mapping of Artificial Neural Networks onto Non-Volatile Memory Cross-Bar Arrays",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neuromorphic computing with crossbar arrays has emerged as a promising alternative to improve computing efficiency for machine learning. Previous work has focused on implementing crossbar arrays to perform basic mathematical operations. However, in this paper, we explore the impact of mapping the layers of an artificial neural network onto physical cross-bar arrays arranged in tiles across a chip. We have developed a simplified mapping algorithm to determine the number of physical tiles, with fixed optimal array dimensions, and to estimate the minimum area occupied by these tiles for a given design objective. This simplified algorithm is compared with conventional binary linear optimization, which solves the equivalent bin-packing problem. We have found that the optimum solution is not necessarily related to the minimum number of tiles; rather, it is shown to be an interaction between tile array capacity and the scaling properties of its peripheral circuits. Additionally, we have discovered that square arrays are not always the best choice for optimal mapping, and that performance optimization comes at the cost of total tile area",
        "subjects": [
            "cs.LG"
        ],
        "comment": "24 pages, 10 figures"
    },
    {
        "paper id": "2411.04832",
        "abstract url": "https://arxiv.org/abs/2411.04832",
        "title": "Plasticity Loss in Deep Reinforcement Learning: A Survey",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Akin to neuroplasticity in human brains, the plasticity of deep neural networks enables their quick adaption to new data. This makes plasticity particularly crucial for deep Reinforcement Learning (RL) agents: Once plasticity is lost, an agent's performance will inevitably plateau because it cannot improve its policy to account for changes in the data distribution, which are a necessary consequence of its learning process. Thus, developing well-performing and sample-efficient agents hinges on their ability to remain plastic during training. Furthermore, the loss of plasticity can be connected to many other issues plaguing deep RL, such as training instabilities, scaling failures, overestimation bias, and insufficient exploration. With this survey, we aim to provide an overview of the emerging research on plasticity loss for academics and practitioners of deep reinforcement learning. First, we propose a unified definition of plasticity loss based on recent works, relate it to definitions from the literature, and discuss metrics for measuring plasticity loss. Then, we categorize and discuss numerous possible causes of plasticity loss before reviewing currently employed mitigation strategies. Our taxonomy is the first systematic overview of the current state of the field. Lastly, we discuss prevalent issues within the literature, such as a necessity for broader evaluation, and provide recommendations for future research, like gaining a better understanding of an agent's neural activity and behavior.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04843",
        "abstract url": "https://arxiv.org/abs/2411.04843",
        "title": "Learning in Budgeted Auctions with Spacing Objectives",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In many repeated auction settings, participants care not only about how frequently they win but also how their winnings are distributed over time. This problem arises in various practical domains where avoiding congested demand is crucial, such as online retail sales and compute services, as well as in advertising campaigns that require sustained visibility over time. We introduce a simple model of this phenomenon, modeling it as a budgeted auction where the value of a win is a concave function of the time since the last win. This implies that for a given number of wins, even spacing over time is optimal. We also extend our model and results to the case when not all wins result in \"conversions\" (realization of actual gains), and the probability of conversion depends on a context. The goal is to maximize and evenly space conversions rather than just wins. We study the optimal policies for this setting in second-price auctions and offer learning algorithms for the bidders that achieve low regret against the optimal bidding policy in a Bayesian online setting. Our main result is a computationally efficient online learning algorithm that achieves $\\tilde O(\\sqrt T)$ regret. We achieve this by showing that an infinite-horizon Markov decision process (MDP) with the budget constraint in expectation is essentially equivalent to our problem, even when limiting that MDP to a very small number of states. The algorithm achieves low regret by learning a bidding policy that chooses bids as a function of the context and the system's state, which will be the time elapsed since the last win (or conversion). We show that state-independent strategies incur linear regret even without uncertainty of conversions. We complement this by showing that there are state-independent strategies that, while still having linear regret, achieve a $(1-\\frac 1 e)$ approximation to the optimal reward.",
        "subjects": [
            "cs.GT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04845",
        "abstract url": "https://arxiv.org/abs/2411.04845",
        "title": "Asymptotic regularity of a generalised stochastic Halpern scheme with applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We provide abstract, general and highly uniform rates of asymptotic regularity for a generalized stochastic Halpern-style iteration, which incorporates a second mapping in the style of a Krasnoselskii-Mann iteration. This iteration is general in two ways: First, it incorporates stochasticity in a completely abstract way rather than fixing a sampling method; secondly, it includes as special cases stochastic versions of various schemes from the optimization literature, including Halpern's iteration as well as a Krasnoselskii-Mann iteration with Tikhonov regularization terms in the sense of Bo\u0163, Csetnek and Meier. For these particular cases, we in particular obtain linear rates of asymptotic regularity, matching (or improving) the currently best known rates for these iterations in stochastic optimization, and quadratic rates of asymptotic regularity are obtained in the context of inner product spaces for the general iteration. We utilize these rates to give bounds on the oracle complexity of such iterations under suitable variance assumptions and batching strategies, again presented in an abstract style. Finally, we sketch how the schemes presented here can be instantiated in the context of reinforcement learning to yield novel methods for Q-learning.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.PR"
        ],
        "comment": "29 pages"
    },
    {
        "paper id": "2411.04852",
        "abstract url": "https://arxiv.org/abs/2411.04852",
        "title": "Conformalized Credal Regions for Classification with Ambiguous Ground Truth",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "An open question in \\emph{Imprecise Probabilistic Machine Learning} is how to empirically derive a credal region (i.e., a closed and convex family of probabilities on the output space) from the available data, without any prior knowledge or assumption. In classification problems, credal regions are a tool that is able to provide provable guarantees under realistic assumptions by characterizing the uncertainty about the distribution of the labels. Building on previous work, we show that credal regions can be directly constructed using conformal methods. This allows us to provide a novel extension of classical conformal prediction to problems with ambiguous ground truth, that is, when the exact labels for given inputs are not exactly known. The resulting construction enjoys desirable practical and theoretical properties: (i) conformal coverage guarantees, (ii) smaller prediction sets (compared to classical conformal prediction regions) and (iii) disentanglement of uncertainty sources (epistemic, aleatoric). We empirically verify our findings on both synthetic and real datasets.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04865",
        "abstract url": "https://arxiv.org/abs/2411.04865",
        "title": "ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset",
        "rating": "0.5",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Facade semantic segmentation is a long-standing challenge in photogrammetry and computer vision. Although the last decades have witnessed the influx of facade segmentation methods, there is a lack of comprehensive facade classes and data covering the architectural variability. In ZAHA, we introduce Level of Facade Generalization (LoFG), novel hierarchical facade classes designed based on international urban modeling standards, ensuring compatibility with real-world challenging classes and uniform methods' comparison. Realizing the LoFG, we present to date the largest semantic 3D facade segmentation dataset, providing 601 million annotated points at five and 15 classes of LoFG2 and LoFG3, respectively. Moreover, we analyze the performance of baseline semantic segmentation methods on our introduced LoFG classes and data, complementing it with a discussion on the unresolved challenges for facade segmentation. We firmly believe that ZAHA shall facilitate further development of 3D facade semantic segmentation methods, enabling robust segmentation indispensable in creating urban digital twins.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted to WACV 2025 (IEEE/CVF Winter Conference on Applications of Computer Vision (WACV))"
    },
    {
        "paper id": "2411.04867",
        "abstract url": "https://arxiv.org/abs/2411.04867",
        "title": "Think Smart, Act SMARL! Analyzing Probabilistic Logic Driven Safety in Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "An important challenge for enabling the deployment of reinforcement learning (RL) algorithms in the real world is safety. This has resulted in the recent research field of Safe RL, which aims to learn optimal policies that are safe. One successful approach in that direction is probabilistic logic shields (PLS), a model-based Safe RL technique that uses formal specifications based on probabilistic logic programming, constraining an agent's policy to comply with those specifications in a probabilistic sense. However, safety is inherently a multi-agent concept, since real-world environments often involve multiple agents interacting simultaneously, leading to a complex system which is hard to control. Moreover, safe multi-agent RL (Safe MARL) is still underexplored. In order to address this gap, in this paper we ($i$) introduce Shielded MARL (SMARL) by extending PLS to MARL -- in particular, we introduce Probabilistic Logic Temporal Difference Learning (PLTD) to enable shielded independent Q-learning (SIQL), and introduce shielded independent PPO (SIPPO) using probabilistic logic policy gradients; ($ii$) show its positive effect and use as an equilibrium selection mechanism in various game-theoretic environments including two-player simultaneous games, extensive-form games, stochastic games, and some grid-world extensions in terms of safety, cooperation, and alignment with normative behaviors; and ($iii$) look into the asymmetric case where only one agent is shielded, and show that the shielded agent has a significant influence on the unshielded one, providing further evidence of SMARL's ability to enhance safety and cooperation in diverse multi-agent environments.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "19 pages, 14 figures"
    },
    {
        "paper id": "2411.04872",
        "abstract url": "https://arxiv.org/abs/2411.04872",
        "title": "FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce FrontierMath, a benchmark of hundreds of original, exceptionally challenging mathematics problems crafted and vetted by expert mathematicians. The questions cover most major branches of modern mathematics -- from computationally intensive problems in number theory and real analysis to abstract questions in algebraic geometry and category theory. Solving a typical problem requires multiple hours of effort from a researcher in the relevant branch of mathematics, and for the upper end questions, multiple days. FrontierMath uses new, unpublished problems and automated verification to reliably evaluate models while minimizing risk of data contamination. Current state-of-the-art AI models solve under 2% of problems, revealing a vast gap between AI capabilities and the prowess of the mathematical community. As AI systems advance toward expert-level mathematical abilities, FrontierMath offers a rigorous testbed that quantifies their progress.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04890",
        "abstract url": "https://arxiv.org/abs/2411.04890",
        "title": "GUI Agents with Foundation Models: A Comprehensive Survey",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advances in foundation models, particularly Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs), facilitate intelligent agents being capable of performing complex tasks. By leveraging the ability of (M)LLMs to process and interpret Graphical User Interfaces (GUIs), these agents can autonomously execute user instructions by simulating human-like interactions such as clicking and typing. This survey consolidates recent research on (M)LLM-based GUI agents, highlighting key innovations in data, frameworks, and applications. We begin by discussing representative datasets and benchmarks. Next, we summarize a unified framework that captures the essential components used in prior research, accompanied by a taxonomy. Additionally, we explore commercial applications of (M)LLM-based GUI agents. Drawing from existing work, we identify several key challenges and propose future research directions. We hope this paper will inspire further developments in the field of (M)LLM-based GUI agents.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04915",
        "abstract url": "https://arxiv.org/abs/2411.04915",
        "title": "Evaluating Robustness of Reinforcement Learning Algorithms for Autonomous Shipping",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recently, there has been growing interest in autonomous shipping due to its potential to improve maritime efficiency and safety. The use of advanced technologies, such as artificial intelligence, can address the current navigational and operational challenges in autonomous shipping. In particular, inland waterway transport (IWT) presents a unique set of challenges, such as crowded waterways and variable environmental conditions. In such dynamic settings, the reliability and robustness of autonomous shipping solutions are critical factors for ensuring safe operations. This paper examines the robustness of benchmark deep reinforcement learning (RL) algorithms, implemented for IWT within an autonomous shipping simulator, and their ability to generate effective motion planning policies. We demonstrate that a model-free approach can achieve an adequate policy in the simulator, successfully navigating port environments never encountered during training. We focus particularly on Soft-Actor Critic (SAC), which we show to be inherently more robust to environmental disturbances compared to MuZero, a state-of-the-art model-based RL algorithm. In this paper, we take a significant step towards developing robust, applied RL frameworks that can be generalized to various vessel types and navigate complex port- and inland environments and scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "5 pages, 4 figures. Will be presented at IEEE RAAI 2024"
    },
    {
        "paper id": "2411.04933",
        "abstract url": "https://arxiv.org/abs/2411.04933",
        "title": "SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering",
        "rating": "0.5",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "Music"
            ],
            [
                "cs.CV"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Audio-Visual Question Answering (AVQA) is a challenging task that involves answering questions based on both auditory and visual information in videos. A significant challenge is interpreting complex multi-modal scenes, which include both visual objects and sound sources, and connecting them to the given question. In this paper, we introduce the Source-aware Semantic Representation Network (SaSR-Net), a novel model designed for AVQA. SaSR-Net utilizes source-wise learnable tokens to efficiently capture and align audio-visual elements with the corresponding question. It streamlines the fusion of audio and visual information using spatial and temporal attention mechanisms to identify answers in multi-modal scenes. Extensive experiments on the Music-AVQA and AVQA-Yang datasets show that SaSR-Net outperforms state-of-the-art AVQA methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "EMNLP 2024"
    },
    {
        "paper id": "2411.04939",
        "abstract url": "https://arxiv.org/abs/2411.04939",
        "title": "Pareto Set Identification With Posterior Sampling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The problem of identifying the best answer among a collection of items having real-valued distribution is well-understood. Despite its practical relevance for many applications, fewer works have studied its extension when multiple and potentially conflicting metrics are available to assess an item's quality. Pareto set identification (PSI) aims to identify the set of answers whose means are not uniformly worse than another. This paper studies PSI in the transductive linear setting with potentially correlated objectives. Building on posterior sampling in both the stopping and the sampling rules, we propose the PSIPS algorithm that deals simultaneously with structure and correlation without paying the computational cost of existing oracle-based algorithms. Both from a frequentist and Bayesian perspective, PSIPS is asymptotically optimal. We demonstrate its good empirical performance in real-world and synthetic instances.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04967",
        "abstract url": "https://arxiv.org/abs/2411.04967",
        "title": "AsCAN: Asymmetric Convolution-Attention Networks for Efficient Recognition and Generation",
        "rating": "0.5",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Neural network architecture design requires making many crucial decisions. The common desiderata is that similar decisions, with little modifications, can be reused in a variety of tasks and applications. To satisfy that, architectures must provide promising latency and performance trade-offs, support a variety of tasks, scale efficiently with respect to the amounts of data and compute, leverage available data from other tasks, and efficiently support various hardware. To this end, we introduce AsCAN -- a hybrid architecture, combining both convolutional and transformer blocks. We revisit the key design principles of hybrid architectures and propose a simple and effective \\emph{asymmetric} architecture, where the distribution of convolutional and transformer blocks is \\emph{asymmetric}, containing more convolutional blocks in the earlier stages, followed by more transformer blocks in later stages. AsCAN supports a variety of tasks: recognition, segmentation, class-conditional image generation, and features a superior trade-off between performance and latency. We then scale the same architecture to solve a large-scale text-to-image task and show state-of-the-art performance compared to the most recent public and commercial models. Notably, even without any computation optimization for transformer blocks, our models still yield faster inference speed than existing works featuring efficient attention mechanisms, highlighting the advantages and the value of our approach.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "NeurIPS 2024. Project Page: https://snap-research.github.io/snap_image/"
    },
    {
        "paper id": "2411.04976",
        "abstract url": "https://arxiv.org/abs/2411.04976",
        "title": "Noisy Zero-Shot Coordination: Breaking The Common Knowledge Assumption In Zero-Shot Coordination Games",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Zero-shot coordination (ZSC) is a popular setting for studying the ability of reinforcement learning (RL) agents to coordinate with novel partners. Prior ZSC formulations assume the $\\textit{problem setting}$ is common knowledge: each agent knows the underlying Dec-POMDP, knows others have this knowledge, and so on ad infinitum. However, this assumption rarely holds in complex real-world settings, which are often difficult to fully and correctly specify. Hence, in settings where this common knowledge assumption is invalid, agents trained using ZSC methods may not be able to coordinate well. To address this limitation, we formulate the $\\textit{noisy zero-shot coordination}$ (NZSC) problem. In NZSC, agents observe different noisy versions of the ground truth Dec-POMDP, which are assumed to be distributed according to a fixed noise model. Only the distribution of ground truth Dec-POMDPs and the noise model are common knowledge. We show that a NZSC problem can be reduced to a ZSC problem by designing a meta-Dec-POMDP with an augmented state space consisting of all the ground-truth Dec-POMDPs. For solving NZSC problems, we propose a simple and flexible meta-learning method called NZSC training, in which the agents are trained across a distribution of coordination problems - which they only get to observe noisy versions of. We show that with NZSC training, RL agents can be trained to coordinate well with novel partners even when the (exact) problem setting of the coordination is not common knowledge.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04981",
        "abstract url": "https://arxiv.org/abs/2411.04981",
        "title": "Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Security experts reverse engineer (decompile) binary code to identify critical security vulnerabilities. The limited access to source code in vital systems - such as firmware, drivers, and proprietary software used in Critical Infrastructures (CI) - makes this analysis even more crucial on the binary level. Even with available source code, a semantic gap persists after compilation between the source and the binary code executed by the processor. This gap may hinder the detection of vulnerabilities in source code. That being said, current research on Large Language Models (LLMs) overlooks the significance of decompiled binaries in this area by focusing solely on source code. In this work, we are the first to empirically uncover the substantial semantic limitations of state-of-the-art LLMs when it comes to analyzing vulnerabilities in decompiled binaries, largely due to the absence of relevant datasets. To bridge the gap, we introduce DeBinVul, a novel decompiled binary code vulnerability dataset. Our dataset is multi-architecture and multi-optimization, focusing on C/C++ due to their wide usage in CI and association with numerous vulnerabilities. Specifically, we curate 150,872 samples of vulnerable and non-vulnerable decompiled binary code for the task of (i) identifying; (ii) classifying; (iii) describing vulnerabilities; and (iv) recovering function names in the domain of decompiled binaries. Subsequently, we fine-tune state-of-the-art LLMs using DeBinVul and report on a performance increase of 19%, 24%, and 21% in the capabilities of CodeLlama, Llama3, and CodeGen2 respectively, in detecting binary code vulnerabilities. Additionally, using DeBinVul, we report a high performance of 80-90% on the vulnerability classification task. Furthermore, we report improved performance in function name recovery and vulnerability description tasks.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04991",
        "abstract url": "https://arxiv.org/abs/2411.04991",
        "title": "Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The Bradley-Terry (BT) model is a common and successful practice in reward modeling for Large Language Model (LLM) alignment. However, it remains unclear why this model -- originally developed for multi-player stochastic game matching -- can be adopted to convert pairwise response comparisons to reward values and make predictions. Especially given the fact that only a limited number of prompt-response pairs are sparsely compared with others. In this paper, we first revisit the foundations of using BT models in reward modeling, and establish the convergence rate of BT reward models based on deep neural networks using embeddings, providing a theoretical foundation for their use. Despite theoretically sound, we argue that the BT model is not a necessary choice from the perspective of downstream optimization. This is because a reward model only needs to preserve the correct ranking predictions through a monotonic transformation of the true reward. We highlight the critical concept of order consistency in reward modeling and demonstrate that the BT model possesses this property. Consequently, we propose a simple and straightforward upper-bound algorithm, compatible with off-the-shelf binary classifiers, as an alternative order-consistent reward modeling objective. To offer practical insights, we empirically evaluate the performance of these different reward modeling approaches across more than 12,000 experimental setups, using $6$ base LLMs, $2$ datasets, and diverse annotation designs that vary in quantity, quality, and pairing choices in preference annotations.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04994",
        "abstract url": "https://arxiv.org/abs/2411.04994",
        "title": "Public Procurement for Responsible AI? Understanding U.S. Cities' Practices, Challenges, and Needs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Most AI tools adopted by governments are not developed internally, but instead are acquired from third-party vendors in a process called public procurement. While scholars and regulatory proposals have recently turned towards procurement as a site of intervention to encourage responsible AI governance practices, little is known about the practices and needs of city employees in charge of AI procurement. In this paper, we present findings from semi-structured interviews with 18 city employees across 7 US cities. We find that AI acquired by cities often does not go through a conventional public procurement process, posing challenges to oversight and governance. We identify five key types of challenges to leveraging procurement for responsible AI that city employees face when interacting with colleagues, AI vendors, and members of the public. We conclude by discussing recommendations and implications for governments, researchers, and policymakers.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "Preprint, under revision"
    },
    {
        "paper id": "2411.04998",
        "abstract url": "https://arxiv.org/abs/2411.04998",
        "title": "HourVideo: 1-Hour Video-Language Understanding",
        "rating": "0.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We present HourVideo, a benchmark dataset for hour-long video-language understanding. Our dataset consists of a novel task suite comprising summarization, perception (recall, tracking), visual reasoning (spatial, temporal, predictive, causal, counterfactual), and navigation (room-to-room, object retrieval) tasks. HourVideo includes 500 manually curated egocentric videos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and features 12,976 high-quality, five-way multiple-choice questions. Benchmarking results reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve marginal improvements over random chance. In stark contrast, human experts significantly outperform the state-of-the-art long-context multimodal model, Gemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal capabilities. Our benchmark, evaluation toolkit, prompts, and documentation are available at https://hourvideo.stanford.edu",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "NeurIPS 2024 Datasets and Benchmarks Track; 28 pages"
    },
    {
        "paper id": "2411.05052",
        "abstract url": "https://arxiv.org/abs/2411.05052",
        "title": "The Fibonacci Network: A Simple Alternative for Positional Encoding",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Coordinate-based Multi-Layer Perceptrons (MLPs) are known to have difficulty reconstructing high frequencies of the training data. A common solution to this problem is Positional Encoding (PE), which has become quite popular. However, PE has drawbacks. It has high-frequency artifacts and adds another hyper-hyperparameter, just like batch normalization and dropout do. We believe that under certain circumstances PE is not necessary, and a smarter construction of the network architecture together with a smart training method is sufficient to achieve similar results. In this paper, we show that very simple MLPs can quite easily output a frequency when given input of the half-frequency and quarter-frequency. Using this, we design a network architecture in blocks, where the input to each block is the output of the two previous blocks along with the original input. We call this a {\\it Fibonacci Network}. By training each block on the corresponding frequencies of the signal, we show that Fibonacci Networks can reconstruct arbitrarily high frequencies.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05097",
        "abstract url": "https://arxiv.org/abs/2411.05097",
        "title": "On the cohesion and separability of average-link for hierarchical agglomerative clustering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Average-link is widely recognized as one of the most popular and effective methods for building hierarchical agglomerative clustering. The available theoretical analyses show that this method has a much better approximation than other popular heuristics, as single-linkage and complete-linkage, regarding variants of Dasgupta's cost function [STOC 2016]. However, these analyses do not separate average-link from a random hierarchy and they are not appealing for metric spaces since every hierarchical clustering has a 1/2 approximation with regard to the variant of Dasgupta's function that is employed for dissimilarity measures [Moseley and Yang 2020]. In this paper, we present a comprehensive study of the performance of average-link in metric spaces, regarding several natural criteria that capture separability and cohesion and are more interpretable than Dasgupta's cost function and its variants. We also present experimental results with real datasets that, together with our theoretical analyses, suggest that average-link is a better choice than other related methods when both cohesion and separability are important goals.",
        "subjects": [
            "cs.LG",
            "cs.DS"
        ],
        "comment": "Accepted to Neurips 2024"
    },
    {
        "paper id": "2411.05197",
        "abstract url": "https://arxiv.org/abs/2411.05197",
        "title": "Hardware and Software Platform Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "It is now a common business practice to buy access to large language model (LLM) inference rather than self-host, because of significant upfront hardware infrastructure and energy costs. However, as a buyer, there is no mechanism to verify the authenticity of the advertised service including the serving hardware platform, e.g. that it is actually being served using an NVIDIA H100. Furthermore, there are reports suggesting that model providers may deliver models that differ slightly from the advertised ones, often to make them run on less expensive hardware. That way, a client pays premium for a capable model access on more expensive hardware, yet ends up being served by a (potentially less capable) cheaper model on cheaper hardware. In this paper we introduce \\textit{\\textbf{hardware and software platform inference (HSPI)}} -- a method for identifying the underlying \\GPU{} architecture and software stack of a (black-box) machine learning model solely based on its input-output behavior. Our method leverages the inherent differences of various \\GPU{} architectures and compilers to distinguish between different \\GPU{} types and software stacks. By analyzing the numerical patterns in the model's outputs, we propose a classification framework capable of accurately identifying the \\GPU{} used for model inference as well as the underlying software configuration. Our findings demonstrate the feasibility of inferring \\GPU{} type from black-box models. We evaluate HSPI against models served on different real hardware and find that in a white-box setting we can distinguish between different \\GPU{}s with between $83.9\\%$ and $100\\%$ accuracy. Even in a black-box setting we are able to achieve results that are up to three times higher than random guess accuracy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05198",
        "abstract url": "https://arxiv.org/abs/2411.05198",
        "title": "Private Algorithms for Stochastic Saddle Points and Variational Inequalities: Beyond Euclidean Geometry",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we conduct a systematic study of stochastic saddle point problems (SSP) and stochastic variational inequalities (SVI) under the constraint of $(\u03b5,\u03b4)$-differential privacy (DP) in both Euclidean and non-Euclidean setups. We first consider Lipschitz convex-concave SSPs in the $\\ell_p/\\ell_q$ setup, $p,q\\in[1,2]$. Here, we obtain a bound of $\\tilde{O}\\big(\\frac{1}{\\sqrt{n}} + \\frac{\\sqrt{d}}{n\u03b5}\\big)$ on the strong SP-gap, where $n$ is the number of samples and $d$ is the dimension. This rate is nearly optimal for any $p,q\\in[1,2]$. Without additional assumptions, such as smoothness or linearity requirements, prior work under DP has only obtained this rate when $p=q=2$ (i.e., only in the Euclidean setup). Further, existing algorithms have each only been shown to work for specific settings of $p$ and $q$ and under certain assumptions on the loss and the feasible set, whereas we provide a general algorithm for DP SSPs whenever $p,q\\in[1,2]$. Our result is obtained via a novel analysis of the recursive regularization algorithm. In particular, we develop new tools for analyzing generalization, which may be of independent interest. Next, we turn our attention towards SVIs with a monotone, bounded and Lipschitz operator and consider $\\ell_p$-setups, $p\\in[1,2]$. Here, we provide the first analysis which obtains a bound on the strong VI-gap of $\\tilde{O}\\big(\\frac{1}{\\sqrt{n}} + \\frac{\\sqrt{d}}{n\u03b5}\\big)$. For $p-1=\u03a9(1)$, this rate is near optimal due to existing lower bounds. To obtain this result, we develop a modified version of recursive regularization. Our analysis builds on the techniques we develop for SSPs as well as employing additional novel components which handle difficulties arising from adapting the recursive regularization framework to SVIs.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "math.OC",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05210",
        "abstract url": "https://arxiv.org/abs/2411.05210",
        "title": "Algorithmic Autonomy in Data-Driven AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "In societies increasingly entangled with algorithms, our choices are constantly influenced and shaped by automated systems. This convergence highlights significant concerns for individual autonomy in the age of data-driven AI. It leads to pressing issues such as data-driven segregation, gaps in accountability for algorithmic decisions, and the infringement on essential human rights and values. Through this article, we introduce and explore the concept of algorithmic autonomy, examining what it means for individuals to have autonomy in the face of the pervasive impact of algorithms on our societies. We begin by outlining the data-driven characteristics of AI and its role in diminishing personal autonomy. We then explore the notion of algorithmic autonomy, drawing on existing research. Finally, we address important considerations, highlighting current challenges and directions for future research.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05228",
        "abstract url": "https://arxiv.org/abs/2411.05228",
        "title": "Solving Hidden Monotone Variational Inequalities with Surrogate Losses",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep learning has proven to be effective in a wide variety of loss minimization problems. However, many applications of interest, like minimizing projected Bellman error and min-max optimization, cannot be modelled as minimizing a scalar loss function but instead correspond to solving a variational inequality (VI) problem. This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case. In this work, we propose a principled surrogate-based approach compatible with deep learning to solve VIs. We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present, interpolation, and sufficient optimization of the surrogates), it guarantees convergence, (2) it provides a unifying perspective of existing methods, and (3) is amenable to existing deep learning optimizers like ADAM. Experimentally, we demonstrate our surrogate-based approach is effective in min-max optimization and minimizing projected Bellman error. Furthermore, in the deep reinforcement learning case, we propose a novel variant of TD(0) which is more compute and sample efficient.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05239",
        "abstract url": "https://arxiv.org/abs/2411.05239",
        "title": "ZipNN: Lossless Compression for AI Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the growth of model sizes and the scale of their deployment, their sheer size burdens the infrastructure requiring more network and more storage to accommodate these. While there is a vast model compression literature deleting parts of the model weights for faster inference, we investigate a more traditional type of compression - one that represents the model in a compact form and is coupled with a decompression algorithm that returns it to its original form and size - namely lossless compression. We present ZipNN a lossless compression tailored to neural networks. Somewhat surprisingly, we show that specific lossless compression can gain significant network and storage reduction on popular models, often saving 33% and at times reducing over 50% of the model size. We investigate the source of model compressibility and introduce specialized compression variants tailored for models that further increase the effectiveness of compression. On popular models (e.g. Llama 3) ZipNN shows space savings that are over 17% better than vanilla compression while also improving compression and decompression speeds by 62%. We estimate that these methods could save over an ExaByte per month of network traffic downloaded from a large model hub like Hugging Face.",
        "subjects": [
            "cs.LG",
            "cs.IT"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2404.15198"
    },
    {
        "paper id": "2411.05263",
        "abstract url": "https://arxiv.org/abs/2411.05263",
        "title": "Minimal Conditions for Beneficial Neighbourhood Search and Local Descent",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper investigates what properties a neighbourhood requires to support beneficial local search. We show that neighbourhood locality, and a reduction in cost probability towards the optimum, support a proof that search among neighbours is more likely to find an improving solution in a single search step than blind search. This is the first paper to introduce such a proof. The concepts underlying these properties are illustrated on a satisfiability problem class, and on travelling salesman problems. Secondly, for a given cost target t, we investigate a combination of blind search and local descent termed local blind descent, and present various conditions under which the expected number of steps to reach a cost better than t using local blind descent, is proven to be smaller than with blind search. Experiments indicate that local blind descent, given target cost t, should switch to local descent at a starting cost that reduces as t approaches the optimum.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05273",
        "abstract url": "https://arxiv.org/abs/2411.05273",
        "title": "Real-World Offline Reinforcement Learning from Vision Language Model Feedback",
        "rating": "0.5",
        "keywords": [
            [
                "Vision Language",
                "VLM"
            ],
            [
                "robot"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Offline reinforcement learning can enable policy learning from pre-collected, sub-optimal datasets without online interactions. This makes it ideal for real-world robots and safety-critical scenarios, where collecting online data or expert demonstrations is slow, costly, and risky. However, most existing offline RL works assume the dataset is already labeled with the task rewards, a process that often requires significant human effort, especially when ground-truth states are hard to ascertain (e.g., in the real-world). In this paper, we build on prior work, specifically RL-VLM-F, and propose a novel system that automatically generates reward labels for offline datasets using preference feedback from a vision-language model and a text description of the task. Our method then learns a policy using offline RL with the reward-labeled dataset. We demonstrate the system's applicability to a complex real-world robot-assisted dressing task, where we first learn a reward function using a vision-language model on a sub-optimal offline dataset, and then we use the learned reward to employ Implicit Q learning to develop an effective dressing policy. Our method also performs well in simulation tasks involving the manipulation of rigid and deformable objects, and significantly outperform baselines such as behavior cloning and inverse RL. In summary, we propose a new system that enables automatic reward labeling and policy learning from unlabeled, sub-optimal offline datasets.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "7 pages. Accepted at the LangRob Workshop 2024 @ CoRL, 2024"
    },
    {
        "paper id": "2411.05276",
        "abstract url": "https://arxiv.org/abs/2411.05276",
        "title": "GPT Semantic Cache: Reducing LLM Costs and Latency via Semantic Embedding Caching",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs), such as GPT (Radford et al., 2019), have significantly advanced artificial intelligence by enabling sophisticated natural language understanding and generation. However, the high computational and financial costs associated with frequent API calls to these models present a substantial bottleneck, especially for applications like customer service chatbots that handle repetitive queries. In this paper, we introduce GPT Semantic Cache, a method that leverages semantic caching of query embeddings in in-memory storage (Redis). By storing embeddings of user queries, our approach efficiently identifies semantically similar questions, allowing for the retrieval of pre-generated responses without redundant API calls to the LLM. This technique reduces operational costs and improves response times, enhancing the efficiency of LLM-powered applications.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05282",
        "abstract url": "https://arxiv.org/abs/2411.05282",
        "title": "MicroScopiQ: Accelerating Foundational Models through Outlier-Aware Microscaling Quantization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Quantization of foundational models (FMs) is significantly more challenging than traditional DNNs due to the emergence of large magnitude features called outliers. Existing outlier-aware algorithm/architecture co-design techniques either use mixed-precision, retaining outliers at high precision but compromise hardware efficiency, or quantize inliers and outliers at the same precision, improving hardware efficiency at the cost of accuracy. To address this mutual exclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique that leverages pruning to complement outlier-aware quantization. MicroScopiQ retains outliers at higher precision while pruning a certain fraction of least important weights to distribute the additional outlier bits; ensuring high accuracy, aligned memory and hardware efficiency. We design a high-throughput, low overhead accelerator architecture composed of simple multi-precision INT processing elements and a novel network-on-chip called ReCoN that efficiently abstracts the complexity of supporting high-precision outliers. Additionally, unlike existing alternatives, MicroScopiQ does not assume any locality of outlier weights, enabling applicability to a broad range of FMs. Extensive experiments across various quantization settings show that MicroScopiQ achieves SoTA quantization performance while simultaneously improving inference performance by 3x and reducing energy by 2x over existing alternatives.",
        "subjects": [
            "cs.AR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2411.05285",
        "abstract url": "https://arxiv.org/abs/2411.05285",
        "title": "A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The ever-improving quality of LLMs has fueled the growth of a diverse range of downstream tasks, leading to an increased demand for AI automation and a burgeoning interest in developing foundation model (FM)-based autonomous agents. As AI agent systems tackle more complex tasks and evolve, they involve a wider range of stakeholders, including agent users, agentic system developers and deployers, and AI model developers. These systems also integrate multiple components such as AI agent workflows, RAG pipelines, prompt management, agent capabilities, and observability features. In this case, obtaining reliable outputs and answers from these agents remains challenging, necessitating a dependable execution process and end-to-end observability solutions. To build reliable AI agents and LLM applications, it is essential to shift towards designing AgentOps platforms that ensure observability and traceability across the entire development-to-production life-cycle. To this end, we conducted a rapid review and identified relevant AgentOps tools from the agentic ecosystem. Based on this review, we provide an overview of the essential features of AgentOps and propose a comprehensive overview of observability data/traceable artifacts across the agent production life-cycle. Our findings provide a systematic overview of the current AgentOps landscape, emphasizing the critical role of observability/traceability in enhancing the reliability of autonomous agent systems.",
        "subjects": [
            "cs.AI",
            "cs.SE"
        ],
        "comment": "19 pages, 9 figures"
    },
    {
        "paper id": "2411.05315",
        "abstract url": "https://arxiv.org/abs/2411.05315",
        "title": "Differentiable Calibration of Inexact Stochastic Simulation Models via Kernel Score Minimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Stochastic simulation models are generative models that mimic complex systems to help with decision-making. The reliability of these models heavily depends on well-calibrated input model parameters. However, in many practical scenarios, only output-level data are available to learn the input model parameters, which is challenging due to the often intractable likelihood of the stochastic simulation model. Moreover, stochastic simulation models are frequently inexact, with discrepancies between the model and the target system. No existing methods can effectively learn and quantify the uncertainties of input parameters using only output-level data. In this paper, we propose to learn differentiable input parameters of stochastic simulation models using output-level data via kernel score minimization with stochastic gradient descent. We quantify the uncertainties of the learned input parameters using a frequentist confidence set procedure based on a new asymptotic normality result that accounts for model inexactness. The proposed method is evaluated on exact and inexact G/G/1 queueing models.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "stat.CO"
        ],
        "comment": "31 pages, 12 tables, 4 figures"
    },
    {
        "paper id": "2411.05318",
        "abstract url": "https://arxiv.org/abs/2411.05318",
        "title": "Fairness in Monotone $k$-submodular Maximization: Algorithms and Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Submodular optimization has become increasingly prominent in machine learning and fairness has drawn much attention. In this paper, we propose to study the fair $k$-submodular maximization problem and develop a $\\frac{1}{3}$-approximation greedy algorithm with a running time of $\\mathcal{O}(knB)$. To the best of our knowledge, our work is the first to incorporate fairness in the context of $k$-submodular maximization, and our theoretical guarantee matches the best-known $k$-submodular maximization results without fairness constraints. In addition, we have developed a faster threshold-based algorithm that achieves a $(\\frac{1}{3} - \u03b5)$ approximation with $\\mathcal{O}(\\frac{kn}\u03b5 \\log \\frac{B}\u03b5)$ evaluations of the function $f$. Furthermore, for both algorithms, we provide approximation guarantees when the $k$-submodular function is not accessible but only can be approximately accessed. We have extensively validated our theoretical findings through empirical research and examined the practical implications of fairness. Specifically, we have addressed the question: ``What is the price of fairness?\" through case studies on influence maximization with $k$ topics and sensor placement with $k$ types. The experimental results show that the fairness constraints do not significantly undermine the quality of solutions.",
        "subjects": [
            "cs.LG",
            "cs.DS"
        ],
        "comment": "17 pages. To appear in IEEE BigData 2024"
    },
    {
        "paper id": "2411.05862",
        "abstract url": "https://arxiv.org/abs/2411.05862",
        "title": "From Electrode to Global Brain: Integrating Multi- and Cross-Scale Brain Connections and Interactions Under Cross-Subject and Within-Subject Scenarios",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The individual variabilities of electroencephalogram signals pose great challenges to cross-subject motor imagery (MI) classification, especially for the data-scarce single-source to single-target (STS) scenario. The multi-scale spatial data distribution differences can not be fully eliminated in MI experiments for the topological structure and connection are the inherent properties of the human brain. Overall, no literature investigates the multi-scale spatial data distribution problem in STS cross-subject MI classification task, neither intra-subject nor inter-subject scenarios. In this paper, a novel multi-scale spatial domain adaptation network (MSSDAN) consists of both multi-scale spatial feature extractor (MSSFE) and deep domain adaptation method called multi-scale spatial domain adaptation (MSSDA) is proposed and verified, our goal is to integrate the principles of multi-scale brain topological structures in order to solve the multi-scale spatial data distribution difference problem.",
        "subjects": [
            "q-bio.NC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05864",
        "abstract url": "https://arxiv.org/abs/2411.05864",
        "title": "Boosting the Efficiency of Metaheuristics Through Opposition-Based Learning in Optimum Locating of Control Systems in Tall Buildings",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Opposition-based learning (OBL) is an effective approach to improve the performance of metaheuristic optimization algorithms, which are commonly used for solving complex engineering problems. This chapter provides a comprehensive review of the literature on the use of opposition strategies in metaheuristic optimization algorithms, discussing the benefits and limitations of this approach. An overview of the opposition strategy concept, its various implementations, and its impact on the performance of metaheuristic algorithms are presented. Furthermore, case studies on the application of opposition strategies in engineering problems are provided, including the optimum locating of control systems in tall building. A shear frame with Magnetorheological (MR) fluid damper is considered as a case study. The results demonstrate that the incorporation of opposition strategies in metaheuristic algorithms significantly enhances the quality and speed of the optimization process. This chapter aims to provide a clear understanding of the opposition strategy in metaheuristic optimization algorithms and its engineering applications, with the ultimate goal of facilitating its adoption in real-world engineering problems.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "eess.SY"
        ],
        "comment": "17 pages, 4 figures, book chapter, Springer"
    },
    {
        "paper id": "2411.05865",
        "abstract url": "https://arxiv.org/abs/2411.05865",
        "title": "Bilinear Fuzzy Genetic Algorithm and Its Application on the Optimum Design of Steel Structures with Semi-rigid Connections",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "An improved bilinear fuzzy genetic algorithm (BFGA) is introduced in this chapter for the design optimization of steel structures with semi-rigid connections. Semi-rigid connections provide a compromise between the stiffness of fully rigid connections and the flexibility of fully pinned connections. However, designing such structures is challenging due to the nonlinear behavior of semi-rigid connections. The BFGA is a robust optimization method that combines the strengths of fuzzy logic and genetic algorithm to handle the complexity and uncertainties of structural design problems. The BFGA, compared to standard GA, demonstrated to generate high-quality solutions in a reasonable time. The application of the BFGA is demonstrated through the optimization of steel structures with semirigid connections, considering the weight and performance criteria. The results show that the proposed BFGA is capable of finding optimal designs that satisfy all the design requirements and constraints. The proposed approach provides a promising solution for the optimization of complex structures with nonlinear behavior.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": "19 pages, 12 figures, book chapter, Springer"
    },
    {
        "paper id": "2411.05868",
        "abstract url": "https://arxiv.org/abs/2411.05868",
        "title": "Provably Faster Algorithms for Bilevel Optimization via Without-Replacement Sampling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bilevel Optimization has experienced significant advancements recently with the introduction of new efficient algorithms. Mirroring the success in single-level optimization, stochastic gradient-based algorithms are widely used in bilevel optimization. However, a common limitation in these algorithms is the presumption of independent sampling, which can lead to increased computational costs due to the complicated hyper-gradient formulation of bilevel problems. To address this challenge, we study the example-selection strategy for bilevel optimization in this work. More specifically, we introduce a without-replacement sampling based algorithm which achieves a faster convergence rate compared to its counterparts that rely on independent sampling. Beyond the standard bilevel optimization formulation, we extend our discussion to conditional bilevel optimization and also two special cases: minimax and compositional optimization. Finally, we validate our algorithms over both synthetic and real-world applications. Numerical results clearly showcase the superiority of our algorithms.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05869",
        "abstract url": "https://arxiv.org/abs/2411.05869",
        "title": "Compactly-supported nonstationary kernels for computing exact Gaussian processes on big data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Gaussian process (GP) is a widely used probabilistic machine learning method for stochastic function approximation, stochastic modeling, and analyzing real-world measurements of nonlinear processes. Unlike many other machine learning methods, GPs include an implicit characterization of uncertainty, making them extremely useful across many areas of science, technology, and engineering. Traditional implementations of GPs involve stationary kernels (also termed covariance functions) that limit their flexibility and exact methods for inference that prevent application to data sets with more than about ten thousand points. Modern approaches to address stationarity assumptions generally fail to accommodate large data sets, while all attempts to address scalability focus on approximating the Gaussian likelihood, which can involve subjectivity and lead to inaccuracies. In this work, we explicitly derive an alternative kernel that can discover and encode both sparsity and nonstationarity. We embed the kernel within a fully Bayesian GP model and leverage high-performance computing resources to enable the analysis of massive data sets. We demonstrate the favorable performance of our novel kernel relative to existing exact and approximate GP methods across a variety of synthetic data examples. Furthermore, we conduct space-time prediction based on more than one million measurements of daily maximum temperature and verify that our results outperform state-of-the-art methods in the Earth sciences. More broadly, having access to exact GPs that use ultra-scalable, sparsity-discovering, nonstationary kernels allows GP methods to truly compete with a wide variety of machine learning methods.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.AP",
            "stat.CO",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08054",
        "abstract url": "https://arxiv.org/abs/2411.08054",
        "title": "GREI Data Repository AI Taxonomy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The Generalist Repository Ecosystem Initiative (GREI), funded by the NIH, developed an AI taxonomy tailored to data repository roles to guide AI integration across repository management. It categorizes the roles into stages, including acquisition, validation, organization, enhancement, analysis, sharing, and user support, providing a structured framework for implementing AI in repository workflows.",
        "subjects": [
            "cs.DL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04457",
        "abstract url": "https://arxiv.org/abs/2411.04457",
        "title": "Efficient single image non-uniformity correction algorithm",
        "rating": "0",
        "keywords": [
            [
                "infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a new way to correct the non-uniformity (NU) in uncooled infrared-type images. The main defect of these uncooled images is the lack of a column (resp. line) time-dependent cross-calibration, resulting in a strong column (resp. line) and time dependent noise. This problem can be considered as a 1D flicker of the columns inside each frame. Thus, classic movie deflickering algorithms can be adapted, to equalize the columns (resp. the lines). The proposed method therefore applies to the series formed by the columns of an infrared image a movie deflickering algorithm. The obtained single image method works on static images, and therefore requires no registration, no camera motion compensation, and no closed aperture sensor equalization. Thus, the method has only one camera dependent parameter, and is landscape independent. This simple method will be compared to a state of the art total variation single image correction on raw real and simulated images. The method is real time, requiring only two operations per pixel. It involves no test-pattern calibration and produces no \"ghost artifacts\".",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2411.03615"
    },
    {
        "paper id": "2411.04501",
        "abstract url": "https://arxiv.org/abs/2411.04501",
        "title": "Pose2Trajectory: Using Transformers on Body Pose to Predict Tennis Player's Trajectory",
        "rating": "0",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Tracking the trajectory of tennis players can help camera operators in production. Predicting future movement enables cameras to automatically track and predict a player's future trajectory without human intervention. Predicting future human movement in the context of complex physical tasks is also intellectually satisfying. Swift advancements in sports analytics and the wide availability of videos for tennis have inspired us to propose a novel method called Pose2Trajectory, which predicts a tennis player's future trajectory as a sequence derived from their body joints' data and ball position. Demonstrating impressive accuracy, our approach capitalizes on body joint information to provide a comprehensive understanding of the human body's geometry and motion, thereby enhancing the prediction of the player's trajectory. We use encoder-decoder Transformer architecture trained on the joints and trajectory information of the players with ball positions. The predicted sequence can provide information to help close-up cameras to keep tracking the tennis player, following centroid coordinates. We generate a high-quality dataset from multiple videos to assist tennis player movement prediction using object detection and human pose estimation methods. It contains bounding boxes and joint information for tennis players and ball positions in singles tennis games. Our method shows promising results in predicting the tennis player's movement trajectory with different sequence prediction lengths using the joints and trajectory information with the ball position.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04533",
        "abstract url": "https://arxiv.org/abs/2411.04533",
        "title": "Neural Fingerprints for Adversarial Attack Detection",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning models for image classification have become standard tools in recent years. A well known vulnerability of these models is their susceptibility to adversarial examples. These are generated by slightly altering an image of a certain class in a way that is imperceptible to humans but causes the model to classify it wrongly as another class. Many algorithms have been proposed to address this problem, falling generally into one of two categories: (i) building robust classifiers (ii) directly detecting attacked images. Despite the good performance of these detectors, we argue that in a white-box setting, where the attacker knows the configuration and weights of the network and the detector, they can overcome the detector by running many examples on a local copy, and sending only those that were not detected to the actual model. This problem is common in security applications where even a very good model is not sufficient to ensure safety. In this paper we propose to overcome this inherent limitation of any static defence with randomization. To do so, one must generate a very large family of detectors with consistent performance, and select one or more of them randomly for each input. For the individual detectors, we suggest the method of neural fingerprints. In the training phase, for each class we repeatedly sample a tiny random subset of neurons from certain layers of the network, and if their average is sufficiently different between clean and attacked images of the focal class they are considered a fingerprint and added to the detector bank. During test time, we sample fingerprints from the bank associated with the label predicted by the model, and detect attacks using a likelihood ratio test. We evaluate our detectors on ImageNet with different attack methods and model architectures, and show near-perfect detection with low rates of false detection.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "stat.AP"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2411.04693",
        "abstract url": "https://arxiv.org/abs/2411.04693",
        "title": "Reciprocal Point Learning Network with Large Electromagnetic Kernel for SAR Open-Set Recognition",
        "rating": "0",
        "keywords": [
            [
                "Radar"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The limitations of existing Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) methods lie in their confinement by the closed-environment assumption, hindering their effective and robust handling of unknown target categories in open environments. Open Set Recognition (OSR), a pivotal facet for algorithmic practicality, intends to categorize known classes while denoting unknown ones as \"unknown.\" The chief challenge in OSR involves concurrently mitigating risks associated with generalizing features from a restricted set of known classes to numerous unknown samples and the open space exposure to potential unknown data. To enhance open-set SAR classification, a method called scattering kernel with reciprocal learning network is proposed. Initially, a feature learning framework is constructed based on reciprocal point learning (RPL), establishing a bounded space for potential unknown classes. This approach indirectly introduces unknown information into a learner confined to known classes, thereby acquiring more concise and discriminative representations. Subsequently, considering the variability in the imaging of targets at different angles and the discreteness of components in SAR images, a proposal is made to design convolutional kernels based on large-sized attribute scattering center models. This enhances the ability to extract intrinsic non-linear features and specific scattering characteristics in SAR images, thereby improving the discriminative features of the model and mitigating the impact of imaging variations on classification performance. Experiments on the MSTAR datasets substantiate the superior performance of the proposed approach called ASC-RPL over mainstream methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04697",
        "abstract url": "https://arxiv.org/abs/2411.04697",
        "title": "Dynamic Brightness Adaptation for Robust Multi-modal Image Fusion",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Infrared and visible image fusion aim to integrate modality strengths for visually enhanced, informative images. Visible imaging in real-world scenarios is susceptible to dynamic environmental brightness fluctuations, leading to texture degradation. Existing fusion methods lack robustness against such brightness perturbations, significantly compromising the visual fidelity of the fused imagery. To address this challenge, we propose the Brightness Adaptive multimodal dynamic fusion framework (BA-Fusion), which achieves robust image fusion despite dynamic brightness fluctuations. Specifically, we introduce a Brightness Adaptive Gate (BAG) module, which is designed to dynamically select features from brightness-related channels for normalization, while preserving brightness-independent structural information within the source images. Furthermore, we propose a brightness consistency loss function to optimize the BAG module. The entire framework is tuned via alternating training strategies. Extensive experiments validate that our method surpasses state-of-the-art methods in preserving multi-modal image information and visual fidelity, while exhibiting remarkable robustness across varying brightness levels. Our code is available: https://github.com/SunYM2020/BA-Fusion.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by IJCAI 2024"
    },
    {
        "paper id": "2411.04707",
        "abstract url": "https://arxiv.org/abs/2411.04707",
        "title": "From CNN to ConvRNN: Adapting Visualization Techniques for Time-Series Anomaly Detection",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Nowadays, neural networks are commonly used to solve various problems. Unfortunately, despite their effectiveness, they are often perceived as black boxes capable of providing answers without explaining their decisions, which raises numerous ethical and legal concerns. Fortunately, the field of explainability helps users understand these results. This aspect of machine learning allows users to grasp the decision-making process of a model and verify the relevance of its outcomes. In this article, we focus on the learning process carried out by a ``time distributed`` convRNN, which performs anomaly detection from video data.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04711",
        "abstract url": "https://arxiv.org/abs/2411.04711",
        "title": "Progressive Multi-Level Alignments for Semi-Supervised Domain Adaptation SAR Target Recognition Using Simulated Data",
        "rating": "0",
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recently, an intriguing research trend for automatic target recognition (ATR) from synthetic aperture radar (SAR) imagery has arisen: using simulated data to train ATR models is a feasible solution to the issue of inadequate measured data. To close the domain gap that exists between the real and simulated data, the unsupervised domain adaptation (UDA) techniques are frequently exploited to construct ATR models. However, for UDA, the target domain lacks labeled data to direct the model training, posing a great challenge to ATR performance. To address the above problem, a semi-supervised domain adaptation (SSDA) framework has been proposed adopting progressive multi-level alignments for simulated data-aided SAR ATR. First, a progressive wavelet transform data augmentation (PWTDA) is presented by analyzing the discrepancies of wavelet decomposition sub-bands of two domain images, obtaining the domain-level alignment. Specifically, the domain gap is narrowed by mixing the wavelet transform high-frequency sub-band components. Second, we develop an asymptotic instance-prototype alignment (AIPA) strategy to push the source domain instances close to the corresponding target prototypes, aiming to achieve category-level alignment. Moreover, the consistency alignment is implemented by excavating the strong-weak augmentation consistency of both individual samples and the multi-sample relationship, enhancing the generalization capability of the model. Extensive experiments on the Synthetic and Measured Paired Labeled Experiment (SAMPLE) dataset, indicate that our approach obtains recognition accuracies of 99.63% and 98.91% in two common experimental settings with only one labeled sample per class of the target domain, outperforming the most advanced SSDA techniques.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04715",
        "abstract url": "https://arxiv.org/abs/2411.04715",
        "title": "NeuroFly: A framework for whole-brain single neuron reconstruction",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neurons, with their elongated, tree-like dendritic and axonal structures, enable efficient signal integration and long-range communication across brain regions. By reconstructing individual neurons' morphology, we can gain valuable insights into brain connectivity, revealing the structure basis of cognition, movement, and perception. Despite the accumulation of extensive 3D microscopic imaging data, progress has been considerably hindered by the absence of automated tools to streamline this process. Here we introduce NeuroFly, a validated framework for large-scale automatic single neuron reconstruction. This framework breaks down the process into three distinct stages: segmentation, connection, and proofreading. In the segmentation stage, we perform automatic segmentation followed by skeletonization to generate over-segmented neuronal fragments without branches. During the connection stage, we use a 3D image-based path following approach to extend each fragment and connect it with other fragments of the same neuron. Finally, human annotators are required only to proofread the few unresolved positions. The first two stages of our process are clearly defined computer vision problems, and we have trained robust baseline models to solve them. We validated NeuroFly's efficiency using in-house datasets that include a variety of challenging scenarios, such as dense arborizations, weak axons, images with contamination. We will release the datasets along with a suite of visualization and annotation tools for better reproducibility. Our goal is to foster collaboration among researchers to address the neuron reconstruction challenge, ultimately accelerating advancements in neuroscience research. The dataset and code are available at https://github.com/beanli161514/neurofly",
        "subjects": [
            "cs.CV",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04746",
        "abstract url": "https://arxiv.org/abs/2411.04746",
        "title": "Taming Rectified Flow for Inversion and Editing",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "video editing",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Rectified-flow-based diffusion transformers, such as FLUX and OpenSora, have demonstrated exceptional performance in the field of image and video generation. Despite their robust generative capabilities, these models often suffer from inaccurate inversion, which could further limit their effectiveness in downstream tasks such as image and video editing. To address this issue, we propose RF-Solver, a novel training-free sampler that enhances inversion precision by reducing errors in the process of solving rectified flow ODEs. Specifically, we derive the exact formulation of the rectified flow ODE and perform a high-order Taylor expansion to estimate its nonlinear components, significantly decreasing the approximation error at each timestep. Building upon RF-Solver, we further design RF-Edit, which comprises specialized sub-modules for image and video editing. By sharing self-attention layer features during the editing process, RF-Edit effectively preserves the structural information of the source image or video while achieving high-quality editing results. Our approach is compatible with any pre-trained rectified-flow-based models for image and video tasks, requiring no additional training or optimization. Extensive experiments on text-to-image generation, image & video inversion, and image & video editing demonstrate the robust performance and adaptability of our methods. Code is available at https://github.com/wangjiangshan0725/RF-Solver-Edit.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04756",
        "abstract url": "https://arxiv.org/abs/2411.04756",
        "title": "A study of Vietnamese readability assessing through semantic and statistical features",
        "rating": "0",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Determining the difficulty of a text involves assessing various textual features that may impact the reader's text comprehension, yet current research in Vietnamese has only focused on statistical features. This paper introduces a new approach that integrates statistical and semantic approaches to assessing text readability. Our research utilized three distinct datasets: the Vietnamese Text Readability Dataset (ViRead), OneStopEnglish, and RACE, with the latter two translated into Vietnamese. Advanced semantic analysis methods were employed for the semantic aspect using state-of-the-art language models such as PhoBERT, ViDeBERTa, and ViBERT. In addition, statistical methods were incorporated to extract syntactic and lexical features of the text. We conducted experiments using various machine learning models, including Support Vector Machine (SVM), Random Forest, and Extra Trees and evaluated their performance using accuracy and F1 score metrics. Our results indicate that a joint approach that combines semantic and statistical features significantly enhances the accuracy of readability classification compared to using each method in isolation. The current study emphasizes the importance of considering both statistical and semantic aspects for a more accurate assessment of text difficulty in Vietnamese. This contribution to the field provides insights into the adaptability of advanced language models in the context of Vietnamese text readability. It lays the groundwork for future research in this area.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04810",
        "abstract url": "https://arxiv.org/abs/2411.04810",
        "title": "GANESH: Generalizable NeRF for Lensless Imaging",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Lensless imaging offers a significant opportunity to develop ultra-compact cameras by removing the conventional bulky lens system. However, without a focusing element, the sensor's output is no longer a direct image but a complex multiplexed scene representation. Traditional methods have attempted to address this challenge by employing learnable inversions and refinement models, but these methods are primarily designed for 2D reconstruction and do not generalize well to 3D reconstruction. We introduce GANESH, a novel framework designed to enable simultaneous refinement and novel view synthesis from multi-view lensless images. Unlike existing methods that require scene-specific training, our approach supports on-the-fly inference without retraining on each scene. Moreover, our framework allows us to tune our model to specific scenes, enhancing the rendering and refinement quality. To facilitate research in this area, we also present the first multi-view lensless dataset, LenslessScenes. Extensive experiments demonstrate that our method outperforms current approaches in reconstruction accuracy and refinement quality. Code and video results are available at https://rakesh-123-cryp.github.io/Rakesh.github.io/",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04821",
        "abstract url": "https://arxiv.org/abs/2411.04821",
        "title": "End-to-end Inception-Unet based Generative Adversarial Networks for Snow and Rain Removals",
        "rating": "0",
        "keywords": [
            [
                "deraining"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The superior performance introduced by deep learning approaches in removing atmospheric particles such as snow and rain from a single image; favors their usage over classical ones. However, deep learning-based approaches still suffer from challenges related to the particle appearance characteristics such as size, type, and transparency. Furthermore, due to the unique characteristics of rain and snow particles, single network based deep learning approaches struggle in handling both degradation scenarios simultaneously. In this paper, a global framework that consists of two Generative Adversarial Networks (GANs) is proposed where each handles the removal of each particle individually. The architectures of both desnowing and deraining GANs introduce the integration of a feature extraction phase with the classical U-net generator network which in turn enhances the removal performance in the presence of severe variations in size and appearance. Furthermore, a realistic dataset that contains pairs of snowy images next to their groundtruth images estimated using a low-rank approximation approach; is presented. The experiments show that the proposed desnowing and deraining approaches achieve significant improvements in comparison to the state-of-the-art approaches when tested on both synthetic and realistic datasets.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04892",
        "abstract url": "https://arxiv.org/abs/2411.04892",
        "title": "In the Era of Prompt Learning with Vision-Language Models",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "remote sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Large-scale foundation models like CLIP have shown strong zero-shot generalization but struggle with domain shifts, limiting their adaptability. In our work, we introduce \\textsc{StyLIP}, a novel domain-agnostic prompt learning strategy for Domain Generalization (DG). StyLIP disentangles visual style and content in CLIP`s vision encoder by using style projectors to learn domain-specific prompt tokens and combining them with content features. Trained contrastively, this approach enables seamless adaptation across domains, outperforming state-of-the-art methods on multiple DG benchmarks. Additionally, we propose AD-CLIP for unsupervised domain adaptation (DA), leveraging CLIP`s frozen vision backbone to learn domain-invariant prompts through image style and content features. By aligning domains in embedding space with entropy minimization, AD-CLIP effectively handles domain shifts, even when only target domain samples are available. Lastly, we outline future work on class discovery using prompt learning for semantic segmentation in remote sensing, focusing on identifying novel or rare classes in unstructured environments. This paves the way for more adaptive and generalizable models in complex, real-world scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ICVGIP 2024, Young Faculty Symposium"
    },
    {
        "paper id": "2411.04919",
        "abstract url": "https://arxiv.org/abs/2411.04919",
        "title": "Stem-OB: Generalizable Visual Imitation Learning with Stem-Like Convergent Observation through Diffusion Inversion",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual imitation learning methods demonstrate strong performance, yet they lack generalization when faced with visual input perturbations, including variations in lighting and textures, impeding their real-world application. We propose Stem-OB that utilizes pretrained image diffusion models to suppress low-level visual differences while maintaining high-level scene structures. This image inversion process is akin to transforming the observation into a shared representation, from which other observations stem, with extraneous details removed. Stem-OB contrasts with data-augmentation approaches as it is robust to various unspecified appearance changes without the need for additional training. Our method is a simple yet highly effective plug-and-play solution. Empirical results confirm the effectiveness of our approach in simulated tasks and show an exceptionally significant improvement in real-world applications, with an average increase of 22.2% in success rates compared to the best baseline. See https://hukz18.github.io/Stem-Ob/ for more info.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Arxiv preprint version, website: https://hukz18.github.io/Stem-Ob/"
    },
    {
        "paper id": "2411.04963",
        "abstract url": "https://arxiv.org/abs/2411.04963",
        "title": "VAIR: Visuo-Acoustic Implicit Representations for Low-Cost, Multi-Modal Transparent Surface Reconstruction in Indoor Scenes",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "RGB-D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Mobile robots operating indoors must be prepared to navigate challenging scenes that contain transparent surfaces. This paper proposes a novel method for the fusion of acoustic and visual sensing modalities through implicit neural representations to enable dense reconstruction of transparent surfaces in indoor scenes. We propose a novel model that leverages generative latent optimization to learn an implicit representation of indoor scenes consisting of transparent surfaces. We demonstrate that we can query the implicit representation to enable volumetric rendering in image space or 3D geometry reconstruction (point clouds or mesh) with transparent surface prediction. We evaluate our method's effectiveness qualitatively and quantitatively on a new dataset collected using a custom, low-cost sensing platform featuring RGB-D cameras and ultrasonic sensors. Our method exhibits significant improvement over state-of-the-art for transparent surface reconstruction.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "https://umfieldrobotics.github.io/VAIR_site/"
    },
    {
        "paper id": "2411.04984",
        "abstract url": "https://arxiv.org/abs/2411.04984",
        "title": "Planar Reflection-Aware Neural Radiance Fields",
        "rating": "0",
        "keywords": [
            [
                "depth",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neural Radiance Fields (NeRF) have demonstrated exceptional capabilities in reconstructing complex scenes with high fidelity. However, NeRF's view dependency can only handle low-frequency reflections. It falls short when handling complex planar reflections, often interpreting them as erroneous scene geometries and leading to duplicated and inaccurate scene representations. To address this challenge, we introduce a reflection-aware NeRF that jointly models planar reflectors, such as windows, and explicitly casts reflected rays to capture the source of the high-frequency reflections. We query a single radiance field to render the primary color and the source of the reflection. We propose a sparse edge regularization to help utilize the true sources of reflections for rendering planar reflections rather than creating a duplicate along the primary ray at the same depth. As a result, we obtain accurate scene geometry. Rendering along the primary ray results in a clean, reflection-free view, while explicitly rendering along the reflected ray allows us to reconstruct highly detailed reflections. Our extensive quantitative and qualitative evaluations of real-world datasets demonstrate our method's enhanced performance in accurately handling reflections.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04995",
        "abstract url": "https://arxiv.org/abs/2411.04995",
        "title": "LoFi: Scalable Local Image Reconstruction with Implicit Neural Representation",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Neural fields or implicit neural representations (INRs) have attracted significant attention in machine learning and signal processing due to their efficient continuous representation of images and 3D volumes. In this work, we build on INRs and introduce a coordinate-based local processing framework for solving imaging inverse problems, termed LoFi (Local Field). Unlike conventional methods for image reconstruction, LoFi processes local information at each coordinate \\textit{separately} by multi-layer perceptrons (MLPs), recovering the object at that specific coordinate. Similar to INRs, LoFi can recover images at any continuous coordinate, enabling image reconstruction at multiple resolutions. With comparable or better performance than standard CNNs for image reconstruction, LoFi achieves excellent generalization to out-of-distribution data and memory usage almost independent of image resolution. Remarkably, training on $1024 \\times 1024$ images requires just 3GB of memory -- over 20 times less than the memory typically needed by standard CNNs. Additionally, LoFi's local design allows it to train on extremely small datasets with less than 10 samples, without overfitting or the need for regularization or early stopping. Finally, we use LoFi as a denoising prior in a plug-and-play framework for solving general inverse problems to benefit from its continuous image representation and strong generalization. Although trained on low-resolution images, LoFi can be used as a low-dimensional prior to solve inverse problems at any resolution. We validate our framework across a variety of imaging modalities, from low-dose computed tomography to radio interferometric imaging.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05005",
        "abstract url": "https://arxiv.org/abs/2411.05005",
        "title": "Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Beyond high-fidelity image synthesis, diffusion models have recently exhibited promising results in dense visual perception tasks. However, most existing work treats diffusion models as a standalone component for perception tasks, employing them either solely for off-the-shelf data augmentation or as mere feature extractors. In contrast to these isolated and thus sub-optimal efforts, we introduce a unified, versatile, diffusion-based framework, Diff-2-in-1, that can simultaneously handle both multi-modal data generation and dense visual perception, through a unique exploitation of the diffusion-denoising process. Within this framework, we further enhance discriminative visual perception via multi-modal generation, by utilizing the denoising network to create multi-modal data that mirror the distribution of the original training set. Importantly, Diff-2-in-1 optimizes the utilization of the created diverse and faithful data by leveraging a novel self-improving learning mechanism. Comprehensive experimental evaluations validate the effectiveness of our framework, showcasing consistent performance improvements across various discriminative backbones and high-quality multi-modal data generation characterized by both realism and usefulness.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "26 pages, 14 figures"
    },
    {
        "paper id": "2411.05007",
        "abstract url": "https://arxiv.org/abs/2411.05007",
        "title": "SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have been proven highly effective at generating high-quality images. However, as these models grow larger, they require significantly more memory and suffer from higher latency, posing substantial challenges for deployment. In this work, we aim to accelerate diffusion models by quantizing their weights and activations to 4 bits. At such an aggressive level, both weights and activations are highly sensitive, where conventional post-training quantization methods for large language models like smoothing become insufficient. To overcome this limitation, we propose SVDQuant, a new 4-bit quantization paradigm. Different from smoothing which redistributes outliers between weights and activations, our approach absorbs these outliers using a low-rank branch. We first consolidate the outliers by shifting them from activations to weights, then employ a high-precision low-rank branch to take in the weight outliers with Singular Value Decomposition (SVD). This process eases the quantization on both sides. However, na\u00efvely running the low-rank branch independently incurs significant overhead due to extra data movement of activations, negating the quantization speedup. To address this, we co-design an inference engine Nunchaku that fuses the kernels of the low-rank branch into those of the low-bit branch to cut off redundant memory access. It can also seamlessly support off-the-shelf low-rank adapters (LoRAs) without the need for re-quantization. Extensive experiments on SDXL, PixArt-$\u03a3$, and FLUX.1 validate the effectiveness of SVDQuant in preserving image quality. We reduce the memory usage for the 12B FLUX.1 models by 3.5$\\times$, achieving 3.0$\\times$ speedup over the 4-bit weight-only quantized baseline on the 16GB laptop 4090 GPU, paving the way for more interactive applications on PCs. Our quantization library and inference engine are open-sourced.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Quantization Library: https://github.com/mit-han-lab/deepcompressor Inference Engine: https://github.com/mit-han-lab/nunchaku Website: https://hanlab.mit.edu/projects/svdquant Demo: https://svdquant.mit.edu Blog: https://hanlab.mit.edu/blog/svdquant"
    },
    {
        "paper id": "2411.05172",
        "abstract url": "https://arxiv.org/abs/2411.05172",
        "title": "ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Handling implicit language is essential for natural language processing systems to achieve precise text understanding and facilitate natural interactions with users. Despite its importance, the absence of a robust metric for accurately measuring the implicitness of language significantly constrains the depth of analysis possible in evaluating models' comprehension capabilities. This paper addresses this gap by developing a scalar metric that quantifies the implicitness level of language without relying on external references. Drawing on principles from traditional linguistics, we define ''implicitness'' as the divergence between semantic meaning and pragmatic interpretation. To operationalize this definition, we introduce ImpScore, a novel, reference-free metric formulated through an interpretable regression model. This model is trained using pairwise contrastive learning on a specially curated dataset comprising $112,580$ (implicit sentence, explicit sentence) pairs. We validate ImpScore through a user study that compares its assessments with human evaluations on out-of-distribution data, demonstrating its accuracy and strong correlation with human judgments. Additionally, we apply ImpScore to hate speech detection datasets, illustrating its utility and highlighting significant limitations in current large language models' ability to understand highly implicit content. The metric model and its training data are available at https://github.com/audreycs/ImpScore.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05212",
        "abstract url": "https://arxiv.org/abs/2411.05212",
        "title": "RT-Grasp: Reasoning Tuning Robotic Grasping via Multi-modal Large Language Model",
        "rating": "0",
        "keywords": [
            [
                "VLM"
            ],
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "Recent advances in Large Language Models (LLMs) have showcased their remarkable reasoning capabilities, making them influential across various fields. However, in robotics, their use has primarily been limited to manipulation planning tasks due to their inherent textual output. This paper addresses this limitation by investigating the potential of adopting the reasoning ability of LLMs for generating numerical predictions in robotics tasks, specifically for robotic grasping. We propose Reasoning Tuning, a novel method that integrates a reasoning phase before prediction during training, leveraging the extensive prior knowledge and advanced reasoning abilities of LLMs. This approach enables LLMs, notably with multi-modal capabilities, to generate accurate numerical outputs like grasp poses that are context-aware and adaptable through conversations. Additionally, we present the Reasoning Tuning VLM Grasp dataset, carefully curated to facilitate the adaptation of LLMs to robotic grasping. Extensive validation on both grasping datasets and real-world experiments underscores the adaptability of multi-modal LLMs for numerical prediction tasks in robotics. This not only expands their applicability but also bridges the gap between text-based planning and direct robot control, thereby maximizing the potential of LLMs in robotics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to IROS 2024"
    },
    {
        "paper id": "2411.05225",
        "abstract url": "https://arxiv.org/abs/2411.05225",
        "title": "Breaking The Ice: Video Segmentation for Close-Range Ice-Covered Waters",
        "rating": "0",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Rapid ice recession in the Arctic Ocean, with predictions of ice-free summers by 2060, opens new maritime routes but requires reliable navigation solutions. Current approaches rely heavily on subjective expert judgment, underscoring the need for automated, data-driven solutions. This study leverages machine learning to assess ice conditions using ship-borne optical data, introducing a finely annotated dataset of 946 images, and a semi-manual, region-based annotation technique. The proposed video segmentation model, UPerFlow, advances the SegFlow architecture by incorporating a six-channel ResNet encoder, two UPerNet-based segmentation decoders for each image, PWCNet as the optical flow encoder, and cross-connections that integrate bi-directional flow features without loss of latent information. The proposed architecture outperforms baseline image segmentation networks by an average 38\\% in occluded regions, demonstrating the robustness of video segmentation in addressing challenging Arctic conditions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05309",
        "abstract url": "https://arxiv.org/abs/2411.05309",
        "title": "GPUVM: GPU-driven Unified Virtual Memory",
        "rating": "0",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "graph"
            ]
        ],
        "abstract": "Graphics Processing Units (GPUs) leverage massive parallelism and large memory bandwidth to support high-performance computing applications, such as multimedia rendering, crypto-mining, deep learning, and natural language processing. These applications require models and datasets that are getting bigger in size and currently challenge the memory capacity of a single GPU, causing substantial performance overheads. To address this problem, a programmer has to partition the data and manually transfer data in and out of the GPU. This approach requires programmers to carefully tune their applications and can be impractical for workloads with irregular access patterns, such as deep learning, recommender systems, and graph applications. To ease programmability, programming abstractions such as unified virtual memory (UVM) can be used, creating a virtually unified memory space across the whole system and transparently moving the data on demand as it is accessed. However, UVM brings in the overhead of the OS involvement and inefficiencies due to generating many transfer requests especially when the GPU memory is oversubscribed. This paper proposes GPUVM, a GPU memory management system that uses an RDMA-capable network device to construct a virtual memory system without involving the CPU/OS. GPUVM enables on-demand paging for GPU applications and relies on GPU threads for memory management and page migration. Since CPU chipsets do not support GPU-driven memory management, we use a network interface card to facilitate transparent page migration from/to the GPU. GPUVM achieves performance up to 4x higher than UVM for latency-bound applications while providing accessible programming abstractions that do not require the users to manage memory transfers directly.",
        "subjects": [
            "cs.DC",
            "cs.OS",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05322",
        "abstract url": "https://arxiv.org/abs/2411.05322",
        "title": "Rate-aware Compression for NeRF-based Volumetric Video",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "NeRF",
                "radiance fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The neural radiance fields (NeRF) have advanced the development of 3D volumetric video technology, but the large data volumes they involve pose significant challenges for storage and transmission. To address these problems, the existing solutions typically compress these NeRF representations after the training stage, leading to a separation between representation training and compression. In this paper, we try to directly learn a compact NeRF representation for volumetric video in the training stage based on the proposed rate-aware compression framework. Specifically, for volumetric video, we use a simple yet effective modeling strategy to reduce temporal redundancy for the NeRF representation. Then, during the training phase, an implicit entropy model is utilized to estimate the bitrate of the NeRF representation. This entropy model is then encoded into the bitstream to assist in the decoding of the NeRF representation. This approach enables precise bitrate estimation, thereby leading to a compact NeRF representation. Furthermore, we propose an adaptive quantization strategy and learn the optimal quantization step for the NeRF representations. Finally, the NeRF representation can be optimized by using the rate-distortion trade-off. Our proposed compression framework can be used for different representations and experimental results demonstrate that our approach significantly reduces the storage size with marginal distortion and achieves state-of-the-art rate-distortion performance for volumetric video on the HumanRF and ReRF datasets. Compared to the previous state-of-the-art method TeTriRF, we achieved an approximately -80% BD-rate on the HumanRF dataset and -60% BD-rate on the ReRF dataset.",
        "subjects": [
            "cs.MM",
            "cs.CV"
        ],
        "comment": "Accepted by ACM MM 2024 (Oral)"
    },
    {
        "paper id": "2411.05863",
        "abstract url": "https://arxiv.org/abs/2411.05863",
        "title": "Exploring the Feasibility of Affordable Sonar Technology: Object Detection in Underwater Environments Using the Ping 360",
        "rating": "0",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This study explores the potential of the Ping 360 sonar device, primarily used for navigation, in detecting complex underwater obstacles. The key motivation behind this research is the device's affordability and open-source nature, offering a cost-effective alternative to more expensive imaging sonar systems. The investigation focuses on understanding the behaviour of the Ping 360 in controlled environments and assessing its suitability for object detection, particularly in scenarios where human operators are unavailable for inspecting offshore structures in shallow waters. Through a series of carefully designed experiments, we examined the effects of surface reflections and object shadows in shallow underwater environments. Additionally, we developed a manually annotated sonar image dataset to train a U-Net segmentation model. Our findings indicate that while the Ping 360 sonar demonstrates potential in simpler settings, its performance is limited in more cluttered or reflective environments unless extensive data pre-processing and annotation are applied. To our knowledge, this is the first study to evaluate the Ping 360's capabilities for complex object detection. By investigating the feasibility of low-cost sonar devices, this research provides valuable insights into their limitations and potential for future AI-based interpretation, marking a unique contribution to the field.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.ET"
        ],
        "comment": "This work is currently under review. This is a pre-print"
    },
    {
        "paper id": "2411.05873",
        "abstract url": "https://arxiv.org/abs/2411.05873",
        "title": "Poor Man's Training on MCUs: A Memory-Efficient Quantized Back-Propagation-Free Approach",
        "rating": "0",
        "keywords": [
            [
                "Memory-Efficient"
            ],
            [
                "FPGA"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Back propagation (BP) is the default solution for gradient computation in neural network training. However, implementing BP-based training on various edge devices such as FPGA, microcontrollers (MCUs), and analog computing platforms face multiple major challenges, such as the lack of hardware resources, long time-to-market, and dramatic errors in a low-precision setting. This paper presents a simple BP-free training scheme on an MCU, which makes edge training hardware design as easy as inference hardware design. We adopt a quantized zeroth-order method to estimate the gradients of quantized model parameters, which can overcome the error of a straight-through estimator in a low-precision BP scheme. We further employ a few dimension reduction methods (e.g., node perturbation, sparse training) to improve the convergence of zeroth-order training. Experiment results show that our BP-free training achieves comparable performance as BP-based training on adapting a pre-trained image classifier to various corrupted data on resource-constrained edge devices (e.g., an MCU with 1024-KB SRAM for dense full-model training, or an MCU with 256-KB SRAM for sparse training). This method is most suitable for application scenarios where memory cost and time-to-market are the major concerns, but longer latency can be tolerated.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.DC",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04434",
        "abstract url": "https://arxiv.org/abs/2411.04434",
        "title": "Scaling Laws for Pre-training Agents and World Models",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The performance of embodied agents has been shown to improve by increasing model parameters, dataset size, and compute. This has been demonstrated in domains from robotics to video games, when generative learning objectives on offline datasets (pre-training) are used to model an agent's behavior (imitation learning) or their environment (world modeling). This paper characterizes the role of scale in these tasks more precisely. Going beyond the simple intuition that `bigger is better', we show that the same types of power laws found in language modeling (e.g. between loss and optimal model size), also arise in world modeling and imitation learning. However, the coefficients of these laws are heavily influenced by the tokenizer, task \\& architecture -- this has important implications on the optimal sizing of models and data.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04534",
        "abstract url": "https://arxiv.org/abs/2411.04534",
        "title": "Hypercube Policy Regularization Framework for Offline Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Offline reinforcement learning has received extensive attention from scholars because it avoids the interaction between the agent and the environment by learning a policy through a static dataset. However, general reinforcement learning methods cannot get satisfactory results in offline reinforcement learning due to the out-of-distribution state actions that the dataset cannot cover during training. To solve this problem, the policy regularization method that tries to directly clone policies used in static datasets has received numerous studies due to its simplicity and effectiveness. However, policy constraint methods make the agent choose the corresponding actions in the static dataset. This type of constraint is usually over-conservative, which results in suboptimal policies, especially in low-quality static datasets. In this paper, a hypercube policy regularization framework is proposed, this method alleviates the constraints of policy constraint methods by allowing the agent to explore the actions corresponding to similar states in the static dataset, which increases the effectiveness of algorithms in low-quality datasets. It was also theoretically demonstrated that the hypercube policy regularization framework can effectively improve the performance of original algorithms. In addition, the hypercube policy regularization framework is combined with TD3-BC and Diffusion-QL for experiments on D4RL datasets which are called TD3-BC-C and Diffusion-QL-C. The experimental results of the score demonstrate that TD3-BC-C and Diffusion-QL-C perform better than state-of-the-art algorithms like IQL, CQL, TD3-BC and Diffusion-QL in most D4RL environments in approximate time.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04564",
        "abstract url": "https://arxiv.org/abs/2411.04564",
        "title": "A Generalisation of Voter Model: Influential Nodes and Convergence Properties",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.SI"
            ]
        ],
        "abstract": "Consider an undirected graph G, representing a social network, where each node is blue or red, corresponding to positive or negative opinion on a topic. In the voter model, in discrete time rounds, each node picks a neighbour uniformly at random and adopts its colour. Despite its significant popularity, this model does not capture some fundamental real-world characteristics such as the difference in the strengths of individuals connections, individuals with neutral opinion on a topic, and individuals who are reluctant to update their opinion. To address these issues, we introduce and study a generalisation of the voter model. Motivating by campaigning strategies, we study the problem of selecting a set of seeds blue nodes to maximise the expected number of blue nodes after some rounds. We prove that the problem is NP- hard and provide a polynomial time approximation algorithm with the best possible approximation guarantee. Our experiments on real-world and synthetic graph data demonstrate that the proposed algorithm outperforms other algorithms. We also investigate the convergence properties of the model. We prove that the process could take an exponential number of rounds to converge. However, if we limit ourselves to strongly connected graphs, the convergence time is polynomial and the period (the number of states in convergence) divides the length of all cycles in the graph.",
        "subjects": [
            "cs.SI",
            "cs.AI",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04570",
        "abstract url": "https://arxiv.org/abs/2411.04570",
        "title": "Higher-Order GNNs Meet Efficiency: Sparse Sobolev Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have shown great promise in modeling relationships between nodes in a graph, but capturing higher-order relationships remains a challenge for large-scale networks. Previous studies have primarily attempted to utilize the information from higher-order neighbors in the graph, involving the incorporation of powers of the shift operator, such as the graph Laplacian or adjacency matrix. This approach comes with a trade-off in terms of increased computational and memory demands. Relying on graph spectral theory, we make a fundamental observation: the regular and the Hadamard power of the Laplacian matrix behave similarly in the spectrum. This observation has significant implications for capturing higher-order information in GNNs for various tasks such as node classification and semi-supervised learning. Consequently, we propose a novel graph convolutional operator based on the sparse Sobolev norm of graph signals. Our approach, known as Sparse Sobolev GNN (S2-GNN), employs Hadamard products between matrices to maintain the sparsity level in graph representations. S2-GNN utilizes a cascade of filters with increasing Hadamard powers to generate a diverse set of functions. We theoretically analyze the stability of S2-GNN to show the robustness of the model against possible graph perturbations. We also conduct a comprehensive evaluation of S2-GNN across various graph mining, semi-supervised node classification, and computer vision tasks. In particular use cases, our algorithm demonstrates competitive performance compared to state-of-the-art GNNs in terms of performance and running time.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04635",
        "abstract url": "https://arxiv.org/abs/2411.04635",
        "title": "Cybercrime Prediction via Geographically Weighted Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Inspired by the success of Geographically Weighted Regression and its accounting for spatial variations, we propose GeogGNN -- A graph neural network model that accounts for geographical latitude and longitudinal points. Using a synthetically generated dataset, we apply the algorithm for a 4-class classification problem in cybersecurity with seemingly realistic geographic coordinates centered in the Gulf Cooperation Council region. We demonstrate that it has higher accuracy than standard neural networks and convolutional neural networks that treat the coordinates as features. Encouraged by the speed-up in model accuracy by the GeogGNN model, we provide a general mathematical result that demonstrates that a geometrically weighted neural network will, in principle, always display higher accuracy in the classification of spatially dependent data by making use of spatial continuity and local averaging features.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "17 pages, 8 figures, Submitted to the International Jordanian Cybersecurity Conference 2024 (IJCC24)"
    },
    {
        "paper id": "2411.04653",
        "abstract url": "https://arxiv.org/abs/2411.04653",
        "title": "IGDrivSim: A Benchmark for the Imitation Gap in Autonomous Driving",
        "rating": "-0.5",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Developing autonomous vehicles that can navigate complex environments with human-level safety and efficiency is a central goal in self-driving research. A common approach to achieving this is imitation learning, where agents are trained to mimic human expert demonstrations collected from real-world driving scenarios. However, discrepancies between human perception and the self-driving car's sensors can introduce an \\textit{imitation gap}, leading to imitation learning failures. In this work, we introduce \\textbf{IGDrivSim}, a benchmark built on top of the Waymax simulator, designed to investigate the effects of the imitation gap in learning autonomous driving policy from human expert demonstrations. Our experiments show that this perception gap between human experts and self-driving agents can hinder the learning of safe and effective driving behaviors. We further show that combining imitation with reinforcement learning, using a simple penalty reward for prohibited behaviors, effectively mitigates these failures. Our code is open-sourced at: https://github.com/clemgris/IGDrivSim.git.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "8 pages, 4 figures, 1 table"
    },
    {
        "paper id": "2411.04655",
        "abstract url": "https://arxiv.org/abs/2411.04655",
        "title": "Centrality Graph Shift Operators for Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph Shift Operators (GSOs), such as the adjacency and graph Laplacian matrices, play a fundamental role in graph theory and graph representation learning. Traditional GSOs are typically constructed by normalizing the adjacency matrix by the degree matrix, a local centrality metric. In this work, we instead propose and study Centrality GSOs (CGSOs), which normalize adjacency matrices by global centrality metrics such as the PageRank, $k$-core or count of fixed length walks. We study spectral properties of the CGSOs, allowing us to get an understanding of their action on graph signals. We confirm this understanding by defining and running the spectral clustering algorithm based on different CGSOs on several synthetic and real-world datasets. We furthermore outline how our CGSO can act as the message passing operator in any Graph Neural Network and in particular demonstrate strong performance of a variant of the Graph Convolutional Network and Graph Attention Network using our CGSOs on several real-world benchmark datasets.",
        "subjects": [
            "cs.LG",
            "cs.SI",
            "math.SP",
            "stat.AP",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04672",
        "abstract url": "https://arxiv.org/abs/2411.04672",
        "title": "Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a semantic-aware multi-modal resource allocation (SAMRA) for multi-task using multi-agent reinforcement learning (MARL), termed SAMRAMARL, utilizing in platoon systems where cellular vehicle-to-everything (C-V2X) communication is employed. The proposed approach leverages the semantic information to optimize the allocation of communication resources. By integrating a distributed multi-agent reinforcement learning (MARL) algorithm, SAMRAMARL enables autonomous decision-making for each vehicle, channel assignment optimization, power allocation, and semantic symbol length based on the contextual importance of the transmitted information. This semantic-awareness ensures that both vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications prioritize data that is critical for maintaining safe and efficient platoon operations. The framework also introduces a tailored quality of experience (QoE) metric for semantic communication, aiming to maximize QoE in V2V links while improving the success rate of semantic information transmission (SRS). Extensive simulations has demonstrated that SAMRAMARL outperforms existing methods, achieving significant gains in QoE and communication efficiency in C-V2X platooning scenarios.",
        "subjects": [
            "cs.LG",
            "cs.MA",
            "cs.NI",
            "eess.SP"
        ],
        "comment": "This paper has been submitted to IEEE Journal. The source code has been released at:https://github.com/qiongwu86/Semantic-Aware-Resource-Management-for-C-V2X-Platooning-via-Multi-Agent-Reinforcement-Learning"
    },
    {
        "paper id": "2411.04696",
        "abstract url": "https://arxiv.org/abs/2411.04696",
        "title": "The Multiple Dimensions of Spuriousness in Machine Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Learning correlations from data forms the foundation of today's machine learning (ML) and artificial intelligence (AI) research. While such an approach enables the automatic discovery of patterned relationships within big data corpora, it is susceptible to failure modes when unintended correlations are captured. This vulnerability has expanded interest in interrogating spuriousness, often critiqued as an impediment to model performance, fairness, and robustness. In this article, we trace deviations from the conventional definition of statistical spuriousness-which denotes a non-causal observation arising from either coincidence or confounding variables-to articulate how ML researchers make sense of spuriousness in practice. Drawing on a broad survey of ML literature, we conceptualize the \"multiple dimensions of spuriousness,\" encompassing: relevance (\"Models should only use correlations that are relevant to the task.\"), generalizability (\"Models should only use correlations that generalize to unseen data\"), human-likeness (\"Models should only use correlations that a human would use to perform the same task\"), and harmfulness (\"Models should only use correlations that are not harmful\"). These dimensions demonstrate that ML spuriousness goes beyond the causal/non-causal dichotomy and that the disparate interpretative paths researchers choose could meaningfully influence the trajectory of ML development. By underscoring how a fundamental problem in ML is contingently negotiated in research contexts, we contribute to ongoing debates about responsible practices in AI development.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04700",
        "abstract url": "https://arxiv.org/abs/2411.04700",
        "title": "Field Assessment of Force Torque Sensors for Planetary Rover Navigation",
        "rating": "-0.5",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Proprioceptive sensors on planetary rovers serve for state estimation and for understanding terrain and locomotion performance. While inertial measurement units (IMUs) are widely used to this effect, force-torque sensors are less explored for planetary navigation despite their potential to directly measure interaction forces and provide insights into traction performance. This paper presents an evaluation of the performance and use cases of force-torque sensors based on data collected from a six-wheeled rover during tests over varying terrains, speeds, and slopes. We discuss challenges, such as sensor signal reliability and terrain response accuracy, and identify opportunities regarding the use of these sensors. The data is openly accessible and includes force-torque measurements from each of the six-wheel assemblies as well as IMU data from within the rover chassis. This paper aims to inform the design of future studies and rover upgrades, particularly in sensor integration and control algorithms, to improve navigation capabilities.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04760",
        "abstract url": "https://arxiv.org/abs/2411.04760",
        "title": "Zero-Shot Temporal Resolution Domain Adaptation for Spiking Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "time efficient"
            ],
            [
                "biologically-inspired"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Spiking Neural Networks (SNNs) are biologically-inspired deep neural networks that efficiently extract temporal information while offering promising gains in terms of energy efficiency and latency when deployed on neuromorphic devices. However, SNN model parameters are sensitive to temporal resolution, leading to significant performance drops when the temporal resolution of target data at the edge is not the same with that of the pre-deployment source data used for training, especially when fine-tuning is not possible at the edge. To address this challenge, we propose three novel domain adaptation methods for adapting neuron parameters to account for the change in time resolution without re-training on target time-resolution. The proposed methods are based on a mapping between neuron dynamics in SNNs and State Space Models (SSMs); and are applicable to general neuron models. We evaluate the proposed methods under spatio-temporal data tasks, namely the audio keyword spotting datasets SHD and MSWC as well as the image classification NMINST dataset. Our methods provide an alternative to - and in majority of the cases significantly outperform - the existing reference method that simply scales the time constant. Moreover, our results show that high accuracy on high temporal resolution data can be obtained by time efficient training on lower temporal resolution data and model adaptation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04772",
        "abstract url": "https://arxiv.org/abs/2411.04772",
        "title": "Attention Masks Help Adversarial Attacks to Bypass Safety Detectors",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Despite recent research advancements in adversarial attack methods, current approaches against XAI monitors are still discoverable and slower. In this paper, we present an adaptive framework for attention mask generation to enable stealthy, explainable and efficient PGD image classification adversarial attack under XAI monitors. Specifically, we utilize mutation XAI mixture and multitask self-supervised X-UNet for attention mask generation to guide PGD attack. Experiments on MNIST (MLP), CIFAR-10 (AlexNet) have shown that our system can outperform benchmark PGD, Sparsefool and SOTA SINIFGSM in balancing among stealth, efficiency and explainability which is crucial for effectively fooling SOTA defense protected classifiers.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04777",
        "abstract url": "https://arxiv.org/abs/2411.04777",
        "title": "Learn to Solve Vehicle Routing Problems ASAP: A Neural Optimization Approach for Time-Constrained Vehicle Routing Problems with Finite Vehicle Fleet",
        "rating": "-0.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Finding a feasible and prompt solution to the Vehicle Routing Problem (VRP) is a prerequisite for efficient freight transportation, seamless logistics, and sustainable mobility. Traditional optimization methods reach their limits when confronted with the real-world complexity of VRPs, which involve numerous constraints and objectives. Recently, the ability of generative Artificial Intelligence (AI) to solve combinatorial tasks, known as Neural Combinatorial Optimization (NCO), demonstrated promising results, offering new perspectives. In this study, we propose an NCO approach to solve a time-constrained capacitated VRP with a finite vehicle fleet size. The approach is based on an encoder-decoder architecture, formulated in line with the Policy Optimization with Multiple Optima (POMO) protocol and trained via a Proximal Policy Optimization (PPO) algorithm. We successfully trained the policy with multiple objectives (minimizing the total distance while maximizing vehicle utilization) and evaluated it on medium and large instances, benchmarking it against state-of-the-art heuristics. The method is able to find adequate and cost-efficient solutions, showing both flexibility and robust generalization. Finally, we provide a critical analysis of the solution generated by NCO and discuss the challenges and opportunities of this new branch of intelligent learning algorithms emerging in optimization science, focusing on freight transportation.",
        "subjects": [
            "cs.LG",
            "cs.ET"
        ],
        "comment": "Affiliation: German Aerospace Center (DLR), Institute of Transport Research, Rudower Chaussee 7, 12489 Berlin Correspondence: Elija.deineko@dlr.de"
    },
    {
        "paper id": "2411.04811",
        "abstract url": "https://arxiv.org/abs/2411.04811",
        "title": "Defending Deep Regression Models against Backdoor Attacks",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep regression models are used in a wide variety of safety-critical applications, but are vulnerable to backdoor attacks. Although many defenses have been proposed for classification models, they are ineffective as they do not consider the uniqueness of regression models. First, the outputs of regression models are continuous values instead of discretized labels. Thus, the potential infected target of a backdoored regression model has infinite possibilities, which makes it impossible to be determined by existing defenses. Second, the backdoor behavior of backdoored deep regression models is triggered by the activation values of all the neurons in the feature space, which makes it difficult to be detected and mitigated using existing defenses. To resolve these problems, we propose DRMGuard, the first defense to identify if a deep regression model in the image domain is backdoored or not. DRMGuard formulates the optimization problem for reverse engineering based on the unique output-space and feature-space characteristics of backdoored deep regression models. We conduct extensive evaluations on two regression tasks and four datasets. The results show that DRMGuard can consistently defend against various backdoor attacks. We also generalize four state-of-the-art defenses designed for classifiers to regression models, and compare DRMGuard with them. The results show that DRMGuard significantly outperforms all those defenses.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04876",
        "abstract url": "https://arxiv.org/abs/2411.04876",
        "title": "Non-Euclidean Mixture Model for Social Network Embedding",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "It is largely agreed that social network links are formed due to either homophily or social influence. Inspired by this, we aim at understanding the generation of links via providing a novel embedding-based graph formation model. Different from existing graph representation learning, where link generation probabilities are defined as a simple function of the corresponding node embeddings, we model the link generation as a mixture model of the two factors. In addition, we model the homophily factor in spherical space and the influence factor in hyperbolic space to accommodate the fact that (1) homophily results in cycles and (2) influence results in hierarchies in networks. We also design a special projection to align these two spaces. We call this model Non-Euclidean Mixture Model, i.e., NMM. We further integrate NMM with our non-Euclidean graph variational autoencoder (VAE) framework, NMM-GNN. NMM-GNN learns embeddings through a unified framework which uses non-Euclidean GNN encoders, non-Euclidean Gaussian priors, a non-Euclidean decoder, and a novel space unification loss component to unify distinct non-Euclidean geometric spaces. Experiments on public datasets show NMM-GNN significantly outperforms state-of-the-art baselines on social network generation and classification tasks, demonstrating its ability to better explain how the social network is formed.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04924",
        "abstract url": "https://arxiv.org/abs/2411.04924",
        "title": "MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We introduce MVSplat360, a feed-forward approach for 360\u00b0 novel view synthesis (NVS) of diverse real-world scenes, using only sparse observations. This setting is inherently ill-posed due to minimal overlap among input views and insufficient visual information provided, making it challenging for conventional methods to achieve high-quality results. Our MVSplat360 addresses this by effectively combining geometry-aware 3D reconstruction with temporally consistent video generation. Specifically, it refactors a feed-forward 3D Gaussian Splatting (3DGS) model to render features directly into the latent space of a pre-trained Stable Video Diffusion (SVD) model, where these features then act as pose and visual cues to guide the denoising process and produce photorealistic 3D-consistent views. Our model is end-to-end trainable and supports rendering arbitrary views with as few as 5 sparse input views. To evaluate MVSplat360's performance, we introduce a new benchmark using the challenging DL3DV-10K dataset, where MVSplat360 achieves superior visual quality compared to state-of-the-art methods on wide-sweeping or even 360\u00b0 NVS tasks. Experiments on the existing benchmark RealEstate10K also confirm the effectiveness of our model. The video results are available on our project page: https://donydchen.github.io/mvsplat360.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "NeurIPS 2024, Project page: https://donydchen.github.io/mvsplat360, Code: https://github.com/donydchen/mvsplat360"
    },
    {
        "paper id": "2411.04962",
        "abstract url": "https://arxiv.org/abs/2411.04962",
        "title": "Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability",
        "rating": "-0.5",
        "keywords": [
            [
                "health",
                "diagnosis",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Large language models (LLMs) are being explored for diagnostic decision support, yet their ability to estimate pre-test probabilities, vital for clinical decision-making, remains limited. This study evaluates two LLMs, Mistral-7B and Llama3-70B, using structured electronic health record data on three diagnosis tasks. We examined three current methods of extracting LLM probability estimations and revealed their limitations. We aim to highlight the need for improved techniques in LLM confidence estimation.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "Accepted to GenAI4Health Workshop at NeurIPS 2024"
    },
    {
        "paper id": "2411.04983",
        "abstract url": "https://arxiv.org/abs/2411.04983",
        "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
        "rating": "-0.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "The ability to predict future outcomes given control actions is fundamental for physical reasoning. However, such predictive models, often called world models, have proven challenging to learn and are typically developed for task-specific solutions with online policy learning. We argue that the true potential of world models lies in their ability to reason and plan across diverse problems using only passive data. Concretely, we require world models to have the following three properties: 1) be trainable on offline, pre-collected trajectories, 2) support test-time behavior optimization, and 3) facilitate task-agnostic reasoning. To realize this, we present DINO World Model (DINO-WM), a new method to model visual dynamics without reconstructing the visual world. DINO-WM leverages spatial patch features pre-trained with DINOv2, enabling it to learn from offline behavioral trajectories by predicting future patch features. This design allows DINO-WM to achieve observational goals through action sequence optimization, facilitating task-agnostic behavior planning by treating desired goal patch features as prediction targets. We evaluate DINO-WM across various domains, including maze navigation, tabletop pushing, and particle manipulation. Our experiments demonstrate that DINO-WM can generate zero-shot behavioral solutions at test time without relying on expert demonstrations, reward modeling, or pre-learned inverse models. Notably, DINO-WM exhibits strong generalization capabilities compared to prior state-of-the-art work, adapting to diverse task families such as arbitrarily configured mazes, push manipulation with varied object shapes, and multi-particle scenarios.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04999",
        "abstract url": "https://arxiv.org/abs/2411.04999",
        "title": "DynaMem: Online Dynamic Spatio-Semantic Memory for Open World Mobile Manipulation",
        "rating": "-0.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "3D"
            ],
            [
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Significant progress has been made in open-vocabulary mobile manipulation, where the goal is for a robot to perform tasks in any environment given a natural language description. However, most current systems assume a static environment, which limits the system's applicability in real-world scenarios where environments frequently change due to human intervention or the robot's own actions. In this work, we present DynaMem, a new approach to open-world mobile manipulation that uses a dynamic spatio-semantic memory to represent a robot's environment. DynaMem constructs a 3D data structure to maintain a dynamic memory of point clouds, and answers open-vocabulary object localization queries using multimodal LLMs or open-vocabulary features generated by state-of-the-art vision-language models. Powered by DynaMem, our robots can explore novel environments, search for objects not found in memory, and continuously update the memory as objects move, appear, or disappear in the scene. We run extensive experiments on the Stretch SE3 robots in three real and nine offline scenes, and achieve an average pick-and-drop success rate of 70% on non-stationary objects, which is more than a 2x improvement over state-of-the-art static systems. Our code as well as our experiment and deployment videos are open sourced and can be found on our project website: https://dynamem.github.io/",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Website: https://dynamem.github.io"
    },
    {
        "paper id": "2411.05006",
        "abstract url": "https://arxiv.org/abs/2411.05006",
        "title": "ProEdit: Simple Progression is All You Need for High-Quality 3D Scene Editing",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "Gaussian splatting"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "This paper proposes ProEdit - a simple yet effective framework for high-quality 3D scene editing guided by diffusion distillation in a novel progressive manner. Inspired by the crucial observation that multi-view inconsistency in scene editing is rooted in the diffusion model's large feasible output space (FOS), our framework controls the size of FOS and reduces inconsistency by decomposing the overall editing task into several subtasks, which are then executed progressively on the scene. Within this framework, we design a difficulty-aware subtask decomposition scheduler and an adaptive 3D Gaussian splatting (3DGS) training strategy, ensuring high quality and efficiency in performing each subtask. Extensive evaluation shows that our ProEdit achieves state-of-the-art results in various scenes and challenging editing tasks, all through a simple framework without any expensive or sophisticated add-ons like distillation losses, components, or training procedures. Notably, ProEdit also provides a new way to control, preview, and select the \"aggressivity\" of editing operation during the editing process.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "NeurIPS 2024. Project Page: https://immortalco.github.io/ProEdit/"
    },
    {
        "paper id": "2411.05051",
        "abstract url": "https://arxiv.org/abs/2411.05051",
        "title": "Intellectual Property Protection for Deep Learning Model and Dataset Intelligence",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "With the growing applications of Deep Learning (DL), especially recent spectacular achievements of Large Language Models (LLMs) such as ChatGPT and LLaMA, the commercial significance of these remarkable models has soared. However, acquiring well-trained models is costly and resource-intensive. It requires a considerable high-quality dataset, substantial investment in dedicated architecture design, expensive computational resources, and efforts to develop technical expertise. Consequently, safeguarding the Intellectual Property (IP) of well-trained models is attracting increasing attention. In contrast to existing surveys overwhelmingly focusing on model IPP mainly, this survey not only encompasses the protection on model level intelligence but also valuable dataset intelligence. Firstly, according to the requirements for effective IPP design, this work systematically summarizes the general and scheme-specific performance evaluation metrics. Secondly, from proactive IP infringement prevention and reactive IP ownership verification perspectives, it comprehensively investigates and analyzes the existing IPP methods for both dataset and model intelligence. Additionally, from the standpoint of training settings, it delves into the unique challenges that distributed settings pose to IPP compared to centralized settings. Furthermore, this work examines various attacks faced by deep IPP techniques. Finally, we outline prospects for promising future directions that may act as a guide for innovative research.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05119",
        "abstract url": "https://arxiv.org/abs/2411.05119",
        "title": "Exploiting the Structure of Two Graphs with Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph neural networks (GNNs) have emerged as a promising solution to deal with unstructured data, outperforming traditional deep learning architectures. However, most of the current GNN models are designed to work with a single graph, which limits their applicability in many real-world scenarios where multiple graphs may be involved. To address this limitation, we propose a novel graph-based deep learning architecture to handle tasks where two sets of signals exist, each defined on a different graph. First we consider the setting where the input is represented as a signal on top of one graph (input graph) and the output is a graph signal defined over a different graph (output graph). For this setup, we propose a three-block architecture where we first process the input data using a GNN that operates over the input graph, then apply a transformation function that operates in a latent space and maps the signals from the input to the output graph, and finally implement a second GNN that operates over the output graph. Our goal is not to propose a single specific definition for each of the three blocks, but rather to provide a flexible approach to solve tasks involving data defined on two graphs. The second part of the paper addresses a self-supervised setup, where the focus is not on the output space but on the underlying latent space and, inspired by Canonical Correlation Analysis, we seek informative representations of the data that can be leveraged to solve a downstream task. By leveraging information from multiple graphs, the proposed architecture can capture more intricate relationships between different entities in the data. We test this in several experimental setups using synthetic and real world datasets, and observe that the proposed architecture works better than traditional deep learning architectures, showcasing the importance of leveraging the information of the two graphs.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05189",
        "abstract url": "https://arxiv.org/abs/2411.05189",
        "title": "Adversarial Robustness of In-Context Learning in Transformers for Linear Regression",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformers have demonstrated remarkable in-context learning capabilities across various domains, including statistical learning tasks. While previous work has shown that transformers can implement common learning algorithms, the adversarial robustness of these learned algorithms remains unexplored. This work investigates the vulnerability of in-context learning in transformers to \\textit{hijacking attacks} focusing on the setting of linear regression tasks. Hijacking attacks are prompt-manipulation attacks in which the adversary's goal is to manipulate the prompt to force the transformer to generate a specific output. We first prove that single-layer linear transformers, known to implement gradient descent in-context, are non-robust and can be manipulated to output arbitrary predictions by perturbing a single example in the in-context training set. While our experiments show these attacks succeed on linear transformers, we find they do not transfer to more complex transformers with GPT-2 architectures. Nonetheless, we show that these transformers can be hijacked using gradient-based adversarial attacks. We then demonstrate that adversarial training enhances transformers' robustness against hijacking attacks, even when just applied during finetuning. Additionally, we find that in some settings, adversarial training against a weaker attack model can lead to robustness to a stronger attack model. Lastly, we investigate the transferability of hijacking attacks across transformers of varying scales and initialization seeds, as well as between transformers and ordinary least squares (OLS). We find that while attacks transfer effectively between small-scale transformers, they show poor transferability in other scenarios (small-to-large scale, large-to-large scale, and between transformers and OLS).",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05311",
        "abstract url": "https://arxiv.org/abs/2411.05311",
        "title": "ZOPP: A Framework of Zero-shot Offboard Panoptic Perception for Autonomous Driving",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Offboard perception aims to automatically generate high-quality 3D labels for autonomous driving (AD) scenes. Existing offboard methods focus on 3D object detection with closed-set taxonomy and fail to match human-level recognition capability on the rapidly evolving perception tasks. Due to heavy reliance on human labels and the prevalence of data imbalance and sparsity, a unified framework for offboard auto-labeling various elements in AD scenes that meets the distinct needs of perception tasks is not being fully explored. In this paper, we propose a novel multi-modal Zero-shot Offboard Panoptic Perception (ZOPP) framework for autonomous driving scenes. ZOPP integrates the powerful zero-shot recognition capabilities of vision foundation models and 3D representations derived from point clouds. To the best of our knowledge, ZOPP represents a pioneering effort in the domain of multi-modal panoptic perception and auto labeling for autonomous driving scenes. We conduct comprehensive empirical studies and evaluations on Waymo open dataset to validate the proposed ZOPP on various perception tasks. To further explore the usability and extensibility of our proposed ZOPP, we also conduct experiments in downstream applications. The results further demonstrate the great potential of our ZOPP for real-world scenarios.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2411.05857",
        "abstract url": "https://arxiv.org/abs/2411.05857",
        "title": "Financial Fraud Detection using Jump-Attentive Graph Neural Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As the availability of financial services online continues to grow, the incidence of fraud has surged correspondingly. Fraudsters continually seek new and innovative ways to circumvent the detection algorithms in place. Traditionally, fraud detection relied on rule-based methods, where rules were manually created based on transaction data features. However, these techniques soon became ineffective due to their reliance on manual rule creation and their inability to detect complex data patterns. Today, a significant portion of the financial services sector employs various machine learning algorithms, such as XGBoost, Random Forest, and neural networks, to model transaction data. While these techniques have proven more efficient than rule-based methods, they still fail to capture interactions between different transactions and their interrelationships. Recently, graph-based techniques have been adopted for financial fraud detection, leveraging graph topology to aggregate neighborhood information of transaction data using Graph Neural Networks (GNNs). Despite showing improvements over previous methods, these techniques still struggle to keep pace with the evolving camouflaging tactics of fraudsters and suffer from information loss due to over-smoothing. In this paper, we propose a novel algorithm that employs an efficient neighborhood sampling method, effective for camouflage detection and preserving crucial feature information from non-similar nodes. Additionally, we introduce a novel GNN architecture that utilizes attention mechanisms and preserves holistic neighborhood information to prevent information loss. We test our algorithm on financial data to show that our method outperforms other state-of-the-art graph algorithms.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "International Conference on Machine Learning and Applications 2024"
    },
    {
        "paper id": "2411.05859",
        "abstract url": "https://arxiv.org/abs/2411.05859",
        "title": "Enhancing Financial Fraud Detection with Human-in-the-Loop Feedback and Feedback Propagation",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Human-in-the-loop (HITL) feedback mechanisms can significantly enhance machine learning models, particularly in financial fraud detection, where fraud patterns change rapidly, and fraudulent nodes are sparse. Even small amounts of feedback from Subject Matter Experts (SMEs) can notably boost model performance. This paper examines the impact of HITL feedback on both traditional and advanced techniques using proprietary and publicly available datasets. Our results show that HITL feedback improves model accuracy, with graph-based techniques benefiting the most. We also introduce a novel feedback propagation method that extends feedback across the dataset, further enhancing detection accuracy. By leveraging human expertise, this approach addresses challenges related to evolving fraud patterns, data sparsity, and model interpretability, ultimately improving model robustness and streamlining the annotation process.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE"
        ],
        "comment": "International Conference on Machine Learning and Applications 2024"
    },
    {
        "paper id": "2411.05874",
        "abstract url": "https://arxiv.org/abs/2411.05874",
        "title": "Interplay between Federated Learning and Explainable Artificial Intelligence: a Scoping Review",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The joint implementation of Federated learning (FL) and Explainable artificial intelligence (XAI) will allow training models from distributed data and explaining their inner workings while preserving important aspects of privacy. Towards establishing the benefits and tensions associated with their interplay, this scoping review maps those publications that jointly deal with FL and XAI, focusing on publications where an interplay between FL and model interpretability or post-hoc explanations was found. In total, 37 studies met our criteria, with more papers focusing on explanation methods (mainly feature relevance) than on interpretability (mainly algorithmic transparency). Most works used simulated horizontal FL setups involving 10 or fewer data centers. Only one study explicitly and quantitatively analyzed the influence of FL on model explanations, revealing a significant research gap. Aggregation of interpretability metrics across FL nodes created generalized global insights at the expense of node-specific patterns being diluted. 8 papers addressed the benefits of incorporating explanation methods as a component of the FL algorithm. Studies using established FL libraries or following reporting guidelines are a minority. More quantitative research and structured, transparent practices are needed to fully understand their mutual impact and under which conditions it happens.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "16 pages, 11 figures, submitted in IEEE Trans. Knowledge and Data Engineering"
    },
    {
        "paper id": "2411.04456",
        "abstract url": "https://arxiv.org/abs/2411.04456",
        "title": "Properties of BV-G structures + textures decomposition models. Application to road detection in satellite images",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper we present some theoretical results about a structures-textures image decomposition model which was proposed by the second author. We prove a theorem which gives the behavior of this model in different cases. Finally, as a consequence of the theorem we derive an algorithm for the detection of long and thin objects applied to a road networks detection application in aerial or satellite images.",
        "subjects": [
            "math.FA",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04469",
        "abstract url": "https://arxiv.org/abs/2411.04469",
        "title": "FreeCap: Hybrid Calibration-Free Motion Capture in Open Environments",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose a novel hybrid calibration-free method FreeCap to accurately capture global multi-person motions in open environments. Our system combines a single LiDAR with expandable moving cameras, allowing for flexible and precise motion estimation in a unified world coordinate. In particular, We introduce a local-to-global pose-aware cross-sensor human-matching module that predicts the alignment among each sensor, even in the absence of calibration. Additionally, our coarse-to-fine sensor-expandable pose optimizer further optimizes the 3D human key points and the alignments, it is also capable of incorporating additional cameras to enhance accuracy. Extensive experiments on Human-M3 and FreeMotion datasets demonstrate that our method significantly outperforms state-of-the-art single-modal methods, offering an expandable and efficient solution for multi-person motion capture across various applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04475",
        "abstract url": "https://arxiv.org/abs/2411.04475",
        "title": "Deep Learning Models for UAV-Assisted Bridge Inspection: A YOLO Benchmark Analysis",
        "rating": "-1",
        "keywords": [
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual inspections of bridges are critical to ensure their safety and identify potential failures early. This inspection process can be rapidly and accurately automated by using unmanned aerial vehicles (UAVs) integrated with deep learning models. However, choosing an appropriate model that is lightweight enough to integrate into the UAV and fulfills the strict requirements for inference time and accuracy is challenging. Therefore, our work contributes to the advancement of this model selection process by conducting a benchmark of 23 models belonging to the four newest YOLO variants (YOLOv5, YOLOv6, YOLOv7, YOLOv8) on COCO-Bridge-2021+, a dataset for bridge details detection. Through comprehensive benchmarking, we identify YOLOv8n, YOLOv7tiny, YOLOv6m, and YOLOv6m6 as the models offering an optimal balance between accuracy and processing speed, with mAP@50 scores of 0.803, 0.837, 0.853, and 0.872, and inference times of 5.3ms, 7.5ms, 14.06ms, and 39.33ms, respectively. Our findings accelerate the model selection process for UAVs, enabling more efficient and reliable bridge inspections.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04480",
        "abstract url": "https://arxiv.org/abs/2411.04480",
        "title": "CFPNet: Improving Lightweight ToF Depth Completion via Cross-zone Feature Propagation",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "flight"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Depth completion using lightweight time-of-flight (ToF) depth sensors is attractive due to their low cost. However, lightweight ToF sensors usually have a limited field of view (FOV) compared with cameras. Thus, only pixels in the zone area of the image can be associated with depth signals. Previous methods fail to propagate depth features from the zone area to the outside-zone area effectively, thus suffering from degraded depth completion performance outside the zone. To this end, this paper proposes the CFPNet to achieve cross-zone feature propagation from the zone area to the outside-zone area with two novel modules. The first is a direct-attention-based propagation module (DAPM), which enforces direct cross-zone feature acquisition. The second is a large-kernel-based propagation module (LKPM), which realizes cross-zone feature propagation by utilizing convolution layers with kernel sizes up to 31. CFPNet achieves state-of-the-art (SOTA) depth completion performance by combining these two modules properly, as verified by extensive experimental results on the ZJU-L5 dataset. The code will be made public.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04493",
        "abstract url": "https://arxiv.org/abs/2411.04493",
        "title": "Synergy-Guided Regional Supervision of Pseudo Labels for Semi-Supervised Medical Image Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Semi-supervised learning has received considerable attention for its potential to leverage abundant unlabeled data to enhance model robustness. Pseudo labeling is a widely used strategy in semi supervised learning. However, existing methods often suffer from noise contamination, which can undermine model performance. To tackle this challenge, we introduce a novel Synergy-Guided Regional Supervision of Pseudo Labels (SGRS-Net) framework. Built upon the mean teacher network, we employ a Mix Augmentation module to enhance the unlabeled data. By evaluating the synergy before and after augmentation, we strategically partition the pseudo labels into distinct regions. Additionally, we introduce a Region Loss Evaluation module to assess the loss across each delineated area. Extensive experiments conducted on the LA dataset have demonstrated superior performance over state-of-the-art techniques, underscoring the efficiency and practicality of our framework.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04499",
        "abstract url": "https://arxiv.org/abs/2411.04499",
        "title": "Memory Remedy: An AI-Enhanced Interactive Story Exploring Human-Robot Interaction and Companionship",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "We present our approach to using AI-generated content (AIGC) and multiple media to develop an immersive, game-based, interactive story experience. The narrative of the story, \"Memory Remedy\", unfolds through flashbacks, allowing the audience to gradually uncover the story and the complex relationship between the robot protagonist and the older adults. This exploration explores important themes such as the journey of life, the profound influence of memories, and the concept of post-human emotional care. By engaging with this AIGC-based interactive story, audiences are encouraged to reflect on the potential role of robotic companionship in the lives of older adults in the future; and to encourage deeper reflection on the complex relationship between artificial intelligence and humanity.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "The 17th International Symposium on Visual Information Communication and Interaction (VINCI 2024), December 11--13, 2024, Hsinchu, Taiwan"
    },
    {
        "paper id": "2411.04510",
        "abstract url": "https://arxiv.org/abs/2411.04510",
        "title": "Sliding Mode Roll Control of Active Suspension Electric Vehicles",
        "rating": "-1",
        "keywords": [
            [
                "Vehicle"
            ]
        ],
        "abstract": "Vehicle roll control has been a well studied problem. One of the ubiquitous methods to mitigate vehicle rollover in the automobile industry is via a mechanical anti-roll bar. However with the advent of electric vehicles, rollover mitigation can be pursued using electric actuation. In this work, we study a roll control algorithm using sliding mode control for active suspension vehicles, where the actuation for the roll control signal is generated by electric motors independently at the four corners of the vehicle. This technology precludes the need for any mechanical actuation which is often slower as well as any anti-roll bar to mitigate vehicle rollover situations. We provide an implementation of the proposed algorithm and conduct numerical experiments to validate the functionality and effectiveness. Specifically, we perform Slalom and J-turn maneuvering tests on an active suspension electric vehicle with sliding model roll control and it is shown to mitigate rollover by atleast 50$\\%$ compared to passive suspension vehicles, while simultaneously maintaining rider comfort.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04517",
        "abstract url": "https://arxiv.org/abs/2411.04517",
        "title": "Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic",
        "rating": "-1",
        "keywords": [
            [
                "Sign Language",
                "facial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Sign languages are the language of hearing-impaired people who use visuals like the hand, facial, and body movements for communication. There are different signs and gestures representing alphabets, words, and phrases. Nowadays approximately 300 sign languages are being practiced worldwide such as American Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language (ISL), and many more. Sign languages are dependent on the vocal language of a place. Unlike vocal or spoken languages, there are no helping words in sign language like is, am, are, was, were, will, be, etc. As only a limited population is well-versed in sign language, this lack of familiarity of sign language hinders hearing-impaired people from communicating freely and easily with everyone. This issue can be addressed by a sign language recognition (SLR) system which has the capability to translate the sign language into vocal language. In this paper, a continuous SLR system is proposed using a deep learning model employing Long Short-Term Memory (LSTM), trained and tested on an ISL primary dataset. This dataset is created using MediaPipe Holistic pipeline for tracking face, hand, and body movements and collecting landmarks. The system recognizes the signs and gestures in real-time with 88.23% accuracy.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.MM"
        ],
        "comment": "14 pages, 4 figures, Wireless Pers Commun"
    },
    {
        "paper id": "2411.04519",
        "abstract url": "https://arxiv.org/abs/2411.04519",
        "title": "l0-Regularized Sparse Coding-based Interpretable Network for Multi-Modal Image Fusion",
        "rating": "-1",
        "keywords": [
            [
                "thermal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal image fusion (MMIF) enhances the information content of the fused image by combining the unique as well as common features obtained from different modality sensor images, improving visualization, object detection, and many more tasks. In this work, we introduce an interpretable network for the MMIF task, named FNet, based on an l0-regularized multi-modal convolutional sparse coding (MCSC) model. Specifically, for solving the l0-regularized CSC problem, we develop an algorithm unrolling-based l0-regularized sparse coding (LZSC) block. Given different modality source images, FNet first separates the unique and common features from them using the LZSC block and then these features are combined to generate the final fused image. Additionally, we propose an l0-regularized MCSC model for the inverse fusion process. Based on this model, we introduce an interpretable inverse fusion network named IFNet, which is utilized during FNet's training. Extensive experiments show that FNet achieves high-quality fusion results across five different MMIF tasks. Furthermore, we show that FNet enhances downstream object detection in visible-thermal image pairs. We have also visualized the intermediate results of FNet, which demonstrates the good interpretability of our network.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04546",
        "abstract url": "https://arxiv.org/abs/2411.04546",
        "title": "Analytical Derivatives for Efficient Mechanical Simulations of Hybrid Soft Rigid Robots",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Algorithms that use derivatives of governing equations have accelerated rigid robot simulations and improved their accuracy, enabling the modeling of complex, real-world capabilities. However, extending these methods to soft and hybrid soft-rigid robots is significantly more challenging due to the complexities in modeling continuous deformations inherent in soft bodies. A considerable number of soft robots and the deformable links of hybrid robots can be effectively modeled as slender rods. The Geometric Variable Strain (GVS) model, which employs the screw theory and the strain parameterization of the Cosserat rod, extends the rod theory to model hybrid soft-rigid robots within the same mathematical framework. Using the Recursive Newton-Euler Algorithm, we developed the analytical derivatives of the governing equations of the GVS model. These derivatives facilitate the implicit integration of dynamics and provide the analytical Jacobian of the statics residue, ensuring fast and accurate computations. We applied these derivatives to the mechanical simulations of six common robotic systems: a soft cable-driven manipulator, a hybrid serial robot, a fin-ray finger, a hybrid parallel robot, a contact scenario, and an underwater hybrid mobile robot. Simulation results demonstrate substantial improvements in computational efficiency, with speed-ups of up to three orders of magnitude. We validate the model by comparing simulations done with and without analytical derivatives. Beyond static and dynamic simulations, the techniques discussed in this paper hold the potential to revolutionize the analysis, control, and optimization of hybrid robotic systems for real-world applications.",
        "subjects": [
            "cs.RO",
            "physics.app-ph"
        ],
        "comment": "27 pages including appendix, 17 figures"
    },
    {
        "paper id": "2411.04584",
        "abstract url": "https://arxiv.org/abs/2411.04584",
        "title": "PASSION for Dermatology: Bridging the Diversity Gap with Pigmented Skin Images from Sub-Saharan Africa",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Africa faces a huge shortage of dermatologists, with less than one per million people. This is in stark contrast to the high demand for dermatologic care, with 80% of the paediatric population suffering from largely untreated skin conditions. The integration of AI into healthcare sparks significant hope for treatment accessibility, especially through the development of AI-supported teledermatology. Current AI models are predominantly trained on white-skinned patients and do not generalize well enough to pigmented patients. The PASSION project aims to address this issue by collecting images of skin diseases in Sub-Saharan countries with the aim of open-sourcing this data. This dataset is the first of its kind, consisting of 1,653 patients for a total of 4,901 images. The images are representative of telemedicine settings and encompass the most common paediatric conditions: eczema, fungals, scabies, and impetigo. We also provide a baseline machine learning model trained on the dataset and a detailed performance analysis for the subpopulations represented in the dataset. The project website can be found at https://passionderm.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "MICCAI 2024"
    },
    {
        "paper id": "2411.04588",
        "abstract url": "https://arxiv.org/abs/2411.04588",
        "title": "Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction",
        "rating": "-1",
        "keywords": [
            [
                "Grammatical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Natural language processing (NLP) utilizes text data augmentation to overcome sample size constraints. Increasing the sample size is a natural and widely used strategy for alleviating these challenges. In this study, we chose Arabic to increase the sample size and correct grammatical errors. Arabic is considered one of the languages with limited resources for grammatical error correction (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used in most Arabic grammatical error correction research, with approximately 20,500 parallel examples, which is considered low compared with other languages. Therefore, this study aims to develop an Arabic corpus called \"Tibyan\" for grammatical error correction using ChatGPT. ChatGPT is used as a data augmenter tool based on a pair of Arabic sentences containing grammatical errors matched with a sentence free of errors extracted from Arabic books, called guide sentences. Multiple steps were involved in establishing our corpus, including the collection and pre-processing of a pair of Arabic texts from various sources, such as books and open-access corpora. We then used ChatGPT to generate a parallel corpus based on the text collected previously, as a guide for generating sentences with multiple types of errors. By engaging linguistic experts to review and validate the automatically generated sentences, we ensured that they were correct and error-free. The corpus was validated and refined iteratively based on feedback provided by linguistic experts to improve its accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to analyze the types of errors in the Tibyan corpus. Our corpus contained 49 of errors, including seven types: orthography, morphology, syntax, semantics, punctuation, merge, and split. The Tibyan corpus contains approximately 600 K tokens.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "17 pages, 11 figures"
    },
    {
        "paper id": "2411.04595",
        "abstract url": "https://arxiv.org/abs/2411.04595",
        "title": "TexLiverNet: Leveraging Medical Knowledge and Spatial-Frequency Perception for Enhanced Liver Tumor Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "Tumor",
                "lesion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Integrating textual data with imaging in liver tumor segmentation is essential for enhancing diagnostic accuracy. However, current multi-modal medical datasets offer only general text annotations, lacking lesion-specific details critical for extracting nuanced features, especially for fine-grained segmentation of tumor boundaries and small lesions. To address these limitations, we developed datasets with lesion-specific text annotations for liver tumors and introduced the TexLiverNet model. TexLiverNet employs an agent-based cross-attention module that integrates text features efficiently with visual features, significantly reducing computational costs. Additionally, enhanced spatial and adaptive frequency domain perception is proposed to precisely delineate lesion boundaries, reduce background interference, and recover fine details in small lesions. Comprehensive evaluations on public and private datasets demonstrate that TexLiverNet achieves superior performance compared to current state-of-the-art methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04598",
        "abstract url": "https://arxiv.org/abs/2411.04598",
        "title": "Social EgoMesh Estimation",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurately estimating the 3D pose of the camera wearer in egocentric video sequences is crucial to modeling human behavior in virtual and augmented reality applications. The task presents unique challenges due to the limited visibility of the user's body caused by the front-facing camera mounted on their head. Recent research has explored the utilization of the scene and ego-motion, but it has overlooked humans' interactive nature. We propose a novel framework for Social Egocentric Estimation of body MEshes (SEE-ME). Our approach is the first to estimate the wearer's mesh using only a latent probabilistic diffusion model, which we condition on the scene and, for the first time, on the social wearer-interactee interactions. Our in-depth study sheds light on when social interaction matters most for ego-mesh estimation; it quantifies the impact of interpersonal distance and gaze direction. Overall, SEE-ME surpasses the current best technique, reducing the pose estimation error (MPJPE) by 53%. The code is available at https://github.com/L-Scofano/SEEME.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04607",
        "abstract url": "https://arxiv.org/abs/2411.04607",
        "title": "Cross- and Intra-image Prototypical Learning for Multi-label Disease Diagnosis and Interpretation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "Diagnosis",
                "Disease",
                "pathological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in prototypical learning have shown remarkable potential to provide useful decision interpretations associating activation maps and predictions with class-specific training prototypes. Such prototypical learning has been well-studied for various single-label diseases, but for quite relevant and more challenging multi-label diagnosis, where multiple diseases are often concurrent within an image, existing prototypical learning models struggle to obtain meaningful activation maps and effective class prototypes due to the entanglement of the multiple diseases. In this paper, we present a novel Cross- and Intra-image Prototypical Learning (CIPL) framework, for accurate multi-label disease diagnosis and interpretation from medical images. CIPL takes advantage of common cross-image semantics to disentangle the multiple diseases when learning the prototypes, allowing a comprehensive understanding of complicated pathological lesions. Furthermore, we propose a new two-level alignment-based regularisation strategy that effectively leverages consistent intra-image information to enhance interpretation robustness and predictive performance. Extensive experiments show that our CIPL attains the state-of-the-art (SOTA) classification accuracy in two public multi-label benchmarks of disease diagnosis: thoracic radiography and fundus images. Quantitative interpretability results show that CIPL also has superiority in weakly-supervised thoracic disease localisation over other leading saliency- and prototype-based explanation methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04620",
        "abstract url": "https://arxiv.org/abs/2411.04620",
        "title": "Multi-temporal crack segmentation in concrete structure using deep learning approaches",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Cracks are among the earliest indicators of deterioration in concrete structures. Early automatic detection of these cracks can significantly extend the lifespan of critical infrastructures, such as bridges, buildings, and tunnels, while simultaneously reducing maintenance costs and facilitating efficient structural health monitoring. This study investigates whether leveraging multi-temporal data for crack segmentation can enhance segmentation quality. Therefore, we compare a Swin UNETR trained on multi-temporal data with a U-Net trained on mono-temporal data to assess the effect of temporal information compared with conventional single-epoch approaches. To this end, a multi-temporal dataset comprising 1356 images, each with 32 sequential crack propagation images, was created. After training the models, experiments were conducted to analyze their generalization ability, temporal consistency, and segmentation quality. The multi-temporal approach consistently outperformed its mono-temporal counterpart, achieving an IoU of $82.72\\%$ and a F1-score of $90.54\\%$, representing a significant improvement over the mono-temporal model's IoU of $76.69\\%$ and F1-score of $86.18\\%$, despite requiring only half of the trainable parameters. The multi-temporal model also displayed a more consistent segmentation quality, with reduced noise and fewer errors. These results suggest that temporal information significantly enhances the performance of segmentation models, offering a promising solution for improved crack detection and the long-term monitoring of concrete structures, even with limited sequential data.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04632",
        "abstract url": "https://arxiv.org/abs/2411.04632",
        "title": "Improved Multi-Task Brain Tumour Segmentation with Synthetic Data Augmentation",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents the winning solution of task 1 and the third-placed solution of task 3 of the BraTS challenge. The use of automated tools in clinical practice has increased due to the development of more and more sophisticated and reliable algorithms. However, achieving clinical standards and developing tools for real-life scenarios is a major challenge. To this end, BraTS has organised tasks to find the most advanced solutions for specific purposes. In this paper, we propose the use of synthetic data to train state-of-the-art frameworks in order to improve the segmentation of adult gliomas in a post-treatment scenario, and the segmentation of meningioma for radiotherapy planning. Our results suggest that the use of synthetic data leads to more robust algorithms, although the synthetic data generation pipeline is not directly suited to the meningioma task. The code for these tasks is available at https://github.com/ShadowTwin41/BraTS_2023_2024_solutions.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04656",
        "abstract url": "https://arxiv.org/abs/2411.04656",
        "title": "ICH-SCNet: Intracerebral Hemorrhage Segmentation and Prognosis Classification Network Using CLIP-guided SAM mechanism",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Intracerebral hemorrhage (ICH) is the most fatal subtype of stroke and is characterized by a high incidence of disability. Accurate segmentation of the ICH region and prognosis prediction are critically important for developing and refining treatment plans for post-ICH patients. However, existing approaches address these two tasks independently and predominantly focus on imaging data alone, thereby neglecting the intrinsic correlation between the tasks and modalities. This paper introduces a multi-task network, ICH-SCNet, designed for both ICH segmentation and prognosis classification. Specifically, we integrate a SAM-CLIP cross-modal interaction mechanism that combines medical text and segmentation auxiliary information with neuroimaging data to enhance cross-modal feature recognition. Additionally, we develop an effective feature fusion module and a multi-task loss function to improve performance further. Extensive experiments on an ICH dataset reveal that our approach surpasses other state-of-the-art methods. It excels in the overall performance of classification tasks and outperforms competing models in all segmentation task metrics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 2 figures, 3 tables, published to BIBM 2024"
    },
    {
        "paper id": "2411.04659",
        "abstract url": "https://arxiv.org/abs/2411.04659",
        "title": "Automated Image Color Mapping for a Historic Photographic Collection",
        "rating": "-1",
        "keywords": [
            [
                "chemistry"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the 1970s, the United States Environmental Protection Agency sponsored Documerica, a large-scale photography initiative to document environmental subjects nation-wide. While over 15,000 digitized public-domain photographs from the collection are available online, most of the images were scanned from damaged copies of the original prints. We present and evaluate a modified histogram matching technique based on the underlying chemistry of the prints for correcting the damaged images by using training data collected from a small set of undamaged prints. The entire set of color-adjusted Documerica images is made available in an open repository.",
        "subjects": [
            "cs.CV",
            "stat.AP"
        ],
        "comment": "11 pages, CHR 2024: Computational Humanities Research Conference, December 4 - 6, 2024, Aarhus University, Denmark"
    },
    {
        "paper id": "2411.04663",
        "abstract url": "https://arxiv.org/abs/2411.04663",
        "title": "Explainable Search and Discovery of Visual Cultural Heritage Collections with Multimodal Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Many cultural institutions have made large digitized visual collections available online, often under permissible re-use licences. Creating interfaces for exploring and searching these collections is difficult, particularly in the absence of granular metadata. In this paper, we introduce a method for using state-of-the-art multimodal large language models (LLMs) to enable an open-ended, explainable search and discovery interface for visual collections. We show how our approach can create novel clustering and recommendation systems that avoid common pitfalls of methods based directly on visual embeddings. Of particular interest is the ability to offer concrete textual explanations of each recommendation without the need to preselect the features of interest. Together, these features can create a digital interface that is more open-ended and flexible while also being better suited to addressing privacy and ethical concerns. Through a case study using a collection of documentary photographs, we provide several metrics showing the efficacy and possibilities of our approach.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "16 pages, CHR 2024: Computational Humanities Research Conference, December 4 - 6, 2024, Aarhus University, Denmark"
    },
    {
        "paper id": "2411.04678",
        "abstract url": "https://arxiv.org/abs/2411.04678",
        "title": "Socially-Aware Opinion-Based Navigation with Oval Limit Cycles",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "When humans move in a shared space, they choose navigation strategies that preserve their mutual safety. At the same time, each human seeks to minimise the number of modifications to her/his path. In order to achieve this result, humans use unwritten rules and reach a consensus on their decisions about the motion direction by exchanging non-verbal messages. They then implement their choice in a mutually acceptable way. Socially-aware navigation denotes a research effort aimed at replicating this logic inside robots. Existing results focus either on how robots can participate in negotiations with humans, or on how they can move in a socially acceptable way. We propose a holistic approach in which the two aspects are jointly considered. Specifically, we show that by combining opinion dynamics (to reach a consensus) with vortex fields (to generate socially acceptable trajectories), the result outperforms the application of the two techniques in isolation.",
        "subjects": [
            "cs.RO",
            "cs.MA"
        ],
        "comment": "7 pages, 6 figures, submitted to ICRA 2025"
    },
    {
        "paper id": "2411.04718",
        "abstract url": "https://arxiv.org/abs/2411.04718",
        "title": "Approximate counting of permutation patterns",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "We consider the problem of counting the copies of a length-$k$ pattern $\u03c3$ in a sequence $f \\colon [n] \\to \\mathbb{R}$, where a copy is a subset of indices $i_1 < \\ldots < i_k \\in [n]$ such that $f(i_j) < f(i_\\ell)$ if and only if $\u03c3(j) < \u03c3(\\ell)$. This problem is motivated by a range of connections and applications in ranking, nonparametric statistics, combinatorics, and fine-grained complexity, especially when $k$ is a small fixed constant. Recent advances have significantly improved our understanding of counting and detecting patterns. Guillemot and Marx [2014] demonstrated that the detection variant is solvable in $O(n)$ time for any fixed $k$. Their proof has laid the foundations for the discovery of the twin-width, a concept that has notably advanced parameterized complexity in recent years. Counting, in contrast, is harder: it has a conditional lower bound of $n^{\u03a9(k / \\log k)}$ [Berendsohn, Kozma, and Marx 2019] and is expected to be polynomially harder than detection as early as $k = 4$, given its equivalence to counting $4$-cycles in graphs [Dudek and Gawrychowski, 2020]. In this work, we design a deterministic near-linear time $(1+\\varepsilon)$-approximation algorithm for counting $\u03c3$-copies in $f$ for all $k \\leq 5$. Combined with the conditional lower bound for $k=4$, this establishes the first known separation between approximate and exact algorithms for pattern counting. Interestingly, our algorithm leverages the Birg\u00e9 decomposition -- a sublinear tool for monotone distributions widely used in distribution testing -- which, to our knowledge, has not been applied in a pattern counting context before.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04724",
        "abstract url": "https://arxiv.org/abs/2411.04724",
        "title": "Controlling Human Shape and Pose in Text-to-Image Diffusion Models via Domain Adaptation",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present a methodology for conditional control of human shape and pose in pretrained text-to-image diffusion models using a 3D human parametric model (SMPL). Fine-tuning these diffusion models to adhere to new conditions requires large datasets and high-quality annotations, which can be more cost-effectively acquired through synthetic data generation rather than real-world data. However, the domain gap and low scene diversity of synthetic data can compromise the pretrained model's visual fidelity. We propose a domain-adaptation technique that maintains image quality by isolating synthetically trained conditional information in the classifier-free guidance vector and composing it with another control network to adapt the generated images to the input domain. To achieve SMPL control, we fine-tune a ControlNet-based architecture on the synthetic SURREAL dataset of rendered humans and apply our domain adaptation at generation time. Experiments demonstrate that our model achieves greater shape and pose diversity than the 2d pose-based ControlNet, while maintaining the visual fidelity and improving stability, proving its usefulness for downstream tasks such as human animation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04735",
        "abstract url": "https://arxiv.org/abs/2411.04735",
        "title": "Learning from Demonstration with Hierarchical Policy Abstractions Toward High-Performance and Courteous Autonomous Racing",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "Fully autonomous racing demands not only high-speed driving but also fair and courteous maneuvers. In this paper, we propose an autonomous racing framework that learns complex racing behaviors from expert demonstrations using hierarchical policy abstractions. At the trajectory level, our policy model predicts a dense distribution map indicating the likelihood of trajectories learned from offline demonstrations. The maximum likelihood trajectory is then passed to the control-level policy, which generates control inputs in a residual fashion, considering vehicle dynamics at the limits of performance. We evaluate our framework in a high-fidelity racing simulator and compare it against competing baselines in challenging multi-agent adversarial scenarios. Quantitative and qualitative results show that our trajectory planning policy significantly outperforms the baselines, and the residual control policy improves lap time and tracking accuracy. Moreover, challenging closed-loop experiments with ten opponents show that our framework can overtake other vehicles by understanding nuanced interactions, effectively balancing performance and courtesy like professional drivers.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 8 figures"
    },
    {
        "paper id": "2411.04752",
        "abstract url": "https://arxiv.org/abs/2411.04752",
        "title": "RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced Code-Mixed Information Retrieval",
        "rating": "-1",
        "keywords": [
            [
                "grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Code-mixing, the integration of lexical and grammatical elements from multiple languages within a single sentence, is a widespread linguistic phenomenon, particularly prevalent in multilingual societies. In India, social media users frequently engage in code-mixed conversations using the Roman script, especially among migrant communities who form online groups to share relevant local information. This paper focuses on the challenges of extracting relevant information from code-mixed conversations, specifically within Roman transliterated Bengali mixed with English. This study presents a novel approach to address these challenges by developing a mechanism to automatically identify the most relevant answers from code-mixed conversations. We have experimented with a dataset comprising of queries and documents from Facebook, and Query Relevance files (QRels) to aid in this task. Our results demonstrate the effectiveness of our approach in extracting pertinent information from complex, code-mixed digital conversations, contributing to the broader field of natural language processing in multilingual and informal text environments. We use GPT-3.5 Turbo via prompting alongwith using the sequential nature of relevant documents to frame a mathematical model which helps to detect relevant documents corresponding to a query.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at FIRE 2024 (Track: Code-Mixed Information Retrieval from Social Media Data)"
    },
    {
        "paper id": "2411.04776",
        "abstract url": "https://arxiv.org/abs/2411.04776",
        "title": "TacEx: GelSight Tactile Simulation in Isaac Sim -- Combining Soft-Body and Visuotactile Simulators",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Training robot policies in simulation is becoming increasingly popular; nevertheless, a precise, reliable, and easy-to-use tactile simulator for contact-rich manipulation tasks is still missing. To close this gap, we develop TacEx -- a modular tactile simulation framework. We embed a state-of-the-art soft-body simulator for contacts named GIPC and vision-based tactile simulators Taxim and FOTS into Isaac Sim to achieve robust and plausible simulation of the visuotactile sensor GelSight Mini. We implement several Isaac Lab environments for Reinforcement Learning (RL) leveraging our TacEx simulation, including object pushing, lifting, and pole balancing. We validate that the simulation is stable and that the high-dimensional observations, such as the gel deformation and the RGB images from the GelSight camera, can be used for training. The code, videos, and additional results will be released online https://sites.google.com/view/tacex.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "11 pages, accepted at \"CoRL Workshop on Learning Robot Fine and Dexterous Manipulation: Perception and Control\""
    },
    {
        "paper id": "2411.04782",
        "abstract url": "https://arxiv.org/abs/2411.04782",
        "title": "An Effective Pipeline for Whole-Slide Image Glomerulus Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "diagnosing",
                "Whole-Slide"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Whole-slide images (WSI) glomerulus segmentation is essential for accurately diagnosing kidney diseases. In this work, we propose a practical pipeline for glomerulus segmentation that effectively enhances both patch-level and WSI-level segmentation tasks. Our approach leverages stitching on overlapping patches, increasing the detection coverage, especially when glomeruli are located near patch image borders. In addition, we conduct comprehensive evaluations from different segmentation models across two large and diverse datasets with over 30K glomerulus annotations. Experimental results demonstrate that models using our pipeline outperform the previous state-of-the-art method, achieving superior results across both datasets and setting a new benchmark for glomerulus segmentation in WSIs. The code and pre-trained models are available at https://github.com/huuquan1994/wsi_glomerulus_seg.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04791",
        "abstract url": "https://arxiv.org/abs/2411.04791",
        "title": "A Continuification-Based Control Solution for Large-Scale Shepherding",
        "rating": "-1",
        "keywords": [
            [
                "robotics"
            ]
        ],
        "abstract": "In this paper, we address the large-scale shepherding control problem using a continuification-based strategy. We consider a scenario in which a large group of follower agents (targets) must be confined within a designated goal region through indirect interactions with a controllable set of leader agents (herders). Our approach transforms the microscopic agent-based dynamics into a macroscopic continuum model via partial differential equations (PDEs). This formulation enables efficient, scalable control design for the herders' behavior, with guarantees of global convergence. Numerical and experimental validations in a mixed-reality swarm robotics framework demonstrate the method's effectiveness.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04813",
        "abstract url": "https://arxiv.org/abs/2411.04813",
        "title": "LuxBank: The First Universal Dependency Treebank for Luxembourgish",
        "rating": "-1",
        "keywords": [
            [
                "grammar"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The Universal Dependencies (UD) project has significantly expanded linguistic coverage across 161 languages, yet Luxembourgish, a West Germanic language spoken by approximately 400,000 people, has remained absent until now. In this paper, we introduce LuxBank, the first UD Treebank for Luxembourgish, addressing the gap in syntactic annotation and analysis for this `low-research' language. We establish formal guidelines for Luxembourgish language annotation, providing the foundation for the first large-scale quantitative analysis of its syntax. LuxBank serves not only as a resource for linguists and language learners but also as a tool for developing spell checkers and grammar checkers, organising existing text archives and even training large language models. By incorporating Luxembourgish into the UD framework, we aim to enhance the understanding of syntactic variation within West Germanic languages and offer a model for documenting smaller, semi-standardised languages. This work positions Luxembourgish as a valuable resource in the broader linguistic and NLP communities, contributing to the study of languages with limited research and resources.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at 22nd Workshop on Treebanks and Linguistic Theories (TLT 2024)"
    },
    {
        "paper id": "2411.04822",
        "abstract url": "https://arxiv.org/abs/2411.04822",
        "title": "When Does Classical Chinese Help? Quantifying Cross-Lingual Transfer in Hanja and Kanbun",
        "rating": "-1",
        "keywords": [
            [
                "named entity recognition"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Historical and linguistic connections within the Sinosphere have led researchers to use Classical Chinese resources for cross-lingual transfer when processing historical documents from Korea and Japan. In this paper, we question the assumption of cross-lingual transferability from Classical Chinese to Hanja and Kanbun, the ancient written languages of Korea and Japan, respectively. Our experiments across machine translation, named entity recognition, and punctuation restoration tasks show minimal impact of Classical Chinese datasets on language model performance for ancient Korean documents written in Hanja, with performance differences within $\\pm{}0.0068$ F1-score for sequence labeling tasks and up to $+0.84$ BLEU score for translation. These limitations persist consistently across various model sizes, architectures, and domain-specific datasets. Our analysis reveals that the benefits of Classical Chinese resources diminish rapidly as local language data increases for Hanja, while showing substantial improvements only in extremely low-resource scenarios for both Korean and Japanese historical documents. These mixed results emphasize the need for careful empirical validation rather than assuming benefits from indiscriminate cross-lingual transfer.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04826",
        "abstract url": "https://arxiv.org/abs/2411.04826",
        "title": "D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Depth estimation is a crucial technology in robotics. Recently, self-supervised depth estimation methods have demonstrated great potential as they can efficiently leverage large amounts of unlabelled real-world data. However, most existing methods are designed under the assumption of static scenes, which hinders their adaptability in dynamic environments. To address this issue, we present D$^3$epth, a novel method for self-supervised depth estimation in dynamic scenes. It tackles the challenge of dynamic objects from two key perspectives. First, within the self-supervised framework, we design a reprojection constraint to identify regions likely to contain dynamic objects, allowing the construction of a dynamic mask that mitigates their impact at the loss level. Second, for multi-frame depth estimation, we introduce a cost volume auto-masking strategy that leverages adjacent frames to identify regions associated with dynamic objects and generate corresponding masks. This provides guidance for subsequent processes. Furthermore, we propose a spectral entropy uncertainty module that incorporates spectral entropy to guide uncertainty estimation during depth fusion, effectively addressing issues arising from cost volume computation in dynamic environments. Extensive experiments on KITTI and Cityscapes datasets demonstrate that the proposed method consistently outperforms existing self-supervised monocular depth estimation baselines. Code is available at \\url{https://github.com/Csyunling/D3epth}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Open sourced"
    },
    {
        "paper id": "2411.04846",
        "abstract url": "https://arxiv.org/abs/2411.04846",
        "title": "On the Complexity of 2-club Cluster Editing with Vertex Splitting",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Editing a graph to obtain a disjoint union of s-clubs is one of the models for correlation clustering, which seeks a partition of the vertex set of a graph so that elements of each resulting set are close enough according to some given criterion. For example, in the case of editing into s-clubs, the criterion is proximity since any pair of vertices (in an s-club) are within a distance of s from each other. In this work we consider the vertex splitting operation, which allows a vertex to belong to more than one cluster. This operation was studied as one of the parameters associated with the Cluster Editing problem. We study the complexity and parameterized complexity of the s-Club Cluster Edge Deletion with Vertex Splitting and s-Club Cluster Vertex Splitting problems. Both problems are shown to be NP-Complete and APX-hard. On the positive side, we show that both problems are Fixed-Parameter Tractable with respect to the number of allowed editing operations and that s-Club Cluster Vertex Splitting is solvable in polynomial-time on the class of forests.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04862",
        "abstract url": "https://arxiv.org/abs/2411.04862",
        "title": "Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models",
        "rating": "-1",
        "keywords": [
            [
                "Song"
            ],
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Title: Sentiment Analysis of Spanish Political Party Communications on Twitter Using Pre-trained Language Models Authors: Chuqiao Song, Shunzhang Chen, Xinyi Cai, Hao Chen Comments: 21 pages, 6 figures Abstract: This study investigates sentiment patterns within Spanish political party communications on Twitter by leveraging BETO and RoBERTuito, two pre-trained language models optimized for Spanish text. Using a dataset of tweets from major Spanish political parties: PSOE, PP, Vox, Podemos, and Ciudadanos, spanning 2019 to 2024, this research analyzes sentiment distributions and explores the relationship between sentiment expression and party ideology. The findings indicate that both models consistently identify a predominant Neutral sentiment across all parties, with significant variations in Negative and Positive sentiments that align with ideological distinctions. Specifically, Vox exhibits higher levels of Negative sentiment, while PSOE demonstrates relatively high Positive sentiment, supporting the hypothesis that emotional appeals in political messaging reflect ideological stances. This study underscores the potential of pre-trained language models for non-English sentiment analysis on social media, providing insights into sentiment dynamics that shape public discourse within Spain's multi-party political system. Keywords: Spanish politics, sentiment analysis, pre-trained language models, Twitter, BETO, RoBERTuito, political ideology, multi-party system",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "comment": "21 pages, 6 figures"
    },
    {
        "paper id": "2411.04975",
        "abstract url": "https://arxiv.org/abs/2411.04975",
        "title": "SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference",
        "rating": "-1",
        "keywords": [
            [
                "SQL"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We present SuffixDecoding, a novel model-free approach to accelerating large language model (LLM) inference through speculative decoding. Unlike existing methods that rely on draft models or specialized decoding heads, SuffixDecoding leverages suffix trees built from previously generated outputs to efficiently predict candidate token sequences. Our approach enables flexible tree-structured speculation without the overhead of maintaining and orchestrating additional models. SuffixDecoding builds and dynamically updates suffix trees to capture patterns in the generated text, using them to construct speculation trees through a principled scoring mechanism based on empirical token frequencies. SuffixDecoding requires only CPU memory which is plentiful and underutilized on typical LLM serving nodes. We demonstrate that SuffixDecoding achieves competitive speedups compared to model-based approaches across diverse workloads including open-domain chat, code generation, and text-to-SQL tasks. For open-ended chat and code generation tasks, SuffixDecoding achieves up to $1.4\\times$ higher output throughput than SpecInfer and up to $1.1\\times$ lower time-per-token (TPOT) latency. For a proprietary multi-LLM text-to-SQL application, SuffixDecoding achieves up to $2.9\\times$ higher output throughput and $3\\times$ lower latency than speculative decoding. Our evaluation shows that SuffixDecoding maintains high acceptance rates even with small reference corpora of 256 examples, while continuing to improve performance as more historical outputs are incorporated.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04989",
        "abstract url": "https://arxiv.org/abs/2411.04989",
        "title": "SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation",
        "rating": "-1",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Trajectory"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Methods for image-to-video generation have achieved impressive, photo-realistic quality. However, adjusting specific elements in generated videos, such as object motion or camera movement, is often a tedious process of trial and error, e.g., involving re-generating videos with different random seeds. Recent techniques address this issue by fine-tuning a pre-trained model to follow conditioning signals, such as bounding boxes or point trajectories. Yet, this fine-tuning procedure can be computationally expensive, and it requires datasets with annotated object motion, which can be difficult to procure. In this work, we introduce SG-I2V, a framework for controllable image-to-video generation that is self-guided$\\unicode{x2013}$offering zero-shot control by relying solely on the knowledge present in a pre-trained image-to-video diffusion model without the need for fine-tuning or external knowledge. Our zero-shot method outperforms unsupervised baselines while being competitive with supervised models in terms of visual quality and motion fidelity.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project page: https://kmcode1.github.io/Projects/SG-I2V/"
    },
    {
        "paper id": "2411.05001",
        "abstract url": "https://arxiv.org/abs/2411.05001",
        "title": "Analyzing The Language of Visual Tokens",
        "rating": "-1",
        "keywords": [
            [
                "grammatical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "With the introduction of transformer-based models for vision and language tasks, such as LLaVA and Chameleon, there has been renewed interest in the discrete tokenized representation of images. These models often treat image patches as discrete tokens, analogous to words in natural language, learning joint alignments between visual and human languages. However, little is known about the statistical behavior of these visual languages - whether they follow similar frequency distributions, grammatical structures, or topologies as natural languages. In this paper, we take a natural-language-centric approach to analyzing discrete visual languages and uncover striking similarities and fundamental differences. We demonstrate that, although visual languages adhere to Zipfian distributions, higher token innovation drives greater entropy and lower compression, with tokens predominantly representing object parts, indicating intermediate granularity. We also show that visual languages lack cohesive grammatical structures, leading to higher perplexity and weaker hierarchical organization compared to natural languages. Finally, we demonstrate that, while vision models align more closely with natural languages than other models, this alignment remains significantly weaker than the cohesion found within natural languages. Through these experiments, we demonstrate how understanding the statistical properties of discrete visual languages can inform the design of more effective computer vision models.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05057",
        "abstract url": "https://arxiv.org/abs/2411.05057",
        "title": "A Brief History of Named Entity Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Named Entity Recognition"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "A large amount of information in today's world is now stored in knowledge bases. Named Entity Recognition (NER) is a process of extracting, disambiguation, and linking an entity from raw text to insightful and structured knowledge bases. More concretely, it is identifying and classifying entities in the text that are crucial for Information Extraction, Semantic Annotation, Question Answering, Ontology Population, and so on. The process of NER has evolved in the last three decades since it first appeared in 1996. In this survey, we study the evolution of techniques employed for NER and compare the results, starting from supervised to the developing unsupervised learning methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Survey done in 2020"
    },
    {
        "paper id": "2411.05059",
        "abstract url": "https://arxiv.org/abs/2411.05059",
        "title": "FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "There is great interest in fine-tuning frontier large language models (LLMs) to inject new information and update existing knowledge. While commercial LLM fine-tuning APIs from providers such as OpenAI and Google promise flexible adaptation for various applications, the efficacy of fine-tuning remains unclear. In this study, we introduce FineTuneBench, an evaluation framework and dataset for understanding how well commercial fine-tuning APIs can successfully learn new and updated knowledge. We analyze five frontier LLMs with commercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro, on their effectiveness in two settings: (1) ingesting novel information, such as recent news events and new people profiles, and (2) updating existing knowledge, such as updated medical guidelines and code frameworks. Our results reveal substantial shortcomings in all the models' abilities to effectively learn new information through fine-tuning, with an average generalization accuracy of 37% across all models. When updating existing knowledge, such as incorporating medical guideline updates, commercial fine-tuning APIs show even more limited capability (average generalization accuracy of 19%). Overall, fine-tuning GPT-4o mini is the most effective for infusing new knowledge and updating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs for Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or update existing knowledge. These findings underscore a major shortcoming in using current commercial fine-tuning services to achieve reliable knowledge infusion in common scenarios. We open source the FineTuneBench dataset at https://github.com/kevinwu23/StanfordFineTuneBench.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05085",
        "abstract url": "https://arxiv.org/abs/2411.05085",
        "title": "PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation",
        "rating": "-1",
        "keywords": [
            [
                "X-ray",
                "clinical",
                "Radiology"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Radiology report generation (RRG) aims to create free-text radiology reports from clinical imaging. Grounded radiology report generation (GRRG) extends RRG by including the localisation of individual findings on the image. Currently, there are no manually annotated chest X-ray (CXR) datasets to train GRRG models. In this work, we present a dataset called PadChest-GR (Grounded-Reporting) derived from PadChest aimed at training GRRG models for CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with grounded reports (3,099 abnormal and 1,456 normal), each containing complete lists of sentences describing individual present (positive) and absent (negative) findings in English and Spanish. In total, PadChest-GR contains 7,037 positive and 3,422 negative finding sentences. Every positive finding sentence is associated with up to two independent sets of bounding boxes labelled by different readers and has categorical labels for finding type, locations, and progression. To the best of our knowledge, PadChest-GR is the first manually curated dataset designed to train GRRG models for understanding and interpreting radiological images and generated text. By including detailed localization and comprehensive annotations of all clinically relevant findings, it provides a valuable resource for developing and evaluating GRRG models from CXR images. PadChest-GR can be downloaded under request from https://bimcv.cipf.es/bimcv-projects/padchest-gr/",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05091",
        "abstract url": "https://arxiv.org/abs/2411.05091",
        "title": "Watermarking Language Models through Language Models",
        "rating": "-1",
        "keywords": [
            [
                "Watermarking"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a novel framework for watermarking language models through prompts generated by language models. The proposed approach utilizes a multi-model setup, incorporating a Prompting language model to generate watermarking instructions, a Marking language model to embed watermarks within generated content, and a Detecting language model to verify the presence of these watermarks. Experiments are conducted using ChatGPT and Mistral as the Prompting and Marking language models, with detection accuracy evaluated using a pretrained classifier model. Results demonstrate that the proposed framework achieves high classification accuracy across various configurations, with 95% accuracy for ChatGPT, 88.79% for Mistral. These findings validate the and adaptability of the proposed watermarking strategy across different language model architectures. Hence the proposed framework holds promise for applications in content attribution, copyright protection, and model authentication.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05102",
        "abstract url": "https://arxiv.org/abs/2411.05102",
        "title": "EnchantedClothes: Visual and Tactile Feedback with an Abdomen-Attached Robot through Clothes",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Wearable robots are designed to be worn on the human body. Taking advantage of their physical form, various applications for wearable robots are being considered. This study proposes a wearable robot worn on the abdomen and a new interaction with it. Our robot enables a variety of applications related to communication between the wearer and surrounding humans through visual and tactile feedback. The contributions of this research will be (1) the proposal of a novel wearable robot worn on the abdomen and (2) a new interaction with it.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05107",
        "abstract url": "https://arxiv.org/abs/2411.05107",
        "title": "MissionGPT: Mission Planner for Mobile Robot based on Robotics Transformer Model",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "Robot"
            ]
        ],
        "abstract": "This paper presents a novel approach to building mission planners based on neural networks with Transformer architecture and Large Language Models (LLMs). This approach demonstrates the possibility of setting a task for a mobile robot and its successful execution without the use of perception algorithms, based only on the data coming from the camera. In this work, a success rate of more than 50\\% was obtained for one of the basic actions for mobile robots. The proposed approach is of practical importance in the field of warehouse logistics robots, as in the future it may allow to eliminate the use of markings, LiDARs, beacons and other tools for robot orientation in space. In conclusion, this approach can be scaled for any type of robot and for any number of robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05113",
        "abstract url": "https://arxiv.org/abs/2411.05113",
        "title": "Co-Located Magnetic Levitation Haptic and Graphic Display using Iron Core Coils under Screen",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper describes a combined haptic and graphical interactive system in which a grasped handle is levitated and controlled so that its dynamic rigid-body motion and the forces and torques generated upon it match those of a tool in a real-time simulated environment, displayed on a thin screen on top of the levitation coils and underneath the levitated handle. In this augmented reality configuration, the haptic sensations delivered to the hand of the user and the displayed simulation graphics are perceived in the same location, and the graphical display of the tool acts as a virtual extension of the grasped handle into the displayed simulated environment. The novelty of the system is that it combines iron core levitation coils with a low-cost position sensing system and co-located display in a portable system. The high closed-loop control bandwidth and precise position sensing of the system enable interactive simulated environments to be presented with a convincing degree of realism. The interactive environments to be demonstrated will include 3D rigid-body dynamics, surface contacts with stiffness and damping, and surface texture and friction.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05114",
        "abstract url": "https://arxiv.org/abs/2411.05114",
        "title": "STEM: Soft Tactile Electromagnetic Actuator for Virtual Environment Interactions",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "The research aims to expand tactile feedback beyond vibrations to various modes of stimuli, such as indentation, vibration, among others. By incorporating soft material into the design of a novel tactile actuator, we can achieve multi-modality and enhance the device's wearability, which encompasses compliance, safety, and portability. The proposed tactile device can elevate the presence and immersion in VR by enabling diverse haptic feedback such as, force indentation, vibration and other arbitrary force outputs. This approach enables the rendering of haptic interactions with virtual objects, such as grasping of aa 3D virtual object to feel its stiffness - action that was difficult to achieve using widely adopted vibrotactile motors.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05128",
        "abstract url": "https://arxiv.org/abs/2411.05128",
        "title": "Edge shape sensation presented in a noncontact manner using airborne ultrasound",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "To perceive 3D shapes such as pyramids, the perception of planes and edges as tactile sensations is an essential component. This is difficult to perceive with the conventional vibrotactile sensation used in ultrasound haptics because of its low spatial resolution. Recently, it has become possible to produce a high-resolution pressure sensation using airborne ultrasound. By using this pressure sensation, it is now possible to reproduce a linear, sharp-edged sensation in the area of a fingerpad. In this study, it is demonstrated that this pressure sensation can be used to reproduce the feeling of fine, sharp edges, and its effectiveness is confirmed by comparing it with conventional vibrotactile sensation. In the demonstration, participants can experience the contact sensation of several types of edges with different curvatures.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05137",
        "abstract url": "https://arxiv.org/abs/2411.05137",
        "title": "Inclusion in Assistive Haircare Robotics: Practical and Ethical Considerations in Hair Manipulation",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "Robot"
            ]
        ],
        "abstract": "Robot haircare systems could provide a controlled and personalized environment that is respectful of an individual's sensitivities and may offer a comfortable experience. We argue that because of hair and hairstyles' often unique importance in defining and expressing an individual's identity, we should approach the development of assistive robot haircare systems carefully while considering various practical and ethical concerns and risks. In this work, we specifically list and discuss the consideration of hair type, expression of the individual's preferred identity, cost accessibility of the system, culturally-aware robot strategies, and the associated societal risks. Finally, we discuss the planned studies that will allow us to better understand and address the concerns and considerations we outlined in this work through interactions with both haircare experts and end-users. Through these practical and ethical considerations, this work seeks to systematically organize and provide guidance for the development of inclusive and ethical robot haircare systems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "3rd Workshop on Inclusive HRI"
    },
    {
        "paper id": "2411.05138",
        "abstract url": "https://arxiv.org/abs/2411.05138",
        "title": "Vibrotactile Feedback for a Remote Operated Robot with Noise Subtraction Based on Perceived Intensity",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "There is a growing demand for teleoperated robots. This paper presents a novel method for reducing vibration noise generated by robot's own motion, which can disrupt the quality of tactile feedback for teleoperated robots. Our approach focuses on perceived intensity, the amount of how humans experience vibration, to create a noise filter that aligns with human perceptual characteristics. This system effectively subtracts ego-noise while preserving the essential tactile signals, ensuring more accurate and reliable haptic feedback for operators. This method offers a refined solution to the challenge of maintaining high-quality tactile feedback in teleoperated systems.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05139",
        "abstract url": "https://arxiv.org/abs/2411.05139",
        "title": "Magical Experience with Full-body Action",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "This paper presents a system that generates a magical experience with full-body motion. The system consists of a locomotion interface and a spatial immersive display. A virtual experience system named the Magical Experience Generator was developed, equipped with a Magical Experience Controller. This system provides a physical movement experience along with magical-like interactions in a virtual space. We developed content inspired by the Japanese story \"The Man Who Made Flowers Bloom\" using Unity as the system's environment. The locomotion interface records the participant's walking trajectory and hand movements, representing their actions in the virtual space.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05141",
        "abstract url": "https://arxiv.org/abs/2411.05141",
        "title": "Audiobox TTA-RAG: Improving Zero-Shot and Few-Shot Text-To-Audio with Retrieval-Augmented Generation",
        "rating": "-1",
        "keywords": [
            [
                "Text-To-Audio"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Current leading Text-To-Audio (TTA) generation models suffer from degraded performance on zero-shot and few-shot settings. It is often challenging to generate high-quality audio for audio events that are unseen or uncommon in the training set. Inspired by the success of Retrieval-Augmented Generation (RAG) in Large Language Model (LLM)-based knowledge-intensive tasks, we extend the TTA process with additional conditioning contexts. We propose Audiobox TTA-RAG, a novel retrieval-augmented TTA approach based on Audiobox, a conditional flow-matching audio generation model. Unlike the vanilla Audiobox TTA solution which generates audio conditioned on text, we augmented the conditioning input with retrieved audio samples that provide additional acoustic information to generate the target audio. Our retrieval method does not require the external database to have labeled audio, offering more practical use cases. To evaluate our proposed method, we curated test sets in zero-shot and few-shot settings. Our empirical results show that the proposed model can effectively leverage the retrieved audio samples and significantly improve zero-shot and few-shot TTA performance, with large margins on multiple evaluation metrics, while maintaining the ability to generate semantically aligned audio for the in-domain setting. In addition, we investigate the effect of different retrieval methods and data sources.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05146",
        "abstract url": "https://arxiv.org/abs/2411.05146",
        "title": "Break Times: Virtual Reality Art Therapy",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper presents a Virtual Reality (VR) art therapy known as \"Break Times\" which aims to enhance students' mental well-being and foster creative expression. The proposed \"Break Times\" application mimics the art therapy sessions in the VR environment design. Pilot user acceptance test with 10 participants showed a notable reduction in stress levels, with 50% reporting normal stress levels post-intervention, compared to 20% pre-intervention. Participants praised the \"Break Times\" therapy's functionality and engagement features and suggested improvements such as saving creations, incorporating 3D painting, and expanding the artmaking scene variety. The study highlights that VR art therapy has potential as an effective tool for stress management, emphasizing the need for continued refinement to maximize its therapeutic benefits.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05162",
        "abstract url": "https://arxiv.org/abs/2411.05162",
        "title": "Automatic Authoring of Physical and Perceptual/Affective Motion Effects for Virtual Reality",
        "rating": "-1",
        "keywords": [
            [
                "flight"
            ]
        ],
        "abstract": "This demo is about automatic authoring of various motion effects that are provided with audiovisual content to improve user experiences. Traditionally, motion effects have been used for simulators, e.g., flight simulators for pilots and astronauts, to present physically accurate vestibular feedback. At present, we have greatly wider use of motion effects for entertainment purposes, such as 4D rides in amusement parks and even shopping malls, 4D films in theaters, and relative new virtual reality games with head-mounted displays and personal motion platforms. However, the production of motion effects is done solely by manual authoring or coding, and this costly process prevents the faster and wider dissemination of 4D content. It is imperative to facilitate motion effect production by providing automatic synthesis algorithms. This demo video presents nine different automatic synthesis algorithms for motion effects and a recorded demonstration of each.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05164",
        "abstract url": "https://arxiv.org/abs/2411.05164",
        "title": "Conveying Surroundings Information of a Robot End-Effector by Adjusting Controller Button Stiffness",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "This study addresses the challenge of low dexterity in teleoperation tasks caused by limited sensory feedback and visual occlusion. We propose a novel approach that integrates haptic feedback into teleoperation using the adaptive triggers of a commercially available DualSense controller. By adjusting button stiffness based on the proximity of objects to the robot's end effector, the system provides intuitive, real-time feedback to the operator. To achieve this, the effective volume of the end effector is virtually expanded, allowing the system to predict interactions by calculating overlap with nearby objects. This predictive capability is independent of the user's intent or the robot's speed, enhancing the operator's situational awareness without requiring complex pre-programmed behaviors. The stiffness of the adaptive triggers is adjusted in proportion to this overlapping volume, effectively conveying spatial proximity and movement cues through an \"one degree of freedom\" haptic feedback mechanism. Compared to existing solutions, this method reduces hardware requirements and computational complexity by using a geometric simplification approach, enabling efficient operation with minimal processing demands. Simulation results demonstrate that the proposed system reduces collision risk and improves user performance, offering an intuitive, precise, and safe teleoperation experience despite real-world uncertainties and communication delays.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05183",
        "abstract url": "https://arxiv.org/abs/2411.05183",
        "title": "Interpretable Measurement of CNN Deep Feature Density using Copula and the Generalized Characteristic Function",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "anomaly detection"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present a novel empirical approach toward measuring the Probability Density Function (PDF) of the deep features of Convolutional Neural Networks (CNNs). Measurement of the deep feature PDF is a valuable problem for several reasons. Notably, a. Understanding the deep feature PDF yields new insight into deep representations. b. Feature density methods are important for tasks such as anomaly detection which can improve the robustness of deep learning models in the wild. Interpretable measurement of the deep feature PDF is challenging due to the Curse of Dimensionality (CoD), and the Spatial intuition Limitation. Our novel measurement technique combines copula analysis with the Method of Orthogonal Moments (MOM), in order to directly measure the Generalized Characteristic Function (GCF) of the multivariate deep feature PDF. We find that, surprisingly, the one-dimensional marginals of non-negative deep CNN features after major blocks are not well approximated by a Gaussian distribution, and that these features increasingly approximate an exponential distribution with increasing network depth. Furthermore, we observe that deep features become increasingly independent with increasing network depth within their typical ranges. However, we surprisingly also observe that many deep features exhibit strong dependence (either correlation or anti-correlation) with other extremely strong detections, even if these features are independent within typical ranges. We elaborate on these findings in our discussion, where we propose a new hypothesis that exponentially infrequent large valued features correspond to strong computer vision detections of semantic targets, which would imply that these large-valued features are not outliers but rather an important detection signal.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05194",
        "abstract url": "https://arxiv.org/abs/2411.05194",
        "title": "Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Recent progress on large language models (LLMs) has enabled dialogue agents to generate highly naturalistic and plausible text. However, current LLM language generation focuses on responding accurately to questions and requests with a single effective response. In reality, many real dialogues are interactive, meaning an agent's utterances will influence their conversational partner, elicit information, or change their opinion. Accounting for how an agent can effectively steer a conversation is a crucial ability in many dialogue tasks, from healthcare to preference elicitation. Existing methods for fine-tuning dialogue agents to accomplish such tasks would rely on curating some amount of expert data. However, doing so often requires understanding the underlying cognitive processes of the conversational partner, which is a skill neither humans nor LLMs trained on human data can reliably do. Our key insight is that while LLMs may not be adept at identifying effective strategies for steering conversations a priori, or in the middle of an ongoing conversation, they can do so post-hoc, or in hindsight, after seeing how their conversational partner responds. We use this fact to rewrite and augment existing suboptimal data, and train via offline reinforcement learning (RL) an agent that outperforms both prompting and learning from unaltered human demonstrations. We apply our approach to two domains that require understanding human mental state, intelligent interaction, and persuasion: mental health support, and soliciting charitable donations. Our results in a user study with real humans show that our approach greatly outperforms existing state-of-the-art dialogue agents.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "23 pages, 5 figures"
    },
    {
        "paper id": "2411.05218",
        "abstract url": "https://arxiv.org/abs/2411.05218",
        "title": "ARfy: A Pipeline for Adapting 3D Scenes to Augmented Reality",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Virtual content placement in physical scenes is a crucial aspect of augmented reality (AR). This task is particularly challenging when the virtual elements must adapt to multiple target physical environments that are unknown during development. AR authors use strategies such as manual placement performed by end-users, automated placement powered by author-defined constraints, and procedural content generation to adapt virtual content to physical spaces. Although effective, these options require human effort or annotated virtual assets. As an alternative, we present ARfy, a pipeline to support the adaptive placement of virtual content from pre-existing 3D scenes in arbitrary physical spaces. ARfy does not require intervention by end-users or asset annotation by AR authors. We demonstrate the pipeline capabilities using simulations on a publicly available indoor space dataset. ARfy automatically makes any generic 3D scene AR-ready and provides evaluation tools to facilitate future research on adaptive virtual content placement.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05219",
        "abstract url": "https://arxiv.org/abs/2411.05219",
        "title": "Anticipatory Understanding of Resilient Agriculture to Climate",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "With billions of people facing moderate or severe food insecurity, the resilience of the global food supply will be of increasing concern due to the effects of climate change and geopolitical events. In this paper we describe a framework to better identify food security hotspots using a combination of remote sensing, deep learning, crop yield modeling, and causal modeling of the food distribution system. While we feel that the methods are adaptable to other regions of the world, we focus our analysis on the wheat breadbasket of northern India, which supplies a large percentage of the world's population. We present a quantitative analysis of deep learning domain adaptation methods for wheat farm identification based on curated remote sensing data from France. We model climate change impacts on crop yields using the existing crop yield modeling tool WOFOST and we identify key drivers of crop simulation error using a longitudinal penalized functional regression. A description of a system dynamics model of the food distribution system in India is also presented, along with results of food insecurity identification based on seeding this model with the predicted crop yields.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05255",
        "abstract url": "https://arxiv.org/abs/2411.05255",
        "title": "Monotone Submodular Multiway Partition",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "In submodular multiway partition (SUB-MP), the input is a non-negative submodular function $f:2^V \\rightarrow \\mathbb{R}_{\\ge 0}$ given by an evaluation oracle along with $k$ terminals $t_1, t_2, \\ldots, t_k\\in V$. The goal is to find a partition $V_1, V_2, \\ldots, V_k$ of $V$ with $t_i\\in V_i$ for every $i\\in [k]$ in order to minimize $\\sum_{i=1}^k f(V_i)$. In this work, we focus on SUB-MP when the input function is monotone (termed MONO-SUB-MP). MONO-SUB-MP formulates partitioning problems over several interesting structures -- e.g., matrices, matroids, graphs, and hypergraphs. MONO-SUB-MP is NP-hard since the graph multiway cut problem can be cast as a special case. We investigate the approximability of MONO-SUB-MP: we show that it admits a $4/3$-approximation and does not admit a $(10/9-\u03b5)$-approximation for every constant $\u03b5>0$. Next, we study a special case of MONO-SUB-MP where the monotone submodular function of interest is the coverage function of an input graph, termed GRAPH-COVERAGE-MP. GRAPH-COVERAGE-MP is equivalent to the classic multiway cut problem for the purposes of exact optimization. We show that GRAPH-COVERAGE-MP admits a $1.125$-approximation and does not admit a $(1.00074-\u03b5)$-approximation for every constant $\u03b5>0$ assuming the Unique Games Conjecture. These results separate GRAPH-COVERAGE-MP from graph multiway cut in terms of approximability.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05312",
        "abstract url": "https://arxiv.org/abs/2411.05312",
        "title": "A Real-time Face Mask Detection and Social Distancing System for COVID-19 using Attention-InceptionV3 Model",
        "rating": "-1",
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "One of the deadliest pandemics is now happening in the current world due to COVID-19. This contagious virus is spreading like wildfire around the whole world. To minimize the spreading of this virus, World Health Organization (WHO) has made protocols mandatory for wearing face masks and maintaining 6 feet physical distance. In this paper, we have developed a system that can detect the proper maintenance of that distance and people are properly using masks or not. We have used the customized attention-inceptionv3 model in this system for the identification of those two components. We have used two different datasets along with 10,800 images including both with and without Face Mask images. The training accuracy has been achieved 98% and validation accuracy 99.5%. The system can conduct a precision value of around 98.2% and the frame rate per second (FPS) was 25.0. So, with this system, we can identify high-risk areas with the highest possibility of the virus spreading zone. This may help authorities to take necessary steps to locate those risky areas and alert the local people to ensure proper precautions in no time.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05324",
        "abstract url": "https://arxiv.org/abs/2411.05324",
        "title": "SASWISE-UE: Segmentation and Synthesis with Interpretable Scalable Ensembles for Uncertainty Estimation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "CT",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces an efficient sub-model ensemble framework aimed at enhancing the interpretability of medical deep learning models, thus increasing their clinical applicability. By generating uncertainty maps, this framework enables end-users to evaluate the reliability of model outputs. We developed a strategy to develop diverse models from a single well-trained checkpoint, facilitating the training of a model family. This involves producing multiple outputs from a single input, fusing them into a final output, and estimating uncertainty based on output disagreements. Implemented using U-Net and UNETR models for segmentation and synthesis tasks, this approach was tested on CT body segmentation and MR-CT synthesis datasets. It achieved a mean Dice coefficient of 0.814 in segmentation and a Mean Absolute Error of 88.17 HU in synthesis, improved from 89.43 HU by pruning. Additionally, the framework was evaluated under corruption and undersampling, maintaining correlation between uncertainty and error, which highlights its robustness. These results suggest that the proposed approach not only maintains the performance of well-trained models but also enhances interpretability through effective uncertainty estimation, applicable to both convolutional and transformer models in a range of imaging tasks.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "stat.ME"
        ],
        "comment": "16 pages, 12 figures, 5 tables"
    },
    {
        "paper id": "2411.05878",
        "abstract url": "https://arxiv.org/abs/2411.05878",
        "title": "Joint-Optimized Unsupervised Adversarial Domain Adaptation in Remote Sensing Segmentation with Prompted Foundation Model",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Unsupervised Domain Adaptation for Remote Sensing Semantic Segmentation (UDA-RSSeg) addresses the challenge of adapting a model trained on source domain data to target domain samples, thereby minimizing the need for annotated data across diverse remote sensing scenes. This task presents two principal challenges: (1) severe inconsistencies in feature representation across different remote sensing domains, and (2) a domain gap that emerges due to the representation bias of source domain patterns when translating features to predictive logits. To tackle these issues, we propose a joint-optimized adversarial network incorporating the \"Segment Anything Model (SAM) (SAM-JOANet)\" for UDA-RSSeg. Our approach integrates SAM to leverage its robust generalized representation capabilities, thereby alleviating feature inconsistencies. We introduce a finetuning decoder designed to convert SAM-Encoder features into predictive logits. Additionally, a feature-level adversarial-based prompted segmentor is employed to generate class-agnostic maps, which guide the finetuning decoder's feature representations. The network is optimized end-to-end, combining the prompted segmentor and the finetuning decoder. Extensive evaluations on benchmark datasets, including ISPRS (Potsdam/Vaihingen) and CITY-OSM (Paris/Chicago), demonstrate the effectiveness of our method. The results, supported by visualization and analysis, confirm the method's interpretability and robustness. The code of this paper is available at https://github.com/CV-ShuchangLyu/SAM-JOANet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages,6 figures, 6 tables"
    },
    {
        "paper id": "2411.05879",
        "abstract url": "https://arxiv.org/abs/2411.05879",
        "title": "Smile upon the Face but Sadness in the Eyes: Emotion Recognition based on Facial Expressions and Eye Behaviors",
        "rating": "-1",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Emotion Recognition (ER) is the process of identifying human emotions from given data. Currently, the field heavily relies on facial expression recognition (FER) because facial expressions contain rich emotional cues. However, it is important to note that facial expressions may not always precisely reflect genuine emotions and FER-based results may yield misleading ER. To understand and bridge this gap between FER and ER, we introduce eye behaviors as an important emotional cues for the creation of a new Eye-behavior-aided Multimodal Emotion Recognition (EMER) dataset. Different from existing multimodal ER datasets, the EMER dataset employs a stimulus material-induced spontaneous emotion generation method to integrate non-invasive eye behavior data, like eye movements and eye fixation maps, with facial videos, aiming to obtain natural and accurate human emotions. Notably, for the first time, we provide annotations for both ER and FER in the EMER, enabling a comprehensive analysis to better illustrate the gap between both tasks. Furthermore, we specifically design a new EMERT architecture to concurrently enhance performance in both ER and FER by efficiently identifying and bridging the emotion gap between the two.Specifically, our EMERT employs modality-adversarial feature decoupling and multi-task Transformer to augment the modeling of eye behaviors, thus providing an effective complement to facial expressions. In the experiment, we introduce seven multimodal benchmark protocols for a variety of comprehensive evaluations of the EMER dataset. The results show that the EMERT outperforms other state-of-the-art multimodal methods by a great margin, revealing the importance of modeling eye behaviors for robust ER. To sum up, we provide a comprehensive analysis of the importance of eye behaviors in ER, advancing the study on addressing the gap between FER and ER for more robust ER performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04508",
        "abstract url": "https://arxiv.org/abs/2411.04508",
        "title": "A Comprehensive Review of Multimodal XR Applications, Risks, and Ethical Challenges in the Metaverse",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "This scoping review examines the broad applications, risks, and ethical challenges associated with Extended Reality (XR) technologies, including Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR), within the context of Metaverse. XR is revolutionizing fields such as immersive learning in education, medical and professional training, neuropsychological assessment, therapeutic interventions, arts, entertainment, retail, e-commerce, remote work, sports, architecture, urban planning, and cultural heritage preservation. The integration of multimodal technologies such as haptics, eye-tracking, face- and body-tracking, and brain-computer interfaces, enhances user engagement and interactivity, playing a key role in shaping the immersive experiences in the Metaverse. However, XR's expansion raises serious concerns, including data privacy risks, cybersecurity vulnerabilities, cybersickness, addiction, dissociation, harassment, bullying, and misinformation. These psychological, social, and security challenges are further complicated by intense advertising, manipulation of public opinion, and social inequality, which could disproportionately affect vulnerable individuals and social groups. This review emphasizes the urgent need for robust ethical frameworks and regulatory guidelines to address these risks while promoting equitable access, privacy, autonomy, and mental well-being. As XR technologies increasingly integrate with artificial intelligence, responsible governance is essential to ensure the safe and beneficial development of the Metaverse and the broader application of XR in enhancing human development.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": "43 Pages, 1 Figure, 3 Tables"
    },
    {
        "paper id": "2411.04644",
        "abstract url": "https://arxiv.org/abs/2411.04644",
        "title": "wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals",
        "rating": "-1.5",
        "keywords": [
            [
                "Physiological"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Accurate classification of sleep stages from less obtrusive sensor measurements such as the electrocardiogram (ECG) or photoplethysmogram (PPG) could enable important applications in sleep medicine. Existing approaches to this problem have typically used deep learning models designed and trained to operate on one or more specific input signals. However, the datasets used to develop these models often do not contain the same sets of input signals. Some signals, particularly PPG, are much less prevalent than others, and this has previously been addressed with techniques such as transfer learning. Additionally, only training on one or more fixed modalities precludes cross-modal information transfer from other sources, which has proved valuable in other problem domains. To address this, we introduce wav2sleep, a unified model designed to operate on variable sets of input signals during training and inference. After jointly training on over 10,000 overnight recordings from six publicly available polysomnography datasets, including SHHS and MESA, wav2sleep outperforms existing sleep stage classification models across test-time input combinations including ECG, PPG, and respiratory signals.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to Machine Learning for Health (ML4H) 2024"
    },
    {
        "paper id": "2411.04662",
        "abstract url": "https://arxiv.org/abs/2411.04662",
        "title": "Enhancing Trust in Clinically Significant Prostate Cancer Prediction with Multiple Magnetic Resonance Imaging Modalities",
        "rating": "-1.5",
        "keywords": [
            [
                "diagnosis",
                "MRI",
                "Cancer",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the United States, prostate cancer is the second leading cause of deaths in males with a predicted 35,250 deaths in 2024. However, most diagnoses are non-lethal and deemed clinically insignificant which means that the patient will likely not be impacted by the cancer over their lifetime. As a result, numerous research studies have explored the accuracy of predicting clinical significance of prostate cancer based on magnetic resonance imaging (MRI) modalities and deep neural networks. Despite their high performance, these models are not trusted by most clinical scientists as they are trained solely on a single modality whereas clinical scientists often use multiple magnetic resonance imaging modalities during their diagnosis. In this paper, we investigate combining multiple MRI modalities to train a deep learning model to enhance trust in the models for clinically significant prostate cancer prediction. The promising performance and proposed training pipeline showcase the benefits of incorporating multiple MRI modalities for enhanced trust and accuracy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 6 pages"
    },
    {
        "paper id": "2411.04671",
        "abstract url": "https://arxiv.org/abs/2411.04671",
        "title": "CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR",
        "rating": "-1.5",
        "keywords": [
            [
                "text-to-speech"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent developments in computer graphics, machine learning, and sensor technologies enable numerous opportunities for extended reality (XR) setups for everyday life, from skills training to entertainment. With large corporations offering consumer-grade head-mounted displays (HMDs) in an affordable way, it is likely that XR will become pervasive, and HMDs will develop as personal devices like smartphones and tablets. However, having intelligent spaces and naturalistic interactions in XR is as important as technological advances so that users grow their engagement in virtual and augmented spaces. To this end, large language model (LLM)--powered non-player characters (NPCs) with speech-to-text (STT) and text-to-speech (TTS) models bring significant advantages over conventional or pre-scripted NPCs for facilitating more natural conversational user interfaces (CUIs) in XR. In this paper, we provide the community with an open-source, customizable, extensible, and privacy-aware Unity package, CUIfy, that facilitates speech-based NPC-user interaction with various LLMs, STT, and TTS models. Our package also supports multiple LLM-powered NPCs per environment and minimizes the latency between different computational models through streaming to achieve usable interactions between users and NPCs. We publish our source code in the following repository: https://gitlab.lrz.de/hctl/cuify",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.04691",
        "abstract url": "https://arxiv.org/abs/2411.04691",
        "title": "AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "psychological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Smartphones, equipped with an array of sensors, have become valuable tools for personal sensing. Particularly in digital health, smartphones facilitate the tracking of health-related behaviors and contexts, contributing significantly to digital phenotyping, a process where data from digital interactions is analyzed to infer behaviors and assess mental health. Traditional methods process raw sensor data into information features for statistical and machine learning analyses. In this paper, we introduce a novel approach that systematically converts smartphone-collected data into structured, chronological narratives. The AWARE Narrator translates quantitative smartphone sensing data into English language descriptions, forming comprehensive narratives of an individual's activities. We apply the framework to the data collected from university students over a week, demonstrating the potential of utilizing the narratives to summarize individual behavior, and analyzing psychological states by leveraging large language models.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04728",
        "abstract url": "https://arxiv.org/abs/2411.04728",
        "title": "Neuromorphic Wireless Split Computing with Multi-Level Spikes",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Inspired by biological processes, neuromorphic computing utilizes spiking neural networks (SNNs) to perform inference tasks, offering significant efficiency gains for workloads involving sequential data. Recent advances in hardware and software have demonstrated that embedding a few bits of payload in each spike exchanged between the spiking neurons can further enhance inference accuracy. In a split computing architecture, where the SNN is divided across two separate devices, the device storing the first layers must share information about the spikes generated by the local output neurons with the other device. Consequently, the advantages of multi-level spikes must be balanced against the challenges of transmitting additional bits between the two devices. This paper addresses these challenges by investigating a wireless neuromorphic split computing architecture employing multi-level SNNs. For this system, we present the design of digital and analog modulation schemes optimized for an orthogonal frequency division multiplexing (OFDM) radio interface. Simulation and experimental results using software-defined radios provide insights into the performance gains of multi-level SNN models and the optimal payload size as a function of the quality of the connection between a transmitter and receiver.",
        "subjects": [
            "cs.LG",
            "cs.IT",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04838",
        "abstract url": "https://arxiv.org/abs/2411.04838",
        "title": "Machine learning and optimization-based approaches to duality in statistical physics",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The notion of duality -- that a given physical system can have two different mathematical descriptions -- is a key idea in modern theoretical physics. Establishing a duality in lattice statistical mechanics models requires the construction of a dual Hamiltonian and a map from the original to the dual observables. By using simple neural networks to parameterize these maps and introducing a loss function that penalises the difference between correlation functions in original and dual models, we formulate the process of duality discovery as an optimization problem. We numerically solve this problem and show that our framework can rediscover the celebrated Kramers-Wannier duality for the 2d Ising model, reconstructing the known mapping of temperatures. We also discuss an alternative approach which uses known features of the mapping of topological lines to reduce the problem to optimizing the couplings in a dual Hamiltonian, and explore next-to-nearest neighbour deformations of the 2d Ising duality. We discuss future directions and prospects for discovering new dualities within this framework.",
        "subjects": [
            "cond-mat.stat-mech",
            "cs.AI",
            "cs.LG",
            "hep-th"
        ],
        "comment": "27 pages + appendices, lots of plots"
    },
    {
        "paper id": "2411.04855",
        "abstract url": "https://arxiv.org/abs/2411.04855",
        "title": "Clinicians' Voice: Fundamental Considerations for XAI in Healthcare",
        "rating": "-1.5",
        "keywords": [
            [
                "Healthcare",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Explainable AI (XAI) holds the promise of advancing the implementation and adoption of AI-based tools in practice, especially in high-stakes environments like healthcare. However, most of the current research is disconnected from its practical applications and lacks input of end users. To address this, we conducted semi-structured interviews with clinicians to discuss their thoughts, hopes, and concerns. We find that clinicians generally think positively about developing AI-based tools for clinical practice, but they have concerns about how these will fit into their workflow and how it will impact clinician-patient relations. We further identify education of clinicians on AI as a crucial factor for the success of AI in healthcare and highlight aspects clinicians are looking for in (X)AI-based tools. In contrast to other studies, we take on a holistic and exploratory perspective to identify general requirements, which is necessary before moving on to testing specific (X)AI products for healthcare.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04863",
        "abstract url": "https://arxiv.org/abs/2411.04863",
        "title": "OneProt: Towards Multi-Modal Protein Foundation Models",
        "rating": "-1.5",
        "keywords": [
            [
                "biocatalytic"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent AI advances have enabled multi-modal systems to model and translate diverse information spaces. Extending beyond text and vision, we introduce OneProt, a multi-modal AI for proteins that integrates structural, sequence, alignment, and binding site data. Using the ImageBind framework, OneProt aligns the latent spaces of modality encoders along protein sequences. It demonstrates strong performance in retrieval tasks and surpasses state-of-the-art methods in various downstream tasks, including metal ion binding classification, gene-ontology annotation, and enzyme function prediction. This work expands multi-modal capabilities in protein models, paving the way for applications in drug discovery, biocatalytic reaction planning, and protein engineering.",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": "28 pages, 15 figures, 7 tables"
    },
    {
        "paper id": "2411.04913",
        "abstract url": "https://arxiv.org/abs/2411.04913",
        "title": "Structure Matters: Dynamic Policy Gradient",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this work, we study $\u03b3$-discounted infinite-horizon tabular Markov decision processes (MDPs) and introduce a framework called dynamic policy gradient (DynPG). The framework directly integrates dynamic programming with (any) policy gradient method, explicitly leveraging the Markovian property of the environment. DynPG dynamically adjusts the problem horizon during training, decomposing the original infinite-horizon MDP into a sequence of contextual bandit problems. By iteratively solving these contextual bandits, DynPG converges to the stationary optimal policy of the infinite-horizon MDP. To demonstrate the power of DynPG, we establish its non-asymptotic global convergence rate under the tabular softmax parametrization, focusing on the dependencies on salient but essential parameters of the MDP. By combining classical arguments from dynamic programming with more recent convergence arguments of policy gradient schemes, we prove that softmax DynPG scales polynomially in the effective horizon $(1-\u03b3)^{-1}$. Our findings contrast recent exponential lower bound examples for vanilla policy gradient.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "math.PR"
        ],
        "comment": "46 pages, 4 figures"
    },
    {
        "paper id": "2411.04987",
        "abstract url": "https://arxiv.org/abs/2411.04987",
        "title": "Few-Shot Task Learning through Inverse Generative Modeling",
        "rating": "-1.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "navigation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Learning the intents of an agent, defined by its goals or motion style, is often extremely challenging from just a few examples. We refer to this problem as task concept learning and present our approach, Few-Shot Task Learning through Inverse Generative Modeling (FTL-IGM), which learns new task concepts by leveraging invertible neural generative models. The core idea is to pretrain a generative model on a set of basic concepts and their demonstrations. Then, given a few demonstrations of a new concept (such as a new goal or a new action), our method learns the underlying concepts through backpropagation without updating the model weights, thanks to the invertibility of the generative model. We evaluate our method in five domains -- object rearrangement, goal-oriented navigation, motion caption of human actions, autonomous driving, and real-world table-top manipulation. Our experimental results demonstrate that via the pretrained generative model, we successfully learn novel concepts and generate agent plans or motion corresponding to these concepts in (1) unseen environments and (2) in composition with training concepts.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05055",
        "abstract url": "https://arxiv.org/abs/2411.05055",
        "title": "Integrating Large Language Models for Genetic Variant Classification",
        "rating": "-1.5",
        "keywords": [
            [
                "clinical",
                "DNA"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The classification of genetic variants, particularly Variants of Uncertain Significance (VUS), poses a significant challenge in clinical genetics and precision medicine. Large Language Models (LLMs) have emerged as transformative tools in this realm. These models can uncover intricate patterns and predictive insights that traditional methods might miss, thus enhancing the predictive accuracy of genetic variant pathogenicity. This study investigates the integration of state-of-the-art LLMs, including GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data alongside structural insights to form a comprehensive analytical framework for variant classification. Our approach evaluates these integrated models using the well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in classification performance. The models were rigorously tested on a set of challenging variants, demonstrating substantial improvements over existing state-of-the-art tools, especially in handling ambiguous and clinically uncertain variants. The results of this research underline the efficacy of combining multiple modeling approaches to significantly refine the accuracy and reliability of genetic variant classification systems. These findings support the deployment of these advanced computational models in clinical environments, where they can significantly enhance the diagnostic processes for genetic disorders, ultimately pushing the boundaries of personalized medicine by offering more detailed and actionable genetic insights.",
        "subjects": [
            "q-bio.GN",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "21 pages, 7 figures"
    },
    {
        "paper id": "2411.05174",
        "abstract url": "https://arxiv.org/abs/2411.05174",
        "title": "Inverse Transition Learning: Learning Dynamics from Demonstrations",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We consider the problem of estimating the transition dynamics $T^*$ from near-optimal expert trajectories in the context of offline model-based reinforcement learning. We develop a novel constraint-based method, Inverse Transition Learning, that treats the limited coverage of the expert trajectories as a \\emph{feature}: we use the fact that the expert is near-optimal to inform our estimate of $T^*$. We integrate our constraints into a Bayesian approach. Across both synthetic environments and real healthcare scenarios like Intensive Care Unit (ICU) patient management in hypotension, we demonstrate not only significant improvements in decision-making, but that our posterior can inform when transfer will be successful.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05196",
        "abstract url": "https://arxiv.org/abs/2411.05196",
        "title": "Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "cancer"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In democratic societies, electoral systems play a crucial role in translating public preferences into political representation. Among these, the D'Hondt method is widely used to ensure proportional representation, balancing fair representation with governmental stability. Recently, there has been a growing interest in applying similar principles of proportional representation to enhance interpretability in machine learning, specifically in Explainable AI (XAI). This study investigates the integration of D'Hondt-based voting principles in the DhondtXAI method, which leverages resource allocation concepts to interpret feature importance within AI models. Through a comparison of SHAP (Shapley Additive Explanations) and DhondtXAI, we evaluate their effectiveness in feature attribution within CatBoost and XGBoost models for breast cancer and diabetes prediction, respectively. The DhondtXAI approach allows for alliance formation and thresholding to enhance interpretability, representing feature importance as seats in a parliamentary view. Statistical correlation analyses between SHAP values and DhondtXAI allocations support the consistency of interpretations, demonstrating DhondtXAI's potential as a complementary tool for understanding feature importance in AI models. The results highlight that integrating electoral principles, such as proportional representation and alliances, into AI explainability can improve user understanding, especially in high-stakes fields like healthcare.",
        "subjects": [
            "cs.AI",
            "cs.DL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05223",
        "abstract url": "https://arxiv.org/abs/2411.05223",
        "title": "Generalizable Single-Source Cross-modality Medical Image Segmentation via Invariant Causal Mechanisms",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Medical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Single-source domain generalization (SDG) aims to learn a model from a single source domain that can generalize well on unseen target domains. This is an important task in computer vision, particularly relevant to medical imaging where domain shifts are common. In this work, we consider a challenging yet practical setting: SDG for cross-modality medical image segmentation. We combine causality-inspired theoretical insights on learning domain-invariant representations with recent advancements in diffusion-based augmentation to improve generalization across diverse imaging modalities. Guided by the ``intervention-augmentation equivariant'' principle, we use controlled diffusion models (DMs) to simulate diverse imaging styles while preserving the content, leveraging rich generative priors in large-scale pretrained DMs to comprehensively perturb the multidimensional style variable. Extensive experiments on challenging cross-modality segmentation tasks demonstrate that our approach consistently outperforms state-of-the-art SDG methods across three distinct anatomies and imaging modalities. The source code is available at \\href{https://github.com/ratschlab/ICMSeg}{https://github.com/ratschlab/ICMSeg}.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "WACV 2025"
    },
    {
        "paper id": "2411.05234",
        "abstract url": "https://arxiv.org/abs/2411.05234",
        "title": "Performative Reinforcement Learning with Linear Markov Decision Process",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the setting of \\emph{performative reinforcement learning} where the deployed policy affects both the reward, and the transition of the underlying Markov decision process. Prior work~\\parencite{MTR23} has addressed this problem under the tabular setting and established last-iterate convergence of repeated retraining with iteration complexity explicitly depending on the number of states. In this work, we generalize the results to \\emph{linear Markov decision processes} which is the primary theoretical model of large-scale MDPs. The main challenge with linear MDP is that the regularized objective is no longer strongly convex and we want a bound that scales with the dimension of the features, rather than states which can be infinite. Our first result shows that repeatedly optimizing a regularized objective converges to a \\emph{performatively stable policy}. In the absence of strong convexity, our analysis leverages a new recurrence relation that uses a specific linear combination of optimal dual solutions for proving convergence. We then tackle the finite sample setting where the learner has access to a set of trajectories drawn from the current policy. We consider a reparametrized version of the primal problem, and construct an empirical Lagrangian which is to be optimized from the samples. We show that, under a \\emph{bounded coverage} condition, repeatedly solving a saddle point of this empirical Lagrangian converges to a performatively stable solution, and also construct a primal-dual algorithm that solves the empirical Lagrangian efficiently. Finally, we show several applications of the general framework of performative RL including multi-agent systems.",
        "subjects": [
            "cs.LG",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05237",
        "abstract url": "https://arxiv.org/abs/2411.05237",
        "title": "Pruning the Path to Optimal Care: Identifying Systematically Suboptimal Medical Decision-Making with Inverse Reinforcement Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "disease",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In aims to uncover insights into medical decision-making embedded within observational data from clinical settings, we present a novel application of Inverse Reinforcement Learning (IRL) that identifies suboptimal clinician actions based on the actions of their peers. This approach centers two stages of IRL with an intermediate step to prune trajectories displaying behavior that deviates significantly from the consensus. This enables us to effectively identify clinical priorities and values from ICU data containing both optimal and suboptimal clinician decisions. We observe that the benefits of removing suboptimal actions vary by disease and differentially impact certain demographic groups.",
        "subjects": [
            "cs.LG",
            "q-bio.QM",
            "stat.AP",
            "stat.CO",
            "stat.ML"
        ],
        "comment": "13 pages, 4 figures"
    },
    {
        "paper id": "2411.05260",
        "abstract url": "https://arxiv.org/abs/2411.05260",
        "title": "QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Federated Learning has emerged as a leading approach for decentralized machine learning, enabling multiple clients to collaboratively train a shared model without exchanging private data. While FL enhances data privacy, it remains vulnerable to inference attacks, such as gradient inversion and membership inference, during both training and inference phases. Homomorphic Encryption provides a promising solution by encrypting model updates to protect against such attacks, but it introduces substantial communication overhead, slowing down training and increasing computational costs. To address these challenges, we propose QuanCrypt-FL, a novel algorithm that combines low-bit quantization and pruning techniques to enhance protection against attacks while significantly reducing computational costs during training. Further, we propose and implement mean-based clipping to mitigate quantization overflow or errors. By integrating these methods, QuanCrypt-FL creates a communication-efficient FL framework that ensures privacy protection with minimal impact on model accuracy, thereby improving both computational efficiency and attack resilience. We validate our approach on MNIST, CIFAR-10, and CIFAR-100 datasets, demonstrating superior performance compared to state-of-the-art methods. QuanCrypt-FL consistently outperforms existing method and matches Vanilla-FL in terms of accuracy across varying client. Further, QuanCrypt-FL achieves up to 9x faster encryption, 16x faster decryption, and 1.5x faster inference compared to BatchCrypt, with training time reduced by up to 3x.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05274",
        "abstract url": "https://arxiv.org/abs/2411.05274",
        "title": "Distributed-Order Fractional Graph Operating Network",
        "rating": "-1.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce the Distributed-order fRActional Graph Operating Network (DRAGON), a novel continuous Graph Neural Network (GNN) framework that incorporates distributed-order fractional calculus. Unlike traditional continuous GNNs that utilize integer-order or single fractional-order differential equations, DRAGON uses a learnable probability distribution over a range of real numbers for the derivative orders. By allowing a flexible and learnable superposition of multiple derivative orders, our framework captures complex graph feature updating dynamics beyond the reach of conventional models. We provide a comprehensive interpretation of our framework's capability to capture intricate dynamics through the lens of a non-Markovian graph random walk with node feature updating driven by an anomalous diffusion process over the graph. Furthermore, to highlight the versatility of the DRAGON framework, we conduct empirical evaluations across a range of graph learning tasks. The results consistently demonstrate superior performance when compared to traditional continuous GNN models. The implementation code is available at \\url{https://github.com/zknus/NeurIPS-2024-DRAGON}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05277",
        "abstract url": "https://arxiv.org/abs/2411.05277",
        "title": "Revisiting the Robustness of Watermarking to Paraphrasing Attacks",
        "rating": "-1.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "Watermarking"
            ],
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Amidst rising concerns about the internet being proliferated with content generated from language models (LMs), watermarking is seen as a principled way to certify whether text was generated from a model. Many recent watermarking techniques slightly modify the output probabilities of LMs to embed a signal in the generated output that can later be detected. Since early proposals for text watermarking, questions about their robustness to paraphrasing have been prominently discussed. Lately, some techniques are deliberately designed and claimed to be robust to paraphrasing. However, such watermarking schemes do not adequately account for the ease with which they can be reverse-engineered. We show that with access to only a limited number of generations from a black-box watermarked model, we can drastically increase the effectiveness of paraphrasing attacks to evade watermark detection, thereby rendering the watermark ineffective.",
        "subjects": [
            "cs.CR",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "EMNLP 2024"
    },
    {
        "paper id": "2411.05316",
        "abstract url": "https://arxiv.org/abs/2411.05316",
        "title": "Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Latent representation alignment has become a foundational technique for constructing multimodal large language models (MLLM) by mapping embeddings from different modalities into a shared space, often aligned with the embedding space of large language models (LLMs) to enable effective cross-modal understanding. While preliminary protein-focused MLLMs have emerged, they have predominantly relied on heuristic approaches, lacking a fundamental understanding of optimal alignment practices across representations. In this study, we explore the alignment of multimodal representations between LLMs and Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines alignment factors from both model and protein perspectives, identifying challenges in current alignment methodologies and proposing strategies to improve the alignment process. Our key findings reveal that GDMs incorporating both graph and 3D structural information align better with LLMs, larger LLMs demonstrate improved alignment capabilities, and protein rarity significantly impacts alignment performance. We also find that increasing GDM embedding dimensions, using two-layer projection heads, and fine-tuning LLMs on protein-specific data substantially enhance alignment quality. These strategies offer potential enhancements to the performance of protein-related multimodal models. Our code and data are available at https://github.com/Tizzzzy/LLM-GDM-alignment.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "q-bio.BM"
        ],
        "comment": "24 pages, 9 figures"
    },
    {
        "paper id": "2411.05861",
        "abstract url": "https://arxiv.org/abs/2411.05861",
        "title": "Rethinking Deep Learning: Non-backpropagation and Non-optimization Machine Learning Approach Using Hebbian Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Developing strong AI could provide a powerful tool for addressing social and scientific challenges. Neural networks (NNs), inspired by biological systems, have the potential to achieve this. However, weight optimization techniques using error backpropagation are not observed in biological systems, raising doubts about current NNs approaches. In this context, Itoh (2024) solved the MNIST classification problem without using objective functions or backpropagation. However, weight updates were not used, so it does not qualify as machine learning AI. In this study, I develop a machine learning method that mimics biological neural systems by implementing Hebbian learning in NNs without backpropagation and optimization method to solve the MNIST classification problem and analyze its output. Development proceeded in three stages. In the first stage, I applied the Hebbian learning rule to the MNIST character recognition algorithm by Itoh (2024), resulting in lower accuracy than non-Hebbian NNs, highlighting the limitations of conventional training procedures for Hebbian learning. In the second stage, I examined the properties of individually trained NNs using norm-based cognition, showing that NNs trained on a specific label respond powerfully to that label. In the third stage, I created an MNIST character recognition program using vector norm magnitude as the criterion, achieving an accuracy of approximately 75%. This demonstrates that the Hebbian learning NNs can recognize handwritten characters without objective functions, backpropagation, or optimization processes. Based on these results, developing a mechanism based on norm-based cognition as a fundamental unit and then increasing complexity to achieve indirect similarity cognition should help mimic biological neural systems and contribute to realizing strong AI.",
        "subjects": [
            "cs.NE",
            "cs.LG"
        ],
        "comment": "13 pages, 4 figures"
    },
    {
        "paper id": "2411.04444",
        "abstract url": "https://arxiv.org/abs/2411.04444",
        "title": "An Empirical Study on the Potential of LLMs in Automated Software Refactoring",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Recent advances in large language models (LLMs), make it potentially feasible to automatically refactor source code with LLMs. However, it remains unclear how well LLMs perform compared to human experts in conducting refactorings automatically and accurately. To fill this gap, in this paper, we conduct an empirical study to investigate the potential of LLMs in automated software refactoring, focusing on the identification of refactoring opportunities and the recommendation of refactoring solutions. We first construct a high-quality refactoring dataset comprising 180 real-world refactorings from 20 projects, and conduct the empirical study on the dataset. With the to-be-refactored Java documents as input, ChatGPT and Gemini identified only 28 and 7 respectively out of the 180 refactoring opportunities. However, explaining the expected refactoring subcategories and narrowing the search space in the prompts substantially increased the success rate of ChatGPT from 15.6% to 86.7%. Concerning the recommendation of refactoring solutions, ChatGPT recommended 176 refactoring solutions for the 180 refactorings, and 63.6% of the recommended solutions were comparable to (even better than) those constructed by human experts. However, 13 out of the 176 solutions suggested by ChatGPT and 9 out of the 137 solutions suggested by Gemini were unsafe in that they either changed the functionality of the source code or introduced syntax errors, which indicate the risk of LLM-based refactoring. To this end, we propose a detect-and-reapply tactic, called RefactoringMirror, to avoid such unsafe refactorings. By reapplying the identified refactorings to the original code using thoroughly tested refactoring engines, we can effectively mitigate the risks associated with LLM-based automated refactoring while still leveraging LLM's intelligence to obtain valuable refactoring recommendations.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04447",
        "abstract url": "https://arxiv.org/abs/2411.04447",
        "title": "Self-orthogonal codes from plateaued functions",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Self-orthogonal codes are of interest as they have important applications in quantum codes, lattices and many areas. In this paper, based on the weakly regular plateaued functions or plateaued Boolean functions, we construct a family of linear codes with four nonzero weights. This family of linear codes is proved to be not only self-orthogonal but also optimally or almost optimally extendable. Besides, we derive binary and ternary linearly complementary dual codes (LCD codes for short) with new parameters from this family of codes. Some families of self-dual codes are also obtained as byproducts.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2401.01135"
    },
    {
        "paper id": "2411.04452",
        "abstract url": "https://arxiv.org/abs/2411.04452",
        "title": "Optimal Allocation of Pauli Measurements for Low-rank Quantum State Tomography",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The process of reconstructing quantum states from experimental measurements, accomplished through quantum state tomography (QST), plays a crucial role in verifying and benchmarking quantum devices. A key challenge of QST is to find out how the accuracy of the reconstruction depends on the number of state copies used in the measurements. When multiple measurement settings are used, the total number of state copies is determined by multiplying the number of measurement settings with the number of repeated measurements for each setting. Due to statistical noise intrinsic to quantum measurements, a large number of repeated measurements is often used in practice. However, recent studies have shown that even with single-sample measurements--where only one measurement sample is obtained for each measurement setting--high accuracy QST can still be achieved with a sufficiently large number of different measurement settings. In this paper, we establish a theoretical understanding of the trade-off between the number of measurement settings and the number of repeated measurements per setting in QST. Our focus is primarily on low-rank density matrix recovery using Pauli measurements. We delve into the global landscape underlying the low-rank QST problem and demonstrate that the joint consideration of measurement settings and repeated measurements ensures a bounded recovery error for all second-order critical points, to which optimization algorithms tend to converge. This finding suggests the advantage of minimizing the number of repeated measurements per setting when the total number of state copies is held fixed. Additionally, we prove that the Wirtinger gradient descent algorithm can converge to the region of second-order critical points with a linear convergence rate. We have also performed numerical experiments to support our theoretical findings.",
        "subjects": [
            "quant-ph",
            "eess.SP",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04464",
        "abstract url": "https://arxiv.org/abs/2411.04464",
        "title": "Decoding Quasi-Cyclic Quantum LDPC Codes",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum low-density parity-check (qLDPC) codes are an important component in the quest for quantum fault tolerance. Dramatic recent progress on qLDPC codes has led to constructions which are asymptotically good, and which admit linear-time decoders to correct errors affecting a constant fraction of codeword qubits. These constructions, while theoretically explicit, rely on inner codes with strong properties only shown to exist by probabilistic arguments, resulting in lengths that are too large to be practically relevant. In practice, the surface/toric codes, which are the product of two repetition codes, are still often the qLDPC codes of choice. A previous construction based on the lifted product of an expander-based classical LDPC code with a repetition code (Panteleev & Kalachev, 2020) achieved a near-linear distance (of $\u03a9(N/\\log N)$ where $N$ is the number of codeword qubits), and avoids the need for such intractable inner codes. Our main result is an efficient decoding algorithm for these codes that corrects $\u0398(N/\\log N)$ adversarial errors. En route, we give such an algorithm for the hypergraph product version these codes, which have weaker $\u0398(\\sqrt{N})$ distance (but are simpler). Our decoding algorithms leverage the fact that the codes we consider are quasi-cyclic, meaning that they respect a cyclic group symmetry. Since the repetition code is not based on expanders, previous approaches to decoding expander-based qLDPC codes, which typically worked by greedily flipping code bits to reduce some potential function, do not apply in our setting. Instead, we reduce our decoding problem (in a black-box manner) to that of decoding classical expander-based LDPC codes under noisy parity-check syndromes. For completeness, we also include a treatment of such classical noisy-syndrome decoding that is sufficient for our application to the quantum setting.",
        "subjects": [
            "quant-ph",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04474",
        "abstract url": "https://arxiv.org/abs/2411.04474",
        "title": "The Impact of Traffic Characteristics on System and User Performance in 5G/6G Cellular Systems",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "The statistical characteristics of the propagation environment and traffic arrival process are known to affect the user performance in 5G/6G millimeter wave (mmWave) and subterahertz (sub-THz) systems. While the former topic has received considerable attention recently, little is known about the impact of traffic statistics. In this study, we characterize the effects of correlation and variability in the session arrival process on the performance of 5G/6G mmWave/sub-THz systems. To this end, we use the tools of stochastic geometry and queuing theory to model the service process at base stations (BS) and specifics of the mmWave/sub-THz radio part. The metrics considered include the system resource utilization and session loss probability. Our results show that the normalized autocorrelation function (NACF), coefficient of variation (CoV), and variance of the resource request distribution have a significant impact on the considered parameters. For the same arrival rate, high values of lag-1 NACF and CoV may lead the system out of the operational regime, affecting the loss probability and resource utilization by up to an order of magnitude. Even a slight deviation from the uncorrelated Poisson process decreases the utilization by 10-20% and increases the session loss probability multiple times. Radio and environmental characteristics may further increase the variability in resource request distribution and decrease resource utilization. In general, the use of the commonly accepted Poisson assumption leads to a severe underestimation of the actual performance of 5G/6G mmWave/sub-THz systems. Therefore, both traffic arrival and propagation statistics are equally important for accurate performance assessment of such systems.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04482",
        "abstract url": "https://arxiv.org/abs/2411.04482",
        "title": "Anonymous Public-Key Quantum Money and Quantum Voting",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum information allows us to build quantum money schemes, where a bank can issue banknotes in the form of authenticatable quantum states that cannot be cloned or counterfeited. Similar to paper banknotes, in existing quantum money schemes, a banknote consists of an unclonable quantum state and a classical serial number, signed by bank. Thus, they lack one of the most fundamental properties cryptographers look for in a currency scheme: privacy. In this work, we first further develop the formal definitions of privacy for quantum money schemes. Then, we construct the first public-key quantum money schemes that satisfy these security notions. Namely, - Assuming existence of indistinguishability obfuscation (iO) and hardness of Learning with Errors (LWE), we construct a public-key quantum money scheme with anonymity against users and traceability by authorities. Since it is a policy choice whether authorities should be able to track banknotes or not, we also construct an untraceable money scheme from the same cryptographic assumptions, where no one (not even the authorities) can track banknotes. Further, we show that the no-cloning principle, a result of quantum mechanics, allows us to construct schemes, with security guarantees that are classically impossible, for a seemingly unrelated application: voting! - Assuming iO and LWE, we construct a universally verifiable quantum voting scheme with classical votes. Finally, as a technical tool, we introduce the notion of publicly rerandomizable encryption with strong correctness, where no adversary is able to produce a malicious ciphertext and a malicious randomness such that the ciphertext before and after rerandomization decrypts to different values! We believe this might be of independent interest. - Assuming LWE, we construct a (post-quantum) classical publicly rerandomizable encryption scheme with strong correctness.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04494",
        "abstract url": "https://arxiv.org/abs/2411.04494",
        "title": "Online Omnidirectional Jumping Trajectory Planning for Quadrupedal Robots on Uneven Terrains",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "robot",
                "navigation"
            ]
        ],
        "abstract": "Natural terrain complexity often necessitates agile movements like jumping in animals to improve traversal efficiency. To enable similar capabilities in quadruped robots, complex real-time jumping maneuvers are required. Current research does not adequately address the problem of online omnidirectional jumping and neglects the robot's kinodynamic constraints during trajectory generation. This paper proposes a general and complete cascade online optimization framework for omnidirectional jumping for quadruped robots. Our solution systematically encompasses jumping trajectory generation, a trajectory tracking controller, and a landing controller. It also incorporates environmental perception to navigate obstacles that standard locomotion cannot bypass, such as jumping from high platforms. We introduce a novel jumping plane to parameterize omnidirectional jumping motion and formulate a tightly coupled optimization problem accounting for the kinodynamic constraints, simultaneously optimizing CoM trajectory, Ground Reaction Forces (GRFs), and joint states. To meet the online requirements, we propose an accelerated evolutionary algorithm as the trajectory optimizer to address the complexity of kinodynamic constraints. To ensure stability and accuracy in environmental perception post-landing, we introduce a coarse-to-fine relocalization method that combines global Branch and Bound (BnB) search with Maximum a Posteriori (MAP) estimation for precise positioning during navigation and jumping. The proposed framework achieves jump trajectory generation in approximately 0.1 seconds with a warm start and has been successfully validated on two quadruped robots on uneven terrains. Additionally, we extend the framework's versatility to humanoid robots.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Submitted to IJRR"
    },
    {
        "paper id": "2411.04509",
        "abstract url": "https://arxiv.org/abs/2411.04509",
        "title": "FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation",
        "rating": "-2",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "medical",
                "surgical",
                "diagnosis",
                "whole slide",
                "cancer",
                "tumor"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is considered the gold standard for pathologists and medical practitioners for tumor diagnosis, surgical planning, and post-operative assessment. With the rapid advancement of deep learning technologies, the development of numerous models based on convolutional neural networks and transformer-based models has been applied to the precise segmentation of WSIs. However, due to privacy regulations and the need to protect patient confidentiality, centralized storage and processing of image data are impractical. Training a centralized model directly is challenging to implement in medical settings due to these privacy concerns.This paper addresses the dispersed nature and privacy sensitivity of medical image data by employing a federated learning framework, allowing medical institutions to collaboratively learn while protecting patient privacy. Additionally, to address the issue of original data reconstruction through gradient inversion during the federated learning training process, differential privacy introduces noise into the model updates, preventing attackers from inferring the contributions of individual samples, thereby protecting the privacy of the training data.Experimental results show that the proposed method, FedDP, minimally impacts model accuracy while effectively safeguarding the privacy of cancer pathology image data, with only a slight decrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%, respectively. This approach facilitates cross-institutional collaboration and knowledge sharing while protecting sensitive data privacy, providing a viable solution for further research and application in the medical field.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted in BIBM2024"
    },
    {
        "paper id": "2411.04554",
        "abstract url": "https://arxiv.org/abs/2411.04554",
        "title": "Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Time series analysis finds wide applications in fields such as weather forecasting, anomaly detection, and behavior recognition. Previous methods attempted to model temporal variations directly using 1D time series. However, this has been quite challenging due to the discrete nature of data points in time series and the complexity of periodic variation. In terms of periodicity, taking weather and traffic data as an example, there are multi-periodic variations such as yearly, monthly, weekly, and daily, etc. In order to break through the limitations of the previous methods, we decouple the implied complex periodic variations into inclusion and overlap relationships among different level periodic components based on the observation of the multi-periodicity therein and its inclusion relationships. This explicitly represents the naturally occurring pyramid-like properties in time series, where the top level is the original time series and lower levels consist of periodic components with gradually shorter periods, which we call the periodic pyramid. To further extract complex temporal variations, we introduce self-attention mechanism into the periodic pyramid, capturing complex periodic relationships by computing attention between periodic components based on their inclusion, overlap, and adjacency relationships. Our proposed Peri-midFormer demonstrates outstanding performance in five mainstream time series analysis tasks, including short- and long-term forecasting, imputation, classification, and anomaly detection.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "38th Conference on Neural Information Processing Systems (NeurIPS 2024)"
    },
    {
        "paper id": "2411.04566",
        "abstract url": "https://arxiv.org/abs/2411.04566",
        "title": "On the average-case hardness of BosonSampling",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "BosonSampling is a popular candidate for near-term quantum advantage, which has now been experimentally implemented several times. The original proposal of Aaronson and Arkhipov from 2011 showed that classical hardness of BosonSampling is implied by a proof of the \"Gaussian Permanent Estimation\" conjecture. This conjecture states that $e^{-n\\log{n}-n-O(\\log n)}$ additive error estimates to the output probability of most random BosonSampling experiments are $\\#P$-hard. Proving this conjecture has since become the central question in the theory of quantum advantage. In this work we make progress by proving that $e^{-n\\log n -n - O(n^\u03b4)}$ additive error estimates to output probabilities of most random BosonSampling experiments are $\\#P$-hard, for any $\u03b4>0$. In the process, we circumvent all known barrier results for proving the hardness of BosonSampling experiments. This is nearly the robustness needed to prove hardness of BosonSampling -- the remaining hurdle is now \"merely\" to show that the $n^\u03b4$ in the exponent can be improved to $O(\\log n).$ We also obtain an analogous result for Random Circuit Sampling. Our result allows us to show, for the first time, a hardness of classical sampling result for random BosonSampling experiments, under an anticoncentration conjecture. Specifically, we prove the impossibility of multiplicative-error sampling from random BosonSampling experiments with probability $1-e^{-O(n)}$, unless the Polynomial Hierarchy collapses.",
        "subjects": [
            "quant-ph",
            "cs.CC"
        ],
        "comment": "41 pages, 6 figures"
    },
    {
        "paper id": "2411.04568",
        "abstract url": "https://arxiv.org/abs/2411.04568",
        "title": "Dynamic-Attention-based EEG State Transition Modeling for Emotion Recognition",
        "rating": "-2",
        "keywords": [
            [
                "EEG"
            ]
        ],
        "abstract": "Electroencephalogram (EEG)-based emotion decoding can objectively quantify people's emotional state and has broad application prospects in human-computer interaction and early detection of emotional disorders. Recently emerging deep learning architectures have significantly improved the performance of EEG emotion decoding. However, existing methods still fall short of fully capturing the complex spatiotemporal dynamics of neural signals, which are crucial for representing emotion processing. This study proposes a Dynamic-Attention-based EEG State Transition (DAEST) modeling method to characterize EEG spatiotemporal dynamics. The model extracts spatiotemporal components of EEG that represent multiple parallel neural processes and estimates dynamic attention weights on these components to capture transitions in brain states. The model is optimized within a contrastive learning framework for cross-subject emotion recognition. The proposed method achieved state-of-the-art performance on three publicly available datasets: FACED, SEED, and SEED-V. It achieved 75.4% accuracy in the binary classification of positive and negative emotions and 59.3% in nine-class discrete emotion classification on the FACED dataset, 88.1% in the three-class classification of positive, negative, and neutral emotions on the SEED dataset, and 73.6% in five-class discrete emotion classification on the SEED-V dataset. The learned EEG spatiotemporal patterns and dynamic transition properties offer valuable insights into neural dynamics underlying emotion processing.",
        "subjects": [
            "cs.HC",
            "eess.SP",
            "q-bio.NC"
        ],
        "comment": "14 pages, 6 figures"
    },
    {
        "paper id": "2411.04576",
        "abstract url": "https://arxiv.org/abs/2411.04576",
        "title": "\"I Always Felt that Something Was Wrong.\": Understanding Compliance Risks and Mitigation Strategies when Professionals Use Large Language Models",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have been increasingly adopted by professionals for work tasks. However, using LLMs also introduces compliance risks relating to privacy, ethics, and regulations. This study investigated the compliance risks professionals perceive with LLM use and their risk mitigation strategies. Semi-structured interviews were conducted with 24 law, healthcare, and academia professionals. Results showed that the main compliance concerns centered around potential exposure to sensitive customer/patient information through LLMs. To address risks, professionals reported proactively inputting distorted data to preserve privacy. However, full compliance proved challenging, given the complex interactions between user inputs, LLM behaviors, and regulations. This research provides valuable insights into designing LLMs with built-in privacy and risk controls to support professionals' evaluation and adoption of emerging AI technologies while meeting compliance obligations.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04593",
        "abstract url": "https://arxiv.org/abs/2411.04593",
        "title": "RainCloud: Decentralized Coordination and Communication in Heterogeneous IoT Swarms",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The increasing volume and complexity of IoT systems demand a transition from the cloud-centric model to a decentralized IoT architecture in the so-called Computing Continuum, with no or minimal reliance on central servers. This paradigm shift, however, raises novel research concerns for decentralized coordination, calling for accurate policies. However, building such strategies is not trivial. Our work aims to relieve the DevOps engineers from this concern and propose a solution for autonomous, decentralized task allocation at runtime for IoT systems. To this end, we present a semantic communication approach and an ad-hoc lightweight coordination strategy based on Ant Colony Optimization (ACO). We compare the ACO strategy with Random Search and Gossip protocol-based algorithms. We conduct accurate experiments with up to a hundred nodes in both a static and a dynamic environment, i.e., with device outages. We show that ACO finds a matching node with the smallest hops and messages sent. While the Gossip strategy can allocate the most tasks successfully, ACO scales better, thus being a promising candidate for decentralized task coordination in IoT clusters.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04629",
        "abstract url": "https://arxiv.org/abs/2411.04629",
        "title": "Pushing Boundaries: Quantum-Enhanced Leader Election and the Limits of Consensus",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "This work addresses the complexities involved in designing distributed quantum algorithms, highlighting that quantum entanglement does not bypass the Fischer-Lynch-Paterson (FLP) impossibility theorem in asynchronous networks. Although quantum resources such as entanglement offer potential speedups, the inherent constraints of classical communication remain. We develop a leader election algorithm as a proof of concept, demonstrating how entanglement can enhance efficiency while still contending with asynchronous delays. This algorithm serves as a foundation for a broader blueprint for future distributed quantum algorithms, providing insights into both the real performance gains and the limitations that entanglement offers in a distributed setting.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": "8 pages, 2 figures"
    },
    {
        "paper id": "2411.04638",
        "abstract url": "https://arxiv.org/abs/2411.04638",
        "title": "QCE'24 Tutorial: Quantum Annealing -- Emerging Exploration for Database Optimization",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum annealing is a meta-heuristic approach tailored to solve combinatorial optimization problems with quantum annealers. In this tutorial, we provide a fundamental and comprehensive introduction to quantum annealing and modern data management systems and show quantum annealing's potential benefits and applications in the realm of database optimization. We demonstrate how to apply quantum annealing for selected database optimization problems, which are critical challenges in many data management platforms. The demonstrations include solving join order optimization problems in relational databases, optimizing sophisticated transaction scheduling, and allocating virtual machines within cloud-based architectures with respect to sustainability metrics. On the one hand, the demonstrations show how to apply quantum annealing on key problems of database management systems (join order selection, transaction scheduling), and on the other hand, they show how quantum annealing can be integrated as a part of larger and dynamic optimization pipelines (virtual machine allocation). The goal of our tutorial is to provide a centralized and condensed source regarding theories and applications of quantum annealing technology for database researchers, practitioners, and everyone who wants to understand how to potentially optimize data management with quantum computing in practice. Besides, we identify the advantages, limitations, and potentials of quantum computing for future database and data management research.",
        "subjects": [
            "quant-ph",
            "cs.DB"
        ],
        "comment": "presented at IEEE Quantum Week 2024 (QCE'24), 5 pages"
    },
    {
        "paper id": "2411.04657",
        "abstract url": "https://arxiv.org/abs/2411.04657",
        "title": "EarCapAuth: Biometric Method for Earables Using Capacitive Sensing Eartips",
        "rating": "-2",
        "keywords": [
            [
                "Biometric"
            ]
        ],
        "abstract": "Earphones can give access to sensitive information via voice assistants which demands security methods that prevent unauthorized use. Therefore, we developed EarCapAuth, an authentication mechanism using 48 capacitive electrodes embedded into the soft silicone eartips of two earables. For evaluation, we gathered capactive ear canal measurements from 20 participants in 20 wearing sessions (12 at rest, 8 while walking). A per user classifier trained for authentication achieves an EER of 7.62% and can be tuned to a FAR (False Acceptance Rate) of 1% at FRR (False Rejection Rate) of 16.14%. For identification, EarCapAuth achieves 89.95%. This outperforms some earable biometric principles from related work. Performance under motion slightly decreased to 9.76% EER for authentication and 86.40% accuracy for identification. Enrollment can be performed rapidly with multiple short earpiece insertions and a biometric decision is made every 0.33s. In the future, EarCapAuth could be integrated into high-resolution brain sensing electrode tips.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04675",
        "abstract url": "https://arxiv.org/abs/2411.04675",
        "title": "Advancing Multi-Connectivity in Satellite-Terrestrial Integrated Networks: Architectures, Challenges, and Applications",
        "rating": "-2",
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "Multi-connectivity (MC) in satellite-terrestrial integrated networks (STINs), included in 3GPP standards, is regarded as a promising technology for future networks. The significant advantages of MC in improving coverage, communication, and sensing through satellite-terrestrial collaboration have sparked widespread interest. In this article, we first introduce three fundamental deployment architectures of MC systems in STINs, including multi-satellite, single-satellite single-base-station, and multi-satellite multi-base-station configurations. Considering the emerging but still evolving satellite networking, we explore system design challenges such as satellite networking schemes, e.g., cell-free and multi-tier satellite networks. Then, key technical challenges that severely influence the quality of mutual communications, including beamforming, channel estimation, and synchronization, are discussed subsequently. Furthermore, typical applications such as coverage enhancement, traffic offloading, collaborative sensing, and low-altitude communication are demonstrated, followed by a case study comparing coverage performance in MC and single-connectivity (SC) configurations. Several essential future research directions for MC in STINs are presented to facilitate further exploration.",
        "subjects": [
            "eess.SP",
            "cs.IT",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04682",
        "abstract url": "https://arxiv.org/abs/2411.04682",
        "title": "DNN-based 3D Cloud Retrieval for Variable Solar Illumination and Multiview Spaceborne Imaging",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "remotely sensed"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Climate studies often rely on remotely sensed images to retrieve two-dimensional maps of cloud properties. To advance volumetric analysis, we focus on recovering the three-dimensional (3D) heterogeneous extinction coefficient field of shallow clouds using multiview remote sensing data. Climate research requires large-scale worldwide statistics. To enable scalable data processing, previous deep neural networks (DNNs) can infer at spaceborne remote sensing downlink rates. However, prior methods are limited to a fixed solar illumination direction. In this work, we introduce the first scalable DNN-based system for 3D cloud retrieval that accommodates varying camera poses and solar directions. By integrating multiview cloud intensity images with camera poses and solar direction data, we achieve greater flexibility in recovery. Training of the DNN is performed by a novel two-stage scheme to address the high number of degrees of freedom in this problem. Our approach shows substantial improvements over previous state-of-the-art, particularly in handling variations in the sun's zenith angle.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "4 pages, 4 figures"
    },
    {
        "paper id": "2411.04706",
        "abstract url": "https://arxiv.org/abs/2411.04706",
        "title": "ESC-MISR: Enhancing Spatial Correlations for Multi-Image Super-Resolution in Remote Sensing",
        "rating": "-2",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-Image Super-Resolution (MISR) is a crucial yet challenging research task in the remote sensing community. In this paper, we address the challenging task of Multi-Image Super-Resolution in Remote Sensing (MISR-RS), aiming to generate a High-Resolution (HR) image from multiple Low-Resolution (LR) images obtained by satellites. Recently, the weak temporal correlations among LR images have attracted increasing attention in the MISR-RS task. However, existing MISR methods treat the LR images as sequences with strong temporal correlations, overlooking spatial correlations and imposing temporal dependencies. To address this problem, we propose a novel end-to-end framework named Enhancing Spatial Correlations in MISR (ESC-MISR), which fully exploits the spatial-temporal relations of multiple images for HR image reconstruction. Specifically, we first introduce a novel fusion module named Multi-Image Spatial Transformer (MIST), which emphasizes parts with clearer global spatial features and enhances the spatial correlations between LR images. Besides, we perform a random shuffle strategy for the sequential inputs of LR images to attenuate temporal dependencies and capture weak temporal correlations in the training stage. Compared with the state-of-the-art methods, our ESC-MISR achieves 0.70dB and 0.76dB cPSNR improvements on the two bands of the PROBA-V dataset respectively, demonstrating the superiority of our method.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04727",
        "abstract url": "https://arxiv.org/abs/2411.04727",
        "title": "Quantum Speedup for Polar Maximum Likelihood Decoding",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Conventional decoding algorithms for polar codes strive to balance achievable performance and computational complexity in classical computing. While maximum likelihood (ML) decoding guarantees optimal performance, its NP-hard nature makes it impractical for real-world systems. In this letter, we propose a novel ML decoding architecture for polar codes based on the Grover adaptive search, a quantum exhaustive search algorithm. Unlike conventional studies, our approach, enabled by a newly formulated objective function, uniquely supports Gray-coded multi-level modulation without expanding the search space size compared to the classical ML decoding. Simulation results demonstrate that our proposed quantum decoding achieves ML performance while providing a pure quadratic speedup in query complexity.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "eess.SP"
        ],
        "comment": "5pages, 6 figures"
    },
    {
        "paper id": "2411.04730",
        "abstract url": "https://arxiv.org/abs/2411.04730",
        "title": "Cloning Games, Black Holes and Cryptography",
        "rating": "-2",
        "keywords": [
            [
                "quantum",
                "physics"
            ]
        ],
        "abstract": "The no-cloning principle has played a foundational role in quantum information and cryptography. Following a long-standing tradition of studying quantum mechanical phenomena through the lens of interactive games, Broadbent and Lord (TQC 2020) formalized cloning games in order to quantitatively capture no-cloning in the context of unclonable encryption schemes. The conceptual contribution of this paper is the new, natural, notion of Haar cloning games together with two applications. In the area of black-hole physics, our game reveals that, in an idealized model of a black hole which features Haar random (or pseudorandom) scrambling dynamics, the information from infalling entangled qubits can only be recovered from either the interior or the exterior of the black hole -- but never from both places at the same time. In the area of quantum cryptography, our game helps us construct succinct unclonable encryption schemes from the existence of pseudorandom unitaries, thereby, for the first time, bridging the gap between \"MicroCrypt\" and unclonable cryptography. The technical contribution of this work is a tight analysis of Haar cloning games which requires us to overcome many long-standing barriers in our understanding of cloning games. Answering these questions provably requires us to go beyond existing methods (Tomamichel, Fehr, Kaniewski and Wehner, New Journal of Physics 2013). In particular, we show a new technique for analyzing cloning games with respect to binary phase states through the lens of binary subtypes, and combine it with novel bounds on the operator norms of block-wise tensor products of matrices.",
        "subjects": [
            "quant-ph",
            "cs.CR",
            "hep-th"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04731",
        "abstract url": "https://arxiv.org/abs/2411.04731",
        "title": "MISGUIDE: Security-Aware Attack Analytics for Smart Grid Load Frequency Control",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "Attack"
            ]
        ],
        "abstract": "Incorporating advanced information and communication technologies into smart grids (SGs) offers substantial operational benefits while increasing vulnerability to cyber threats like false data injection (FDI) attacks. Current SG attack analysis tools predominantly employ formal methods or adversarial machine learning (ML) techniques with rule-based bad data detectors to analyze the attack space. However, these attack analytics either generate simplistic attack vectors detectable by the ML-based anomaly detection models (ADMs) or fail to identify critical attack vectors from complex controller dynamics in a feasible time. This paper introduces MISGUIDE, a novel defense-aware attack analytics designed to extract verifiable multi-time slot-based FDI attack vectors from complex SG load frequency control dynamics and ADMs, utilizing the Gurobi optimizer. MISGUIDE can identify optimal (maliciously triggering under/over frequency relays in minimal time) and stealthy attack vectors. Using real-world load data, we validate the MISGUIDE-identified attack vectors through real-time hardware-in-the-loop (OPALRT) simulations of the IEEE 39-bus system.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "12 page journal"
    },
    {
        "paper id": "2411.04767",
        "abstract url": "https://arxiv.org/abs/2411.04767",
        "title": "Why quantum state verification cannot be both efficient and secure: a categorical approach",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "The advantage of quantum protocols lies in the inherent properties of the shared quantum states. These states are sometimes provided by sources that are not trusted, and therefore need to be verified. Finding secure and efficient quantum state verification protocols remains a big challenge, and recent works illustrate trade-offs between efficiency and security for different groups of states in restricted settings. However, whether a universal trade-off exists for all quantum states and all verification strategies remains unknown. In this work, we instantiate the categorical composable cryptography framework to show a fundamental limit for quantum state verification for all cut-and-choose approaches used to verify arbitrary quantum states. Our findings show that the prevailing cut-and-choose techniques cannot lead to quantum state verification protocols that are both efficient and secure.",
        "subjects": [
            "quant-ph",
            "cs.CR",
            "math.CT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04789",
        "abstract url": "https://arxiv.org/abs/2411.04789",
        "title": "Distributed Attack-Resilient Platooning Against False Data Injection",
        "rating": "-2",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Attack"
            ]
        ],
        "abstract": "This paper presents a novel distributed vehicle platooning control and coordination strategy. We propose a distributed predecessor-follower CACC scheme that allows to choose an arbitrarily small inter-vehicle distance while guaranteeing no rear-end collisions occur, even in the presence of undetected cyber-attacks on the communication channels such as false data injection. The safety guarantees of the CACC policy are derived by combing a sensor-based ACC policy that explicitly accounts for actuator saturation, and a communication-based predictive term that has state-dependent limits on its control authority, thus containing the effects of an unreliable communication channel. An undetected attack may still however be able to degrade platooning performance. To mitigate it, we propose a tailored Kalman observer-based attack detection algorithm that initially triggers a switch from the CACC policy to the ACC policy. Subsequently, by relying on a high-level coordinator, our strategy allows to isolate a compromised vehicle from the platoon formation by reconfiguring the platoon topology itself. The coordinator can also handle merging and splitting requests. We compare our algorithm in simulation against a state of the art distributed MPC scheme and we extensively test our full method in practice on a real system, a team of scaled-down car-like robots. Furthermore, we share the code to run both the simulations and robotic experiments.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04798",
        "abstract url": "https://arxiv.org/abs/2411.04798",
        "title": "Orbit: A Framework for Designing and Evaluating Multi-objective Rankers",
        "rating": "-2",
        "keywords": [
            [
                "recommendation"
            ]
        ],
        "abstract": "Machine learning in production needs to balance multiple objectives: This is particularly evident in ranking or recommendation models, where conflicting objectives such as user engagement, satisfaction, diversity, and novelty must be considered at the same time. However, designing multi-objective rankers is inherently a dynamic wicked problem -- there is no single optimal solution, and the needs evolve over time. Effective design requires collaboration between cross-functional teams and careful analysis of a wide range of information. In this work, we introduce Orbit, a conceptual framework for Objective-centric Ranker Building and Iteration. The framework places objectives at the center of the design process, to serve as boundary objects for communication and guide practitioners for design and evaluation. We implement Orbit as an interactive system, which enables stakeholders to interact with objective spaces directly and supports real-time exploration and evaluation of design trade-offs. We evaluate Orbit through a user study involving twelve industry practitioners, showing that it supports efficient design space exploration, leads to more informed decision-making, and enhances awareness of the inherent trade-offs of multiple objectives. Orbit (1) opens up new opportunities of an objective-centric design process for any multi-objective ML models, as well as (2) sheds light on future designs that push practitioners to go beyond a narrow metric-centric or example-centric mindset.",
        "subjects": [
            "cs.HC",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04817",
        "abstract url": "https://arxiv.org/abs/2411.04817",
        "title": "Harnessing the Power of Gradient-Based Simulations for Multi-Objective Optimization in Particle Accelerators",
        "rating": "-2",
        "keywords": [
            [
                "physics"
            ]
        ],
        "abstract": "Particle accelerator operation requires simultaneous optimization of multiple objectives. Multi-Objective Optimization (MOO) is particularly challenging due to trade-offs between the objectives. Evolutionary algorithms, such as genetic algorithm (GA), have been leveraged for many optimization problems, however, they do not apply to complex control problems by design. This paper demonstrates the power of differentiability for solving MOO problems using a Deep Differentiable Reinforcement Learning (DDRL) algorithm in particle accelerators. We compare DDRL algorithm with Model Free Reinforcement Learning (MFRL), GA and Bayesian Optimization (BO) for simultaneous optimization of heat load and trip rates in the Continuous Electron Beam Accelerator Facility (CEBAF). The underlying problem enforces strict constraints on both individual states and actions as well as cumulative (global) constraint for energy requirements of the beam. A physics-based surrogate model based on real data is developed. This surrogate model is differentiable and allows back-propagation of gradients. The results are evaluated in the form of a Pareto-front for two objectives. We show that the DDRL outperforms MFRL, BO, and GA on high dimensional problems.",
        "subjects": [
            "physics.acc-ph",
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04844",
        "abstract url": "https://arxiv.org/abs/2411.04844",
        "title": "Differentiable Gaussian Representation for Incomplete CT Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "CT",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Incomplete Computed Tomography (CT) benefits patients by reducing radiation exposure. However, reconstructing high-fidelity images from limited views or angles remains challenging due to the ill-posed nature of the problem. Deep Learning Reconstruction (DLR) methods have shown promise in enhancing image quality, but the paradox between training data diversity and high generalization ability remains unsolved. In this paper, we propose a novel Gaussian Representation for Incomplete CT Reconstruction (GRCT) without the usage of any neural networks or full-dose CT data. Specifically, we model the 3D volume as a set of learnable Gaussians, which are optimized directly from the incomplete sinogram. Our method can be applied to multiple views and angles without changing the architecture. Additionally, we propose a differentiable Fast CT Reconstruction method for efficient clinical usage. Extensive experiments on multiple datasets and settings demonstrate significant improvements in reconstruction quality metrics and high efficiency. We plan to release our code as open-source.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04861",
        "abstract url": "https://arxiv.org/abs/2411.04861",
        "title": "High Entropy Alloy property predictions using Transformer-based language model",
        "rating": "-2",
        "keywords": [
            [
                "Alloy"
            ]
        ],
        "abstract": "This study introduces a language transformer-based machine learning model to predict key mechanical properties of high-entropy alloys (HEAs), addressing the challenges due to their complex, multi-principal element compositions and limited experimental data. By pre-training the transformer on extensive synthetic materials data and fine-tuning it with specific HEA datasets, the model effectively captures intricate elemental interactions through self-attention mechanisms. This approach mitigates data scarcity issues via transfer learning, enhancing predictive accuracy for properties like elongation (%) and ultimate tensile strength (UTS) compared to traditional regression models such as Random Forests and Gaussian Processes. The model's interpretability is enhanced by visualizing attention weights, revealing significant elemental relationships that align with known metallurgical principles. This work demonstrates the potential of transformer models to accelerate materials discovery and optimization, enabling accurate property predictions, thereby advancing the field of materials informatics.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04874",
        "abstract url": "https://arxiv.org/abs/2411.04874",
        "title": "Hardness of approximation for ground state problems",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "After nearly two decades of research, the question of a quantum PCP theorem for quantum Constraint Satisfaction Problems (CSPs) remains wide open. As a result, proving QMA-hardness of approximation for ground state energy estimation has remained elusive. Recently, it was shown [Bittel, Gharibian, Kliesch, CCC 2023] that a natural problem involving variational quantum circuits is QCMA-hard to approximate within ratio N^(1-eps) for any eps > 0 and N the input size. Unfortunately, this problem was not related to quantum CSPs, leaving the question of hardness of approximation for quantum CSPs open. In this work, we show that if instead of focusing on ground state energies, one considers computing properties of the ground space, QCMA-hardness of computing ground space properties can be shown. In particular, we show that it is (1) QCMA-complete within ratio N^(1-eps) to approximate the Ground State Connectivity problem (GSCON), and (2) QCMA-hard within the same ratio to estimate the amount of entanglement of a local Hamiltonian's ground state, denoted Ground State Entanglement (GSE). As a bonus, a simplification of our construction yields NP-completeness of approximation for a natural k-SAT reconfiguration problem, to be contrasted with the recent PCP-based PSPACE hardness of approximation results for a different definition of k-SAT reconfiguration [Karthik C.S. and Manurangsi, 2023, and Hirahara, Ohsaka, STOC 2024].",
        "subjects": [
            "quant-ph",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04928",
        "abstract url": "https://arxiv.org/abs/2411.04928",
        "title": "DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce \\textbf{DimensionX}, a framework designed to generate photorealistic 3D and 4D scenes from just a single image with video diffusion. Our approach begins with the insight that both the spatial structure of a 3D scene and the temporal evolution of a 4D scene can be effectively represented through sequences of video frames. While recent video diffusion models have shown remarkable success in producing vivid visuals, they face limitations in directly recovering 3D/4D scenes due to limited spatial and temporal controllability during generation. To overcome this, we propose ST-Director, which decouples spatial and temporal factors in video diffusion by learning dimension-aware LoRAs from dimension-variant data. This controllable video diffusion approach enables precise manipulation of spatial structure and temporal dynamics, allowing us to reconstruct both 3D and 4D representations from sequential frames with the combination of spatial and temporal dimensions. Additionally, to bridge the gap between generated videos and real-world scenes, we introduce a trajectory-aware mechanism for 3D generation and an identity-preserving denoising strategy for 4D generation. Extensive experiments on various real-world and synthetic datasets demonstrate that DimensionX achieves superior results in controllable video generation, as well as in 3D and 4D scene generation, compared with previous methods.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "comment": "Project Page: https://chenshuo20.github.io/DimensionX/"
    },
    {
        "paper id": "2411.04972",
        "abstract url": "https://arxiv.org/abs/2411.04972",
        "title": "Uniformity testing when you have the source code",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We study quantum algorithms for verifying properties of the output probability distribution of a classical or quantum circuit, given access to the source code that generates the distribution. We consider the basic task of uniformity testing, which is to decide if the output distribution is uniform on $[d]$ or $\u03b5$-far from uniform in total variation distance. More generally, we consider identity testing, which is the task of deciding if the output distribution equals a known hypothesis distribution, or is $\u03b5$-far from it. For both problems, the previous best known upper bound was $O(\\min\\{d^{1/3}/\u03b5^{2},d^{1/2}/\u03b5\\})$. Here we improve the upper bound to $O(\\min\\{d^{1/3}/\u03b5^{4/3}, d^{1/2}/\u03b5\\})$, which we conjecture is optimal.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.DS"
        ],
        "comment": "21 pages"
    },
    {
        "paper id": "2411.05003",
        "abstract url": "https://arxiv.org/abs/2411.05003",
        "title": "ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning",
        "rating": "-2",
        "keywords": [
            [
                "point cloud",
                "depth"
            ],
            [
                "diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recently, breakthroughs in video modeling have allowed for controllable camera trajectories in generated videos. However, these methods cannot be directly applied to user-provided videos that are not generated by a video model. In this paper, we present ReCapture, a method for generating new videos with novel camera trajectories from a single user-provided video. Our method allows us to re-generate the reference video, with all its existing scene motion, from vastly different angles and with cinematic camera motion. Notably, using our method we can also plausibly hallucinate parts of the scene that were not observable in the reference video. Our method works by (1) generating a noisy anchor video with a new camera trajectory using multiview diffusion models or depth-based point cloud rendering and then (2) regenerating the anchor video into a clean and temporally consistent reangled video using our proposed masked video fine-tuning technique.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.LG"
        ],
        "comment": "project page: https://generative-video-camera-controls.github.io/"
    },
    {
        "paper id": "2411.05103",
        "abstract url": "https://arxiv.org/abs/2411.05103",
        "title": "MoHeat: A Modular Platform for High-Responsive Non-Contact Thermal Feedback Interactions",
        "rating": "-2",
        "keywords": [
            [
                "Thermal"
            ]
        ],
        "abstract": "MoHeat is a modular hardware and software platform designed for rapid prototyping of highly responsive, non-contact thermal feedback interactions. In our previous work, we developed an intensity-adjustable, highly responsive, non-contact thermal feedback system by integrating the vortex effect and thermal radiation. In this study, we further enhanced the system by developing an authoring tool that allows users to freely adjust the intensity of thermal stimuli, the duration of stimuli, the delay time before stimuli, and the interval between alternating hot and cold stimuli. This modular approach enables countless combinations of non-contact thermal feedback experiences.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05108",
        "abstract url": "https://arxiv.org/abs/2411.05108",
        "title": "Simultaneous Presentation of Thermal and Mechanical Stimulation Using High-Intensity Airborne Ultrasound",
        "rating": "-2",
        "keywords": [
            [
                "Thermal"
            ]
        ],
        "abstract": "In this study, we propose a non-contact thermal presentation method using airborne ultrasound. We generate strong sound field directly on the human skin and present a perceivable temperature rise. The proposed method enables simultaneous presentation of mechanical and thermal stimuli. In preliminary experiments, we confirmed that temperature increase of 5.4 ${}^\\circ$C occurs at the palm after 5.0 s.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05120",
        "abstract url": "https://arxiv.org/abs/2411.05120",
        "title": "On the Computational Complexity of Schr\u00f6dinger Operators",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We study computational problems related to the Schr\u00f6dinger operator $H = -\u0394+ V$ in the real space under the condition that (i) the potential function $V$ is smooth and has its value and derivative bounded within some polynomial of $n$ and (ii) $V$ only consists of $O(1)$-body interactions. We prove that (i) simulating the dynamics generated by the Schr\u00f6dinger operator implements universal quantum computation, i.e., it is BQP-hard, and (ii) estimating the ground energy of the Schr\u00f6dinger operator is as hard as estimating that of local Hamiltonians with no sign problem (a.k.a. stoquastic Hamiltonians), i.e., it is StoqMA-complete. This result is particularly intriguing because the ground energy problem for general bosonic Hamiltonians is known to be QMA-hard and it is widely believed that $\\texttt{StoqMA}\\varsubsetneq \\texttt{QMA}$.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "math-ph"
        ],
        "comment": "32 pages, 5 figures, submitted to QIP 2025"
    },
    {
        "paper id": "2411.05129",
        "abstract url": "https://arxiv.org/abs/2411.05129",
        "title": "Silicone-made Tactile Actuator Integrated with Hot Thermo-fiber Finger Sleeve",
        "rating": "-2",
        "keywords": [
            [
                "thermal"
            ]
        ],
        "abstract": "Multi-mode haptic feedback is essential to achieve high realism and immersion in virtual environments. This paper proposed a novel silicone fingertip actuator integrated with a hot thermal fabric finger sleeve to render pressure, vibration, and hot thermal feedback simultaneously. The actuator is pneumatically actuated to render a realistic and effective tactile experience in accordance with hot thermal sensation. The silicone actuator, with two air chambers controlled by pneumatic valves connected to compressed air tanks. Simultaneously, a PWM signal from a microcontroller regulates the temperature of the thermal fabric sleeve, enhancing overall system functionality. The lower chamber of the silicone actuator is responsible for pressure feedback, whereas the upper chamber is devoted to vibrotactile feedback. The conductive yarn or thread was utilized to spread the thermal feedback actuation points on the thermal fabric's surface. To demonstrate the actuator's capability, a VR environment consisting of a bowl of liquid and a stove with fire was designed. Based on different functionalities the scenario can simulate the tactile perception of pressure, vibration, and temperature simultaneously or consecutively.",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05142",
        "abstract url": "https://arxiv.org/abs/2411.05142",
        "title": "Relaxed or Tense? Mutual Biosignal Transmission with Heartbeat Vibrations during Online Gameplay",
        "rating": "-2",
        "keywords": [
            [
                "Biosignal"
            ]
        ],
        "abstract": "Esports offers a platform for players to engage in competitive and cooperative gaming with others remotely via the Internet. Despite these opportunities for social interaction, many players may still experience loneliness while playing online games. This study aims to enhance the social presence of partner players during online gameplay. The demonstration system, designed for 1-on-1 online competitive games, mutually transmits the partner's biosignals, through heartbeat-like vibrotactile stimuli. The system generates vibrotactile signals that represent two-dimensional emotions, arousal and valence, based on biosignals such as heart rate and electrodermal activity.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05145",
        "abstract url": "https://arxiv.org/abs/2411.05145",
        "title": "v-Relax: Virtual Footbath Experiencing by Airflow and Thermal Presentation",
        "rating": "-2",
        "keywords": [
            [
                "Thermal"
            ]
        ],
        "abstract": "Relaxation is a critical counterbalance to the demands of modern business life. Footbaths, a simple yet highly effective therapeutic practice, have been used for centuries across various cultures to promote relaxation and overall well-being. This study presents a novel approach to simulating the experience of a public footbath through the use of tactile and thermal stimulation of airflow to the calf and those on the foot soles. Our system aims to offer a realistic and immersive virtual footbath experience without the need for actual water, by controlling the temperature and airflow to mimic the sensation of soaking feet in water or a water wave. Without using actual water, our system can be more compact, highly responsive, and more reproducible. The layer of airflow is made as thin as possible by adjusting air outlet, and the Coanda effect is also considered to generate a water surface more realistic. The system can provide a multi-sensory experience, including visual and audio feedback of water flow, enhancing the relaxation and therapeutic benefits of a footbath.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05148",
        "abstract url": "https://arxiv.org/abs/2411.05148",
        "title": "Haptic VR Simulation for Surgery Procedures in Medical Training",
        "rating": "-2",
        "keywords": [
            [
                "Medical",
                "Surgery"
            ]
        ],
        "abstract": "Traditional medical training faces challenges like ethical concerns, safety risks, and high costs. VR technology offers a promising solution but is limited by low complexity and lack of tactile feedback. This paper presents a cost-effective haptic VR surgery simulation which simulates realistic Kidney Transplant using commercial devices to enhance training authenticity and immersion. Trainees can conduct incision and anastomosis procedures using a haptic stylus device that provides tactile sensations. Results from the test with medical participants showed that haptic feedback positively enhances the VR medical training experience.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05155",
        "abstract url": "https://arxiv.org/abs/2411.05155",
        "title": "DynaPain: Moving Flame Beetle with Dynamic Pain Illusion Adapting Apparent Movement to Thermal Grill Illusion",
        "rating": "-2",
        "keywords": [
            [
                "Thermal"
            ]
        ],
        "abstract": "Pain sensation presentation with movable sensory position is important to imitate the pain caused by objects in motion and the pain corresponding to a person's movements. We aimed at proposing a novel dynamic pain sensation experience, called DynaPain. DynaPain was achieved by the non-contact thermal grill illusion and the apparent movement. The demonstration provided the dynamic heat and pain experience through interaction with a flame beetle moving on the arm.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05157",
        "abstract url": "https://arxiv.org/abs/2411.05157",
        "title": "HeatFlicker: A Virtual Campfire System Utilizing Flickering Thermal Illusions by Asymmetric Vibrations",
        "rating": "-2",
        "keywords": [
            [
                "Thermal"
            ]
        ],
        "abstract": "In recent years, thermal feedback has emerged as a significant sensory modality in virtual reality. However, the concept of conveying the sensation of thermal movement remains largely unexplored. We propose HeatFlicker, a virtual campfire device that recreates the flickering of fire by using a thermal illusion of moving heat identified in preliminary experiments. This device creates the illusion of heat moving from a fixed heat source. In our demonstration, we provide a novel thermal experience by simulating the flickering of a real fire.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05176",
        "abstract url": "https://arxiv.org/abs/2411.05176",
        "title": "How to Delete Without a Trace: Certified Deniability in a Quantum World",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Is it possible to comprehensively destroy a piece of quantum information, so that nothing is left behind except the memory of whether one had it at one point? For example, various works, most recently Morimae, Poremba, and Yamakawa (TQC 2024), show how to construct a signature scheme with certified deletion where a user who deletes a signature on m cannot later produce a signature for m. However, in all of the existing schemes, even after deletion the user is still able keep irrefutable evidence that m was signed, and thus they do not fully capture the spirit of deletion. In this work, we initiate the study of certified deniability in order to obtain a more comprehensive notion of deletion. Certified deniability uses a simulation-based security definition, ensuring that any information the user has kept after deletion could have been learned without being given the deleteable object to begin with; meaning that deletion leaves no trace behind! We define and construct two non-interactive primitives that satisfy certified deniability in the quantum random oracle model: signatures and non-interactive zero-knowledge arguments (NIZKs). As a consequence, for example, it is not possible to delete a signature/NIZK and later provide convincing evidence that it used to exist. Notably, our results utilize uniquely quantum phenomena to bypass the celebrated result of Pass (CRYPTO, 2003) showing that deniable NIZKs are impossible even in the random oracle model.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05188",
        "abstract url": "https://arxiv.org/abs/2411.05188",
        "title": "AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive Outcome for Infant Brain Injury",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of every 1,000 newborns, with 30% to 50% of cases resulting in adverse neurocognitive outcomes. However, these outcomes can only be reliably assessed as early as age 2. Therefore, early and accurate prediction of HIE-related neurocognitive outcomes using deep learning models is critical for improving clinical decision-making, guiding treatment decisions and assessing novel therapies. However, a major challenge in developing deep learning models for this purpose is the scarcity of large, annotated HIE datasets. We have assembled the first and largest public dataset, however it contains only 156 cases with 2-year neurocognitive outcome labels. In contrast, we have collected 8,859 normal brain black Magnetic Resonance Imagings (MRIs) with 0-97 years of age that are available for brain age estimation using deep learning models. In this paper, we introduce AGE2HIE to transfer knowledge learned by deep learning models from healthy controls brain MRIs to a diseased cohort, from structural to diffusion MRIs, from regression of continuous age estimation to prediction of the binary neurocognitive outcomes, and from lifespan age (0-97 years) to infant (0-2 weeks). Compared to training from scratch, transfer learning from brain age estimation significantly improves not only the prediction accuracy (3% or 2% improvement in same or multi-site), but also the model generalization across different sites (5% improvement in cross-site validation).",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "q-bio.NC"
        ],
        "comment": "Submitted to ISBI 2025"
    },
    {
        "paper id": "2411.05208",
        "abstract url": "https://arxiv.org/abs/2411.05208",
        "title": "DQC1-hardness of estimating correlation functions",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Out-of-Time-Order Correlation function measures transport properties of dynamical systems. They are ubiquitously used to measure quantum mechanical quantities, such as scrambling times, criticality in phase transitions, and detect onset of thermalisation. We characterise the computational complexity of estimating OTOCs over all eigenstates and show it is Complete for the One Clean Qubit model (DQC1). We then generalise our setup to establish DQC1-Completeness of N-time Correlation functions over all eigenstates. Building on previous results, the DQC1-Completeness of OTOCs and N-time Correlation functions then allows us to highlight a dichotomy between query complexity and circuit complexity of estimating correlation functions.",
        "subjects": [
            "quant-ph",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05236",
        "abstract url": "https://arxiv.org/abs/2411.05236",
        "title": "Designing a Light-based Communication System with a Biomolecular Receiver",
        "rating": "-2",
        "keywords": [
            [
                "Biomolecular"
            ]
        ],
        "abstract": "Biological systems transduce signals from their surroundings in numerous ways. This paper introduces a communication system using the light-gated ion channel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in response to light. Our design includes a ChR2-based receiver along with encoding, modulation techniques and detection. Analyzing the resulting communication system, we discuss the effect of different parameters on the performance of the system. Finally, we discuss its potential design in the context of bio-engineering and light-based communication and show that the data rate scales up with the number of receptors, indicating that high-speed communication may be possible.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "11 pages, 16 figures and 4 Tables"
    },
    {
        "paper id": "2411.05247",
        "abstract url": "https://arxiv.org/abs/2411.05247",
        "title": "Traceable random numbers from a nonlocal quantum advantage",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "The unpredictability of random numbers is fundamental to both digital security and applications that fairly distribute resources. However, existing random number generators have limitations-the generation processes cannot be fully traced, audited, and certified to be unpredictable. The algorithmic steps used in pseudorandom number generators are auditable, but they cannot guarantee that their outputs were a priori unpredictable given knowledge of the initial seed. Device-independent quantum random number generators can ensure that the source of randomness was unknown beforehand, but the steps used to extract the randomness are vulnerable to tampering. Here, for the first time, we demonstrate a fully traceable random number generation protocol based on device-independent techniques. Our protocol extracts randomness from unpredictable non-local quantum correlations, and uses distributed intertwined hash chains to cryptographically trace and verify the extraction process. This protocol is at the heart of a public traceable and certifiable quantum randomness beacon that we have launched. Over the first 40 days of operation, we completed the protocol 7434 out of 7454 attempts -- a success rate of 99.7%. Each time the protocol succeeded, the beacon emitted a pulse of 512 bits of traceable randomness. The bits are certified to be uniform with error times actual success probability bounded by $2^{-64}$. The generation of certifiable and traceable randomness represents one of the first public services that operates with an entanglement-derived advantage over comparable classical approaches.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": "40 pages, 4 main figures, 10 supplementary figures"
    },
    {
        "paper id": "2411.05248",
        "abstract url": "https://arxiv.org/abs/2411.05248",
        "title": "Ten Pillars for Data Meshes",
        "rating": "-2",
        "keywords": [
            [
                "biomedical",
                "health"
            ]
        ],
        "abstract": "Over the past few years, a growing number of data platforms have emerged, including data commons, data repositories, and databases containing biomedical, environmental, social determinants of health and other data relevant to improving health outcomes. With the growing number of data platforms, interoperating multiple data platforms to form data meshes, data fabrics and other types of data ecosystems reduces data silos, expands data use, and increases the potential for new discoveries. In this paper, we introduce ten principles, which we call pillars, for data meshes. The goals of the principles are 1) to make it easier, faster, and more uniform to set up a data mesh from multiple data platforms; and, 2) to make it easier, faster, and more uniform, for a data platform to join one or more data meshes. The hope is that the greater availability of data through data meshes will accelerate research and that the greater uniformity of meshes will lower the cost of developing meshes and connecting a data platform to them.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "10 pages, 1 figure"
    },
    {
        "paper id": "2411.05269",
        "abstract url": "https://arxiv.org/abs/2411.05269",
        "title": "Cancer-Net SCa-Synth: An Open Access Synthetically Generated 2D Skin Lesion Dataset for Skin Cancer Classification",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "health",
                "healthcare",
                "Cancer",
                "Lesion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In the United States, skin cancer ranks as the most commonly diagnosed cancer, presenting a significant public health issue due to its high rates of occurrence and the risk of serious complications if not caught early. Recent advancements in dataset curation and deep learning have shown promise in quick and accurate detection of skin cancer. However, current open-source datasets have significant class imbalances which impedes the effectiveness of these deep learning models. In healthcare, generative artificial intelligence (AI) models have been employed to create synthetic data, addressing data imbalance in datasets by augmenting underrepresented classes and enhancing the overall quality and performance of machine learning models. In this paper, we build on top of previous work by leveraging new advancements in generative AI, notably Stable Diffusion and DreamBooth. We introduce Cancer-Net SCa-Synth, an open access synthetically generated 2D skin lesion dataset for skin cancer classification. Further analysis on the data effectiveness by comparing the ISIC 2020 test set performance for training with and without these synthetic images for a simple model highlights the benefits of leveraging synthetic data to improve performance. Cancer-Net SCa-Synth is publicly available at https://github.com/catai9/Cancer-Net-SCa-Synth as part of a global open-source initiative for accelerating machine learning for cancer care.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05298",
        "abstract url": "https://arxiv.org/abs/2411.05298",
        "title": "Integrated Power and Thermal Management for Enhancing Energy Efficiency and Battery Life in Connected and Automated Electric Vehicles",
        "rating": "-2",
        "keywords": [
            [
                "Thermal"
            ]
        ],
        "abstract": "Effective power and thermal management are essential for ensuring battery efficiency, safety, and longevity in Connected and Automated Electric Vehicles (CAEVs). However, real-time implementation is challenging due to the multi-timescale dynamics and complex trade-offs between energy consumption, battery degradation, traffic efficiency, and thermal regulation. This paper proposes a novel integrated power and thermal management strategy based on the Multi-Horizon Model Predictive Control (MH-MPC) framework to enhance energy efficiency, optimize battery temperature, ensure traffic safety and efficiency, and reduce battery degradation for CAEVs. The proposed strategy is formulated with a focus on the aging term, allowing it to more effectively manage the trade-offs between energy consumption, battery degradation, and temperature regulation. Moreover, the proposed strategy leverages multi-horizon optimization to achieve substantial improvements, reducing computation time by 7.18%, cooling energy by 14.22%, traction energy by 8.26%, battery degradation loss by over 22%, and battery degradation inconsistency by 36.57% compared to the benchmark strategy. Furthermore, sensitivity analyses of key parameters, including weighting factors, sampling time, and prediction horizons, demonstrate the robustness of the strategy and underscore its potential for practical applications in extending battery lifespan while ensuring safety and efficiency.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04491",
        "abstract url": "https://arxiv.org/abs/2411.04491",
        "title": "Series-to-Series Diffusion Bridge Model",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models have risen to prominence in time series forecasting, showcasing their robust capability to model complex data distributions. However, their effectiveness in deterministic predictions is often constrained by instability arising from their inherent stochasticity. In this paper, we revisit time series diffusion models and present a comprehensive framework that encompasses most existing diffusion-based methods. Building on this theoretical foundation, we propose a novel diffusion-based time series forecasting model, the Series-to-Series Diffusion Bridge Model ($\\mathrm{S^2DBM}$), which leverages the Brownian Bridge process to reduce randomness in reverse estimations and improves accuracy by incorporating informative priors and conditions derived from historical time series data. Experimental results demonstrate that $\\mathrm{S^2DBM}$ delivers superior performance in point-to-point forecasting and competes effectively with other diffusion-based models in probabilistic forecasting.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04899",
        "abstract url": "https://arxiv.org/abs/2411.04899",
        "title": "Sampling-guided Heterogeneous Graph Neural Network with Temporal Smoothing for Scalable Longitudinal Data Imputation",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "Disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a novel framework, the Sampling-guided Heterogeneous Graph Neural Network (SHT-GNN), to effectively tackle the challenge of missing data imputation in longitudinal studies. Unlike traditional methods, which often require extensive preprocessing to handle irregular or inconsistent missing data, our approach accommodates arbitrary missing data patterns while maintaining computational efficiency. SHT-GNN models both observations and covariates as distinct node types, connecting observation nodes at successive time points through subject-specific longitudinal subnetworks, while covariate-observation interactions are represented by attributed edges within bipartite graphs. By leveraging subject-wise mini-batch sampling and a multi-layer temporal smoothing mechanism, SHT-GNN efficiently scales to large datasets, while effectively learning node representations and imputing missing data. Extensive experiments on both synthetic and real-world datasets, including the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, demonstrate that SHT-GNN significantly outperforms existing imputation methods, even with high missing data rates. The empirical results highlight SHT-GNN's robust imputation capabilities and superior performance, particularly in the context of complex, large-scale longitudinal data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04907",
        "abstract url": "https://arxiv.org/abs/2411.04907",
        "title": "Enhancing Missing Data Imputation through Combined Bipartite Graph and Complete Directed Graph",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we aim to address a significant challenge in the field of missing data imputation: identifying and leveraging the interdependencies among features to enhance missing data imputation for tabular data. We introduce a novel framework named the Bipartite and Complete Directed Graph Neural Network (BCGNN). Within BCGNN, observations and features are differentiated as two distinct node types, and the values of observed features are converted into attributed edges linking them. The bipartite segment of our framework inductively learns embedding representations for nodes, efficiently utilizing the comprehensive information encapsulated in the attributed edges. In parallel, the complete directed graph segment adeptly outlines and communicates the complex interdependencies among features. When compared to contemporary leading imputation methodologies, BCGNN consistently outperforms them, achieving a noteworthy average reduction of 15% in mean absolute error for feature imputation tasks under different missing mechanisms. Our extensive experimental investigation confirms that an in-depth grasp of the interdependence structure substantially enhances the model's feature embedding ability. We also highlight the model's superior performance in label prediction tasks involving missing data, and its formidable ability to generalize to unseen data points.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04946",
        "abstract url": "https://arxiv.org/abs/2411.04946",
        "title": "SPGD: Steepest Perturbed Gradient Descent Optimization",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Optimization algorithms are pivotal in advancing various scientific and industrial fields but often encounter obstacles such as trapping in local minima, saddle points, and plateaus (flat regions), which makes the convergence to reasonable or near-optimal solutions particularly challenging. This paper presents the Steepest Perturbed Gradient Descent (SPGD), a novel algorithm that innovatively combines the principles of the gradient descent method with periodic uniform perturbation sampling to effectively circumvent these impediments and lead to better solutions whenever possible. SPGD is distinctively designed to generate a set of candidate solutions and select the one exhibiting the steepest loss difference relative to the current solution. It enhances the traditional gradient descent approach by integrating a strategic exploration mechanism that significantly increases the likelihood of escaping sub-optimal local minima and navigating complex optimization landscapes effectively. Our approach not only retains the directed efficiency of gradient descent but also leverages the exploratory benefits of stochastic perturbations, thus enabling a more comprehensive search for global optima across diverse problem spaces. We demonstrate the efficacy of SPGD in solving the 3D component packing problem, an NP-hard challenge. Preliminary results show a substantial improvement over four established methods, particularly on response surfaces with complex topographies and in multidimensional non-convex continuous optimization problems. Comparative analyses with established 2D benchmark functions highlight SPGD's superior performance, showcasing its ability to navigate complex optimization landscapes. These results emphasize SPGD's potential as a versatile tool for a wide range of optimization problems.",
        "subjects": [
            "math.OC",
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "math-ph"
        ],
        "comment": "28 pages, 26 figures, submitted to Journal of Mechanical Design"
    },
    {
        "paper id": "2411.05056",
        "abstract url": "https://arxiv.org/abs/2411.05056",
        "title": "Seeing is Deceiving: Exploitation of Visual Pathways in Multi-Modal Language Models",
        "rating": "-2.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Multi-Modal Language Models (MLLMs) have transformed artificial intelligence by combining visual and text data, making applications like image captioning, visual question answering, and multi-modal content creation possible. This ability to understand and work with complex information has made MLLMs useful in areas such as healthcare, autonomous systems, and digital content. However, integrating multiple types of data also creates security risks. Attackers can manipulate either the visual or text inputs, or both, to make the model produce unintended or even harmful responses. This paper reviews how visual inputs in MLLMs can be exploited by various attack strategies. We break down these attacks into categories: simple visual tweaks and cross-modal manipulations, as well as advanced strategies like VLATTACK, HADES, and Collaborative Multimodal Adversarial Attack (Co-Attack). These attacks can mislead even the most robust models while looking nearly identical to the original visuals, making them hard to detect. We also discuss the broader security risks, including threats to privacy and safety in important applications. To counter these risks, we review current defense methods like the SmoothVLM framework, pixel-wise randomization, and MirrorCheck, looking at their strengths and limitations. We also discuss new methods to make MLLMs more secure, including adaptive defenses, better evaluation tools, and security approaches that protect both visual and text data. By bringing together recent developments and identifying key areas for improvement, this review aims to support the creation of more secure and reliable multi-modal AI systems for real-world use.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05167",
        "abstract url": "https://arxiv.org/abs/2411.05167",
        "title": "EPIC: Enhancing Privacy through Iterative Collaboration",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated learning"
            ],
            [
                "bioinformatics",
                "medical",
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Advancements in genomics technology lead to a rising volume of viral (e.g., SARS-CoV-2) sequence data, resulting in increased usage of machine learning (ML) in bioinformatics. Traditional ML techniques require centralized data collection and processing, posing challenges in realistic healthcare scenarios. Additionally, privacy, ownership, and stringent regulation issues exist when pooling medical data into centralized storage to train a powerful deep learning (DL) model. The Federated learning (FL) approach overcomes such issues by setting up a central aggregator server and a shared global model. It also facilitates data privacy by extracting knowledge while keeping the actual data private. This work proposes a cutting-edge Privacy enhancement through Iterative Collaboration (EPIC) architecture. The network is divided and distributed between local and centralized servers. We demonstrate the EPIC approach to resolve a supervised classification problem to estimate SARS-CoV-2 genomic sequence data lineage without explicitly transferring raw sequence data. We aim to create a universal decentralized optimization framework that allows various data holders to work together and converge to a single predictive model. The findings demonstrate that privacy-preserving strategies can be successfully used with aggregation approaches without materially altering the degree of learning convergence. Finally, we highlight a few potential issues and prospects for study in FL-based approaches to healthcare applications.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "Accepted at SIMBig 2024"
    },
    {
        "paper id": "2411.05173",
        "abstract url": "https://arxiv.org/abs/2411.05173",
        "title": "DWFL: Enhancing Federated Learning through Dynamic Weighted Averaging",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "bioinformatics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Learning (FL) is a distributed learning technique that maintains data privacy by providing a decentralized training method for machine learning models using distributed big data. This promising Federated Learning approach has also gained popularity in bioinformatics, where the privacy of biomedical data holds immense importance, especially when patient data is involved. Despite the successful implementation of Federated learning in biological sequence analysis, rigorous consideration is still required to improve accuracy in a way that data privacy should not be compromised. Additionally, the optimal integration of federated learning, especially in protein sequence analysis, has not been fully explored. We propose a deep feed-forward neural network-based enhanced federated learning method for protein sequence classification to overcome these challenges. Our method introduces novel enhancements to improve classification accuracy. We introduce dynamic weighted federated learning (DWFL) which is a federated learning-based approach, where local model weights are adjusted using weighted averaging based on their performance metrics. By assigning higher weights to well-performing models, we aim to create a more potent initial global model for the federated learning process, leading to improved accuracy. We conduct experiments using real-world protein sequence datasets to assess the effectiveness of DWFL. The results obtained using our proposed approach demonstrate significant improvements in model accuracy, making federated learning a preferred, more robust, and privacy-preserving approach for collaborative machine-learning tasks.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at SIMBig 2024"
    },
    {
        "paper id": "2411.05205",
        "abstract url": "https://arxiv.org/abs/2411.05205",
        "title": "Maximizing User Connectivity in AI-Enabled Multi-UAV Networks: A Distributed Strategy Generalized to Arbitrary User Distributions",
        "rating": "-2.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "UAV"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep reinforcement learning (DRL) has been extensively applied to Multi-Unmanned Aerial Vehicle (UAV) network (MUN) to effectively enable real-time adaptation to complex, time-varying environments. Nevertheless, most of the existing works assume a stationary user distribution (UD) or a dynamic one with predicted patterns. Such considerations may make the UD-specific strategies insufficient when a MUN is deployed in unknown environments. To this end, this paper investigates distributed user connectivity maximization problem in a MUN with generalization to arbitrary UDs. Specifically, the problem is first formulated into a time-coupled combinatorial nonlinear non-convex optimization with arbitrary underlying UDs. To make the optimization tractable, a multi-agent CNN-enhanced deep Q learning (MA-CDQL) algorithm is proposed. The algorithm integrates a ResNet-based CNN to the policy network to analyze the input UD in real time and obtain optimal decisions based on the extracted high-level UD features. To improve the learning efficiency and avoid local optimums, a heatmap algorithm is developed to transform the raw UD to a continuous density map. The map will be part of the true input to the policy network. Simulations are conducted to demonstrate the efficacy of UD heatmaps and the proposed algorithm in maximizing user connectivity as compared to K-means methods.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04610",
        "abstract url": "https://arxiv.org/abs/2411.04610",
        "title": "Solar potential analysis over Indian cities using high-resolution satellite imagery and DEM",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "LiDAR"
            ],
            [
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Most of the research work in the solar potential analysis is performed utilizing aerial imagery, LiDAR data, and satellite imagery. However, in the existing studies using satellite data, parameters such as trees/ vegetation shadow, adjacent higher architectural structures, and eccentric roof structures in urban areas were not considered, and relatively coarser-resolution datasets were used for analysis. In this work, we have implemented a novel approach to estimate rooftop solar potential using inputs of high-resolution satellite imagery (0.5 cm), a digital elevation model (1m), along with ground station radiation data. Solar radiation analysis is performed using the diffusion proportion and transmissivity ratio derived from the ground station data hosted by IMD. It was observed that due to seasonal variations, environmental effects and technical reasons such as solar panel structure etc., there can be a significant loss of electricity generation up to 50%. Based on the results, it is also understood that using 1m DEM and 50cm satellite imagery, more authentic results are produced over the urban areas.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04630",
        "abstract url": "https://arxiv.org/abs/2411.04630",
        "title": "Brain Tumour Removing and Missing Modality Generation using 3D WDM",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "inpainting"
            ],
            [
                "MRI",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents the second-placed solution for task 8 and the participation solution for task 7 of BraTS 2024. The adoption of automated brain analysis algorithms to support clinical practice is increasing. However, many of these algorithms struggle with the presence of brain lesions or the absence of certain MRI modalities. The alterations in the brain's morphology leads to high variability and thus poor performance of predictive models that were trained only on healthy brains. The lack of information that is usually provided by some of the missing MRI modalities also reduces the reliability of the prediction models trained with all modalities. In order to improve the performance of these models, we propose the use of conditional 3D wavelet diffusion models. The wavelet transform enabled full-resolution image training and prediction on a GPU with 48 GB VRAM, without patching or downsampling, preserving all information for prediction. For the inpainting task of BraTS 2024, the use of a large and variable number of healthy masks and the stability and efficiency of the 3D wavelet diffusion model resulted in 0.007, 22.61 and 0.842 in the validation set and 0.07 , 22.8 and 0.91 in the testing set (MSE, PSNR and SSIM respectively). The code for these tasks is available at https://github.com/ShadowTwin41/BraTS_2023_2024_solutions.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04639",
        "abstract url": "https://arxiv.org/abs/2411.04639",
        "title": "Complexity theory of orbit closure intersection for tensors: reductions, completeness, and graph isomorphism hardness",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum",
                "physics"
            ]
        ],
        "abstract": "Many natural computational problems in computer science, mathematics, physics, and other sciences amount to deciding if two objects are equivalent. Often this equivalence is defined in terms of group actions. A natural question is to ask when two objects can be distinguished by polynomial functions that are invariant under the group action. For finite groups, this is the usual notion of equivalence, but for continuous groups like the general linear groups it gives rise to a new notion, called orbit closure intersection. It captures, among others, the graph isomorphism problem, noncommutative PIT, null cone problems in invariant theory, equivalence problems for tensor networks, and the classification of multiparty quantum states. Despite recent algorithmic progress in celebrated special cases, the computational complexity of general orbit closure intersection problems is currently quite unclear. In particular, tensors seem to give rise to the most difficult problems. In this work we start a systematic study of orbit closure intersection from the complexity-theoretic viewpoint. To this end, we define a complexity class TOCI that captures the power of orbit closure intersection problems for general tensor actions, give an appropriate notion of algebraic reductions that imply polynomial-time reductions in the usual sense, but are amenable to invariant-theoretic techniques, identify natural tensor problems that are complete for TOCI, including the equivalence of 2D tensor networks with constant physical dimension, and show that the graph isomorphism problem can be reduced to these complete problems, hence GI$\\subseteq$TOCI. As such, our work establishes the first lower bound on the computational complexity of orbit closure intersection problems, and it explains the difficulty of finding unconditional polynomial-time algorithms beyond special cases, as has been observed in the literature.",
        "subjects": [
            "cs.CC",
            "math.AG",
            "math.RT"
        ],
        "comment": "38 pages, 3 figures"
    },
    {
        "paper id": "2411.04646",
        "abstract url": "https://arxiv.org/abs/2411.04646",
        "title": "DanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for Audio-Driven Dance Motion Reconstruction",
        "rating": "-3",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "Diffusion"
            ],
            [
                "music"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces DanceFusion, a novel framework for reconstructing and generating dance movements synchronized to music, utilizing a Spatio-Temporal Skeleton Diffusion Transformer. The framework adeptly handles incomplete and noisy skeletal data common in short-form dance videos on social media platforms like TikTok. DanceFusion incorporates a hierarchical Transformer-based Variational Autoencoder (VAE) integrated with a diffusion model, significantly enhancing motion realism and accuracy. Our approach introduces sophisticated masking techniques and a unique iterative diffusion process that refines the motion sequences, ensuring high fidelity in both motion generation and synchronization with accompanying audio cues. Comprehensive evaluations demonstrate that DanceFusion surpasses existing methods, providing state-of-the-art performance in generating dynamic, realistic, and stylistically diverse dance motions. Potential applications of this framework extend to content creation, virtual reality, and interactive entertainment, promising substantial advancements in automated dance generation. Visit our project page at https://th-mlab.github.io/DanceFusion/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04692",
        "abstract url": "https://arxiv.org/abs/2411.04692",
        "title": "Personalized Federated Learning for Cross-view Geo-localization",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Federated Learning"
            ],
            [
                "satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper we propose a methodology combining Federated Learning (FL) with Cross-view Image Geo-localization (CVGL) techniques. We address the challenges of data privacy and heterogeneity in autonomous vehicle environments by proposing a personalized Federated Learning scenario that allows selective sharing of model parameters. Our method implements a coarse-to-fine approach, where clients share only the coarse feature extractors while keeping fine-grained features specific to local environments. We evaluate our approach against traditional centralized and single-client training schemes using the KITTI dataset combined with satellite imagery. Results demonstrate that our federated CVGL method achieves performance close to centralized training while maintaining data privacy. The proposed partial model sharing strategy shows comparable or slightly better performance than classical FL, offering significant reduced communication overhead without sacrificing accuracy. Our work contributes to more robust and privacy-preserving localization systems for autonomous vehicles operating in diverse environments",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "6 pages, 2 figures, Preprint submitted to the IEEE 26th International Workshop on Multimedia Signal Processing (MMSP)"
    },
    {
        "paper id": "2411.04893",
        "abstract url": "https://arxiv.org/abs/2411.04893",
        "title": "Efficient quantum pseudorandomness under conservation laws",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum",
                "physics"
            ]
        ],
        "abstract": "The efficiency of locally generating unitary designs, which capture statistical notions of quantum pseudorandomness, lies at the heart of wide-ranging areas in physics and quantum information technologies. While there are extensive potent methods and results for this problem, the evidently important setting where continuous symmetries or conservation laws (most notably U(1) and SU(d)) are involved is known to present fundamental difficulties. In particular, even the basic question of whether any local symmetric circuit can generate 2-designs efficiently (in time that grows at most polynomially in the system size) remains open with no circuit constructions provably known to do so, despite intensive efforts. In this work, we resolve this long-standing open problem for both U(1) and SU(d) symmetries by explicitly constructing local symmetric quantum circuits which we prove to converge to symmetric unitary 2-designs in polynomial time using a combination of representation theory, graph theory, and Markov chain methods. As a direct application, our constructions can be used to efficiently generate near-optimal random covariant quantum error-correcting codes, confirming a conjecture in [PRX Quantum 3, 020314 (2022)].",
        "subjects": [
            "quant-ph",
            "cond-mat.stat-mech",
            "cs.IT",
            "math-ph"
        ],
        "comment": "8 + 48 pages"
    },
    {
        "paper id": "2411.04898",
        "abstract url": "https://arxiv.org/abs/2411.04898",
        "title": "Convergence efficiency of quantum gates and circuits",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "We consider quantum circuit models where the gates are drawn from arbitrary gate ensembles given by probabilistic distributions over certain gate sets and circuit architectures, which we call stochastic quantum circuits. Of main interest in this work is the speed of convergence of stochastic circuits with different gate ensembles and circuit architectures to unitary t-designs. A key motivation for this theory is the varying preference for different gates and circuit architectures in different practical scenarios. In particular, it provides a versatile framework for devising efficient circuits for implementing $t$-designs and relevant applications including random circuit and scrambling experiments, as well as benchmarking the performance of gates and circuit architectures. We examine various important settings in depth. A key aspect of our study is an \"ironed gadget\" model, which allows us to systematically evaluate and compare the convergence efficiency of entangling gates and circuit architectures. Particularly notable results include i) gadgets of two-qubit gates with KAK coefficients $\\left(\\frac\u03c0{4}-\\frac{1}{8}\\arccos(\\frac{1}{5}),\\frac\u03c0{8},\\frac{1}{8}\\arccos(\\frac{1}{5})\\right)$ (which we call $\u03c7$ gates) directly form exact 2- and 3-designs; ii) the iSWAP gate family achieves the best efficiency for convergence to 2-designs under mild conjectures with numerical evidence, even outperforming the Haar-random gate, for generic many-body circuits; iii) iSWAP + complete graph achieve the best efficiency for convergence to 2-designs among all graph circuits. A variety of numerical results are provided to complement our analysis. We also derive robustness guarantees for our analysis against gate perturbations. Additionally, we provide cursory analysis on gates with higher locality and found that the Margolus gate outperforms various other well-known gates.",
        "subjects": [
            "quant-ph",
            "cond-mat.str-el",
            "cs.CC",
            "cs.IT",
            "math-ph"
        ],
        "comment": "50 pages + 8 tables + 6 figures"
    },
    {
        "paper id": "2411.04953",
        "abstract url": "https://arxiv.org/abs/2411.04953",
        "title": "Quantum Threshold is Powerful",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "In 2005, H\u00f8yer and \u0160palek showed that constant-depth quantum circuits augmented with multi-qubit Fanout gates are quite powerful, able to compute a wide variety of Boolean functions as well as the quantum Fourier transform. They also asked what other multi-qubit gates could rival Fanout in terms of computational power, and suggested that the quantum Threshold gate might be one such candidate. Threshold is the gate that indicates if the Hamming weight of a classical basis state input is greater than some target value. We prove that Threshold is indeed powerful--there are polynomial-size constant-depth quantum circuits with Threshold gates that compute Fanout to high fidelity. Our proof is a generalization of a proof by Rosenthal that exponential-size constant-depth circuits with generalized Toffoli gates can compute Fanout. Our construction reveals that other quantum gates able to \"weakly approximate\" Parity can also be used as substitutes for Fanout.",
        "subjects": [
            "quant-ph",
            "cs.CC"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2411.04956",
        "abstract url": "https://arxiv.org/abs/2411.04956",
        "title": "Uncovering Hidden Subspaces in Video Diffusion Models Using Re-Identification",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Re-Identification"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Latent Video Diffusion Models can easily deceive casual observers and domain experts alike thanks to the produced image quality and temporal consistency. Beyond entertainment, this creates opportunities around safe data sharing of fully synthetic datasets, which are crucial in healthcare, as well as other domains relying on sensitive personal information. However, privacy concerns with this approach have not fully been addressed yet, and models trained on synthetic data for specific downstream tasks still perform worse than those trained on real data. This discrepancy may be partly due to the sampling space being a subspace of the training videos, effectively reducing the training data size for downstream models. Additionally, the reduced temporal consistency when generating long videos could be a contributing factor. In this paper, we first show that training privacy-preserving models in latent space is computationally more efficient and generalize better. Furthermore, to investigate downstream degradation factors, we propose to use a re-identification model, previously employed as a privacy preservation filter. We demonstrate that it is sufficient to train this model on the latent space of the video generator. Subsequently, we use these models to evaluate the subspace covered by synthetic video datasets and thus introduce a new way to measure the faithfulness of generative machine learning models. We focus on a specific application in healthcare echocardiography to illustrate the effectiveness of our novel methods. Our findings indicate that only up to 30.8% of the training videos are learned in latent video diffusion models, which could explain the lack of performance when training downstream tasks on synthetic data.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 5 tables, 6 figures"
    },
    {
        "paper id": "2411.04979",
        "abstract url": "https://arxiv.org/abs/2411.04979",
        "title": "Quantum speedups in solving near-symmetric optimization problems by low-depth QAOA",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "We present new advances in achieving exponential quantum speedups for solving optimization problems by low-depth quantum algorithms. Specifically, we focus on families of combinatorial optimization problems that exhibit symmetry and contain planted solutions. We rigorously prove that the 1-step Quantum Approximate Optimization Algorithm (QAOA) can achieve a success probability of $\u03a9(1/\\sqrt{n})$, and sometimes $\u03a9(1)$, for finding the exact solution in many cases. Furthermore, we construct near-symmetric optimization problems by randomly sampling the individual clauses of symmetric problems, and prove that the QAOA maintains a strong success probability in this setting even when the symmetry is broken. Finally, we construct various families of near-symmetric Max-SAT problems and benchmark state-of-the-art classical solvers, discovering instances where all known classical algorithms require exponential time. Therefore, our results indicate that low-depth QAOA could achieve an exponential quantum speedup for optimization problems.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "comment": "24 pages, 4 figures"
    },
    {
        "paper id": "2411.05106",
        "abstract url": "https://arxiv.org/abs/2411.05106",
        "title": "Enhancing Medical Anatomy Education through Virtual Reality (VR): Design, Development, and Evaluation",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical"
            ]
        ],
        "abstract": "Modern medicine demands innovations in medical education, particularly in the learning of human anatomy, traditionally taught through textbooks, dissections, and lectures. Virtual Reality (VR) has emerged as a promising tool to address the limitations of these conventional methods by emphasising vision-based and active learning. However, current VR educational tools are often inaccessible due to high costs and specialised equipment requirements. This paper details the design and development of an accessible, desktop-based VR system aimed at enhancing anatomy education by leveraging the user's visual perception to promote a meaningful and interactive learning experience. The Virtual Anatomy Lab was designed to enable students to interact with a 3D Skull model to complete tasks virtually via an interactive user interface (UI) with the help of common devices like a mouse and keyboard. As part of the study, a group of medical students from prestigious medical schools throughout Malaysia were invited to evaluate the built system to offer feedback and determine its overall efficiency and usability in fulfilling their learning goals. The results and findings from user evaluations were then analysed to discuss its effectiveness and areas for future improvement.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05118",
        "abstract url": "https://arxiv.org/abs/2411.05118",
        "title": "An emotional expression system with vibrotactile feedback during the robot's speech",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "psychological"
            ]
        ],
        "abstract": "This study aimed to develop a system that provides vibrotactile feedback corresponding to the emotional content of text when a communication robot speaks. We used OpenAI's \"GPT-4o Mini\" for emotion estimation, extracting valence and arousal values from the text. The amplitude and frequency of vibrotactile stimulation using sine waves were controlled on the basis of estimated emotional values. We assembled a palm-sized tactile display to present these vibrotactile stimuli. In the experiment, participants listened to the robot's speech while holding the device and then evaluated their psychological state. The results suggested that the communication accompanied by the vibrotactile feedback could influence psychological states and intimacy levels.",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05122",
        "abstract url": "https://arxiv.org/abs/2411.05122",
        "title": "Socially Assistive Robots: A Technological Approach to Emotional Support",
        "rating": "-3",
        "keywords": [
            [
                "robotics",
                "robot"
            ],
            [
                "facial"
            ]
        ],
        "abstract": "In today's high-pressure and isolated society, the demand for emotional support has surged, necessitating innovative solutions. Socially Assistive Robots (SARs) offer a technological approach to providing emotional assistance by leveraging advanced robotics, artificial intelligence, and sensor technologies. This study explores the development of an emotional support robot designed to detect and respond to human emotions, particularly sadness, through facial recognition and gesture analysis. Utilising the Lego Mindstorms Robotic Kit, Raspberry Pi 4, and various Python libraries, the robot is capable of delivering empathetic interactions, including comforting hugs and AI-generated conversations. Experimental findings highlight the robot's effective facial recognition accuracy, user interaction, and hug feedback mechanisms. These results demonstrate the feasibility of using SARs for emotional support, showcasing their potential features and functions. This research underscores the promise of SARs in providing innovative emotional assistance and enhancing human-robot interaction.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05131",
        "abstract url": "https://arxiv.org/abs/2411.05131",
        "title": "The impact of mobility, beam sweeping and smart jammers on security vulnerabilities of 5G cells",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "5G"
            ]
        ],
        "abstract": "The vulnerability of 5G networks to jamming attacks has emerged as a significant concern. This paper contributes in two primary aspects. Firstly, it investigates the effect of a multi-jammer on 5G cell metrics, specifically throughput and goodput. The investigation is conducted within the context of a mobility model for user equipment (UE), with a focus on scenarios involving connected vehicles (CVs) engaged in a mission. Secondly, the vulnerability of synchronization signal block (SSB) components is examined concerning jamming power and beam sweeping. Notably, the study reveals that increasing jamming power beyond 40 dBm in our specific scenario configuration no longer decreases network throughput due to the re-transmission of packets through the hybrid automatic repeat request (HARQ) process. Furthermore, it is observed that under the same jamming power, the physical downlink shared channel (PDSCH) is more vulnerable than the primary synchronization signal (PSS) and secondary synchronization signal (SSS). However, a smart jammer can disrupt the cell search process by injecting less power and targeting PSS-SSS or physical broadcast channel (PBCH) data compared to a barrage jammer. On the other hand, beam sweeping proves effective in mitigating the impact of a smart jammer, reducing the error vector magnitude root mean square from 51.59% to 23.36% under the same jamming power.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "8 pages, 11 figures, Wireless World: Research and Trends Magazine"
    },
    {
        "paper id": "2411.05135",
        "abstract url": "https://arxiv.org/abs/2411.05135",
        "title": "A Vibrotactile Belt for Interpersonal Synchronization of Breath",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "healthcare"
            ]
        ],
        "abstract": "This paper introduces a vibrotactile belt for interpersonal synchronization of breath. It can synchronize the breathing tempo of two people by transferring breathing rhythm of one user to vibration signals of another belt, where the depth of breathing is represented by the intensity of vibration. This provides a novel way of emotional connect between people. Meanwhile, this breath-sharing device may also be combined with smart devices in the future to form a one-to-many, many-to-many internet of breath, which has promising application prospects in healthcare, sports breathing guidance and other scenarios.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05292",
        "abstract url": "https://arxiv.org/abs/2411.05292",
        "title": "SimpleBEV: Improved LiDAR-Camera Fusion Architecture for 3D Object Detection",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "BEV"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "More and more research works fuse the LiDAR and camera information to improve the 3D object detection of the autonomous driving system. Recently, a simple yet effective fusion framework has achieved an excellent detection performance, fusing the LiDAR and camera features in a unified bird's-eye-view (BEV) space. In this paper, we propose a LiDAR-camera fusion framework, named SimpleBEV, for accurate 3D object detection, which follows the BEV-based fusion framework and improves the camera and LiDAR encoders, respectively. Specifically, we perform the camera-based depth estimation using a cascade network and rectify the depth results with the depth information derived from the LiDAR points. Meanwhile, an auxiliary branch that implements the 3D object detection using only the camera-BEV features is introduced to exploit the camera information during the training phase. Besides, we improve the LiDAR feature extractor by fusing the multi-scaled sparse convolutional features. Experimental results demonstrate the effectiveness of our proposed method. Our method achieves 77.6\\% NDS accuracy on the nuScenes dataset, showcasing superior performance in the 3D object detection track.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05302",
        "abstract url": "https://arxiv.org/abs/2411.05302",
        "title": "Adaptive Whole-Body PET Image Denoising Using 3D Diffusion Models with ControlNet",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Positron Emission Tomography (PET) is a vital imaging modality widely used in clinical diagnosis and preclinical research but faces limitations in image resolution and signal-to-noise ratio due to inherent physical degradation factors. Current deep learning-based denoising methods face challenges in adapting to the variability of clinical settings, influenced by factors such as scanner types, tracer choices, dose levels, and acquisition times. In this work, we proposed a novel 3D ControlNet-based denoising method for whole-body PET imaging. We first pre-trained a 3D Denoising Diffusion Probabilistic Model (DDPM) using a large dataset of high-quality normal-dose PET images. Following this, we fine-tuned the model on a smaller set of paired low- and normal-dose PET images, integrating low-dose inputs through a 3D ControlNet architecture, thereby making the model adaptable to denoising tasks in diverse clinical settings. Experimental results based on clinical PET datasets show that the proposed framework outperformed other state-of-the-art PET image denoising methods both in visual quality and quantitative metrics. This plug-and-play approach allows large diffusion models to be fine-tuned and adapted to PET images from diverse acquisition protocols.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05860",
        "abstract url": "https://arxiv.org/abs/2411.05860",
        "title": "Conditional Diffusion Model for Longitudinal Medical Image Generation",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "biological",
                "Medical",
                "MRI",
                "disease"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Alzheimers disease progresses slowly and involves complex interaction between various biological factors. Longitudinal medical imaging data can capture this progression over time. However, longitudinal data frequently encounter issues such as missing data due to patient dropouts, irregular follow-up intervals, and varying lengths of observation periods. To address these issues, we designed a diffusion-based model for 3D longitudinal medical imaging generation using single magnetic resonance imaging (MRI). This involves the injection of a conditioning MRI and time-visit encoding to the model, enabling control in change between source and target images. The experimental results indicate that the proposed method generates higher-quality images compared to other competing methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "4 pages, 2 figures, conference"
    },
    {
        "paper id": "2411.05866",
        "abstract url": "https://arxiv.org/abs/2411.05866",
        "title": "Mitigating Stop-and-Go Traffic Congestion with Operator Learning",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "This paper presents a novel neural operator learning framework for designing boundary control to mitigate stop-and-go congestion on freeways. The freeway traffic dynamics are described by second-order coupled hyperbolic partial differential equations (PDEs). The proposed framework learns feedback boundary control strategies from the closed-loop PDE solution using backstepping controllers, which are widely employed for boundary stabilization of PDE systems. The PDE backstepping control design is time-consuming and requires intensive depth of expertise, since it involves constructing and solving backstepping control kernels. To address these challenges, we present neural operator (NO) learning schemes for the ARZ traffic system that not only ensure closed-loop stability robust to parameter and initial condition variations but also accelerate boundary controller computation. The stability guarantee of the NO-approximated control laws is obtained using Lyapunov analysis. We further propose the physics-informed neural operator (PINO) to reduce the reliance on extensive training data. The performance of the NO schemes is evaluated by simulated and real traffic data, compared with the benchmark backstepping controller, a Proportional Integral (PI) controller, and a PINN-based controller. The NO-approximated methods achieve a computational speedup of approximately 300 times with only a 1% error trade-off compared to the backstepping controller, while outperforming the other two controllers in both accuracy and computational efficiency. The robustness of the NO schemes is validated using real traffic data, and tested across various initial traffic conditions and demand scenarios. The results show that neural operators can significantly expedite and simplify the process of obtaining controllers for traffic PDE systems with great potential application for traffic management.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04556",
        "abstract url": "https://arxiv.org/abs/2411.04556",
        "title": "Uncertainty Prediction Neural Network (UpNet): Embedding Artificial Neural Network in Bayesian Inversion Framework to Quantify the Uncertainty of Remote Sensing Retrieval",
        "rating": "-3.5",
        "keywords": [
            [
                "biophysical"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "For the retrieval of large-scale vegetation biophysical parameters, the inversion of radiative transfer models (RTMs) is the most commonly used approach. In recent years, Artificial Neural Network (ANN)-based methods have become the mainstream for inverting RTMs due to their high accuracy and computational efficiency. It has been widely used in the retrieval of biophysical variables (BV). However, due to the lack of the Bayesian inversion theory interpretation, it faces challenges in quantifying the retrieval uncertainty, a crucial metric for product quality validation and downstream applications such as data assimilation or ecosystem carbon cycling modeling. This study proved that the ANN trained with squared loss outputs the posterior mean, providing a rigorous foundation for its uncertainty quantification, regularization, and incorporation of prior information. A Bayesian theoretical framework was subsequently proposed for ANN-based methods. Using this framework, we derived a new algorithm called Uncertainty Prediction Neural Network (UpNet), which enables the simultaneous training of two ANNs to retrieve BV and provide retrieval uncertainty. To validate our method, we compared UpNet with the standard Bayesian inference method, i.e., Markov Chain Monte Carlo (MCMC), in the inversion of a widely used RTM called ProSAIL for retrieving BVs and estimating uncertainty. The results demonstrated that the BVs retrieved and the uncertainties estimated by UpNet were highly consistent with those from MCMC, achieving over a million-fold acceleration. These results indicated that UpNet has significant potential for fast retrieval and uncertainty quantification of BVs or other parameters with medium and high-resolution remote sensing data. Our Python implementation is available at: https://github.com/Dash-RSer/UpNet.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "24 pages, f figures"
    },
    {
        "paper id": "2411.04669",
        "abstract url": "https://arxiv.org/abs/2411.04669",
        "title": "EffiCANet: Efficient Time Series Forecasting with Convolutional Attention",
        "rating": "-3.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The exponential growth of multivariate time series data from sensor networks in domains like industrial monitoring and smart cities requires efficient and accurate forecasting models. Current deep learning methods often fail to adequately capture long-range dependencies and complex inter-variable relationships, especially under real-time processing constraints. These limitations arise as many models are optimized for either short-term forecasting with limited receptive fields or long-term accuracy at the cost of efficiency. Additionally, dynamic and intricate interactions between variables in real-world data further complicate modeling efforts. To address these limitations, we propose EffiCANet, an Efficient Convolutional Attention Network designed to enhance forecasting accuracy while maintaining computational efficiency. EffiCANet integrates three key components: (1) a Temporal Large-kernel Decomposed Convolution (TLDC) module that captures long-term temporal dependencies while reducing computational overhead; (2) an Inter-Variable Group Convolution (IVGC) module that captures complex and evolving relationships among variables; and (3) a Global Temporal-Variable Attention (GTVA) mechanism that prioritizes critical temporal and inter-variable features. Extensive evaluations across nine benchmark datasets show that EffiCANet achieves the maximum reduction of 10.02% in MAE over state-of-the-art models, while cutting computational costs by 26.2% relative to conventional large-kernel convolution methods, thanks to its efficient decomposition strategy.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04747",
        "abstract url": "https://arxiv.org/abs/2411.04747",
        "title": "Equivariant Graph Attention Networks with Structural Motifs for Predicting Cell Line-Specific Synergistic Drug Combinations",
        "rating": "-3.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Graph"
            ],
            [
                "Cancer"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Cancer is the second leading cause of death, with chemotherapy as one of the primary forms of treatment. As a result, researchers are turning to drug combination therapy to decrease drug resistance and increase efficacy. Current methods of drug combination screening, such as in vivo and in vitro, are inefficient due to stark time and monetary costs. In silico methods have become increasingly important for screening drugs, but current methods are inaccurate and generalize poorly to unseen anticancer drugs. In this paper, I employ a geometric deep-learning model utilizing a graph attention network that is equivariant to 3D rotations, translations, and reflections with structural motifs. Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specific to each cell line. I compared the proposed geometric deep learning framework to current state-of-the-art (SOTA) methods, and the proposed model architecture achieved greater performance on all 12 benchmark tasks performed on the DrugComb dataset. Specifically, the proposed framework outperformed other SOTA methods by an accuracy difference greater than 28%. Based on these results, I believe that the equivariant graph attention network's capability of learning geometric data accounts for the large performance improvements. The model's ability to generalize to foreign drugs is thought to be due to the structural motifs providing a better representation of the molecule. Overall, I believe that the proposed equivariant geometric deep learning framework serves as an effective tool for virtually screening anticancer drug combinations for further validation in a wet lab environment. The code for this work is made available online at: https://github.com/WeToTheMoon/EGAT_DrugSynergy.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "8 pages, 1 figure, Presented at IEEE CIBCB"
    },
    {
        "paper id": "2411.04936",
        "abstract url": "https://arxiv.org/abs/2411.04936",
        "title": "Fed-LDR: Federated Local Data-infused Graph Creation with Node-centric Model Refinement",
        "rating": "-3.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Graph"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "The rapid acceleration of global urbanization has introduced novel challenges in enhancing urban infrastructure and services. Spatio-temporal data, integrating spatial and temporal dimensions, has emerged as a critical tool for understanding urban phenomena and promoting sustainability. In this context, Federated Learning (FL) has gained prominence as a distributed learning paradigm aligned with the privacy requirements of urban IoT environments. However, integrating traditional and deep learning models into the FL framework poses significant challenges, particularly in capturing complex spatio-temporal dependencies and adapting to diverse urban conditions. To address these challenges, we propose the Federated Local Data-Infused Graph Creation with Node-centric Model Refinement (Fed-LDR) algorithm. Fed-LDR leverages FL and Graph Convolutional Networks (GCN) to enhance spatio-temporal data analysis in urban environments. The algorithm comprises two key modules: (1) the Local Data-Infused Graph Creation (LDIGC) module, which dynamically reconfigures adjacency matrices to reflect evolving spatial relationships within urban environments, and (2) the Node-centric Model Refinement (NoMoR) module, which customizes model parameters for individual urban nodes to accommodate heterogeneity. Evaluations on the PeMSD4 and PeMSD8 datasets demonstrate Fed-LDR's superior performance over six baseline methods. Fed-LDR achieved the lowest Mean Absolute Error (MAE) values of 20.15 and 17.30, and the lowest Root Mean Square Error (RMSE) values of 32.30 and 27.15, respectively, while maintaining a high correlation coefficient of 0.96 across both datasets. Notably, on the PeMSD4 dataset, Fed-LDR reduced MAE and RMSE by up to 81\\% and 78\\%, respectively, compared to the best-performing baseline FedMedian.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05243",
        "abstract url": "https://arxiv.org/abs/2411.05243",
        "title": "An Integrated Epidemic Simulation Workflow for Submodular Intervention Strategies",
        "rating": "-3.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "graph"
            ],
            [
                "disease"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Owing to the ongoing COVID-19 pandemic and other recent global epidemics, epidemic simulation frameworks are gaining rapid significance. In this work, we present a workflow that will allow researchers to simulate the spread of an infectious disease under different intervention schemes. Our workflow is built using the Covasim simulator for COVID-19 alongside a network-based PREEMPT tool for vaccination. The Covasim simulator is a stochastic agent-based simulator with the capacity to test the efficacy of different intervention schemes. PREEMPT is a graph-theoretic approach that models epidemic intervention on a network using submodular optimization. By integrating the PREEMPT tool with the Covasim simulator, users will be able to test network diffusion based interventions for vaccination. The paper presents a description of this integrated workflow alongside preliminary results of our empirical evaluation for COVID-19.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05867",
        "abstract url": "https://arxiv.org/abs/2411.05867",
        "title": "Modeling Nonlinear Oscillator Networks Using Physics-Informed Hybrid Reservoir Computing",
        "rating": "-3.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Surrogate modeling of non-linear oscillator networks remains challenging due to discrepancies between simplified analytical models and real-world complexity. To bridge this gap, we investigate hybrid reservoir computing, combining reservoir computing with \"expert\" analytical models. Simulating the absence of an exact model, we first test the surrogate models with parameter errors in their expert model. Second, we assess their performance when their expert model lacks key non-linear coupling terms present in an extended ground-truth model. We focus on short-term forecasting across diverse dynamical regimes, evaluating the use of these surrogates for control applications. We show that hybrid reservoir computers generally outperform standard reservoir computers and exhibit greater robustness to parameter tuning. Notably, unlike standard reservoir computers, the performance of the hybrid does not degrade when crossing an observed spectral radius threshold. Furthermore, there is good performance for dynamical regimes not accessible to the expert model, demonstrating the contribution of the reservoir.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "27 pages, 10 figures, 17 supplementary figures. Code available at https://github.com/AJS50/Hybrid_RC_for_NLONS_paper_code"
    },
    {
        "paper id": "2411.04454",
        "abstract url": "https://arxiv.org/abs/2411.04454",
        "title": "Mixing time of quantum Gibbs sampling for random sparse Hamiltonians",
        "rating": "-4",
        "keywords": [
            [
                "thermal"
            ],
            [
                "quantum"
            ]
        ],
        "abstract": "Providing evidence that quantum computers can efficiently prepare low-energy or thermal states of physically relevant interacting quantum systems is a major challenge in quantum information science. A newly developed quantum Gibbs sampling algorithm by Chen, Kastoryano, and Gily\u00e9n provides an efficient simulation of the detailed-balanced dissipative dynamics of non-commutative quantum systems. The running time of this algorithm depends on the mixing time of the corresponding quantum Markov chain, which has not been rigorously bounded except in the high-temperature regime. In this work, we establish a polylog(n) upper bound on its mixing time for various families of random n by n sparse Hamiltonians at any constant temperature. We further analyze how the choice of the jump operators for the algorithm and the spectral properties of these sparse Hamiltonians influence the mixing time. Our result places this method for Gibbs sampling on par with other efficient algorithms for preparing low-energy states of quantumly easy Hamiltonians.",
        "subjects": [
            "quant-ph",
            "cs.DS",
            "math-ph"
        ],
        "comment": "31 pages, 1 figure"
    },
    {
        "paper id": "2411.04471",
        "abstract url": "https://arxiv.org/abs/2411.04471",
        "title": "FQsun: A Configurable Wave Function-Based Quantum Emulator for Power-Efficient Quantum Simulations",
        "rating": "-4",
        "keywords": [
            [
                "FPGAs"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum computing has emerged as a powerful tool for solving complex computational problems, but access to real quantum hardware remains limited due to high costs and increasing demand for efficient quantum simulations. Unfortunately, software simulators on CPUs/GPUs such as Qiskit, ProjectQ, and Qsun offer flexibility and support for a large number of qubits, they struggle with high power consumption and limited processing speed, especially as qubit counts scale. Accordingly, quantum emulators implemented on dedicated hardware, such as FPGAs and analog circuits, offer a promising path for addressing energy efficiency concerns. However, existing studies on hardware-based emulators still face challenges in terms of limited flexibility, lack of fidelity evaluation, and power consumption. To overcome these gaps, we propose FQsun, a quantum emulator that enhances performance by integrating four key innovations: efficient memory organization, a configurable Quantum Gate Unit (QGU), optimized scheduling, and multiple number precisions. Five FQsun versions with different number precisions, including 16-bit floating point, 32-bit floating point, 16-bit fixed point, 24-bit fixed point, and 32-bit fixed point, are implemented on the Xilinx ZCU102 FPGA, utilizing between 9,226 and 18,093 LUTs, 1,440 and 7,031 FFs, 344 and 464 BRAMs, and 14 and 88 DSPs and consuming a maximum power of 2.41W. Experimental results demonstrate high accuracy in normalized gate speed, fidelity, and mean square error, particularly with 32-bit fixed-point and floating-point versions, establishing FQsun's capability as a precise quantum emulator. Benchmarking on quantum algorithms such as Quantum Fourier Transform, Parameter-Shift Rule, and Random Quantum Circuits reveals that FQsun achieves superior power-delay product, outperforming traditional software simulators on powerful CPUs by up to 9,870 times.",
        "subjects": [
            "quant-ph",
            "cs.AR"
        ],
        "comment": "17 pages, 14 figures, submitted to the IEEE Transaction on Quantum Engineering"
    },
    {
        "paper id": "2411.04558",
        "abstract url": "https://arxiv.org/abs/2411.04558",
        "title": "Experimental Secure Multiparty Computation from Quantum Oblivious Transfer with Bit Commitment",
        "rating": "-4",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Secure multiparty computation enables collaborative computations across multiple users while preserving individual privacy, which has a wide range of applications in finance, machine learning and healthcare. Secure multiparty computation can be realized using oblivious transfer as a primitive function. In this paper, we present an experimental implementation of a quantum-secure quantum oblivious transfer (QOT) protocol using an adapted quantum key distribution system combined with a bit commitment scheme, surpassing previous approaches only secure in the noisy storage model. We demonstrate the first practical application of the QOT protocol by solving the private set intersection, a prime example of secure multiparty computation, where two parties aim to find common elements in their datasets without revealing any other information. In our experiments, two banks can identify common suspicious accounts without disclosing any other data. This not only proves the experimental functionality of QOT, but also showcases its real-world commercial applications.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04612",
        "abstract url": "https://arxiv.org/abs/2411.04612",
        "title": "Population estimation using 3D city modelling and Carto2S datasets -- A case study",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "health"
            ],
            [
                "remote sensing",
                "satellite"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the launch of Carto2S series of satellites, high resolution images (0.6-1.0 meters) are acquired and available for use. High resolution Digital Elevation Model (DEM) with better accuracies can be generated using C2S multi-view and multi date datasets. DEMs are further used as an input to derive Digital terrain models (DTMs) and to extract accurate heights of the objects (building and tree) over the surface of the Earth. Extracted building heights are validated with ground control points and can be used for generation of city modelling and resource estimation like population estimation, health planning, water and transport resource estimations. In this study, an attempt is made to assess the population of a township using high-resolution Indian remote sensing satellite datasets. We used Carto 2S multi-view data and generated a precise DEM and DTM over a city area. Using DEM and DTM datasets, accurate heights of the buildings are extracted which are further validated with ground data. Accurate building heights and high resolution imagery are used for generating accurate virtual 3D city model and assessing the number of floor and carpet area of the houses/ flats/ apartments. Population estimation of the area is made using derived information of no of houses/ flats/ apartments from the satellite datasets. Further, information about number of hospital and schools around the residential area is extracted from open street maps (OSM). Population estimation using satellite data and derived information from OSM datasets can prove to be very good tool for local administrator and decision makers.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04648",
        "abstract url": "https://arxiv.org/abs/2411.04648",
        "title": "Bayesian reconstruction of sparse raster-scanned mid-infrared optoacoustic signals enables fast, label-free chemical microscopy",
        "rating": "-4",
        "keywords": [
            [
                "infrared"
            ],
            [
                "biomolecular",
                "clinical"
            ],
            [
                "chemical"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Hyperspectral optoacoustic microscopy (OAM) enables obtaining images with label-free biomolecular contrast, offering excellent perspectives as a diagnostic tool to assess freshly excised and unprocessed tissues. However, time-consuming raster-scanning image formation currently limits the translation potential of OAM into the clinical setting-for instance, in intraoperative histopathological assessments-where micrographs of excised tissue need to be taken within a few minutes for fast clinical decision-making. Here, we present a non-data-driven computational framework tailored to enable fast OAM by sparse data acquisition and model-based image reconstruction, termed Bayesian raster-computed optoacoustic microscopy (BayROM). Unlike conventional machine learning, BayROM doesn't require training datasets, but instead, it employs 1) optomechanical system properties to define a forward model and 2) prior knowledge of the imaged samples to facilitate reconstructing images based on the sparsely acquired data. We show that BayROM enables acquiring micrographs ten times faster and with structural similarity (SSIM) indices greater than 0.93 compared to conventional raster scanning microscopy, thus facilitating the clinical translation of OAM for fast, label-free intraoperative histopathology.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04740",
        "abstract url": "https://arxiv.org/abs/2411.04740",
        "title": "Quantum Neural Network Classifier for Cancer Registry System Testing: A Feasibility Study",
        "rating": "-4",
        "keywords": [
            [
                "medical",
                "Health",
                "Cancer"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "The Cancer Registry of Norway (CRN) is a part of the Norwegian Institute of Public Health (NIPH) and is tasked with producing statistics on cancer among the Norwegian population. For this task, CRN develops, tests, and evolves a software system called Cancer Registration Support System (CaReSS). It is a complex socio-technical software system that interacts with many entities (e.g., hospitals, medical laboratories, and other patient registries) to achieve its task. For cost-effective testing of CaReSS, CRN has employed EvoMaster, an AI-based REST API testing tool combined with an integrated classical machine learning model. Within this context, we propose Qlinical to investigate the feasibility of using, inside EvoMaster, a Quantum Neural Network (QNN) classifier, i.e., a quantum machine learning model, instead of the existing classical machine learning model. Results indicate that Qlinical can achieve performance comparable to that of EvoClass. We further explore the effects of various QNN configurations on performance and offer recommendations for optimal QNN settings for future QNN developers.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05279",
        "abstract url": "https://arxiv.org/abs/2411.05279",
        "title": "Path Planning in Complex Environments with Superquadrics and Voronoi-Based Orientation",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "robot",
                "navigation"
            ],
            [
                "drone"
            ]
        ],
        "abstract": "Path planning in narrow passages is a challenging problem in various applications. Traditional planning algorithms often face challenges in complex environments like mazes and traps, where narrow entrances require special orientation control for successful navigation. In this work, we present a novel approach that combines superquadrics (SQ) representation and Voronoi diagrams to solve the narrow passage problem in both 2D and 3D environment. Our method utilizes the SQ formulation to expand obstacles, eliminating impassable passages, while Voronoi hyperplane ensures maximum clearance path. Additionally, the hyperplane provides a natural reference for robot orientation, aligning its long axis with the passage direction. We validate our framework through a 2D object retrieval task and 3D drone simulation, demonstrating that our approach outperforms classical planners and a cutting-edge drone planner by ensuring passable trajectories with maximum clearance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05320",
        "abstract url": "https://arxiv.org/abs/2411.05320",
        "title": "Privacy Protection Framework against Unauthorized Sensing in the 5.8 GHz ISM Band",
        "rating": "-4",
        "keywords": [
            [
                "medical"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Unauthorized sensing activities pose an increasing threat to individual privacy, particularly in the industrial, scientific, and medical (ISM) band where regulatory frameworks remain limited. This paper presents a novel signal process methodology to monitor and counter unauthorized sensing activities. Specifically, we model the pedestrian trajectories as a random process. Then, we leverage the Cram\u00e9r-Rao bound (CRB) to evaluate sensing performance and model it as sampling error of such a random process. Through simulation, we verify the accuracy of monitoring unauthorized sensing activities in urban scenarios, and validate the effectiveness of corresponding mitigation strategies.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to ICC 2025"
    },
    {
        "paper id": "2411.04708",
        "abstract url": "https://arxiv.org/abs/2411.04708",
        "title": "Exploring Hierarchical Molecular Graph Representation in Multimodal LLMs",
        "rating": "-4.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "biochemical"
            ],
            [
                "chemistry",
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Following the milestones in large language models (LLMs) and multimodal models, we have seen a surge in applying LLMs to biochemical tasks. Leveraging graph features and molecular text representations, LLMs can tackle various tasks, such as predicting chemical reaction outcomes and describing molecular properties. However, most current work overlooks the multi-level nature of graph features. The impact of different feature levels on LLMs and the importance of each level remain unexplored, and it is possible that different chemistry tasks require different feature levels. In this work, we first investigate the effect of feature granularity by fusing GNN-generated feature tokens, discovering that even reducing all tokens to a single token does not significantly impact performance. We then explore the effect of various feature levels on performance, finding that both the quality of LLM-generated molecules and performance on different tasks benefit from different feature levels. We conclude with two key insights: (1) current molecular Multimodal LLMs(MLLMs) lack a comprehensive understanding of graph features, and (2) static processing is not sufficient for hierarchical graph feature. Our code will be publicly available soon.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04762",
        "abstract url": "https://arxiv.org/abs/2411.04762",
        "title": "JC5A: Service Delay Minimization for Aerial MEC-assisted Industrial Cyber-Physical Systems",
        "rating": "-5",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "6G",
                "Industrial"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In the era of the sixth generation (6G) and industrial Internet of Things (IIoT), an industrial cyber-physical system (ICPS) drives the proliferation of sensor devices and computing-intensive tasks. To address the limited resources of IIoT sensor devices, unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) has emerged as a promising solution, providing flexible and cost-effective services in close proximity of IIoT sensor devices (ISDs). However, leveraging aerial MEC to meet the delay-sensitive and computation-intensive requirements of the ISDs could face several challenges, including the limited communication, computation and caching (3C) resources, stringent offloading requirements for 3C services, and constrained on-board energy of UAVs. To address these issues, we first present a collaborative aerial MEC-assisted ICPS architecture by incorporating the computing capabilities of the macro base station (MBS) and UAVs. We then formulate a service delay minimization optimization problem (SDMOP). Since the SDMOP is proved to be an NP-hard problem, we propose a joint computation offloading, caching, communication resource allocation, computation resource allocation, and UAV trajectory control approach (JC5A). Specifically, JC5A consists of a block successive upper bound minimization method of multipliers (BSUMM) for computation offloading and service caching, a convex optimization-based method for communication and computation resource allocation, and a successive convex approximation (SCA)-based method for UAV trajectory control. Moreover, we theoretically prove the convergence and polynomial complexity of JC5A. Simulation results demonstrate that the proposed approach can achieve superior system performance compared to the benchmark approaches and algorithms.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04797",
        "abstract url": "https://arxiv.org/abs/2411.04797",
        "title": "Development of a Service Robot for Hospital Environments in Rehabilitation Medicine with LiDAR Based Simultaneous Localization and Mapping",
        "rating": "-5",
        "keywords": [
            [
                "3D"
            ],
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "robotics",
                "Robot",
                "navigation"
            ],
            [
                "medical",
                "healthcare"
            ]
        ],
        "abstract": "This paper presents the development and evaluation of a medical service robot equipped with 3D LiDAR and advanced localization capabilities for use in hospital environments. The robot employs LiDAR-based Simultaneous Localization and Mapping SLAM to navigate autonomously and interact effectively within complex and dynamic healthcare settings. A comparative analysis with established 3D SLAM technology in Autoware version 1.14.0, under a Linux ROS framework, provided a benchmark for evaluating our system performance. The adaptation of Normal Distribution Transform NDT Matching to indoor navigation allowed for precise real-time mapping and enhanced obstacle avoidance capabilities. Empirical validation was conducted through manual maneuvers in various environments, supplemented by ROS simulations to test the system response to simulated challenges. The findings demonstrate that the robot integration of 3D LiDAR and NDT Matching significantly improves navigation accuracy and operational reliability in a healthcare context. This study highlights the robot ability to perform essential tasks with high efficiency and identifies potential areas for further improvement, particularly in sensor performance under diverse environmental conditions. The successful deployment of this technology in a hospital setting illustrates its potential to support medical staff and contribute to patient care, suggesting a promising direction for future research and development in healthcare robotics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04445",
        "abstract url": "https://arxiv.org/abs/2411.04445",
        "title": "Large Sets of Asymptotically Optimal and Near-Optimal Quasi-Complementary Sequences",
        "rating": "-10",
        "keywords": [],
        "abstract": "Perfect complementary sequence sets (PCSSs) are widely used in multi-carrier code-division multiple-access (MC-CDMA) communication system. However, the set size of a PCSS is upper bounded by the number of row sequences of each two-dimensional matrix in PCSS. Then quasi-complementary sequence set (QCSS) was proposed to support more users in MC-CDMA communications. For practical applications, it is desirable to construct an $(M,K,N,\\vartheta_{max})$-QCSS with $M$ as large as possible and $\\vartheta_{max}$ as small as possible, where $M$ is the number of matrices with $K$ rows and $N$ columns in the set and $\\vartheta_{max}$ denotes its periodic tolerance. There exists a tradoff among these parameters and constructing QCSSs achieving or nearly achieving the known correlation lower bound has been an interesting research topic. Up to now, only a few constructions of asymptotically optimal or near-optimal periodic QCSSs were reported in the literature. In this paper, we construct five families of asymptotically optimal or near-optimal periodic QCSSs with large set sizes and low periodic tolerances. These families of QCSSs have set size $\u0398(q^2)$ or $\u0398(q^3)$ and flock size $\u0398(q)$, where $q$ is a power of a prime. To the best of our knowledge, only three known families of periodic QCSSs with set size $\u0398(q^2)$ and flock size $\u0398(q)$ were constructed and all other known periodic QCSSs have set sizes much smaller than $\u0398(q^2)$. Our new constructed periodic QCSSs with set size $\u0398(q^2)$ and flock size $\u0398(q)$ have better parameters than known ones. They have larger set sizes or lower periodic tolerances.The periodic QCSSs with set size $\u0398(q^3)$ and flock size $\u0398(q)$ constructed in this paper have the largest set size among all known families of asymptotically optimal or near-optimal periodic QCSSs.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04467",
        "abstract url": "https://arxiv.org/abs/2411.04467",
        "title": "A Distributionally Robust Control Strategy for Frequency Safety based on Koopman Operator Described System Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "As the proportion of renewable energy and power electronics in the power system increases, modeling frequency dynamics under power deficits becomes more challenging. Although data-driven methods help mitigate these challenges, they are exposed to data noise and training errors, leading to uncertain prediction errors. To address uncertain and limited statistical information of prediction errors, we introduce a distributionally robust data-enabled emergency frequency control (DREFC) framework. It aims to ensure a high probability of frequency safety and allows for adjustable control conservativeness for decision makers. Specifically, DREFC solves a min-max optimization problem to find the optimal control that is robust to distribution of prediction errors within a Wasserstein-distance-based ambiguity set. With an analytical approximation for VaR constraints, we achieve a computationally efficient reformulations. Simulations demonstrate that DREFC ensures frequency safety, low control costs and low computation time.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04472",
        "abstract url": "https://arxiv.org/abs/2411.04472",
        "title": "Accurate Calculation of Switching Events in Electromagnetic Transient Simulation Considering State Variable Discontinuities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Accurate calculation of switching events is important for electromagnetic transient simulation to obtain reliable results. The common presumption of continuous differential state variables could prevent the accurate calculation, thus leading to unreliable results. This paper explores accurately calculating switching events without presuming continuous differential state variables. Possibility of the calculation is revealed by the proposal of related methods. Feasibility and accuracy of the proposed methods are demonstrated and analyzed via numerical case studies.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04479",
        "abstract url": "https://arxiv.org/abs/2411.04479",
        "title": "On the number of partitions of the hypercube ${\\bf Z}_q^n$ into large subcubes",
        "rating": "-10",
        "keywords": [],
        "abstract": "We prove that the number of partitions of the hypercube ${\\bf Z}_q^n$ into $q^m$ subcubes of dimension $n-m$ each for fixed $q$, $m$ and growing $n$ is asymptotically equal to $n^{(q^m-1)/(q-1)}$. For the proof, we introduce the operation of the bang of a star matrix and demonstrate that any star matrix, except for a fractal, is expandable under some bang, whereas a fractal remains to be a fractal under any bang.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04489",
        "abstract url": "https://arxiv.org/abs/2411.04489",
        "title": "An Equitable Experience? How HCI Research Conceptualizes Accessibility of Virtual Reality in the Context of Disability",
        "rating": "-10",
        "keywords": [],
        "abstract": "Creating accessible Virtual Reality (VR) is an ongoing concern in the Human-Computer Interaction (HCI) research community. However, there is little reflection on how accessibility should be conceptualized in the context of an experiential technology. We address this gap in our work: We first explore how accessibility is currently defined, highlighting a growing recognition of the importance of equitable and enriching experiences. We then carry out a literature study (N=28) to examine how accessibility and its relationship with experience is currently conceptualized in VR research. Our results show that existing work seldom defines accessibility in the context of VR, and that barrier-centric research is prevalent. Likewise, we show that experience - e.g., that of presence or immersion - is rarely designed for or evaluated, while participant feedback suggests that it is relevant for disabled users of VR. On this basis, we contribute a working definition of VR accessibility that considers experience a necessary condition for equitable access, and discuss the need for future work to focus on experience in the same way as VR research addressing non-disabled persons does.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04515",
        "abstract url": "https://arxiv.org/abs/2411.04515",
        "title": "Effect of the geometry of butt-joint implant-supported restorations on the fatigue life of prosthetic screws",
        "rating": "-10",
        "keywords": [],
        "abstract": "Statement of problem. Dental implant geometry affects the mechanical performance and fatigue behavior of butt-joint implant-supported restorations. However, failure of the implant component has been generally studied by ignoring the prosthetic screw, which is frequently the critical restoration component Purpose. Evaluate the effect of 3 main implant geometric parameters: the implant body diameter, the platform diameter, and the implant-abutment connection type (external versus internal butt-joint) on the fatigue life of the prosthetic screw. The experimental values were further compared with the theoretical ones obtained by using a previously published methodology M&M. 4 different designs of direct-to-implant dental restorations from the manufacturer BTI were tested. Forty-eight fatigue tests were performed in an axial fatigue testing machine according to ISO 14801. Linear regression models, 95% interval confidence bands for the linear regression, and 95% prediction intervals of the fatigue load-life results were obtained and compared through an analysis of covariance to determine the influence of the 3 parameters under study on the fatigue behavior Results. Linear regression models showed a statistical difference when the implant body diameter was increased by 1 mm; an average 3.5-fold increase in fatigue life was observed. Increasing the implant abutment connection diameter by 1.4 mm also showed a significant difference, leading to 7-fold longer fatigue life on average. No significant statistical evidence was found to demonstrate a difference in fatigue life between internal and external connections Conclusions. Increasing the implant platform and body diameter significantly improved the fatigue life of the screw, whereas external and internal connections provided similar results. In addition, experimental results proved the accuracy of the fatigue life prediction methodology",
        "subjects": [
            "physics.med-ph",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04524",
        "abstract url": "https://arxiv.org/abs/2411.04524",
        "title": "Emotion Analysis of Social Media Bangla Text and Its Impact on Identifying the Author's Gender",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Gender Identification (GI) problem is concerned with determining the gender of the author from a given text. It has numerous applications in different fields like forensics, literature, security, marketing, trade, etc. Due to its importance, researchers have put extensive efforts into identifying gender from the text for different languages. Unfortunately, the same statement is not true for the Bangla language despite its being the 7th most spoken language in the world. In this work, we explore Gender Identification from Social media Bangla Text. Specially, we consider two approaches for feature extraction. The first one is Bag-Of-Words(BOW) approach and another one is based on computing features from sentiment and emotions. There is a common stereotype that female authors write in a more emotional way than male authors. One goal of this work is to validate this stereotype for the Bangla language.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2411.04529",
        "abstract url": "https://arxiv.org/abs/2411.04529",
        "title": "Exploring the Danmaku Content Moderation on Video-Sharing Platforms: Existing Limitations, Challenges, and Design Opportunities",
        "rating": "-10",
        "keywords": [],
        "abstract": "Video-sharing platforms (VSPs) have been increasingly embracing social features such as likes, comments, and Danmaku to boost user engagement. However, viewers may post inappropriate content through video commentary to gain attention or express themselves anonymously and even toxically. For example, on VSPs that support Danmaku, users may even intentionally create a \"flood\" of Danmaku with inappropriate content shown overlain on videos, disrupting the overall user experience. Despite of the prevalence of inappropriate Danmaku on these VSPs, there is a lack of understanding about the challenges and limitations of Danmaku content moderation on video-sharing platforms. To explore how users perceive the challenges and limitations of current Danmaku moderation methods on VSPs, we conducted probe-based interviews and co-design activities with 21 active end-users. Our findings reveal that the one-size-fits-all rules set by users or customizaibility moderation cannot accurately match the continuous Danmaku. Additionally, the moderation requirements of the Danmaku and the definition of offensive content must dynamically adjust to the video content. Non-intrusive methods should be used to maintain the coherence of the video browsing experience. Our findings inform the design of future Danmaku moderation tools on video-sharing platforms.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04538",
        "abstract url": "https://arxiv.org/abs/2411.04538",
        "title": "Analysis of Blockchain Assisted Energy Sharing Algorithms with Realistic Data Across Microgrids",
        "rating": "-10",
        "keywords": [],
        "abstract": "With escalating energy demands, innovative solutions have emerged to supply energy affordably and sustainably. Energy sharing has also been proposed as a solution, addressing affordability issues while reducing consumers' greed. In this paper, we analyse the feasibility of two energy sharing algorithms, centralized and peer-to-peer, within two scenarios, between microgrids within a county, and between microgrids across counties. In addition, we propose a new sharing algorithm named Selfish Sharing, where prosumers take advantage of consumers' batteries in return for letting them consume part of the shared energy. The results for sharing between microgrids across counties show that the dependency on the grid could be reduced by approximately 5.72%, 6.12%, and 5.93% using the centralized, peer-to-peer and selfish sharing algorithms respectively, compared to trading only. The scenario of sharing between microgrids within a county has an average decrease in dependency on the grid by 5.66%, 6.0%, and 5.80% using the centralized, peer-to-peer and selfish algorithms respectively, compared to trading without sharing. We found that trading with batteries and the proposed sharing algorithms prove to be beneficial in the sharing between microgrids case. More specifically, the case of trading and sharing energy between microgrids across counties outperforms sharing within a county, with P2P sharing appearing to be superior.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "8 pages, 4 figures, and 3 tables. Accepted for publication in The Sixth International Conference on Blockchain Computing and Applications (BCCA 2024)"
    },
    {
        "paper id": "2411.04541",
        "abstract url": "https://arxiv.org/abs/2411.04541",
        "title": "Low Complexity Joint Chromatic Dispersion and Time/Frequency Offset Estimation Based on Fractional Fourier Transform",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose and experimentally validate a joint estimation method for chromatic dispersion and time-frequency offset based on the fractional Fourier transform, which reduces computational complexity by more than 50% while keeping estimation accuracy.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, 5 figures, 1 table, ACPIPOC2024 accept"
    },
    {
        "paper id": "2411.04542",
        "abstract url": "https://arxiv.org/abs/2411.04542",
        "title": "Automatic Identification of Political Hate Articles from Social Media using Recurrent Neural Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The increasing growth of social media provides us with an instant opportunity to be informed of the opinions of a large number of politically active individuals in real-time. We can get an overall idea of the ideologies of these individuals on governmental issues by analyzing the social media texts. Nowadays, different kinds of news websites and popular social media such as Facebook, YouTube, Instagram, etc. are the most popular means of communication for the mass population. So the political perception of the users toward different parties in the country is reflected in the data collected from these social sites. In this work, we have extracted three types of features, such as the stylometric feature, the word-embedding feature, and the TF-IDF feature. Traditional machine learning classifiers and deep learning models are employed to identify political ideology from the text. We have compared our methodology with the research work in different languages. Among them, the word embedding feature with LSTM outperforms all other models with 88.28% accuracy.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "8 Pages !"
    },
    {
        "paper id": "2411.04548",
        "abstract url": "https://arxiv.org/abs/2411.04548",
        "title": "Convergence and Robustness of Value and Policy Iteration for the Linear Quadratic Regulator",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper revisits and extends the convergence and robustness properties of value and policy iteration algorithms for discrete-time linear quadratic regulator problems. In the model-based case, we extend current results concerning the region of exponential convergence of both algorithms. In the case where there is uncertainty on the value of the system matrices, we provide input-to-state stability results capturing the effect of model parameter uncertainties. Our findings offer new insights into these algorithms at the heart of several approximate dynamic programming schemes, highlighting their convergence and robustness behaviors. Numerical examples illustrate the significance of some of the theoretical results.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been submitted to the European Control Conference 2025"
    },
    {
        "paper id": "2411.04561",
        "abstract url": "https://arxiv.org/abs/2411.04561",
        "title": "Joint wireless and computing resource management with optimal slice selection in in-network-edge metaverse system",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an approach to joint wireless and computing resource management in slice-enabled metaverse networks, addressing the challenges of inter-slice and intra-slice resource allocation in the presence of in-network computing. We formulate the problem as a mixed-integer nonlinear programming (MINLP) problem and derive an optimal solution using standard optimization techniques. Through extensive simulations, we demonstrate that our proposed method significantly improves system performance by effectively balancing the allocation of radio and computing resources across multiple slices. Our approach outperforms existing benchmarks, particularly in scenarios with high user demand and varying computational tasks.",
        "subjects": [
            "cs.DC",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04574",
        "abstract url": "https://arxiv.org/abs/2411.04574",
        "title": "RIS-Assisted Space Shift Keying with Non-Ideal Transceivers and Greedy Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reconfigurable intelligent surfaces (RIS) and index modulation (IM) represent key technologies for enabling reliable wireless communication with high energy efficiency. However, to fully take advantage of these technologies in practical deployments, comprehending the impact of the non-ideal nature of the underlying transceivers is paramount. In this context, this paper introduces two RIS-assisted IM communication models, in which the RIS is part of the transmitter and space-shift keying (SSK) is employed for IM, and assesses their performance in the presence of hardware impairments. In the first model, the RIS acts as a passive reflector only, reflecting the oncoming SSK modulated signal intelligently towards the desired receive diversity branch/antenna. The second model employs RIS as a transmitter, employing M-ary phase-shift keying for reflection phase modulation (RPM), and as a reflector for the incoming SSK modulated signal. Considering transmissions subjected to Nakagami-m fading, and a greedy detection rule at the receiver, the performance of both the system configurations is evaluated. Specifically, the pairwise probability of erroneous index detection and the probability of erroneous index detection are adopted as performance metrics, and their closed-form expressions are derived for the RIS-assisted SSK and RIS-assisted SSK-RPM system models. Monte-Carlo simulation studies are carried out to verify the analytical framework, and numerical results are presented to study the dependency of the error performance on the system parameters. The findings highlight the effect of hardware impairment on the performance of the communication system under study.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "12 pages, 8 figures"
    },
    {
        "paper id": "2411.04575",
        "abstract url": "https://arxiv.org/abs/2411.04575",
        "title": "Generative Semantic Communications with Foundation Models: Perception-Error Analysis and Semantic-Aware Power Allocation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Generative foundation models can revolutionize the design of semantic communication (SemCom) systems allowing high fidelity exchange of semantic information at ultra low rates. In this work, a generative SemCom framework with pretrained foundation models is proposed, where both uncoded forward-with-error and coded discard-with-error schemes are developed for the semantic decoder. To characterize the impact of transmission reliability on the perceptual quality of the regenerated signal, their mathematical relationship is analyzed from a rate-distortion-perception perspective, which is proved to be non-decreasing. The semantic values are defined to measure the semantic information of multimodal semantic features accordingly. We also investigate semantic-aware power allocation problems aiming at power consumption minimization for ultra low rate and high fidelity SemComs. To solve these problems, two semantic-aware power allocation methods are proposed by leveraging the non-decreasing property of the perception-error relationship. Numerically, perception-error functions and semantic values of semantic data streams under both schemes for image tasks are obtained based on the Kodak dataset. Simulation results show that our proposed semanticaware method significantly outperforms conventional approaches, particularly in the channel-coded case (up to 90% power saving).",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04581",
        "abstract url": "https://arxiv.org/abs/2411.04581",
        "title": "URLLC Networks enabled by STAR-RIS, Rate Splitting, and Multiple Antennas",
        "rating": "-10",
        "keywords": [],
        "abstract": "The challenges in dense ultra-reliable low-latency communication networks to deliver the required service to multiple devices are addressed by three main technologies: multiple antennas at the base station (MISO), rate splitting multiple access (RSMA) with private and common message encoding, and simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS). Careful resource allocation, encompassing beamforming and RIS optimization, is required to exploit the synergy between the three. We propose an alternating optimization-based algorithm, relying on minorization-maximization. Numerical results show that the achievable second-order max-min rates of the proposed scheme outperform the baselines significantly. MISO, RSMA, and STAR-RIS all contribute to enabling ultra-reliable low-latency communication (URLLC).",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Accepted at 2025 International Conference on Mobile and Miniaturized Terahertz Systems (ICMMTS)"
    },
    {
        "paper id": "2411.04605",
        "abstract url": "https://arxiv.org/abs/2411.04605",
        "title": "Mint: Cost-Efficient Tracing with All Requests Collection via Commonality and Variability Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Distributed traces contain valuable information but are often massive in volume, posing a core challenge in tracing framework design: balancing the tradeoff between preserving essential trace information and reducing trace volume. To address this tradeoff, previous approaches typically used a '1 or 0' sampling strategy: retaining sampled traces while completely discarding unsampled ones. However, based on an empirical study on real-world production traces, we discover that the '1 or 0' strategy actually fails to effectively balance this tradeoff. To achieve a more balanced outcome, we shift the strategy from the '1 or 0' paradigm to the 'commonality + variability' paradigm. The core of 'commonality + variability' paradigm is to first parse traces into common patterns and variable parameters, then aggregate the patterns and filter the parameters. We propose a cost-efficient tracing framework, Mint, which implements the 'commonality + variability' paradigm on the agent side to enable all requests capturing. Our experiments show that Mint can capture all traces and retain more trace information while optimizing trace storage (reduced to an average of 2.7%) and network overhead (reduced to an average of 4.2%). Moreover, experiments also demonstrate that Mint is lightweight enough for production use.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted by ASPLOS'25"
    },
    {
        "paper id": "2411.04611",
        "abstract url": "https://arxiv.org/abs/2411.04611",
        "title": "Compressive Spectrum Sensing with 1-bit ADCs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Efficient wideband spectrum sensing (WSS) is essential for managing spectrum scarcity in wireless communications. However, existing compressed sensing (CS)-based WSS methods require high sampling rates and power consumption, particularly with high-precision analog-to-digital converters (ADCs). Although 1-bit CS with low-precision ADCs can mitigate these demands, most approaches still depend on multi-user cooperation and prior sparsity information, which are often unavailable in WSS scenarios. This paper introduces a non-cooperative WSS method using multicoset sampling with 1-bit ADCs to achieve sub-Nyquist sampling without requiring sparsity knowledge. We analyze the impact of 1-bit quantization on multiband signals, then apply eigenvalue decomposition to isolate the signal subspace from noise, enabling spectrum support estimation without signal reconstruction. This approach provides a power-efficient solution for WSS that eliminates the need for cooperation and prior information.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04615",
        "abstract url": "https://arxiv.org/abs/2411.04615",
        "title": "The Functional Machine Calculus III: Choice (Early Announcement)",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Functional Machine Calculus (Heijltjes 2022) is an extension of the lambda-calculus that preserves confluent reduction and typed termination, while enabling both call-by-name and call-by-value reduction behaviour and encoding the computational effects of mutable higher-order store, input/output, and probabilistic computation. In this note the calculus is extended to capture exception handling and loop constructs.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04658",
        "abstract url": "https://arxiv.org/abs/2411.04658",
        "title": "Finding Strong Lottery Ticket Networks with Genetic Algorithms",
        "rating": "-10",
        "keywords": [],
        "abstract": "According to the Strong Lottery Ticket Hypothesis, every sufficiently large neural network with randomly initialized weights contains a sub-network which - still with its random weights - already performs as well for a given task as the trained super-network. We present the first approach based on a genetic algorithm to find such strong lottery ticket sub-networks without training or otherwise computing any gradient. We show that, for smaller instances of binary classification tasks, our evolutionary approach even produces smaller and better-performing lottery ticket networks than the state-of-the-art approach using gradient information.",
        "subjects": [
            "cs.NE"
        ],
        "comment": "12 pages, 7 figures, 5 tables, accepted for publication at the 16th International Joint Conference on Computational Intelligence (IJCCI 2024)"
    },
    {
        "paper id": "2411.04676",
        "abstract url": "https://arxiv.org/abs/2411.04676",
        "title": "A Comparative Study of Distributed Feedback Optimizing Control Architectures",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers the problem of steady-state real-time optimization (RTO) of interconnected systems with a common constraint that couples several units, for example, a shared resource. Such problems are often studied under the context of distributed optimization, where decisions are made locally in each subsystem, and are coordinated to optimize the overall performance. Here, we use distributed feedback-optimizing control framework, where the local systems and the coordinator problems are converted into feedback control problems. This is a powerful scheme that allows us to design feedback control loops, and estimate parameters locally, as well as provide local fast response, allowing different closed-loop time constants for each local subsystem. This paper provides a comparative study of different distributed feedback optimizing control architectures using two case studies. The first case study considers the problem of demand response in a residential energy hub powered by a common renewable energy source, and compares the different feedback optimizing control approaches using simulations. The second case study experimentally validates and compares the different approaches using a lab-scale experimental rig that emulates a subsea oil production network, where the common resource is the gas lift that must be optimally allocated among the wells. %The pros and cons of the different approaches are discussed.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "Accepted to IEEE Transactions on Control Systems Technology"
    },
    {
        "paper id": "2411.04677",
        "abstract url": "https://arxiv.org/abs/2411.04677",
        "title": "Lightning IR: Straightforward Fine-tuning and Inference of Transformer-based Language Models for Information Retrieval",
        "rating": "-10",
        "keywords": [],
        "abstract": "A wide range of transformer-based language models have been proposed for information retrieval tasks. However, fine-tuning and inference of these models is often complex and requires substantial engineering effort. This paper introduces Lightning IR, a PyTorch Lightning-based framework for fine-tuning and inference of transformer-based language models for information retrieval. Lightning IR provides a modular and extensible architecture that supports all stages of an information retrieval pipeline: from fine-tuning and indexing to searching and re-ranking. It is designed to be straightforward to use, scalable, and reproducible. Lightning IR is available as open-source: https://github.com/webis-de/lightning-ir.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Accepted as a demo at WSDM'25"
    },
    {
        "paper id": "2411.04686",
        "abstract url": "https://arxiv.org/abs/2411.04686",
        "title": "Precision-Aware Iterative Algorithms Based on Group-Shared Exponents of Floating-Point Numbers",
        "rating": "-10",
        "keywords": [],
        "abstract": "Iterative solvers are frequently used in scientific applications and engineering computations. However, the memory-bound Sparse Matrix-Vector (SpMV) kernel computation hinders the efficiency of iterative algorithms. As modern hardware increasingly supports low-precision computation, the mixed-precision optimization of iterative algorithms has garnered widespread attention. Nevertheless, existing mixed-precision methods pose challenges, including format conversion overhead, tight coupling between storage and computation representation, and the need to store multiple precision copies of data. This paper proposes a floating-point representation based on the group-shared exponent and segmented storage of the mantissa, enabling higher bit utilization of the representation vector and fast switches between different precisions without needing multiple data copies. Furthermore, a stepped mixed-precision iterative algorithm is proposed. Our experimental results demonstrate that, compared with existing floating-point formats, our approach significantly improves iterative algorithms' performance and convergence residuals.",
        "subjects": [
            "cs.DC",
            "math.NA"
        ],
        "comment": "13 pages, 9 figures"
    },
    {
        "paper id": "2411.04689",
        "abstract url": "https://arxiv.org/abs/2411.04689",
        "title": "Over-the-Air DPD and Reciprocity Calibration in Massive MIMO and Beyond",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study an over-the-air (OTA) approach for digital pre-distortion (DPD) and reciprocity calibration in massive multiple-input-multiple-output systems. In particular, we consider a memory-less non-linearity model for the base station (BS) transmitters and propose a methodology to linearize the transmitters and perform the calibration by using mutual coupling OTA measurements between BS antennas. We show that by only using the OTA-based data, we can linearize the transmitters and design the calibration to compensate for both the non-linearity and non-reciprocity of BS transceivers effectively. This allows to alleviate the requirement to have dedicated hardware modules for transceiver characterization. Moreover, exploiting the results of the DPD linearization step, our calibration method may be formulated in terms of closed-form transformations, achieving a significant complexity reduction over state-of-the-art methods, which usually rely on costly iterative computations. Simulation results showcase the potential of our approach in terms of the calibration matrix estimation error and downlink data-rates when applying zero-forcing precoding after using our OTA-based DPD and calibration method.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.04702",
        "abstract url": "https://arxiv.org/abs/2411.04702",
        "title": "Large Intelligent Surfaces with Low-End Receivers: From Scaling to Antenna and Panel Selection",
        "rating": "-10",
        "keywords": [],
        "abstract": "We analyze the performance of large intelligent surface (LIS) with hardware distortion at its RX-chains. In particular, we consider the memory-less polynomial model for non-ideal hardware and derive analytical expressions for the signal to noise plus distortion ratio after applying maximum ratio combining (MRC) at the LIS. We also study the effect of back-off and automatic gain control on the RX-chains. The derived expressions enable us to evaluate the scalability of LIS when hardware impairments are present. We also study the cost of assuming ideal hardware by analyzing the minimum scaling required to achieve the same performance with a non-ideal hardware. Then, we exploit the analytical expressions to propose optimized antenna selection schemes for LIS and we show that such schemes can improve the performance significantly. In particular, the antenna selection schemes allow the LIS to have lower number of non-ideal RX-chains for signal reception while maintaining a good performance. We also consider a more practical case where the LIS is deployed as a grid of multi-antenna panels, and we propose panel selection schemes to optimize the complexity-performance trade-offs and improve the system overall efficiency.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.04704",
        "abstract url": "https://arxiv.org/abs/2411.04704",
        "title": "Distinguishing LLM-generated from Human-written Code by Contrastive Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large language models (LLMs), such as ChatGPT released by OpenAI, have attracted significant attention from both industry and academia due to their demonstrated ability to generate high-quality content for various tasks. Despite the impressive capabilities of LLMs, there are growing concerns regarding their potential risks in various fields, such as news, education, and software engineering. Recently, several commercial and open-source LLM-generated content detectors have been proposed, which, however, are primarily designed for detecting natural language content without considering the specific characteristics of program code. This paper aims to fill this gap by proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on a contrastive learning framework and a semantic encoder built with UniXcoder. To assess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generated code from human-written code, we first curate a large-scale Human and Machine comparison Corpus (HMCorp), which includes 550K pairs of human-written and ChatGPT-generated code (i.e., 288K Python code pairs and 222K Java code pairs). Based on the HMCorp dataset, our qualitative and quantitative analysis of the characteristics of ChatGPT-generated code reveals the challenge and opportunity of distinguishing ChatGPT-generated code from human-written code with their representative features. Our experimental results indicate that CodeGPTSensor can effectively identify ChatGPT-generated code, outperforming all selected baselines.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "30 pages, 6 figures, Accepted by TOSEM'24"
    },
    {
        "paper id": "2411.04739",
        "abstract url": "https://arxiv.org/abs/2411.04739",
        "title": "The New Dynamics of Open Source: Relicensing, Forks, & Community Impact",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many popular open source projects are owned and driven by vendors, and in today's difficult economic climate, those vendors are under increasing pressure from investors to deliver a strong return on their investments. One response to this pressure has been the relicensing of popular open source projects to more restrictive licenses in the hopes of generating more revenue, disrupting the idea of open source as a digital commons. In some cases, relicensing has resulted in a hard fork of the original project. These relicensing events and resulting forks can be disruptive to the organizations and individuals using these open source projects. This research compares and contrasts organizational affiliation data from three case studies based on license changes that resulted in forks: Elasticsearch / OpenSearch, Redis / Valkey, and Terraform / OpenTofu. The research indicates that the forks resulting from these relicensing events have more organizational diversity than the original projects, especially when the forks are created under a neutral foundation, like the Linux Foundation, rather than by a single company.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Presented at OpenForum Academy (OFA) Symposium in Boston, Massachusetts, November 13 & 14, 2024"
    },
    {
        "paper id": "2411.04753",
        "abstract url": "https://arxiv.org/abs/2411.04753",
        "title": "Efficient Channel Estimation With Shorter Pilots in RIS-Aided Communications: Using Array Geometries and Interference Statistics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Accurate estimation of the cascaded channel from a user equipment (UE) to a base station (BS) via each reconfigurable intelligent surface (RIS) element is critical to realizing the full potential of the RIS's ability to control the overall channel. The number of parameters to be estimated is equal to the number of RIS elements, requiring an equal number of pilots unless an underlying structure can be identified. In this paper, we show how the spatial correlation inherent in the different RIS channels provides this desired structure. We first optimize the RIS phase-shift pattern using a much-reduced pilot length (determined by the rank of the spatial correlation matrices) to minimize the mean square error (MSE) in the channel estimation under electromagnetic interference. In addition to considering the linear minimum MSE (LMMSE) channel estimator, we propose a novel channel estimator that requires only knowledge of the array geometry while not requiring any user-specific statistical information. We call this the reduced-subspace least squares (RS-LS) estimator and optimize the RIS phase-shift pattern for it. This novel estimator significantly outperforms the conventional LS estimator. For both the LMMSE and RS-LS estimators, the proposed optimized RIS configurations result in significant channel estimation improvements over the benchmarks.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "16 pages, 9 figures, to appear in IEEE Transactions on Wireless Communications"
    },
    {
        "paper id": "2411.04787",
        "abstract url": "https://arxiv.org/abs/2411.04787",
        "title": "AllGaits: Learning All Quadruped Gaits and Transitions",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a framework for learning a single policy capable of producing all quadruped gaits and transitions. The framework consists of a policy trained with deep reinforcement learning (DRL) to modulate the parameters of a system of abstract oscillators (i.e. Central Pattern Generator), whose output is mapped to joint commands through a pattern formation layer that sets the gait style, i.e. body height, swing foot ground clearance height, and foot offset. Different gaits are formed by changing the coupling between different oscillators, which can be instantaneously selected at any velocity by a user. With this framework, we systematically investigate which gait should be used at which velocity, and when gait transitions should occur from a Cost of Transport (COT), i.e. energy-efficiency, point of view. Additionally, we note how gait style changes as a function of locomotion speed for each gait to keep the most energy-efficient locomotion. While the currently most popular gait (trot) does not result in the lowest COT, we find that considering different co-dependent metrics such as mean base velocity and joint acceleration result in different `optimal' gaits than those that minimize COT. We deploy our controller in various hardware experiments, showing all 9 typical quadruped animal gaits, and demonstrate generalizability to unseen gaits during training, and robustness to leg failures. Video results can be found at https://youtu.be/OLoWSX_R868.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04803",
        "abstract url": "https://arxiv.org/abs/2411.04803",
        "title": "Unbounded Error Correcting Codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce a variant of Error Correcting Codes with no predetermined length. An Unbounded ECC with rate $R$ and distance $\\varepsilon$ is an encoding of a possibly infinite message into a possibly infinite codeword, such that for every large enough $k$ we may recover the first $Rk$ symbols of the message from the first $k$ symbols of the codeword -- even when up to $\\frac{1}{2}\\varepsilon k$ of these codeword symbols are adversarially corrupted. We study unbounded codes over a binary alphabet in the regime of small distance $\\varepsilon$, and obtain nearly-tight upper and lower bounds in several natural settings. We show that the optimal rate of such a code is between $R<1-\u03a9(\\sqrt{\\varepsilon})$ and $R>1-O\\left(\\sqrt{\\varepsilon\\log\\log\\left(1/\\varepsilon\\right)}\\right)$. Surprisingly, our construction is non-linear, and we show that the optimal rate of a linear unbounded code is the asymptotically worse $R=1-\u0398\\left(\\sqrt{\\varepsilon\\log\\left(1/\\varepsilon\\right)}\\right)$. In the setting of random noise, the optimal rate of unbounded codes improves and matches the rate of standard codes at $R=1-\u0398({\\varepsilon\\log{\\left(1/\\varepsilon\\right)}})$.",
        "subjects": [
            "cs.DS",
            "cs.IT",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04809",
        "abstract url": "https://arxiv.org/abs/2411.04809",
        "title": "Minimax Linear Regulator Problems for Positive Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Exceptional are the instances where explicit solutions to optimal control problems are obtainable. Of particular interest are the explicit solutions derived for minimax problems, which provide a framework for tackling challenges characterized by adversarial conditions and uncertainties. This work builds on recent discrete-time research, extending it to a multi-disturbance minimax linear framework for linear time-invariant systems in continuous time. Disturbances are considered to be bounded by elementwise linear constraints, along with unconstrained positive disturbances. Dynamic programming theory is applied to derive explicit solutions to the Hamilton-Jacobi-Bellman (HJB) equation for both finite and infinite horizons. For the infinite horizon a fixed-point method is proposed to compute the solution of the HJB equation. Moreover, the Linear Regulator (LR) problem is introduced, which, analogous to the Linear-Quadratic Regulator (LQR) problem, can be utilized for the stabilization of positive systems. A linear program formulation for the LR problem is proposed which computes the associated stabilizing controller, it it exists. Additionally necessary and sufficient conditions for minimizing the $l_1$-induced gain of the system are derived and characterized through the disturbance penalty of the cost function of the minimax problem class. We motivate the prospective scalability properties of our framework with a large-scale water management network.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "26 pages, 5 figures"
    },
    {
        "paper id": "2411.04824",
        "abstract url": "https://arxiv.org/abs/2411.04824",
        "title": "Image-based adaptive domain decomposition for continuum damage models",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a novel image-based adaptive domain decomposition FEM framework to accelerate the solution of continuum damage mechanics problems. The key idea is to use image-processing techniques in order to identify the moving interface between the healthy subdomain and unhealthy subdomain as damage propagates, and then use an iterative Schur complement approach to efficiently solve the problem. The implementation of the algorithm consists of several modular components. Following the FEM solution of a load increment, the damage detection module is activated, a step that is based on several image-processing operations including colormap manipulation and morphological convolution-based operations. Then, the damage tracking module is invoked, to identify the crack growth direction using geometrical operations and ray casting algorithm. This information is then passed into the domain decomposition module, where the domain is divided into the healthy subdomain which contains only undamaged elements, and the unhealthy subdomain which comprises both damaged and undamaged elements. Continuity between the two regions is restored using penalty constraints. The computational savings of our method stem from the Schur complement, which allows for the iterative solution of the system of equations appertaining only to the unhealthy subdomain. Through an exhaustive comparison between our approach and single domain computations, we demonstrate the accuracy, efficiency, and robustness of the framework. We ensure its compatibility against local and non-local damage laws, structured and unstructured meshes, as well as in cases where different damage paths eventually merge. Since the key novelty lies in using image processing tools to inform the decomposition, our framework can be readily extended beyond damage mechanics and model several classes of non-linear problems such as plasticity and phase-field.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04833",
        "abstract url": "https://arxiv.org/abs/2411.04833",
        "title": "Finding Control Invariant Sets via Lipschitz Constants of Linear Programs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Control invariant sets play an important role in safety-critical control and find broad application in numerous fields such as obstacle avoidance for mobile robots. However, finding valid control invariant sets of dynamical systems under input limitations is notoriously difficult. We present an approach to safely expand an initial set while always guaranteeing that the set is control invariant. Specifically, we define an expansion law for the boundary of a set and check for control invariance using Linear Programs (LPs). To verify control invariance on a continuous domain, we leverage recently proposed Lipschitz constants of LPs to transform the problem of continuous verification into a finite number of LPs. Using concepts from differentiable optimization, we derive the safe expansion law of the control invariant set and show how it can be interpreted as a second invariance problem in the space of possible boundaries. Finally, we show how the obtained set can be used to obtain a minimally invasive safety filter in a Control Barrier Function (CBF) framework. Our work is supported by theoretical results as well as numerical examples.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04864",
        "abstract url": "https://arxiv.org/abs/2411.04864",
        "title": "Voltage Support Capability Analysis of Grid-Forming Inverters with Current-Limiting Control Under Asymmetrical Grid Faults",
        "rating": "-10",
        "keywords": [],
        "abstract": "Voltage support capability is critical for grid-forming (GFM) inverters with current-limiting control (CLC) during grid faults. Despite the findings on the voltage support for symmetrical grid faults, its applicability to more common but complex asymmetrical grid faults has yet to be verified rigorously. This letter fills the gap in the voltage support capability analysis for asymmetrical grid faults by establishing and analyzing positive- and negative-sequence equivalent circuit models, where the virtual impedance is adopted to emulate various CLCs. It is discovered that matching the phase angle of the virtual impedance, emulated by the CLC, with that of the composed impedance from the capacitor to the fault location can maximize the voltage support capability of GFM inverters under asymmetrical grid faults. Rigorous theoretical analysis and experimental results verify this conclusion.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.04870",
        "abstract url": "https://arxiv.org/abs/2411.04870",
        "title": "Manifold Diagrams for Higher Categories",
        "rating": "-10",
        "keywords": [],
        "abstract": "We develop a graphical calculus of manifold diagrams which generalises string and surface diagrams to arbitrary dimensions. Manifold diagrams are pasting diagrams for $(\\infty, n)$-categories that admit a semi-strict composition operation for which associativity and unitality is strict. The weak interchange law satisfied by composition of manifold diagrams is determined geometrically through isotopies of diagrams. By building upon framed combinatorial topology, we can classify critical points in isotopies at which the arrangement of cells changes. This allows us to represent manifold diagrams combinatorially and use them as shapes with which to probe $(\\infty, n)$-categories, presented as $n$-fold Segal spaces. Moreover, for any system of labels for the singularities in a manifold diagram, we show how to generate a free $(\\infty, n)$-category.",
        "subjects": [
            "math.AT",
            "cs.LO",
            "math.CT"
        ],
        "comment": "originally submitted version, before corrections"
    },
    {
        "paper id": "2411.04906",
        "abstract url": "https://arxiv.org/abs/2411.04906",
        "title": "Faster feasibility for dynamic flows and transshipments on temporal networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study flow problems on temporal networks, where edge capacities and travel times change over time. We consider a network with $n$ nodes and $m$ edges where the capacity and length of each edge is a piecewise constant function, and use $\u03bc=\u03a9(m)$ to denote the total number of pieces in all of the $2m$ functions. Our goal is to design exact algorithms for various flow problems that run in time polynomial in the parameter $\u03bc$. Importantly, the algorithms we design are strongly polynomial, i.e. have no dependence on the capacities, flow value, or the time horizon of the flow process, all of which can be exponentially large relative to the other parameters; and return an integral flow when all input parameters are integral. Our main result is an algorithm for checking feasibility of a dynamic transshipment problem on temporal networks -- given multiple sources and sinks with supply and demand values, is it possible to satisfy the desired supplies and demands within a given time horizon? We develop a fast ($O(\u03bc^3)$ time) algorithm for this feasibility problem when the input network has a certain canonical form, by exploiting the cut structure of the associated time expanded network. We then adapt an approach of \\cite{hoppe2000} to show how other flow problems on temporal networks can be reduced to the canonical format. For computing dynamic transshipments on temporal networks, this results in a $O(\u03bc^7)$ time algorithm, whereas the previous best integral exact algorithm runs in time $\\tilde O(\u03bc^{19})$. We achieve similar improvements for other flow problems on temporal networks.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "33 pages, 8 figures"
    },
    {
        "paper id": "2411.04949",
        "abstract url": "https://arxiv.org/abs/2411.04949",
        "title": "Global Optimal Closed-Form Solutions for Intelligent Surfaces With Mutual Coupling: Is Mutual Coupling Detrimental or Beneficial?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reconfigurable Intelligent Surface (RIS) is a breakthrough technology enabling the dynamic control of the propagation environment in wireless communications through programmable surfaces. To improve the flexibility of conventional diagonal RIS (D-RIS), beyond diagonal RIS (BD-RIS) has emerged as a family of more general RIS architectures. However, D-RIS and BD-RIS have been commonly explored neglecting mutual coupling effects, while the global optimization of RIS with mutual coupling, its performance limits, and scaling laws remain unexplored. This study addresses these gaps by deriving global optimal closed-form solutions for BD-RIS with mutual coupling to maximize the channel gain, specifically fully- and tree-connected RISs. Besides, we provide the expression of the maximum channel gain achievable in the presence of mutual coupling and its scaling law in closed form. By using the derived scaling laws, we analytically prove that mutual coupling increases the channel gain on average under Rayleigh fading channels. Our theoretical analysis, confirmed by numerical simulations, shows that both fully- and tree-connected RISs with mutual coupling achieve the same channel gain upper bound when optimized with the proposed global optimal solutions. Furthermore, we observe that a mutual coupling-unaware optimization of RIS can cause a channel gain degradation of up to 5 dB.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Submitted to IEEE for publication"
    },
    {
        "paper id": "2411.05087",
        "abstract url": "https://arxiv.org/abs/2411.05087",
        "title": "Measuring Software Innovation with Open Source Software Development Data",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper introduces a novel measure of software innovation based on open source software (OSS) development activity on GitHub. We examine the dependency growth and release complexity among $\\sim$200,000 unique releases from 28,000 unique packages across the JavaScript, Python, and Ruby ecosystems over two years post-release. We find that major versions show differential, strong prediction of one-year lagged log change in dependencies. In addition, semantic versioning of OSS releases is correlated with their complexity and predict downstream adoption. We conclude that major releases of OSS packages count as a unit of innovation complementary to scientific publications, patents, and standards, offering applications for policymakers, managers, and researchers.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05098",
        "abstract url": "https://arxiv.org/abs/2411.05098",
        "title": "Proposal of a Contact Detection System using Micro-phones for a Chambara-based Augmented Sports",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study presents a novel contact detection system for \"Parablade,\" a chambara-based, sword-play augmented sport. Augmented sports combine physical activities with virtual parameters (VPs) to create a balanced and equitable gaming experience, irrespective of players' physical capabilities. The proposed Parablade Microphone Unit (PMU) employs multiple micro-phones and machine learning algorithms to detect and classify hit events through sound recogni-tion. This system aims to ensure real-time updates of VPs, thereby enhancing the gameplay expe-rience. Experimental results indicate that the PMU can accurately recognize the occurrence and location of hit events with a high accuracy rate of 93.33%, with the assistance of 10kHz additional sound generated from the sword.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05099",
        "abstract url": "https://arxiv.org/abs/2411.05099",
        "title": "Exploring Vibrotactile Intensity Perception with Multiple Waveform Parameters",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is known that by longing the duration of a vibrotactile stimuli or applying a damping or an increasing factor to the waveform the perceived intensity is affected in different ways. This paper presents a vibrotactile presentation system assembled with a software waveform generator that enables comparison in the perceived intensity for different waveforms made by multiple parameters. The adjustable parameters are frequency, amplitude, and wave type for the basic part of the stimuli and in addition, it is possible to apply an exponential decay or increasing factor to the waveform by specificizing the duration. By using the presented system, an easy comparison of the influence to the perception of intensity by different parameters of the waveform is possible. We conducted a preliminary experiment on a variety of waveshapes with and without damping by using this system.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05100",
        "abstract url": "https://arxiv.org/abs/2411.05100",
        "title": "Fingernail-Based Tangential Force Simulation for Enhanced Dexterous Manipulation in Virtual Reality",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study introduces a novel haptic device for enhancing dexterous manipulation in virtual reality. By stimulating mechanoreceptors on both sides of the fingernail, our lightweight system simulates tangential force sensations. We employ mechanical stimulation for more natural tactile feedback. A preliminary \"balancing grasp challenge\" experiment shows that users make more frequent micro-adjustments with our device, indicating improved precision. This research aims to advance haptic feedback in VR, potentially leading to more immersive and realistic virtual interactions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05104",
        "abstract url": "https://arxiv.org/abs/2411.05104",
        "title": "Skill Transfer System that Visualizes and Presents Tactile Information in an AR Environment",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, the lack of successors for traditional skills has become an issue. To solve this problem, we propose a skill transfer system that presents tactile information in spatial tasks as a color map on an AR space. We believe that providing the operator with feedback of the force and tactile information during the work is useful for learning skills that require time to master. Furthermore, by following the operator's hand and presenting tactile information, we expect to accelerate the learning of skills by not only presenting tactile information as a physical sensation, but also by making the operator associate tactile information with position.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05105",
        "abstract url": "https://arxiv.org/abs/2411.05105",
        "title": "Presenting the Sense of Effort through Vibration Based on Force Estimated by Inverse Dynamics in Videos",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present the sense of effort through vibration to help the video viewer understand how the person in the video moves the body. We suppose sense of effort is related to force, so we generate vibration based on force and present the sense of effort through the vibration. We use perceived intensity to make sense of effort proportional to vibration. In our demonstration, you can experience vibration while watching a video. We can create vibration on the spot, so you can experience vibration made from a video taken on the spot.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05109",
        "abstract url": "https://arxiv.org/abs/2411.05109",
        "title": "Haptic Information Feedback Given to Handles in Guide Dog Training",
        "rating": "-10",
        "keywords": [],
        "abstract": "In guide dog training, trainers use haptic information transmitted through the handle of the harness worn by the guide dog to understand the dog's state. They then apply appropriate force to the handle to train the dog to make correct judgments. This tactile experience can only be felt between the dog and the trainer, making it challenging to communicate the amount of force applied to others quantitatively. To solve this problem, this study proposes a method for real-time visualization of the force exerted on the handle and quantification of the handle movement through image processing, which can be applied to actual guide dog training.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05110",
        "abstract url": "https://arxiv.org/abs/2411.05110",
        "title": "Haptic Reproduction of Curved Surface and Edge by Controlling the Contact Position between the Disk and the Finger Using Airborne Ultrasound",
        "rating": "-10",
        "keywords": [],
        "abstract": "By presenting curved surfaces of various curvatures including edges to the fingertip, it is possible to reproduce the haptic sensation of object shapes that cannot be reproduced by flat surfaces alone, such as spheres and rectangular objects. In this paper, we propose a method of presenting curved surfaces by controlling the inclination of a disk in contact with the finger belly with acoustic radiation pressure of ultrasound. The user only needs to mount a lightweight device on the fingertip to experience a tactile presentation with low physical burden. In the demonstration, the user can experience the sensation of stroking an edge and different curvatures of curved surfaces.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05111",
        "abstract url": "https://arxiv.org/abs/2411.05111",
        "title": "Location-Based Output Adaptation for Enhanced Actuator Performance using Frequency Sweep Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a methodology for enhancing actuator performance in older devices or retrofitting devices with haptic feedback actuators. The approach is versatile, accommodating various actuator and mounting positions. Through a frequency sweep analysis, the system's characteristics are captured, enabling the creation of location-specific transfer functions to accurately transform input signals into command signals for a precise output at the target location. This method offers fast and simple collection of the system properties and generation of location-specific signals.",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05115",
        "abstract url": "https://arxiv.org/abs/2411.05115",
        "title": "Bridging Player Intentions: Exploring the Potential of Synchronized Haptic Controllers in Multiplayer Game",
        "rating": "-10",
        "keywords": [],
        "abstract": "In multiplayer cooperative video games, players traditionally use individual controllers, inferring others' actions through on-screen visuals and their own movements. This indirect understanding limits truly collaborative gameplay. Research in Joint Action shows that when manipulating a single object, motor performance improves when two people operate together while sensing each other's movements. Building on this, we developed a controller allowing multiple players to operate simultaneously while sharing haptic sensations. We showcased our system at exhibitions, gathering feedback from over 150 participants on how shared sensory input affects their gaming experience. This approach could transform player interaction, enhance cooperation, and redefine multiplayer gaming experiences.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05116",
        "abstract url": "https://arxiv.org/abs/2411.05116",
        "title": "Haptic Color Patterns for Visually Impaired People-Pilot Study for a Learning Color Wheel",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study proposes a tactile diagram pattern for visually impaired people to recognize color information. The pattern uses the principle of three primary colors, with different patterns representing red, blue, and yellow. The size of tactile elements on these patterns indicates the proportion of the color mixing. A preliminary experiment showed that even a sighted participant could understand and reconstruct the tactile diagram. Future experiments will target visually impaired people to confirm the effectiveness of this method.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05117",
        "abstract url": "https://arxiv.org/abs/2411.05117",
        "title": "Development of fall prevention training device that can provide external disturbance to the ankle with pneumatic gel muscles (PGM) while walking",
        "rating": "-10",
        "keywords": [],
        "abstract": "Although the average life expectancy in Japan has been increasing in recent years, the problem of the large gap between healthy life expectancy and average life expectancy is still unresolved. Among the factors that lead to the need for nursing care, injuries due to falls account for a certain percentage of the total. In this paper, we developed boots that can provide external disturbance to the ankle with pneumatic gel muscles (PGM) while walking. We experimented using an angular velocity and acceleration of the heel as evaluation indices to evaluate the effectiveness of fall prevention training using this device, which is smaller and more wearable than conventional devices. In this study, we confirmed that the developed system has enough training intensity to significantly affect the gait waveform.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05121",
        "abstract url": "https://arxiv.org/abs/2411.05121",
        "title": "Development and evaluation of a system to express a sense of telekinesis in VR",
        "rating": "-10",
        "keywords": [],
        "abstract": "Telekinesis is the ability to manipulate remote objects without direct physical contact. In fictional works, telekinesis users are often depicted as controlling objects with their hands and other body parts as if by will alone. Such depictions suggest that users experience a sense of agency over the object despite not physically touching it. In this study, we developed a VR method to simulate telekinesis and investigated whether it is possible to achieve a sense of physical sensation and agency similar to the experience portrayed in fiction.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05123",
        "abstract url": "https://arxiv.org/abs/2411.05123",
        "title": "Friction tunable electrostatic clutch with low driving voltage for kinesthetic haptic feedback",
        "rating": "-10",
        "keywords": [],
        "abstract": "As interest in Virtual Reality (VR) and Augmented Reality (AR) increases, the demand for kinesthetic haptic feedback devices is rapidly rising. Motor based haptic interfaces are heavy and bulky, leading to discomfort for the user. To address this issue, haptic gloves based on electrostatic clutches that offer fast response times and a thin form factor are being researched. However, high operating voltages and variable force control remain challenges to overcome. Electrostatic clutches utilizing functional polymers with charge accumulation properties and dielectric liquid can generate the frictional shear stress over a wide range from 0.35 N/cm$^2$ to 18.9 N/cm$^2$ at low voltages below 100 V. Based on this, the haptic glove generates a high blocking force and is comfortable to wear.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05125",
        "abstract url": "https://arxiv.org/abs/2411.05125",
        "title": "Mouse Embedded Soft Vibration Actuator for Exploring Surface Textures",
        "rating": "-10",
        "keywords": [],
        "abstract": "We aimed to develop a tactile display that allows users to actively explore the virtual texture of a surface. We developed a tactile display embedded in an optical mouse that provides a wide range of frequency vibrations to the user's fingertip in response to its movement. We conducted an experiment to confirm the degree of fineness based on a stripe pattern identification task using a trial system. The results showed that the subject could identify a fine spatial resolution up to 0.16 mm width.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05126",
        "abstract url": "https://arxiv.org/abs/2411.05126",
        "title": "A Comparison of Violin Bowing Pressure and Position among Expert Players and Beginners",
        "rating": "-10",
        "keywords": [],
        "abstract": "The violin is one of the most popular musical instruments, but mastering it requires a significant amount of practice time. The bowing action (pressure, position, speed) of the right hand is crucial in determining tonal quality, but this is difficult to master. This study compared the bowing movements, specifically bow pressure, bow position, and bow speed, of experienced players with those of beginners. Identifying common bowing characteristics of experienced violin players can aid the evaluation of beginners' skills and the development of a feedback system that supports self-practice and instruction.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05127",
        "abstract url": "https://arxiv.org/abs/2411.05127",
        "title": "Emotional VR handshake by controlling skin deformation distribution",
        "rating": "-10",
        "keywords": [],
        "abstract": "Digital communication tools are limited to visual and auditory information and lack non-verbal information such as touch, which is important for communicating intentions and emotions. In order to solve this problem, the use of haptic technology in digital communication is attracting attention. In this study, we constructed a virtual handshake system that can reproduce distributed haptic information using a wearable device that presents skin deformation. Using the system, we experimentally obtained the correspondence between emotions and handshaking behavior, and constructed a demonstration of handshakes that can express differences in emotions based on the experimental results.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05130",
        "abstract url": "https://arxiv.org/abs/2411.05130",
        "title": "Independent perceptual process of microscopic texture and surface shapes through lateral resistive force cues",
        "rating": "-10",
        "keywords": [],
        "abstract": "Macroscopic surface shapes, such as bumps and dents, as well as microscopic surface features, like texture, can be identified solely through lateral resistive force cues when a stylus moves across them. This perceptual phenomenon has been utilized to advance tactile presentation techniques for surface tactile displays. However, the effects on shape recognition when microscopic textures and macroscopic shapes coexist have not been thoroughly investigated. This study reveals that macroscopic surface shapes can be recognized independently of the presence of microscopic textures. These findings enhance our understanding of human perceptual properties and contribute to the development of tactile displays.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05132",
        "abstract url": "https://arxiv.org/abs/2411.05132",
        "title": "Conformal Surface Splines",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce a family of boundary conditions and point constraints for conformal immersions that increase the controllability of surfaces defined as minimizers of conformal variational problems. Our free boundary conditions fix the metric on the boundary, up to a global scale, and admit a discretization compatible with discrete conformal equivalence. We also introduce constraints on the conformal scale factor, enforcing rigidity of the geometry in regions of interest, and describe how in the presence of point constraints the conformal class encodes knot points of the spline that can be directly manipulated. To control the tangent planes, we introduce flux constraints balancing the internal material stresses. The collection of these point constraints provide intuitive controls for exploring a subspace of conformal immersions interpolating a fixed set of points in space. We demonstrate the applicability of our framework to geometric modeling, mathematical visualization, and form finding.",
        "subjects": [
            "math.DG",
            "cs.GR"
        ],
        "comment": "to appear in Differential Geom. Appl., 26 pages"
    },
    {
        "paper id": "2411.05133",
        "abstract url": "https://arxiv.org/abs/2411.05133",
        "title": "Innovative Weight Simulation in Virtual Reality Cube Games: A Pseudo-Haptic Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an innovative pseudo-haptic model for weight simulation in virtual reality (VR) environments. By integrating visual feedback with voluntary exerted force through a passive haptic glove, the model creates haptic illusions of weight perception. Two VR cube games were developed to evaluate the model's effectiveness. The first game assesses participants' ability to discriminate relative weights, while the second evaluates their capability to estimate absolute weights. Twelve participants, aged 18 to 59, tested the games. Results suggest that the pseudo-haptic model is effective for relative weight discrimination tasks and holds potential for various VR applications. Further research with a larger participant group and more complex scenarios is recommended to refine and validate the model.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05134",
        "abstract url": "https://arxiv.org/abs/2411.05134",
        "title": "Quality Assurance Practices in Agile Methodology",
        "rating": "-10",
        "keywords": [],
        "abstract": "The complexity of software is increasing day by day the requirement and need for a verity of softwareproducts increases, this necessitates the provision of a strong tool that will make a balance betweenproduction and quality. The practice of applying software metrics to the development process and to asoftware product is a critical task and crucial enough that requires study and discipline and whichbrings knowledge of the status of the process and/or product of software in regards to the goals toachieve, this discipline is known as quality assurance which is the key factor behind the success ofevery software engineering project, the quality assurance activities are what result in the qualitativeproduct as well as the process in both conventional software development methodology and agilemethodology. However, agile methodology is now becoming one of the dominant method adopted bymost of the software industries because it allows developing of software with very limited requirementand supports rapid changes in the requirement, the method may produce the product very fast but wemight not guarantee the quality of the product unless we apply the SQA activities to the process. Thisresearch paper aimed to study the quality assurance activities practice in agile software developmentmethodology, investigate the common problems and key drivers of quality in agile, and propose asolution to improve the practice of SQA in agile methodology by analyzing the parameters that assurequality in agile software.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05140",
        "abstract url": "https://arxiv.org/abs/2411.05140",
        "title": "Hold and Feel! A Multiplayer Video Game System with Interpersonal Vibrotactile Feedback via Bracelet Controllers",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent multiplayer video games (MPVGs) have increasingly incorporated social behaviors, such as gathering in the same place and facing each other, to enhance player interaction. This study aims to develop an MPVG system that facilitates social interaction through interpersonal touch between players. We present an MPVG system where two players wearing bracelet-type game controllers control a player character through touch to catch items and feel the position of the player character through vibrotactile sensations between their hands.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05143",
        "abstract url": "https://arxiv.org/abs/2411.05143",
        "title": "Pneumatically Controlled Tactile Actuating Modules for Enhanced VR Safety Training",
        "rating": "-10",
        "keywords": [],
        "abstract": "Our system introduces a modularized pneumatic actuating unit capable of delivering vibration, pressure, and impact feedback. Designed for adaptability, these modular tactile actuating units can be rapidly customized and reconfigured to suit a wide range of virtual reality (VR) scenarios, with a particular emphasis on safety training applications. This flexibility is demonstrated through scenarios such as using construction tools in a virtual environment and simulating safety protocols against falling objects. Innovative mounting solutions securely attach the actuators to various body sites, ensuring both comfort and stability during use. Our approach enables seamless integration into diverse VR safety training programs, enhancing the realism and effectiveness of simulations with precise and reliable haptic feedback.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05144",
        "abstract url": "https://arxiv.org/abs/2411.05144",
        "title": "Effects of Coordinative Arm Swing Movements on the Sense of Agency in Walking Sensation Induced by Kinesthetic Illusion",
        "rating": "-10",
        "keywords": [],
        "abstract": "Kinesthetic illusion can present a sense of movement without actual physical movement of the body, but it often lacks a sense of agency over the movement. Therefore, we focused on the sensation of walking induced by the kinesthetic illusion and hypothesized that incorporating coordinated arm swing movements as actual actions could enhance the sense of agency over the kinesthetic illusion. In this study, we implemented a system that switches the vibrations of the thighs and ankles back and forth based on arm swing movements and investigated whether the sense of agency over the walking sensation induced by the kinesthetic illusion changes with or without arm swing movements. The results suggest a tendency for the sense of agency to be enhanced when arm swing movements are combined.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05147",
        "abstract url": "https://arxiv.org/abs/2411.05147",
        "title": "A Soft Vibrotactile Display Using Sound Speakers",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study introduces an innovative vibrotactile display that harnesses audio speakers to convey tactile information to the fingertips while preserving the display's softness and flexibility. Our proposed system integrates a flexible polymer body with silicone rubber tubes connected to audio speakers. By streaming audio through these speakers, we induce air vibrations within the tubes, generating tactile stimuli on the skin. In contrast to conventional tactile displays that often rely on bulky, rigid actuators, our approach employs multiple speakers to deliver high-resolution vibration patterns. This configuration enables the presentation of high-frequency vibrations, potentially enhancing the fidelity of tactile feedback. We present a detailed description of the display's design principles and implementation methodology, highlighting its potential to advance the field of haptic interfaces.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05149",
        "abstract url": "https://arxiv.org/abs/2411.05149",
        "title": "Electrostatic Tactile Display without Insulating Layer",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper explores an approach to eliminating the surface insulating layer in electrostatic (electroadhesion) tactile displays. Electrostatic tactile displays modulate the surface friction by an electrical charge between the skin and the display. Traditionally, the non-conductive dielectric layer has been considered crucial for charge accumulation, as well as for safety to prevent DC current stimulation. However, by utilizing a current control technology for electrotactile displays, we can achieve electrostatic tactile display without the insulating layer. The electrical charge is possibly accumulated in the skin itself or in the air gap between the skin and the electrodes. Safety is maintained by balancing positive and negative current pulses. Furthermore, this system is compatible with existing electrotactile displays. This paper details the system configuration, presentation algorithm, and experimental results. The preliminary trial revealed that five out of eight participants could clearly feel the vibration, confirmed by acceleration recording, while the remaining participants could not experience the sensation.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05150",
        "abstract url": "https://arxiv.org/abs/2411.05150",
        "title": "Scanning Tactile Sensor with Spiral Coil Structure Amplifying Detection Performance of Micro-concave",
        "rating": "-10",
        "keywords": [],
        "abstract": "Surface inspection is a delicate process aimed at detecting fine defects, irregularities, and foreign substances at the tens of micrometers level, subsequently excluding products that do not meet the quality standards as defective. Currently, this inspection relies on the tactile senses of skilled technicians, leading to variability in the detection accuracy based on the level of proficiency and experience. Consequently, a standardized method for surface inspection has yet to be established. In response to this issue, we have developed a device capable of amplifying tactile information, allowing for the detection of minute distortions without the need for highly skilled technicians. The experimental results on various small distortions suggest the potential for the quantitative evaluation of these distortions. In the future, the application of this device could contribute to the automation of surface inspection.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05151",
        "abstract url": "https://arxiv.org/abs/2411.05151",
        "title": "Presentation of tracing sensation with different roughness by using disk with uneven surface",
        "rating": "-10",
        "keywords": [],
        "abstract": "Tracing sensation plays an important role in discriminating friction and texture of objects. We have been studying a method of presenting the tracing sensation by contacting the center of a rotating disk with the fingertip. Although this method can reduce the size and complexity of the presentation device compared to conventional methods, it has the problem of fixed sensation. In this study, we examined a method to dynamically modulate the roughness sensation by devising the surface shape of the disk. We designed two types of disks: slit disks and milling disks. Experiments revealed that the perceived roughness of these disks can be changed by altering the rotation speed and direction.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05152",
        "abstract url": "https://arxiv.org/abs/2411.05152",
        "title": "Passive Touch Experience with Virtual Doctor Fish Using Ultrasound Haptics",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study implements and evaluates passive interaction using an autostereoscopic display and ultrasound haptics technology, simulating Garra rufa (\"doctor fish\") nibbling. When the virtual doctor fish touches the user's hand, ultrasound tactile sensations are presented by spatio-temporal modulation (STM) as an ultrasound focal point orbits around the contact points. A user study evaluated parameters affecting realism, including STM frequency, the number of focal points, ultrasound amplitude, and hand moistening. Comparing several combinations of parameters revealed that representing contact with fewer representative points and setting the frequency of the STM to 10 Hz produced the most realistic experience.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05153",
        "abstract url": "https://arxiv.org/abs/2411.05153",
        "title": "Wearable Haptic Device to Render 360-degree Torque Feedback on the Wrist",
        "rating": "-10",
        "keywords": [],
        "abstract": "Haptic feedback increases the realism of virtual environments. This paper proposes a wearable haptic device that renders torque feedback to the user's wrist from any angle. The device comprises a control part and a handle part. The control part consists of three DC gear motors and a microcontroller, while the handle part securely holds the Oculus Quest 2 right controller. The control part manages string tension to deliver the sensation of torque feedback during interactions with virtual tools or objects. The three points of the handle part are connected to the three motors of the control part via strings, which pull the handle part to render precise 360-degree (yaw and pitch) torque feedback to the user's wrist. Finally, to show the effectiveness of the proposed device, two VR demos were implemented- Shooting Game and Shielding Experience.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05156",
        "abstract url": "https://arxiv.org/abs/2411.05156",
        "title": "Average-Distortion Sketching",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce average-distortion sketching for metric spaces. As in (worst-case) sketching, these algorithms compress points in a metric space while approximately recovering pairwise distances. The novelty is studying average-distortion: for any fixed (yet, arbitrary) distribution $\u03bc$ over the metric, the sketch should not over-estimate distances, and it should (approximately) preserve the average distance with respect to draws from $\u03bc$. The notion generalizes average-distortion embeddings into $\\ell_1$ [Rabinovich '03, Kush-Nikolov-Tang '21] as well as data-dependent locality-sensitive hashing [Andoni-Razenshteyn '15, Andoni-Naor-Nikolov-et-al. '18], which have been recently studied in the context of nearest neighbor search. $\\bullet$ For all $p \\in [1, \\infty)$ and any $c$ larger than a fixed constant, we give an average-distortion sketch for $([\u0394]^d, \\ell_p)$ with approximation $c$ and bit-complexity $\\text{poly}(cp \\cdot 2^{p/c} \\cdot \\log(d\u0394))$, which is provably impossible in (worst-case) sketching. $\\bullet$ As an application, we improve on the approximation of sublinear-time data structures for nearest neighbor search over $\\ell_p$ (for large $p > 2$). The prior best approximation was $O(p)$ [Andoni-Naor-Nikolov-et-al. '18, Kush-Nikolov-Tang '21], and we show it can be any $c$ larger than a fixed constant (irrespective of $p$) by using $n^{\\text{poly}(cp \\cdot 2^{p/c})}$ space. We give some evidence that $2^{\u03a9(p/c)}$ space may be necessary by giving a lower bound on average-distortion sketches which produce a certain probabilistic certificate of farness (which our sketches crucially rely on).",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05158",
        "abstract url": "https://arxiv.org/abs/2411.05158",
        "title": "visionFinGAR: Transmission of Softness and Shape Motion by Vision Based Tactile Sensor and Combination of Mechanical and Electrical Stimulation",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper describes a system for transmitting softness and the motion of shape or contact area sensation using a vision based tactile sensor and a tactile display in which mechanical and electrical stimulation are combined. A unit of tactile sensor consists of a camera and markers, enable to detect a light touch, a pressure or a shape. On the other hand, a unit of tactile display consists of an electrode array and a mechanical arm to provide softness / pressure and shape perception. The display can provide four mode stimulation: anodic, cathodic, mechanical vibration and skin deformation; thus, it can reproduce a large range of tactile sensations. This study mainly aims to transmit a wide range of softness and shape motion perception with a vision based tactile sensor.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05159",
        "abstract url": "https://arxiv.org/abs/2411.05159",
        "title": "A self-healing tactile sensor using an optical waveguide",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose an optical tactile sensor using self-healing materials. The proposed tactile sensor consists of a structure that includes a diode, a phototransistor, and an optical waveguide made from self-healing materials. This design offers the advantage of being less susceptible to electromagnetic noise compared to traditional tactile sensors based on electrical detection principles. The sensor estimates the applied force by detecting changes in the total internal reflection caused by deformation due to contact force. In this study, we first established a fabrication method for the optical waveguide-based tactile sensor using self-healing materials. Subsequently, we measured the sensor output when a static load was applied to the fabricated tactile sensor and evaluated its characteristics. The results confirmed that the sensor output decreases in response to the applied load.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05160",
        "abstract url": "https://arxiv.org/abs/2411.05160",
        "title": "Measurement and Interpolation for Data-Driven Pressure Distribution Rendering on a Finger Pad",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a data-driven pressure distribution rendering method that uses the interpolation of experimentally obtained pressure values. The pressure data were collected using a pressure sensor array. The prediction was performed using linear interpolation, assuming that the pressure distribution is dependent on pushing displacement and contact angle. Leap Motion Controller was used to implement the prediction based on user input. The proposed prediction model was found to be fast and reproduce the measured data well.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05161",
        "abstract url": "https://arxiv.org/abs/2411.05161",
        "title": "Investigation of Tactile Texture Simulation on Online Shopping Experience",
        "rating": "-10",
        "keywords": [],
        "abstract": "With safety measures towards the current Covid-19 pandemic, many retails clothing stores have restricted on-site fittings and shifted their business online. Inability to touch on product evaluations shows an apparent limitation as compared to retail shopping especially when the object's material information is crucial like clothing. Haptic technologies show potential of bridging the gap between online shops and the shoppers by providing a sense of touch, yet little research has been done especially on the effect of the simulation of tactile texture on the shopping experience. In this study, we modified a mock-up e-commerce website by adding clothing products and enabling a mid-air haptic interface with Ultrahaptics Evaluation Kit (UHEV1). We developed texture sensations using Time Point Streaming (TSP) modulation for clothing products with different texture materials and a user study was carried out to investigate the tactile texture sensation on shoppers' experience in evaluating online products. Our results show that tactile texture sensation using multipoint mid-air haptic feedback improves online shopper's satisfaction on the product browsing experience. This study contributes to the improvement of general lifestyle of the society in terms of e-commerce experience and could expand its application to impact different sectors like education and different communities including the visually impaired.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05163",
        "abstract url": "https://arxiv.org/abs/2411.05163",
        "title": "Soft or Stiff? Stroop Tasks in Visuo-Tactile Tapping Interactions",
        "rating": "-10",
        "keywords": [],
        "abstract": "One of the key challenges in the field of haptic research is designing plausible stimuli using haptic interfaces with limited degrees of freedom. Although the plausible approach, which simplifies and/or exaggerates stimuli to enhance information transfer or create an artistic effect, has proven effective, evaluations of such stimuli have traditionally relied on subjective measures. This study aims to establish an objective evaluation method for haptic stimuli designed using the plausible approach. Focusing on stiffness/material perception, we developed a Stroop test within visuo-tactile tapping interactions in a virtual space. The demonstration system presents visual (textures) and tactile (vibration) stimuli at the moment of contact between a stylus and a cube, prompting participants to immediately identify the material they perceive visually. If the tactile stimuli are perceived as plausible, reaction times will be longer when the visual and tactile stimuli represent different materials than when they represent the same material.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05165",
        "abstract url": "https://arxiv.org/abs/2411.05165",
        "title": "Haptic Dial based on Magnetorheological Fluid Having Bumpy Structure",
        "rating": "-10",
        "keywords": [],
        "abstract": "We proposed a haptic dial based on magnetorheological fluid (MRF) which enhances performance by increasing the MRF-exposed area through concave shaft and housing structure. We developed a breakout-style game to show that the proposed haptic dial allows users to efficiently interact with virtual objects.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05166",
        "abstract url": "https://arxiv.org/abs/2411.05166",
        "title": "Out-of-body Localization of Virtual Vibration Sources Using a Limited Numbers of Transducers on the Torso",
        "rating": "-10",
        "keywords": [],
        "abstract": "Stereohaptic vibration is an innovative vibrotactile technology that extends the conventional tactile localization to the surrounding space, representing a virtual vibration source in the external environment. Previously, we have developed displays on the forearms and soles. Today, we present a demonstration of a new jacket-type device, which enables localization at any position around the body by arranging multiple vibrators along the torso centered on the midline. In our demonstration, you can experience the footsteps and roars of a inosaur walking around you, and it provides an experience that is as if you are in a fantasy movie.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "Part of proceedings of 6th International Conference AsiaHaptics 2024"
    },
    {
        "paper id": "2411.05185",
        "abstract url": "https://arxiv.org/abs/2411.05185",
        "title": "PentestAgent: Incorporating LLM Agents to Automated Penetration Testing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Penetration testing is a critical technique for identifying security vulnerabilities, traditionally performed manually by skilled security specialists. This complex process involves gathering information about the target system, identifying entry points, exploiting the system, and reporting findings. Despite its effectiveness, manual penetration testing is time-consuming and expensive, often requiring significant expertise and resources that many organizations cannot afford. While automated penetration testing methods have been proposed, they often fall short in real-world applications due to limitations in flexibility, adaptability, and implementation. Recent advancements in large language models (LLMs) offer new opportunities for enhancing penetration testing through increased intelligence and automation. However, current LLM-based approaches still face significant challenges, including limited penetration testing knowledge and a lack of comprehensive automation capabilities. To address these gaps, we propose PentestAgent, a novel LLM-based automated penetration testing framework that leverages the power of LLMs and various LLM-based techniques like Retrieval Augmented Generation (RAG) to enhance penetration testing knowledge and automate various tasks. Our framework leverages multi-agent collaboration to automate intelligence gathering, vulnerability analysis, and exploitation stages, reducing manual intervention. We evaluate PentestAgent using a comprehensive benchmark, demonstrating superior performance in task completion and overall efficiency. This work significantly advances the practical applicability of automated penetration testing systems.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "14 pages, 13 figures"
    },
    {
        "paper id": "2411.05187",
        "abstract url": "https://arxiv.org/abs/2411.05187",
        "title": "Cooperative Maximum Likelihood Target Position Estimation for MIMO-ISAC Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "This letter investigates target position estimation in integrated sensing and communications (ISAC) networks composed of multiple cooperating monostatic base stations (BSs). Each BS employs a MIMO-orthogonal time-frequency space (OTFS) scheme, enabling the coexistence of communication and sensing. A general cooperative maximum likelihood (ML) framework is derived, directly estimating the target position in a common reference system rather than relying on local range and angle estimates at each BS. Positioning accuracy is evaluated in single-target scenarios by varying the number of collaborating BSs, using root mean square error (RMSE), and comparing against the Cram\u00e9r-Rao lower bound. Numerical results demonstrate that the ML framework significantly reduces the position RMSE as the number of cooperating BSs increases.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2411.05211",
        "abstract url": "https://arxiv.org/abs/2411.05211",
        "title": "ARLang: An Outdoor Augmented Reality Application for Portuguese Vocabulary Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "With recent computer vision techniques and user-generated content, we can augment the physical world with metadata that describes attributes, such as names, geo-locations, and visual features of physical objects. To assess the benefits of these potentially ubiquitous labels for foreign vocabulary learning, we built a proof-of-concept system that displays bilingual text and sound labels on physical objects outdoors using augmented reality. Established tools for language learning have focused on effective content delivery methods such as books and flashcards. However, recent research and consumer learning tools have begun to focus on how learning can become more mobile, ubiquitous, and desirable. To test whether our system supports vocabulary learning, we conducted a preliminary between-subjects (N=44) study. Our results indicate that participants preferred learning with virtual labels on real-world objects outdoors over learning with flashcards. Our findings motivate further investigation into mobile AR-based learning systems in outdoor settings.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05229",
        "abstract url": "https://arxiv.org/abs/2411.05229",
        "title": "Further Evaluations of a Didactic CPU Visual Simulator (CPUVSIM)",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper discusses further evaluations of the educational effectiveness of an existing CPU visual simulator (CPUVSIM). The CPUVSIM, as an Open Educational Resource, has been iteratively improved over a number of years following an Open Pedagogy approach, and was designed to enhance novices understanding of computer operation and mapping from high-level code to assembly language. The literature reports previous evaluations of the simulator, at K12 and undergraduate level, conducted from the perspectives of both developers and students, albeit with a limited sample size and primarily through qualitative methods. This paper describes additional evaluation activities designed to provide a more comprehensive assessment, across diverse educational settings: an action research pilot study recently carried out in Singapore and the planning of a more quantitative-oriented study in Dubai, with a larger sample size. Results from the pilot study in Singapore confirm the effectiveness and high level of appreciation of the tool, alongside a few identified challenges, which inform the planning of the more comprehensive evaluation in Dubai.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2411.05230",
        "abstract url": "https://arxiv.org/abs/2411.05230",
        "title": "Feature Importance in the Context of Traditional and Just-In-Time Software Defect Prediction Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software defect prediction models can assist software testing initiatives by prioritizing testing error-prone modules. In recent years, in addition to the traditional defect prediction model approach of predicting defects from class, modules, etc., Just-In-Time defect prediction research, which focuses on the change history of software products is getting prominent. For building these defect prediction models, it is important to understand which features are primary contributors to these classifiers. This study considered developing defect prediction models incorporating the traditional and the Just-In-Time approaches from the publicly available dataset of the Apache Camel project. A multi-layer deep learning algorithm was applied to these datasets in comparison with machine learning algorithms. The deep learning algorithm achieved accuracies of 80% and 86%, with the area under receiving operator curve (AUC) scores of 66% and 78% for traditional and Just-In-Time defect prediction, respectively. Finally, the feature importance of these models was identified using a model-specific integrated gradient method and a model-agnostic Shapley Additive Explanation (SHAP) technique.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "5 pages, IEEE Canadian Conference on Electrical and Computer Engineering (CCECE), August/2024"
    },
    {
        "paper id": "2411.05245",
        "abstract url": "https://arxiv.org/abs/2411.05245",
        "title": "GraV: Grasp Volume Data for the Design of One-Handed XR Interfaces",
        "rating": "-10",
        "keywords": [],
        "abstract": "Everyday objects, like remote controls or electric toothbrushes, are crafted with hand-accessible interfaces. Expanding on this design principle, extended reality (XR) interfaces for physical tasks could facilitate interaction without necessitating the release of grasped tools, ensuring seamless workflow integration. While established data, such as hand anthropometric measurements, guide the design of handheld objects, XR currently lacks comparable data, regarding reachability, for single-hand interfaces while grasping objects. To address this, we identify critical design factors and a design space representing grasp-proximate interfaces and introduce a simulation tool for generating reachability and displacement cost data for designing these interfaces. Additionally, using the simulation tool, we generate a dataset based on grasp taxonomy and common household objects. Finally, we share insights from a design workshop that emphasizes the significance of reachability and motion cost data, empowering XR creators to develop bespoke interfaces tailored specifically to grasping hands.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05258",
        "abstract url": "https://arxiv.org/abs/2411.05258",
        "title": "GroupBeaMR: Analyzing Collaborative Group Behavior in Mixed Reality Through Passive Sensing and Sociometry",
        "rating": "-10",
        "keywords": [],
        "abstract": "Understanding group behavior is essential for improving collaboration and productivity. While research on group behavior in virtual reality (VR) is significantly advanced, understanding group dynamics in mixed reality (MR) remains understudied. Understanding MR group dynamics will enable designing systems that optimize collaboration, enhance productivity, and improve user experiences. This work outlines how MR headsets sensory systems can effectively capture group behavior, devise algorithms to process and interpret the data and demonstrate the correlation between group behavior and task-related performance metrics. We propose a framework for group behavior analysis in MR, or GroupBeaMR for short, to capture and analyze group behavior in MR. Using the rich sensory capabilities of MR headsets, GroupBeaMR passively collects data on conversation, shared attention, and proximity. This data is processed using social network analysis techniques to identify patterns of interaction and assess group behavior. Our evaluation, involving 44 participants in 11 groups, demonstrates the effectiveness of GroupBeaMR in capturing and analyzing group behavior in collaborative MR tasks. An example of insight from GroupBeaMR is that balanced participation in different types of interaction leads to higher group cohesion. These findings enable real-time assessments of group behavior in MR that can enhance collaborative experiences.",
        "subjects": [
            "cs.HC",
            "cs.ET"
        ],
        "comment": "37 pages, 18 figures, 10 tables"
    },
    {
        "paper id": "2411.05267",
        "abstract url": "https://arxiv.org/abs/2411.05267",
        "title": "Optimal Design to Dual-Scale Channel Estimation for Sensing-Assisted Communication Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Sensing-assisted communication is critical to enhance the system efficiency in integrated sensing and communication (ISAC) systems. However, most existing literature focuses on large-scale channel sensing, without considering the impacts of small-scale channel aging. In this paper, we investigate a dual-scale channel estimation framework for sensing-assisted communication, where both large-scale channel sensing and small-scale channel aging are considered. By modeling the channel aging effect with block fading and incorporating CRB (Cram\u00e9r-Rao bound)-based sensing errors, we optimize both the time duration of large-scale detection and the frequency of small-scale update within each subframe to maximize the achievable rate while satisfying sensing requirements. Since the formulated optimization problem is non-convex, we propose a two-dimensional search-based optimization algorithm to obtain the optimal solution. Simulation results demonstrate the superiority of our proposed optimal design over three counterparts.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "9 pages, 4 figures, conference"
    },
    {
        "paper id": "2411.05272",
        "abstract url": "https://arxiv.org/abs/2411.05272",
        "title": "Tap into Reality: Understanding the Impact of Interactions on Presence and Reaction Time in Mixed Reality",
        "rating": "-10",
        "keywords": [],
        "abstract": "Enhancing presence in mixed reality (MR) relies on precise measurement and quantification. While presence has traditionally been measured through subjective questionnaires, recent research links presence with objective metrics like reaction time. Past studies examined this correlation with varying technical factors (object realism and behavior) and human conditioning, but the impact of interaction remains unclear. To answer this question, we conducted a within-subjects study (N=50) to explore the correlation between presence and reaction time across two interaction scenarios (direct and symbolic) with two tasks (selection and manipulation). We found that presence scores and reaction times are correlated (correlation coefficient of $-0.54$), suggesting that the impact of interaction on reaction time correlates with its effect on presence.",
        "subjects": [
            "cs.HC",
            "cs.ET"
        ],
        "comment": "11 pages, 9 figures, 3 tables"
    },
    {
        "paper id": "2411.05275",
        "abstract url": "https://arxiv.org/abs/2411.05275",
        "title": "Reaction Time as a Proxy for Presence in Mixed Reality with Distraction",
        "rating": "-10",
        "keywords": [],
        "abstract": "Distractions in mixed reality (MR) environments can significantly influence user experience, affecting key factors such as presence, reaction time, cognitive load, and Break in Presence (BIP). Presence measures immersion, reaction time captures user responsiveness, cognitive load reflects mental effort, and BIP represents moments when attention shifts from the virtual to the real world, breaking immersion. However, the effects of distractions on these elements remain insufficiently explored. To address this gap, we have presented a theoretical model to understand how congruent and incongruent distractions affect all these constructs. We conducted a within-subject study (N=54) where participants performed image-sorting tasks under different distraction conditions. Our findings show that incongruent distractions significantly increase cognitive load, slow reaction times, and elevate BIP frequency, with presence mediating these effects.",
        "subjects": [
            "cs.HC",
            "cs.ET"
        ],
        "comment": "11 pages, 10 figures, 7 tables"
    },
    {
        "paper id": "2411.05278",
        "abstract url": "https://arxiv.org/abs/2411.05278",
        "title": "Integrated Location Sensing and Communication for Ultra-Massive MIMO With Hybrid-Field Beam-Squint Effect",
        "rating": "-10",
        "keywords": [],
        "abstract": "The advent of ultra-massive multiple-input-multiple output systems holds great promise for next-generation communications, yet their channels exhibit hybrid far- and near- field beam-squint (HFBS) effect. In this paper, we not only overcome but also harness the HFBS effect to propose an integrated location sensing and communication (ILSC) framework. During the uplink training stage, user terminals (UTs) transmit reference signals for simultaneous channel estimation and location sensing. This stage leverages an elaborately designed hybrid-field projection matrix to overcome the HFBS effect and estimate the channel in compressive manner. Subsequently, the scatterers' locations can be sensed from the spherical wavefront based on the channel estimation results. By treating the sensed scatterers as virtual anchors, we employ a weighted least-squares approach to derive UT' s location. Moreover, we propose an iterative refinement mechanism, which utilizes the accurately estimated time difference of arrival of multipath components to enhance location sensing precision. In the following downlink data transmission stage, we leverage the acquired location information to further optimize the hybrid beamformer, which combines the beam broadening and focusing to mitigate the spectral efficiency degradation resulted from the HFBS effect. Extensive simulation experiments demonstrate that the proposed ILSC scheme has superior location sensing and communication performance than conventional methods.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "This paper has been accepted by IEEE JSAC"
    },
    {
        "paper id": "2411.05286",
        "abstract url": "https://arxiv.org/abs/2411.05286",
        "title": "Metrology and Manufacturing-Integrated Digital Twin (MM-DT) for Advanced Manufacturing: Insights from CMM and FARO Arm Measurements",
        "rating": "-10",
        "keywords": [],
        "abstract": "Metrology, the science of measurement, plays a key role in Advanced Manufacturing (AM) to ensure quality control, process optimization, and predictive maintenance. However, it has often been overlooked in AM domains due to the current focus on automation and the complexity of integrated precise measurement systems. Over the years, Digital Twin (DT) technology in AM has gained much attention due to its potential to address these challenges through physical data integration and real-time monitoring, though its use in metrology remains limited. Taking this into account, this study proposes a novel framework, the Metrology and Manufacturing-Integrated Digital Twin (MM-DT), which focuses on data from two metrology tools, collected from Coordinate Measuring Machines (CMM) and FARO Arm devices. Throughout this process, we measured 20 manufacturing parts, with each part assessed twice under different temperature conditions. Using Ensemble Machine Learning methods, our proposed approach predicts measurement deviations accurately, achieving an R2 score of 0.91 and reducing the Root Mean Square Error (RMSE) to 1.59 micrometers. Our MM-DT framework demonstrates its efficiency by improving metrology processes and offers valuable insights for researchers and practitioners who aim to increase manufacturing precision and quality.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05288",
        "abstract url": "https://arxiv.org/abs/2411.05288",
        "title": "Balancing Pipeline Parallelism with Vocabulary Parallelism",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pipeline parallelism is widely used to scale the training of transformer-based large language models, various works have been done to improve its throughput and memory footprint. In this paper, we address a frequently overlooked issue: the vocabulary layers can cause imbalanced computation and memory usage across pipeline stages, worsening pipeline bubbles and the memory bottleneck. To tackle this, we partition the vocabulary layers evenly across pipeline devices and group the computation into pipeline passes. To reduce the activation memory overhead, we propose several algorithms to reduce communication barriers within vocabulary layers. Additionally, we utilize a generalizable method to integrate Vocabulary Parallelism with existing pipeline schedules. By combining these techniques, our methods effectively balance the computation and parameter memory, with only a small constant activation memory overhead. Notably, when combined with activation memory-balanced schedules like V-Half, our approach achieves perfect balance in both memory and computation. Extensive evaluations demonstrate that our method achieves computation and memory balance regardless of the vocabulary size, resulting in a 5% to 51% improvement in throughput compared to naive approaches, meanwhile significantly reducing peak memory usage especially for large vocabulary scenarios. Our implementation is open-sourced at https://github.com/sail-sg/VocabularyParallelism .",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05295",
        "abstract url": "https://arxiv.org/abs/2411.05295",
        "title": "Content-Adaptive Rate-Quality Curve Prediction Model in Media Processing System",
        "rating": "-10",
        "keywords": [],
        "abstract": "In streaming media services, video transcoding is a common practice to alleviate bandwidth demands. Unfortunately, traditional methods employing a uniform rate factor (RF) across all videos often result in significant inefficiencies. Content-adaptive encoding (CAE) techniques address this by dynamically adjusting encoding parameters based on video content characteristics. However, existing CAE methods are often tightly coupled with specific encoding strategies, leading to inflexibility. In this paper, we propose a model that predicts both RF-quality and RF-bitrate curves, which can be utilized to derive a comprehensive bitrate-quality curve. This approach facilitates flexible adjustments to the encoding strategy without necessitating model retraining. The model leverages codec features, content features, and anchor features to predict the bitrate-quality curve accurately. Additionally, we introduce an anchor suspension method to enhance prediction accuracy. Experiments confirm that the actual quality metric (VMAF) of the compressed video stays within 1 of the target, achieving an accuracy of 99.14%. By incorporating our quality improvement strategy with the rate-quality curve prediction model, we conducted online A/B tests, obtaining both +0.107% improvements in video views and video completions and +0.064% app duration time. Our model has been deployed on the Xiaohongshu App.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "Accepted by IEEE VCIP 2024 (Oral)"
    },
    {
        "paper id": "2411.05305",
        "abstract url": "https://arxiv.org/abs/2411.05305",
        "title": "Hybrid Precoding with Per-Beam Timing Advance for Asynchronous Cell-free mmWave Massive MIMO-OFDM Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cell-free massive multiple-input-multiple-output (CF-mMIMO) is regarded as one of the promising technologies for next-generation wireless networks. However, due to its distributed architecture, geographically separated access points (APs) jointly serve a large number of user-equipments (UEs), there will inevitably be a discrepancies in the arrival time of transmitted signals. In this paper, we investigate millimeter-wave (mmWave) CF-mMIMO orthogonal frequency division multiplexing (OFDM) systems with asynchronous reception in a wide area coverage scenario, where asynchronous timing offsets may extend far beyond the cyclic prefix (CP) range. A comprehensive asynchronous beam-domain signal transmission model is presented for mmWave CF-mMIMO-OFDM systems in both downlink and uplink, incorporating phase offset, inter-carrier interference (ICI) and inter-symbol interference (ISI). To address the issue of asynchronous reception, we propose a novel per-beam timing advance (PBTA) hybrid precoding architecture and analyze the spectral efficiency (SE) in the beam domain for downlink and uplink asynchronous receptions. Both scalable centralized and distributed implementations are taken into account, and the asynchronous delay phase is utilized to design precoding/combining vectors. Furthermore, we formulate the sum rate maximization problem and develop two low-complexity joint beam selection and UE association algorithms considering the impact of asynchronous timing offset exceeding the CP range. Simulation results demonstrate that the performance will be severely limited by ICI and ISI, and our proposed PBTA hybrid precoding architecture effectively mitigates asynchronous interference compared to the nearest AAU/UE-based timing-advance scheme. Additionally, numerical results show that our proposed low-complexity joint beam selection and UE association algorithms achieve superior SE performance.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05317",
        "abstract url": "https://arxiv.org/abs/2411.05317",
        "title": "SeqRFM: Fast RFM Analysis in Sequence Data",
        "rating": "-10",
        "keywords": [],
        "abstract": "In recent years, data mining technologies have been well applied to many domains, including e-commerce. In customer relationship management (CRM), the RFM analysis model is one of the most effective approaches to increase the profits of major enterprises. However, with the rapid development of e-commerce, the diversity and abundance of e-commerce data pose a challenge to mining efficiency. Moreover, in actual market transactions, the chronological order of transactions reflects customer behavior and preferences. To address these challenges, we develop an effective algorithm called SeqRFM, which combines sequential pattern mining with RFM models. SeqRFM considers each customer's recency (R), frequency (F), and monetary (M) scores to represent the significance of the customer and identifies sequences with high recency, high frequency, and high monetary value. A series of experiments demonstrate the superiority and effectiveness of the SeqRFM algorithm compared to the most advanced RFM algorithms based on sequential pattern mining. The source code and datasets are available at GitHub https://github.com/DSI-Lab1/SeqRFM.",
        "subjects": [
            "cs.DB"
        ],
        "comment": "Preprint. 5 figures, 5 tables"
    },
    {
        "paper id": "2411.05323",
        "abstract url": "https://arxiv.org/abs/2411.05323",
        "title": "TraDE: Network and Traffic-aware Adaptive Scheduling for Microservices Under Dynamics",
        "rating": "-10",
        "keywords": [],
        "abstract": "The transition from monolithic architecture to microservices has enhanced flexibility in application design and its scalable execution. This approach often involves using a computing cluster managed by a container orchestration platform, which supports the deployment of microservices. However, this shift introduces significant challenges, particularly in the efficient scheduling of containerized services. These challenges are compounded by unpredictable scenarios such as dynamic incoming workloads with various execution traffic and variable communication delays among cluster nodes. Existing works often overlook the real-time traffic impacts of dynamic requests on running microservices, as well as the varied communication delays across cluster nodes. Consequently, even optimally deployed microservices could suffer from significant performance degradation over time. To address these issues, we introduce a network and traffic-aware adaptive scheduling framework, TraDE. This framework can adaptively redeploy microservice containers to maintain desired performance amid changing traffic and network conditions within the hosting cluster. We have implemented TraDE as an extension to the Kubernetes platform. Additionally, we deployed realistic microservice applications in a real compute cluster and conducted extensive experiments to assess our framework's performance in various scenarios. The results demonstrate the effectiveness of TraDE in rescheduling running microservices to enhance end-to-end performance while maintaining a high goodput ratio. Compared with the existing method NetMARKS, TraDE outperforms it by reducing the average response time of the application by up to 48.3\\%, and improving the throughput by up to 1.4x while maintaining a goodput ratio of 95.36\\% and showing robust adaptive capability under sustained workloads.",
        "subjects": [
            "cs.NI",
            "cs.DC",
            "cs.ET",
            "cs.PF"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2411.05870",
        "abstract url": "https://arxiv.org/abs/2411.05870",
        "title": "An Adaptive Online Smoother with Closed-Form Solutions and Information-Theoretic Lag Selection for Conditional Gaussian Nonlinear Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Data assimilation (DA) combines partial observations with a dynamical model to improve state estimation. Filter-based DA uses only past and present data and is the prerequisite for real-time forecasts. Smoother-based DA exploits both past and future observations. It aims to fill in missing data, provide more accurate estimations, and develop high-quality datasets. However, the standard smoothing procedure requires using all historical state estimations, which is storage-demanding, especially for high-dimensional systems. This paper develops an adaptive-lag online smoother for a large class of complex dynamical systems with strong nonlinear and non-Gaussian features, which has important applications to many real-world problems. The adaptive lag allows the DA to utilize only observations within a nearby window, significantly reducing computational storage. Online lag adjustment is essential for tackling turbulent systems, where temporal autocorrelation varies significantly over time due to intermittency, extreme events, and nonlinearity. Based on the uncertainty reduction in the estimated state, an information criterion is developed to systematically determine the adaptive lag. Notably, the mathematical structure of these systems facilitates the use of closed analytic formulae to calculate the online smoother and the adaptive lag, avoiding empirical tunings as in ensemble-based DA methods. The adaptive online smoother is applied to studying three important scientific problems. First, it helps detect online causal relationships between state variables. Second, its advantage of computational storage is illustrated via Lagrangian DA, a high-dimensional nonlinear problem. Finally, the adaptive smoother advances online parameter estimation with partial observations, emphasizing the role of the observed extreme events in accelerating convergence.",
        "subjects": [
            "eess.SY",
            "math.DS",
            "math.PR",
            "physics.data-an",
            "stat.ME"
        ],
        "comment": "40 pages, 7 figures, typeset in LaTeX. Submitted for peer-review to Springer Nature's Journal of Nonlinear Science. For more info see https://sites.google.com/wisc.edu/mariosandreou/pubs-and-talks/cgns-online-martingale-free#h.55a05qfs9w12"
    }
]